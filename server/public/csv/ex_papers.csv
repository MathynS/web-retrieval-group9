id,year,title,event_type,pdf_name,abstract,paper_text
1,1987,"Self-Organization of Associative Database and Its Applications","",1-self-organization-of-associative-database-and-its-applications.pdf,"Abstract Missing","767

SELF-ORGANIZATION OF ASSOCIATIVE DATABASE
AND ITS APPLICATIONS
Hisashi Suzuki and Suguru Arimoto
Osaka University, Toyonaka, Osaka 560, Japan
ABSTRACT
An efficient method of self-organizing associative databases is proposed together with
applications to robot eyesight systems. The proposed databases can associate any input
with some output. In the first half part of discussion, an algorithm of self-organization is
proposed. From an aspect of hardware, it produces a new style of neural network. In the
latter half part, an applicability to handwritten letter recognition and that to an autonomous
mobile robot system are demonstrated.

INTRODUCTION
Let a mapping f : X -+ Y be given. Here, X is a finite or infinite set, and Y is another
finite or infinite set. A learning machine observes any set of pairs (x, y) sampled randomly
from X x Y. (X x Y means the Cartesian product of X and Y.) And, it computes some
estimate j : X -+ Y of f to make small, the estimation error in some measure.
Usually we say that: the faster the decrease of estimation error with increase of the number of samples, the better the learning machine. However, such expression on performance
is incomplete. Since, it lacks consideration on the candidates of J of j assumed preliminarily. Then, how should we find out good learning machines? To clarify this conception,
let us discuss for a while on some types of learning machines. And, let us advance the
understanding of the self-organization of associative database .
. Parameter Type
An ordinary type of learning machine assumes an equation relating x's and y's with
parameters being indefinite, namely, a structure of f. It is equivalent to define implicitly a
set F of candidates of
(F is some subset of mappings from X to Y.) And, it computes
values of the parameters based on the observed samples. We call such type a parameter
type.
For a learning machine defined well, if F 3 f, j approaches f as the number of samples
increases. In the alternative case, however, some estimation error remains eternally. Thus,
a problem of designing a learning machine returns to find out a proper structure of f in this
sense.
On the other hand, the assumed structure of f is demanded to be as compact as possible
to achieve a fast learning. In other words, the number of parameters should be small. Since,
if the parameters are few, some j can be uniquely determined even though the observed
samples are few. However, this demand of being proper contradicts to that of being compact.
Consequently, in the parameter type, the better the compactness of the assumed structure
that is proper, the better the learning machine. This is the most elementary conception
when we design learning machines .

1.

. Universality and Ordinary Neural Networks
Now suppose that a sufficient knowledge on f is given though J itself is unknown. In
this case, it is comparatively easy to find out proper and compact structures of J. In the
alternative case, however, it is sometimes difficult. A possible solution is to give up the
compactness and assume an almighty structure that can cover various 1's. A combination
of some orthogonal bases of the infinite dimension is such a structure. Neural networks 1 ,2
are its approximations obtained by truncating finitely the dimension for implementation.

? American Institute of Physics 1988

768
A main topic in designing neural networks is to establish such desirable structures of 1.
This work includes developing practical procedures that compute values of coefficients from
the observed samples. Such discussions are :flourishing since 1980 while many efficient methods have been proposed. Recently, even hardware units computing coefficients in parallel
for speed-up are sold, e.g., ANZA, Mark III, Odyssey and E-1.
Nevertheless, in neural networks, there always exists a danger of some error remaining
eternally in estimating /. Precisely speaking, suppose that a combination of the bases of a
finite number can define a structure of 1 essentially. In other words, suppose that F 3 /, or
1 is located near F. In such case, the estimation error is none or negligible. However, if 1
is distant from F, the estimation error never becomes negligible. Indeed, many researches
report that the following situation appears when 1 is too complex. Once the estimation
error converges to some value (> 0) as the number of samples increases, it decreases hardly
even though the dimension is heighten. This property sometimes is a considerable defect of
neural networks .
. Recursi ve Type
The recursive type is founded on another methodology of learning that should be as
follows. At the initial stage of no sample, the set Fa (instead of notation F) of candidates
of I equals to the set of all mappings from X to Y. After observing the first sample
(Xl, Yl) E X x Y, Fa is reduced to Fi so that I(xt) = Yl for any I E F. After observing
the second sample (X2' Y2) E X x Y, Fl is further reduced to F2 so that i(xt) = Yl and
I(X2) = Y2 for any I E F. Thus, the candidate set F becomes gradually small as observation
of samples proceeds. The after observing i-samples, which we write
is one of the most
likelihood estimation of 1 selected in fi;. Hence, contrarily to the parameter type, the
recursive type guarantees surely that j approaches to 1 as the number of samples increases.
The recursive type, if observes a sample (x"" yd, rewrites values 1,-l(X),S to I,(x)'s for
some x's correlated to the sample. Hence, this type has an architecture composed of a rule
for rewriting and a free memory space. Such architecture forms naturally a kind of database
that builds up management systems of data in a self-organizing way. However, this database
differs from ordinary ones in the following sense. It does not only record the samples already
observed, but computes some estimation of l(x) for any x E X. We call such database an
associative database.
The first subject in constructing associative databases is how we establish the rule for
rewri ting. For this purpose, we adap t a measure called the dissimilari ty. Here, a dissimilari ty
means a mapping d : X x X -+ {reals > O} such that for any (x, x) E X x X, d(x, x) > 0
whenever l(x) t /(x). However, it is not necessarily defined with a single formula. It is
definable with, for example, a collection of rules written in forms of ""if? .. then?? .. ""
The dissimilarity d defines a structure of 1 locally in X x Y. Hence, even though
the knowledge on f is imperfect, we can re:flect it on d in some heuristic way. Hence,
contrarily to neural networks, it is possible to accelerate the speed of learning by establishing
d well. Especially, we can easily find out simple d's for those l's which process analogically
information like a human. (See the applications in this paper.) And, for such /'s, the
recursive type shows strongly its effectiveness.
We denote a sequence of observed samples by (Xl, Yd, (X2' Y2),???. One of the simplest
constructions of associative databases after observing i-samples (i = 1,2,.,,) is as follows.

i

i""

I,

Algorithm 1. At the initial stage, let So be the empty set. For every i =
1,2"" .. , let i,-l(x) for any x E X equal some y* such that (x*,y*) E S,-l and

d(x, x*) =

min
(%,y)ES.-t

d(x, x) .

Furthermore, add (x"" y,) to S;-l to produce Sa, i.e., S, = S,_l U {(x""

(1)

y,n.

769

Another version improved to economize the memory is as follows.

Algorithm 2, At the initial stage, let So be composed of an arbitrary element
in X x Y. For every i = 1,2"""", let ii-lex) for any x E X equal some y. such
that (x?, y.) E Si-l and
d(x, x?) =

min

d(x, x) .

(i,i)ES.-l

Furthermore, if ii-l(Xi) # Yi then let Si = Si-l, or add (Xi, Yi) to Si-l to
produce Si, i.e., Si = Si-l U {(Xi, Yi)}'
In either construction, ii approaches to f as i increases. However, the computation time
grows proportionally to the size of Si. The second subject in constructing associative
databases is what addressing rule we should employ to economize the computation time. In
the subsequent chapters, a construction of associative database for this purpose is proposed.
It manages data in a form of binary tree.

SELF-ORGANIZATION OF ASSOCIATIVE DATABASE
Given a sample sequence (Xl, Yl), (X2' Y2), .. "" the algorithm for constructing associative
database is as follows.

Algorithm 3,'

Step I(Initialization): Let (x[root], y[root]) = (Xl, Yd. Here, x[.] and y[.] are
variables assigned for respective nodes to memorize data.. Furthermore, let t = 1.
Step 2: Increase t by 1, and put x, in. After reset a pointer n to the root, repeat
the following until n arrives at some terminal node, i.e., leaf.
Notations nand
d(xt, x[n)), let n

n mean the descendant nodes of n.
=n. Otherwise, let n =n.

If d(x"" r[n)) ~

Step 3: Display yIn] as the related information. Next, put y, in. If yIn] = y"" back
to step 2. Otherwise, first establish new descendant nodes n and n. Secondly,
let

(x[n], yIn))
(x[n], yIn))

(x[n], yIn)),
(Xt, y,).

(2)
(3)

Finally, back to step 2. Here, the loop of step 2-3 can be stopped at any time
and also can be continued.
Now, suppose that gate elements, namely, artificial ""synapses"" that play the role of branching by d are prepared. Then, we obtain a new style of neural network with gate elements
being randomly connected by this algorithm.

LETTER RECOGNITION
Recen tly, the vertical slitting method for recognizing typographic English letters3 , the
elastic matching method for recognizing hand written discrete English letters4 , the global
training and fuzzy logic search method for recognizing Chinese characters written in square
styleS, etc. are published. The self-organization of associative database realizes the recognition of handwritten continuous English letters.

770

9 /wn""

NOV

~ ~ ~ -xk :La.t

~~ ~ ~~~

dw1lo'

~~~~~of~~

~~~ 4,-?~~4Fig. 1. Source document.
2~~---------------'

lOO~---------------'

H

o

o
Fig. 2. Windowing.

1000

2000

3000

4000

Number of samples

o

1000

2000

3000

4000

NUAlber of sampl es

Fig. 3. An experiment result.

An image scanner takes a document image (Fig. 1). The letter recognizer uses a parallelogram window that at least can cover the maximal letter (Fig. 2), and processes the
sequence of letters while shifting the window. That is, the recognizer scans a word in a
slant direction. And, it places the window so that its left vicinity may be on the first black
point detected. Then, the window catches a letter and some part of the succeeding letter.
If recognition of the head letter is performed, its end position, namely, the boundary line
between two letters becomes known. Hence, by starting the scanning from this boundary
and repeating the above operations, the recognizer accomplishes recursively the task. Thus
the major problem comes to identifying the head letter in the window.
Considering it, we define the following.
? Regard window images as x's, and define X accordingly.
? For a (x, x) E X x X, denote by B a black point in the left area from the boundary on
window image X. Project each B onto window image x. Then, measure the Euclidean
distance 6 between fj and a black point B on x being the closest to B. Let d(x, x) be
the summation of 6's for all black points B's on x divided by the number of B's.
? Regard couples of the ""reading"" and the position of boundary as y's, and define Y
accordingly.
An operator teaches the recognizer in interaction the relation between window image and
reading& boundary with algorithm 3. Precisely, if the recalled reading is incorrect, the
operator teaches a correct reading via the console. Moreover, if the boundary position is
incorrect, he teaches a correct position via the mouse.
Fig. 1 shows partially a document image used in this experiment. Fig. 3 shows the
change of the number of nodes and that of the recognition rate defined as the relative
frequency of correct answers in the past 1000 trials. Speciiications of the window are height
= 20dot, width = 10dot, and slant angular = 68deg. In this example, the levels of tree
were distributed in 6-19 at time 4000 and the recognition rate converged to about 74%.
Experimentally, the recognition rate converges to about 60-85% in most cases, and to 95% at
a rare case. However, it does not attain 100% since, e.g., ""c"" and ""e"" are not distinguishable
because of excessive lluctuation in writing. If the consistency of the x, y-relation is not
assured like this, the number of nodes increases endlessly (d. Fig. 3). Hence, it is clever to
stop the learning when the recognition rate attains some upper limit. To improve further
the recognition rate, we must consider the spelling of words. It is one of future subjects.

771

OBSTACLE AVOIDING MOVEMENT
Various systems of camera type autonomous mobile robot are reported flourishingly6-1O.
The system made up by the authors (Fig. 4) also belongs to this category. Now, in mathematical methodologies, we solve usually the problem of obstacle avoiding movement as
a cost minimization problem under some cost criterion established artificially. Contrarily,
the self-organization of associative database reproduces faithfully the cost criterion of an
operator. Therefore, motion of the robot after learning becomes very natural.
Now, the length, width and height of the robot are all about O.7m, and the weight is
about 30kg. The visual angle of camera is about 55deg. The robot has the following three
factors of motion. It turns less than ?30deg, advances less than 1m, and controls speed less
than 3km/h. The experiment was done on the passageway of wid th 2.5m inside a building
which the authors' laboratories exist in (Fig. 5). Because of an experimental intention, we
arrange boxes, smoking stands, gas cylinders, stools, handcarts, etc. on the passage way at
random. We let the robot take an image through the camera, recall a similar image, and
trace the route preliminarily recorded on it. For this purpose, we define the following.
? Let the camera face 28deg downward to take an image, and process it through a low
pass filter. Scanning vertically the filtered image from the bottom to the top, search
the first point C where the luminance changes excessively. Then, su bstitu te all points
from the bottom to C for white, and all points from C to the top for black (Fig. 6).
(If no obstacle exists just in front of the robot, the white area shows the ''free'' area
where the robot can move around.) Regard binary 32 x 32dot images processed thus
as x's, and define X accordingly.
? For every (x, x) E X x X, let d(x, x) be the number of black points on the exclusive-or
image between x and X.
? Regard as y's the images obtained by drawing routes on images x's, and define Y
accordingly.
The robot superimposes, on the current camera image x, the route recalled for x, and
inquires the operator instructions. The operator judges subjectively whether the suggested
route is appropriate or not. In the negative answer, he draws a desirable route on x with the
mouse to teach a new y to the robot. This opera.tion defines implicitly a sample sequence
of (x, y) reflecting the cost criterion of the operator.

.::l"" !
-

IibUBe

_. -

22

11

Roan

12

{-

13

Stationary uni t

Fig. 4. Configuration of
autonomous mobile robot system.

~

I

,

23

24

North
14

rmbi Ie unit (robot)

-

Roan

y

t

Fig. 5. Experimental
environment.

772

Wall

Camera image

Preprocessing

A

::: !fa

?

Preprocessing

0

O

Course
suggest ion

??

..

Search

A

Fig. 6. Processing for
obstacle avoiding movement.

x

Fig. 1. Processing for
position identification.
We define the satisfaction rate by the relative frequency of acceptable suggestions of
route in the past 100 trials. In a typical experiment, the change of satisfaction rate showed
a similar tendency to Fig. 3, and it attains about 95% around time 800. Here, notice that
the rest 5% does not mean directly the percentage of collision. (In practice, we prevent the
collision by adopting some supplementary measure.) At time 800, the number of nodes was
145, and the levels of tree were distributed in 6-17.
The proposed method reflects delicately various characters of operator. For example, a
robot trained by an operator 0 moves slowly with enough space against obstacles while one
trained by another operator 0' brushes quickly against obstacles. This fact gives us a hint
on a method of printing ""characters"" into machines.
POSITION IDENTIFICATION
The robot can identify its position by recalling a similar landscape with the position data
to a camera image. For this purpose, in principle, it suffices to regard camera images and
position data as x's and y's, respectively. However, the memory capacity is finite in actual
compu ters. Hence, we cannot but compress the camera images at a slight loss of information.
Such compression is admittable as long as the precision of position identification is in an
acceptable area. Thus, the major problem comes to find out some suitable compression
method.
In the experimental environment (Fig. 5), juts are on the passageway at intervals of
3.6m, and each section between adjacent juts has at most one door. The robot identifies
roughly from a surrounding landscape which section itself places in. And, it uses temporarily
a triangular surveying technique if an exact measure is necessary. To realize the former task,
we define the following .
? Turn the camera to take a panorama image of 360deg. Scanning horizontally the
center line, substitute the points where the luminance excessively changes for black
and the other points for white (Fig. 1). Regard binary 360dot line images processed
thus as x's, and define X accordingly.
? For every (x, x) E X x X, project each black point A on x onto x. And, measure the
Euclidean distance 6 between A and a black point A on x being the closest to A. Let
the summation of 6 be S. Similarly, calculate S by exchanging the roles of x and X.
Denoting the numbers of A's and A's respectively by nand n, define

773

d(x, x) =

~(~
+ ~).
2 n
n

(4)

? Regard positive integers labeled on sections as y's (cf. Fig. 5), and define Y accordingly.
In the learning mode, the robot checks exactly its position with a counter that is reset periodically by the operator. The robot runs arbitrarily on the passageways within 18m area
and learns the relation between landscapes and position data. (Position identification beyond 18m area is achieved by crossing plural databases one another.) This task is automatic
excepting the periodic reset of counter, namely, it is a kind of learning without teacher.
We define the identification rate by the relative frequency of correct recalls of position
data in the past 100 trials. In a typical example, it converged to about 83% around time
400. At time 400, the number of levels was 202, and the levels oftree were distributed in 522. Since the identification failures of 17% can be rejected by considering the trajectory, no
pro blem arises in practical use. In order to improve the identification rate, the compression
ratio of camera images must be loosened. Such possibility depends on improvement of the
hardware in the future.
Fig. 8 shows an example of actual motion of the robot based on the database for obstacle
avoiding movement and that for position identification. This example corresponds to a case
of moving from 14 to 23 in Fig. 5. Here, the time interval per frame is about 40sec.

,~. .~ (
;~""i..
~

""

""

.

..I

I

?
?

""

I'
.
'.1
t

;

i

-:
, . . , 'II

Fig. 8. Actual motion of the robot.

774

CONCLUSION
A method of self-organizing associative databases was proposed with the application to
robot eyesight systems. The machine decomposes a global structure unknown into a set of
local structures known and learns universally any input-output response. This framework
of problem implies a wide application area other than the examples shown in this paper.
A defect of the algorithm 3 of self-organization is that the tree is balanced well only
for a subclass of structures of f. A subject imposed us is to widen the class. A probable
solution is to abolish the addressing rule depending directly on values of d and, instead, to
establish another rule depending on the distribution function of values of d. It is now under
investigation.

REFERENCES
1. Hopfield, J. J. and D. W. Tank, ""Computing with Neural Circuit: A Model/'

Science 233 (1986), pp. 625-633.
2. Rumelhart, D. E. et al., ""Learning Representations by Back-Propagating Errors,"" Nature 323 (1986), pp. 533-536.

3. Hull, J. J., ""Hypothesis Generation in a Computational Model for Visual Word
Recognition,"" IEEE Expert, Fall (1986), pp. 63-70.
4. Kurtzberg, J. M., ""Feature Analysis for Symbol Recognition by Elastic Matching,"" IBM J. Res. Develop. 31-1 (1987), pp. 91-95.

5. Wang, Q. R. and C. Y. Suen, ""Large Tree Classifier with Heuristic Search and
Global Training,"" IEEE Trans. Pattern. Anal. & Mach. Intell. PAMI 9-1
(1987) pp. 91-102.
6. Brooks, R. A. et al, ""Self Calibration of Motion and Stereo Vision for Mobile
Robots,"" 4th Int. Symp. of Robotics Research (1987), pp. 267-276.
7. Goto, Y. and A. Stentz, ""The CMU System for Mobile Robot Navigation,"" 1987
IEEE Int. Conf. on Robotics & Automation (1987), pp. 99-105.
8. Madarasz, R. et al., ""The Design of an Autonomous Vehicle for the Disabled,""
IEEE Jour. of Robotics & Automation RA 2-3 (1986), pp. 117-125.
9. Triendl, E. and D. J. Kriegman, ""Stereo Vision and Navigation within Buildings,"" 1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 1725-1730.
10. Turk, M. A. et al., ""Video Road-Following for the Autonomous Land Vehicle,""
1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 273-279.

"
2,1987,"The Capacity of the Kanerva Associative Memory is Exponential","",2-the-capacity-of-the-kanerva-associative-memory-is-exponential.pdf,"Abstract Missing","184

THE CAPACITY OF THE KANERVA ASSOCIATIVE MEMORY IS EXPONENTIAL
P. A. Choul
Stanford University. Stanford. CA 94305
ABSTRACT
The capacity of an associative memory is defined as the maximum
number of vords that can be stored and retrieved reliably by an address
vithin a given sphere of attraction. It is shown by sphere packing
arguments that as the address length increases. the capacity of any
associati ve memory is limited to an exponential grovth rate of 1 - h2 ( 0).
vhere h2(0) is the binary entropy function in bits. and 0 is the radius
of the sphere of attraction. This exponential grovth in capacity can
actually be achieved by the Kanerva associative memory. if its
parameters are optimally set . Formulas for these op.timal values are
provided. The exponential grovth in capacity for the Kanerva
associative memory contrasts sharply vith the sub-linear grovth in
capacity for the Hopfield associative memory.
ASSOCIATIVE MEMORY AND ITS CAPACITY
Our model of an associative memory is the folloving. Let ()(,Y) be
an (address. datum) pair. vhere )( is a vector of n ?ls and Y is a
vector of m ?ls. and let ()(l),y(I)), ... ,()(M) , y(M)). be M (address,
datum) pairs stored in an associative memory. If the associative memory
is presented at the input vith an address )( that is close to some
stored address )(W. then it should produce at the output a vord Y that
is close to the corresponding contents y(j). To be specific, let us say
that an associative memory can correct fraction 0 errors if an )( vi thin
Hamming distance no of )((j) retrieves Y equal to y(j). The Hamming
sphere around each )(W vill be called the sphere of attraction, and 0
viII be called the radius of attraction.
One notion of the capacity of this associative memory is the
maximum number of vords that it can store vhile correcting fraction 0
errors . Unfortunately. this notion of capacity is ill-defined. because
it depends on exactly vhich (address. datum) pairs have been stored.
Clearly. no associative memory can correct fraction 0 errors for every
sequence of stored (address, datum) pairs. Consider. for example, a
sequence in vhich several different vords are vritten to the same
address . No memory can reliably retrieve the contents of the
overvritten vords. At the other extreme. any associative memory ' can
store an unlimited number of vords and retrieve them all reliably. if
their contents are identical.
A useful definition of capacity must lie somevhere betveen these
tvo extremes. In this paper. ve are interested in the largest M such
that for most sequences of addresses XU), .. . , X(M) and most sequences of
data y(l), ... , y(M). the memory can correct fraction 0 errors. We define
IThis vork vas supported by the National Science Foundation under NSF
grant IST-8509860 and by an IBM Doctoral Fellovship.

? American Institute of Physics 1988

185

most sequences' in a probabilistic sense, as some set of sequences yi th
total probability greater than say, .99. When all sequences are
equiprobab1e, this reduces to the deterministic version: 991. of all
sequences.
In practice it is too difficult to compute the capacity of a given
associative memory yith inputs of length n and outputs of length Tn.
Fortunately, though, it is easier to compute the asymptotic rate at
which A1 increases, as n and Tn increase, for a given family of
associative memories. This is the approach taken by McEliece et al. [1]
toyards the capacity of the Hopfield associative memory. We take the
same approach tovards the capacity of the Kanerva associative memory,
and tovards the capacities of associative memories in general . In the
next section ve provide an upper bound on the rate of grovth of the
capacity of any associative memory fitting our general model. It is
shown by sphere packing arguments that capacity is limited to an
exponential rate of grovth of 1- h2(t5), vhere h2(t5) is the binary entropy
function in bits, and 8 is the radius of attraction. In a later section
it vill turn out that this exponential grovth in capacity can actually
be achieved by the Kanerva associative memory, if its parameters are
optimally set. This exponential grovth in capacity for the Kanerva
associative memory contrasts sharply yith the sub-linear grovth in
capacity for the Hopfield associative memory [1].
I

A UNIVERSAL UPPER BOUND ON CAPACITY
Recall that our definition of the capacity of an associative memory
is the largest A1 such that for most sequences of addresses
X(1), ... ,X(M) and most sequences of data y(l), ... , y(M), the memory can
correct fraction 8 errors. Clearly, an upper bound to this capacity is
the largest Af for vhich there exists some sequence of addresses
X(1), . . . , X(M) such that for most sequences of data y(l), ... , y(M), the
memory can correct fraction 8 errors. We nov derive an expression for
this upper bound.
Let 8 be the radius of attraction and let DH(X(i) , d) be the sphere
of attraction, i.e., the set of all Xs at most Hamming distance d= Ln8J
from .y(j). Since by assumption the memory corrects fraction 8 errors,
every address X E DH(XU),d) retrieves the vord yW. The size of
DH(XU),d) is easily shown to be independent of xU) and equal to
vn.d = 2:%=0
vhere
is the binomial coefficient n!jk!(n - k)!. Thus
n
out of a total of 2 n-bit addresses, at least vn.d addresses retrieve
y(l), at least Vn.d addresses retrieve y(2), at least Vn.d addresses
retrieve y(~, and so forth. It fol10vs that the total number of
distinct yU)s can be at most 2 n jv n .d ' Nov, from Stirling's formula it
can be shovn that if d:S; nj2, then vn.d = 2nh2 (d/n)+O(logn), vhere
h 2 ( 8) = -81og 2 8 - (1 - 8) log2( 1 - 8) is the binary entropy function in bits,
and O(logn) is some function yhose magnitude grovs more slovly than a
constant times log n. Thus the total number of distinct y(j)s can be at
most 2 n (1-h2(S?+O(logn)
Since any set containing I most sequences' of Af
Tn-bit vords vill contain a large number of distinct vords (if Tn is

(1:),

(I:)

186

Figure 1: Neural net representation of the Kanerva associative memory. Signals propagate from the bottom (input) to the top (output). Each arc multiplies the signal by its
weight; each node adds the incoming signals and then thresholds.
sufficiently large --- see [2] for details), it follovs that
M :5 2 n (l-h 2 (o?+O(logn).

(1)

In general a function fen) is said to be O(g(n)) if f(n)fg(n) is
bounded, i.e. , if there exists a constant a such that If(n)1 :5 a\g(n)1 for
all n. Thus (1) says that there exists a constant a such that
M :5 2 n(l-h 2 (S?+alogn. It should be emphasized that since a is unknow,
this bound has no meaning for fixed n. Hovever, it indicates that
asymptotically in n, the maximum exponential rate of grovth of M is
1 - h2 ( 6).
Intui ti vely, only a sequence of addresses X(l), ... , X(M) that
optimally pack the address space {-l,+l}n can hope to achieve this
upper bound. Remarkably, most such sequences are optimal in this sense,
vhen n is large. The Kanerva associative memory can take advantage of
this fact.

THE KANERVA ASSOCIATIVE MEMORY
The Kanerva associative memory [3,4] can be regarded as a tvo-layer
neural netvork, as shovn in Figure 1, vhere the first layer is a
preprocessor and the second layer is the usual Hopfield style array.
The preprocessor essentially encodes each n-bit input address into a
very large k-bit internal representation, k ~ n, vhose size will be
permitted to grov exponentially in n. It does not seem surprising,
then, that the capacity of the Kanerva associative memory can grov
exponentially in n, for it is knovn that the capacity of the Hopfield
array grovs almost linearly in k, assuming the coordinates of the
k-vector are dravn at random by independent flips of a fair coin [1].

187

Figure 2: Matrix representation of the Kanerva associative memory. Signals propagate
from the right (input) to the left (output). Dimensions are shown in the box corners.
Circles stand for functional composition; dots stand for matrix multiplication.
In this situation, hovever, such an assumption is ridiculous: Since the
k-bit internal representation is a function of the n-bit input address,
it can contain at most n bits of information, whereas independent flips
of a fair coin contain k bits of information. Kanerva's primary
contribution is therefore the specification of the preprocessor, that
is, the specification of how to map each n-bit input address into a very
large k-bit internal representation.
The operation of the preprocessor is easily described. Consider
the matrix representation shovn in Figure 2. The matrix Z is randomly
populated vith ?ls. This randomness assumption is required to ease the
analysis. The function fr is 1 in the ith coordinate if the ith row of
Z is within Hamming distance r of X, and is Oothervise. This is
accomplished by thresholding the ith input against n-2r. The
parameters rand k are two essential parameters in the Kanerva
associative memory. If rand k are set correctly, then the number of 1s
in the representation fr(ZX) vill be very small in comparison to the
number of Os. Hence fr(Z~Y) can be considered to be a sparse internal
representation of X.
The second stage of the memory operates in the usual way, except on
the internal representation of X. That is, Y = g(W fr(ZX)), vhere
M

l-V = LyU)[Jr(ZXU))]t,

(2)

i=l

and 9 is the threshold function whose ith coordinate is +1 if the ith
input is greater than 0 and -1 is the ith input is less than O. The ith
column of l-V can be regarded as a memory location vhose address is the
ith row of Z. Every X vi thin Hamming distance r of the ith rov of Z
accesses this location. Hence r is known as the access radius, and k is
the number of memory locations.
The approach taken in this paper is to fix the linear rate p at
which r grovs vith n, and to fix the exponential rate ~ at which k grovs
with n. It turns out that the capacity then grovs at a fixed
exponential rate Cp,~(t5), depending on p, ~, and 15. These exponential
rates are sufficient to overcome the standard loose but simple
polynomial bounds on the errors due to combinatorial approximations.

188

THE CAPACITY OF THE KANERVA ASSOCIATIVE MEMORY
Fix 0 $ K $1. 0 $ p$ 1/2. and 0 $ 0 $ min{2p,1/2}. Let n be the
input address length, and let Tn be the output word length. It is
assumed that Tn is at most polynomial in n, i.e., Tn = exp{O(logn)}. Let
r = IJmJ be the access radius, let k = 2 L""nJ be the number of memory
locations, and let d= LonJ be the radius of attraction. Let Afn be the
number of stored words. The components of the n-vectors X(l), .. . , X(Mn) ,
the m-vectors y(l), ... , y(,Yn), and the k X n matrix Z are assumed to be
lID equiprobable ?1 random variables. Finally, given an n-vector X,
let Y = g(W fr(ZX)) where W = Ef;nl yU)[Jr(ZXW)jf.
Define the quantity

Cp ,,(0) = { 26 + 2(1- 0)h(P;~~2)
'Cp,ICo(p)(o)
where
KO(p)

2h(p)

2; - 2(1- ;)h(P~242)

= 2h(p) -

and

~-

; =

Theorem:

+ K, -

If
Af

J

196 -

if K, $ K,o(p)
if K> K,O(p) ,

+ 1- he;)

(3)

(4)

2p(1 - p).

< 2nCp... (5)+O(logn)

n_

then for all f>O, all sufficiently large n, all jE{l, ... ,Afn }. and all
X E DH(X(j) , d),

P{y

-::J y(j)}

< f.

See [2].
Interpretation: If the exponential growth rate of the number of
stored words Afn is asymptotically less than C p ,,, ( 0), then for every
sufficiently large address length n. there is some realization of the
nx 2n "" preprocessor matrix Z such that the associative memory can
correct fraction 0 errors for most sequences of Afn (address, datum)
pairs. Thus Cp,IC( 0) is a lover bound on the exponential growth rate of
the capacity of the Kanerva associative memory with access radius np and
number of memory locations 2nIC ?
Figure 3 shows Cp,IC(O) as a function of the radius of attraction 0,
for K,= K,o(p) and p=O.l, 0.2, 0.3, 0.4 and 0.45. For? any fixed access
radius p, Cp,ICO(p) (0) decreases as 0 increases. This reflects the fact
that fewer (address, datum) pairs can be stored if a greater fraction of
errors must be corrected. As p increases, Cp,,,o(p)(o) begins at a lower
point but falls off less steeply. In a moment we shall see that p can
be adjusted to provide the optimal performance for a given O.
Not ShOVIl in Figure 3 is the behavior of Cp ,,, ( 0) as a function of K,.
However, the behavior is simple. For K, > K,o(p), Cp,,,(o) remains
unchanged, while for K$ K,o(p), Cp,,,(o) is simply shifted doVIl by the
difference KO(p)-K,. This establishes the conditions under which the
Kanerva associative memory is robust against random component failures.
Although increasing the number of memory locations beyond 2rl11:o(p) does
not increase the capacity, it does increase robustness. Random
Proof:

189

0.8

0.6

'!I.2 ...... - - -

""

"" ?1

1Il.2

IIl.S

1Il.3

Figure 3: Graphs of Cp,lCo(p)(o) as defined by (3). The upper envelope is 1- h2(0).
component failures will not affect the capacity until so many components
have failed that the number of surviving memory locations is less than
2nlCo (p) .

Perhaps the most important curve exhibited in Figure 3 is the
sphere packing upper bound 1 - h2 ( 0). which is achieved for a particular

J

p by b = ~ - 196 - 2p(1 - p). Equivalently. the upper bound is achieved
for a particular 0 by P equal to

poCo) =

t - Jt - iO(l -

~o).

(5)

Thus (4) and (5) specify the optimal values of the parameters K and P.
respectively. These functions are shown in Figure 4. With these
optimal values. (3) simplifies to

the sphere packing bound.
It can also be seen that for 0 = 0 in (3). the exponential growth
rate of the capacity is asymptotically equal to K. which is the
exponential growth rate of the number of memory locations. k n ? That is.
Mn = 2n1C +O(logn) = k n . 20 (logn). Kanerva [3] and Keeler [5] have argued
that the capacity at 8 =0 is proportional to the number of memory
locations, i.e .? Mn = k n . (3. for some constant (3. Thus our results are
consistent with those of Kanerva and Keeler. provided the 'polynomial'
20 (logn) can be proved to be a constant. However. the usual statement of
their result. M = k?(3. that the capacity is simply proportional to the
number of memory locations. is false. since in light of the universal

190

liLS

o
riJ.S

Figure 4: Graphs of KO(p) and co(p), the inverse of Po(<5), as defined by (4) and (5).

upper bound, it is impossible for the capacity to grow without bound,
with no dependence on the dimension n. In our formulation, this
difficulty does not arise because we have explicitly related the number
of memory locations to the input dimension: kn =2n~. In fact, our
formulation provides explicit, coherent relationships between all of the
following variables: the capacity .~, the number of memory locations k,
the input and output dimensions n and Tn, the radius of attraction C,
and the access radius p. We are therefore able to generalize the
results of [3,5] to the case C>0, and provide explicit expressions for
the asymptotically optimal values of p and K as well.
CONCLUSION
We described a fairly general model of associative memory and
selected a useful definition of its capacity. A universal upper bound
on the growth of the capacity of such an associative memory was shown by
a sphere packing argument to be exponential with rate 1 - h 2 ( c), where
h2(C) is the binary entropy function and 8 is the radius of attraction.
We reviewed the operation of the Kanerva associative memory, and stated
a lower bound on the exponential growth rate of its capacity. This
lower bound meets the universal upper bound for optimal values of the
memory parameters p and K. We provided explicit formulas for these
optimal values. Previous results for <5 =0 stating that the capacity of
the Kanerva associative memory is proportional to the number of memory
locations cannot be strictly true. Our formulation corrects the problem
and generalizes those results to the case C > o.

191

REFERENCES
1. R.J. McEliece, E.C. Posner, E.R. Rodemich, and S.S. Venkatesh,
""The capacity of the Hopfield associative memory,"" IEEE
Transactions on Information Theory, submi tt ed .
2. P.A. Chou, ""The capacity of the Kanerva associative memory,""
IEEE Transactions on Information Theory, submitted.
3. P. Kanerva, ""Self-propagating search: a unified theory of
memory,"" Tech. Rep. CSLI-84-7, Stanford Center for the Study of
Language and Information. Stanford. CA, March 1984.
4. P. Kanerva, ""Parallel structures in human and computer memory,""
in Neural Networks for Computing, (J .S. Denker. ed.), Nev York:
American Institute of Physics. 1986.
5 . J.D. Keeler. ""Comparison betveen sparsely distributed memory and
Hopfield-type neural netvork models,"" Tech . Rep. RIACS TR 86 . 31,
NASA Research Institute for Advanced Computer Science, Mountain
Viev. CA, Dec. 1986.

"
3,1987,"Supervised Learning of Probability Distributions by Neural Networks","",3-supervised-learning-of-probability-distributions-by-neural-networks.pdf,"Abstract Missing","52

Supervised Learning of Probability Distributions
by Neural Networks
Eric B. Baum
Jet Propulsion Laboratory, Pasadena CA 91109
Frank Wilczek t
Department of Physics,Harvard University,Cambridge MA 02138

Abstract:
We propose that the back propagation algorithm for supervised learning can be generalized, put on a satisfactory conceptual
footing, and very likely made more efficient by defining the values of the output and input neurons as probabilities and varying
the synaptic weights in the gradient direction of the log likelihood,
rather than the 'error'.

In the past thirty years many researchers have studied the
question of supervised learning in 'neural'-like networks. Recently
a learning algorithm called 'back propagation H -

4

or the 'general-

ized delta-rule' has been applied to numerous problems including
the mapping of text to phonemes 5 , the diagnosis of illnesses 6 and
the classification of sonar targets 7 ? In these applications, it would
often be natural to consider imperfect, or probabilistic information. We believe that by considering supervised learning from this
slightly larger perspective, one can not only place back propagat Permanent address: Institute for Theoretical Physics, Univer-

sity of California, Santa Barbara CA 93106
? American Institute of Physics 1988

53

tion on a more rigorous and general basis, relating it to other well
studied pattern recognition algorithms, but very likely improve its
performance as well.
The problem of supervised learning is to model some mapping
between input vectors and output vectors presented to us by some
real world phenomena. To be specific, coqsider the question of
medical diagnosis. The input vector corresponds to the symptoms
of the patient; the i-th component is defined to be 1 if symptom i
is present and 0 if symptom i is absent. The output vector corresponds to the illnesses, so that its j-th component is 1 if the j-th
illness is present and 0 otherwise. Given a data base consisting
of a number of diagnosed cases, the goal is to construct (learn) a
mapping which accounts for these examples and can be applied to
diagnose new patients in a reliable way. One could hope, for instance, that such a learning algorithm might yield an expert system
to simulate the performance of doctors. Little expert advice would
be required for its design, which is advantageous both because experts' time is valuable and because experts often have extraodinary
difficulty in describing how they make decisions.
A feedforward neural network implements such a mapping between input vectors and output vectors. Such a network has a set
of input nodes, one or several layers of intermediate nodes, and a
layer of output nodes. The nodes are connected in a forward directed manner, so that the output of a node may be connected to
the inputs of nodes in subsequent layers, but closed loops do not
occur. See figure 1. The output of each node is assumed to be a
bounded semilinear function of its inputs. That is, if
the output of the j-th node and

Wij

Vj

denotes

denotes the weight associated

with the connection of the output of the j-th node to the input of

54

the i-th, then the i-th neuron takes value Vi = g(L,i Wi:jV:j), where
g is a bounded, differentiable function called the activation function. g(x)

= 1/(1 + e- X ),

called the logistic function, is frequently

used. Given a fixed set of weights {Wi:j}, we set the input node
values to equal some input vector, compute the value of the nodes
layer by layer until we compute the output nodes, and so generate
an output vector.

Figure 1: A 5 layer network. Note bottleneck at layer 3.

55

Such networks have been studied because of analogies to neurobiology, because it may be easy to fabricate them in hardware,
and because learning algorithms such as the Perceptron learning
algorithm 8 , Widrow- Hoff9, and backpropagation have been able
to choose weights

Wi,.

that solve interesting problems.

Given a set of input vectors
values

tj,

sr, together with associated target

back propagation attempts to adjust the weights so as

to minimize the error E in achieving these target values, defined as

E

= E EJL = E(tj - oj)2
JL

where

oj

input.

(1)

JL,i

is the output of the j-th node when sJL is presented as

Back propagation starts with randomly chosen

Wi,.

and

then varies in the gradient direction of E until a local minimum
is obtained. Although only a locally optimal set of weights is obtained, in a number of experiments the neural net so generated
has performed surprisingly well not only on the training set but on
subsequent data. 4 -

6

This performance is probably the main reason

for widespread interest in backpropagation.
It seems to us natural, in the context of the medical diagnosis
pro blem, the other real world problems to which backpropagation
has been applied, and indeed in any mapping problem where one
desires to generalize from a limited and noisy set of examples, to
interpret the output vector in probabilistic terms. Such an interpretation is standard in the literature on pattern classification. 1o
Indeed, the examples might even be probabilistic themselves. That
is to say it might not be certain whether symptom i was present
in case /L or not.
Let

sr represent the probability symptom i is present in case

/L, and let

tj

represent the probability disease j ocurred in case

56

fL.

Consider for the moment the case where the

tJ

are 1 or 0,
A

so that the cases are in fact fully diagnosed. Let

Ii (s, 0)

be our

prediction of the probability of disease i given input vector 5, where
{; is some set of parameters determined by our learning algorithm.
In the neural network case, the {; are the connection weights and

Ii (sl' , {Wi.i })

=

oJ.

Now lacking a priori knowledge of good

0, the best one can do

is to choose the parameters {; to maximize the likelihood that the
given set of examples should have occurred. 10 The formula for this
likelihood, p, is immediate:

or

The extension of equation (2), and thus equation (3) to the
case where the f are probabilities, taking values in [0,1]' is straight-

57

forward * 1 and yields

log(p) =

~ [tjlog(Jj (s"", 0)) + (1 -

tj)log(1 - Ij (W, 0))]

(4)

p. ,3

Expressions of this sort often arise in physics and information theory and are generally interpreted as an entropy. 11
We may now vary the {O} in the gradient direction of the entropy. The back propagation algorithm generalizes immediately
from minimizing 'Error' or 'Energy' to maximizing entropy or log
likelihood, or indeed any other function of the outputs and the
inputs 12 . Of course it remains true that the gradient can be computed by back propagation with essentially the same number of
computations as are required to compute the output of the network.
A backpropagation algorithm based on log-likelihood is not
only more intuitively appealing than one based on an ad-hoc definition of error, but will make quite different and more accurate
predictions as well. Consider e.g. training the net on an example which it already understands fairly well.

/j(80)

=L

Now, from eqn(l) BE/B/j

Say

tj

= 2?, so using

= 0, and

'Error' as a

* 1 We may see this by constructing an equivalent larger set of
examples with the f taking only values 0 or 1 with the appropriate
frequency. Thus assume the

tj

are rational numbers with denomi-

nator dj and numerator nj and let p

= IIp.,j dj.

What we mean by

the set of examples {tp. : J-t = 1, ... , M} can be represented by con-

ij = 0
for p(J-t- 1) < v < pJ-t and 1 < vmod(dj) < (dj - nj), and ij = 1

sidering a set of N

= Mp examples {ij}

where for each J-t,

otherwise. N ow applying equation (3) gives equation (4), up to an
overall normalization.

58

criterion the net learns very little from this example, whereas, using eqn(3), Blog(p)/B!;j

= 1/(1 -

f), so the net continues to learn

and can in fact converge to predict probabilities near 1. Indeed
because back propagation using the standard 'Error' measure can
not converge to generate outputs of 1 or 0, it has been customary in the literature 4 to round the target values so that a target
of 1 would be presented in the learning algorithm as some ad hoc
number such as .8, whereas a target of 0 would be presented as .2.
In the context of our general discussion it is natural to ask
whether using a feedforward network and varying the weights is in
fact the most effective alternative. Anderson and Abrahams 13 have
discussed this issue from a Bayesian viewpoint. From this point of
view, fitting output to input using normal distributions and varying
the means and covariance matrix may seem to be more logical.
Feedforward networks do however have several advantages for
complex problems. Experience with neural networks has shown the
importance of including hidden units wherein the network can form
an internal representation of the world. If one simply uses normal
distributions, any hidden variables included will simply integrate
out in calculating an output. It will thus be necessary to include at
least third order correlations to implement useful hidden variables.
Unfortunately, the number of possible third order correlations is
very large, so that there may be practical obstacles to such an
approach. Indeed it is well known folklore in curve fitting and
pattern classification that the number of parameters must be small
compared to the size of the data set if any generalization to future
cases is expected. 10
In feedforward nets the question takes a different form. There
can be bottlenecks to information flow. Specifically, if the net is

59

constructed with an intermediate layer which is not bypassed by
any connections (i.e. there are no connections from layers preceding
to layers subsequent), and if furthermore the activation functions
are chosen so that the values of each of the intermediate nodes
tend towards either 1 or 0*2, then this layer serves as a bottleneck
to information flow. No matter how many input nodes, output
nodes, or free parameters there are in the net, the output will be
constrained to take on no more than 21 different patterns, where
I is the number of nodes in the bottleneck layer.

Thus if I is

small, some sort of 'generalization' must occur even if the number
of weights is large. One plausible reason for the success of back
propagation in adequately solving tasks, in spite of the fact that
it finds only local minima, is its ability to vary a large number of
parameters. This freedom may allow back propagation to escape
from many putative traps and to find an acceptable solution.
A good expert system, say for medical diagnosis, should not
only give a diagnosis based on the available information, but should
be able to suggest, in questionable cases, which lab tests might be
performed to clarify matters. Actually back propagation inherently has such a capability. Back propagation involves calculation
of 81og(p)/8wij. This information allows one to compute immediately 81og(p)/8s j . Those input nodes for which this partial derivative is large correspond to important experiments.
In conclusion, we propose that back propagation can be generalized, put on a satisfactory conceptual footing, and very likely
made more efficient, by defining the values of the output and in*2

Alternatively when necessary this can be enforced by adding

an energy term to the log-likelihood to constrain the parameter
variation so that the neuronal values are near either 1 or O.

60

put neurons as probabilities, and replacing the 'Error' by the loglikelihood.
Acknowledgement: E. B. Baum was supported in part by DARPA

through arrangement with NASA and by NSF grant DMB-840649,
802. F. Wilczek was supported in part by NSF grant PHY82-17853
References

(1)Werbos,P, ""Beyond Regression: New Tools for Prediction and
Analysis in the Behavioral Sciences"" , Harvard University Dissertation (1974)
(2)Parker D. B., ""Learning Logic"" ,MIT Tech Report TR-47, Center
for Computationl Research in Economics and Management Science,
MIT, 1985
(3)Le Cun, Y., Proceedings of Cognitiva 85,p599-604, Paris (1985)
(4)Rumelhart, D. E., Hinton, G. E., Williams, G. E., ""Learning
Internal Representations by Error Propagation"", in ""Parallel Distributed Processing"" , vol 1, eds. Rumelhart, D. E., McClelland, J.
L., MIT Press, Cambridge MA,( 1986)
(5)Sejnowski, T. J., Rosenberg, C. R., Complex Systems, v 1, pp
145-168 (1987)
(6)LeCun, Y., Address at 1987 Snowbird Conference on Neural
Networks
(7)Gorman, P., Sejnowski, T. J., ""Learned Classification of Sonar
Targets Using a Massively Parallel Network"", in ""Workshop on
Neural Network Devices and Applications"", JPLD-4406, (1987)
pp224-237
(8)Rosenblatt, F., ""Principles of Neurodynamics: Perceptrons and

61

the theory of brain mechanisms"", Spartan Books, Washington DC
(1962)
(9)Widrow, B., Hoff, M. E., 1960 IRE WESCON Cony. Record,
Part 4, 96-104 (1960)
(10)Duda, R. 0., Hart, P. E., ""Pattern Classification and Scene
Analysis"", John Wiley and Sons, N.Y., (1973)
(11)Guiasu, S., ""Information Theory with Applications"", McGraw
Hill, NY, (1977)
(12)Baum,E.B., ""Generalizing Back Propagation to Computation"" ,
in ""Neural Networks for Computing"", AlP Conf. Proc. 151, Snowbird UT (1986)pp47-53
(13)Anderson, C.H., Abrahams, E., ""The Bayes Connection"" , Proceedings of the IEEE International Conference on Neural N etwor ks,
San Diego,(1987)

"
4,1987,"Constrained Differential Optimization","",4-constrained-differential-optimization.pdf,"Abstract Missing","612

Constrained Differential Optimization
John C. Platt
Alan H. Barr
California Institute of Technology, Pasadena, CA 91125

Abstract
Many optimization models of neural networks need constraints to restrict the space of outputs to
a subspace which satisfies external criteria. Optimizations using energy methods yield ""forces"" which
act upon the state of the neural network. The penalty method, in which quadratic energy constraints
are added to an existing optimization energy, has become popular recently, but is not guaranteed
to satisfy the constraint conditions when there are other forces on the neural model or when there
are multiple constraints. In this paper, we present the basic differential multiplier method (BDMM),
which satisfies constraints exactly; we create forces which gradually apply the constraints over time,
using ""neurons"" that estimate Lagrange multipliers.
The basic differential multiplier method is a differential version of the method of multipliers
from Numerical Analysis. We prove that the differential equations locally converge to a constrained
minimum.
Examples of applications of the differential method of multipliers include enforcing permutation
codewords in the analog decoding problem and enforcing valid tours in the traveling salesman problem.

1. Introduction
Optimization is ubiquitous in the field of neural networks. Many learning algorithms, such as
back-propagation,18 optimize by minimizing the difference between expected solutions and observed
solutions. Other neural algorithms use differential equations which minimize an energy to solve
a specified computational problem, such as associative memory, D differential solution of the traveling salesman problem,s,lo analog decoding,lS and linear programming. 1D Furthennore, Lyapunov
methods show that various models of neural behavior find minima of particular functions. 4,D
Solutions to a constrained optimization problem are restricted to a subset of the solutions of the
corresponding unconstrained optimization problem. For example, a mutual inhibition circuitS requires
one neuron to be ""on"" and the rest to be ""off"". Another example is the traveling salesman problem,ls
where a salesman tries to minimize his travel distance, subject to the constraint that he must visit
every city exactly once. A third example is the curve fitting problem, where elastic splines are as
smooth as possible, while still going through data points.s Finally, when digital decisions are being
made on analog data, the answer is constrained to be bits, either 0 or 1. 14
A constrained optimization problem can be stated as
minimize / (~),
subject to g(~) = 0,

(1)

where ~ is the state of the neural network, a position vector in a high-dimensional space; f(~) is a
scalar energy, which can be imagined as the height of a landscape as a function of position~; g(~) = 0
is a scalar equation describing a subspace of the state space. During constrained optimization, the
state should be attracted to the subspace g(~) = 0, then slide along the subspace until it reaches the
locally smallest value of f(~) on g(~) = O.
In section 2 of the paper, we describe classical methods of constrained optimization, such as the
penalty method and Lagrange multipliers.
Section 3 introduces the basic differential multiplier method (BDMM) for constrained optimization, which calcuIates a good local minimum. If the constrained optimization problem is convex, then
the local minimum is the global minimum; in general, finding the global minimum of non-convex
problems is fairly difficult.
In section 4, we show a Lyapunov function for the BDMM by drawing on an analogy from
physics.

? American Institute of Physics 1988

613

In section 5, augmented Lagrangians, an idea from optimization theory, enhances the convergence
properties of the BDMM.
In section 6, we apply the differential algorithm to two neural problems, and discuss the insensitivity of BDMM to choice of parameters. Parameter sensitivity is a persistent problem in neural
networks.

2. Classical Methods of Constrained Optimization
This section discusses two methods of constrained optimization, the penalty method and Lagrange
multipliers. The penalty method has been previously used in differential optimization. The basic
differential multiplier method developed in this paper applies Lagrange multipliers to differential
optimization.

2.l. The Penalty Method
The penalty method is analogous to adding a rubber band which attracts the neural state to
the subspace g(~) = o. The penalty method adds a quadratic energy term which penalizes violations of constraints. 8 Thus, the constrained minimization problem (1) is converted to the following
unconstrained minimization problem:

(2)

Figure 1. The penalty method makes a trough in state space
The penalty method can be extended to fulfill multiple constraints by using more than one rubber
band. Namely, the constrained optimization problem
minimize f (.~),
8ubject to go (~)

= OJ

a

= 1,2, ... , n;

(3)

is converted into unconstrained optimization problem
n

minimize l'pena1ty(~) = f(~)

+ L Co(go(~))2.

(4)

0:::1

The penalty method has several convenient features. First, it is easy to use. Second, it is globally
convergent to the correct answer as Co - 00. 8 Third, it allows compromises between constraints. For
example, in the case of a spline curve fitting input data, there can be a compromise between fitting
the data and making a smooth spline.

614

However, the penalty method has a number of disadvantages. First, for finite constraint strengths
it doesn't fulfill the constraints exactly. Using multiple rubber band constraints is like building
a machine out of rubber bands: the machine would not hold together perfectly. Second, as more
constraints are added, the constraint strengths get harder to set, especially when the size of the
network (the dimensionality of
gets large.
In addition, there is a dilemma to the setting of the constraint strengths. If the strengths are small,
then the system finds a deep local minimum, but does not fulfill all the constraints. If the strengths
are large, then the system quickly fulfills the constraints, but gets stuck in a poor local minimum.

COl'

.u

2.2. Lagrange Multipliers
Lagrange multiplier methods also convert constrained optimization problems into unconstrained
extremization problems. Namely, a solution to the equation (1) is also a critical point of the energy

(5)
). is called the Lagrange multiplier for the constraint g(~) = 0.8
A direct consequence of equation (5) is that the gradient of f is collinear to the gradient of 9 at
the constrained extrema (see Figure 2). The constant of proportionality between 'i1 f and 'i1 9 is -).:
'i1 'Lagrange

= 0 = 'i1 f + ). 'i1 g.

(6)

We use the collinearity of 'i1 f and 'i1 9 in the design of the BDMM.

Figure 2. At the constrained minimum, 'i1 f = -). 'i1 9
A simple example shows that Lagrange multipliers provide the extra degrees of freedom necessary
to solve constrained optimization problems. Consider the problem of finding a point (x, y) on the
line x + y = 1 that is closest to the origin. Using Lagrange multipliers,
'Lagrange

= x 2 + y2 + ).(x + y -

1)

(7)

Now, take the derivative with respect to all variables, x, y, and A.
aeLagrange

= 2x + A = 0

a'Lagrange

= 2y + A = 0

ax
ay

a'Lagrange =

a).

x

+y -

1= 0

(8)

615

With the extra variable A, there are now three equations in three unknowns. In addition, the last
equation is precisely the constraint equation.

3. The Basic Differential Multiplier Method for Constrained Optimization
This section presents a new ""neural"" algorithm for constrained optimization, consisting of differential equations which estimate Lagrange multipliers. The neural algorithm is a variation of the
method of multipliers, first presented by Hestenes 9 and Powell 16 ?

3.1. Gradient Descent does not work with Lagrange Multipliers
The simplest differential optimization algorithm is gradient descent, where the state variables of
the network slide downhill, opposite the gradient. Applying gradient descent to the energy in equation
(5) yields

x. - _ a!Lagrange
,ax?,
\.
a!Lagrange
= aA
J\

= _

al _ A ag
ax?""
ax' '

= -g

*.

(9)

( )

Note that there is a auxiliary differential equation for A, which is an additional ""neuron"" necessary
to apply the constraint g(~) = O. Also, recall that when the system is at a constrained extremum,
VI = -AVg, hence, x. = O.
Energies involving Lagrange multipliers, however, have critical points which tend to be saddle
points. Consider the energy in equation (5). If ~ is frozen, the energy can be decreased by sending
A to +00 or -00.
Gradient descent does not work with Lagrange multipliers, because a critical point of the energy
in equation (5) need not be an attractor for (9). A stationary point must be a local minimum in order
for gradient descent to converge.

3.2. The New Algorithm: the Basic Differential Multiplier Method
We present an alternative to differential gradient descent that estimates the Lagrange multipliers,
so that the constrained minima are attractors of the differential equations, instead of ""repulsors."" The
differential equations that solve (1) is

.
al
,
ax,
i = +g(*).

ag
ax.'

X' = - - - A -

(10)

Equation (10) is similar to equation (9). As in equation (9), constrained extrema of the energy
(5) are stationary points of equation (10). Notice, however, the sign inversion in the equation for i,
as compared to equation (9). The equation (10) is performing gradient ascent on A. The sign flip
makes the BDMM stable, as shown in section 4.
Equation (10) corresponds to a neural network with anti-symmetric connections between the A
neuron and all of the ~ neurons.

3.3. Extensions to the Algorithm
One extension to equation (10) is an algorithm for constrained minimization with multiple constraints. Adding an extra neuron for every equality constraint and summing all of the constraint forces
creates the energy
(11)
!multiple = !(~) +
Ao<ga(~),

I:
0<

which yields differential equations

x' - _ al _ """" A agcr.
,- ax'

~

'0<

0<

ax' )
'

(12)

616

Another extension is constrained minimization with inequality constraints. As in traditional
optimization theory.8 one uses extra slack variables to convert inequality constraints into equality
constraints. Namely. a constraint of the form h(~) ~ 0 can be expressed as

(13)
Since Z2 must always be positive, then h(~) is constrained to be positive. The slack variable z is
treated like a component of ~ in equation (10). An inequality constraint requires two extra neurons,
one for the slack variable % and one for the Lagrange multiplier ~.
Alternatively, the inequality constraint can be represented as an equality constraint For example,
if h(~) ~ 0, then the optimization can be constrained with g(~) = h(.~), when h(~) ~ 0; and
g(.~) = 0 otherwise.

4. Why the algorithm works
The system of differential equations (10) (the BDMM) gradually fulfills the constraints. Notice
that the function g(~) can be replaced by kg(~), without changing the location of the constrained
minimum. As k is increased, the state begins to undergo damped oscillation about the constraint
subspace g(~) = o. As k is increased further, the frequency of the oscillations increase, and the time
to convergence increases.
constraint subspace

./

/'

initial?state

.,.-

path of algorithm

""\

\

Figure 3. The state is attracted to the constraint subspace

The damped oscillations of equation (10) can be explained by combining both of the differential
equations into one second-order differential equation.

(14)
Equation (14) is the equation for a damped mass system, with an inertia term Xi. a damping matrix

(15)
and an internal force, gOg/O%i, which is the derivative of the internal energy

(16)

617

If the system is damped and the state remains bounded, the state falls into a constrained minima.
As in physics, we can construct a total energy of the system, which is the sum of the kinetic and
potential energies.
E= T

+U =

L, i(xd

2

+ i(g(~))2.

(17)

If the total energy is decreasing with time and the state remains bounded, then the system will
dissipate any extra energy, and will settle down into the state where

(18)
which is a constrained extremum of the original problem in equation (1).
The time derivative of the total energy in equation (17) is

= -

(19)

Lx,A,jxj.
',i

If damping matrix Aii is positive definite, the system converges to fulfill the constraints.
BDMM always converges for a special case of constrained optimization: quadratic programming.
A quadratic programming problem has a quadratic function f(~) and a piecewise linear continuous
function g(~) such that

(20)
Under these circumstances, the damping matrix Aii is positive definite for all
system converges to the constraints.

~

and A, so that the

4.1. Multiple constraints
For the case of multiple constraints, the total energy for equation (12) is

E = T

+U =

L
i

i(Xi)2 +

L igo(~)2.

(21)

0

and the time derivative is

(22)

Again, BDMM solves a quadratic programming problem, if a solution exists. However, it is
possible to pose a problem that has contradictory constraints. For example,

gdx) = x =

0,

g2(X) = x - I = 0

(23)

In the case of conflicting constraints, the BDMM compromises, trying to make each constraint go as
small as possible. However, the Lagrange multipliers Ao goes to ?oo as the constraints oppose each
other. It is possible, however, to arbitrarily limit the Ao at some large absolute value.

618

LaSalle's invariance theorem 12 is used to prove that the BDMM eventually fulfills the constraints.
Let G be an open subset of Rn. Let F be a subset of G*, the closure of G, where the system of
differential equations (12) is at an equilibrium.

(24)
If the damping matrix

a2 f + '"" A a2 ga
-----:;_
ax, ax;

~

a

ax,ax;

(25)

is positive definite in G, if xa{ t) and Aa (t) are bounded, and remain in G for all time, and ~f F
is non-empty, then F is the largest invariant set in G*, hence, by LaSalle's invariance theorem, the
system (t), Aa (t) approaches Fast -+ 00.

x,

5. The Modified Differential Method of Multipliers
This section presents the modified differemiaI multiplier method (MDMM), which is a modification of the BDMM with more robust convergence properties. For a given constrained optimization
problem, it is frequently necessary to alter the BDMM to have a region of positive damping surrounding the constrained minima. The non-differential method of multipliers from Numerical Analysis also
has this difficulty. 2 Numerical Analysis combines the multiplier method with the penalty method to
yield a modified multiplier method that is locally convergent around constrained minima. 2
The BDMM is completely compatible with the penalty method. If one adds a penalty force to
equation (10) corresponding to an quadratic energy
Epenalty

= ~(g(~))2.

(26)

then the set of differential equations for MDMM is

.

af

ag

x, = -ax,
-- A
ax,- j = g(~).

ag
ax,

cg-,

(27)

The extra force from the penalty does not change the position of the stationary points of the differential
equations, because the penalty force is 0 when g(~) = O. The damping matrix is modified by the
penalty force to be

(28)
There is a theorem 1 that states that there exists a c* > 0 such that if c > c*, the damping matrix
in equation (28) is positive definite at constrained minima. Using continuity, the damping matrix is
positive definite in a region R surrounding each constrained minimum. If the system starts in the
region R and remains bounded and in R, then the convergence theorem at the end of section 4 is
applicable, and MDMM will converge to a constrained minimum.
The minimum necessary penalty strength c for the MDMM is usually much less than the strength
needed by the penalty method alone. 2

6. Examples
This section contains two examples which illustrate the use of the BDMM and the MDMM. First,
the BDMM is used to find a good solution to the planar traveling salesman problem. Second, the
MDMM is used to enforcing mutual inhibition and digital results in the task of analog decoding.

6.1. Planar Traveling Salesman
The traveling salesman problem (fSP) is, given a set of cities lying in the plane, find the shortest
closed path that goes through every city exactly once. Finding the shortest path is NP-complete.

619

Finding a nearly optimal path, however, is much easier than finding a globally optimal path. There
exist many heuristic algorithms for approximately solving the traveling salesman problem. 5,10,11,13
The solution presented in this section is moderately effective and illustrates the independence of
BDMM to changes in parameters.
Following Durbin and Willshaw,5 we use an elastic snake to solve the TSP. A snake is a discretized
curve which lies on the plane. The elements of the snake are points on the plane, (Xi, Yd. A snake
is a locally connected neural network, whose neural outputs are positions on the plane.
The snake minimizes its length

2:)Xi+1 - x,)2 - (Yi+l - Yi)2,

(29)

i

subject to the constraint that the snake must lie on the cities:

k(x* - xc) = 0,
k(y* - Yc) = 0,
(30)
where (x*, y*) are city coordinates, (xc, Yc) is the closest snake point to the city, and k is the constraint
strength.
The minimization in equation (29) is quadratic and the constraints in equation (30) are piecewise
linear, corresponding to a CO continuous potential energy in equation (21). Thus, the damping is
positive definite, and the system converges to a state where the constraints are fulfilled.
In practice, the snake starts out as a circle. Groups of cities grab onto the snake, deforming
it As the snake gets close to groups of cities, it grabs onto a specific ordering of cities that locally
minimize its length (see Figure 4).
The system of differential equations that solve equations (29) and (30) are piecewise linear. The
differential equations for Xi and Yi are solved with implicit Euler's method, using tridiagonal LV
decomposition to solve the linear system. 17 The points of the snake are sorted into bins that divide
the plane, so that the computation of finding the nearest point is simplified.

Figure 4. The snake eventually attaches to the cities
The constrained minimization in equations (29) and (30) is a reasonable method for approximately
solving the TSP. For 120 cities distributed in the unti square, and 600 snake points, a numerical step
size of 100 time units, and a constraint strength of 5 x 10- 3 , the tour lengths are 6% ? 2% longer
than that yielded by simulated annealing 11 . Empirically, for 30 to 240 cities, the time needed to
compute the final city ordering scales as N1.6, as compared to the Kernighan-Lin method13 , which
scales roughly as N 2 .2 ?
The constraint strength is usable for both a 30 city problem and a 240 city problem. Although
changing the constraint strength affects the performance, the snake attaches to the cities for any nonzero constraint strength. Parameter adjustment does not seem to be an issue as the number of cities
increases, unlike the penalty method.

620

6.2. Analog Decoding
Analog decoding uses analog signals from a noisy channel to reconstruct codewords. Analog
decoding has been performed neurally,15 with a code space of permutation matrices, out of the
possible space of binary matrices.
To perform the decoding of permutation matrices, the nearest permutation matrix to the signal
matrix must be found. In other words, find the nearest matrix to the signal matrix, subject to the
constraint that the matrix has on/off binary elements, and has exactly one ""on"" per row and one ""on""
per column. If the signal matrix is Ii; and the result is Vi;, then minimize

- ""v..
L..J .,,1-.
.,

(31)

i ,;

subject to constraints

Vi,,(l- Vi;) = OJ

LVi"" -1 =

(32)

O.

;

In this example, the first constraint in equation (32) forces crisp digital decisions. The second
and third constraints are mutual inhibition along the rows and columns of the matrix.
The optimization in equation (31) is not quadratic, it is linear. In addition, the first constraint in
equation (32) is non-linear. Using the BDMM results in undamped oscillations. In order to converge
onto a constrained minimum, the MDMM must be used. For both a 5 x 5 and a 20 x 20 system, a
c = 0,2 is adequate for damping the oscillations. The choice of c seems to be reasonably insensitive
to the size of the system, and a wide range of c, from 0.02 to 2.0, damps the oscillations.

.?...?....
..?????...???. ?....?.?????
..'
????
???????
??..'
...????.
. .?.???.
??
??
.?.
???
??? ???
??
???
???
.... . ...
??
??
.. ??? ... ... .?....??
..

,

?

?

?

?
.

'

..?......
? ? ... e? ... .

.. .

? .. . e? ... ? .

?

???

?

? ??

.

?

?

?

?

??????

'

????????
?
?

?

?

,

?

.

?

.?

: :e&:.:: ....?.

??? ?.
?

????
.
? ???
..

?

???::r::::::::
.
.

?????
....

?

?

:~:.:.:
?

?

?

?

?

.

.

???.

?

'

?
??
???
? ?
?

?

?

?

.

?

.....

Figure 5. The decoder finds the nearest permutation matrix

In a test of the MDMM, a signal matrix which is a permutation matrix plus some noise, with
a signal-to-noise ratio of 4 is supplied to the network. In figure 5, the system has turned on the
correct neurons but also many incorrect neurons. The constraints start to be applied, and eventually
the system reaches a permutation matrix. The differential equations do not need to be reset. If a new
signal matrix is applied to the network, the neural state will move towards the new solution.

7. ConClusions
In the field of neural networks, there are differential optimization algorithms which find local
solutions to non-convex problems. The basic differential multiplier method is a modification of a
standard constrained optimization algorithm, which improves the capability of neural networks to
perform constrained optimization.
The BDMM and the MDMM offer many advantages over the penalty method. First, the differential equations (10) are much less stiff than those of the penalty method. Very large quadratic terms
are not needed by the MDMM in order to strongly enforce the constraints. The energy terrain for the

621

penalty method looks like steep canyons, with gentle floors; finding minima of these types of energy
surfaces is numerically difficult In addition, the steepness of the penalty tenns is usually sensitive
to the dimensionality of the space. The differential multiplier methods are promising techniques for
alleviating stiffness.
The differential multiplier methods separate the speed of fulfilling the constraints from the accuracy of fulfilling the constraints. In the penalty method, as the strengths of a constraint goes to
00, the constraint is fulfilled, but the energy has many undesirable local minima. The differential
multiplier methods allow one to choose how quickly to fulfill the constraints.
The BDMM fulfills constraints exactly and is compatible with the penalty method. Addition of
penalty tenns in the MDMM does not change the stationary points of the algorithm, and sometimes
helps to damp oscillations and improve convergence.
Since the BDMM and the MDMM are in the form of first-order differential equations, they can
be directly implemented in hardware. Performing constrained optimization at the raw speed of analog
VLSI seems like a promising technique for solving difficult perception problems. 14
There exist Lyapunov functions for the BDMM and the MDMM. The BDMM converges globally for quadratic programming. The MDMM is provably convergent in a local region around the
constrained minima Other optimization algorithms, such as Newton's method,17 have similar local convergence properties. The global convergence properties of the BDMM and the MDMM are
currently under investigation.
In summary, the differential method of multipliers is a useful way of enforcing constraints on
neural networks for enforcing syntax of solutions, encouraging desirable properties of solutions, and
making crisp decisions.

Acknowledgments
This paper was supported by an AT&T Bell Laboratories fellowship (JCP).

References
1. K. J. Arrow, L. Hurwicz, H. Uzawa, Studies in Linear and Nonlinear Programming. (Stanford
University Press, Stanford, CA, 1958).
2. D. P. Bertsekas, Automatica, 12, 133-145, (1976).
3. C. de Boor, A Practical Guide to Splines. (Springer-Verlag, NY, 1978).
4. M. A. Cohen, S. Grossberg, IEEE Trans. Systems. Man. and Cybernetics, ,815-826, (1983).
5. R. Durbin, D. Willshaw, Nature, 326, 689-691, (1987).
6. J. C. Eccles, The Physiology of Nerve Cells, (Johns Hopkins Press, Baltimore, 1957).
7. M. R. Hestenes, J. Opt. Theory Appl., 4, 303-320, (1969).
8. M. R. Hestenes, Optimization Theory, (Wiley & Sons, NY, 1975).
9. J. J. Hopfield, PNAS, 81, 3088, (1984).
10. J. J. Hopfield, D. W. Tank, Biological Cybernetics, 52, 141, (1985).
11. S. Kirkpatrick, C. D. Gelatt, C. M. Vecchi, Science, 220, 671-680, (1983).
12. J. LaSalle, The Stability of Dynamical Systems, (SIAM, Philadelphia, 1976).
13. S. Lin, B. W. Kernighan, Oper. Res., 21,498-516 (1973).
14. C. A. Mead, Analog VLSI and Neural Systems, (Addison-Wesley, Reading. MA, TBA).
15. J. C. Platt, J. J. Hopfield, in AlP Con/. Proc.151: Neural Networksfor Computing (1. Denker
ed.) 364-369, (American Institute of PhysiCS, NY, 1986).
16. M. 1. Powell, in Optimization, (R. Fletcher, ed.), 283-298, (Academic Press, NY, 1969).
17. W. H. Press, B. P. Flannery, S. A. Teukolsky, W. T. Vetterling, Numerical Recipes, (Cambridge University Press, Cambridge, 1986).
18. D. Rumelhart, G. Hinton, R. Williams, in Parallel Distributed Processing, (D. Rumelhart,
ed), 1, 318-362, (MIT Press, Cambridge, MA, 1986).
19. D. W. Tank, J. J. Hopfield, IEEE Trans. Cir. & Sys., CAS-33, no. 5,533-541 (1986).

"
5,1987,"Towards an Organizing Principle for a Layered Perceptual Network","",5-towards-an-organizing-principle-for-a-layered-perceptual-network.pdf,"Abstract Missing","485

TOWARDS AN ORGANIZING PRINCIPLE FOR
A LAYERED PERCEPTUAL NETWORK
Ralph Linsker
IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598

Abstract
An information-theoretic optimization principle is proposed for the development
of each processing stage of a multilayered perceptual network. This principle of
""maximum information preservation"" states that the signal transformation that is to be
realized at each stage is one that maximizes the information that the output signal values
(from that stage) convey about the input signals values (to that stage), subject to certain
constraints and in the presence of processing noise. The quantity being maximized is a
Shannon information rate. I provide motivation for this principle and -- for some simple
model cases -- derive some of its consequences, discuss an algorithmic implementation,
and show how the principle may lead to biologically relevant neural architectural
features such as topographic maps, map distortions, orientation selectivity, and
extraction of spatial and temporal signal correlations. A possible connection between
this information-theoretic principle and a principle of minimum entropy production in
nonequilibrium thermodynamics is suggested.

Introduction
This paper describes some properties of a proposed information-theoretic
organizing principle for the development of a layered perceptual network. The purpose
of this paper is to provide an intuitive and qualitative understanding of how the principle
leads to specific feature-analyzing properties and signal transformations in some simple
model cases. More detailed analysis is required in order to apply the principle to cases
involving more realistic patterns of signaling activity as well as specific constraints on
network connectivity.
This section gives a brief summary of the results that motivated the formulation
of the organizing principle, which I call the principle of ""maximum information
preservation."" In later sections the principle is stated and its consequences studied.
In previous work l I analyzed the development of a layered network of model cells
with feedforward connections whose strengths change in accordance with a Hebb-type
synaptic modification rule. I found that this development process can produce cells that
are selectively responsive to certain input features, and that these feature-analyzing
properties become progressively more sophisticated as one proceeds to deeper cell
layers. These properties include the analysis of contrast and of edge orientation, and
are qualitatively similar to properties observed in the first several layers of the
mammalian visual pathway.2
Why does this happen? Does a Hebb-type algorithm (which adjusts synaptic
strengths depending upon correlations among signaling activities 3 ) cause a developing
perceptual network to optimize some property that is deeply connected with the mature
network's functioning as an information processing system?

? American Institute ofPhvsics 1988

486

Further analysis 4 .s has shown that a suitable Hebb-type rule causes a
linear-response cell in a layered feedforward network (without lateral connections) to
develop so that the statistical variance of its output activity (in response to an ensemble
of inputs from the previous layer) is maximized, subject to certain constraints. The
mature cell thus performs an operation similar to principal component analysis (PCA),
an approach used in statistics to expose regularities (e.g., clustering) present in
high-dimensional input data. (Oja 6 had earlier demonstrated a particular form of
Hebb-type rule that produces a model cell that implements PCA exactly.)
Furthermore, given a linear device that transforms inputs into an output, and given
any particular output value, one can use optimal estimation theory to make a ""best
estimate"" of the input values that gave rise to that output. Of all such devices, I have
found that an appropriate Hebb-type rule generates that device for which this ""best
estimate"" comes closest to matching the input values. 4 ?s Under certain conditions, such
a cell has the property that its output preserves the maximum amount of information
about its input values. s
Maximum Information Preservation
The above results have suggested a possible organizing principle for the
development of each layer of a multilayered perceptual network. s The principle can be
applied even if the cells of the network respond to their inputs in a nonlinear fashion,
and even if lateral as well as feedforward connections are present. (Feedback from later
to earlier layers, however, is absent from this formulation.) This principle of ""maximum
information preservation"" states that for a layer of cells L that is connected to and
provides input to another layer M, the connections should develop so that the
transformation of signals from L to M (in the presence of processing noise) has the
property that the set of output values M conveys the maximum amount of information
about the input values L, subject to various constraints on, e.g., the range of lateral
connections and the processing power of each cell. The statistical properties of the
ensemble of inputs L are assumed stationary, and the particular L-to-M transformation
that achieves this maximization depends on those statistical properties. The quantity
being maximized is a Shannon information rate. 7
An equivalent statement of this principle is: The L-to-M transformation is chosen
so as to minimize the amount of information that would be conveyed by the input values
L to someone who already knows the output values M.
We shall regard the set of input signal values L (at a given time) as an input
""message""; the message is processed to give an output message M. Each message is in
general a set of real-valued signal activities. Because noise is introduced during the
processing, a given input message may generate any of a range of different output
messages when processed by the same set of connections.
The Shannon information rate (i.e., the average information transmitted from L
to M per message) is7
R = LL LMP(L,M) log [P(L,M)/P(L)P(M)].

(1)

For a discrete message space, peL) [resp. P(M)] is the probability of the input (resp.
output) message being L (resp. M), and P(L,M) is the joint probability of the input
being L and the output being M. [For a continuous message space, probabilities are

487

replaced by probability densities, and sums (over states) by integrals.] This rate can be
written as
(2)

where

h == -

LL P(L) log P(L)

(3)

is the average information conveyed by message Land

(4)
is the average information conveyed by message L to someone who already knows M.
Since II. is fixed by the properties of the input ensemble, maximizing R means
minimizing I LIM , as stated above.
The information rate R can also be written as
(5)

where 1M and IMI L are defined by interchanging Land M in Eqns. 3 and 4. This form is
heuristically useful, since it suggests that one can attempt to make R large by (if
possible) simultaneously making 1M large and IMI L small. The term 1M is largest when
each message M occurs with equal probability. The term 1""'1/. is smallest when each L
is transformed into a unique M, and more generally is made small by ""sharpening"" the
P(M IL) distribution, so that for each L, P(M IL) is near zero except for a small set of
messages M.
How can one gain insight into biologically relevant properties of the L - M
transformation that may follow from the principle of maximum information preservation
(which we also call the ""infomax"" principle)? In a network, this L - M transformation
may be a function of the values of one or a few variables (such as a connection strength)
for each of the allowed connections between and within layers, and for each cell. The
search space is quite large, particularly from the standpoint of gaining an intuitive or
qualitative understanding of network behavior. We shall therefore consider a simple
model in which the dimensionalities of the Land M signal spaces are greatly reduced,
yet one for which the infomax analysis exhibits features that may also be important
under more general conditions relevant to biological and synthetic network
development.
The next four sections are organized as follows. (i) A model is introduced in
which the Land M messages, and the L-to-M transformation, have simple forms. The
infomax principle is found to be satisfied when some simple geometric conditions (on
the transformation) are met. (ii) I relate this model to the analysis of signal processing
and noise in an interconnection network. The formation of topographic maps is
discussed. (iii) The model is applied to simplified versions of biologically relevant
problems, such as the emergence of orientation selectivity. (iv) I show that the main
properties of the infomax principle for this model can be realized by certain local
algorithms that have been proposed to generate topographic maps using lateral
interactions.

488

A Simple Geometric Model
In this model, each input message L is described by a point in a low-dimensional
vector space, and the output message M is one of a number of discrete states. For
definiteness, we will take the L space to be two-dimensional (the extension to higher
dimensionality is straightforward). The L - M transformation consists of two steps.
(i) A noise process alters L to a message L' lying within a neighborhood of radius v
centered on L. (ii) The altered message L' is mapped deterministically onto one of the
output messages M.
A given L' - M mapping corresponds to a partitioning of the L space into regions
labeled by the output states M. (We do not exclude a priori the possibility that multiple
disjoint regions may be labeled by the same M.) Let A denote the total area of the L
state space. For each M, let A (M) denote the area of L space that is labeled by M. Let
sCM) denote the total border length that the region(s) labeled M share with regions of
unlike M -label. A point L lying within distance v of a border can be mapped onto either
M-value (because of the noise process L - L'). Call this a ""borderline"" L. A point L
that is more than a distance v from every border can only be mapped onto the M-value
of the region containing it.
Suppose v is sufficiently small that (for the partitionings of interest) the area
occupied by borderline L states is small compared to the total area of the L space.
Consider first the case in which peL) is uniform over L. Then the information rate R
(using Eqn. 5) is given approximately (through terms of order v) by
R = - ~M[A(M)/A] 10g[A(M)/A] - (yv/A) ~Ms(M).

(6)

To see this, note that P(M) = A(M)/A and that P(M IL) log P(M IL) is zero except for
borderline L (since 0 log 0 = 1 log 1 = 0). Here y is a positive number whose value
depends upon the details of the noise process, which determines P(M I L) for borderline
L as a function of distance from the border.
For small v (low noise) the first term (1M) on the RHS of Eqn. 6 dominates. It is
maximized when the A(M) [and hence the P(M)] values are equal for all M. The second
term (with its minus sign), which equals ( -~'4IL)' is maximized when the sum of the
border lengths of all M regions is minimized. This corresponds to ""sharpening"" the
P(M IL) distribution in our earlier, more general, discussion. This suggests that the
infomax solution is obtained by partitioning the L space into M-regions (one for each
M value) that are of substantially equal area, with each M-region tending to have
near-minimum border length.
Although this simple analysis applies to the low-noise case, it is plausible that even
when v is comparable to the spatial scale of the M regions, infomax will favor making
the M regions have approximately the same extent in all directions (rather than be
elongated), in order to ""sharpen"" p(MI L) and reduce the probability of the noise
process mapping L onto many different M states.
What if peL) is nonuniform? Then the same result (equal areas, minimum border)
is obtained except that both the area and border-length elements must now be weighted
by the local value of peL). Therefore the infomax principle tends to produce maps in
which greater representation in the output space is given to regions of the input signal
space that are activated more frequently.
To see how lateral interactions within the M layer can affect these results, let us
suppose that the L - M mapping has three, not two, process steps: L - L'

489

- M - M, where the first two steps are as above, and the third step changes the output
M into any of a number of states M (which by definition comprise the
""M-neighborhood"" of M). We consider the case in which this M-neighborhood relation
is symmetric.
This type of ""lateral interaction"" between M states causes the infomax principle
to favor solutions for which M regions sharing a border in L space are M-neighbors in
the sense defined. For a simple example in which each state M has n M-neighbors
(including itself), and each M-neighbor has an equal chance of being the final state
(given M), infomax tends to favor each M-neighborhood having similar extent in all
directions (in L space).

Relation Between the Geometric Model and Network Properties
The previous section dealt with certain classes of transformations from one
message space to another, and made no specific reference to the implementation of these
transformations by an interconnected network of processor cells. Here we show how
some of the features discussed in the previous section are related to network properties.
For simplicity suppose that we have a two-dimensional layer of uniformly
distributed cells, and that the signal activity of each cell at any given time is either 1
(active) or 0 (quiet). We need to specify the ensemble of input patterns. Let us first
consider a simple case in which each pattern consists of a disk of activity of fixed radius,
but arbitrary center position, against a quiet background. In this case the pattern is fully
defined by specifying the coordinates of the disk center. In a two-dimensional L state
space (previous section), each pattern would be represented by a point having those
coordinates.
Now suppose that each input pattern consists not of a sharply defined disk of
activity, but of a ""fuzzy"" disk whose boundary (and center position) are not sharply
defined. [Such a pattern could be generated by choosing (from a specified distribution)
a position Xc as the nominal disk center, then setting the activity of the cell at position
X to 1 with a probability that decreases with distance I x - Xc I . ] Any such pattern can
be described by giving the coordinates of the ""center of activity"" along with many other
values describing (for example) various moments of the activity pattern relative to the
center.
For the noise process L - L' we suppose that the activity of an L cell can be
""misread"" (by the cells of the M layer) with some probability. This set of distorted
activity values is the ""message"" L'. We then suppose that the set of output activities M
is a deterministic function of L'.
We have constructed a situation in which (for an appropriate choice of noise level)
two of the dimensions of the L state space -- namely, those defined by the disk center
coordinates -- have large variance compared to the variance induced by the noise
process, while the other dimensions have variance comparable to that induced by noise.
In other words, the center position of a pattern is changed only a small amount by the
noise process (compared to the typical difference between the center positions of two
patterns), whereas the values of the other attributes of an input pattern differ as much
from their noise-altered values as two typical input patterns differ from each other.
(Those attributes are ""lost in the noise. "")
Since the distance between L states in our geometric model (previous section)
corresponds to the likelihood of one L state being changed into the other by the noise

490

process, we can heuristically regard the L state space (for the present example) as a
""slab"" that is elongated in two dimensions and very thin in all other dimensions. (In
general this space could have a much more complicated topology, and the noise process
which we here treat as defining a simple metric structure on the L state space need not
do so. These complications are beyond the scope of the present discussion.)
This example, while simple. illustrates a feature that is key to understanding the
operation of the infomax principle: The character of the ensemble statistics and of the
noise process jointly determine which attributes of the input pattern are statistically
most significant; that is, have largest variance relative to the variance induced by noise.
We shall see that the infomax principle selects a number of these most significant
attributes to be encoded by the L - M transformation.
We turn now to a description of the output state space M. We shall assume that
this space is also of low dimensionality. For example, each M pattern may also be a disk
of activity having a center defined within some tolerance. A discrete set of discriminable
center-coordinate values can then be used as the M-region ""labels"" in our geometric
model.
Restricting the form of the output activity in this particular way restricts us to
considering positional encodings L - M, rather than encodings that make use of the
shape of the output pattern, its detailed activity values, etc. However, this restriction
on the form of the output does not determine which features of the input patterns are
to be encoded, nor whether or not a topographic (neighbor-preserving) mapping is to
be used. These properties will be seen to emerge from the operation of the infomax
principle.
In the previous section we saw that the infomax principle will tend to lead to a
partitioning of the L space into M regions having equal areas [if peL) is uniform in the
coordinates of the L disk center] and minimum border length. For the present case this
means that the M regions will tend to ""tile"" the two long dimensions of the L state space
""slab,"" and that a single M value will represent all points ill L space that differ only in
their low-variance coordinates. If peL) is nonuniform, then the area of the M region
at L will tend to be inversely proportional to peL). Furthermore, if there are local lateral
connections between M cells, then (depending upon the particular form of such
interaction) M states corresponding to nearby localized regions of layer-M activity can
be M-neighbors in the sense of the previous section. In this case the mapping from the
two high-variance coordinates of L space to M space will tend to be topographic.

Examples: Orientation Selectivity and Temporal Feature Maps
The simple example in the previous section illustrates how infomax can lead to
topographic maps, and to map distortions [which provide greater M-space
representation for regions of L having large peL)]. Let us now consider a case in which
information about input features is positionally encoded in the output layer as a result
of the infomax principle.
Consider a model case in which an ensemble of patterns is presented to the input
layer L. Each pattern consists of a rectangular bar of activity (of fixed length and width)
against a quiet background. The bar's center position and orientation are chosen for
each pattern from uniform distributions over some spatial interval for the position, and
over all orientation angles (i.e., from 0? to 180?). The bar need not be sharply defined,
but can be ""fuzzy"" in the sense described above. We assume, however, that all

491

properties that distinguish different patterns of the ensemble -- except for center
position and orientation -- are ""lost in the noise"" in the sense we discussed.
To simplify the representation of the solution, we further assume that only one
coordinate is needed to describe the center position of the bar for the given ensemble.
For example, the ensemble could consist of bar patterns all of which have the same y
coordinate of center position, but differ in their x coordinate and in orientation 0.
We can then represent each input state by a point in a rectangle (the L state space
defined in a previous section) whose abscissa is the center-position coordinate x and
whose ordinate is the angle 0. The horizontal sides of this rectangle are identified with
each other, since orientations of 0 0 and 180 0 are identical. (The interior of the
rectangle can thus be thought of as the surface of a horizontal cylinder.)
The number N x of different x positions that are discriminable is given by the range
of x values in the input ensemble divided by the tolerance with which x can be measured
(given the noise process L - L'); similarly for No. The relative lengths Llx and MJ of the
sides of the L state space rectangle are given by Llx/ MJ = Nj No. We discuss below the
case in which Nx > > No; if No were> > Nx the roles of x and 0 in the resulting mappings
would be reversed.
There is one complicating feature that should be noted, although in the interest
of clarity we will not include it in the present analysis. Two horizontal bar patterns that
are displaced by a horizontal distance that is small compared with the bar length, are
more likely to be rendered indiscriminable by the noise process than are two vertical bar
patterns that are displaced by the same horizontal distance (which may be large
compared with the bar's width). The Hamming distance, or number of binary activity
values that need to be altered to change one such pattern into the other, is greater in the
latter case than in the former. Therefore, the distance in L state space between the two

UNORIENTED RECEPTIVE FIELDS

Figure 1.

Orientation Selectivity in a Simple Model: As the input domain size
(see text) is reduced [from (a) upper left, to (b) upper right, to (c)
lower left figure], infomax favors the emergence of an
orientation-selective L - M mapping. (d) Lower right figure shows
a solution obtained by applying Kohonen's relaxation algorithm with
50 M-points (shown as dots) to this mapping problem.

492

states should be greater in the latter case. This leads to a ""warped"" rather than simple
rectangular state space. We ignore this effect here, but it must be taken into account in
a fuller treatment of the emergence of orientation selectivity.
Consider now an L - M transformation that consists of the three-step process
(discussed above) (i) noise-induced L - L' ; (ii) deterministic L' - M'; (iii)
lateral-interaction-induced M' - M. Step (ii) maps the two-dimensional L state space
of points (x, 0) onto a one-dimensional M state space. For the present discussion, we
.consider L' - M' maps satisfying the following Ansatz: Points corresponding to the
M states are spaced uniformly, and in topographic order, along a helical line in L state
space (which we recall is represented by the surface of a horizontal cylinder). The pitch
of the helix (or the slope dO/dx) remains to be determined by the infomax principle.
Each M-neighborhood of M states (previous section) then corresponds to an interval
on such a helix. A state L' is mapped onto a state in a particular M-neighborhood if L'
is closer (in L space) to the corresponding interval of the helix than to any other portion
of the helix. We call this set of L states (for an M-neighborhood centered on M ) the
""input domain"" of M. It has rectangular shape and lies on the cylindrical surface of the
L space.
We have seen (previous sections) that infomax tends to produce maps having (i)
equal M-region areas, (ii) topographic organization, and (iii) an input domain (for each
M-neighborhood) that has similar extent in all directions (in L space). Our choice of
Ansatz enforces (i) and (ii) explicitly. Criterion (iii) is satisfied by choosing dO / dx such
that the input domain is square (for a given M-neighborhood size).
Figure 1a (having dO/dx = 0) shows a map in which the output M encodes only
information about bar center position x, and is independent of bar orientation o. The
size of the M -neighborhood is relatively large in this case. The input domain of the state
M denoted by the 'x' is shown enclosed by dotted lines. (The particular 0 value at which
we chose to draw the M line in Fig. 1a is irrelevant.) For this M-neighborhood size, the
length of the border of the input domain is as small as it can be.
As the M -neighborhood size is reduced, the dotted lines move closer together. A
vertically oblong input domain (which would result if we kept dO/dx = 0 ) would not
satisfy the infomax criterion. The helix for which the input domain is square (for this
smaller choice of M-neighborhood size) is shown in Fig. lb. The M states for this
solution encode information about bar orientation as well as center position. If each M
state corresponds to a localized output activity pattern centered at some position in a
one-dimensional array of M cells, then this solution corresponds to orientation-selective
cells organized in ""orientation columns"" (really ""orientation intervals"" in this
one-dimensional model). A ""labeling"" of the linear array of cells according to whether
their orientation preferences lie between 0 and 60, 60 and 120, or 120 and 180 degrees
is indicated by the bold, light, and dotted line segments beneath the rectangle in Fig. 1b
(and 1c).
As the M-neighborhood size is decreased still further, the mapping shown in Fig.
Ie becomes favored over that of either Fig. 1a or lb. The ""orientation columns"" shown
in the lower portion of Fig. 1c are narrower than in Fig. 1b.
A more detailed analysis of the information rate function for various mappings
confirms the main features we have here obtained by a simple geometric argument.
The same type of analysis can be applied to different types of input pattern
ensembles. To give just one other example, consider a network that receives an
ensemble of simple patterns of acoustic input. Each such pattern consists of a tone of

493

some frequency that is sensed by two ""ears"" with some interaural time delay. Suppose
that the initial network layers organize the information from each ear (separately) into
tonotopic maps, and that (by means of connections having a range of different time
delays) the signals received by both ears over some time interval appear as patterns of
cell activity at some intermediate layer L. We can then apply the infomax principle to
the signal transformation from layer L to the next layer M. The L state space can (as
before) be represented as a rectangle, whose axes are now frequency and interaural
delay (rather than spatial position and bar orientation). Apart from certain differences
(the density of L states may be nonuniform, and states at the top and bottom of the
rectangle are no longer identical), the infomax analysis can be carried out as it was for
the simplified case of orientation selectivity.
Local Algorithms
The information rate (Eqn. I), which the infomax principle states is to be
maximized subject to constraints (and possibly as part of an optimization function
containing other cost terms not discussed here), has a very complicated mathematical
form. How might this optimization process, or an approximation to it, be implemented
by a network of cells and connections each of which has limited computational power?
The geometric form in which we have cast the infomax principle for some very simple
model cases, suggests how this might be accomplished.
An algorithm due to Kohonen 8 demonstrates how topographic maps can emerge
as a result of lateral interactions within the output layer. I applied this algorithm to a
one-dimensional M layer and a two-dimensional L layer, using a Euclidean metric and
imposing periodic boundary conditions on the short dimension of the L layer. A
resulting map is shown in Fig. Id. This map is very similar to those of Figs. 1band Ic,
except for one reversal of direction. The reversal is not surprising, since the algorithm
involves only local moves (of the M-points) while the infomax principle calls for a
globally optimal solution.
More generally, Kohonen's algorithm tends empirically8 to produce maps having
the property that if one constructs the Voronoi diagram corresponding to the positions
of the M-points (that is, assigns each point L to an M region based on which M-point
L is closest to), one obtains a set of M regions that tend to have areas inversely
proportional to P(L) , and neighborhoods (corresponding to our input domains) that
tend to have similar extent in all directions rather than being elongated.
The Kohonen algorithm makes no reference to noise, to information content, or
even to an optimization principle. Nevertheless, it appears to implement, at least in a
qualitative way, the geometric conditions that infomax imposes in some simple cases.
This suggests that local algorithms along similar lines may be capable of implementing
the infomax principle in more general situations.
Our geometric formulation of the infomax principle also suggests a connection
with an algorithm proposed by von der Malsburg and Willshaw9 to generate topographic
maps. In their ""tea trade"" model, neighborhood relationships are postulated within the
source and the target spaces, and the algorithm's operation leads to the establishment
of a neighborhood-preserving mapping from source to target space. Such neighborhood
relationships arise naturally in our analysis when the infomax principle is applied to our
The noise process induces a
three-step L - L' - M' - M transformation.

494

neighborhood relation on the L space, and lateral connections in the M cell layer can
induce a neighborhood relation on the M space.
More recently, Durbin and Willshaw lO have devised an approach to solving certain
geometric optimization problems (such as the traveling salesman problem) by a gradient
descent method bearing some similarity to Kohonen's algorithm.
There is a complementary relationship between the infomax principle and a local
algorithm that may be found to implement it. On the one hand, the principle may
explain what the algorithm is ""for"" -- that is, how the algorithm may contribute to the
generation of a useful perceptual system. This in turn can shed light on the system-level
role of lateral connections and synaptic modification mechanisms in biological networks.
On the other hand, the existence of such a local algorithm is important for demonstrating
that a network of relatively simple processors -- biological or synthetic -- can in fact find
global near-maxima of the Shannon information rate.

A Possible Connection Between Infomax and a Thermodynamic Principle
The principle of ""maximum preservation of information"" can be viewed
equivalently as a principle of ""minimum dissipation of information."" When the principle
is satisfied, the loss of information from layer to layer is minimized, and the flow of
information is in this sense as ""nearly reversible"" as the constraints allow. There is a
resemblance between this principle and the principle of ""minimum entropy production""
II in nonequilibrium thermodynamics. It has been suggested by Prigogine and others
that the latter principle is important for understanding self-organization in complex
systems. There is also a resemblance, at the algorithmic level, between a Hebb-type
modification rule and the autocatalytic processes l2 considered in certain models of
evolution and natural selection. This raises the possibility that the connection I have
drawn between synaptic modification rules and an information-theoretic optimization
principle may be an example of a more general relationship that is important for the
emergence of complex and apparently ""goal-oriented If structures and behaviors from
relatively simple local interactions, in both neural and non-neural systems.
References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]

R. Linsker, Proc. Natl. Acad. Sci. USA 83,7508,8390,8779 (1986).
D. H . Hubel and T. N. Wiesel, Proc. Roy. Soc. London 8198,1 (1977).
D. O. Hebb, The Organization of Behavior (Wiley, N. Y., 1949).
R. Linsker, in: R. Cotterill (ed.), Computer Simulation in Brain Science
20-22 August 1986; Cambridge Univ. Press, in press), p. 416.
R. Linsker, Computer (March 1988, in press).
E. Oja,J. Math. Bioi. 15 , 267 (1982).
C . E. Shannon, Bell Syst. Tech. J. 27 . 623 (1948).
T . Kohonen, Self-Organization and Associative Memory (Springer-Verlag,
C. von der Malsburg and D. J. Willshaw, Proc. Nat I. A cad. Sci. USA 74 ,
R. Durbin and D. J. Willshaw, Nature 326,689 (1987).
P. Glansdorff and I. Prigogine, Thermodynamic Theory of Structure,
Fluctuations (Wiley-Interscience, N. Y., 1971).
M. Eigen and P. Schuster, Die Naturwissenschaften 64 , 541 (1977).

(Copenhagen.

N. Y .. 19S4).
5176 (1977).
Stabili(v. and

"
6,1987,"A Neural-Network Solution to the Concentrator Assignment Problem","",6-a-neural-network-solution-to-the-concentrator-assignment-problem.pdf,"Abstract Missing","775

A NEURAL-NETWORK SOLUTION TO THE CONCENTRATOR
ASSIGNNlENT PROBLEM
Gene A. Tagliarini
Edward W. Page
Department of Computer Science, Clemson University, Clemson, SC

29634-1906
ABSTRACT
Networks of simple analog processors having neuron-like properties have
been employed to compute good solutions to a variety of optimization problems. This paper presents a neural-net solution to a resource allocation problem that arises in providing local access to the backbone of a wide-area communication network. The problem is described in terms of an energy function
that can be mapped onto an analog computational network. Simulation results
characterizing the performance of the neural computation are also presented.
INTRODUCTION
This paper presents a neural-network solution to a resource allocation
problem that arises in providing access to the backbone of a communication
network. 1 In the field of operations research, this problem was first known as
the warehouse location problem and heuristics for finding feasible, suboptimal
solutions have been developed previously.2. 3 More recently it has been known
as the multifacility location problem4 and as the concentrator assignment problem.1
THE HOPFIELD NEURAL NETWORK MODEL
The general structure of the Hopfield neural network model5 ? 6,7 is illustrated in Fig. 1. Neurons are modeled as amplifiers that have a sigmoid input!
output curve as shown in Fig. 2. Synapses are modeled by permitting the output of any neuron to be connected to the input of any other neuron. The
strength of the synapse is modeled by a resistive connection between the output
of a neuron and the input to another. The amplifiers provide integrative analog
summation of the currents that result from the connections to other neurons as
well as connection to external inputs. To model both excitatory and inhibitory
synaptic links, each amplifier provides both a normal output V and an inverted
output V. The normal outputs range between 0 and 1 while the inverting amplifier produces corresponding values between 0 and -1. The synaptic link between the output of one amplifier and the input of another is defined by a
conductance Tij which connects one of the outputs of amplifier j to the input of
amplifier i. In the Hopfield model, the connection between neurons i and j is
made with a resistor having a value Rij = 1rrij . To provide an excitatory synaptic connection (positive Tij ), the resistor is connected to the normal output of
This research was supported by the U.S. Army Strategic Defense Command.
? American Institute of Physics 1988

776

13

14

inputs

1

V

o
VI

V2
V3
V4
outputs
Fig. 1. Schematic for a simplified
Hopfield network with four neurons.

o

-u

+u

Fig. 2. Amplifier input/output
relationship

amplifier j. To provide an inhibitory connection (negative Tij), the resistor is
connected to the inverted output of amplifier j. The connections among the
neurons are defined by a matrix T consisting of the conductances T ij . Hopfield has shown that a symmetric T matrix (Tij = Tji ) whose diagonal entries
are all zeros, causes convergence to a stable state in which the output of each
amplifier is either 0 or 1. Additionally, when the amplifiers are operated in the
high-gain mode, the stable states of a network of n neurons correspond to the
local minima of the quantity

n

E

= (-112)

n

L L
i=l j=l

n

T?V.V?
IJ 1 J

L

V.I?
I 1

(1)

where Vi is the output of the ith neuron and Ii is the externally supplied input
to the ph neuron. Hopfield refers to E as the computational energy of the system.
THE CONCENTRATOR ASSIGNMENT PROBLEM
Consider a collection of n sites that are to be connected to m concentrators as illustrated in Fig. 3(a). The sites are indicated by the shaded circles
and the concentrators are indicated by squares. The problem is to find an
assignment of sites to concentrators that minimizes the total cost of the assignment and does not exceed the capacity of any concentrator. The constraints
that must be met can be summarized as follows:
a) Each site i ( i
and

= 1,

2, ... , n ) is connected to exactly one concentrator;

777

b) Each concentrator j (j = 1, 2, ... , m ) is connected to no more than kj
sites (where kj is the capacity of concentrator D.
Figure 3(b) illustrates a possible solution to the problem represented in Fig.
3(a).

?

0

0

??

??

?

0

? ?

?
??

?

0

o Concentrators

? Sites

(a). Site/concentrator map

(b). Possible assignment

Fig. 3. Example concentrator assignment problem
If the cost of assigning site i to concentrator j is cij , then the total cost of

a particular assignment is
total cost

n

m

i=l

j=l

= L L x ??IJ c??IJ

(2)

where Xij = 1 only if we actually decide to assign site i to concentrator j and is 0
otherwise. There are mn possible assignments of sites to concentrators that
satisfy constraint a). Exhaustive search techniques are therefore impractical
except for relatively small values of m and n.
THE NEURAL NETWORK SOLUTION
This problem is amenable to solution using the Hopfield neural network
model. The Hopfield model is used to represent a matrix of possible assignments of sites to concentrators as illustrated in Fig. 4. Each square corresponds

778

CONCENTRATORS
1
2
j
m

r,;------;-,
/r

SITES

1

,II 11- --III ---III,

2

,~ .---~ ---~I
????
,..
?
? I The darkly shaded neu-

~~

i

'~n

~

III 11- --II --- II Iron corresponds to the
::

:

:

'Ii ? ---Ii ---Ii '
~ -

"" n+l

SLACK .... < n+2
,~n+k j

-

-

-

-

hypothesis that site i
should be

as~igned to

:.J concentrator J.

-

II 111---11---11
III II ---~ ---?
?

??

II 11- --III ---III
Fig. 4. Concentrator assignment array

to a neuron and a neuron in row i and column j of the upper n rows of the
array represents the hypothesis that site i should be connected to concentrator
j. If the neuron in row i and column j is on, then site i should be assigned to
concentrator j; if it is off, site i should not be assigned to concentrator j.
The neurons in the lower sub-array, indicated as ""SLACK"", are used to
implement individual concentrator capacity constraints. The number of slack
neurons in a column should equal the capacity (expressed as the number sites
which can be accommodated) of the corresponding concentrator. While it is
not necessary to assume that the concentrators have equal capacities, it was
assumed here that they did and that their cumulative capacity is greater than or
equal to the number of sites.
To ena~le the neurons in the network illustrated above to compute solutions to the concentrator problem, the network must realize an energy function
in which the lowest energy states correspond to the least cost assignments. The
energy function must therefore favor states which satisfy constraints a) and b)
above as well as states that correspond to a minimum cost assignment. The
energy function is implemented in terms of connection strengths between neurons. The following section details the construction of an appropriate energy
function.

779

THE ENERGY FUNCTION
Consider the following energy equation:
n

E

=

A

m

L ( .L1 y 1J..

. 1
1=

2

- 1 )

+

J=

B

m

n+k?

j=1

i=1

L (L

J y .. - k . )2

IJ

J

(3~

m n+kj

+ C

L L

y.. ( 1 - Yij )
j=1 i=1 1J

where Y ij is the output of the amplifier in row i and column j of the neuron
matrix, m and n are the number of concentrators and the number of sites
respectively, and kj is the capacity of concentrator j.
The first term will be minimum when the sum of the outputs in each row
of neurons associated with a site equals one. Notice that this term influences
only those rows of neurons which correspond to sites; no term is used to coerce
the rows of slack neurons into a particular state.
The second term of the equation will be minimum when the sum of the
outputs in each column equals the capacity kj of the corresponding concentrator. The presence of the kj slack neurons in each column allows this term to
enforce the concentrator capacity restrictions. The effect of this term upon the
upper sub-array of neurons (those which correspond to site assignments) is
that no more than kj sites will be assigned to concentrator j. The number of
neurons to be turned on in column j is kj ; consequently, the number of neurons turned on in column j of the assignment sub-array will be less than or
equal to kj .
The third term causes the energy function to favor the ""zero"" and ""one""
states of the individual neurons by being minimum when all neurons are in one
or the other of these states. This term influences all neurons in the network.
In summary, the first term enforces constraint a) and the second term
enforces constraint b) above. The third term guarantees that a choice is actually made; it assures that each neuron in the matrix will assume a final state
near zero or one corresponding to the Xij term of the cost equation (Eq. 2).

After some algebraic re-arrangement, Eq. 3 can be written in the form of
Eq. 1 where
.,
{A * 8(i,k) * (1-8U,I) + B * 8U,1) * (1-8(i,k?, if i<n and k<n
T IJ kl =
(4)
,
C * 8U,I) * (1-8(i,k?, if i>n or k>n.
Here quadruple subscripts are used for the entries in the matrix T. Each entry
indicates the strength of the connection between the neuron in row i and column j and the neuron in row k and column I of the neuron matrix. The function delta is given by

780

1, if i = j
(5)
0, otherwise.
The A and B terms specify inhibitions within a row or a column of the upper
sub-array and the C term provides the column inhibitions required for the
neurons in the sub-array of slack neurons.
8( i , j ) = {

Equation 3 specifies the form of a solution but it does not include a term
that will cause the network to favor minimum cost assignments. To complete
the formulation, the following term is added to each Tij,kl:

D ? 8( j , I ) ? ( 1 - 8( i , k ) )
(cost [ i , j ] + cost [ k , I ])
where cost[ i , j ] is the cost of assigning site i to concentrator j. The effect of
this term is to reduce the inhibitions among the neurons that correspond to low
cost assignments. The sum of the costs of assigning both site i to concentrator j
and site k to concentrator I was used in order to maintain the symmetry of T.
The external input currents were derived from the energy equation (Eq.3)
and are given by
j , if i < n
(6)
IJ 2 ? k j - 1, otherwise.

I.._ {2. k

This exemplifies a teChnique for combining external input currents which arise
from combinations of certain basic types of constraints.
AN EXAMPLE

The neural network solution for a concentrator assignment problem consisting of twelve sites and five concentrators was simulated. All sites and concentrators were located within the unit square on a randomly generated map.
For this problem, it was assumed that no more than three sites could be
assigned to a concentrator. The assignment cost matrix and a typical assignment resulting from the simulation are shown in Fig. 5. It is interesting to
notice that the network proposed an assignment which made no use of concentrator 2.
Because the capacity of each concentrator kj was assumed to be three
sites, the external input current for each neuron in the upper sub-array was
I ij = 6
while in the sub-array of slack neurons it was
I ij = 5.
The other parameter values used in the simulation were
A = B = C =-2

and

D = 0.1 .

781

SITES

1

CONCENTRATORS
2
4
3

5

@

.46

.40

.63

.39

.92

.38

.82

.81

.56

@

.51

.76

.46

.17

.39

.77

.41

H

@

.81

.54

.52

I

.60

.67

.44

J

@

.84

.76

K

.42

.33

.55

L

@

A

.47

.28

B

.72

.75

C

.95

.71

D

.88

.78

@
@
@

E

.31

.62

F

.25

G

.55

.60 1.05

G
B
.66

.71

G
G
.56
.51
.48
.38
.18

Fig. 5. The concentrator assignment cost matrix with choices circled.
Since this choice of parameters results in a T matrix that is symmetric
and whose diagonal entries are all zeros, the network will converge to the
minima of Eq. 3. Furthermore, inclusion of the term which is weighted by the
parameter D causes the network to favor minimum cost assignments.
To evaluate the performance of the simulated network, an exhaustive
search of all solutions to the problem was conducted using a backtracking algorithm. A frequency distribution of the solution costs associated with the assignments generated by the exhaustive search is shown in Fig. 6. For comparison,
a histogram of the results of one hundred consecutive runs of the neural-net
simulation is shown in Fig. 7. Although the neural-net simulation did not find
a global minimum, ninety-two of the one hundred assignments which it did
find were among the best 0.01 % of all solutions and the remaining eight were
among the best 0.3%.
CONCLUSION
Neural networks can be used to find good, though not necessarily optimal, solutions to combinatorial optimization problems like the concentrator

782

Frequency

Frequency

25
4000000
3500000
3000000
250000

20
15
10

1500000
100000
500000

5

OL----

3.2

4.2

5.2

6.2

7.2

Cost

o

8.2

Fig. 6. Distribution of assignment Fig. 7. Distribution of assignment
costs resulting from an exhaustive costs resulting from 100 consecutive executions of the neural net
search of all possible solutions.
simulation.
assignment problem. In order to use a neural network to solve such problems,
it is necessary to be able to represent a solution to the problem as a state of the
network. Here the concentrator assignment problem was successfully mapped
onto a Hopfield network by associating each neuron with the hypothesis that a
given site should be assigned to a particular concentrator. An energy function
was constructed to determine the connections that were needed and the resulting neural network was simulated.
While the neural network solution to the concentrator assignment problem did not find a globally minimum cost assignment, it very effectively rejected poor solutions. The network was even able to suggest assignments which
would allow concentrators to be removed from the communication network.
REFERENCES
1. A. S. Tanenbaum, Computer Networks (Prentice-Hall: Englewood Cliffs,

New Jersey, 1981), p. 83.
2. E. Feldman, F. A. Lehner and T. L. Ray, Manag. Sci. V12, 670 (1966).
3. A. Kuehn and M. Hamburger, Manag. Sci. V9, 643 (1966).
4. T. Aykin and A. 1. G. Babu, 1. of the Oper. Res. Soc. V38, N3, 241 (1987).
5. J. 1. Hopfield, Proc. Natl. Acad. Sci. U. S. A., V79, 2554 (1982).
6. J. 1. Hopfield and D. W. Tank, Bio. Cyber. V52, 141 (1985) .
7. D. W. Tank and 1. 1. Hopfield, IEEE Trans. on Cir. and Sys. CAS-33, N5,
533 (1986).

"
7,1987,"Experimental Demonstrations of Optical Neural Computers","",7-experimental-demonstrations-of-optical-neural-computers.pdf,"Abstract Missing","377

EXPERIMENTAL DEMONSTRATIONS OF
OPTICAL NEURAL COMPUTERS
Ken Hsu, David Brady, and Demetri Psaltis
Department of Electrical Engineering
California Institute of Technology
Pasadena, CA 91125

ABSTRACT
We describe two expriments in optical neural computing. In the first
a closed optical feedback loop is used to implement auto-associative image
recall. In the second a perceptron-Iike learning algorithm is implemented with
photorefractive holography.

INTRODUCTION
The hardware needs of many neural computing systems are well matched
with the capabilities of optical systems l ,2,3. The high interconnectivity
required by neural computers can be simply implemented in optics because
channels for optical signals may be superimposed in three dimensions with
little or no cross coupling. Since these channels may be formed holographically,
optical neural systems can be designed to create and maintain interconnections
very simply.
Thus the optical system designer can to a large extent
avoid the analytical and topological problems of determining individual
interconnections for a given neural system and constructing physical paths
for these interconnections.
An archetypical design for a single layer of an optical neural computer is
shown in Fig. 1. Nonlinear thresholding elements, neurons, are arranged on
two dimensional planes which are interconnected via the third dimension by
holographic elements. The key concerns in implementing this design involve
the need for suitable nonlinearities for the neural planes and high capacity,
easily modifiable holographic elements. While it is possible to implement the
neural function using entirely optical nonlinearities, for example using etalon
arrays\ optoelectronic two dimensional spatial light modulators (2D SLMs)
suitable for this purpose are more readily available. and their properties,
i.e. speed and resolution, are well matched with the requirements of neural
computation and the limitations imposed on the system by the holographic
interconnections 5 ,6. Just as the main advantage of optics in connectionist
machines is the fact that an optical system is generally linear and thus
allows the superposition of connections, the main disadvantage of optics is
that good optical nonlinearities are hard to obtain. Thus most SLMs are
optoelectronic with a non-linearity mediated by electronic effects. The need for
optical nonlinearities arises again when we consider the formation of modifiable
optical interconnections, which must be an all optical process. In selecting

@

American Institute of Physics 1988

378

a holographic material for a neural computing application we would like to
have the capability of real-time recording and slow erasure. Materials such
as photographic film can provide this only with an impractical fixing process.
Photorefractive crystals are nonlinear optical materials that promise to have
a relatively fast recording response and long term memory4,5,6,7,B.

'. '.

.

""

.....

..

'.

.. .'

- ~ :-w:-=7 -~---

"" . '.

......

. '.
Fourier
lens

hologro.phlc I""IealuI""I

Fourier
lens

Figure 1. Optical neural computer architecture.
In this paper we describe two experimental implementations of optical
neural computers which demonstrate how currently available optical devices
may be used in this application. The first experiment we describe involves an
optical associative loop which uses feedback through a neural plane in the form
of a pinhole array and a separate thresholding plane to implement associate
regeneration of stored patterns from correlated inputs. This experiment
demonstrates the input-output dynamics of an optical neural computer similar
to that shown in Fig. 1, implemented using the Hughes Liquid Crystal Light
Valve. The second experiment we describe is a single neuron optical perceptron
implemented with a photorefractive crystal. This experiment demonstrates
how the learning dynamics of long term memory may be controlled optically.
By combining these two experiments we should eventually be able to construct
high capacity adaptive optical neural computers.

OPTICAL ASSOCIATIVE LOOP
A schematic diagram of the optical associative memory loop is shown in
Fig. 2. It is comprised of two cascaded Vander Lugt correlators9. The input
section of the system from the threshold device P1 through the first hologram
P2 to the pinhole array P3 forms the first correlator. The feedback section
from P3 through the second hologram P4 back to the threshold device P1
forms the second correlator. An array of pinholes sits on the back focal plane
of L2, which coincides with the front focal plane of L3. The purpose of the
pinholes is to link the first and the second (reversed) correlator to form a closed
optical feedback loop 10.
There are two phases in operating this optical loop, the learning phase
and the recal phase. In the learning phase, the images to be stored are
spatially multiplexed and entered simultaneously on the threshold device. The

379

thresholded images are Fourier transformed by the lens Ll. The Fourier
spectrum and a plane wave reference beam interfere at the plane P2 and
record a Fourier transform hologram. This hologram is moved to plane P4
as our stored memory. We then reconstruct the images from the memory to
form a new input to make a second Fourier transform hologram that will stay
at plane P2.
This completes the
learning phase. In the recalling phase
an input is imaged on the threshold Input
~~~*+++~~~~
device. This image is correlated with
the reference images in the hologram
at P2. If the correlation between the
input and one of the stored images is
high a bright peak appears at one of
the pinholes. This peak is sampled by
~ -,.....,.- Second
Pinhole
Hologram
Array - -.... L z
the pinhole to reconstruct the stored
I
I
image from the hologram at P4. The
reconstructed beam is then imaged
back to the threshold device to form a
closed loop. If the overall optical gain Figure. 2.
All-optical associative
in the loop exceeds the loss the loop loop. The threshold device is a LCLV,
signal will grow until the threshold and the holograms are thermoplastic
device is saturated. In this case, we plates.
can cutoff the external input image
and the optical loop will be latched at
the stable memory.
The key elements in this optical loop are the holograms, the pinhole array,
and the threshold device. If we put a mirror 10 or a phase conjugate mirror 7 ,11
at the pinhole plane P3 to reflect the correlation signal back through the
system then we only need one hologram to form a closed loop. The use of two
holograms, however, improves system performance. We make the hologram at
P2 with a high pass characteristic so that the input section of the loop has
high spectral discrimination. On the other hand we want the images to be
reconstructed with high fidelity to the original images. Thus the hologram at
plane P4 must have broadband characteristics. We use a diffuser to achieve
this when making this hologram. Fig. 3a shows the original images. Fig. 3b
and Fig. 3c are the images reconstructed from first and second holograms,
respectively. As desired, Fig. 3b is a high pass version of the stored image
while Fig. 3c is broadband .
Each of the pinholes at the correlation plane P3 has a diameter of 60
j.lm. The separations between the pinholes correspond to the separations of
the input images at plane P 1. If one of the stored images appears at P 1 there
will be a bright spot at the corresponding pinhole on plane P3. If the input
image shifts to the position of another image the correlation peak will also

380

,.
~
?.. ?

'

.a:..J

~

a.

. , .'""
.

~

~.

(

i

\~ .~

-y::'
. ..

?Il,... .'

.r

I

K~?';t

L
?

? ?
.#

b.

c.

Figure 3. (a) The original images. (b)The reconstructed images from the highpass hologram P2. (c) The reconstructed images from the band-pass hologram

P4.
shift to another pinhole. But if the shift is not an exact image spacing the
correlation peak can not pass the pinhole and we lose the feedback signal.
Therefore this is a loop with ""discrete"" shift invariance. Without the pinholes
the cross-correlation noise and the auto-correlation peak will be fed back to
the loop together and the reconstructed images won't be recognizable. There
is a compromise between the pinhole size and the loop performance. Small
pinholes allow good memory discrimination and sharp reconstructed images,
but can cut the signal to below the level that can be detected by the threshold
device and reduce the tolerance of the system to shifts in the input. The
function of the pinhole array in this system might also be met by a nonlinear
spatial light modulator, in which case we can achieve full shift invariance 12 ?
The threshold device at plane PI is a Hughes Liquid Crystal Light Valve.
The device has a resolution of 16 Ip/mm and uniform aperture of 1 inch
diameter. This gives us about 160,000 neurons at PI. In order to compensate
for the optical loss in the loop, which is on the order of 10- 5 , we need the
neurons to provide gain on the order of 105. In our system this is achieved
by placing a Hamamatsu image intensifier at the write side of the LCLV.
Since the microchannel plate of the image intensifier can give gains of 104 , the
combination of the LCLV and the image intensifier can give gains of 10 6 with
sensitivity down to n W /cm 2 . The optical gain in the loop can be adjusted by
changing the gain of the image intensifier.
Since the activity of neurons and the dynamics of the memory loop is
a continuously evolving phenomenon, we need to have a real time device to
monitor and record this behavior. We do this by using a prism beam splitter
to take part of the read out beam from the LCLV and image it onto a CCD
camera. The output is displayed on a CRT monitor and also recorded on a
video tape recorder. Unfortunately, in a paper we can only show static pictures
taken from the screen. We put a window at the CCD plane so that each time
we can pick up one of the stored images. Fig. 4a shows the read out image

381

a.

b.

c.

Figure 4. (a) The external input to the optical loop. (b) The feedback image
superimposed with the input image. (c) The latched loop image.
from the LCLV which comes from the external input shifted away from its
stored position. This shift moves its correlation peak so that it does not match
the position of the pinhole. Thus there is no feedback signal going through
the loop. If we cut off the input image the read out image will die out with a
characteristic time on the order of 50 to 100 ms, corresponding to the response
time of the LCLV. Now we shift the input image around trying to search for
the correct position. Once the input image comes close enough to the correct
position the correlation peak passes through the right pinhole, giving a strong
feedback signal superimposed with the external input on the neurons. The
total signal then goes through the feedback loop and is amplified continuously
until the neurons are saturated. Depending on the optical gain of the neurons
the time required for the loop to reach a stable state is between 100 ms and
several seconds. Fig. 4b shows the superimposed images of the external input
and the loop images. While the feedback signal is shifted somewhat with
respect to the input, there is sufficient correlation to induce recall. If the
neurons have enough gain then we can cut off the input and the loop stays in
its stable state. Otherwise we have to increase the neuron gain until the loop
can sustain itself. Fig. 4c shows the image in the loop with the input removed
and the memory latched. If we enter another image into the system, again
we have to shift the input within the window to search the memory until we
are close enough to the correct position. Then the loop will evolve to another
stable state and give a correct output.
The input images do not need to match exactly with the memory. Since
the neurons can sense and amplify the feedback signal produced by a partial
match between the input and a stored image, the stored memory can grow
in the loop. Thus the loop has the capability to recall the complete memory
from a partial input. Fig. 5a shows the image of a half face input into the
system. Fig. 5b shows the overlap of the input with the complete face from
the memory. Fig. 5c shows the stable state of the loop after we cut off the
external input. In order to have this associative behavior the input must have
enough correlation with the stored memory to yield a strong feedback signal.
For instance, the loop does not respond to the the presentation of a picture of

382

a.

c.

Figure 5. (a) Partial face used as the external input. (b) The superimposed
images of the partial input with the complete face recalled by the loop. (c)
The complete face latched in the loop.

a.

b.

c.

Figure 6. (a) Rotated image used as the external input. (b) The superimposed
images of the input with the recalled image from the loop. (c) The image
latched in the optical loop.
a person not stored in memory.
Another way to demonstrate the associative behavior of the loop is to use
a rotated image as the input. Experiments show that for a small rotation the
loop can recognize the image very quickly. As the input is rotated more, it
takes longer for the loop to reach a stable state. If it is rotated too much,
depending on the neuron gain, the input won't be recognizable. Fig. 6a shows
the rotated input. Fig. 6b shows the overlap of loop image with input after
we turn on the loop for several seconds. Fig. 6c shows the correct memory
recalled from the loop after we cut the input. There is a trade-off between the
degree of distortion at the input that the system can tolerate and its ability
to discriminate against patterns it has not seen before. In this system the
feedback gain (which can be adjusted through the image intensifier) controls
this trade-off.

PHOTOREFRACTIVE PERCEPTRON
Holograms are recorded in photorefractive crystals via the electrooptic
modulation of the index of refraction by space charge fields created by
the migration of photogenerated charge 13 ,14. Photorefractive crystals are
attractive for optical neural applications because they may be used to store

383

long term interactions between a very large number of neurons. While
photorefractive recording does not require a development step, the fact that
the response is not instantaneous allows the crystal to store long term traces
of the learning process. Since the photorefractive effect arises from the
reversible redistribution of a fixed pool of charge among a fixed set of optically
addressable trapping sites, the photorefractive response of a crystal does not
deteriorate with exposure. Finally, the fact that photorefractive holograms
may extend over the entire volume of the crystal has previously been shown to
imply that as many as 10 10 interconnections may be stored in a single crystal
with the independence of each interconnection guaranteed by an appropriate
spatial arrangement of the interconnected neurons 6 ,5.
In this section we consider a rudimentary optical neural system which uses
the dynamics of photorefractive crystals to implement perceptron-like learning.
The architecture of this system is shown schematically in Fig. 7. The input
to the system, x, corresponds to a two dimensional pattern recorded from a
video monitor onto a liquid crystal light valve. The light valve transfers this
pattern on a laser beam. This beam is split into two paths which cross in a
photorefractive crystal. The light propagating along each path is focused such
that an image of the input pattern is formed on the crystal. The images along
both paths are of the same size and are superposed on the crystal, which is
assumed to be thinner than the depth of focus of the images. The intensity
diffracted from one of the two paths onto the other by a hologram stored in
the crystal is isolated by a polarizer and spatially integrated by a single output
detector. The thresholded output of this detector corresponds to the output
of a neuron in a perceptron.
laser

~---,t+

-

PB

LCL V TV

--f4HJ
ucl

BS$- -

COl""lputer

Xtal

PM

Figure 7. Photorefractive perceptron. PB is a polarizing beam splitter. Ll
and L2 are imaging lenses. WP is a quarter waveplate. PM is a piezoelectric
mirror. P is a polarizer. D is a detector. Solid lines show electronic control.
Dashed lines show the optical path.
The ith component of the input to this system corresponds to the intensity
in the ith pixel of the input pattern. The interconnection strength, Wi, between
the ith input and the output neuron corresponds to the diffraction efficiency
of the hologram taking one path into the other at the ith pixel of the image
plane. While the dynamics of Wi can be quite complex in some geometries

384

and crystals, it is possible to show from the band transport model for the
photorefractive effect that under certain circumstances the time development
of Wi may be modeled by

(1)
where m(s) and 4>(s) are the modulation depth and phase, respectively, of the
interference pattern formed in the crystal between the light in the two paths 15 ?
T is a characteristic time constant for crystal. T is inversely proportional to
the intensity incident on the ith pixel of the crystal. Using Eqn. 1 it is possible
to make Wi(t) take any value between 0 and W m l1Z by properly exposing the
ith pixel of the crystal to an appropriate modulation depth and intensity. The
modulation depth between two optical beams can be adjusted by a variety of
simple mechanisms. In Fig. 7 we choose to control met) using a mirror mounted
on a piezoelectric crystal. By varying the frequency and the amplitude of
oscillations in the piezoelectric crystal we can electronically set both met) and
4>(t) over a continuous range without changing the intensity in the optical
beams or interrupting readout of the system. With this control over met) it
is possible via the dynamics described in Eqn. (1) to implement any learning
algorithm for which Wi can be limited to the range (0, w maz ).
The architecture of Fig. 7 classifies input patterns into two classes
according to the thresholded output of the detector. The goal of a learning
algorithm for this system is to correctly classify a set of training patterns. The
perceptron learning algorithm involves simply testing each training vector and
adding training vectors which yield too Iowan output to the weight vector
and subtracting training vectors which yield too high an output from the
weight vector until all training vectors are correctly classified 16. This training
algorithm is described by the equation L\wi = aXj where alpha is positive
(negative) if the output for x is too low (high). An optical analog of this
method is implemented by testing each training pattern and exposing the
crystal with each incorrectly classified pattern. Training vectors that yield
a high output when a low output is desired are exposed at zero modulation
depth . Training vectors that yield a low output when high output is desired
are exposed at a modulation depth of one.
The weight vector for the k + 1th iteration when erasure occurs in the kth
iteration is given by

(2)
where we assume that the exposure time, L\t, is much less than T. Note that
since T is inversely proportional to the intensity in the ith pixel, the change in

385

Wi is proportional to the ith input. The weight vector at the k + 1th iteration
when recording occurs in the kth iteration is given by
-2~t

-~t

_ /

-~t

-~t

wi(k+ 1) = e-r-Wi(k) +2y Wi(k)Wmcue-r- (l-e-r- ) +wmaz(l-e-r-)
To lowest order in

6.t
.,.

2

(3)

and ~,
Eqn. (3) yields
w m ....

_/
~t
~t 2
wi(k + 1) = wi(k) + 2y wi(k)Wmaz(-) + Wmaz(-)
T

T

(4)

Once again the change in Wi is proportional to the ith input.
We have implemented the architecture of Fig. 7 using a SBN60:Ce crystal
provided by the Rockwell International Science Center. We used the 488 nm
line of an argon ion laser to record holograms in this crystal. Most of the
patterns we considered were laid out on 10 x 10 grids of pixels, thus allowing
100 input channels. Ultimately, the number of channels which may be achieved
using this architecture is limited by the number of pixels which may be imaged
onto the crystal with a depth of focus sufficient to isolate each pixel along the
length of the crystal.

-

??

+.+
Y

....... ? ? ?
1

3

2

..... ? ?
4

Figure 8. Training patterns.

...

1'1

j

Ia.

8.

!

l

t

I
,

0

0
aCOftClS

~

W

CIII)

Figure 9. Output in the second training cycle.

Using the variation on the perceptron learning algorithm described above
with a fixed exposure times ~tr and ~te for recording and erasing, we have
been able to correctly classify various sets of input patterns. One particular
set which we used is shown in Fig. 8. In one training sequence, we grouped
patterns 1 and 2 together with a high output and patterns 3 and 4 together
with a low output. After all four patterns had been presented four times,
the system gave the correct output for all patterns. The weights stored in
the crystal were corrected seven times, four times by recording and three by
erasing. Fig . 9a shows the output of the detector as pattern 1 is recorded in
the second learning cycle. The dashed line in this figure corresponds to the
threshold level. Fig. 9b shows the output of the detector as pattern 3 is erased
in the second learning cycle.

386

CONCLUSION
The experiments described in this paper demonstrate how neural network
architectures can be implemented using currently available optical devices. By
combining the recall dynamics of the first system with the learning capability
of the second, we can construct sophisticated optical neural computers.

ACKNOWLEDGEMENTS
The authors thank Ratnakar Neurgaonkar and Rockwell International for
supplying the SBN crystal used in our experiments and Hamamatsu Photonics
K.K. for assistance with image intesifiers. We also thank Eung Gi Paek and
Kelvin Wagner for their contributions to this research.
This research is supported by the Defense Advanced Research Projects
Agency, the Army Research Office, and the Air Force Office of Scientific
Research.

REFERENCES
1. Y. S. Abu-Mostafa and D. Psaltis, Scientific American, pp.88-95, March,

2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.

1987.
D. Psaltis and N. H. Farhat, Opt. Lett., 10,(2),98(1985).
A. D. Fisher, R. C. Fukuda, and J. N. Lee, Proc. SPIE 625, 196(1986).
K. Wagner and D. Psaltis, Appl. opt., 26(23), pp.5061-5076(1987).
D. Psaltis, D. Brady, and K. Wagner, Applied optics, March 1988.
D. Psaltis, J. Yu, X. G. Gu, and H. Lee, Second Topical Meeting on
Optical Computing, Incline Village, Nevada, March 16-18,1987.
A. Yariv, S.-K. Kwong, and K. Kyuma, SPIE proc. 613-01,(1986).
D. Z. Anderson, Proceedings of the International Conference on Neural
Networks, San Diego, June 1987.
A. B. Vander Lugt, IEEE Trans. Inform. Theory, IT-I0(2), pp.139145(1964).
E. G. Paek and D. Psaltis, Opt. Eng., 26(5), pp.428-433(1987).
Y. Owechko, G. J. Dunning, E. Marom, and B. H. Soffer, Appl. Opt.
26,(10) ,1900(1987).
D. Psaltis and J. Hong, Opt. Eng. 26,10(1987).
N. V. Kuktarev, V. B. Markov, S. G. Odulov, M. S. Soskin, and V. L.
Vinetskii, Ferroelectrics, 22,949(1979).
J. Feinberg, D. Heiman, A. R. Tanguay, and R. W. Hellwarth, J. Appl.
Phys. 51,1297(1980).
T. J. Hall, R. Jaura, L. M. Connors, P. D. Foote, Prog. Quan. Electr.
10,77(1985).
F. Rosenblatt, ' Principles of Neurodynamics: Perceptron and the Theory
of Brain Mechanisms, Spartan Books, Washington,(1961).

"
8,1987,"The Sigmoid Nonlinearity in Prepyriform Cortex","",8-the-sigmoid-nonlinearity-in-prepyriform-cortex.pdf,"Abstract Missing","242

THE SIGMOID NONLINEARITY IN PREPYRIFORM CORTEX
Frank H. Eeckman
University of California, Berkeley, CA 94720
ABSlRACT
We report a study ?on the relationship between EEG amplitude values and unit
spike output in the prepyriform cortex of awake and motivated rats. This relationship
takes the form of a sigmoid curve, that describes normalized pulse-output for
normalized wave input. The curve is fitted using nonlinear regression and is
described by its slope and maximum value.
Measurements were made for both excitatory and inhibitory neurons in the cortex.
These neurons are known to form a monosynaptic negative feedback loop. Both
classes of cells can be described by the same parameters.
The sigmoid curve is asymmetric in that the region of maximal slope is displaced
toward the excitatory side. The data are compatible with Freeman's model of
prepyriform burst generation. Other analogies with existing neural nets are being
discussed, and the implications for signal processing are reviewed. In particular the
relationship of sigmoid slope to efficiency of neural computation is examined.
INTRODUCTION
The olfactory cortex of mammals generates repeated nearly sinusoidal bursts of
electrical activity (EEG) in the 30 to 60 Hz. range 1. These bursts ride on top of a
slower ( 1 to 2 Hz.), high amplitude wave related to respiration. Each burst begins
shortly after inspiration and terminates during expiration. They are generated locally
in the cortex. Similar bursts occur in the olfactory bulb (OB) and there is a high
degree of correlation between the activity in the two structures!'
The two main cell types in the olfactory cortex are the superficial pyramidal cell
(type A), an excitatory neuron receiving direct input from the OB, and the cortical
granule cell (type B), an inhibitory interneuron. These cell groups are
monosynaptically connected in a negative feedback loop2.
Superficial pyramidal cells are mutually excitatory3, 4, 5 as well as being
excitatory to the granule cells. The granule cells are inhibitory to the pyramidal cells
as well as to each other3, 4, 6.
In this paper we focus on the analysis of amplitude dependent properties: How is
the output of a cellmass (pulses) related to the synaptic potentials (ie. waves)? The
concurrent recording of multi-unit spikes and EEG allows us to study these
phenomena in the olfactory cortex.
The anatomy of the olfactory system has been extensively studied beginning with
the work of S. Ramon y Cajal 7. The regular geometry and the simple three-layered
architecture makes these structures ideally suitable for EEG recording 4, 8. The EEG
generators in the various olfactory regions have been identified and their synaptic
connectivities have been extensively studied9, 10,5,4, 11,6.
The EEG is the scalar sum of synaptic currents in the underlying cortex. It can
be recorded using low impedance ? .5 Mohm) cortical or depth electrodes. Multiunit signals are recorded in the appropriate cell layers using high impedance (> .5
Mohm) electrodes and appropriate high pass filtering.
Here we derive a function that relates waves (EEG) to pulses in the olfactory
cortex of the rat. This function has a sigmoidal shape. The derivative of this curve
? American Institute of Physics 1988

243

gives us the gain curve for wave-to-pulse conversion. This is the forward gain for
neurons embedded in the cortical cellmass. The product of the forward gain values of
both sets of neurons (excitatory and inhibitory) gives us the feedback gain values.
These ultimately determine the dynamics of the system under study.

MATERIALS AND METI-IODS
A total of twenty-nine rats were entered in this study. In each rat a linear array of
6 100 micron stainless steel electrodes was chronically implanted in the prepyriform
(olfactory) cortex. The tips of the electrodes were electrolytically sharpened to
produce a tip impedance on the order of .5 to 1 megaohm. The electrodes were
implanted laterally in the midcortex, using stereotaxic coordinates. Their position was
verified electrophysiologically using a stimulating electrode in the olfactory tract.
This procedure has been described earlier by Freeman 12. At the end of the recording
session a small iron deposit was made to help in histological verification. Every
electrode position was verified in this manner.
Each rat was recorded from over a two week period following implantation. All
animals were awake and attentive. No stimulation (electrical or olfactory) was used.
The background environment for recording was the animal's home cage placed in the
same room during all sessions.
For the present study two channels of data were recorded concurrently. Channel
1 carried the EEG signal, filtered between 10 and 300 Hz. and digitized at 1 ms
intervals. Channel 2 carried standard pulses 5 V, 1.2 ms wide, that were obtained by
passing the multi-unit signal (filtered between 300 Hz. and 3kHz.) through a
window discriminator.
These two time-series were stored on disk for off-line processing using a PerkinElmer 3220 computer. All routines were written in FORTRAN. They were tested on
data files containing standard sine-wave and pulse signals.
DATA PROCESSING
The procedures for obtaining a two-dimensional conditional pulse probability
table have been described earlier 4. This table gives us the probability of occurrence
of a spike conditional on both time and normalized EEG amplitude value.
By counting the number of pulses at a fixed time-delay, where the EEG is
maximal in amplitude, and plotting them versus the normalized EEG amplitudes, one
obtains a sigmoidal function: The Pulse probability Sigmoid Curve (PSC) 13, 14.
This function is normalized by dividing it by the average pulse level in the record. It
is smoothed by passing it through a digital 1: 1: 1 filter and fitted by nonlinear
regression.
The equations are:
Q = Qmax ( 1- exp [ - ( ev - 1) I Qmax ]) for v> - uO
Q = -1
for v < - uO

(1 )

where uO is the steady state voltage, and Q = (p-PO)/pO.
and Qmax =(Pmax-PO)/pO.
PO is the background pulse count, Pmax is the maximal pulse count.
These equations rely on one parameter only. The derivation and justification for
these equations were discussed in an earlier paper by Freeman 13.

244

RESULTS
Data were obtained from all animals. They express normalized pulse counts, a
dimensionless value as a function of normalized EEG values, expressed as a Z-score
(ie. ranging from - 3 sd. to + 3 sd., with mean of 0.0). The true mean for the EEG
after filtering is very close to 0.0 m V and the distribution of amplitude values is very
nearly Gaussian.
The recording convention was such that high EEG-values (ie. > 0.0 to + 3.0 sd.)
corresponded to surface-negative waves. These in turn occur with activity at the
apical dendrites of the cells of interest. Low EEG values (ie. from - 3.0 sd. to < 0.0)
corresponded to surface-positive voltage values, representing inhibition of the cells.
The data were smoothed and fitted with equation (1). This yielded a Qrnax value
for every data file. There were on average 5 data files per animal. Of these 5, an
average of 3.7 per animal could be fitted succesfully with our technique. In 25 % of
the traces, each representing a different electrode pair, no correlations between spikes
and the EEG were found.
Besides Qmax we also calculated Q' the maximum derivative of the PSC,
representing the maximal gain.
There were 108 traces in all. In the first 61 cases the Qrnax value described the
wave-to-pulse conversion for a class of cells whose maximum firing probability is in
phase with the EEG. These cells were labelled type A cells 2. These traces
correspond to the excitatory pyramidal cells. The mean for Qmax in that group was
14.6, with a standard deviation of 1.84. The range was 10.5 to 17.8.
In the remaining 47 traces the Qmax described the wave-to-pulse conversion for
class B cells. Class B is a label for those cells whose maximal firing probability lags
the EEG maximum by approximately 1/4 cycle. The mean for Qrnax in that group
was 14.3, with a standard deviation of 2.05. The range in this group was 11.0 to
18.8.
The overall mean for Qmax was 14.4 with a standard deviation of 1.94. There is
no difference in Qmax between both groups as measured by the Student t-test. The
nonparametric Wilcoxon rank-sum test also found no difference between the groups
( p =0.558 for the t-test; p = 0.729 for the Wilcoxon).
Assuming that the two groups have Qmax values that are normally distributed (in
group A, mean = 14.6, median = 14.6; in group B, mean = 14.3, median = 14.1),
and that they have equal variances ( st. deviation group A is 1.84; st. deviation group
B is 2.05) but different means, we estimated the power of the t-test to detect that
difference in means.
A difference of 3 points between the Qmax's of the respective groups was
considered to be physiologically significant. Given these assumptions the power of
the t-test to detect a 3 point difference was greater than .999 at the alpha .05 level for
a two sided test. We thus feel reasonably confident that there is no difference
between the Qmax values of both groups.
The first derivative of the PSC gives us the gain for wave-to-pulse conversion4.
The maximum value for this first derivative was labelled Q'. The location at which
the maximum Q' occurs was labelled Vmax . Vmax is expressed in units of standard
deviation of EEG amplitudes.
The mean for Q' in group A was 5.7, with a standard deviation of .67, in group B
it was 5.6 with standard deviation of .73. Since Q' depends on Qmax, the same
statistics apply to both: there was no significant difference between the two groups
for slope maxima.

245

Figure 1. Distribution of Qmax values
group A
14
H
CII
.Q

~

-

"",,

12
10

-

8

I-

6

I-

group B

~

""' r-

>, r-,
;

.

"" '

,
,'
,
,
,
,
,
,
,
,

H
CII
.Q

~

r""':
;
;

~

, ,

,~

, ,,
r,
,
4 I- ~, , ': 1',
;
, , "", 1';'
, """" v,
2 .- , ,
, "" v,
, , ,"" ; ,
"".'
o
1011121314151617181920
Qmax values
,""

1','

""

;

""

;

;

14

-

12

-

10

~

8

I-

6

I-

4

~

2

.-

o

""""
,~

, ,
~""

, ,
, ,, ,

~,

,"" , , , ;: ,...
,
, ,, ,, , ,, ""
,
""
, , , , ,
, , , , , "" ' ,
,""!l~.
, , .f71.
,

p:

;

1011121314151617181920

Qmax values

The mean for Vmax was at 2.15 sd. +/- .307. In every case Vmax was on the
excitatory side from 0.00, ie. at a positive value of EEG Z-scores. All values were
greater than 1.00. A similar phenomenon has been reported in the olfactory bulb 4,
14, 15.
Figure 2. Examples of sigmoid fits.
A cell

B cell

14

14

12

12

10

10

8

8

6

6

CII

4

4

~

2

2

0

0

-2

-2

~
~

?rot

~

CII
og

11\

Po

-4
-3

-2

-1

0

1

2

3

-4
-3

-2

0

-1

1

normalized EEG amplitude
Qm = 14.0

Qm = 13.4

2

3

246

COMPARISON WITH DATA FROM TIIE OB
Previously we derived Qrnax values for the mitral cell population in the olfactory
bulb14. The mitral cells are the output neurons of the bulb and their axons form the
lateral olfactory tract (LOT). The LOT is the main input to the pyramidal cells (type
A) in the cortex.
For awake and motivated rats (N = 10) the mean Qmax value was 6.34 and the
standard deviation was 1.46. The range was 4.41- 9.53. For anesthetized animals
(N= 8) the mean was 2.36 and the standard deviation was 0.89. The range was 1.153.62. There was a significant difference between anesthetized and awake animals.
Furthermore there is a significant difference between the Qmax value for cortical cells
and the Qmaxvalue for bulbar cells (non - overlapping distributions).
DISCUSSION
An important characteristic of a feedback loop is its feedback gain. There is ample
evidence for the existence of feedback at all levels in the nervous system. Moreover
specific feedback loops between populations of neurons have been described and
analyzed in the olfactory bulb and the prepyriform cortex 3, 9, 4.
A monosynaptic negative feedback loop has been shown to exist in the PPC,
between the pyramidal cells and inhibitory cells, called granule cells 3, 2, 6, 16.
Time series analysis of concurrent pulse and EEG recordings agrees with this idea.
The pyramidal cells are in the forward limb of the loop: they excite the granule
cells. They are also mutually excitatory 2,4,16. The granule cells are in the feedback
limb: they inhibit the pyramidal cells. Evidence for mutual inhibition (granule to
granule) in the PPC also exists 17, 6.
The analysis of cell firings versus EEG amplitude at selected time-lags allows one
to derive a function (the PSC) that relates synaptic potentials to output in a neural
feedback system. The first derivative of this curve gives an estimate of the forward
gain at that stage of the loop. The procedure has been applied to various structures in
the olfactory system 4, 13, 15, 14. The olfactory system lends itself well to this type
of analysis due to its geometry, topology and well known anatomy.
Examination of the experimental gain curves shows that the maximal gain is
displaced to the excitatory side. This means that not only will the cells become
activated by excitatory input, but their mutual interaction strength will increase. The
result is an oscillatory burst of high frequency ( 30- 60 Hz.) activity. This is the
mechanism behind bursting in the olfactory EEG 4, 13.
In comparison with the data from the olfactory bulb one notices that there is a
significant difference in the slope and the maximum of the PSC. In cortex the values
are substantially higher, however the Vmax is similar. C. Gray 15 found a mean
value of 2.14 +/- 0.41 for V max in the olfactory bulb of the rabbit (N= 6). Our value
in the present study is 2.15 +/- .31. The difference is not statistically significant.
There are important aspects of nonlinear coupling of the sigmoid type that are of
interest in cortical functioning. A sigmoid interaction between groups of elements
(""neurons"") is a prominent feature in many artificial neural nets. S. Grossberg has
extensively studied the many desirable properties of sigmoids in these networks.
Sigmoids can be used to contrast-enhance certain features in the stimulus. Together
with a thresholding operation a sigmoid rule can effectively quench noise. Sigmoids
can also provide for a built in gain control mechanism 18, 19.

247

Changing sigmoid slopes have been investigated by J. Hopfield. In his network
changing the slope of the sigmoid interaction between the elements affects the
number of attractors that the system can go to 20. We have previously remarked
upon the similarities between this and the change in sigmoid slope between waking
and anesthetized animals 14. Here we present a system with a steep slope (the PPC)
in series with a system with a shallow slope (the DB).
Present investigations into similarities between the olfactory bulb and Hopfield
networks have been reported 21, 22. Similarities between the cortex and Hopfieldlike networks have also been proposed 23.
Spatial amplitude patterns of EEG that correlate with significant odors exist in the
bulb 24. A transmission of ""wave-packets"" from the bulb to the cortex is known to
occur 25. It has been shown through cofrequency and phase analysis that the bulb
can drive the cortex 25, 26. It thus seeems likely that spatial patterns may also exist
in the cortex. A steeper sigmoid, if the analogy with neural networks is correct,
would allow the cortex to further classify input patterns coming from the olfactory
bulb.
In this view the bulb could form an initial classifier as well as a scratch-pad
memory for olfactory events. The cortex could then be the second classifier, as well
as the more permanent memory.
These are at present speculations that may turn out to be premature. They
nevertheless are important in guiding experiments as well as in modelling.
Theoretical studies will have to inform us of the likelihood of this kind of processing.
REFERENCES
1 S.L. Bressler and W.J. Freeman, Electroencephalogr. Clin. Neurophysiol. ~: 19
(1980).
.
2 W.J. Freeman, J. Neurophysiol. ll: 1 (1968).
3 W.J. Freeman, Exptl. Neurol. .lO.: 525 (1964).
4 W.J. Freeman, Mass Action in the Nervous System. (Academic Press, N.Y.,
1975), Chapter 3.
5 L.B. Haberly and G.M. Shepherd, Neurophys.~: 789 (1973).
6 L.B. Haberly and J.M. Bower, J. Neurophysiol. ll: 90 (1984).
7 S. Ramon y Cajal, Histologie du Systeme Nerveux de l'Homme et des Vertebres.
( Ed. Maloine, Paris, 1911) .
8 W.J. Freeman, BioI. Cybernetics . .3..5.: 21 (1979).
9 W. Rall and G.M. Shepherd, J. Neurophysiol.ll: 884 (1968).
10 G.M. Shepherd, Physiol. Rev. 5l: 864 (1972).
11 L.B. Haberly and J.L. Price, J. Compo Neurol. .l18.; 711 (1978).
12 W.J. Freeman, Exptl. Neurol. ~: 70 (1962).
13 W.J. Freeman, BioI. Cybernetics.ll: 237 (1979).
14 F.H. Eeckman and W.J. Freeman, AlP Proc. ill: 135 (1986).
15 C.M. Gray, Ph.D. thesis, Baylor College of Medicine (Houston,1986)
16 L.B. Haberly, Chemical Senses, .ll!: 219 (1985).
17 M. Satou et aI., J. Neurophysiol. ~: 1157 (1982).
18 S. Grossberg, Studies in Applied Mathematics, Vol LII, 3 (MIT Press, 1973)
p 213.
19 S. Grossberg, SIAM-AMS Proc. U: 107 (1981).
20 J.J Hopfield, Proc. Natl. Acad. Sci. USA 8.1: 3088 (1984).
21 W.A. Baird, Physica 2.m: 150 (1986).
22 W.A. Baird, AlP Proceedings ill: 29 (1986).
23 M. Wilson and J. Bower, Neurosci. Abstr. 387,10 (1987).

248

24 K.A. Grajski and W.J. Freeman, AlP Proc.lS.l: 188 (1986).
25 S.L. Bressler, Brain Res. ~: 285 (1986).
26 S.L. Bressler, Brain Res.~: 294 (1986).

"
9,1987,"Learning on a General Network","",9-learning-on-a-general-network.pdf,"Abstract Missing","22

LEARNING ON A GENERAL NETWORK

Amir F. Atiya
Department of Electrical Engineering
California Institute of Technology
Ca 91125

Abstract
This paper generalizes the backpropagation method to a general network containing feedback t;onnections. The network model considered consists of interconnected groups of neurons,
where each group could be fully interconnected (it could have feedback connections, with possibly asymmetric weights), but no loops between the groups are allowed. A stochastic descent
algorithm is applied, under a certain inequality constraint on each intra-group weight matrix
which ensures for the network to possess a unique equilibrium state for every input.

Introduction
It has been shown in the last few years that large networks of interconnected ""neuron"" -like
elemp.nts are quite suitable for performing a variety of computational and pattern recognition
tasks. One of the well-known neural network models is the backpropagation model [1]-[4]. It
is an elegant way for teaching a layered feedforward network by a set of given input/output
examples. Neural network models having feedback connections, on the other hand, have also
been devised (for example the Hopfield network [5]), and are shown to be quite successful in
performing some computational tasks. It is important, though, to have a method for learning
by examples for a feedback network, since this is a general way of design, and thus one can
avoid using an ad hoc design method for each different computational task. The existence
of feedback is expected to improve the computational abilities of a given network. This is
because in feedback networks the state iterates until a stable state is reached. Thus processing
is perforrr:.ed on several steps or recursions. This, in general allows more processing abilities
than the ""single step"" feedforward case (note also the fact that a feedforward network is
a special case of a feedback network). Therefore, in this work we consider the problem of
developing a general learning algorithm for feedback networks.

In developing a learning algorithm for feedback networks, one has to pay attention to the
following (see Fig. 1 for an example of a configuration of a feedback network). The state of
the network evolves in time until it goes to equilibrium, or possibly other types of behavior
such as periodic or chaotic motion could occur. However, we are interested in having a steady
and and fixed output for every input applied to the network. Therefore, we have the following
two important requirements for the network. Beginning in any initial condition, the state
should ultimately go to equilibrium. The other requirement is that we have to have a unique

? American Institute of Physics 1988

23

equilibrium state. It is in fact that equilibrium state that determines the final output. The
objective of the learning algorithm is to adjust the parameters (weights) of the network in small
steps, so as to move the unique equilibrium state in a way that will result finally in an output
as close as possible to the required one (for each given input). The existence of more than op.e
equilibrium state for a given input causes the following problems. In some iterations one might
be updating the weights so as to move one of the equilibrium states in a sought direction, while
in other iterations (especially with different input examples) a different equilibrium state is
moved. Another important point is that when implementing the network (after the completion
oflearning), for a fixed input there can be more than one possible output. Independently, other
work appeared recently on training a feedback network [6],[7],[8]. Learning algorithms were
developed, but solving the problem of ensuring a unique equilibrium was not considered. This
problem is addressed in this paper and an appropriate network and a learning algorithm are
proposed.

neuron 1

outputs

inputs

Fig . 1
A recurrent network

The Feedback Network
Consider a group of n neurons which could be fully inter-connected (see Fig. 1 for an
example). The weight matrix W can be asymmetric (as opposed to the Hopfield network).
The inputs are also weighted before entering into the network (let V be the weight matrix).
Let x and y be the input and output vectors respectively. In our model y is governed by the
following set of differential equations, proposed by Hopfield [5]:

du

Tdj = Wf(u) - u

+ Vx,

y = f(u)

(1)

24

where f(u) = (J(ud, ... , f(un)f, T denotes the transpose operator, f is a bounded and
differentiable function, and.,. is a positive constant.

For a given input, we would like the network after a short transient period to give a steady
and fixed output, no matter what the initial network state was. This means that beginning
any initial condition, the state is to be attracted towards a unique equilibrium. This leads to
looking for a condition on the matrix W.

Theorem: A network (not necessarily symmetric) satisfying

L L w'fi
i

< l/max(J')2,

i

exhibits no other behavior except going to a unique equilibrium for a given input.

Proof : Let udt) and U2(t) be two solutions of (1). Let

where "" II is the two-norm. Differentiating J with respect to time, one obtains

Using (1) , the expression becomes

dJ(t) = --lluI(t)
2
-d- u2(t))11 2
t

1""

2
+ -(uI(t)
- U2(t)) T W [f( uI(t) ) - f ( uz(t) )] .
.,.

Using Schwarz's Inequality, we obtain

Again, by Schwarz's Inequality,

i = 1, ... ,n
where

Wi

denotes the

ith

row of W. Using the mean value theorem, we get

Ilf(udt)) - f(U2(t))II ~ (maxl!'I)IIUl(t) - uz(t)ll.
Using (2),(3), and the expression for J(t), we get

d~~t) ~
where

-aJ(t)

(4)

(3)

(2)

25

By hypothesis of the Theorem, a is strictly positive. Multiplying both sides of (4) by exp( at),
the inequality

results, from which we obtain

J(t)

~

J(O)e- at .

From that and from the fact that J is non-negative, it follows that J(t) goes to zero as t -+ <Xl.
Therefore, any two solutions corresponding to any two initial conditions ultimately approach
each other. To show that this asymptotic solution is in fact an equilibrium, one simply takes
U2(t) = Ul(t + T), where T is a constant, and applies the above argument (that J(t) -+ 0 as
t -+ <Xl), and hence Ul(t + T) -+ udt) as t -+ <Xl for any T, and this completes the proof.

For example, if the function

I

is of the following widely used sigmoid-shaped form,
1

I(u) = l+e- u

'

then the sum of the square of the weights should be less than 16. Note that for any function
I, scaling does not have an effect on the overall results. We have to work in our updating
scheme subject to the constraint given in the Theorem. In many cases where a large network
is necessary, this constraint might be too restrictive. Therefore we propose a general network,
which is explained in the next Section.

The General Network
We propose the following network (for an example refer to Fig. 2). The neurons are
partitioned into several groups. Within each group there are no restrictions on the connections
and therefore the group could be fully interconnected (i.e. it could have feedback connections) .
The groups are connected to each other, but in a way that there are no loops. The inputs to
the whole network can be connected to the inputs of any of the groups (each input can have
several connections to several groups). The outputs of the whole network are taken to be the
outputs (or part of the outputs) of a certain group, say group I. The constraint given in the
Theorem is applied on each intra-group weight matrix separately. Let (qa, s""), a = 1, .. . , N be
the input/output vector pairs of the function to be implemented. We would like to minimize
the sum of the square error, given by

a=l

where
M

e""

=

I)y{ -

si}2,

i=l

and yf is the output vector of group f upon giving input qa, and M is the dimension of vector
s"". The learning process is performed by feeding the input examples qU sequentially to the
network, each time updating the weights in an attempt to minimize the error.

26

inputs

J---V

outputs

Fig. 2
An example of a general network
(each group represents a recurrent network)

Now, consider a single group l. Let Wi be the intra-group weight matrix of group l, vrl
be the matrix of weights between the outputs of group,. and the inputs of group l, and yl be
the output vector of group I. Let the respective elements be w~i' V[~., and y~. Furthermore,
let
be the number of neurons of group l. Assume that the time constant l' is sufficiently
small so as to allow the network to settle quickly to the equilibrium state, which is given by
the solution of the equation

n,

yl = f(W'yl +

L vrlyr) .

(5)

r?A I

where A, is the set of the indices of the groups whose outputs a.re connected to the inputs of
group ,. We would like each iteration to update the weight matrices Wi and vrl so as to move
the equilibrium in a direction to decrease the error. We need therefore to know the change in
the error produced by a small change in the weight matrices. Let .:;';, , and aa~~, denote the
matrices whose (i, j)th element are :~'.' and ::~ respectively. Let ~ be the column vector
'1
'1
:r
whose ith element is ~. We obtain the following relations:
uy.

8e a =
8W'
8e a
8V tl

[A' _ (W')T] -1 8ea (

8yl Y

')T

,

a ( r)T
= [A' _ (W')T] -1 8e
8yl y
,

where A' is the diagonal matrix whose ith diagonal element is l/f'(Lk w!kY~ + LrLktJ[kyk)
for a derivation refer to Appendix). The vector ~ associated with groUp l can be obtained
in terms of the vectors ~, fEB"" where B, is the set of the indices of the groups whose inputs
are connected to the outputs of group ,. We get (refer to Appendix)

8e a
8yl

= '"" (V'i)T[Ai _ (Wi{r 1 8e""..
~

8y3

JlBI

(6)

The matrix A' ~ (W')T for any group l can never be singular, so we will not face any
problem in the updating process. To prove that, let z be a vector satisfying

[A' - (W'f]z = o.

27

We can write
zdmaxlf' I ~

LW~.Zk'

i

= I, ... , nl

k

where

Zi is the ,""th element of z.

Using Schwarz's Inequality, we obtain

i = I, ... ,nl
Squaring both sides and adding the inequalities for i

= I, ... , nl, we get

L/; ~ max(J')2(Lz~) LL(w~i)2.
i

k

Since the condition

(7)

k

LL(W!k)2 < I/max(J')2),
k

is enforced, it follows that (7) cannot be satisfied unless z is the zero vector. Thus, the matrix

A' - (W')T cannot be singular.

For each iteration we begin by updating the weights of group f (the group contammg
the final outputs). For that group ~ equals simply 2(y{ - SI, ... , yf.t - SM, 0, ... , O)T). Then
we move backwards to the groups connected to that group and obtain their corresponding
vectors using (6), update the weights, and proceed in the same manner until we complete
updating all the groups. Updating the weights is performed using the following stochastic
descent algorithm for each group,

!!J:

8e a

t:. V = -a3 8V

+ a4 ea R ,

where R is a noise matrix whose elements are characterized by independent zero-mean unityvariance Gaussian densities, and the a's are parameters. The purpose of adding noise is to
allow escaping local minima if one gets stuck in any of them. Note that the control parameter
is taken to be ea. Hence the variance of the added noise tends to decrease the more we
approach the ideal zero-error solution. This makes sense because for a large error, i.e. for an
unsatisfactory solution, it pays more to add noise to the weight matrices in order to escape
local minima. On the other hand, if the error is small, then we are possibly near the global
minimum or to an acceptable solution, and hence we do not want too much noise in order
not to be thrown out of that basin. Note that once we reach the ideal zero-error solution the
added noise as well as the gradient of ea become zero for all a and hence the increments of the
weight matrices become zero. If after a certain iteration W happens to violate the constraint
Liiwlj ~ constant < I/max(J')2, then its elements are scaled so as to project it back onto
the surface of the hypershere.

Implementation Example
A pattern recognition example is considered. Fig. 3 shows a set of two-dimensional
training patterns from three classes. It is required to design a neural network recognizer with

28

three output neurons. Each of the neurons should be on if a sample of the corresponding class is
presented, and off otherwise, i.e. we would like to design a ""winner-take-all"" network. A singlelayer three neuron feedback network is implemented. We obtained 3.3% error. Performing the
same experiment on a feedforward single-layer network with three neurons, we obtained 20%
error. For satisfactory results, a feedforward network should be two-layer. With one neuron
in the first layer and three in the second layer, we got 36.7% error. Finally, with two neurons
in the first layer and three in the second layer, we got a match with the feedback case, with
3.3% error .

z
z z
z

z

z

z

z
z

z
z

z

z

z z
z

zil

1
33

3
3
3

1

3
3

33
3
3

3

~

3

3
3

3

3

3

Fig. 3
A pattern recognition example

Conclusion

A way to extend the backpropagation method to feedback networks has been proposed .
A condition on the weight matrix is obtained, to insure having only one fixed point, so as
to prevent having more than one possible output for a fixed input. A general structure for
networks is presented, in which the network consists of a number of feedback groups connected
to each other in a feedforward manner. A stochastic descent rule is used to update the weights.
The lJ!ethod is applied to a pattern recognition example. With a single-layer feedback network
it obtained good results. On the other hand, the feedforward backpropagation method achieved
good resuls only for the case of more than one layer, hence also with a larger number of neurons
than the feedback case.

29
Acknow ledgement
The author would like to gratefully acknowledge Dr . Y. Abu-Mostafa for the useful
discussions. This work is supported by Air Force Office of Scientific Research under Grant
AFOSR-86-0296.

Appendix
Differentiating (5), one obtains

aI

- Yj
a
I
=
w kp

aI

k,p = 1, ... ,n,

I
Ym
p jk ,
f '(')(,,"",
Zj L..,Wjm-a
I
+Y'6)

w kp

m

where
if j = k
otherwise,

and

We can write

a~'

=

(A' _ Wi) -lbkz>

(A - 1)

aw kp

where b kp is the nt-dimensional vector whose

b~l> = {y~
?

0

ith

component is given by

ifi = k
otherwise.

By the chain rule,
aea _ """"' ae a ay;
-a
I
-L..,-aI - a
I'
w kp
j
Yj w kp

which, upon substituting from (A - 1), can be put in the form y!,gk~' where gk is the
column of (A' - Wt)-l. Finally, we obtain the required expression, which is
ae"" = [At _ (WI)T]

aw'

-1

ae"" ( ,)T

ayl

y

.

Regarding a()~~I' it is obtained by differentiating (5) with respect to vr~,. We get similarly

where

C kl'

is the nt-dimensional vector whose ith component is given by

if i = k
otherwise.

kth

30

A derivation very similar to the case of :~l results in the following required expression:
Be a =
BVrl
8

8

[A' _ (w,)T] -1 Be a ( r)T.
By' y

8yJ

j

Now, finally consider ~. Let ~, jf.B, be the matrix whose (k,p)th element is ~. The
elements
of ~
can be obtained by differentiating the equation for the fixed point for group
.
uy
J, as follows,

Hence,

:~~.

=

(Ai - Wi) -IV'i.

(A - 2)

Using the chain rule, one can write
Be a

By'

?T

= ~(ByJ)
~ Byl

JEEr

Be a
By;'

We substitute from (A - 2) into the previous equation to complete the derivation by obtaining

References
111 P. Werbos, ""Beyond regression: New tools for prediction and analysis in behavioral sciences"", Harvard University dissertation, 1974.
[21 D. Parker, ""Learning logic"", MIT Tech Report TR-47, Center for Computational Research
in Economics and Management Science, 1985.
[31 Y. Le Cun, ""A learning scheme for asymmetric threshold network"", Proceedings of Cognitiva, Paris, June 1985.
[41 D. Rumelhart, G.Hinton, and R. Williams, ""Learning internal representations by error
propagation"", in D. Rumelhart, J. McLelland and the PDP research group (Eds.), Parallel
distributed processing: Explorations in the microstructure of cognition, Vol. 1, MIT Press,
Cambridge, MA, 1986.
151 J. Hopfield, ""Neurons with graded response have collective computational properties like
those of two-state neurons"", Proc. N atl. Acad. Sci. USA, May 1984.
[61 L. Ahneida, "" A learning rule for asynchronous perceptrons with feedback in a combinatorial environment"", Proc. of the First Int. Annual Conf. on Neural Networks, San Diego,
June 1987.
[71 R. Rohwer, and B. Forrest, ""Training time-dependence in neural networks"", Proc. of the
First Int. Annual Conf. on Neural Networks, San Diego, June 1987.
[81 F. Pineda, ""Generalization of back-propagation to recurrent neural networks"", Phys. Rev.
Lett., vol. 59, no. 19, 9 Nov. 1987.

"
10,1987,"A Mean Field Theory of Layer IV of Visual Cortex and Its Application to Artificial Neural Networks","",10-a-mean-field-theory-of-layer-iv-of-visual-cortex-and-its-application-to-artificial-neural-networks.pdf,"Abstract Missing","683

A MEAN FIELD THEORY OF LAYER IV OF VISUAL CORTEX
AND ITS APPLICATION TO ARTIFICIAL NEURAL NETWORKS*
Christopher L. Scofield
Center for Neural Science and Physics Department
Brown University
Providence, Rhode Island 02912
and
Nestor, Inc., 1 Richmond Square, Providence, Rhode Island,
02906.
ABSTRACT
A single cell theory for the development of selectivity and
ocular dominance in visual cortex has been presented previously
by Bienenstock, Cooper and Munrol. This has been extended to a
network applicable to layer IV of visual cortex 2 . In this paper
we present a mean field approximation that captures in a fairly
transparent manner the qualitative, and many of the
quantitative, results of the network theory. Finally, we consider
the application of this theory to artificial neural networks and
show that a significant reduction in architectural complexity is
possible.
A SINGLE LAYER NETWORK AND THE MEAN FIELD
APPROXIMATION
We consider a single layer network of ideal neurons which
receive signals from outside of the layer and from cells within
the layer (Figure 1). The activity of the ith cell in the network is
c'1 -- m'1 d + """"'
~ T .. c'
~J J'

J

(1)

Each cell
d is a vector of afferent signals to the network.
receives input from n fibers outside of the cortical network
through the matrix of synapses mi' Intra-layer input to each cell
is then transmitted through the matrix of cortico-cortical
synapses L.
? American Institute of Physics 1988

684

Afferent
Signals

>

... ..

m2

m1

mn

~

r;.

"",...-

d

.L
:

1

,~

2

... ..

, ...c.. ,

~

~

Figure 1: The general single layer recurrent
network.
Light circles are the LGN -cortical
synapses.
Dark circles are the (nonmodifiable) cortico-cortical synapses.
We now expand the response of the i th cell into individual
terms describing the number of cortical synapses traversed by
the signal d before arriving through synapses Lij at cell i.
Expanding Cj in (1), the response of cell i becomes
ci

=mi d + l: ~j mj d + l: ~jL Ljk mk d + 2: ~j 2Ljk L Lkn mn d +... (2)
J

J

K

J

K' n

Note that each term contains a factor of the form

This factor describes the first order effect, on cell q, of the
cortical transformation of the signal d.
The mean field
approximation consists of estimating this factor to be a constant,
independant of cell location
(3)

685

This assumption does not imply that each cell in the network is
selective to the same pattern, (and thus that mi = mj). Rather,
the assumption is that the vector sum is a constant

This amounts to assuming that each cell in the network is
surrounded by a population of cells which represent, on average,
all possible pattern preferences.
Thus the vector sum of the
afferent synaptic states describing these pattern preferences is a
constant independent of location.
Finally, if we assume that the lateral connection strengths are
a function only of i-j then Lij becomes a circular matrix so that

r. Lij ::: ~J Lji = Lo = constan t.
1

Then the response of the cell i becomes
(4)

for I

~

I <1

where we define the spatial average of cortical cell activity C = in
d, and N is the average number of intracortical synapses.
Here, in a manner similar to that in the theory of magnetism,
we have replaced the effect of individual cortical cells by their
average effect (as though all other cortical cells can be replaced
by an 'effective' cell, figure 2). Note that we have retained all
orders of synaptic traversal of the signal d.
Thus, we now focus on the activity of the layer after
'relaxation' to equilibrium. In the mean field approximation we
can therefore write
(5)

where the mean field

a
with

=am

686

and we asume that
inhibitory).

Afferent
Signals
d

Lo < 0 (the network is,

on

average,

>

Figure 2: The single layer mean field network.
Detailed connectivity between all cells of the
network is replaced with a single (nonmodifiable) synapse from an 'effective' cell.
LEARNING IN THE CORTICAL NETWORK

We will first consider evolution of the network according to a
synaptic modification rule that has been studied in detail, for
single cells, elsewhere!? 3.
We consider the LGN - cortical
synapses to be the site of plasticity and assume for maximum
simplicity that there is no modification of cortico-cortical
synapses. Then
(6)

.

Lij = O.
In what follows c denotes the spatial average over cortical cells,
while Cj denotes the time averaged activity of the i th cortical cell.
The function cj> has been discussed extensively elsewhere.
Here
we note that cj> describes a function of the cell response that has
both hebbian and anti-hebbian regions.

687

This leads to a very complex set of non-linear stochastic
equations that have been analyzed partially elsewhere 2 . In
general, the afferent synaptic state has fixed points that are
stable and selective and unstable fixed points that are nonselective!, 2. These arguments may now be generalized for the
network. In the mean field approximation
(7)

The mean field, a has a time dependent component m. This
varies as the average over all of the network modifiable
synapses and, in most environmental situations, should change
slowly compared to the change of the modifiable synapses to a
single cell. Then in this approximation we can write

?

(mi(a)-a) = cj>[mi(a) - a] d.

(8)

We see that there is a mapping
mi' <-> mica) - a

(9)

such that for every mj(a) there exists a corresponding (mapped)
point mj' which satisfies

the original equation for the mean field zero theory. It can be
shown 2, 4 that for every fixed point of mj( a = 0), there exists a
corresponding fixed point mj( a) with the same selectivity and
stability properties.
The fixed points are available to the
neurons if there is sufficient inhibition in the network (ILo I is
sufficiently large).
APPLICATION OF THE MEAN FIELD NETWORK TO
LAYER IV OF VISUAL CORTEX
Neurons in the primary visual cortex of normal adult cats are
sharply tuned for the orientation of an elongated slit of light and
most are activated by stimulation of either eye. Both of these
properties--orientation selectivity and binocularity--depend on
the type of visual environment experienced during a critical

688

period of early postnatal development. For example, deprivation
of patterned input during this critical period leads to loss of
orientation selectivity while monocular deprivation (MD) results
in a dramatic shift in the ocular dominance of cortical neurons
such that most will be responsive exclusively to the open eye.
The ocular dominance shift after MD is the best known and most
intensively studied type of visual cortical plasticity.
The behavior of visual cortical cells in various rearing
conditions suggests that some cells respond more rapidly to
environmental changes than others.
In monocular deprivation,
for example, some cells remain responsive to the closed eye in
spite of the very large shift of most cells to the open eye- Singer
et. al. 5 found, using intracellular recording, that geniculo-cortical
synapses on inhibitory interneurons are more resistant to
monocular deprivation than are synapses on pyramidal cell
dendrites. Recent work suggests that the density of inhibitory
GABAergic synapses in kitten striate cortex is also unaffected by
MD during the cortical period 6, 7.
These results suggest that some LGN -cortical synapses modify
rapidly, while others modify relatively slowly, with slow
modification of some cortico-cortical synapses. Excitatory LGNcortical synapses into excitatory cells may be those that modify
primarily.
To embody these facts we introduce two types of
LGN -cortical synapses:
those (mj) that modify and those (Zk)
that remain relatively constant. In a simple limit we have

and

(10)

We assume for simplicity and consistent with the above
physiological interpretation that these two types of synapses are
confined to two different classes of cells and that both left and
right eye have similar synapses (both m i or both Zk) on a given
cell. Then, for binocular cells, in the mean field approximation
(where binocular terms are in italics)

689

where dl(r) are the explicit left (right) eye time averaged signals
arriving form the LGN.
Note that a1(r) contain terms from
modifiable and non-modifiable synapses:
al(r) =

a (ml(r) + zl(r?).

Under conditions of monocular deprivation, the animal is reared
with one eye closed. For the sake of analysis assume that the
right eye is closed and that only noise-like signals arrive at
cortex from the right eye. Then the environment of the cortical
cells is:
d = (di, n)

(12)

Further, assume that the left eye synapses have reached their
1

r

selective fixed point, selective to pattern d 1 ? Then (mi' m i )
(m:*, xi) with IXil ?lm!*1.
linear analysis of the
the closed eye

<I> -

=

Following the methods of BCM, a local
function is employed to show that for

Xi =

a (1 - }..a)-li.r.

(13)

where A. = NmIN is the ratio of the number modifiable cells to the
total number of cells in the network. That is, the asymptotic
state of the closed eye synapses is a scaled function of the meanfield due to non-modifiable (inhibitory) cortical cells. The scale
of this state is set not only by the proportion of non-modifiable
cells, but in addition, by the averaged intracortical synaptic
strength Lo.
Thus contrasted with the mean field zero theory the deprived
eye LGN-cortical synapses do not go to zero.
Rather they
approach the constant value dependent on the average inhibition
produced by the non-modifiable cells in such a way that the
asymptotic output of the cortical cell is zero (it cannot be driven
by the deprived eye). However lessening the effect of inhibitory
synapses (e.g. by application of an inhibitory blocking agent such
as bicuculine) reduces the magnitude of a so that one could once
more obtain a response from the deprived eye.

690

We find, consistent with previous theory and experiment,
that most learning can occur in the LGN-cortical synapse, for
inhibitory (cortico-cortical) synapses need not modify.
Some
non-modifiable LGN-cortical synapses are required.
THE MEAN FIELD APPROXIMATION AND
ARTIFICIAL NEURAL NETWORKS
The mean field approximation may be applied to networks in
which the cortico-cortical feedback is a general function of cell
activity. In particular, the feedback may measure the difference
between the network activity and memories of network activity.
In this way, a network may be used as a content addressable
memory.
We have been discussing the properties of a mean
field network after equilibrium has been reached. We now focus
on the detailed time dependence of the relaxation of the cell
activity to a state of equilibrium.
Hopfield8 introduced a simple formalism for the analysis of
the time dependence of network activity.
In this model,
network activity is mapped onto a physical system in which the
state of neuron activity is considered as a 'particle' on a potential
energy surface.
Identification of the pattern occurs when the
activity 'relaxes' to a nearby minima of the energy.
Thus
mlmma are employed as the sites of memories. For a Hopfield
network of N neurons, the intra-layer connectivity required is of
order N2. This connectivity is a significant constraint on the
practical implementation of such systems for large scale
problems. Further, the Hopfield model allows a storage capacity
which is limited to m < N memories 8, 9. This is a result of the
proliferation of unwanted local minima in the 'energy' surface.
Recently, Bachmann et al. l 0, have proposed a model for the
relaxation of network activity in which memories of activity
patterns are the sites of negative 'charges', and the activity
caused by a test pattern is a positive test 'charge'. Then in this
model, the energy function is the electrostatic energy of the
(unit) test charge with the collection of charges at the memory
sites

E = -IlL ~ Qj I J-l- Xj I - L,
J

(14)

691

where Jl (0) is a vector describing the initial network activity
caused by a test pattern, and Xj' the site of the jth memory. L is
a parameter related to the network size.
This model has the advantage that storage density is not
restricted by the the network size as it is in the Hopfield model,
and in addition, the architecture employs a connectivity of order
m x N.
Note that at each stage in the settling of Jl (t) to a memory
(of network activity) Xj' the only feedback from the network to
each cell is the scalar
~

J

Q. I Jl- X? I - L
J

J

(15)

This quantity is an integrated measure of the distance of the
current network state from stored memories.
Importantly, this
measure is the same for all cells; it is as if a single virtual cell
was computing the distance in activity space between the
current state and stored states. The result of the computation is
This is a
then broadcast to all of the cells in the network.
generalization of the idea that the detailed activity of each cell in
the network need not be fed back to each cell.
Rather some
global measure, performed by a single 'effective' cell is all that is
sufficient in the feedback.
DISCUSSION

We have been discussing a formalism for the analysis of
networks of ideal neurons based on a mean field approximation
of the detailed activity of the cells in the network. We find that
a simple assumption concerning the spatial distribution of the
pattern preferences of the cells allows a great simplification of
the analysis. In particular, the detailed activity of the cells of
the network may be replaced with a mean field that in effect is
computed by a single 'effective' cell.
Further, the application of this formalism to the cortical layer
IV of visual cortex allows the prediction that much of learning in
cortex may be localized to the LGN-cortical synaptic states, and
that cortico-cortical plasticity is relatively unimportant. We find,
in agreement with experiment, that monocular deprivation of
the cortical cells will drive closed-eye responses to zero, but
chemical blockage of the cortical inhibitory pathways would
reveal non-zero closed-eye synaptic states.

692

Finally, the mean field approximation allows the development
of single layer models of memory storage that are unrestricted
in storage density, but require a connectivity of order mxN. This
is significant for the fabrication of practical content addressable
memories.
ACKNOWLEOOEMENTS
I would like to thank Leon Cooper for many helpful discussions
and the contributions he made to this work.

*This work was supported by the Office of Naval Research and
the Army Research Office under contracts #NOOOI4-86-K-0041
and #DAAG-29-84-K-0202.

REFERENCES
[1] Bienenstock, E. L., Cooper, L. N & Munro, P. W. (1982) 1.
Neuroscience 2, 32-48.
[2] Scofield, C. L. (I984) Unpublished Dissertation.
[3] Cooper, L. N, Munro, P. W. & Scofield, C. L. (1985) in Synaptic
Modification, Neuron Selectivity and Nervous System
Organization, ed. C. Levy, J. A. Anderson & S. Lehmkuhle,
(Erlbaum Assoc., N. J.).
[4] Cooper, L. N & Scofield, C. L. (to be published) Proc. Natl. Acad.
Sci. USA ..
[5] Singer, W. (1977) Brain Res. 134, 508-000.
[6] Bear, M. F., Schmechel D. M., & Ebner, F. F. (1985) 1. Neurosci.
5, 1262-0000.
[7] Mower, G. D., White, W. F., & Rustad, R. (1986) Brain Res. 380,
253-000.
[8] Hopfield, J. J. (1982) Proc. Natl. A cad. Sci. USA 79, 2554-2558.
[9] Hopfield, J. J., Feinstein, D. 1., & Palmer, R. O. (1983) Nature
304, 158-159.
[10] Bachmann, C. M., Cooper, L. N, Dembo, A. & Zeitouni, O. (to be
published) Proc. Natl. Acad. Sci. USA.

"
11,1987,"Microelectronic Implementations of Connectionist Neural Networks","",11-microelectronic-implementations-of-connectionist-neural-networks.pdf,"Abstract Missing","515

MICROELECTRONIC IMPLEMENTATIONS OF CONNECTIONIST
NEURAL NETWORKS
Stuart Mackie, Hans P. Graf, Daniel B. Schwartz, and John S. Denker
AT&T Bell Labs, Holmdel, NJ 07733

Abstract
In this paper we discuss why special purpose chips are needed for useful
implementations of connectionist neural networks in such applications as pattern
recognition and classification. Three chip designs are described: a hybrid
digital/analog programmable connection matrix, an analog connection matrix with
adjustable connection strengths, and a digital pipe lined best-match chip. The common
feature of the designs is the distribution of arithmetic processing power amongst the
data storage to minimize data movement.

RAMs
?????/..... Distributed
/ '. '. co mputati on
chips

... 0

/ ......

Q)Q)

,c""C

E~

''iiit:::::::;:::::,

::::S,....

ZO

???

..

Conventional
CPUs
??

??..

1
1

10 3
10 6
10 9
Node Complexity
(No. of Transistors)

Figure 1. A schematic graph of addressable node complexity and size for conventional
computer chips. Memories can contain millions of very simple nodes each
with a very few transistors but with no processing power. CPU chips are
essentially one very complex node. Neural network chips are in the
distributed computation region where chips contain many simple fixed
instruction processors local to data storage. (After Reece and Treleaven 1 )
? American Institute of Physics 1988

516

Introduction
It is clear that conventional computers lag far behind organic computers when it
comes to dealing with very large data rates in problems such as computer vision and
speech recognition. Why is this? The reason is that the brain performs a huge number
of operations in parallel whereas in a conventional computer there is a very fast
processor that can perform a variety of instructions very quickly, but operates on only
two pieces of data at a time.
The rest of the many megabytes of RAM is idle during any instruction cycle. The
duty cycle of the processor is close to 100%, but that of the stored data is very close to
zero. If we wish to make better use of the data, we have to distribute processing
power amongst the stored data, in a similar fashion to the brain. Figure 1 illustrates
where distributed computation chips lie in comparison to conventional computer chips
as regard number and complexity of addressable nodes per chip.
In order for a distributed strategy to work, each processing element must be small
in order to accommodate many on a chip, and communication must be local and hardwired. Whereas the processing element in a conventional computer may be able to
execute many hundred different operations, in our scheme the processor is hard-wired
to perform just one. This operation should be tailored to some particular application.
In neural network and pattern recognition algorithms, the dot products of an input
vector with a series of stored vectors (referred to as features or memories) is often
required. The general calculation is:

Sum of Products

v . F(i) = L. v.J f..IJ
J

where V is the input vector and F(i) is one of the stored feature vectors. Two
variations of this are of particular interest. In feature extraction, we wish to find all the
features for which the dot product with the input vector is greater than some threshold
T, in which case we say that such features are present in the input vector.

Feature Extraction

v . F(i) =

L. v.J f..IJ
J

In pattern classification we wish to find the stored vector that has the largest dot
product with the input vector, and we say that the the input is a member of the class
represented by that feature, or simply that that stored vector is closest to input vector.

Classification

max(V. F(i) =

LV.
f..
. J IJ
J

The chips described here are each designed to perform one or more of the above
functions with an input vector and a number of feature vectors in parallel. The overall
strategy may be summed up as follows: we recognize that in typical pattern recognition
applications, the feature vectors need to be changed infrequently compared to the input

517

vectors, and the calculation that is perfonned is fixed and low-precision, we therefore
distribute simple fixed-instruction processors throughout the data storage area, thus
minimizing the data movement and optimizing the use of silicon. Our ideal is to have
every transistor on the chip doing something useful during every instruction cycle.

Analog Sum-or-Products
U sing an idea slightly reminiscent of synapses and neurons from the brain, in two
of the chips we store elements of features as connections from input wires on which the
elements of the input vectors appear as voltages to summing wires where a sum-ofproducts is perfonned. The voltage resulting from the current summing is applied to
the input of an amplifier whose output is then read to determine the result of the
calculation. A schematic arrangement is shown in Figure 2 with the vertical inputs
connected to the horizontal summing wires through resistors chosen such that the
conductance is proportional to the magnitude of the feature element. When both
positive and negative values are required, inverted input lines are also necessary.
Resistor matrices have been fabricated using amorphous silicon connections and metal
linewidths. These were programmed during fabrication by electron beam lithography
to store names using the distributed feedback method described by Hopfield2 ,3. This
work is described more fully elsewhere. 4 ,5 Hard-wired resistor matrices are very
compact, but also very inflexible. In many applications it is desirable to be able to
reprogram the matrix without having to fabricate a new chip. For this reason, a series
of programmable chips has been designed.
Input lines
Feature 4

-t-----tI----4t---t---f--.---1

Feature 3 -+--4II--I--'--+---+--4~

oc:

--

""'C

c:

Feature 2 ~--+-""""'-+--4---1~--I

( I)

Feature 1

Figure 2. A schematic arrangement for calculating parallel sum-of-products with a
resistor matrix. Features are stored as connections along summing wires and
the input elements are applied as voltages on the input wires. The voltage
generated by the current summing is thresholded by the amplifer whose
output is read out at the end of the calculation. Feedback connections may be

518

made to give mutual inhibition and allow only one feature amplifier to tum
on, or allow the matrix to be used as a distributed feedback memory.

Programmable Connection Matrix
Figure 3 is a schematic diagram of a programmable connection using the contents of
two RAM cells to control current sinking or sourcing into the summing wire. The
switches are pass transistors and the 'resistors' are transistors with gates connected to
their drains. Current is sourced or sunk if the appropriate RAM cell contains a '1' and
the input Vi is high thus closing both switches in the path. Feature elements can
therefore take on values (a,O,-b) where the values of a and b are determined by the
conductivities of the n- and p-transistors obtained during processing. A matrix with
2916 such connections allowing full interconnection of the inputs and outputs of 54
amplifiers was designed and fabricated in 2.5Jlm CMOS (Figure 4). Each connection
is about 100x100Jlm, the chip is 7x7mm and contains about 75,000 transistors. When
loaded with 49 49-bit features (7x7 kernel), and presented with a 49-bit input vector,
the chip performs 49 dot products in parallel in under 1Jls. This is equivalent to 2.4
billion bit operations/sec. The flexibility of the design allows the chip to be operated in
several modes. The chip was programmed as a distributed feedback memory
(associative memory), but this did not work well because the current sinking capability
of the n-type transistors was 6 times that of the p-types. An associative memory was
implemented by using a 'grandmother cell' representation, where the memories were
stored along the input lines of amplifiers, as for feature extraction, but mutually
inhibitory connections were also made that allowed only one output to tum on. With
10 stored vectors each 40 bits long, the best match was found in 50-600ns, depending
on the data. The circuit can also be programmed to recognize sequences of vectors and
to do error correction when vectors were omitted or wrong vectors were inserted into
the sequences. The details of operation of the chip are described more fully
elsewhere 6 . This chip has been interfaced to a UNIX minicomputer and is in everyday
use as an accelerator for feature extraction in optical character recognition of handwritten numerals. The chip speeds up this time consuming calculation by a factor of
more than 1000. The use of the chip enables experiments to be done which would be
too time consuming to simulate.
Experience with this device has led to the design of four new chips, which are
currently being tested. These have no feedback capability and are intended exclusively
for feature extraction. The designs each incorporate new features which are being
tested separately, but all are based on a connection matrix which stores 46 vectors each
96 bits long. The chip will perform a full parallel calculation in lOOns.

519

VDD

~,
Output(!)

<:]

Vj

~

Excitatory

Inhibitory
V?

J

Ivss
Figure 3. Schematic diagram of a programmable connection. A current sourcing or
sinking connection is made if a RAM cell contains a '1' and the input Vi is
high. The currents are summed on the input wire of the amplifier.

?1 Pads ?

Row Decoders
r:--3 Connections
ITII1 Amplifie rs

Figure 4. Programmable connection matrix chip. The chip contains 75,000 transistors
in 7x7mm, and was fabricated using 2.5Jlm design rules.

520

Adaptive Connection Matrix
Many problems require analog depth in the connection strengths, and this is
especially important if the chip is to be used for learning, where small adjustments are
required during training. Typical approaches which use transistors sized in powers of
two to give conductance variability take up an area equivalent to the same number of
minimum sized transistors as the dynamic range, which is expensive in area and
enables only a few connections to be put on a chip. We have designed a fully analog
connection based on a DRAM structure that can be fabricated using conventional
CMOS technology. A schematic of a connection and a connection matrix is shown in
Figure 5. The connection strength is represented by the difference in voltages stored
on two MOS capacitors. The capacitors are 33Jlm on edge and lose about 1% of their
charge in five minutes at room temperature. The leakage rate can be reduced by three
orders of magnitude by cooling the the capacitors to -50?C and by five orders of
magnitude by cooling to -100?C. The output is a current proportional to the product of
the input voltage and the connection strength. The output currents are summed on a
wire and are sent off chip to external amplifiers. The connection strengths can be
adjusted using transferring charge between the capacitors through a chain of transistors.
The connections strengths may be of either polarity and it is expected that the
connections will have about 7 bits of analog depth. A chip has been designed in
1.25Jlm CMOS containing 1104 connections in an array with 46 inputs and 24 outputs.

Input

Weight update and decay
by shifting charge

.1

..L

1..

'-1'--,

02

:or:

.4111.

..

'""

,

...

1""

'r""

...-

........
....
...
........
...
........
......
......

...

Input

w (l (01-02)
Output=w*lnput

!
....
...-

Output through external amplifiers

Figure 5. Analog connection. The connection strength is represented by the difference
in voltages stored on two capacitors. The output is a current proprtional to
the product of the input voltage and the connection strength.
Each connection is 70x240Jlm. The design has been sent to foundry, and testing is
expected to start in April 1988. The chip has been designed to perform a network
calculation in <30ns, i.e., the chip will perform at a rate of 33 billion multiplies/sec. It
can be used simply as a fast analog convolver for feature extraction, or as a learning

521

engine in a gradient descent algorithm using external logic for connection strength
adjustment. Because the inputs and outputs are true analog, larger networks may be
formed by tiling chips, and layered networks may be made by cascading through
amplifiers acting as hidden units.

Digital Classifier Chip
The third design is a digital implementation of a classifier whose architecture is not
a connectionist matrix. It is nearing completion of the design stage, and will be
fabricated using 1.25Jlm CMOS. It calculates the largest five V?P(i) using an alldigital pipeline of identical processors, each attached to one stored word. Each
processor is also internally pipelined to the extent that no stage contains more than two
gate delays. This is important, since the throughput of the processor is limited by the
speed of the slowest stage. Each processor calculates the Hamming distance (number
of difference bits) between an input word and its stored word, and then compares that
distance with each of the smallest 5 values previously found for that input word. An
updated list of 5 best matches is then passed to the next processor in the pipeline. At
the end of the pipeline the best 5 matches overall are output.

(1 ) Features stored in

Data
pipeline

ring shift register

:{ it

~

~

Best match list
pipeline
Tag register

+

~ ~

it {{ : : : Ii :::::;::::::.
f:: Jr }/ :{ it :r : : :: :mIfl
::t:t if::::: t::}; {}} [,
:i::

II:: ::::::::I; : I::::::I::;:: : : {::::::I:
; ;: : :I[HI tm.

: ~L!.~\.._-...-t!~[1

/ Pf --

(2) Input and feature
(3) Accumulator
are compared
dumps
distance
bit-serially
into comparison
register at end
of input word

Pig. 6

,

(4) Comparator inserts
new match and tag into
list when better than
old match

Schematic of one of the 50 processors in the digital classifier chip. The
Hamming distance of the input vector to the feature vector is calculated, and
if better than one of the five best matches found so far, is inserted into the
match list together with the tag and passed onto the next processor. At the
end of the pipeline the best five matches overall are output

522

The data paths on chip are one bit wide and all calculations are bit serial. This
means that the processing elements and the data paths are compact and maximizes the
number of stored words per chip. The layout of a single processor is shown in
Fig. 6. The features are stored as 128-bit words in 8 16-bit ring shift registers and
associated with each feature is a 14-bit tag or name string that is stored in a static
register. The input vector passes through the chip and is compared bit-by-bit to each
stored vector, whose shift registers are cycled in tum. The total number of bits
difference is summed in an accumulator. After a vector has passed through a processor,
the total Hamming distance is loaded into the comparison register together with the tag.
At this time, the match list for the input vector arrives at the comparator. It is an
ordered list of the 5 lowest Hamming distances found in the pipeline so far, together
with associated tag strings. The distance just calculated is compared bit-serially with
each of the values in the list in turn. If the current distance is smaller than one of the
ones in the list, the output streams of the comparator are switched, having the effect of
inserting the current match and tag into the list and deleting the previous fifth best
match. After the last processor in the pipeline, the list stream contains the best five
distances overall, together with the tags of the stored vectors that generated them. The
data stream and the list stream are loaded into 16-bit wide registers ready for output.
The design enables chips to be connected together to extend the pipeline if more than 50
stored vectors are required. The throughput is constant, irrespective of the number of
chips connected together; only the latency increases as the number of chips increases.
The chip has been designed to operate with an on-chip clock frequency of at least
l00MHz. This high speed is possible because stage sizes are very small and data paths
have been kept short. The computational efficiency is not as high as in the analog chips
because each processor only deals with one bit of stored data at a time. However, the
overall throughput is high because of the high clock speed. Assuming a clock
frequency of l00MHz, the chip will produce a list of 5 best distances with tag strings
every 1.3Jls, with a latency of about 2.5Jls. Even if a thousand chips containing
50,000 stored vectors were pipelined together, the latency would be 2.5ms, low
enough for most real time applications. The chip is expected to perform 5 billion bit
operation/sec.
While it is important to have high clock frequencies on the chip, it is also important
to have them much lower off the chip, since frequencies above 50MHz are hard to deal
on circuit boards. The 16-bit wide communication paths onto and off the chip ensure
that this is not a problem here.

Conclusion
The two approaches discussed here, analog and digital, represent opposites in
computational approach. In one, a single global computation is performed for each
match, in the other many local calculations are done. Both the approaches have their
advantages and it remains to be seen which type of circuit will be more efficient in
applications, and how closely an electronic implementation of a neural network should
resemble the highly interconnected nature of a biolOgical network.
These designs represent some of the first distributed computation chips. They are
characterized by having simple processors distributed amongst data storage. The
operation performed by the processor is tailored to the application. It is interesting to
note some of the reasons why these designs can now be made: minimum linewidths on

523

circuits are now small enough that enough processors can be put on one chip to make
these designs of a useful size, sophisticated design tools are now available that enable a
single person to design and simulate a complete circuit in a matter of months, and
fabrication costs are low enough that highly speculative circuits can be made without
requiring future volume production to offset prototype costs.
We expect a flurry of similar designs in the coming years, with circuits becoming
more and more optimized for particular applications. However, it should be noted that
the impressive speed gain achieved by putting an algorithm into custom silicon can only
be done once. Further gains in speed will be closely tied to mainstream technological
advances in such areas as transistor size reduction and wafer-scale integration. It
remains to be seen what influence these kinds of custom circuits will have in useful
technology since at present their functions cannot even be simulated in reasonable time.
What can be achieved with these circuits is very limited when compared with a three
dimensional, highly complex biological system, but is a vast improvement over
conventional computer architectures.
The authors gratefully acknowledge the contributions made by L.D. Jackel, and
R.E. Howard

References

1

M. Reece and P.C. Treleaven, ""Parallel Architectures for Neural Computers"", Neural
Computers, R. Eckmiller and C. v.d. Malsburg, eds (Springer-Verlag, Heidelberg,
1988)

2

J.I. Hopfield, Proc. Nat. Acad. Sci. 79.2554 (1982).

3

J.S. Denker, Physica 22D, 216 (1986).

4

R.E. Howard, D.B. Schwartz, J.S. Denker, R.W. Epworth, H.P. Graf, W .E.
Hubbard, L.D. Jackel, B.L. Straughn, and D.M. Tennant, IEEE Trans. Electron
Devices ED-34, 1553, (1987)

5

H.P. Oraf and P. deVegvar, ""A CMOS Implementation of a Neural Network
Model"", in ""Advanced Research in VLSI"", Proceedings of the 1987 Stanford
Conference, P. Losleben (ed.), (MIT Press 1987).

6

H.P. Oraf and P. deVegvar, ""A CMOS Associative Memory Chip Based on Neural
Networks"", Tech. Digest, 1987 IEEE International Solid-State Circuits Conference.

"
12,1987,"Using Neural Networks to Improve Cochlear Implant Speech Perception","",12-using-neural-networks-to-improve-cochlear-implant-speech-perception.pdf,"Abstract Missing","783

USING NEURAL NETWORKS TO IMPROVE
COCHLEAR IMPLANT SPEECH PERCEPTION
Manoel F. Tenorio
School of Electrical Engineering
Purdue University
West Lafayette, IN 47907

ABSTRACT

-

An increasing number of profoundly deaf patients suffering from sensorineural deafness are using cochlear implants as prostheses. Mter the
implant, sound can be detected through the electrical stimulation of the
remaining peripheral auditory nervous system. Although great progress has
been achieved in this area, no useful speech recognition has been attained
with either single or multiple channel cochlear implants.
Coding evidence suggests that it is necessary for any implant which
would effectively couple with the natural speech perception system to simulate the temporal dispersion and other phenomena found in the natural
receptors, and currently not implemented in any cochlear implants. To this
end, it is presented here a computational model using artificial neural networks (ANN) to incorporate the natural phenomena in the artificial
cochlear.
The ANN model presents a series of advantages to the implementation
of such systems. First, the hardware requirements, with constraints on
power, size, and processing speeds, can be taken into account together with
the development of the underlining software, before the actual neural structures are totally defined. Second, the ANN model, since it is an abstraction
of natural neurons, carries the necessary ingredients and is a close mapping
for implementing the necessary functions. Third, some of the processing,
like sorting and majority functions, could be implemented more efficiently,
requiring only local decisions. Fourth, the ANN model allows function
modifications through parametric modification (no software recoding), which
permits a variety of fine-tuning experiments, with the opinion of the
patients, to be conceived. Some of those will permit the user some freedom
in system modification at real-time, allowing finer and more subjective
adjustments to fit differences on the condition and operation of individual's
remaining peripheral auditory system.
1. INTRODUCTION

The study of the model of sensory receptors can be carried out either
via trying to understand how the natural receptors process incoming signals
and build a representation code, or via the construction of artificial replacements. In the second case, we are interested in to what extent those
artificial counterparts have the ability to replace the natural receptors.
Several groups are now carrying out the design of artificial sensors.
Artificial cochleas seem to have a number of different designs and a tradition
of experiments. These make them now available for widespread use as
prostheses for patients who have sensorineural deafness caused by hair cell
damage.
? American Institute of Physics 1988

784

Although surgery is required for such implants, their performance has
reached a level of maturity to induce patients to seek out these devices
voluntarily. Unfortunately, only partial acoustic information is obtained by
severely deaf patients with cochlear prosthesis. Useful patterns for speech
communication are not yet 'fully recognizable through auditory prostheses.
This problem with artificial receptors is true for both single implants, that
stimulate large sections of the cochlea with signals that cover a large portion
of the spectrum [4,5], and multi channel implants, that stimulate specific
regions of the cochlea with specific portions of the auditory spectrum [3,13].
In this paper, we tackle the problem of artificial cochlear implants
through the used of neurocomputing tools. The receptor model used here
was developed by Gerald Wasserman of the Sensory Coding Laboratory,
Department of Psychological Sciences, Purdue University [20], and the
implants were performed by Richard Miyamoto of the Department of Otolaryngology, Indiana University Medical School [11].
The idea is to introduce with the cochlear implant, the computation
that would be performed otherwise by the natural receptors. It would therefore be possible to experimentally manipulate the properties of the implant
and measure the effect of coding variations on behavior. The model was
constrained to be portable, simple to implant, fast enough computationally
for on-line use, and built with a flexible paradigm, which would allow for
modification of the different parts of the model, without having to reconstruct it entirely. In the next section, we review parts of the receptor model,
and discuss the block diagram of the implant. Section 3 covers the limitations associated with the technique, and discusses the r.e sults obtained with
a single neuron and one feedback loop. Section 4 discusses the implementations of these models using feedforward neural networks, and the computational advantages for doing so.

2. COCHLEAR IMPLANTS AND THE NEURON MODEL
Although patients cannot reliably recognize randomly chosen spoken
words to them (when implanted with either multichannel or single channel
devices), this is not to say that no information is extracted from speech. If
the vocabulary is reduced to a limited set of words, patients perform
significantly better than chance, at associating the word with a member of
the set.
For these types of experiments, single channel implants correspond to
reported performance of 14% to 20% better than chance, with 62% performance being the highest reported. For multiple channels, performances of
95% were reported. So far no one has investigated the differences in performance between the two types of implants. Since the two implants have so
many differences, it is difficult to point out the cause for the better performance in the multiple channel case.
The results of such experiments are encouraging, and point to the fact
that cochlea implants need only minor improvement to be able to mediate
ad-lib speech perception successfully. Sensory coding studies have suggested
a solution to the implant problem, by showing that the representation code
generated by the sensory system is task dependent. This evidence came
from comparison of intracellular recordings taken from a single receptor of
intact subjects.
This coding evidence suggests that the temporal dispersion (time
integration) found in natural receptors would be a necessary part of any

785

cochlear implant. Present cochlear implants have no dispersion at all. Figure 2 shows the block diagram for a representative cochlear implant, the
House-Urban stimulator. The acoustic signal is picked up by the microphone, which sends it to an AM oscillator. This modulation step is necessary to induce an electro-magnetic coupling between the external and internal coil. The internal coil has been surgically implanted, and it is connected
to a pair of wires implanted inside and outside the cochlea.
Just incorporating the temporal dispersion model to an existing device
would not replicate the fact that in natural receptors, temporal dispersion
appears in conjunction to other operations which are strongly non linear.
There are operations like selection of a portion of the spectrum, rectification,
compression, and time-dispersion to be considered.
In figure 3, a modified implant is shown, which takes into consideration
some of these operations. It is depicted as a single-channel implant,
although the ultimate goal is to make it multichannel. Details of the operation of this device can be found elsewhere [21]. Here, it is important to mention that the implant would also have a compression/rectification function,
and it would receive a feedback from the integrator stage in order to control
its gain.

3. CHARACTERISTICS AND RESULTS OF THE IMPLANTS
The above model has been implemented as an off-line process, and then
the patients were exposed to a preprocessed signal which emulated the
operation of the device. It is not easy to define the amount of feedback
needed in the system or the amount of time dispersion. It could also be that
these parameters are variable across different conditions. Another variance
in the experiment is the amount of damage (and type) among different individuals. So, these parameters have to be determined clinically.
The coupling between the artificial receptor and the natural system also
presents problems. If a physical connection is used, it increases the risk of
infections. When inductive methods are used, the coupling is never ideal. If
portability and limited power is of concern in the implementation, then the
limited energy available for coupling has to be used very effectively.
The computation of the receptor model has to be made in a way to
allow for fast implementation. The signal transformation is to be computed
on-line. Also, the results from clinical studies should be able to be incorpora ted fairly easily without having to reengineer the implant.
Now we present the results of the implementation of the transfer function of figure 4. Patients, drawn from a population described elsewhere
[11,12,14], were given spoken sentences processed off-line, and simultaneously
presented with a couple of words related to the context. Only one of them
was the correct answer. The patient had two buttons, one for each alternative; he/she was to press the button which corresponded to the correct alternative. The results are shown in the tables below.
Patient 1 (Average of the population)
Percentage of correct alternatives
Dispersion
No disp.
0.1 msec
0.3 msec

67%
78%
85%

Best performance

786

1 msec
3 msec

76%
72%

Table I: Phoneme discrimination in

d.

two-alternate task.

Patient 2
.
D ?lsperSlOn

No disp.
1.0 msec

Percentage of correct alternatives
50%
76%

Best performance

Table II: Sentence comprehension in a two-alternative task.
There were quite a lot of variations in the performance of the different
patients, some been able to perform better at different dispersion and
compression amounts than the average of the population. Since one cannot
control the amount of damage in the system of each patient or differences in
individuals, it is hard to predict the ideal values for a given patient.
Nevertheless, the improvements observed are of undeniable value in improving speech perception.

4. THE NEUROCOMPUTING MODEL
In studying the implementation of such a system for on-line use, yet
flexible enough to produce a carry-on device, we look at feedforward neurocomputer models as a possible answer. First, we wanted a model that easily
produced a parallel implementation, so that the model could be expanded in
a multichannel environment without compromising the speed of the system.
Figure 5 shows the initial idea for the implementation of the device as a Single Instruction Multiple Data (SIMD) architecture.
The implant would be similar to the one described in Figure 4, except
that the transfer function of the receptor would be performed by a two layer
feed forward network (Figure 6). Since there is no way of finding out the
values of compression and dispersion a part from clinical trials, or even if
these values do change in certain conditions, we need to create a structure
that is flexible enough to modify the program structure by simple manipulation of parameters. This is also the same problem we would face when trying to expand the system to a multichannel implant. Again, neuromorphic
models provided a nice paradigm in which the dataflow and the function of
the program could be altered by simple parameter (weight) change.
For this first implementation we chose to use the no-contact inductive
coupling method. The drawback of this method is that all the information
has to be compressed in a single channel for reliable transmission and cross
talk elimination.
Since the inductive coupling of the implant? is critical at every cycle, the
most relevant information must be picked out of the processed signal. This
information is then given all the available energy, and after all the coupling
loss, it should be sufficient to provide for speech pattern discrimination. In a
multichannel setting, this corresponds to doing a sorting of all the n signals
in the channels, selecting the m highest signals, and adding them up for
modulation. In a naive single processor implementation, this could
correspond to n 2 comparisons, and in a multiprocessor implementation,
log(n) comparisons. Both are dependent on the number of signals to be

787

sorted.
We needed a scheme in which the sorting time would be constant with
the number of channels, and would be easily implementable in analog circuitry, in case this became a future route. Our scheme is shown in Figure 7.
Each channel is connected to a threshold element, whose threshold can be
varied externally. A monotonically decreasing function scans the threshold
values, from the highest possible value of the output to the lowest. The output of these elements will be high corresponding to the values that are the
highest first. These output are summed with a quasi-integrator with threshold set to m. This element, when high, disables the scanning functions; and
it corresponds to having found the m highest signals. This sorting is
independent of the number of channels.
The output of the threshold units are fed into sigma-pi units which
gates the signals to be modulated. The output of these units are summed
and correspond to the final processed signal (Figure 8).
The user has full control of the characteristics of this device. The
number of channels can be easily altered; the number of components allowed
in the modulation can be changed; the amount of gain, rectificationcompression, and dispersion of each channel can also be individually controlled. The entire system is easily implementable in analog integrated circuits, once the clinical tests have determine the optimum operational
characteristics.

6. CONCLUSION
We have shown that the study of sensory implants can enhance our
understanding of the representation schemes used for natural sensory receptors. In particular, implants can be enhanced significantly if the effects of
the sensory processing and transfer functions are incorporated in the model.
We have also shown that neuromorphic computing paradigm provides a
parallel and easily modifiable framework for signal processing structures,
with advantages that perhaps cannot be offered by other technology.
We will soon start the use of the first on-line portable model, using a
single processor. This model will provide a testbed for more extensive clinical trials of the implant. We will then move to the parallel implementation,
and from there, possibly move toward analog circuitry implementation.
Another route for the use of neuromorphic computing in this domain is
possibly the use of sensory recordings from healthy animals to train selforganizing adaptive learning networks, in order to design the implant
transfer functions.

REFERENCES

[1]

[2]

Bilger, R.C.; Black, F.O.; Hopkinson, N.T.; and Myers, E.N.,
""Implanted auditory prosthesis: An evaluation of subjects presently
fitted with cochlear implants,"" Otolaryngology, 1977, Vol. 84, pp. 677682.
Bilger, R.C.; Black, F.O.; Hopkinson, N.T.; ~~ers, E.~.; Payne, !.L.;
Stenson, N.R.; Vega, A.; and Wolf, R.V., EvaluatiOn of subJects
presently fitted with implanted auditory prostheses,"" Annals of Otology, Rhinology, and Laryngology, 1977, Vol. 86(Supp. 38), pp. 1-176.

788

[3]

[4]

[5]
[6]

Eddington, D.K.; Dobelle, W.H.; Brackmann, D.E.; Mladejovsky, M.G.;
and Parkin, J., ""Place and periodicity pitch by stimulation of multiple
scala tympani electrodes in deaf volunteers,"" American Society for
Artificial Internal Organs, Transactions, 1978, Vol. 24, pp. 1-5.
House, W.F.; Berliner, .K.; Crary, W.; Graham, M.; Luckey, R;; Norton,
N.; Selters, W.; Tobm, H.; Urban, J.; and Wexler, M., Cochlear
implants,"" Annals of Otology, Rhinology and Laryngology, 1976, Vol.
85(Supp. 27), pp. 1-93.
House, W.F. and Urban, J., ""Long term results of electrode implantation and electronic stimulation of the cochlea in man,"" Annals of Otology, Rhinology and Laryngology, 1973, Vol. 82, No.2, pp. 504-517.
Ifukube, T. and White, R.L., ""A speech processor with lateral inhibition for an eight channel cochlear implant and its evaluation,"" IEEE
Trans. on Biomedical Engineering, November 1987, Vol. BME-34, No.

11.

[7]
[8]
[9]
[10]

[11]
[12]

[13]

[14]

[15]

[16]

Kong, K.-L., and Wasserman, G.S., ""Changing response measures
alters temporal summation in the receptor and spike potentials of the
Limulus lateral eye,"" Sensory Processes, 1978, Vol. 2, pp. 21-31. (a)
Kong, K.-L., and Wasserman, G.S., ""Temporal summation in the receptor potential of the Limulus lateral eye: Comparison between retinula
and eccentric cells,"" Sensory Processes, 1978, Vol. 2, pp. 9-20. (b)
Michelson, R.P., ""The results of electrical stimulation of the cochlea in
human sensory deafness,"" Annals of Otology, Rhinology and Laryngology, 1971, Vol. 80, pp. 914-919.
Mia dej ovsky, M.G.; Eddington, D.K.; Dobelle, W.H.; and Brackmann,
D.E., ""Artificial hearing for the deaf by cochlear stimulation: Pitch
modulation and some parametric thresholds,"" American Society for
Artificial Internal Organs, Transactions, 1974, Vol. 21, pp. 1-7.
Miyamoto, R.T.; Gossett, S.K.; Groom, G.L.; Kienle, M.L.; Pope, M.L.;
and Shallop, J.K., ""Cochlear implants: An auditory prosthesis for the
deaf,"" Journal of the Indiana State Medical Association, 1982, Vol. 75,
pp. 174-177.
Miyamoto, R.T.; Myres, W.A.; Pope, M.L.; and Carotta, C.A.,
""Cochlear implants for deaf children,"" Laryngoscope, 1986, Vol. 96, pp.
990-996.
Pialoux, P.; Chouard, C.H.; Meyer, B.; and Fu,?ain, C., ""Indications
and results of the multichannel cochlear implant,' Acta Otolaryngology,
1979, Vo .. 87, pp. 185-189.
Robbins, A.M.i Osberger, M.J.; Miyamoto, R.T.; Kienle, M.J.; and
Myres, W.A., ? Speech-tracking performance in single-channel cochlear
implant subjects,"" JourntLl of Speech and Hearing Research, 1985, Vol.
28, pp. 565-578.
Russell, I.J. and Sellick, P.M., ""The tuning properties of cochlear hair
cells,"" in E.F. Evans and J.P. Wilson (eds.), Psychophysics and Physiology 0 f Hearing, London: Academic Press, 1977.
Wasserman, G.S., ""Limulus psychophysics: Temporal summation in the
ventral eye,"" Journal of Experimental Psychology: General, 1978, Vol.
107, pp. 276-286.

789

[17]
[18]

[19]

[20]
[21]

Wasserman, G.S., ""Limulus psychophysics: Increment threshold,"" Perception & Psychophysics, 1981, Vol. 29, pp. 251-260.
Wasserman, G.S.; Felsten, G.; and Easland, G.S., ""Receptor saturation
and the psychophysical function,"" Investigative Ophthalmology and
Visual Science, 1978, Vol. 17, p. 155 (Abstract).
Wasserman, G.S.; Felsten, G.; and Easland, G.S., ""The psychophysical
function: Harmonizing Fechner and Stevens,"" Science, 1979, Vol. 204,
pp. 85-87.
Wasserman, G.S., ""Cochlear implant codes and speech perception in
profoundly deaf,"" Bulletin of Psychonomic Society, Vol. (18)3, 1987.
Wasserman, G.S.; Wang-Bennett, L.T.; and Miyamoto, R.T., ""Temporal dispersion in natural receptors and pattern discrimination mediated by artificial receptor,"" Proc. of the Fechner Centennial Symposium, Hans Buffart (Ed.), Elsevier/North Holland, Amsterdam, 1987.

r
I
I

7~

9

~ SENSORY CODING DATA ~ - ,

13

RECEPTOR
SIGNAL

STIMULUS

I
I

CENTRAL
ANALYSIS

BEHAVIOR

11

I

15

r----------~

I

L

..: PROSTHETIC :
-

-

I

SIGNAL

:- -

...... -r:-. __ .
I

I

-

..J

?

17

Fig. 1. Path of Natural and Prosthetic Signals.
Sound

Central Nervous System

Fig. 2. The House-Urban Cochlear Implant.

790

AMPLIFICATION

-----1~

COMPRESSIVE RECTIFIER

DISPERSION

-----1~

INTEGRATOR

Fig. 3. Receptor Model

Sound

Central Nervous System

Fig. 4. Modified Implant Model.

791

PORTABLE PARALLEL NEUROCOMpuTER

16KHz AM
MODULATED OUTPUT

m

EXTERNAL
USER CONTROLLED
PARAMETERS

Fig. 5. Initial Concept for a SIMD Architecture.

EXTERNALLY CONTROLLED
AMPUFICATION

DISPERSION

NEURON
MODEL

SORTER

OF
N SIGNALS

NEURON
MODEL

Fig. 6. Feedforward Neuron Model Implant.

792

SORTER OF n SIGNALS IN 0(1)

I--~ RESET SCANNING

SIGNALS
INPUTS

FUNCTION

THRESHOLD
SETOFn,
EXTERNALLY
CONTROLLED
THRESHOLD CONTROL:
SCANNING FUNCTION FROM I imax TO I j min

I j max

I I. min

Fig. 7. Signal Sorting Circuit.

SIGNAL SELECTORS

t---~.

0 -leS
1

1

1

J----"" OUTPUT SIGNAL
In

---+---~.c

Fig. 8. Sigma-Pi Units for Signal Composition.

793

USER CONTROLLED PARAMETERS

tJ4

13121114131

BEST
MATCHES

DISPERSION

10101312111
GAIN

~
FILTER
BYPASS

~
PROCESSOR
BYPASS

~

SINGLE
NEURON
PROCESSING

MICROPHONE

Fig. 9. Parameter Controls for Clinical Studies.

"
13,1987,"Temporal Patterns of Activity in Neural Networks","",13-temporal-patterns-of-activity-in-neural-networks.pdf,"Abstract Missing","297

TEMPORAL PATTERNS OF ACTIVITY IN
NEURAL NETWORKS
Paolo Gaudiano
Dept. of Aerospace Engineering Sciences,
University of Colorado, Boulder CO 80309, USA
January 5, 1988

Abstract
Patterns of activity over real neural structures are known to exhibit timedependent behavior. It would seem that the brain may be capable of utilizing
temporal behavior of activity in neural networks as a way of performing functions
which cannot otherwise be easily implemented. These might include the origination
of sequential behavior and the recognition of time-dependent stimuli. A model is
presented here which uses neuronal populations with recurrent feedback connections in an attempt to observe and describe the resulting time-dependent behavior.
Shortcomings and problems inherent to this model are discussed. Current models
by other researchers are reviewed and their similarities and differences discussed.

METHODS / PRELIMINARY RESULTS
In previous papers,[2,3] computer models were presented that simulate a net consisting of two spatially organized populations of realistic neurons. The populations are
richly interconnected and are shown to exhibit internally sustained activity. It was
shown that if the neurons have response times significantly shorter than the typical unit
time characteristic of the input patterns (usually 1 msec), the populations will exhibit
time-dependent behavior. This will typically result in the net falling into a limit cycle.
By a limit cycle, it is meant that the population falls into activity patterns during which
all of the active cells fire in a cyclic, periodic fashion. Although the period of firing of
the individual cells may be different, after a fixed time the overall population activity
will repeat in a cyclic, periodic fashion. For populations organized in 7x7 grids, the
limit cycle will usually start 20~200 msec after the input is turned off, and its period
will be in the order of 20-100 msec.
The point ofinterest is that ifthe net is allowed to undergo synaptic modifications by
means of a modified hebbian learning rule while being presented with a specific spatial
pattern (i.e., cells at specific spatial locations within the net are externally stimulated),
subsequent presentations of the same pattern with different temporal characteristics
will cause the population to recall patterns which are spatially identical (the same cells
will be active) but which have different temporal qualities. In other words, the net can
fall into a different limit cycle. These limit cycles seem to behave as attractors in that
similar input patterns will result in the same limit cycle, and hence each distinct limit
cycle appears to have a basin of attraction. Hence a net which can only learn a small

? American Institute of Physics 1988

298

number of spatially distinct patterns can recall the patterns in a number of temporal
modes. If it were possible to quantitatively discriminate between such temporal modes,
it would seem reasonable to speculate that different limit cycles could correspond to
different memory traces. This would significantly increase estimates on the capacity of
memory storage in the net.
It has also been shown that a net being presented with a given pattern will fall and
stay into a limit cycle until another pattern is presented which will cause the system
to fall into a different basin of attraction. If no other patterns are presented, the net
will remain in the same limit cycle indefinitely. Furthermore, the net will fall into the
same limit cycle independently of the duration of the input stimulus, so long as the
input stimulus is presented for a long enough time to raise the population activity level
beyond a minimum necessary to achieve self-sustained activity. Hence, if we suppose
that the net ""recognizes"" the input when it falls into the corresponding limit cycle, it
follows that the net will recognize a string of input patterns regardless of the duration of
each input pattern, so long as each input is presented long enough for the net to fall into
the appropriate limit cycle. In particular, our system is capable of falling into a limit
cycle within some tens of milliseconds. This can be fast enough to encode, for example, a
string of phonemes as would typically be found in continuous speech. It may be possible,
for instance, to create a model similar to Rumelhart and McClelland's 1981 model on
word recognition by appropriately connecting multiple layers of these networks. If the
response time of the cells were increased in higher layers, it may be possible to have
the lowest level respond to stimuli quickly enough to distinguish phonemes (or some
sub-phonemic basic linguistic unit), then have populations from this first level feed into
a slower, word-recognizing population layer, and so On. Such a model may be able to
perform word recognition from an input consisting of continuous phoneme strings even
when the phonemes may vary in duration of presentation.
SHORTCOMINGS
Unfortunately, it was noticed a short time ago that a consistent mistake had been
made in the process of obtaining the above-mentioned results. Namely, in the process
of decreasing the response time of the cells I accidentally reached a response time below
the time step used in the numerical approximation that updates the state of each cell
during a simulation. The equations that describe the state of each cell depend on the
state of the cell at the previous time step as well as on the input at the present time.
These equations are of first order in time, and an explicit discrete approximation is
used in the model. Unfortunately it is a known fact that care must be taken in selecting
the size of the time step in order to obtain reliable results. It is infact the case that
by reducing the time step to a level below the response time of the cells the dynamics
of the system varied significantly. It is questionable whether it would be possible to
adjust some of the population parameters within reson to obtain the same results with
a smaller step size, but the following points should be taken into account: 1) other
researchers have created similar models that show such cyclic behavior (see for example
Silverman, Shaw and Pearson[7]). 2) biological data exists which would indicate the
existance of cyclic or periodic bahvior in real neural systems (see for instance Baird[1]).
As I just recently completed a series of studies at this university, I will not be able
to perform a detailed examination of the system described here, but instead I will more

299

than likely create new models on different research equipment which will be geared more
specifically towards the study of temporal behavior in neural networks.
OTHER MODELS
It should be noted that in the past few years some researchers have begun investigating the possibility of neural networks that can exhibit time-dependent behavior,
and I would like to report on some of the available results as they relate to the topic of
temporal patterns. Baird[l] reports findings from the rabbit's olfctory bulb which indicate the existance of phase-locked oscillatory states corresponding to olfactory stimuli
presented to the subjects. He outlines an elegant model which attributes pattern recognition abilities to competing instabilities in the dynamic activity of neural structures.
He further speculates that inhomogeneous connectivity in the bulb can be selectively
modified to achieve input-sensitive oscillatory states.
Silverman, Shaw and Pearson[7] have developed a model based on a biologically-inspired
idealized neural structure, which they call the trion. This unit represents a localized
group of neurons with a discrete firing period. It was found that small ensembles of trions with symmetric connections can exhibit quasi-stable periodic firing patterns which
do not require pacemakers or external driving. Their results are inspired by existing
physiological data and are consistent with other works.
Kleinfeld[6], and Sompolinsky and Kanter[8] independently developed neural network
models that can generate and recognize sequential or cyclic patterns. Both models rely
on what could be summarized as the recirculation of information through time-delayed
channels.
Very similar results are presented by Jordan[4] who extends a typical connectionist or
PDP model to include state and plan units with recurrent connections and feedback
from output units through hidden units. He employs supervised learning with fuzzy
constraints to induce learning of sequences in the system.
From a slightly different approach, Tank and Hopfield[9] make USe of patterned sets
of delays which effectively compress information in time. They develop a model which
recognizes patterns by falling into local minima of a state-space energy function. They
suggest that a systematic selection of delay functions can be done which will allow for
time distortions that would be likely to occur in the input.
Finally, a somewhat different approach is taken by Homma, Atlas and Marks[5], who
generalize a network for spatial pattern recognition to one that performs spatio-temporal
patterns by extending classical principles from spatial networks to dynamic networks.
In particular, they replace multiplication with convolution, weights with transfer functions, and thresholding with non linear transforms. Hebbian and Delta learning rules
are similarly generalized. The resulting models are able to perform temporal pattern
recognition.
The above is only a partial list of some of the relevant work in this field, and there
are probably various other results I am not aware of.
DISCUSSION
All of the above results indicate the importance of temporal patterns in neural networks. The need is apparent for further formal models which can successfully quantify
temporal behavior in neural networks. Several questions must be answered to further

300

clarify the role and meaning of temporal patterns in neural nets. For instance, there
is an apparent difference between a model that performs sequential tasks and one that
performs recognition of dynamic patterns. It seems that appropriate selection of delay
mechanisms will be necessary to account for many types of temporal pattern recognition. The question of scaling must also be explored: mechanism are known to exist in
the brain which can cause delays ranging from the millisecond-range (e.g. variations
in synaptic cleft size) to the tenth of a second range (e.g. axonal transmission times).
On the other hand, the brain is capable of rec""Ignizing sequences of stimuli that can be
much longer than the typical neural event, such as for instance being able to remember
a song in its entirety. These and other questions could lead to interesting new aspects
of brain function which are presently unclear.

References
[1] Baird, B., ""Nonlinear Dynamics of Pattern Formation and Pattern Recognition in
the Rabbit Olfactory Bulb"". Physica 22D, 150-175. 1986.
[2] Gaudiano, P., ""Computer Models of Neural Networks"". Unpublished Master's Thesis. University of Colorado. 1987.
[3] Gaudiano, P., MacGregor, R.J., ""Dynamic Activity and Memory Traces in
Computer-Simulated Recurrently-Connected Neural Networks"". Proceedings of the
First International Conference on Neural Networks. 2:177-185. 1987.
[4] Jordan, M.I., ""Attractor Dynamics and Parallelism in a Connectionist Sequential
Machine"". Proceedings of the Eighth Annual Conference of the Cognitive Sciences
Society. 1986.
[5] Homma, T., Atlas, L.E., Marks, R.J.II, ""An Artificial Neural Network for SpatioTemporal Bipolar Patterns: Application to Phoneme Classification"". To appear in
proceedings of Neural Information Processing Systems Conference (AlP). 1987.
[6] Kleinfeld, D., ""Sequential State Generation by Model Neural Networks"". Proc.
Natl. Acad. Sci. USA. 83: 9469-9473. 1986.
[7] Silverman, D.l., Shaw, G.L., Pearson, l.C. ""Associative Recall Properties of the
Trion Model of Cortical Organization"". Biol. Cybern. 53:259-271. 1986.
[8] Sompolinsky, H., Kanter, I. ""Temporal Association in Asymmetric Neural Networks"". Phys. Rev. Let. 57:2861-2864. 1986.
[9] Tank, D.W., Hopfield, l.l. ""Neural Computation by Concentrating Information in
Time"". Proc. Natl. Acad. Sci. USA. 84:1896-1900. 1987.

"
14,1987,"Encoding Geometric Invariances in Higher-Order Neural Networks","",14-encoding-geometric-invariances-in-higher-order-neural-networks.pdf,"Abstract Missing","301

ENCODING GEOMETRIC INVARIANCES IN
HIGHER-ORDER NEURAL NETWORKS
C.L. Giles
Air Force Office of Scientific Research, Bolling AFB, DC 20332
R.D. Griffin
Naval Research Laboratory, Washington, DC

20375-5000

T. Maxwell
Sachs-Freeman Associates, Landover, MD 20785
ABSTRACT
We describe a method of constructing higher-order neural
networks that respond invariantly under geometric transformations on
the input space. By requiring each unit to satisfy a set of
constraints on the interconnection weights, a particular structure is
imposed on the network. A network built using such an architecture
maintains its invariant performance independent of the values the
weights assume, of the learning rules used, and of the form of the
nonlinearities in the network. The invariance exhibited by a firstorder network is usually of a trivial sort, e.g., responding only to
the average input in the case of translation invariance, whereas
higher-order networks can perform useful functions and still exhibit
the invariance. We derive the weight constraints for translation,
rotation, scale, and several combinations of these transformations,
and report results of simulation studies.
INTRODUCTION
A persistent difficulty for pattern recognition systems is the
requirement that patterns or objects be recognized independent of
irrelevant parameters or distortions such as orientation (position,
rotation, aspect), scale or size, background or context, doppler
shift, time of occurrence, or signal duration. The remarkable
performance of humans and other animals on this problem in the visual
and auditory realms is often taken for granted, until one tries to
build a machine with similar performance. Thoufh many methods have
been developed for dealing with these problems, we have classified
them into two categories: 1) preprocessing or transformation
(inherent) approaches, and 2) case-specific or ""brute force""
(learned) approaches. Common transformation techniques include:
Fourier, Hough, and related transforms; moments; and Fourier
descriptors of the input signal. In these approaches the signal is
usually transformed so that the subsequent processing ignores
arbitrary parameters such as scale, translation, etc. In addition,
these techniques are usually computationally expensive and are
sensitive to noise in the input signal. The ""brute force"" approach
is exemplified by training a device, such as a perceptron, to
classify a pattern independent of it's position by presenting the

@

American Institute of Physics 1988

302

training pattern at all possible positions. MADALINE machines 2 have
been shown to perform well using such techniques. Often, this type
of invariance is pattern specific, does not easily generalize to
other patterns, and depends on the type of learning algorithm
employed. Furthermore, a great deal of time and energy is spent on
learning the invariance, rather than on learning the signal. We
describe a method that has the advantage of inherent invariance but
uses a higher-order neural network approach that must learn only the
desired signal. Higher-order units have been shown to have unique
computational strengths and are quite amenable to the encoding of a
priori know1edge. 3 - 7
MATHEMATICAL DEVELOPMENT
Our approach is similar to the group invariance approach,8,10
although we make no appeal to group theory to obtain our results. We
begin by selecting a transformation on the input space, then require
the output of the unit to be invariant to the transformation. The
resulting equations yield constraints on the interconnection weights,
and thus imply a particular form or structure for the network
architecture.
For the i-th unit Yi of order M defined on a discrete input
space, let the output be given by
Yi[YiM(X),P(x)] - f( WiO + ~ Wi 1 (X1) P(x1)

+ ~~ Wi 2 (X1,X2) P(x1) P(x2) + ...
+~ ... ~ Wi M(X1,? ?XM) P(x1)? ?P(XM) ),

(1)

where p(x) is the input pattern or signal function (sometimes called
a pixel) evaluated at position vector x, wim(xl, ... Xm) is the weight
of order m connecting the outputs of units at Xl, x2, .. Xm to the ith unit, i.e., it correlates m values, f(u) is some threshold or
sigmoid output function, and the summations extend over the input
space. YiM(X) represents the entire set of weights associated with
the i-th unit. These units are equivalent to the sigma-pi units a
defined by Rumelhart, Hinton, and Williams. 7 Systems built from
these units suffer from a combinatorial explosion of terms, hence are
more complicated to build and train. To reduce the severity of this
problem, one can limit the range of the interconnection weights or
the number of orders, or impose various other constraints. We find
that, in addition to the advantages of inherent invariance, imposing
an invariance constraint on Eq. (1) reduces the number of allowed
aThe sigma-pi neural networks are multi-layer networks with
higher-order terms in any layer. As such, most of the neural
networks described here can be considered as a special case of the
sigma-pi units. However, the sigma-pi units as originally formulated
did not have invariant weight terms, though it is quite simple to
incorporate such invariances in these units.

303

weights, thus simplifying the architecture and shortening the
training time.
We now define what we mean by invariance. The output of a unit
is invariant with respect to the transformation T on the input
pattern if 9
(2)

An example of the class of invariant response defined by Eq. (2)
would be invariant detection of an object in the receptive field of a
panning or zooming camera. An example of a different class would be
invariant detection of an object that is moving within the field of a
fixed camera. One can think of this latter case as consisting of a
fixed field of ""noise"" plus a moving field that contains only the
object of interest. If the detection system does not respond to the
fixed field, then this latter case is included in Eq. (2).
To illustrate our method we derive the weight constraints for
one-dimensional translation invariance. We will first switch to a
continuous formulation, however, for reasons of simplicity and
generality, and because it is easier to grasp the physical
significance of the results, although any numerical simulation
requires a discrete formulation and has significant implications for
the implementation of our results. Instead of an index i, we now
keep track of our units with the continuous variable u. With these
changes Eq. (2) now becomes
y[u;wM(x),p(X)] = f( wO + JrdXl Wl(U;Xl) P(xl) + ...

+

f?? Jr dXl? .dXM

wM(U;Xl,? ?XM) P(Xl)? .P(XM) ),

(3)

The limits on the integrals are defined by the problem and are
crucial in what follows. Let T be a translation of the input pattern
by -xO, so that

(4)

T[p(x)] - p(x+XO)
where xo is the translation of the input pattern.
Ty[u;wM(x) ,p(x)] - y[u;YM(x),p(x+XO?)

=

Then, from eq (2),

y[u;wM(x),p(x)]

(5)

Since p(x) is arbitrary we must impose term-by-term equality in the
argument of the threshold function; i.e.,

f dXl Wl(U;Xl)

P(xl) =

f dxl Wl(U;Xl)

P(xl+XO),

(Sa)

Jr fdxl dX2 W2 (U;Xl,X2) P(xl) P(x2) =
Jr

f dXl

dX2 W2 (U;Xl,X2) P(xl+XO) P(x2+XO),
etc.

(Sb)

304

Making the substitutions xl. xl-XO, x2 "",x2-XO, etc, we find that

f dXl Wl(U;Xl)

f f dxl

P(xl) -

f dxl WI(U;Xl-XO)

P(XI) ,

(6a)

dX2 W2 (U;XI,X2) P(xI) P(x2) -

f f dXI

dX2 W2 (U;XI-XO,X2-XO) P(xI) P(x2),

(6b)

etc.
Note that the limits of the integrals on the right hand side must be
adjusted to satisfy the change-of-variables. If the limits on the
integrals are infinite or if one imposes some sort of periodic
boundary condition, the limits of the integrals on both sides of the
equation can be set equal. We will assume in the remainder of this
paper that these conditions can be met; normally this means the
limits of the integrals extend to infinity. (In an implementation,
it is usually impractical or even impossible to satisfy these
requirements, but our simulation results indicate that these networks
perform satisfactorily even though the regions of integration are not
identical. This question must be addressed for each class of
transformation; it is an integral part of the implementation design.)
Since the functions p(x) are arbitrary and the regions of integration
are the same, the weight functions must be equal. This imposes a
constraint on the functional form of the weight functions or, in the
discrete implementation, limits the allowed connections and thus the
number of weights. In the case of translation invariance, the
constraint on the functional form of the weight functions requires
that
w1(U;XI) - wl(u;X].-XO),
w2(U;XI,X2) - w2(U;XI-XO,X2-XO),

(7a)

(7b)

etc.
These equations imply that the first order weight is independent of
input position, and depends only on the output position u. The
second order weight is a function only of vector differences,IO i.e.,
w1(u;Xj) - J..(u),

(8a)

w2(U;X].,X2) - w2(u:X]. -Xl)?

(8b)

For a discrete implementation with N input units (pixels) fully
connected to an output unit, this requirement reduces the number of
second-order weights from order N2 to order N, i.e., only weights for
differences of indexes are needed rather than all unique pair
combinations. Of course, this advantage is multiplied as the number
of fully-connected output units increases.

FURTHER EXAMPLES
We have applied these techniques to several other
transformations of interest. For the case of transformation of scale

305

define the scale operator S such that
Sp(x) - aIlp(ax)

(9)

where a is the scale factor, and x is a vector of dimension n. The
factor an is used for normalization purposes, so that a given figure
always contains the same ""energy"" regardless of its scale.
Application of the same procedure to this transformation leads to the
following constraints on the weights:
wl(u;Xjfa) -= wl(u;~,

w2(u;X1Ia,xv'a) .. w2(u;'X.l.'~)'
w3(u;xlla,x2/a ,x3/a) ... w3(U;X].,X2,X3), etc.

(lOa)
(lOb)
(lOc)

Consider a two-dimensional problem viewed in polar coordinates (r,t).
A set of solutions to these constraints is
J.(u;q,tI) - w1(u;Q),

w2(u;rl,r2;tl,t2) - w2(u;rllr2;tl,t2).
w3 (u;rl,r2,r3;tl,t2,t3) - w3 (u;(rl-r2)/r3;tl,t2,t3).

(lla)
(llb)
(llc)

Note that with increasing order comes increasing freedom in the
selection of the functional form of the weights. Any solution that
satisfies the constraint may be used. This gives the designer
additional freedom to limit the connection complexity, or to encode
special behavior into the net architecture. An example of this is
given later when we discuss combining translation and scale
invariance in the same network.
Now consider a change of scale for a two-dimensional system in
rectangular coordinates, and consider only the second-order weights.
A set of solutions to the weight constraint is:
W2 (U;Xl,Yl;X2,Y2)

-

W2 (U;Xl/Yl;X2/Y2),

- W2 (U;Xl/X2;Yl/Y2),
W2 (U;Xl,Yl;X2,Y2) - w2 (U;(Xl-X2)/(Yl-Y2)), etc.
W2 (U;Xl,Yl;X2,Y2)

(12a)
(l2b)
(12c)

We have done a simulation using the form of Eq. (12b). The
simulation was done using a small input space (8x8) and one output
unit. A simple least-mean-square (back-propagation) algorithm was
used for training the network. When taught to distinguish the
letters T and C at one scale, it distinguished them at changes of
scale of up to 4X with about 15 percent maximum degradation in the
output strength. These results are quite encouraging because no
special effort was required to make the system work, and no
corrections or modifications were made to account for the boundary
condition requirements as discussed near Eq. (6). This and other
simulations are discussed further later.
As a third example of a geometric transformation, consider the
case of rotation about the origin for a two-dimensional space in
polar coordinates. One can readily show that the weight constraints

306

are satisfied if
wl(u;rl,tl) ~ wl(u;rl),
w2(u;rl,r2;tl,t2) - w2(u;rl,r2;tl-t2), etc.

(13a)
(l3b)

These results are reminiscent of the results for translation
invariance. This is not uncommon: seemingly different problems
often have similar constraint requirements if the proper change of
variable is made. This can be used to advantage when implementing
such networks but we will not discuss it further here.
An interesting case arises when one considers combinations of
invariances, e.g., scale and translation. This raises the question
of the effect of the order of the transformations, i.e., is scale
followed by translation equivalent to translation followed by scale?
The obvious answer is no, yet for certain cases the order is
unimportant. Consider first the case of change-of-scale by a,
followed by a translation XC; the constraints on the weights up to
second order are:
Wl(U;Xl) - wl(u; (xl-xo)/a),
w2 (u; Xl ,x2)

0=

w2(u; (xl-xo)/a, (x2-xo)/a) ,

(14a)
(l4b)

and for translation followed by scale the constraints are:
wl(u;Xl) - wl(u; (xl/a)-xo). and

(lSa)

w2(U;Xl,X2) = w2(u;(xl/a)-xo,(x2Ia )-XO) .

(lSb)

Consider only the second-order weights for the two-dimensional case.
Choose rectangular coordinate variables (x,y) so that the translation
is given by (xO,YO). Then
W2 (U;Xl,Yl;X2,Y2) =
w2 (u;(xl/a)-xO,(Yl/a)-YO;(x2/a)-xO'(Y2/a)-yO)'

(l6a)

W2 (U;Xl,Yl;X2,Y2) w2 (U;(Xl- x o)/a, (Yl-yo)/a; (x2- xo)/a, (Y2-Yo)/a).

(16b)

or

If we take as our solution
w2(U;Xl,Yl;X2,Y2) = w2(U;(X1-X2)/(Yl-Y2?,

(17)

then w2 is invariant to scale and translation, and the order is
unimportant. With higher-order weights one can be even more
adventurous.
As a final example consider the case of a change of scale by a
factor a and rotation about the origin by an amount to for a twodimensional system in polar coordinates. (Note that the order of
transformation makes no difference.) The weight constraints up to
second order are:
(18a)

307

(18b)
The first-order constraint requires that wI be independent of the
input variables, but for the second-order term one can obtain a more
useful solution:

(19)
This implies that with second-order weights, one can construct a unit
that is insensitive to changes in scale and rotation of the input
space. How useful it is depends upon the application.
SIMULATION RESULTS
We have constructed several higher-order neural networks that
demonstrated invariant response to transformations of scale and of
translation of the input patterns. The systems were small,
consisting of less than 100 input units, were constructed from
second-and first-order units, and contained only one, two, or three
layers. We used a back-propagation algorithm modified for the
higher-order (sigma-pi) units. The simulation studies are still in
the early stages, so the performance of the networks has not been
thoroughly investigated. It seems safe to say, however, that there
is much to be gained by a thorough study of these systems. For
example, we have demonstrated that a small system of second-order
units trained to distinguish the letters T and C at one scale can
continue to distinguish them over changes in scale of factors of at
least four without retraining and with satisfactory performance.
Similar performance has been obtained for the case of translation
invariance.
Even at this stage, some interesting facets of this approach are
becoming clear: 1) Even with the constraints imposed by the
invariance, it is usually necessary to limit the range of connections
in order to restrict the complexity of the network. This is often
cited as a problem with higher-order networks, but we take the view
that one can learn a great deal more about the nature of a problem by
examining it at this level rather than by simply training a network
that has a general-purpose architecture. 2) The higher-order
networks seem to solve problems in an elegant and simple manner.
However, unless one is careful in the design of the network, it
performs worse than a simpler conventional network when there is
noise in the input field. 3) Learning is often ""quicker"" than in a
conventional approach, although this is highly dependent on the
specific problem and implementation design. It seems that a tradeoff
can be made: either faster learning but less noise robustness, or
slower learning with more robust performance.
DISCUSSION
We have shown a simple way to encode geometric invariances into
neural networks (instead of training them), though to be useful the
networks must be constructed of higher-order units. The invariant
encoding is achieved by restricting the allowable network

308

architectures and is independent of learning rules and the form of
the sigmoid or threshold functions. The invariance encoding is
normally for an entire layer, although it can be on an individual
unit basis. It is easy to build one or more invariant layers into a
multi-layer net, and different layers can satisfy different
invariance requirements. This is useful for operating on internal
features or representations in an invariant manner. For learning in
such a net, a multi-layered learning rule such as generalized backpropagation 7 must be used. In our simulations we have used a
generalized back-propagation learning rule to train a two-layer
system consisting of a second-order, translation-invariant input
layer and a first-order output layer. Note that we have not shown
that one can not encode invariances into layered first-order
networks, but the analysis in this paper implies that such invariance
would be dependent on the form of the sigmoid function.
When invariances are encoded into higher-order neural networks,
the number of interconnections required is usually reduced by orders
of powers of N where N is the size of the input. For example, a
fully connected, first-order, single-layer net with a single output
unit would have order N interconnections; a similar second-order net,
order N2 . If this second-order net (or layer) is made shift
invariant, the order is reduced to N. The number of multiplies and
adds is still of order N2 .
We have limited our discussion in this paper to geometric
invariances, but there seems to be no reason why temporal or other
invariances could not be encoded in a similar manner.
REFERENCES
1.

D.H. Ballard and C.M. Brown, Computer Vision (Prentice-Hall,
Englewood Cliffs, NJ, 1982).

2.

B. Widrow, IEEE First Int1. Conf. on Neural Networks, 87TH019l7, Vol. 1, p. 143, San Diego, CA, June 1987.

3.

J.A. Feldman, Biological Cybernetics 46, 27 (1982).

4.

C.L. Giles and T. Maxwell, App1. Optics 26, 4972 (1987).

5.

G.E. Hinton, Proc. 7th IntI. Joint Conf. on Artificial
Intelligence, ed. A. Drina, 683 (1981).

6.

Y.C. Lee, G. Doolen, H.H. Chen, G.Z. Sun, T. Maxwell, H.Y. Lee,
C.L. Giles, Physica 22D, 276 (1986).

7.

D.E. Rume1hart, G.E. Hinton, and R.J. Williams, Parallel
Distributed Processing, Vol. 1, Ch. 8, D.E. Rume1hart and J.L.
McClelland, eds., (MIT Press, Cambridge, 1986).

309

8.

T . Maxwell, C.L. Giles, Y.C. Lee, and H.H. Chen, Proc. IEEE
IntI. Conf. on Systems, Man, and Cybernetics, 86CH2364-8, p.
627, Atlanta, GA, October 1986.

9.

W. Pitts and W.S. McCulloch, Bull. Math. Biophys. 9, 127
(1947).

10.

M. Minsky and S, Papert, Perceptrons (MIT Press, Cambridge,
Mass., 1969).

"
15,1987,"Correlational Strength and Computational Algebra of Synaptic Connections Between Neurons","",15-correlational-strength-and-computational-algebra-of-synaptic-connections-between-neurons.pdf,"Abstract Missing","270

Correlational Strength and Computational Algebra
of Synaptic Connections Between Neurons
Eberhard E. Fetz
Department of Physiology & Biophysics,
University of Washington, Seattle, WA 98195
ABSTRACT
Intracellular recordings in spinal cord motoneurons and cerebral
cortex neurons have provided new evidence on the correlational strength of
monosynaptic connections, and the relation between the shapes of
postsynaptic potentials and the associated increased firing probability. In
these cells, excitatory postsynaptic potentials (EPSPs) produce crosscorrelogram peaks which resemble in large part the derivative of the EPSP.
Additional synaptic noise broadens the peak, but the peak area -- i.e., the
number of above-chance firings triggered per EPSP -- remains proportional to
the EPSP amplitude. A typical EPSP of 100 ~v triggers about .01 firings per
EPSP. The consequences of these data for information processing by
polysynaptic connections is discussed. The effects of sequential polysynaptic
links can be calculated by convolving the effects of the underlying
monosynaptic connections. The net effect of parallel pathways is the sum of
the individual contributions.
INTRODUCTION
Interactions between neurons are determined by the strength and
distribution of their synaptic connections.
The strength of synaptic
interactions has been measured directly in the central nervous system by two
techniques. Intracellular recording reveals the magnitude and time course of
postsynaptic potentials (PSPs) produced by synaptic connections, and crosscorrelation of extracellular spike trains measures the effect of the PSP's on the
firing probability of the connected cells. The relation between the shape of
excitatory postsynaptic potentials (EPSPs) and the shape of the crosscorrelogram peak they produce has been empirically investigated in cat
motoneurons 2,4,5 and in neocortical cells 10.
RELATION BETWEEN EPSP'S AND CORRELOGRAM PEAKS
Synaptic interactions have been studied most thoroughly in spinal
cord motoneurons. Figure 1 illustrates the membrane potential of a
rhythmically firing motoneuron, and the effect of EPSPs on its firing. An
EPSP occurring sufficiently close to threshold (8) will cause the motoneuron
to fire and will advance an action potential to its rising edge (top).
Mathematical analysis of this threshold-crossing process predicts that an
EPSP with shape e(t) will produce a firing probability f(t), which resembles
? American Institute of Phy~ics 1988

271

rI

f;

::

'I

8

'I

I'

/..-::-- ----.... ....

."",.""""..,."",

.,...,.""""

~-""""""

/'

I

..,, .... ..

)

\

..."",/

,;

I

i:

.. :

\

--.----r

,

'I

.,.,,,,

....

....

EPSP
e(t)
t

CROSS-

CORRELOGRAM
f(t)

TIME

t

Fig. 1. The relation between EPSP's and motoneuron firing. Top: membrane trajectory of
rhythmically firing motoneuron, showing EPSP crossing threshold (8) and shortening the
normal interspike interval by advancing a spike. V(t) is difference between membrane
potential and threshold. Middle: same threshold-crossing process aligned with EPSP, with
v(t) plotted as falling trajectory. Intercept (at upward arrow) indicates time of the advanced
action potential. Bottom: Cross-correlation histogram predicted by threshold crossings. The
peak in the firing rate f(t) above baseline (fo) is produced by spikes advanced from baseline,
as indicated by the changed counts for the illustrated trajectory. Consequently, the area in
the peak equals the area of the subsequent trough.

272

the derivative of the EPSP 4,8. Specifically, for smooth membrane potential
trajectories approaching threshold (the case of no additional synaptic noise):
f(t)

=fo + (fo/v) del dt

(1)

v

where fo is the baseline firing rate of the motoneuron and is the rate of
closure between motoneuron membrane potential and threshold. This
relation can be derived analytically by tranforming the process to a
coordinate system aligned with the EPSP (Fig. 1, middle) and calculating the
relative timing of spikes advanced by intercepts of the threshold trajectories
with the EPSP 4. The above relation (1) is also valid for the correlogram
trough during the falling phase of the EPSP, as long as del dt >
if the EPSP
falls more rapidly than
the trough is limited at zero firing rate (as
illustrated for the correlogram at bottom). The fact that the shape of the
correlogram peak above baseline matches the EPSP derivative has been
empirically confirmed for large EPSPs in cat motoneurons 4. This relation
implies that the height of the correlogram peak above baseline is proportional
to the EPSP rate of rise. The integral of this relationship predicts that the area
between the correlogram peak and baseline is proportional to the EPSP
amplitude.
This linear relation further implies that the effects of
simultaneously arriving EPSPs will add linearly.
The presence of additional background synaptic ""noise"", which is
normally produced by randomly occurring synaptic inputs, tends to make the
correlogram peak broader than the duration of the EPSP risetime. This
broadening is produced by membrane potential fluctuations which cause
additional threshold crossings during the decay of the EPSP by trajectories
that would have missed the EPSP (e.g., the dashed trajectory in Fig. 1,
middle). On the basis of indirect empirical comparisons it has been proposed
6,7 that the broader correlogram peaks can be described by the sum of two
linear functions of e(t):

-v,

f(t)

=fo + a e(t) + b deldt

-v;

(2)

This relation provides a reasonable match when the coefficients (a and b) can
be optimized for each case 5,7, but direct empirical comparisons 2,4 indicate
that the difference between the correlogram peak and the derivative is
typically briefer than the EPSP.
The effect of synaptic noise on the transform -between EPSP and
correlogram peak has not yet been analytically derived (except for the case of
However the threshold-crossing process has been
Gaussian noise1).
simulated by a computer model which adds synaptic noise to the trajectories
intercepting the EPSP 1. The correlograms generated by the simulation match
the correlograms measured empirically for small EPSP's in motoneurons 2,
confirming the validity of the model.
Although synaptic noise distributes the triggered firings over a wider
peak, the area of the correlogram peak, i.e., the number of motoneuron firings
produced by an EPSP, is essentially preserved and remains proportional to
EPSP amplitude for moderate noise levels. For unitary EPSP's (produced by

273

a single afferent fiber) in cat motoneurons, the number of firings triggered per
EPSP (Np) was linearly related to the amplitude (h) of the EPSP 2:
Np = (O.l/mv)? h (mv) + .003

(3)

The fact that the number of triggered spikes increases in proportion to EPSP
amplitude has also been confirmed for neocortical neurons 10; for cells
recorded in sensorimotor cortex slices (probably pyramidal cells) the
coefficient of h was very similar: 0.07/mv. This means that a typical unitary
EPSP with amplitude of 100 Ilv, raises the probability that the postsynaptic
cell fires by less than .01. Moreover, this increase occurs during a specific
time interval corresponding to the rise time of the EPSP - on the order of 1 - 2
msec. The net increase in firing rate of the postsynaptic cell is calculated by
the proportional decrease in interspike intervals produced by the triggered
spikes 4. (While the above values are typical, unitary EPSP's range in size
from several hundred IlV down to undetectable levels of severalllv., and
have risetimes of.2 - 4 msec.)
Inhibitory connections between cells, mediated by inhibitory
postsynaptic potentials (IPSPs), produce a trough in the cross-correlogram.
This reduction of firing probability below baseline is followed by a
subsequent broad, shallow peak, representing the spikes that have been
delayed during the IPSP. Although the effects of inhibitory connections
remain to be analyzed more quantitatively, preliminary results indicate that
small IPSP's in synaptic noise produce decreases in firing probability that are
similar to the increases produced by EPSP's 4,5.
DISYNAPTIC LINKS

The effects of polysynaptic links between neurons can be understood
as combinations of the underlying monosynaptic connections.
A
monosynaptic connection from cell A to cell B would produce a first-order
cross-correlation peak P1(BIA,t), representing the conditional probability that
neuron B fires above chance at time t, given a spike in cell A at time t = O. As
noted above, the shape of this first-order correlogram peak is largely
proportional to the EPSP derivative (for cells whose interspike interval
exceeds the duration of the EPSP). The latency of the peak is the conduction
time from A to B (Fig. 2 top left).
In contrast, several types of disynaptic linkages betw.een A and B,
mediated by a third neuron C, will produce a second-order correlation peak
between A and B. A disynaptic link may be produced by two serial
monosynaptic connections, from A to C and from C to B (Fig. 2, bottom left),
or by a common synaptic input from C ending on both A and B (Fig. 2,
bottom right). In both cases, the second-order correlation between A and B
produced by the disynaptic link would be the convolution of the two firstorder correlations between the monosynaptically connected cells:

(4)

274

As indicated by the diagram, the cross-correlogram peak P2(BIA,t) would be
smaller and more dispersed than the peaks of the underlying first-order
correlation peaks. For serial connections the peak would appear to the right
of the origin, at a latency that is the sum of the two monosynaptic latencies.
The peak produced by a common input typically straddles the origin, since its
timing reflects the difference between the underlying latencies.

=>

Monosynaptic connection

-----..'t-

I \
t \

@

First-order correlation

~(AIB,t)

LJA,,-_~_(_B_I_A_'t_)_

Disynaptic connection

=

~(~IA,-t)

1
~

Serial connection

Second-order correlation
Common input

r--A---t
t
I

t \
I \

: \. A

~ (C I A)

@

t
t
t
I

:

ll(AIC)

:""

V

H\~
t

:

j

\

I'""
t \

\
\

\
\

t

\~(BIC)
P(BIA)

_________ ~,_2__----

@

\.

P(BIC)

1 \/\ '

J t""-_------

_ _ _/\.~(BIA)
-L

Fig. 2. Correlational effects of monosynaptic and disynaptic links between two neurons.
Top: monosynaptic excitatory link from A to B produces an increase in firing probability of B
after A (left). As with all correlograms this is the time-inverted probability of increased firing
in A relative to B (right). Bottom: Two common disynaptic links between A and B are a
serial connection via C (left) and a common input from C. In both cases the effect of the
disynaptic link is the convolution of the underlying monosynaptic links.

275

This relation means that the probability that a spike in cell A will
produce a correlated spike in cell B would be the product of the two
probabilities for the intervening monosynaptic connections. Given a typical
Np of .Ol/EPSP, this would reduce the effectiveness of a given disynaptic
linkage by two orders of magnitude relative to a monosynaptic connection.
However, the net strength of all the disynaptic linkages between two given
cells is proportional to the number of mediating intemeurons (C}, since the
effects of parallel pathways add. Thus, the net potency of all the disynaptic
linkages between two cells could approach that of a monosynaptic linkage if
the number of mediating interneurons were sufficiently large. It should also
be noted that some intemeurons may fire more than once per EPSP and have
a higher probability of being triggered to fire than motoneurons 11.
For completeness, two other possible disynaptic links between A and B
involving a third cell C may be considered. One is a serial connection from B
to C to A, which is the reverse of the serial connection from A to B. This
would produce a P2(BIA) with peak to the left of the origin. The fourth
circuit involves convergent connections from both A and B to C; this is the
only combination that would not produce any causal link between A and B.
The effects of still higher-order polysynaptic linkages can be computed
similarly, by convolving the effects produced by the sequential connections.
For example, trisynaptic linkages between four neurons are equivalent to
combinations of disynaptic and monosynaptic connections.
The cross-correlograms between two cells have a certain symmetry,
depending on which is the reference cell. The cross-correlation histogram of
cell B referenced to A is identical to the time-inverted correlogram of A
referenced to B. This is illustrated for the monosynaptic connection in Fig.2,
top right, but is true for all correlograms. This symmetry represents the fact
that the above-chance probability of B firing after A is the same as the
probability of A firing before B:
P(BIA, t)

= P(AIB, -t)

(5)

As a consequence, polysynaptic correlational links can be computed as the
same convolution integral (Eq. 4), independent of the direction of impulse
propagation.
P ARALLEL PATHS AND FEEDBACK LOOPS
In addition to the simple combinations of pair-wise connections
between neurons illustrated above, additional connections between the same
cells may form circuits with various kinds of loops. Recurrent connections
can produce feedback loops, whose correlational effects are also calculated by
convolving effects of the underlying synaptic links. Parallel feed-forward
paths can form multiple pathways between the same cells. These produce
correlational effects that are the sum of the effects of the individual
underlying connections.
The simplest feedback loop is formed by reciprocal connections
between a pair of cells. The effects of excitatory feedback can be computed by

276

successive cO?1volutions of the underlying monosynaptic connections (Fig. 3
top). Note that such a positive feedback loop would be capable of sustaining
activity only if the connections were sufficiently potent to ensure
postsynaptic firing. Since the probabilities of triggered firings at a single
synapse are considerably less than one, reverberating activity can be
sustained only if the number of interacting cells is correspondingly increased.
Thus, if the probability for a single link is on the order of .01, reverberating
activity can be sustained if A and B are similarly interconnected with at least
a hundred cells in parallel.
Connections between three neurons may produce various kinds of
loops.
Feedforward parallel pathways are formed when cell A is
monosynaptically connected to B and in addition has a serial disynaptic
connection through C, as illustrated in Fig. 3 (bottom left); the correlational
effects of the two linkages from A to B would sum linearly, as shown for
excitatory connections. Again, the effect of a larger set of cells {C} would be
additive. Feedback loops could be formed with three cells by recurrent
connections between any pair; the correlational consequences of the loop
again are the convolution of the underlying links. Three cells can form
another type loop if both A and B are monosynaptically connected, and
simultaneously influenced by a common interneuron C (Fig. 3 bottom right).
In this case the expected correlogram between A and B would be the sum of
the individual components -- a common input peak around the origin plus a
delayed peak produced by the serial connection.
Feedback loop
1 - - - - -..
'l;---~

...

..../

-',

\....

.... ....

..
I:

'

....

.......

...........""
;'""
........

..?.:....

....
-',

....

?????

'""

???.

Parallel jeedfOrward path

I
I
:

t
t
t

Common input loop

I
t
PI (BIA) +P 2 (BIA)

PI (BIA)+P

2

(BIA)

:/\ ____

___.;.J

l~

Fig. 3. Correlational effects of parallel connections between two neurons. Top: feedback
loop between two neurons A and B produces higher-order effects equivalent to convolution
of mono~aptic effects. Bottom: Loops formed by parallel feed forward paths (left) and by a
common mput concurrent with a monosynaptic link (right) produce additive effects.

277

CONCLUSIONS
Thus, a simple computational algebra can be used to derive the
correlational effects of a given network structure. Effects of sequential
connections can be computed by convolution and effects of parallel paths by
summation. The inverse problem, of deducing the circuitry from the
correlational data is more difficult, since similar correlogram features may be
produced by different circuits 9.
The fact that monosynaptic links produce small correlational effects on
the order of .01 represents a significant constraint in the mechanisms of
information processing in real neural nets. For example, secure propagation
of activity through serial polysynaptic linkages requires that the small
probability of triggered firing via a given link is compensated by a
proportional increase in the number of parallel links. Thus, reliable serial
conduction would require hundreds of neurons at each level, with
appropriate divergent and convergent connections. It should also be noted
that the effect of intemeurons can be modulated by changing their activity.
The intervening cells need to be active to mediate the correlational effects. As
indicated by eq. I, the size of the correlogram peak is proportional to the
firing rate (fo) of the postsynaptic cell. This allows dynamic modulation of
polysynaptic linkages. The greater the number of links, the more susceptible
they are to modulation.
Acknowledgements: The author thanks Mr. Garrett Kenyon for stimulating
discussions and the cited colleagues for collaborative efforts. This work was
supported in part by Nll-I grants NS 12542 and RR00166.
REFERENCES
1. Bishop, B., Reyes, A.D., and Fetz E.E., Soc. for Neurosci Abst. 11:157 (1985).
2. Cope, T.C., Fetz, E.E., and Matsumura, M., J. Physiol. 390:161-18 (1987).
3. Fetz, E.E. and Cheney, P.D., J. Neurophysiol. 44:751-772 (1980).
4. Fetz, E.E. and Gustafsson, B., J. Physiol. 341:387-410 (1983).
5. Gustafsson, B., and McCrea, D., J. Physiol. 347:431-451 (1984).
6. Kirkwood, P.A., J. Neurosci. Meth. 1:107-132 (1979).
7. Kirkwood, P.A., and Sears, T._ J. Physiol. 275:103-134 (1978).
8. Knox, C.K., Biophys. J. 14: 567-582 (1974).
9. Moore, G.P., Segundo, J.P., Perkel, D.H. and Levitan, H., Biophys. J. 10:876900 (1970).
10. Reyes, A.D., Fetz E.E. and Schwindt, P.C., Soc. for Neurosci Abst. 13:157
(1987).
11. Surmeier, D.J. and Weinberg, R.J., Brain Res. 331:180-184 (1985).

"
16,1987,"Network Generality, Training Required, and Precision Required","",16-network-generality-training-required-and-precision-required.pdf,"Abstract Missing","219

Network Generality, Training Required,
and PrecisIon Required
John S. Denker and Ben S. Wittner
AT&T Bell Laboratories
Holmdel, New Jersey 07733

1

Keep your hand on your wallet.
- Leon Cooper, 1987

Abstract
We show how to estimate (1) the number of functions that can be implemented by a
particular network architecture, (2) how much analog precision is needed in the connections in the network, and (3) the number of training examples the network must see
before it can be expected to form reliable generalizations.

Generality versus Training Data Required
Consider the following objectives: First, the network should be very powerful and versatile, i.e., it should implement any function (truth table) you like, and secondly, it
should learn easily, forming meaningful generalizations from a small number of training
examples. Well, it is information-theoretically impossible to create such a network. We
will present here a simplified argument; a more complete and sophisticated version can
be found in Denker et al. (1987).
It is customary to regard learning as a dynamical process: adjusting the weights (etc.)
in a single network. In order to derive the results of this paper, however, we take
a different viewpoint, which we call the ensemble viewpoint. Imagine making a very
large number of replicas of the network. Each replica has the same architecture as the
original, but the weights are set differently in each case. No further adjustment takes
place; the ""learning process"" consists of winnowing the ensemble of replicas, searching
for the one( s) that satisfy our requirements.

Training proceeds as follows: We present each item in the training set to every network
in the ensemble. That is, we use the abscissa of the training pattern as input to the
network, and compare the ordinate of the training pattern to see if it agrees with the
actual output of the network. For each network, we keep a score reflecting how many
times (and how badly) it disagreed with a training item. Networks with the lowest score
are the ones that agree best with the training data. If we had complete confidence in
lCurrently at NYNEX Science and Technology, 500 Westchester Ave., White Plains, NY 10604

@) American Institute of Physics 1988

220

the reliability of the training set, we could at each step simply throwaway all networks
that disagree.
For definiteness, let us consider a typical network architecture, with No input wires and
Nt units in each processing layer I, for I E {I?? ?L}. For simplicity we assume NL = 1.
We recognize the importance of networks with continuous-valued inputs and outputs,
but we will concentrate for now on training (and testing) patterns that are discrete,
with N == No bits of abscissa and N L = 1 bit of ordinate. This allows us to classify the
networks into bins according to what Boolean input-output relation they implement,
and simply consider the ensemble of bins.
There are 22N jossible bins. If the network architecture is completely general and
powerful, all 22 functions will exist in the ensemble of bins. On average, one expects
that each training item will throwaway at most half of the bins. Assuming maximal
efficiency, if m training items are used, then when m ~ 2N there will be only one bin
remaining, and that must be the unique function that consistently describes all the
data. But there are only 2N possible abscissas using N bits. Therefore a truly general
network cannot possibly exhibit meaningful generalization - 100% of the possible data
is needed for training.
Now suppose that the network is not completely general, so that even with all possible
settings of the weights we can only create functions in 250 bins, where So < 2N. We call
So the initial entropy of the network. A more formal and general definition is given in
Denker et al. (1987). Once again, we can use the training data to winnow the ensemble,
and when m ~ So, there will be only one remaining bin. That function will presumably
generalize correctly to the remaining 2N - m possible patterns. Certainly that function
is the best we can do with the network architecture and the training data we were given.
The usual problem with automatic learning is this: If the network is too general, So
will be large, and an inordinate amount of training data will be required. The required
amount of data may be simply unavailable, or it may be so large that training would be
prohibitively time-consuming. The shows the critical importance of building a network
that is not more general than necessary.

Estimating the Entropy
In real engineering situations, it is important to be able to estimate the initial entropy
of various proposed designs, since that determines the amount of training data that will
be required. Calculating So directly from the definition is prohibitively difficult, but we
can use the definition to derive useful approximate expressions. (You wouldn't want to
calculate the thermodynamic entropy of a bucket of water directly from the definition,
either. )

221

Suppose that the weights in the network at each connection i were not continuously
adjustable real numbers, but rather were specified by a discrete code with bi bits. Then
the total number of bits required to specify the configuration of the network is

(1)
Now the total number offunctions that could possibly be implemented by such a network
architecture would be at most 2B. The actual number will always be smaller than this,
since there are various ways in which different settings of the weights can lead to identical
functions (bins). For one thing, for each hidden layer 1 E {1??? L-1}, the numbering of
the hidden units can be permuted, and the polarity of the hidden units can be flipped,
which means that 2 50 is less than 2B by a factor (among others) of III Nl! 2N ,. In
addition, if there is an inordinately large number of bits bi at each connection, there
will be many settings where small changes in the connection will be immaterial. This
will make 2 so smaller by an additional factor. We expect aSO/abi ~ 1 when bi is small,
and aSO/ab i ~ 0 when bi is large; we must now figure out where the crossover occurs.
The number of ""useful and significant"" bits of precision, which we designate b*, typically
scales like the logarithm of number of connections to the unit in question. This can be
understood as follows: suppose there are N connections into a given unit, and an input
signal to that unit of some size A is observed to be significant (the exact value of A
drops out of the present calculation). Then there is no point in having a weight with
magnitude much larger than A, nor much smaller than A/N. That is, the dynamic
range should be comparable to the number of connections. (This argument is not exact,
and it is easy to devise exceptions, but the conclusion remains useful.) If only a fraction
1/ S of the units in the previous layer are active (nonzero) at a time, the needed dynamic
range is reduced. This implies b* ~ log(N/S).
Note: our calculation does not involve the dynamics of the learning process. Some
numerical methods (including versions of back propagation) commonly require a number
of temporary ""guard bits"" on each weight, as pointed out by llichard Durbin (private
communication). Another log N bits ought to suffice. These bits are not needed after
learning is complete, and do not contribute to So.
If we combine these ideas and apply them to a network with N units in each layer, fully
connected, we arrive at the following expression for the number of different Boolean
functions that can be implemented by such a network:

(2)
where
B ~ LN 2 log N

(3)

These results depend on the fact that we are considering only a very restricted type of
processing unit: the output is a monotone function of a weighted sum of inputs. Cover

222

(1965) discussed in considerable depth the capabilities of such units. Valiant (1986) has
explored the learning capabilities of various models of computation.
Abu-Mustafa has emphasized the principles of information and entropy and applied
them to measuring the properties of the training set. At this conference, formulas
similar to equation 3 arose in the work of Baum, Psaltis, and Venkatesh, in the context
of calculating the number of different training patterns a network should be able to
memorize. We originally proposed equation 2 as an estimate of the number of patterns
the network would have to memorize before it could form a reliable generalization. The
basic idea, which has numerous consequences, is to estimate the number of (bins of)
networks that can be realized.

References
1. Vasser Abu-Mustafa, these proceedings.

2. Eric Baum, these proceedings.
3. T. M. Cover, ""Geometrical and statistical properties of systems of linear inequalities with applications in pattern recognition,"" IEEE Trans. Elec. Comp., EC-14,
326-334, (June 1965)
4. John Denker, Daniel Schwartz, Ben Wittner, Sara Solla, John Hopfield, Richard
Howard, and Lawrence Jackel, Complex Systems, in press (1987).
5. Demetri Psaltis, these proceedings.
6. 1. G. Valiant, SIAM J. Comput. 15(2), 531 (1986), and references therein.
7. Santosh Venkatesh, these proceedings.

"
17,1987,"Learning a Color Algorithm from Examples","",17-learning-a-color-algorithm-from-examples.pdf,"Abstract Missing","622

LEARNING A COLOR ALGORITHM FROM EXAMPLES
Anya C. Hurlbert and Tomaso A. Poggio
Artificial Intelligence Laboratory and Department of Brain and Cognitive Sciences,
Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA
ABSTRACT
A lightness algorithm that separates surface reflectance from illumination in a
Mondrian world is synthesized automatically from a set of examples, pairs of input
(image irradiance) and desired output (surface reflectance). The algorithm, which resembles a new lightness algorithm recently proposed by Land, is approximately equivalent to filtering the image through a center-surround receptive field in individual chromatic channels. The synthesizing technique, optimal linear estimation, requires only
one assumption, that the operator that transforms input into output is linear. This
assumption is true for a certain class of early vision algorithms that may therefore be
synthesized in a similar way from examples. Other methods of synthesizing algorithms
from examples, or ""learning"", such as backpropagation, do not yield a significantly different or better lightness algorithm in the Mondrian world. The linear estimation and
backpropagation techniques both produce simultaneous brightness contrast effects.

The problems that a visual system must solve in decoding two-dimensional images
into three-dimensional scenes (inverse optics problems) are difficult: the information
supplied by an image is not sufficient by itself to specify a unique scene. To reduce
the number of possible interpretations of images, visual systems, whether artificial
or biological, must make use of natural constraints, assumptions about the physical
properties of surfaces and lights. Computational vision scientists have derived effective
solutions for some inverse optics problems (such as computing depth from binocular
disparity) by determining the appropriate natural constraints and embedding them in
algorithms. How might a visual system discover and exploit natural constraints on its
own? We address a simpler question: Given only a set of examples of input images and
desired output solutions, can a visual system synthesize. or ""learn"", the algorithm that
converts input to output? We find that an algorithm for computing color in a restricted
world can be constructed from examples using standard techniques of optimal linear
estimation.
The computation of color is a prime example of the difficult problems of inverse
optics. We do not merely discriminate betwN'n different wavelengths of light; we assign

@ American Institute of Physics 1988

623

roughly constant colors to objects even though the light signals they send to our eyes
change as the illumination varies across space and chromatic spectrum. The computational goal underlying color constancy seems to be to extract the invariant surface
spectral reflectance properties from the image irradiance, in which reflectance and iI-""
lumination are mixed 1 ?
Lightness algorithms 2-8, pioneered by Land, assume that the color of an object
can be specified by its lightness, or relative surface reflectance, in each of three independent chromatic channels, and that lightness is computed in the same way in each
channel. Computing color is thereby reduced to extracting surface reflectance from the
image irradiance in a single chromatic channel.
The image irra.diance, s', is proportional to the product of the illumination intensity e' and the surface reflectance r' in that channel:

s' (x, y) = r' (x, y )e' (x, y).
(1 )
This form of the image intensity equation is true for a Lambertian reflectance model,
in which the irradiance s' has no specular components, and for appropriately chosen
color channels 9. Taking the logarithm of both sides converts it to a sum:
s(x, y) = rex, y)

+ e(x,y),

(2)

where s = loges'), r = log(r') and e = log(e').
Given s(x,y) alone, the problem of solving Eq. 2 for r(x,y) is underconstrained.
Lightness algorithms constrain the problem by restricting their domain to a world of
Mondrians, two-dimensional surfaces covered with patches of random colors 2 and by
exploiting two constraints in that world: (i) r'(x,y) is unifonn within patches but
has sharp discontinuities at edges between patches and (ii) e' (x, y) varies smoothly
across the Mondrian. Under these constraints, lightness algorithms can recover a good
approximation to r( x, y) and so can recover lightness triplets that label roughly constant
colors 10.
We ask whether it is possible to synthesize from examples an algorithm that ex?
tracts reflectance from image irradiance. and whether the synthesized algorithm will resemble existing lightness algorithms derived from an explicit analysis of the constraints.
We make one assumption, that the operator that transforms irradiance into reflectance
is linear. Under that assumption, motivated by considerations discussed later, we use
optimal linear estimation techniques to synthesize an operator from examples. The
examples are pairs of images: an input image of a Mondrian under illumination that
varies smoothly across space and its desired output image that displays the reflectance
of the Mondrian without the illumination. The technique finds the linear estimator
that best maps input into desired output. in the least squares sense.
For computational convenience we use one-dimensional ""training vectors"" that
represent vertical scan lines across the ~londrian images (Fig. 1). We generate many

624

1S0t? -~
? ~

100 ,

'.

a

,

~~~--------------~~--~--~~
SO
100
110
100
llO
100
lilt.,

Input d.t.

i;[:2:=:0
a

SO

101

ISO

ZOO

UI

:~kfhJfEirQ b
0

)01

II

100

ISO

100

110

p/Jte'

f~l
o

50

100

UO

ZOO

ZSO

100

I""'""

c

)00

.1

p,xe'

100

ISO

100

110

lot

p'.""

OlltPllt lIlll.l . .ll.a

Fig. 1. (a) The input data, a one-dimensional vector 320 pixels long. Its random
Mondrian reflectance pattern is superimposed on a linear illumination gradient with
a random slope and offset. (b) shows the corresponding output solution, on the left
the illumination and on the right reBectance. We used 1500 such pairs of inputoutput examples (each different from the others) to train the operator shown in Fig.
2. (c) shows the result obtained by the estimated operator when it acts on the input
data (a), not part of the training set. On the left is the illumination and on the
right the reflectance, to be compared with (b). This result is fairly typical: in some
cases the prediction is even better, in others it is worse.
different input vectors s by adding together different random T and e vectors, according
to Eq. 2. Each vector r represents a pattern of step changes across space, corresponding
to one column of a reHectance image. The step changes occur at random pixels and
are of random amplitude between set minimum and maximum values. Each vector t
represents a smooth gradient across space with a random offset and slope, correspondin~
to one column of an illumination image. We th~n arrange the training vectors sand r
as the columns of two matrices Sand R, resp~ti?.. ely. Our goal is then to compute the
optimal solution L of

LS

=R

where L is a linear operator represented as a matrix.

625

It is well known that the solution of this equation that is optimal in the least

squares sense is

( 4)
where S+ is the Moore-Penrose pseudoinverse 11. We compute the pseudoinverse by
overconstraining the problem - using many more training vectors than there are number
of pixels in each vector - and using the straightforward formula that applies in the
overconstrained case 12: S+ ST(SST)-l.
The operator L computed in this way recovers a good approximation to the correct
output vector r when given a new s, not part of the training set, as input (Fig. Ic).
A second operator, estimated in the same way, recovers the illumination e. Acting on
a random two-dimensional Mondrian L also yields a satisfactory approximation to the
correct output image.
Our estimation scheme successfully synthesizes an algorithm that performs the
lightness computation in a Mondrian world. What is the algorithm and what is its
relationship to other lightness algorithms? To answer these questions we examine the
structure of the matrix L. We assume that, although the operator is not a convolution
operator, it should approximate one far from the boundaries of the image. That is,
in its central part, the operator should be space-invariant, performing the same action
on each point in the image. Each row in the central part of L should therefore be
the same as the row above but displaced by one element to the right. Inspection of
the matrix confirmes this expectation. To find the form of L in its center, we thus
average the rows there, first shifting them appropriately. The result, shown in Fig. 2,
is a space-invariant filter with a narrow positive peak and a broad, shallow, negative
surround.
Interestingly, the filter our scheme synthesizes is very similar to Land's most recent
retinex operator 5, which divides the image irradiance at each pixel by a weighted
average of the irradiance at all pixels in a large surround and takes the logarithm of
that result to yield lightness 13. The lightness triplets computed by the retinex operator
agree well with human perception in a Mondrian world. The retinex operator and our
matrix L both differ from Land's earlier retinex algorithms, which require a non-linear
thresholding step to eliminate smooth gradients of illumination.
The shape of the filter in Fig. 2, particularly of its large surround, is also suggestive of the ""nonclassical"" receptive fields that have been found in V4, a cortical area
implicated in mechanisms underlying color constancy 14-17.
The form of the space-invariant filter is similar to that derived in our earlier formal
analysis of the lightness problem 8. It is qualitatively the same as that which results
from the direct application of regularization methods exploiting the spatial constraints
on reflectance and illumination described above 9.18.19. The Fourier transform of the
filter of Fig. 2 is approximately a bandpass filter that cuts out low frequencies due

=

626

~

0

( .)

~

C'
C

-

-80

s::.

0
Pi xe Is

.2'

~

a

-80

-----------

o

+80

Pixels
Fig. 2. The space-invariant part of the estimated operator, obtained by shifting and
averaging the rows of a 160-pixel-wide central square of the matrix L, trained on a set
of 1500 examples with linear illumination gradients (see Fig. 1). When logarithmic
illumination gradients are used , a qualitatively similar receptive field is obtained. In
a separate experiment we use a training set of one-dimensional Mondrians with either
linear illumination gradients or slowly varying sinusoidal illumination components
with random wavelength, phase and amplitude. T he resulting filter is shown in
the inset. The surrounds of both filters extend beyond the range we can estimate
reliably, the range we show here.
to slow gradients of illumination and preserves intennediate frequencies due to step
changes in reflectance. In contrast, the operator that recovers the illumination, e.
takes the form of a low-pass filter. \Ve stress that the entire operator L is not a
space-invariant filter.
In this context, it is clear that the shape of the estimated operator should vary with
the type of illumination gradient in the training set. We synthesize a second operator
using a new set of examples that contain equal numbers of vectors with random, sinusoidally varying illumination components and VE""(tors with random, linear illumination
gradients. Whereas the first operator, synthE.>Sized from examples with strictly linear
illumination gradients, has a broad negative surround that remains virtually constant
throughout its extent, the new operator's surround (Fig . 2, inset) has a smaller ext(,111

627

and decays smoothly towards zero from its peak negative value in its center.
We also apply the operator in Fig. 2 to new input vectors in which the density
and amplitude of the step changes of reflectance differ greatly from those on which the
operator is trained. The operator performs well, for example, on an input vector representing one column of an image of a small patch of one reflectance against a uniform
background of a different reflectance, the entire image under a linear illumination gradient. This result is consistent with psychophysical experiments that show that color
constancy of a patch holds when its Mondrian background is replaced by an equivalent
grey background 20.
The operator also produces simultaneous brightness contrast, as expected from the
shape and sign of its surround. The output reflectance it computes for a patch of fixed
input reflectance decreases linearly with increasing average irradiance of the input test
vector in which the patch appears. Similarly, to us, a dark patch appears darker when
against a light background than against a dark one.
This result takes one step towards explaining such illusions as the Koffka Ring 21.
A uniform gray annulus against a bipartite background (Fig. 3a) appears to split into
two halves of different lightnesses when the midline between the light and dark halves
of the background is drawn across the annulus (Fig. 3b). The estimated operator
acting on the Koffka Ring of Fig. 3b reproduces our perception by assigning a lower
output reflectance to the left half of the annulus (which appears darker to us) than to
the right half 22. Yet the operator gives this brightness contrast effect whether or not
the midline is drawn across the annulus (Fig. 3c). Becau~e the opf'rator can perform
only a linear transformation between the input and output images, it is not surprising
that the addition of the midline in the input evokes so little change in the output.
These results demonstrate that the linear operator alone cannot compute lightness in
all worlds and suggest that an additional operator might be necessary to mark and
guide it within bounded regions.
Our estimation procedure is motivated by our previous observation 9.23,18 that
standard regularization algorithms 19 in early vision define linear mappings between
input and output and therefore can be estimated associatively under certain condi?
tions. The technique of optimal linear estimation that we use is closely related to
optimal Bayesian estimation 9. If we were to assume from the start that the optimal
linear operator is space-invariant, we could considerably simplify (and streamline) the
computation by using standard correlation te<:hniques 9.24.
How does our estimation technique compare with other methods of ""learning"" a
lightness algorithm? We can compute the r~ularized pseudoinverse using gradient
descent on a ""neural"" network 25 with linf'ar units. Since the pseudoinverse is lhf""
unique best linear approximation in the L1 norm. a gradient descent method that

628

minimizes the square error between the actual output and desired output of a fully
connected linear network is guaranteed to converge, albeit slowly. Thus gradient descent in weight space converges to the same result as our first technique, the global
minimum.

b

a

c

.n

sa

0
.It

.sa

_

ut

_

input data

pixel

...~~

~:==
:iu II ...

,,

e.

sa

.

~

-

~

.

_

.

ut

_

output reflectance - with edge

~'~
...:i'I~~
I'
_ . .'
- ..

=..
e. ""
~.

.

_
I

~

~

(

ut

,

_

output reflectance - without edge

Fig. 3. (a) Koffka Ring. (b) Koftka Ring with
midline drawn across annulus. (c) Horizontal
scan lines across Koffka Ring.
Top: Scan
line starting at arrow in (b).
Middle: Scan
line at corresponding location in the output of
linear operator acting on (b). Bottom: Scan line
at same location in the output of operator acting
on (a).

629

We also compare the linear estimation technique with a ""backpropagation"" network: gradient descent on a 2-layer network with sigmoid units 25 (32 inputs, 32
""hidden units"", and 32 linear outputs), using training vectors 32 pixels long. The network requires an order of magnitude more time to converge to a stable configuration
than does the linear estimator for the same set of 32-pixel examples. The network's
performance is slightly, yet consistently, better, measured as the root-mean-square error in output, averaged over sets of at least 2000 new input vectors. Interestingly, the
backpropagation network and the linear estimator err in the same way on the same
input vectors. It is possible that the backpropagation network may show considerable
inprovement over the linear estimator in a world more complex than the Mondrian one.
We are presently examining its performance on images with real-world features such
as shading, shadows, and highlights26.
We do not think that our results mean that color constancy may be learned during
a critical period by biological organisms. It seems more reasonable to consider them
simply as a demonstration on a toy world that in the course of evolution a visual system
may recover and exploit natural constraints hidden in the physics of the world. The
significance of our results lies in the facts that a simple statistical technique may be used
to synthesize a lightness algorithm from examples; that the technique does as well as
other techniques such as backpropagation; and that a similar technique may be used for
other problems in early vision. Furthermore, the synthesized operator resembles both
Land's psychophysically-tested retinex operator and a neuronal nonclassical receptive
field. The operator's properties suggest that simultaneous color (or brightness) contrast
might be the result of the visual system's attempt to discount illumination gradients
27

REFERENCES AND NOTES
1. Since we do not have perfect color constancy, our visual system must not extract
reflectance exactly. The limits on color constancy might reveal limits on the underlying
computation.

2.
3.
4.
and S.
5.
6.

E.H. Land, Am. Sci. 52,247 (1964).
E.H. Land and J.J. McCann, J. Opt. Soc. Am. 61, 1 {1971}.
E.H. Land, in Central and Peripheral Mechanisms of Colour Vision, T. Ottoson
Zeki, Eds., (Macmillan, New York, 1985), pp. 5-17.
E.H. Land, Proc. Nat. Acad. Sci. USA 83, 3078 (1986).
B.K.P. Hom, Computer Graphics and Image Processing 3, 277 (1974).

630

7. A. Blake, in Central and Peripheral Mechanisms of Colour Vision, T. Ottoson
and S. Zeki, Eds., (Macmillan, New York, 1985), pp. 45-59.
8. A. Hurlbert, J. Opt. Soc. Am. A 3,1684 (1986).
9. A. Hurlbert and T. Poggio, ArtificiaLIntelligence Laboratory Memo 909, (M.LT.,
Cambridge, MA, 1987).
10. r'{x,y) can be recovered at best only to within a constant, since Eq. 1
is invariant under the transformation of r' int.o ar' and e' into a-ie', where a is a
constant.
11. A. Albert, Regression and the Moore-Penrose Pseudoinllerse, (Academic Press,
New York, 1972).
12. The pseudoinverse, and therefore L, may also be computed by recursive techniques that improve its form as more data become available l l .
13. Our synthesized filter is not exactly identical with Land's: the filter of Fig.
2 subtracts from the value at each point the average value of the logarithm of irradiance at all pixels, rather than the logarithm of the average values. The estimated
operator is therefore linear in the logarithms, whereas Land's is not. The numerical
difference between the outputs of the two filters is small in most cases (Land, personal
communication), and both agree well with psychophysical results.
14. R. Desimone, S.J. Schein, J. Moran and L.G. Ungerleider, Vision Res. 25,
441 (1985).
15. H.M. Wild, S.R. Butler, D. Carden and J.J. Kulikowski, Nature (London) 313,
133 (1985).
16. S.M. Zeki, Neuroscience 9, 741 (1983).
17. S.M. Zeki, Neuroscience 9, 767 (1983).
18. T. Poggio, et. al, in Proceedings Image Understanding Workshop, L. Baumann, Ed., (Science Applications International Corporation, McLean, VA, 1985), pp.'
25-39.
19. T. Poggio, V. Torre and C. Koch, Nature (London) 317,314 (1985).
20. A. Valberg and B. Lange-Malecki, Investigative Ophthalmology and Visual
Science Supplement 28, 92 (1987).
21. K. Koffka, Principles of Gestalt Psychology, (Harcourt, Brace and Co., New
York, 1935).
22. Note that the operator achieves this effect by subtracting a non-existent illumination gradient from the input signal.
23. T. Poggio and A. Hurlbert, Artificial Intelligence Laboratory Working Paper
264, (M.LT., Cambridge, MA, 1984).
24. Estimation of the operator on two-dimensional examples is possible, but computationally very expensive if done in the same way. The present computer simulations
require several hours when run on standard serial computers. The two-dimensional case

631

will need much more time (our one-dimensional estimation scheme runs orders of magnitude faster on a CM-1 Connection Machine System with 16K-processors).
25. D. E. Rumelhart, G.E. Hinton and R.J. Williams, Nature (London) 323, 533
(1986 ).
26. A. Hurlbert, The Computation of Color, Ph.D. Thesis, M.l. T., Cambridge,
MA, in preparation.
2i. We are grateful to E. Land, E. Hildreth, .J. Little, F. Wilczek and D. Hillis
for reading the draft and for useful discussions. A. Rottenberg developed the routines
for matrix operations that we used on the Connection Machine. T. Breuel wrote the
backpropagation simulator.

"
18,1987,"Programmable Synaptic Chip for Electronic Neural Networks","",18-programmable-synaptic-chip-for-electronic-neural-networks.pdf,"Abstract Missing","564

PROGRAMMABLE SYNAPTIC CHIP FOR
ELECTRONIC NEURAL NETWORKS
A. Moopenn, H. Langenbacher, A.P. Thakoor, and S.K. Khanna
Jet Propulsion Laboratory
California Institute of Technology
Pasadena, CA 91009
ABSTRACT
A binary synaptic matrix chip has been developed for electronic
neural networks. The matrix chip contains a programmable 32X32
array of ""long channel"" NMOSFET binary connection elements implemented in a 3-um bulk CMOS process. Since the neurons are kept offchip, the synaptic chip serves as a ""cascadable"" building block for
a multi-chip synaptic network as large as 512X512 in size.
As an
alternative to the programmable NMOSFET (long channel) connection
elements, tailored thin film resistors are deposited, in series with
FET switches, on some CMOS test chips, to obtain the weak synaptic
connections.
Although deposition and patterning of the resistors
require additional
processing steps, they promise substantial
savings in silcon area. The performance of a synaptic chip in a 32neuron breadboard system in an associative memory test application
is discussed.
INTRODUCTION
The highly parallel and distributive architecture of neural
networks offers potential advantages in fault-tolerant and high
speed associative information processing. For the past few years,
there has been a growing interest in developing electronic hardware
to investigate the computational
capabilities and application
potential of
neural networks as well as their dynamics and
collective propertiesl - 5 ? In an electronic hardware implementation
of neural networks6 ? 7 r the neurons (analog processing units) are
represented by threshold amplifiers and the synapses linking the
neurons by a resistive connection network. The synaptic strengths
between neurons (the electrical resistance of the connections)
represent the stored information or the computing function of the
neural network.
Because of the massive interconectivity of the neurons and the
large number of the interconnects required with the increasing
number of neurons, implementation of a synaptic network using
current LSI/VLSI technology can become very difficult. A synaptic
network based on a multi-chip architecture would lessen this
difficulty.
He have designed, fabricated, and successfully tested
CMOS-based programmable synaptic chips which could serve as basic
"" cascadabl e"" building blocks for a multi-chip electronic neural
network. The synaptic chips feature complete programmability of
1024, (32X32) binary synapses.
Since the neurons are kept offchip, the synaptic chips can be connected in parallel, to obtain
multiple grey levels of the connection strengths, as well as
? American Institute of Physics 1988

565

""cascaded"" to form larger synaptic arrays for an expansion to a 512neuron system in a feedback or feed-forward architecture. As a
research tool, such a system would offer a significant speed
software-based neural network
improvement
over
conventional
simulations since convergence times for the parallel hardware system
would be significantly smaller.
In this paper, we describe the basic design and operation of
synaptic CMOS chips incorporating MOSFET's as binary connection
elements.
The design and fabrication of synaptic test chips with
tailored thin film resistors as ballast resistors for controlling
power dissipation are also described.
Finally, we describe a
synaptic chip-based 32-neuron breadboard system in a feedback
configuration and discuss its performance in an associative memory
test application.
BINARY SYNAPTIC CMOS CHIP WITH MOSFET CONNECTION ELEMENTS
There are two important design requirements for a binary
connection element in a high density synaptic chip. The first
requirement is that the connection in the ON state should be ""weak""
to ensure low overall power dissipation.
The required degree of
""weakness"" of the ON connection largely depends on the synapse
density of the chip. If, for example, a synapse density larger than
1000 per chip is desired, a dynamic resistance of the ON connection
should be greater than ~100 X-ohms. The second requirement is that
to obtain grey scale synapses with up to four bits of precision from
binary connections, the consistency of the ON state connection
resistance must be better than +/-5 percent, to ensure proper
threshold operation of the neurons.
Both of the requirements are
generally difficult to satisfy simultaneously in conventional VLSI
CMOS technology.
For example, doped-polysilicon resistors could be
used to provide the weak connections, but they are difficult to
fabricate with a resistance uniformity of better than 5 percent.
We have used NMOSFET's as connection elements in a multi-chip
synaptic network. By designing the NMOSFET's with long channel,
both the required high uniformity and high ON state resistance have
been obtained. A block diagram of a binary synaptic test chip
incorporating NMOSFET's as programmable connection elements is shown
in Fig. 1. A photomicrograph of the chip is shown in Fig. 2.
The
synaptic chip was fabricated through MOSIS (MOS Implementation
bulk CMOS,
two-level metal, P-well
Service) in a 3-micron,
technology.
The chip contains 1024 synaptic cells arranged in a
32X32 matrix configuration.
Each cell consists of a long channel
NMOSFET connected in series with another NMOSFET serving as a simple
ON/OFF switch. The state of the FET switch is controlled by the
output of a latch which can be externally addressed via the ROW/COL
address decoders.
The 32 analog input lines (from the neuron
outputs) and 32 analog output lines (to the neuron inputs) allow a
number of such chips to be connected together to form larger
connection matrices with up to 4-bit planes.
The long channel NMOSFET can function as either a purely
resistive or a constant current source connection element, depending

566

FROM NEURON OUTPUTS

1 ??? 32

vG ______~~~----~~----_=~
~-.--a. ....

Ur-C~

/I6-A9

\

AOOR
OECOOER

SETRST

--------I

\

. .

ROW~V~
C~

.\
.\
.

S

? \ RST

R

. ::-Q

??????????????? ? ? 1 1
??
?

0

.

32

TO
NEURON
INPUTS

?

I L -----d I
6=. . . . . =a
AO-M

Figure 1.
Block diagram of a 32X32 binary synnaptic chip with long
channel NMOSFETs as connection elements .

...

~'

.

,,)

.,.

,""

Figure 2. Photomicrographs of a 32X32 binary connection CMOS chip.
The blowup on the right shows several synaptic cells; the ""S""-shape
structures are the long-channel NMOSFETs.
on whether analog or binary output neurons are used. As a resistive
connection. the NMOSFET's must operate in the linear region of the
transistor's drain I-V characteristics. In the linear region. the
channel resistance is approximately given byB
Ro N

=

(11K)

(LIN)

(VG - VT H ) -

1 ?

567

Here, K is a proportionality constant which depends on process
parameters, Land Ware the channel length and width respectively,
VG is the gate voltage, and VTH is the threshold voltage. The
transistor acts as a linear resistor provided the voltage across the
channel is much less than the difference of the gate and threshold
voltages, and thus dictates the operating voltage range of the
connection.
The NMOSFET's presently used in our synaptic chip
design have a channel length of 244 microns and width of 12 microns.
At a gate voltage of 5 volts, a channel resistance of about 200 Kohms was obtained over an operating voltage range of 1.5 volts. The
consistency of the transistor I-V characteristics has been verified
to be within +/-3 percent in a single chip and +/-5 percent for
chips from different fabrication runs.
In the latter case, the
transistor characteristics in the linear region can be further
matched to within +/-3% by the fine adjustment of their common gate
bias.
With two-state neurons, current source connections may be used
by operating the transistor in the saturation mode. Provided the
voltage across the channel is greater than (VG - VTH), the
transistor behaves almost as a constant current source with the
saturation current given approximately byB
ION = K (W/L)

(VG - VTH)2 .

With the appropriate selection of L, W, and VG, it is possible to
obtain ON-state currents which vary by two orders of magnitude in
values. Figure 3 shows a set of measured I-V curves for a NMOSFET
with the channel dimensions, L= 244 microns and W=12 microns and
applied gate voltages from 2 to 4.5 volts.
To ensure constant
current source operation, the neuron's ON-state output should be
greater than 3.5 volts. A consistency of the ON-state currents to
within +/-5 percent has similarly been observed in a set of chip
samples. With current source connections therefore, quantized grey
scale synapses with up to 16 grey levels (4 bits) can be realized
using a network of binary weighted current sources.
Figure 3. I-V characteristics of
an NMOSFET connection element.
L=244 urn,
Channel
dimension:
W=12um

For proper operation of the NMOSFET connections, the analog
output lines (to neuron inputs) should always be held close to
ground potential. Moreover, the voltages at the analog input lines
must be at or above ground potential.
Since the current normally

568

flows from the analog input to the output, the NMOSFET's may be used
as either all excitatory or inhibitory type connections.
However,
the complementary connection function can be realized using long
For a PMOSFET
channel PMOSFET's in series with PMOSFET switches.
connection, the voltage of an analog input line would be at or below
ground. Furthermore, due to the difference in the mobilites of
electrons and holes in the channel, a PMOSFET used as a resistive
connection has a channel resistance about twice as large as an
NMOSFET with the same channel dimension.
This fact results in a
subtantial reduction in the size of PMOSFET needed.
THIN FILM RESISTOR CONNECTIONS
The use of MOSFET's as connection elements in a CMOS synaptic
matrix chip has the major advantage that the complete device can be
readily fabricated in a conventional CMOS production run. However,
the main disadvantages are the large area (required for the long
channel) for the MOSFET's connections and their non-symmetrical
inhibitory/excitatory functional characteristics. The large overall
gate area not only substantially limits the number of synapses that
can be fabricated on a single chip, but the transistors are more
susceptible to processing defects which can lead to excessive gate
leakage and thus reduce chip yield considerably.
An alternate
approach is simply to use resistors in place of MOSFET's. We have
investigated one such approach where thin film resistors are
deposited on top of the passivation layer of CMOS-processed chips as
an additional special processing step to the normal CMOS fabrication
run.
With an appropriate choice of resistive materials, a dense
array of resistive connections with highly uniform resistance of up
to 10 M-ohms appears feasible.
Several candidate materials, including a cermet based on
platinum/aluminum oxide, and amorphous semiconductor/metal alloys
such as a-Ge:Cu and a-Ge:Al, have been examined for their applicability as thin film resistor connections.
These materials are of
particular interest since their resistivity can easily be tailored
in the desired semiconducting range of 1-10 ohm-cm by controlling
the metal content'.
The a-Ge/metal films are deposited by thermal
evaporation of presynthesized alloys of the desired composition in
high vacuum, whereas platinum/aluminum oxide films are deposited by
co-sputtering from platinum and aluminum oxide targets in a high
purity argon and oxygen gas mixture. Room temperature resistivities
in the 0.1 to 100 ohm-cm range have been obtained by varying the
metal content in these materials.
Other factors which would also
determine their suitability include their device processing and
material compatibilities and their stability with time, temperature, and extended application of normal operating electric current.
The temperature coefficient of resistance (TCR) of these materials
at room temperature has been measured to be in the 2000 to 6000 ppm
range.
Because of their relatively high TCR's, the need for weak
connections to reduce the effect of localized heating is especially
important here.
The a-Ge/metal alloy films are observed to be
relatively stable with exposure to air for temperatures below 130o C.

569

The platinum/aluminum oxide film stabilize with time after annealing
in air for several hours at 130o C.
Sample test arrays
of thin film resistors based on the
described materials have been fabricated to test their consistency.
The resistors, with a nominal resistance of 1 M-ohm, were deposited
on a glass substrate in a 40X40 array over a O.4cm by O.4cm area.
Variation in the measured resistance in these test arrays has been
found to be from +/- 2-5 percent for all three materials. Smaller
test arrays of a-Ge:Cu thin film resistors on CMOS test chips have
also been fabricated.
A photo-micrograph of a CMOS synaptic test
chip containing a 4X4 array of a-Ge:Cu thin film resistors is shown
in Fig. 4.
Windows in the passivation layer of silicon nitride
(SiN) were opened in the final processing step of a normal CMOS
fabrication run to provide access to the aluminum metal for
electrical contacts. A layer of resistive material was deposited
and patterned by lift-off.
A layer of buffer metal of platinum or
nickel was then deposited by RF sputtering and also patterned by
lift-off.
The buffer metal pads serve as a conducting bridges for
connecting the aluminum electrodes to the thin film resistors. In
addition to providing a reliable ohmic contact to the aluminum and
resistor, it also provides conformal step coverage over the silicon
nitride window edge. The resistor elements on the test chip are 100
micron long, 10 micron wide with a thickness of about 1500 angstroms
and a nominal resistance of 250 K-ohms. Resistance variations from
10-20 percent have been observed in several such test arrays.
The
unusually large variation is largely due to the surface roughness of
the chip passivation layer. As one possible solution, a thin spin-

Figure 4. Photomicrographs of? a CMOS synaptic test chip with a 4X4
array of a-Ge:Cu thin film resistors.
The nominal resistance was
250 K-ohms.

570

on coating of an insulating material such as polyimide to smooth out
the surface of the passivation layer prior to depositing the
resistors is under investigation.
SYNAPTIC CHIP-BASED 32-NEURON BREADBOARD SYSTEM
A 32-neuron breadboard system utilizing an array of discrete
neuron electronics has been fabricated to evaluate the operation of
32X32 binary synaptic CMOS chips with NMOSFET connection elements.
Each neuron consists of an operational amplifier configured as a
current to voltage converter (with virtual ground input) followed by
a fixed-gain voltage difference amplifier.
The overall time
constant of the neurons is approximately 10 microseconds.
The
neuron array is interfaced directly to the synaptic chip in a full
feedback configuration. The system also contains prompt electronics
consisting of a programmable array of RC discharging circuits with a
relaxation time of approximately 5 microseconds.
The prompt
hardware allows the neuron states to be initialized by precharging
the selected capacitors in the RC circuits.
A microcomputer
interfaced to the breadboard system is used for programming the
synaptic matrix chip, controlling the prompt electronics, and
reading the neuron outputs.
The stability of the breadboard system is tested in an
associative mellory feedback configuration,b. A dozen random dilutecoded binary vectors are stored using the following simplified
outer-product storage scheme:
~
s s
if L Vi Vj = 0
-1
Ti

j

=

f
10

S

otherwise.

In this scheme, the feedback matrix consists of only inhibitory (1lor open (0) connections.
The neurons are set to be normally ON
and are driven OFF when inhibited by another neuron via the feedback
matrix.
The system exhibits excellent stability and associative
recall performance. Convergence to a nearest stored memory in
Hamming distance is always observed for any given input cue. Figure
5 shows some typical neuron output traces for a given test prompt
and a set of stored memories. The top traces show the response of
two neurons that are initially set ON; the bottom traces for two
other neurons initially set OFF.
Convergence times of 10-50
microseconds have
been
observed, depending on the prompt
conditions, but are primarily governed by the speed of the neurons.
CONCLUSIONS
Synaptic CMOS
chips containing
1024 programmable binary
synapses in a 32X32 array have been designed, fabricated, and
tested.
These synaptic chips are designed to serve as basic
building blocks for large multi-chip synaptic networks.
The use of
long channel
MOSFET's as either resistive or current source
connection elements meets the ""weak"" connection and consistency

571

Figure 5. Typical neuron response curves for
(Horiz scale: 10 microseconds per div)

a test

prompt input.

requirements.
Alternately, CMOS-based synaptic test chips with
specially deposited thin film high-valued resistors, in series with
FET switches,
offer an
attractive approach to high density
programmable synaptic chips.
A 32-neuron breadboard system
incorporating a
32X32 NMOSFET
synaptic chip and a feedback
configuration exhibits excellent stability and associative recall
performance as an associative memory. Using discrete neuron array,
convergence times of 10-50 microseconds have been demonstrated.
With optimization of the input/output wiring layout and the use of
high speed neuron electronics, convergence times can certainly be
reduced to less than a microsecond.
ACKNOWLEDGEMENTS
This work was performed by the Jet Propulsion Laboratory,
California Institute of Technology, and was sponsored by the Joint
Tactical Fusion Program Office, through an agreement with the
National Aeronautics and Space Administration.
The authors would
like to thank John Lambe for his invaluable suggestions, T. Duong
for his assistance in the breadboard hardware development, J. Lamb
and S. Thakoor for their help in the thin film resistor deposition,
and R. Nixon and S. Chang for their assistance in the chip layout
design.
REFERENCES
1.
2.
3.
4.
5.

J. Lambe, A. Moopenn, and A.P. Thakoor, Proc. AIAA/ACM/NASA/IEEE Computers in Aerospace V, 160 (1985)
A.P. Thakoor, J.L. Lamb, A. Moopenn, and S.K. Khanna, MRS
Proc. 95, 627 (1987)
W. Hubbard, D. Schwartz, J. Denker, H.P. Graf, R. Howard, L.
Jackel, B. Straughn, and D. Tennant, AIP Conf. Proc. 151, 227
(1986)
M.A. Sivilotti, M.R. Emerling, and C. Mead, AIP Conf. Proc.
151, 408 (1986)
J.P. Sage, K. Thompson, and R.S. Withers, AIP Conf. Proc. 151,

572

6.
7.
8,
9.

381
3.3.
3.3.
S.M.
ley,
3.L.
Sci.

(19861
Hopfield, Proc. Nat. Acad. SCi., 81, 3088 (1984)
Hopfield, Proc. Nat. Acad. Sci., 79, 2554 (1982)
Sze, ""Semiconductor Devices-Physics and Technology,"" (WiNew York, 1985) p.205
Lamb, A.P. Thakoor, A. Moopenn, and S.K. Khanna, 3. Vac.
Tech., A 5(4), 1407 (1987)

"
19,1987,"Optimization with Artificial Neural Network Systems: A Mapping Principle and a Comparison to Gradient Based Methods","",19-optimization-with-artificial-neural-network-systems-a-mapping-principle-and-a-comparison-to-gradient-based-methods.pdf,"Abstract Missing","474

OPTIMIZAnON WITH ARTIFICIAL NEURAL NETWORK SYSTEMS:
A MAPPING PRINCIPLE
AND
A COMPARISON TO GRADIENT BASED METHODS t
Harrison MonFook Leong
Research Institute for Advanced Computer Science
NASA Ames Research Center 230-5
Moffett Field, CA, 94035

ABSTRACT
General formulae for mapping optimization problems into systems of ordinary differential
equations associated with artificial neural networks are presented. A comparison is made to optimization using gradient-search methods. The perfonnance measure is the settling time from an initial
state to a target state. A simple analytical example illustrates a situation where dynamical systems
representing artificial neural network methods would settle faster than those representing gradientsearch. Settling time was investigated for a more complicated optimization problem using computer simulations. The problem was a simplified version of a problem in medical imaging: determining loci of cerebral activity from electromagnetic measurements at the scalp. The simulations
showed that gradient based systems typically settled 50 to 100 times faster than systems based on
current neural network optimization methods.
INTRODUCTION
Solving optimization problems with systems of equations based on neurobiological principles
has recently received a great deal of attention. Much of this interest began when an artificial
neural network was devised to find near-optimal solutions to an np-complete problem 13. Since
then, a number of problems have been mapped into the same artificial neural network and variations of it 10.13,14,17.18,19.21,23.24. In this paper, a unifying principle underlying these mappings is
derived for systems of first to nth -order ordinary differential equations. This mapping principle
bears similarity to the mathematical tools used to generate optimization methods based on the gradient. In view of this, it seemed important to compare the optimization efficiency of dynamical
systems constructed by the neural network mapping principle with dynamical systems constructed
from the gradient.
.
THE PRINCIPLE
This paper concerns itself with networks of computational units having a state variable V, a
function! that describes how a unit is driven by inputs, a linear ordinary differential operator with
constant coefficients D (v) that describes the dynamical response of each unit, and a function g that
describes how the output of a computational unit is detennined from its state v. In particular, the
paper explores how outputs of the computational units evolve with time in tenns of a scalar function E, a single state variable for the whole network. Fig. I summarizes the relationships between
variables, functions, and operators associated with each computational unit. Eq. (1) summarizes the
equations of motion for a network composed of such units:
D""-+(M)(v)

=1(g 1(v I)' . . . ? gN (VN ) )

(I)

where the i th element of jJ(M) is D(M)(Vj), superscript (M) denotes that operator D is Mth order,
the i th element of
is !i(gl(VI) ? ...? gN(VN?, and the network is comprised of N computational units. The network of Hopfield 12 has M=I, functions
are weighted linear sums, and functions 1 (where the ith element of 1 is gj(Vj) ) are all the same sigmoid function. We will examine two ways of defining functions
given a function F. Along with these definitions will be

1

1

1

t Work supported by NASA Cooperative Agreement No. NCC 2-408

? American Institute of Physics 1988

475

defined corresponding functions E that will be used to describe the dynamics of Eq. (1).
The first method corresponds to optimization methods introduced by artificial neural network
research. It will be referred to as method V y (""dell gil):

!

== VyF

(2a)

with associated E function

tN[
dv '(S)jdg .(S)
E""j = F(""g)-JL D(M)(v ?(S?- - ''
ds.
i

dt

'

dt

(2b)

Here, V xR denotes the gradient of H, where partials are taken with respect to variables of X, and
E7 denotes the E function associated with gradient operator V7' With appropriate operator D and
and g,
is simply the ""energy function"" of Hopfield 12. Note that Eq. (2a) makes
functions
that can be derived from scalar potential functions.
explicit that we will only be concerned with
For example, this restriction excludes artificial neural networks that have connections between excitatory and inhibitory units such as that of Freeman 8. The second method corresponds to optimization methods based on the gradient. It will be referred to as method V if (""dell v""):

1

Er

1

1 == VyoF

(3a)

with associated E function
Ev>

N [
dv ? (s) 1
dv ? (s )
= FCg) -JL
D(M)(v .(s?--' '
i
dt
dt
t

ds

(3b)

I

where notation is analogous to that for Eqs. (2).
computational unit i :
~_
??
The critical result
that allows us to map
\\
optimization problems into
transform that detennines unit i's
networks described by Eq.
output from state variable Vi
(1) is that conditions on the
constituents of the equation
differential operator specifying the
can be chosen so that along
dynamical characteristics of unit i
any solution trajectory, the
E function corresponding
function governing how inputs to
to the system will be a
unit i are combined to drive it
monotonic function of time.
For method V""j' here are
/
the conditions: all functions g are 1) differentiable
/gl(V 1) 'Tg2 (v:z)
I'
and 2) monotonic in the
same sense. Only the first
Figure 1: Schematic of a computational unit i from which netcondition is needed to
works considered in this paper are constructed. Triangles suggest
make a similar assertion for
connections between computational units.
method Vv- When these conditions are met and when solutions of Eq. (1) exist, the dynamical systems can be used for optimization. The appendix contains proofs for the monotonicity of function
E along solution trajectories and references necessary existence theorems. In conclusion, mapping
optimization problems onto dynamical systems summarized by Eq. (l) can be reduced to a matter
of differentiation if a scalar function representation of the problem can be found and the integrals
of Eqs. (2b) and (3b) are ignorable. This last assumption is certainly upheld for the case where
operator D has no derivatives less than M'h order. In simulations below, it will be observed to
hold for the case M =1 with a nonzero O'h order derivative in D . (Also see Lapedes and Falber 19.)
PERSPECTIVES OF RECENT WORK

476

The fonnulations above can be used to classify the neural network optimization techniques
used in several recent studies. In these studies, the functions 1 were all identical. For the most
part, following Hopfield's fonnulation, researchers 10.13.14.17.23.24 have used method Vy to derive
with Ey quadratic in functions 1 and
fonns of Eq. (1) that exhibit the ability to find extrema of
all functions 1 describable by sigmoid functions such as tanh (x ). However, several researchers
have written about artificial neural networks associated with non-quadratic E functions. Method
Vy has been used to derive systems capable of finding extrema of non-quadrntic Ey 19. Method
Vv has been used to derive systems capable of optimizing Ev where Ev were not necessarily quadratic in variables V 21. A sort of hybrid of the two methods was used by Jeffery and Rosner 18 to
find extrema of functions that were not quadratic. The important distinction is that their functions j
were derived from a given function Fusing Eq. (3a) where, in addition, a sign definite diagonal
matrix was introduced; the left side of Eq. (3a) was left multiplied by this matrix. A perspective
on the relationship between all three methods to construct dynamical systems for optimization is
summarized by Eq. (4) which describes the relationship between methods Vyand Vyo:

E-t

V?

= <liag [a~~;ll-l V,J'

(4)

where diag [ Xi] is a diagonal matrix with Xi as the diagonal element of row i. (A similar equation
has been derived for quadratic F s.) The relationship between the method of Jeffery and Rosner
and Vv is simply Eq. (4) with the time dependent diagonal matrix replaced by a constant diagonal
matrix of free parameters. It is noted that Jeffery and Rosner presented timing results that compared
simulated annealing. conjugate-gradient, and artificial neural network methods for optimization.
Their results are not comparable to the results reported below since they used computation time as
a perfonnance measure, not settling times of analog systems. The perspective provided by Eq. (4)
will be useful for anticipating the relative performance of methods V~ and Vv in the analytical
example below and will aid in understanding the results of computer simulations.
COMPARISON OF METHODS Vt AND Vv
When M =1 and operator D has no Ofh order derivatives, method Vv is the basis of gradientsearch methods of optimization. Given the long history of of such methods. it is important to know
what possible benefits could be achieved by the relatively ne,w optimization scheme. method Vy .
In the following. the optimization efficiency of methods Vt and Vv is compared by comparing settling times. the time required for dynamical systems described by Eq. (1) to traverse a continuous
path to local optima. To qualify this perfonnance measure. this study anticipates application to the
creation of analog devices that would instantiate Eq. (1); hence, we are not interested in estimating
the number of discrete steps that would be required to find local optima, an appropriate performance measure if the point was to develop new numerical methods. An analytical example will
serve to illustrate the possibility of improvements in settling time by using method Vt instead of
method VV' Computer simulations will be reported for more complicated problems following this
example.
For the analytical example, we will examine the case where all functions 1 are identical and
g(v)

= tanhG(v -Th)

(5)

where G > 0 is the gain and Th is the threshold. Transforms similar to this are widely used in
artificial neural network research. Suppose we wish to use such computational units to search a
multi-dimensional binary solution space. We note that

!li..
= G sech 2G(v -Th)
dv

(6)

is near 0 at valid solution states (comers of a hypercube for the case of binary solution spaces). We
see from Eq. (4) that near a valid solution state. a network based on method Vy will allow computational units to recede from incorrect states and approach correct states comparatively faster. Does

477

this imply faster settling time for method V""t?
To obtain an analytical comparison of settling times, consider the case where M =1 and
operator D has no Om order derivatives and

F

1
= -2~'J
~('.?(tanhGv?)(tanhGv ? )
?
J

(7)

'oJ

where matrix S is symmetric. Method Vy gives network equations

dV =StanhGv

(8)

~ =diag [G sech 2Gvj 1S tanhGV

(9)

dt

and method Vv gives network equations

where tanhGY denotes a vector with i'"" component tanhGv;. For method Vr there is one stable
point, i.e. where '::

= 0, at V = O .

For method Vv the stable points are

V = 0 and V ? V where

V is the set of vectors with component values that are either +- or - . Further trivialization
allows for comparing estimates of settling times: Suppose S is diagonal. For this case, if Vj = 0 is
on the trajectory of any computational unit i for one method, Vj
0 is on the trajectory of that unit
for the other method; hence, a comparison of settling times can be obtained by comparing time
estimates for a computational unit to evolve from near 0 to near an extremum or, equivalently, the
converse. Specifically, let the interval be [Bo, I-a] where 0< Bo<l-a and o<a<1. For method V..,
integrating velocity over time gives the estimate

=

1[1'2 [1
1 1+ [1-a
5(2-5) - l-aJ
""5(2-a) ~
00 lJ

T Vi = G

In

(10)

and for method V y the estimate is

T,,;=

~ln [~~~) ~l

(11)

From these estimates, method Vv will always take longer to satisfy the criterion for convergence:
Note that only with the largest value for Bo, Bo =1-5, is the first term of Eq. (10) zero; for any
smaller Bo, this term is positive. Unfortunately, this simple analysis cannot be generalized to nondiagonal S. With diagonal S, all computational units operate independently. Hence, the derivation
of ':: is irrelevant with respect to convergence rates; convergence rate depends only on the diagonal element of S having the smallest magnitude. In this sense, the problem is one dimensional.
But for non-diagonal S, the problem would be, in general, multi-dimensional and, hence, the direction of ':: becomes relevant To compare settling times for non-diagonal S, computer simulations
were done. 'These are described below.

COMPUTER SIMULAnONS
Methods
The problem chosen for study was a much simplified version of a problem in medical imaging: Given electromagnetic field measurements taken from the human scalp, identify the location
and magnitude of cerebral activity giving rise to the fields. This problem has received much attention in the last 20 years 3,6.7. The problem, sufficient for our purposes here, was reduced to the
following problem: given a few samples of the electric potential field at the surface of a spherical
conductor within which reside several static electric dipoles, identify the dipole locations and
moments. For this situation, there is a closed form solution for electric potential fields at the

478

spherical surface:
(12)
where ~ is the electric potential at the spherical conductor surface, 'Xsamp/~ is the location of the
sample point ( x denotes a vector, i the corresponding unit vector, and x the corresponding vector
magnitude), j1; is the dipole moment of dipole i, and d; is the vector from dipole i to X:ampl~ (This
equation can be derived from one derived by Brody, Terry, and Ideker 4 ). Fig. 2 facilitates picturing these relationships.
With this analytical solution, the problem was formulated as a least squares minimization problem where
the variables were dipole moments. In short, the following process was used: A dipole model was chosen.
This model was used with Eq. (12) to calculate potentials at points on a sphere which covered about 60% of
the surface. A cluster of internal locations that encompassed the locations of the model was specified. The
two optimization techniques were then required to determine dipole moment values at cluster locations such
that the collection of dipoles at cluster locations accuFigure 2: Vectors of Eq. (12).
rately reflected the dipole distribution specified by the
model.
This was to be done given only the potential values at the sample points and an initial guess of
dipole moments at cluster locations. The optimization systems were to accomplish the task by
minimizing the sum of squared differences between potentials calculated using the dipole model
and potentials calculated using a guess of dipole moments at cluster locations where the sum is
taken over all sample points. Further simplifications of the problem included
1)
choosing the dipole model locations to correspond exactly to various locations of the cluster,
2)
requiring dipole model moments to.be I, 0, or -I, and
3)
representing dipole moments at cluster locations with two bit binary numbers.
To describe the dynamical systems used, it suffices to specify operator D and functions '( of
Eq. (1) and function F used in Eqs. (2a) and (3a). Operator D was
D

=

d

dt + 1.

(13)

Eq. (5) with a multiplicative factor of 112 was used for all functions '(. Hence, regarding
simplification 3) above, each cluster location was associated with two computational units. Considering simplification 2) above, dipole moment magnitude 1 would be represented by both computational units being in the high state, for -I, both in the low state, and for 0, one in the high state and
one in the low state. Regarding function F ,
F

= ~

all samp/~
poims s

[~lMaSlll'~d(X:) -

<Ilcillomr ('Xs)

r-

c

~

g (v)2

(14)

all compu,ariOflal
u""irs j

where ~_as""""~d is calculated from the dipole model and Eq. (12) (The subscript measured is used
because the role of the dipole model is to simulate electric potentials that would be measured in a
real world situation. In real world situations, we do not know the source distribution underlying
~_asar~d .), C is an experimentally detennined constant (.002 was used), and ~clJIS'~r is Eq. (12)
where the sum of Eq. (12) is taken over all cluster locations and the k,h coordinate of the i,h cluster location dipole moment is
? Pi#:

=

~
all bits b

g (Vil:b)'

(15)

479

Index j of Eq. (14) corresponds to one combination of indices ikb.
Sample points, 100 of them, were scattered semi-uniformly over the spherical surface
emphasized by horizontal shading in Fig. 3. Ouster locations, 11, and model dipoles, 5, were scattered within the subset of the sphere emphasized by vertical shading. For the dipole model used,
10 dipole moment components were non-zero; hence, optimization techniques needed to hold 56
dipole moment components at zero and set 10 components to correct non-zero values in order to
correctly identify the dipole model underlying ~_Qs""'~d'
The dynamical systems corresponding to
0.8
methods V,. and Vv' were integrated using the
relative radii
forward Euler method (e.g. Press, Flannery,
I I
Teukolsky, and Vetterling 22). Numerical
,'
I I
methods were observed to be convergent experI
imentally: settling time and path length were
I ,
observed to asymtotically approach stable
I I
values as step size of the numerical integrator
I I
was decreased over two orders of magnitude.
Settling times, path lengths, and relative
directions of travel were calculated for the two
optimization methods using several different
initial bit patterns at the cluster locations. In
Figure 3: illustration of the distribution of
other
words. the search was started at different
sample points on the surface of the sphericorners
of the hypercube comprising the space
cll conductor (horizontal shading) and the
of acceptable solutions. One corner of the
distribution of model dipole locations and
hypercube was chosen to be the target solution.
cluster locations within the conductor
(Note
that a zero dipole moment has a degen(verticll shading).
erate two bit representation in the dynamical
systems explored; the target corner was arbitrarily chosen to be one of the degenerate solutions.)
Note from Eq. (5) that for the network to reach a hypercube corner, all elements of would have
to be singular. For this reason, settling time and other measures were studied as a function of the
proximity of the computational units to their extremum states.
Computations were done on a Sequent Balance.
I

,

I

I

,

I

v

5
Results
Graph 1 shows results for exploring settling
time as a function of extremum depth, the minimum of
the deviations of variables
from the threshold of
functions g. Extremum depth is reported in multiples
of the width of functions g. The term transition, used
in the caption of Graph 1 and below, refers to the
movement of a computational unit from one extremum
state to the other. The calculations were done for two
initial states, one where the output of 1 computational
unit was set to zero and one where outputs of 13 computational units were set to zero; bence, 1 and 13,
respectively, half transitions were required to reach
the target hypercube comer. It can be observed that
settling time increases faster for method V v' than that
for method Vy just as we would expect from considering Eqs. (4) and (5). However, it can be observed
that method Vv is still an order of magnitude faster
even wben extremum depth is 3 widths of functions
g. For the purpose of unambiguously identifying
what hypercube corner the dynamical system settles

v

+,1

4
3

I

-

~

I

I

~

~

#

...

t---.

o
o

""
-

2
extremum depth

1

'""-

=-

-

4

3

Graph 1: settling time as a function of
extremum depth. #: method Vr- 1 half
transition required. .: method V 13
half transitions required. +: method
V.... 1 half transition required. -: V....
13 half transitions required.

r

480

to, this extremum depth is more than adequate.
Table 1 displays results for various initial conditions. Angles are reported in degrees. These
measures refer to the angle between directions of travel in v-space as specified by the two optimization methods. The average angle reported is taken over all trajectory points visited by the numerical integrator. Initial angle is the angle at the beginning of the path. Parasite cost percentage is a
measure that compares parasite cost, the integral in Eqs. (2b) and (3b), to the range of function F
over the path:

.
parasite cost %

parasite cost

= 100x I F
F
I
fi"",,"" ;,udal

transitions
reauired

time

1

0.16
0.0016

100

6.1
1.9

2

0.14
0.0018

78

4.7
1.9

75

3

0.15
0.0021

71

4.7
2.1

74

7

0.19
0.0032

59

4.6
2.4

63

10

0.17
0.0035

49

3.8
2.5

60

13

0.80
0.0074

110

9.2
3.2

39

relative path initial Mean angle extremum
time
len2th anlZle (std dev)
deoth
68

(16)

parasite
cost %

76 (3.8)
76 (3.5)

2.3
2.3

0.22
0.039

72 (4.3)
73 (4.1)

2.5
2.5

0.055
0.016

71 (3.7)
72 (3.0)

2.3
2.5

0.051
0.0093

69 (4.1)
71 (7.0)

2.4
2.7

0.058
0.0033

63 (2.8)

64 (4.7)

2.5
2.8

O.OOO6{)

77 (11)
71 (8.9)

2.3
2.7

0.076
0.0028

0.030

Table 1: Settling time and other measurements for various required transitions. For
each transition case, the upper row is for V y and the lower row is for V v- Std deY
denotes standard deviation. See text for definition of measurement terms and units.
Noting the differences in path length and angles reported, it is clear that the path taken to the target
hypercube comer was quite different for the two methods. Method V v settles from 1 to 2 orders of
magnitude faster than method V -r and usually takes a path less than half as long. These relationships did not change significantly for different values for c of Eq. (14) and coefficients of Eq. (13)
(both unity in Eq. (13?. Values used favored method Vr Parasite cost is consistently less
significant for method V v and is quite small for both methods.
To further compare the ability of the optimization methods to solve the brain imaging problem, a large variety of initial hypercube comers were tested. Table 2 displays results that suggest
the ability of each method to locate the target comer or to converge to a solution that was consistent with the dipole model. Initial comers were chosen by randomly selecting a number of computational units and setting them to eXtI""emwn states opposite to that required by the target solution.
Five cases were run for each case of required transitions. It can be observed that the system based
on method Vv is better at finding the target comer and is much better at finding a solution that is
consistent with the dipole model.
DISCUSSION
The simulation results seem to contradict settling time predictions of the second analytical
example. It is intuitively clear that there is no contradiction when considering the analytical example as a one dimensional search and the simulations as multi-dimensional searches. Consider Fig. 4
which illustrates one dimensional search starting at point I. Since both optimization methods must
decrease function E monotonically, both must head along the same path to the minimum point A.
Now consider Fig. 5 which illustrates a two dimensional search starting at point I: Here, the two
methods needn't follow the same paths. The two dashed paths suggest that method V."" can still be

481

V..

transitions I
required
3
4

5

I

6

Vv

~erent dipole different target different dipole different target
comer comer
solution
comer comer,
solution
1
4
0
5
0
0
4
1
1
1
0
3
4
4
1
1
0
0
4
1
1
2
0
2
1
4
4
1
0
0
3
1
1
5
0
0
5
5
0
0
0
I 0
2
3
0
5
0
0

I

I

I

7
13
20
26

33

5

0

40

5
5
5

0

46

I

53

I

0
0

0
0
0
0

3
3
2
4

2

I

2

3
1

0

I

0
0

!

0

Table 2: Solutions found starting from various initial conditions, five cases for each
transition case. Different dipole solution indicates that the system assigned non-zero
dipole moments at cluster locations that did not correspond to locations of the dipole
model sources. Different corner indicates the solution was consistent with the dipole
model but was not the target hypercube comer. Target corner indicates that the solution was the target solution.
monotonically decreasing E while traversing a more circuitous route to minimum B or traversing a path to minimum
A. The longer path lengths reported in Table 1 for method
V~ suggest the occurrence of the fonner. The data of Table
2 verifies the occurrence of the latter: Note that for many
v
cases where the system based on method Vv settled to the .
Figure 4: One dimensional search
target comer, the system based on method V~ settled to some
other minimum.
for minima.
Would we observe similar differences in optimization
I
efficiency for other optimization problems that also have
binary solution spaces? A view that supports the plausibility
of the affirmative is the following: Consider Eq. (4) and Eq.
E
(5). We have already made the observation that method Vv
would slow convergence into extrema of functions g. We
have observed this experimentally via Graph 1. These observations suggest that computational units of Vv systems
tend to stay closer to the transition regions of functions g
compared to computational units of V'I systems. It seems
plausible that this property may allow Vv systems to avoid
advancing too deeply toward ineffective solutions and, hence,
allow the systems to approach effective solutions more
Figure 5: Two dimensional search
efficiently. 1bis behavior might also be the explanation for
for minima.
the comparative success of method Vv revealed in Table 2.
Regarding the construction of electronic circuitry to instantiate Eq. (l), systems based on
method Vv would require the introduction of a component implementing multiplication by the
derivative of functions g. This additional complexity may binder the use of method Vv for the

482

construction of analog circuits for optimization. To
illustrate the extent of this additional complexity, Fig.
Input
6a shows a schematized circuit for a computational
unit of method V-r and Fig. 6b shows a schematized
circuit for a computational unit of method VT The
simulations reported above suggest that there may be
problems for which improvements in settling time
Output
may offset complications that might come with added
circuit complexity.
On the problem of imaging cerebral activity, the
results above suggest the possibility of constructing
analog devices to do the job. Consider the problem of
analyzing electric potentials from the scalp of one perOutput
son: It is noted that the measured electric potentials,
Figure 6: Schematized circuits for a com- ~_as""rcd' appear as linear coefficients in F of Eq.
putational unit Notation is consistem (14); hence, they would appear as constant terms in
with Horowitz and Hill IS. Shading of of Eq. (1). Thus. cf)_asllrcd would be implemented as
amplifiers is to e3IIllark components amplifier biases in the circuits of Figs. 6. This is a
referred to in the text. a) Computational significant benefit. To understand this. note that funcunit for method Vr b) Computational tion Ij of Fig. 1 corresponding to the optimization of
. ti
thod V
function F of Eq. (14) would involve a weighted
umt or me
...
linear sum of inputs g 1(v 1), ??? , gN (VN). The weights
would be the nonlinear coefficients of Eq. (14) and correspond to the strengths of the connections
shown in Fig. 1. These connection strengths need only be calculated once for the person ar!d Car!
then be set in hardware using, for example, a resistor network. Electric potential measurements
could then be ar!alyzed by simply using the measurements to bias the input to shaded amplifiers of
Figs. 6. For initialization, the system can be initialized with all dipole moments at zero (the 10
transition case in Table 1). This is a reasonable first guess if it is assumed that cluster locations are
far denser than the loci of cerebral activity to be observed. For subsequent measurements, the solution for immediately preceding measurements would be a reasonable initial state if it is assumed
that cerebral activity of interest waxes and wanes continuously.
Might non-invasive real time imaging of cerebral activity be possible using such optimization
devices? Results of this study are far from adequate for answering this question. Many complexities that have been avoided may nUllify the practicality of the idea. Among these problems are:
1)
The experiment avoided the possibility of dipole sources actually occurring at locations other
than cluster locations. The minimization of function F of Eq. (14) may circumvent this
problem by employing the superposition of dipole moments at neighboring cluster locations
to give a sufficient model in the mear!.
2)
The experiment asswned a very restricted range of dipole strengths. This might be dealt
with by increasing the number of bits used to represent dipole moments.
3)
The conductor model, a homogeneously conducting sphere, may not be sufficient to model
the hwnan head 16. Non-sphericity ar!d major inhomogeneities in conductivity Car! be dealt
with, to a certain extent, by replacing Eq. (12) with a generalized equation based on a
numerical approximation of a boundary integral equation 20
4)
The cerebral activity of interest may not be observable at the scalp.
5)
Not all forms of cerebral activity give rise to dipolar sources. (For example, this is well
known in olfactory cortex 8.)
6)
Activity of interest may be overwhelmed by irrelevant activity. Many methods have been
devised to contend with this problem (For example, Gevins and Morgan 9.)
Clearly, much theoretical work is left to be done.
(a)

(b)

1

CONCLUDING REMARKS

483

In this study. the mapping principle underlying the application of artificial neural networks to
the optimization of multi-dimensional scalar functions has been stated explicitly. Hopfield 12 has
shown that for some scalar functions. i.e. functions F quadratic in functions 1. this mapping can
lead to dynamical systems that can be easily implemented in hardware. notably. hardware that
requires electronic components common to semiconductor technology. Here. mapping principles
that have been known for a considerably longer period of time. those underlying gradient based
optimization, have been shown capable of leading to dynamical systems that can also be implemented using semiconductor hardware. A problem in medical imaging which requires the search of
a multi-dimensional surface full of local extrema has suggested the superiority of the latter mapping
principle with respect to settling time of the corresponding dynamical system. 1bis advantage may
be quite significant when searching for global extrema using techniques such as iterated descent 2
or iterated genetic hill climbing 1 where many searches for local extrema are required. This advantage is further emphasized by the brain imaging problem: volumes of measurements can be
analyzed without reconfiguring the interconnections between computational units; hence, the cost of
developing problem specific hardware for finding local extrema may be justifiable. Finally. simulations have contributed plausibility to a possible scheme for non-invasively imaging cerebral
activity.
APPENDIX

To show that for a dynamical system based on method Vr E,. is a monotonic function of
time given that all functions g are differentiable and monotonic in the same sense, we need to
show that the derivative of ET with respect to time is semi-definite:

dET
dt

-

N dFT dg j N [M
dVj ] dg,
= L - - - L D( )(Vj)-- - .
j

dgj

dt

i

dt

(Ala)

dt

Substituting Eq. (2a),
-dET ==
dt

N [
I,
f?

dV'] dg?
'dt
dt

(Alb)

-D(M)(v ? ) + - ' - ' .

j '

Using Eq. (1),

d~ = N [dV i
dt
~, dt

]2 dgi ~O

(Alc)

av?, s

as needed. The appropriate inequality depends on the sense in which functions 1 are monotonic.
In a similar manner, the result can be obtained for method Vv>- With the condition that functions 1
are differentiable, we can show that the derivative of 4 is semi-definite:

dE."".
dt

_v

dv?
N [
dV'] dv?
v= IN ,dF' - I,
D(M)(Vj)_-' - ' .
j

dVj

dt

j

dt

(A2a)

dt

Using Eqs. (3a) and (1),

dEv
N [dVj
dt - ~
, dt

--~-

]2~0

(A2b)

S

as needed.
In order to use the results derived above to conclude that Eq. (1) can be used for optimization of functions 4 and Et in the vicinity of some point
we need to show that there exists a
neighborhood of Vo in which there exist solution trajectories to Eq. (1). The necessary existence
theorems and transformations of Eq. (1) needed in order to apply the theorems can be found in
many texts on ordinary differential equations; e.g. Guckenheimer and Holmes 11. Here, it is mainly
important to state that the theorems require that functions ,?c(1), functions g are differentiable,
and initial conditions are specified for all derivatives of lower order than M.

vo.

484

ACKNOWLEDGEMENTS
I would like to thank Dr. Michael Raugh and Dr. Pentti Kanerva for constructive criticism
and support. I would like to thank Bill Baird and Dr. James Keeler for reviewing this work. I
would like to thank Dr. Derek Fender, Dr. John Hopfield, and Dr. Stanley Klein for giving me
opportunities that fostered this conglomeration of ideas.

[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]

[171
[18]
[19]
[20]
[21]
[22]
[23]
[24]

REFERENCES
Ackley D.H., ""Stochastic iterated genetic bill climbing"", PhD. dissertation, Carnegie Mellon
U.,1987.
Bawn E., Neural Networks for Computing, ed. Denker 1.S. (AlP Confrnc. Proc. 151, ed.
Lerner R.G.), p53-58, 1986.
Brody D.A., IEEE Trans. vBME-32, n2, pl06-110, 1968.
Brody D.A., Terry F.H., !deker RE., IEEE Trans. vBME-20, p141-143, 1973.
Cohen M.A., Grossberg S., IEEE Trans. vSMC-13, p815-826, 1983.
Cuffin B.N., IEEE Trans. vBME-33, n9, p854-861. 1986.
Darcey T.M., AIr J.P., Fender D.H., Prog. Brain Res., v54, pI28-134, 1980.
Freeman W J., ""Mass Action in the Nervous System"", Academic Press, Inc., 1975.
Gevins A.S., Morgan N.H., IEEE Trans., vBME-33, n12, pl054-1068, 1986.
Goles E., Vichniac G.Y., Neural Networks for Computing, ed. Denker J.S. (AlP Confrnc.
Proc. 151, ed. Lerner R.G.), p165-181, 1986.
Guckenheimer J., Holmes P., ""Nonlinear Oscillations, Dynamical Systems, and Bifurcations
of Vector Fields"", Springer Verlag, 1983.
Hopfield J.I., Proc. Nat!. Acad. Sci., v81, p3088-3092, 1984.
Hopfield 1.1., Tank D.W., Bio. Cybrn., v52, p141-152, 1985.
Hopfield 1.J., Tank D.W., Science, v233, n4764, p625-633, 1986.
Horowitz P., Hill W., ""The art of electronics"", Cambridge U. Press, 1983.
Hosek RS., Sances A., Jodat RW., Larson S.I., IEEE Trans., vBME-25, nS, p405-413, 1978.
Hutchinson J.M., Koch C., Neural Networks for Computing, ed. Denker J.S. (AlP Confrnc.
Proc. 151, ed. Lerner RG.), p235-240, 1986.
Jeffery W., Rosner R, Astrophys. I., v310, p473-481, 1986.
Lapedes A., Farber R., Neural Networks for Computing, ed. Denker 1.S. (AlP Confrnc. Proc.
lSI, ed. Lerner RG.), p283-298, 1986.
Leong H.M.F., ''Frequency dependence of electromagnetic fields: models appropriate for the
brain"", PhD. dissertation, California Institute of Technology, 1986.
Platt I.C., Hopfield J.J., Neural Networks for Computing, ed. Denker I.S. (AlP Confrnc. Proc.
151, ed. Lerner RG.), p364-369, 1986.
Press W.H., Flannery B.P., Teukolsky S.A., Vetterling W.T., ""Numerical Recipes"", Cambridge U. Press, 1986.
Takeda M., Goodman J.W., Applied Optics, v25. n18, p3033-3046, 1986.
Tank D.W., Hopfield I.J., ""Neural computation by concentrating infornation in time"", preprint, 1987.

"
20,1987,"An Artificial Neural Network for Spatio-Temporal Bipolar Patterns: Application to Phoneme Classification","",20-an-artificial-neural-network-for-spatio-temporal-bipolar-patterns-application-to-phoneme-classification.pdf,"Abstract Missing","31

AN ARTIFICIAL NEURAL NETWORK FOR SPATIOTEMPORAL BIPOLAR PATTERNS: APPLICATION TO
PHONEME CLASSIFICATION
Toshiteru Homma
Les E. Atlas
Robert J. Marks II

Interactive Systems Design Laboratory
Department of Electrical Engineering, Ff-l0
University of Washington
Seattle, Washington 98195

ABSTRACT
An artificial neural network is developed to recognize spatio-temporal
bipolar patterns associatively. The function of a formal neuron is generalized by
replacing multiplication with convolution, weights with transfer functions, and
thresholding with nonlinear transform following adaptation. The Hebbian learning rule and the delta learning rule are generalized accordingly, resulting in the
learning of weights and delays. The neural network which was first developed
for spatial patterns was thus generalized for spatio-temporal patterns. It was
tested using a set of bipolar input patterns derived from speech signals, showing
robust classification of 30 model phonemes.

1. INTRODUCTION
Learning spatio-temporal (or dynamic) patterns is of prominent importance in biological
systems and in artificial neural network systems as well. In biological systems, it relates to such
issues as classical and operant conditioning, temporal coordination of sensorimotor systems and
temporal reasoning. In artificial systems, it addresses such real-world tasks as robot control,
speech recognition, dynamic image processing, moving target detection by sonars or radars, EEG
diagnosis, and seismic signal processing.
Most of the processing elements used in neural network models for practical applications
have been the formal neuron l or"" its variations. These elements lack a memory flexible to temporal patterns, thus limiting most of the neural network models previously proposed to problems
of spatial (or static) patterns. Some past solutions have been to convert the dynamic problems to
static ones using buffer (or storage) neurons, or using a layered network with/without feedback.
We propose in this paper to use a ""dynamic formal neuron"" as a processing element for
learning dynamic patterns. The operation of the dynamic neuron is a temporal generalization of
the formal neuron. As shown in the paper, the generalization is straightforward when the activation part of neuron operation is expressed in the frequency domain. Many of the existing learning rules for static patterns can be easily generalized for dynamic patterns accordingly. We show
some examples of applying these neural networks to classifying 30 model phonemes.

? American Institute of Physics 1988

32

2. FORMAL NEURON AND DYNAMIC FORMAL NEURON
The formal neuron is schematically drawn in Fig. l(a), where

r = [Xl Xz ... xd 1
Yi' i = 1,2?... ?N
Zi, i = 1,2. . . . ?N

Input
Activation
Output
Transmittance
Node operator
Neuron operation

W

= [Wil

WiZ ... wiLf

11 where 11(') is a nonlinear memory less transform
Zi

= 11(wTr>

(2.1)

Note that a threshold can be implicitly included as a transmittance from a constant input.
In its original form of formal neuron, Xi E {O,I} and 110 is a unit step function u ('). A
variation of it is a bipolar formal neuron where Xi E {-I, I} and 110 is the sign function sgn O.
When the inputs and output are converted to frequency of spikes, it may be expressed as
Xi E Rand 110 is a rectifying function rO. Other node operators such as a sigmoidal function
may be used.
We generalize the notion of formal neuron so that the input and output are functions of
time. In doing so, weights are replaced with transfer functions, multiplication with convolution,
and the node operator with a nonlinear transform following adaptation as often observed in biological systems.
Fig. 1(b) shows a schematic diagram of a dynamic formal neuron where
r(l) = [Xl(t) xz(t) ... xdt)f
Yi(t), i == 1,2?... . N
Zi(t), i = 1,2?... ?N
w(t) = [Wjl(t) wiZ(t) ... WiL(t)]T
ai (t)

Input
Activation
Output
Transfer function
Adaptation
Node operator
Neuron operation

1l where 110 is a nonlinear memoryless transform
Zj(t)

=ll(ai (-t). W;(t)T .x(t?

(2.2)

For convenience, we denote ? as correlation instead of convolution. Note that convolving a(t)
with b(t) is equivalent to correlating a( -t) with b(t).
If the Fourier transforms r(f)=F{r(t)}, w;(f)=F{W;(t)}, Yj(f)=F{Yi(t)}, and
aj(f) = F {ai(t)} exist, then
Yi (f)

= ai (f)

[Wi (f

fT

r(f)]

(2.3)

where Wi (f fT is the conjugate transpose of Wi (t).
x,(1)

I----zt

1----zt(I)

?

(b)

Fig. 1. Formal Neuron and Dynamic Formal Neuron.

33

3. LEARNING FOR FORMAL NEURON AND DYNAMIC FORMAL NEURON
A number of learning rules for formal neurons has been proposed in the past. In the following paragraphs, we formulate a learning problem and describe two of the existing learning
rules, namely, Hebbian learning and delta learning, as examples.
Present to the neural network M pairs of input and desired output samples
k ::;: 1,2, ... ,M , in order. Let W(k)::;: [w/k) w!k) '"" wJk~T where wr) is the
transmittance vector at the k-th step of learning. Likewise, let
{X<k), (lk)},

K(k) = [X<I) x'-2)

... X<k)], r(k)

~(k)

= [z<I) z<2)

... ~k)],

'Ik)

= W(k)x'-k),

z<k)

and

= rfl) t 2) ...
D(k) = [(ll) (l2)

t k)],
'""

(lk)] ,

where

= n<tk?,

and

n<Y> = [T1(Y I) T1(Y2) .. . T1(yN)]T.

The Hebbian learning rule 2 is described as follows *:
W(k) ::;: W(k-I) + a;JC.k)X<k)T

(3.1)

The delta learning (or LMS learning) rule 3, 4 is described as follows:
W(k)

= W(k-I) _

o.{W(k-l)t:k ) _ (lk)}X<k)T

(3.2)

The learning rules described in the previous section are generalized for the dynamic formal
neuron by replacing multiplication with correlation. First, the problem is reformulated and then
the generalized rules are described as follows.
Present to the neural network M pairs of time-varing input
= 1,2, .. . ,M , in order. Let W(k)(t) = [WI(t)(k)(t)
where w/k)(t) is the vector whose elements W;)t)(t) are transfer functions
to the neuron i at the k-th step of learning. The Hebbian learning rule for
then
{X<k)(t), (lk)(t)), k

W(kl(t)

= W(k-I)(t) + 0.(-1}. (lk)(t). X<k)(t)T

and output samples
w~k)(t)?? . wJk)(t)f
connecting the input j
the dynamic neuron is

.

(3.3)

The delta learning rule for dynamic neuron is then
W(kl(t) ::;: W(k-I)(t) - o.(-t). {W(k-Il(t). X<k)(t) - (It)(t)} .X<k)(t)T .

(3.4)

This generalization procedure can be applied to other learning rules in some linear discriminant systems 5 , the self-organizing mapping system by Kohonen6 , the perceptron 7 , the backpropagation model 3 , etc. When a system includes a nonlinear operation, more careful analysis
is necesssay as pointed out in the Discussion section.
4. DELTA LEARNING,PSEUDO INVERSE AND REGULARIZATION
This section reviews the relation of the delta learning rule to the pseudo-inverse and the
technique known as regularization. 4, 6, 8, 9,10
Consider a minimization problem as described below: Find W which minimizes
R

= LII'Ik) -

(lk)U

i = <f-k) -

(lky <tk) - (lk?

(4.1)

subject to t k ) = WX<k) ?
A solution by the delta rule is, using a gradient descent method,
W(k)

-

= W(k-I) _ o.-1... R (k)
aw

? This interpretation assumes a strong supervising signal at the output while learning.

(4.2)

34

where R (k) = II y<k) ... ~A:)1I1. The minimum norm solution to the problem, W*, is unique and
can tie expressed as

W* == D xt

(4.3)

where !. t is the Moore-Penrose pseudo-inverse of!. , i.e.,

X t = lim(XTX + dl/)-lX T = limXT (X XT
-

a-.o -

-

-

On the condition that 0 <

-

a-+O-

- -

+ dl/)-l.
-

(4.4)

a < ~ where An- is the max.imum eigenvalue of !.T!., J'.k) and

(jC.k) are independent, and WCl) is uncorrelated with ~l),

E {W*}

=E (~c..)}

(4.5)

where E {x} denotes the expected value of x. One way to make use of this relation is to calculate W* for known standard data and refine it by (4.2), thereby saving time in the early stage of
learning.
However, this solution results in an ill-conditioned W often in practice. When the problem is ill-posed as such, the technique known as regularization can alleviate the ill-conditioning
of W . The problem is reformulated by finding W which minimizes

R(a)

= Dly<t) -

(jC.k)IIl

+ dlLII wkll 1

1

(4.6)

k

t =

subject to k ) ~k) where W = [Wlw2 ... WN]T .
This reformulation regularizes (4.3) to
W (a) =

D!.T (!.!.T + a2n-1

(4.7)

which is statistically equivalent to Wc..) when the input has an additive noise of variance dl
utlcorrelated with ~l). Interestingly, the leaky LMS algorithm ll leads to a statistically
equivalent solution
W(l)

= ~WCk-l) _ tx~(k-l)~l) -

whete 0 < ~ < 1 and 0 <

E {W(a)}
if dl =

(4.8)

{jC.l)};f<l)T

2

a < Amax ? These solutions are related as

=E {Wc..)}

(4.9)

..!::J!
when WCl) is uncorrelated with ;f<l) .11
a
-

Equation (4.8) can be generalized for a network using dynamic formal neurons, resulting in
a equation similar to (3.4). Making use of (4.9), (4.7) can be generalized for a dynamic neuron
network as
W (t ; a) = F- 1{Q if )!. if fT (!. if )!. if)CT

n-

+ a2

1}

(4.10)

where F-1 denotes the inverse Fourier transform.

s. SYNTHESIS OF BIPOLAR PHONEME PATTERNS
This section illustrates the scheme used to synthesize bipolar phoneme patterns and to
form prototype and test patterns.
The fundamental and first three formant frequencies, along with their bandwidths, of
phonemes provided by Klatt l2 were taken as parameters to synthesize 30 prototype phoneme patterns. The phonemes were labeled as shown in Table 1. An array of L (=100) input neurons
OOVered the range of 100 to 4000 Hz. Each neuron had a bipolar state which was +1 only when
one of the frequency bands in the phoneme presented to the network was within the critical band

35
of the neuron and -1 otherwise. The center frequencies if e) of critical bands were obtained by
dividing the 100 to 4000 Hz range into a log scale by L. The critical bandwidth was a constant
100 Hz up to the center frequency Ie = 500 Hz and 0.2/e Hz when Ie >500 Hz.13
The parameters shown in Table 1 were used to construct Table 1. Labels of Phonemes
30 prototype phoneme patterns. For 9. it was constructed as a
Label
Phoneme
combination of t and 9. Fl. F 2 .F 3 were the first. second. and
1
[i Y]
third formants. and B I' B 2. and B 3. were corresponding
[Ia]
2
bandwidths. The fundamental frequency F 0 = 130 Hz with B 0 =
3
leY]
10 Hz was added when the phoneme was voiced. For plosives.
4
[Ea ]
there was a stop before formant traces start. The resulting bipo[3e']
5
lar patterns are shown in Fig.2. Each pattern had length of 5
6
[el]
time units, composed by linearly interpolating the frequencies
7
[~]
when the formant frequency was gliding.
8
[It ]
A sequence of phonemes converted from a continuous
[ow]
9
pronunciation of digits, {o, zero, one, two, three. four, five, six.
10
[\I~]
seven, eight, nine }, was translated into a bipolar pattern, adding
11
[u w]
12
two time units of transition between two consequtive phonemes
[a;J
13
[a ]
by interpolating the frequency and bandwidth parameters
[aWl
14
linearly. A flip noise was added to the test pattern and created a
15
loY]
noisy test pattern. The sign at every point in the original clean
16
[w]
test pattern was flipped with the probability 0.2. These test pat17
[y]
terns are shown in Fig. 3.
18
[r]
19
[I]
20
[f]
21
[v]
I'IlDM_ Label I 1 5 7 , II Il 15 .7 ., JI 21 Z5 17 It
2 4 , I II 11 14 16 II II U 14 I' II JO
22
[9]
II.
23
[\]
24
[s]
25
[z]
26
[p]
27
[t]
28
[d]
29
[k]
30
[n]

Fig. 2. Prototype Phoneme Patterns. (Thirty phoneme patterns are shown
in sequence with intervals of two time units.)

6. SIMULATION OF SPATIO-TEMPORAL FILTERS FOR PHONEME CLASSIFICATION
The network system described below was simulated and used to classify the prototype
phoneme patterns in the test patterns shown in the previoius section. It is an example of generalizing a scheme developed for static patterns 13 to that for dynamic patterns. Its operation is
in two stages. The first stage operation is a spatio-temporal filter bank:

36

?

!!

z .4

:!

e=

~

!

?

?

I
?

'

,

I

if

""I '
~..

I '

,

lU

'I

U'

(b)

(a)

Fig. 3. Test Patterns. (a) Clean Test Pattern. (b) Noisy Test Pattern.
(6.1)

1(t) = W(t).r(t) , and r(t) = !:(a(-t)y(t? .

The second stage operation is the ""winner-take-all"" lateral inhibition:
(/(t) = zt(t) , and (/(t+A) = !:(~(-t).(/(t) -

Ii),

(6.2)

and
A(t) = (1

-

114
+ -)/O(t) - -S""fiI' 2,O(t-nA).
SN -

N

(6.3)

11=0

where Ii is a constant threshold vector with elements hi = h and 0(.) is the Kronecker delta
function. This operation is repeated a sufficient number of times, No .13,14 The output is
(/(t + No ?A).
Two models based on different leaming rules were simulated with parameters shown
below.

Model 1 (Spatio-temporal Matched Filter Bank)
Let a(t) = O(t) , (/tk) = et in (3.3) where ek is a unit vector with its elements eki = O(k-i) .
(6.4)

W(t)=!(t)T.
4 1
h=200, and a(t) = 2,-O(t-nA).
11=0 S

Model 2 (Spatio-temporal Pseudo-inverse Filter)
Let D

=L in (4.10). Using the alternative expression in (4.4),
W (t) = F- 1{(! (j fT! (j) + cr2n-lXCT}.
h = O.OS ,cr2 = 1000.0, and a(t)

(6.5)

= O(t).

This minimizes
R (cr,!)

= DI1k )(j) ""

(/t"")(j )lIi + cr 22,11
k

w"" if )lIi

for all ! .

(6.6)

37

Because the time and frequency were finite and discrete in simulation, the result of the
inverse discrete Fourier transform in (6.5) may be aliased. To alleviate the aliasing, the transfer
functions in the prototype matrix:! (t) were padded with zeros, thereby doubling the lengths.
Further zero-padding the transfer functions did not seem to change teh result significantly.
The results are shown in Fig. 4(a)-(d). The arrows indicate the ideal response positions at
the end of a phoneme. When the program was run with different thresholds and adaptation function a (t), the result was not very sensitive to the threshold value, but was, nevertheless affected
by the choice of the adaptation function. The maximum number of iterations for the lateral inhibition network to converge was observed: for the experiments shown in Fig. 4(a) - (d), the
numbers were 44, 69, 29, and 47, respectively. Model 1 missed one phoneme and falsely
responded once in the clean test pattern. It missed three and had one false response in the noisy
test pattern. Model 2 correctly recognized all phonemes in the clean test pattern, and falsealarmed once in the noisy test pattern.

7. DISCUSSION
The notion of convolution or correlation used in the models presented is popular in
engineering disciplines and has been applied extensively to designing filters, control systems, etc.
Such operations also occur in biological systems and have been applied to modeling neural networks. IS ,16 Thus the concept of dynamic formal neuron may be helpful for the improvement of
artificial neural network models as well as the understanding of biological systems. A portion of
the system described by Tank and Hopfield 11 is similar to the matched filter bank model simulated in this paper.
The matched filter bank model (Modell) performs well when all phonemes (as above) are
of the same duration. Otherwise, it would perform poorly unless the lengths were forced to a
maximum length by padding the input and transfer functions with -1' s during calculation. The
pseudo-inverse filter model, on the other hand, should not suffer from this problem. However,
this aspect of the 11KXlel (Model 2) has not yet been explicitly simulated.
Given a spatio-temporal pattern of size L x K, i.e., L spatial elements and K temporal elements, the number of calculations required to process the first stage of filtering by both models is
the same as that by a static formal neuron network in which each neuron is connected to the L x
K input elements. In both cases, L x K multiplications and additions are necessary to calculate
one output value. In the case of bipolar patterns, the rnutiplication used for calculation of activation can be replaced by sign-bit check and addition. A future investigation is to use recursive
filters or analog filters as transfer functions for faster and more efficient calculation. There are
various schemes to obtain optimal recursive or analog filters.t 8,19 Besides the lateral inhibition
scheme used in the models, there are a number of alternative procedures to realize a ""winnertake-all"" network in analog or digital fashion. IS, 20, 21
As pointed out in the previous section, the Fourier transform in (6.5) requires a precaution
concerning the resulting length of transfer functions. Calculating the recursive correlation equation (3.4) also needs such preprocessing as windowing or truncation. 22
The generalization of static neural networks to dynamic ones along with their learning
rules is strainghtforward as shown if the neuron operation and the learning rule are linear. Generalizing a system whose neuron operation and/or learning rule are nonlinear requires more careful analysis and remains for future work. The system described by Watrous and Shastri l6 is an
example of generalizing a backpropagation model. Their result showed a good potential of the
model and a need for more rigorous analysis of the model. Generalizing a system with recurrent
connections is another task to be pursued. In a system with a certain analytical nonlinearity, the
signals are expressed by Volterra functionals, for example. A practical learning system can then
be constructed if higher kernels are neglected. For example, a cubic function can be used instead
of a sigmoidal function.

38

1'1

3.

0-{'-r.

1\
~

j""--

~

;~.
1\

U

--{.

!

e

(a)

~

z

~
0

'\
.t

?f-t

7\

-

-.

?

?

I

I

, I

I

I

I

I
IS.

t ..

51

I

I

en

TIme

""t

~

l~

~
~
~7

!.

!

1

1

~

e
Ii

(b)

z

"";

.:-

~

~

?

1.
l

?

?

j

r--

I

u

I

t ..

I
lSI

tu

TIme

Fig. 4. Performance of Models. (a) Modell with Clean Test Pattern. (b)
Model 2 with Clean Test Pattern. (c) Modell with Noisy Test Pattern.
(d) Model 2 with Noisy Test Pattern. Arrows indicate the ideal response
positions at the end of phoneme.
8. CONCLUSION
The formal neuron was generalized to the dynamic formal neuron to recognize spatiotemporal patterns. It is shown that existing learning rules can be generalized for dynamic formal
neurons.
An artificial neural network using dynamic formal neurons was applied to classifying 30
model phonemes with bipolar patterns created by using parameters of formant frequencies and
their bandwidths. The model operates in two stages: in the first stage, it calculates the correlation between the input and prototype patterns stored in the transfer function matrix, and, in the
second stage, a lateral inhibition network selects the output of the phoneme pattern close to the
input pattern.

39

---{'.-\

3.

1""'? j

,--; '

at

i!!

e

(C)

zii

~

C

It
!""

P,
X

?

?

I

I

I

I

I

t ..

51

u.

t51

nme
.~

3.

""
I

~0
.'--~

u

'1

""?

i!!

e
ii

(d)

z

,..

~

C

?

It

?

I

I

,

?
Fig. 4 (continued.)

Two models with different transfer functions were tested. Model 1 was a matched filter
bank model and Model 2 was a pseudo-inverse filter model. A sequence of phoneme patterns
corresponding to continuous pronunciation of digits was used as a test pattern. For the test pattern, Modell missed to recognize one phoneme and responded falsely once while Model 2
correctly recognized all the 32 phonemes in the test pattern. When the flip noise which flips the
sign of the pattern with the probability 0.2, Model 1 missed three phonemes and falsely
responded once while Model 2 recognized all the phonemes and false-alarmed once. Both
models detected the phonerns at the correct position within the continuous stream.
References
1.

W. S. McCulloch and W. Pitts, ""A logical calculus of the ideas imminent in nervous
activity,"" Bulletin of Mathematical Biophysics, vol. 5, pp. 115-133, 1943.

2.

D. O. Hebb, The Organization of Behavior, Wiley, New York, 1949.

40

3.

D. E. Rumelhart, G. E. Hinton, and R. J. Williams, ""Learning internal representations by
error propagation,"" in Parallel Distributed Processing. Vol. 1, MIT, Cambridge, 1986.

4.

B. Widrow and M. E. Hoff, ""Adaptive switching circuits,"" Institute of Radio Engineers.
Western Electronics Show and Convention, vol. Convention Record Part 4, pp. 96-104,
1960.

5.

R. O. Duda and P. E. Hart, Pattern Classification and Scene Analysis. Chapter 5, Wiley,
New York, 1973.

6.

T. Kohonen, Self-organization and Associative Memory, Springer-Verlag, Berlin, 1984.

7.

F. Rosenblatt, Principles of Neurodynamics, Spartan Books, Washington, 1962.

8.

1. M. Varah, ""A practical examination of some numerical methods for linear discrete illposed problems,"" SIAM Review, vol. 21, no. 1, pp. 100-111, 1979.

9.

C. Koch, J. Marroquin, and A. Y uiIle, ""Analog neural networks in early vision,"" Proceedings of the National Academy of Sciences. USA, vol. 83, pp. 4263-4267, 1986.

10.

G. O. Stone, ""An analysis of the delta rule and the learning of statistical associations,"" in
Parallel Distributed Processing .? Vol. 1, MIT, Cambridge, 1986.

11.

B. Widrow and S. D. Stearns, Adaptive Signal Processing, Prentice-Hall, Englewood
Cliffs, 1985.

12.

D. H. Klatt, ""Software for a cascade/parallel formant synthesizer,"" Journal of Acoustical
Society of America, vol. 67, no. 3, pp. 971-995, 1980.

13.

L. E. Atlas, T. Homma, and R. J. Marks II, ""A neural network for vowel classification,""

Proceedings International Conference on Acoustics. Speech. and Signal Processing, 1987.
14.

R. P. Lippman, ""An introduction to computing with neural nets,"" IEEE ASSP Magazine,
April, 1987.

15.

S. Amari and M. A. Arbib, ""Competition and cooperation in neural nets,"" in Systems Neuroscience, ed. J. Metzler, pp. 119-165, Academic Press, New York, 1977.

16.

R. L. Watrous and L. Shastri, ""Learning acoustic features from speech data using connectionist networks,"" Proceedings of The Ninth Annual Conference of The Cognitive Science
Society, pp. 518-530, 1987.

17.

D. Tank and J. J. Hopfield, ""Concentrating information in time: analog neural networks
with applications to speech recognition problems,"" Proceedings of International Conference on Neural Netoworks, San Diego, 1987.

18.

J. R. Treichler, C. R. Johnson,Jr., and M. G. Larimore, Theory and Design of Adaptive
Filters. Chapter 5, Wiley, New York, 1987.

19.

M Schetzen, The Volterra and Wiener Theories of Nonlinear Systems. Chapter 16, Wiley,
New York, 1980.

20.

S. Grossberg, ""Associative and competitive principles of learning,"" in Competition and
Cooperation in Neural Nets, ed. M. A. Arbib, pp. 295-341, Springer-Verlag, New York,
1982.

21.

R. J. Marks II, L. E. Atlas, J. J. Choi, S. Oh, K. F. Cheung, and D. C. Park, ""A performance analysis of associative memories with nonlinearities in the correlation domain,""
(submitted to Applied Optics), 1987.

22.

D. E. Dudgeon and R. M. Mersereau, Multidimensional Digital Signal Processing, pp.
230-234, Prentice-Hall, Englewood Cliffs, 1984.

"
21,1987,"PATTERN CLASS DEGENERACY IN AN UNRESTRICTED STORAGE DENSITY MEMORY","",21-pattern-class-degeneracy-in-an-unrestricted-storage-density-memory.pdf,"Abstract Missing","674

PA'ITERN CLASS DEGENERACY IN AN UNRESTRICfED STORAGE
DENSITY MEMORY
Christopher L. Scofield, Douglas L. Reilly,
Charles Elbaum, Leon N. Cooper
Nestor, Inc., 1 Richmond Square, Providence, Rhode Island,
02906.
ABSTRACT
The study of distributed memory systems has produced a
number of models which work well in limited domains.
However, until recently, the application of such systems to realworld problems has been difficult because of storage limitations,
and their inherent architectural (and for serial simulation,
computational) complexity.
Recent development of memories
with unrestricted storage capacity and economical feedforward
architectures has opened the way to the application of such
systems to complex pattern recognition problems.
However,
such problems are sometimes underspecified by the features
which describe the environment, and thus a significant portion
of the pattern environment is often non-separable.
We will
review current work on high density memory systems and their
network implementations.
We will discuss a general learning
algorithm for such high density memories and review its
application to separable point sets. Finally, we will introduce an
extension of this method for learning the probability
distributions of non-separable point sets.
INTRODUcnON
Information storage in distributed content addressable
memories has long been the topic of intense study.
Early
research focused on the development of correlation matrix
memories 1, 2, 3, 4. Workers in the field found that memories of
this sort allowed storage of a number of distinct memories no
larger than the number of dimensions of the input space.
Further storage beyond this number caused the system to give
an incorrect output for a memorized input.
@ American Institute of Physics 1988

675

Recent work on distributed memory systems has focused on
single layer, recurrent networks.
Hopfield 5, 6 introduced a
method for the analysis of settling of activity in recurrent
networks.
This method defined the network as a dynamical
system for which a global function called the 'energy' (actually a
Liapunov function for the autonomous system describing the
Hopfield showed that
state of the network) could be defined.
flow in state space is always toward the fixed points of the
dynamical system if the matrix of recurrent connections satisfies
certain conditions.
With this property, Hopfield was able to
define the fixed points as the sites of memories of network
acti vity.
Like its forerunners, the Hopfield network is limited in
storage capacity. Empirical study of the system found that for
randomly chosen memories, storage capacity was limited to m ~
O.lSN, where m is the number of memories that could be
accurately recalled, and N is the dimensionality of the network
(this has since been improved to m ~ N, 7, 8). The degradation of
memory recall with increased storage density is directly related
to the proliferation in the state space of unwanted local minima
which serve as basins of flow.
UNRESTRICIEn STORAGE DENSITY MEMORIES

Bachman et al. 9 have studied another relaxation system
similar in some respects to the Hopfield network. However, in
contrast to Hopfield, they have focused on defining a dynamical
system in which the locations of the minima are explicitly
known.
In particular, they have chosen a system with a Liapunov
function given by

E = -IlL ~

Qj I Il- Xj I - L,

(1)

J
where E is the total 'energy' of the
describing the initial network activity
and Xj' the site of the jth memory, for
parameter related to the network size.
= Xj for some memory j according to

network, Il (0) is a vector
caused by a test pattern,
m memories in RN. L is a
Then 1l(0) relaxes to Il(T)

676

(2)

This system is isomorphic to the classical electrostatic potential
between a positive (unit) test charge, and negative charges Qj at
the sites Xj (for a 3-dimensional input space, and L = 1). The Ndimensional Coulomb energy function then defines exactly m
basins of attraction to the fixed points located at the charge sites
Xj.
It can been shown that convergence to the closest distinct
memory is guaranteed, independent of the number of stored
memories m, for proper choice of Nand L 9, to.
Equation 1 shows that each cell receives feedback from the
network in the form of a scalar
~ Q-I Jl- x-I- L
J J
J
?

(3)

Importantly, this quantity is the same for all cells; it is as if a
single virtual cell was computing the distance in activity space
between the current state and stored states. The result of the
computation is then broadcast to all of the cells in the network.
A 2-layer feedforward network implementing such a system has
been described elsewhere 10 .
The connectivity for this architecture is of order m?N, where
m is the number of stored memories and N is the dimensionality
of layer 1.
This is significant since the addition of a new
memory m' = m + 1 will change the connectivity by the addition
of N + 1 connections, whereas in the Hopfield network, addition
of a new memory requires the addition of 2N + 1 connections.
An equilibrium feedforward network with similar properties
has been under investigation for some time 11. This model does
not employ a relaxation procedure, and thus was not originally
framed in the language of Liapunov functions.
However, it is
possible to define a similar system if we identify the locations of
the 'prototypes' of this model as? the locations in state space of
potentials which satisfy the following conditions
Ej

= -Qj lRo for I j.t - Xj I < Aj
=0

for I fl - Xj I > A].

(4)

677

where Ro is a constant.
This form of potential is often referred to as the 'square-well'
potential. This potential may be viewed as a limit of the Ndimensional Coulomb potential, in which the l/R (L = l) well is
replaced with a square well (for which L ? l). Equation 4
describes an energy landscape which consists of plateaus of zero
potential outside of wells with flat, zero slope basins. Since the
landscape has only flat regions separated by discontinuous
boundaries, the state of the network is always at equilibrium,
and relaxation does not occur. For this reason, this system has
been called an equilibrium model. This model, also referred to
as the Restricted Coulomb Energy (RCE)14 model, shares the
property of unrestricted storage density.
LEARNING IN HIGH DENSITY MEMORIES

A simple learning algorithm for the placement of the wells has
been described in detail elsewhere 11, 12.

Figurel: 3-layer feedforward network. Cell i
computes the quantity IJl - xii and compares
to internal threshold Ai.

678

Reilly et. al. have employed a three layer feedforward
network (figure 1) which allows the generalization of a content
addressable memory to a pattern classification memory.
Because the locations of the minima are explicitly known in the
equilibrium model, it is possible to dynamically program the
energy function for an arbitrary energy landscape. This allows
the construction of geographies of basins associated with the
classes constituting the pattern environment. Rapid learning of
complex, non-linear, disjoint, class regions is possible by this
method 12, 13.
LEARNING NON-SEPARABLE CLASS REGIONS

Previous studies have focused on the acquisition of the
geography and boundaries of non-linearly separable point sets.
However, a method by which such high density models can
acquire the probability distributions of non-separable sets has
not been described.
Non-separable sets are defined as point sets in the state
space of a system which are labelled with multiple class
affiliations.
This can occur because the input space has not
carried all of the features in the pattern environment, or because
the pattern set itself is not separable. Points may be degenerate
with respect to the explicit features of the space, however they
may have different probability distributions within the
environment.
This structure in the environment is important
information for the identification of patterns by such memories
10 the presence of feature space degeneracies.
We now describe one possible mechanism for the acquisition
of the probability distribution of non-separable points.
It is
assumed that all points in some region R of the state space of the
network are the site of events Jl (0, Ci ) which are examples of
pattern classes C = {C 1 , ... , CM }. A basin of attraction, xk( C i ),
defined by equation 4, is placed at each site fl(O, Ci ) unless
(5)

that is, unless a memory at Xj (of the class Ci ) already contains
fl(O, Ci )? The initial values of Qo and Ro at xk(Ci) are a constant for
all sites Xj. Thus as events of the classes C 1 , ... , C M occur at a
particular site in R, multiple wells are placed at this location.

679

If a well x/ C i) correctly covers an event Jl (0, C i ), then the

charge at that site (which defines the depth of the well) is
incremented by a constant amount ~ Q o. In this manner, the
region R is covered with wells of all classes {C 1 , ... , C M }, with the
depth of well XiCi) proportional to the frequency of occurence of
C i at Xj.
The architecture of this network is exactly the same as that
already described. As before, this network acquires a new cell
for each well placed in the energy landscape. Thus we are able
to describe the meaning of wells that overlap as the competition
by multiple cells in layer 2 in firing for the pattern of activity in
the input layer.
APPLICATIONS
This system has been applied to a problem in the area of risk
assessment in mortgage lending. The input space consisted of
feature detectors with continuous firing rates proportional to the
values of 23 variables in the application for a mortgage. For this
set of features, a significant portion of the space was nonseparable.
Figures 2a and 2b illustrate the probability distributions of
high and low risk applications for two of the features. It is clear
that in this 2-dimensional subspace, the regions of high and low
risk are non-separable but have different distributions.

t-----------#llir----- Prob. = 1.0.
1000 Patterns

Prob.

0.0

Feature 1

= 0.5

1.0

Figure 2a: Probability distribution for High
and Low risk patterns for feature 1.

680

=

Prob.
1.0.
t 000 Patterns

1-----1----\---------

Prob.

0.0

= 0.5

1.0

Feature 2

Figure 2b: Probability distribution for High
and Low risk patterns for feature 2.
Figure 3 depicts the probability distributions acquired by
the system for this 2-dimensional subspace.
In this image,
circle radius is proportional to the degree of risk: Small circles
are regions of low risk, and large circles are regions of high
risk.
00

o

o

V

0 0

0

0

o

0:>0
t?.

0

0

00

0

o

o

00

0

0

0

00

0

o

Feature 1

Figure 3: Probability distribition for Low and
High risk.
Small circles indicate low risk
regIons and large circles indicate high risk
regions.

681

Of particular interest is the clear clustering of high and low risk
regions in the 2-d map. Note that the regions are in fact nonlinearly separable.
DISCUSSION
We have presented a simple method for the acquisition of
probability distributions in non-separable point sets.
This
method generates an energy landscape of potential wells with
depths that are proportional to the local probability density of
the classes of patterns in the environment. These well depths
set the probability of firing of class cells In a 3-layer
feedforward network.
Application of this method to a problem in risk assessment
has shown that even completely non-separable subspaces may
be modeled with surprising accuracy.
This method improves
pattern classification in such problems with little additional
computational burden.
This algorithm has been run in conjunction with the method
described by Reilly et. al. II for separable regions. This combined
system is able to generate non-linear decision surfaces between
the separable zones, and approximate the probability
distributions of the non-separable zones in a seemless manner.
Further discussion of this system will appear in future reports.
Current work is focused on the development of a more
general method for modelling the scale of variations in the
distributions.
Sensitivity to this scale suggests that the
transition from separable to non-separable regions is smooth
and should not be handled with a 'hard' threshold.
ACKNOWLEDGEMENTS
We would like to thank Ed Collins and Sushmito Ghosh for their
significant contributions to this work through the development
of the mortgage risk assessment application.

REFERENCES
[1] Anderson, J .A.: A simple neural network generating an
interactive memory. Math. Biosci. 14, 197-220 (1972).

682

[2] Cooper, L.N.: A possible organization of animal memory and
learning. In: Proceedings of the Nobel Symposium on Collective
Properties of Physical Systems, Lundquist, B., Lundquist, S.
(eds.). (24), 252-264 London, New York: Academic Press 1973.
[3] Kohonen, T.: Correlation matrix memories.
IEEE Trans.
Comput. 21, 353-359 (1972).
[4] Kohonen, T.: Associative memory - a system-theoretical
approach. Berlin, Heidelberg, New York: Springer 1977.
[5] Hopfield, J.J.: Neural networks and physical systems with
emergent collective computational abilities. Proc. Natl. Acad. Sci.
USA 79, 2554-2558 (April 1982).
[6] Hopfield, J.J.: Neurons with graded response have collective
computational properties like those of two-state neurons. Proc.
Natl. Acad. Sci. USA 81, 2088-3092 (May, 1984).
[7] Hopfield, J.J., Feinstein, D.I., Palmer, R.G.: 'Unlearning' has a
stabilizing effect in collective memories. Nature 304, 158-159
(July 1983).
[8] Potter, T.W.: Ph.D. Dissertation in advanced technology,
S.U.N.Y. Binghampton, (unpublished).
[9] Bachmann, C.M., Cooper, L.N., Dembo, A., Zeitouni, 0.: A
relaxation model for memory with high density storage. to be
published in Proc. Nati. Acad. Sci. USA.
[10] Dembo, A., Zeitouni, 0.: ARO Technical Report, Brown
University, Center for Neural Science, Pr0vidence, R.I., (1987),
also submitted to Phys. Rev. A.
[11] Reilly, D.L., Cooper, L.N., Elbaum, C.: A neural model for
category learning. BioI. Cybern. 45, 35 -41 (1982).
[12] Reilly, D.L., Scofield, C., Elbaum, C., Cooper, L.N.: Learning
system architectures composed of multiple learning modules. to
appear in Proc. First In1'1. Conf. on Neural Networks (1987).
[13] Rimey, R., Gouin, P., Scofield, C., Reilly, D.L.: Real-time 3-D
object classification using a learning system. Intelligent Robots
and Computer Vision, Proc. SPIE 726 (1986).
[14] Reilly, D.L., Scofield, C. L., Elbaum, C., Cooper, L.N: Neural
Networks with low connectivity and unrestricted memory
storage density. To be published.

"
22,1987,"New Hardware for Massive Neural Networks","",22-new-hardware-for-massive-neural-networks.pdf,"Abstract Missing","201

NEW HARDWARE FOR MASSIVE NEURAL NETWORKS
D. D. Coon and A. G. U. Perera
Applied Technology Laboratory
University of Pittsburgh
Pittsburgh, PA 15260.

ABSTRACT
Transient phenomena associated with forward biased silicon p + - n - n + structures at 4.2K show remarkable similarities with biological neurons. The devices play
a role similar to the two-terminal switching elements in Hodgkin-Huxley equivalent
circuit diagrams. The devices provide simpler and more realistic neuron emulation
than transistors or op-amps. They have such low power and current requirements
that they could be used in massive neural networks. Some observed properties of
simple circuits containing the devices include action potentials, refractory periods,
threshold behavior, excitation, inhibition, summation over synaptic inputs, synaptic
weights, temporal integration, memory, network connectivity modification based on
experience, pacemaker activity, firing thresholds, coupling to sensors with graded signal outputs and the dependence of firing rate on input current. Transfer functions
for simple artificial neurons with spiketrain inputs and spiketrain outputs have been
measured and correlated with input coupling.
INTRODUCTION
Here we discuss the simulation of neuron phenomena by electronic processes in
silicon from the point of view of hardware for new approaches to electronic processing
of information which parallel the means by which information is processed in intelligent organisms. Development of this hardware basis is pursued through exploratory
work on circuits which exhibit some basic features of biological neural networks. Fig. 1
shows the basic circuit used to obtain spiketrain outputs. A distinguishing feature
of this hardware basis is the spontaneous generation of action potentials as a device
physics feature.

,----_O_u-f)tput

) ! -_ _

R

JLJLL

Figure 1: Spontaneous,
neuronlike spiketrain
generating circuit. The
spikes are nearly equal in
amplitude so that
information is contained in
the frequency and
temporal pattern of the
spiketrain generation.

? American Institute of Physics 1988

202

TWO-TERMINAL SWITCHING ELEMENTS
The use of transistor based circuitry 1 is avoided because transistor electrical
characteristics are not similar to neuron characteristics. The use of devices with
fundamentally non-neuronlike character increases the complexity of artificial neural
networks. Complexity would be an important drawback for massive neural networks
and most neural networks in nature achieve their remarkable performance through
their massive size. In addition) transistors have three terminals whereas the switching
elements of Hodgkin-Huxley equivalent circuits have two terminals. Motivated in
part by Hodgkin-Huxley equivalent circuit diagrams) we employ two-terminal p+ n - n+ devices which execute transient switching between low conductance and high
conductance states. (See Fig. 2) We call these devices injection mode devices (IMDs).
In the ""OFF-STATE"", a typical current through the devices is '"" 100fA/mm2) and
in the ""ON-STATE"" a typical current is '"" 10mA/mm2. Hence this device is an
extremely good switch with a ON / 0 F F ratio of 1011. As in real neurons 2, the current
in the device is a function of voltage and time, not only voltage. The devices require
cryogenic cooling but this results in an advantageously low quiescent power drain of
< 1 nanowatt/cm2 of chip area and the very low leakage currents mentioned above.
In addition, the highly unique ability of the neural networks described here to operate
in a cryogenic environment is an important advantage for infrared image processing
at the focal plane (see Fig. 3 and further discussion below). Vision systems begin
processing at the focal plane and there are many benefits to be gained from the
vision system approach to IR image processing.

/ \
-----/

-----

...-.

I( V, t)

I

I

R

VD C ~--~--VV~--~------~

IR

;;SS:Ulse
Output

1----0

+Q

C

- Q

Figure 2:
Switching element
in Hodgkin-Huxley equivalent circuits.

Figure 3: Single stage conversion of
infrared intensity to spiketrain frequency with a neuron-like semiconductor device. No pre-amplifiers
are necessary.

Coding of graded input signals (see Fig. 4) such as photocurrents into action potential spike trains with millimeter scale devices has been experimentally
demonstrated3 with currents from 1 IlA down to about 1 picoampere with coding
noise referred to input of < 10 femtoamperes. Coding of much smaller current levels
should be possible with smaller devices. Figure 5 clearly shows the threshold behavior
of the IMD. For devices studied to date, a transition from action potential output to
graded signal output is observed for input currents of the order of 0.5 picoamperes 1~

203

--..

o

Z

o

10

4

U

w

(f)

CURRENT (AMPERES)

Figure 4: Coding of NIR-VISmLE-UV intensity into firing frequency of a spiketrain
and the experimentally determined firing rate vs. the input current for one device.
Note that the dynamic range is about 107 .

>
'0

'>
o

UBI)

E2

Figure 5: mustration of the threshold firing of the
device in response to input step functions.

---PL
500 fLS/ div

This transition is remarkably well described in von Neumann's discussion 5 ,6 of
the mixed character of neural elements which he relates to the concept of subliminal stimulation levels which are too low to produce the stereotypical all-or-nothing
response. Neural network modelers frequently adopt viewpoints which ignore this
interesting mixed character. The von Neumann viewpoint links the mixed character
to concepts of nonlinear dynamics in a way which is not apparent in recent neural
network modeling literature. The scaling down of IMD size should result in even
lower current requirements for all-or-nothing response.
DEVICE PHYSICS
Recently, neuronlike action potential transients in IMDs have been the subject
of considerable research3 ,4,7,8,9,1O,1l,12,13. In the simple circuits of Fig. 1, the IMD
gives rise to a spontaneous neuronlike spiketrain output. Between pulses, the IMD is
polarized in the sense that it is in a low conductance state with a substantial voltage
occurring across it, even though it is forward biased. The low conductance has been
attributed to small interfacial work functions due to band offsets at the n+ -n and
p+ -n interfaces 8 ?
Low temperatures inhibit thermionic injection of electrons and holes into the
n-region from the n+ -layer and p+ -layer impurity bands 14 . Pulses are caused by

204

switching to depolarized states with low diode potential drops and large injection
currents which are believed to be triggered by the slow buildup of a small thermionic
injection current from the n+ -layer into the n-region. The injection current can cause
impact ionization of n-region donor impurities resulting in an increasingly positive
space charge which further enhances the injection current to the point where the IMD
abruptly switches to the low conductance state with large injection current. Switching
times are typically under lOOns. Charging of the load capacitance CL cuts off the
large injection current and resets the diode to its low conductance state. The load
capacitor CL then discharges through RL. During the CL discharging time constant
RLCL the voltage across the IMD itself is low and therefore the bias voltage would
have to be raised substantially to cause further firing. Thus, RLCL is analogous to
the refractory period of a neuron. The output pulses of an IMD generally have about
the same amplitude while the rate of pulsing varies over a wide range depending on
the bias voltage and the presence of electromagnetic radiation. 7,8,10

~ DETECTOR ARRAY

?=::I

TRANSIENT SENSING

?=::I MOTION

SENSING -

TRACKING

2-D PARALLEL OUTPUT

Figure 6: lllustrative
laminar architecture
showing stacked wafers in
3-dimensions.

LAMINAR
NEURAL NETWORK

REAL TIME PARALLEL ASYNCHRONOUS PROCESSING
The devices described here could form the hardware basis for a parallel asynchronous processor in much the same way that transistors form the basis for digital
computers. The devices could be used to construct networks which could perform real
time signal processing. Pulse propagation through silicon chips (parallel firethrough,
see Fig. 7) as opposed to the lateral planar propagation in conventional integrated
circuits has been proposed. 1S This would permit the use of laminar, stacked wafer
architectures. See Fig. 6.
Such architectures would eliminate the serial processing limitations of standard processors which utilize multiplexing and charge transfer. There are additional
advantages in terms of elimination of pre-amplifiers and reduction in power consumption. The approach would utilize the low power, low noise devices lO described here
to perform input signal-to-frequency conversion in every processing channel.
POWER CONSUMPTION FOR A BRAIN SCALE SYSTEM
The low power and low current requirements together with the electronic simplicity (lower parts-count as compared with transistor and op-amp approaches) and

205

INPUTS

;1""*""*""* *'""*""* '*""* '* '*""* ""*1
111111111111

;1* ***'* *""*""*""* *' **1

;1*
*
*
*
*
*
*
*
**
*
*1
;1*""*""*""*
*
**
*""*
'
*
""*
""*1
;1* **""* ***""*""* '*""* ""*1

Siwafer
Siwafer

Siwaf.r
Siwaf.r

Figure 7: Schematic illustration of the signal flow
pattern through a real time
parallel asynchronous processor consisting of stacked
silicon wafers.

wafer
; I I I I I I I I I I I I I 1SiSiwaf.r
! ! ! ! ! ! ! ! ! ! ! !
OUTPUTS

the natural emulation of neuron features means that the approach described here
would be especially advantageous for very large neural networks, e.g. systems comparable to supercomputers in which power dissipation and system complexity are important considerations. The power consumption of large scale analog 16 and digital 17
systems is always a major concern. For example, the power consumption of the
CRAY XMP-48 is of the order of 300 kilowatts. For the devices described here, the
power consumption is very low. For these devices, we have observed quiescent power
drains of about 1 n W /cm 2 and pulse power consumption of about 500 nJ/pulse/cm 2 ?
We estimate that a system with 1011 active 10~m x 10~m elements (comparable
to the number of neurons in the brain 18 ) all firing with an average pulse rate of 1
KHz (corresponding to a high neuronal firing rateS) would consume about 50 watts.
The quiescent power drain for this system would be 0.1 milliwatts. Thus, power
(P) requirements for such an artificial neural network with the size scale (1011 pulse
generating elements) of the human brain and a range of activity between zero and
the maximum conceivable sustained activity for neurons in the brain would be 0.1
milliwatts < P < 50 watts for 10 micron technology. For comparison, we note that
von Neumann's estimate for the power dissipation of the brain is of order 10 to 25
watts. S,6 Fabrication of a 1011 element 10 ~m artificial neural network would require
processing of about 1500 four inch wafers.
NETWORK CONNECTIVITY
For a network with coupling between many IMD's3 we have shown"" that

(1)
where Vj is the voltage across the diode and the input capacitance Cj of the i-th
network node, Rj represents a leakage resistance in parallel with Cil and Ij represents
an external current input to the i-th diode. iJ=1,2,3, ..... label different network nodes
and Tij incoporates coupling between network elements. Equation 1 has the same
form as equations which occur in the Hopfield modeI 2o ,21,22,23 for neural networks.
Sejnowski has also discussed similar equations in connection with skeleton filters in

206

OUTPUTS

INPUTS

;~
t----o
~f---r----t---t t----o
t----o

c);
o---j

R

o---j~~~~~'fi-~

o---j

R

:P---o

~:
TRANSMISSION LINE

Figure 8: a) Main features of a typical neuron from Kandel and Schwartz. 19 b) Our
artificial neuron) which shows the summation over synaptic inputs and fan-out.
the brain. 24 ?25 Nonlinear threshold behavior of IMD)s enters through F(V) as it does
in the neural network models.
In Fig. 8-b a range of input capacitances is possible. This range of capacitances
is related to the range of possible synaptic weights. The circuit in Fig. 8 accomplishes
pulse height discrimination and each pulse can contribute to the charge stored on
the central node capacitance C. The charge added to C during each input pulse is
linearly related to the input capacitance except at extreme limits. The range of input
capacitances for a particular experiment was .002 J-lF to .2 J-lF which differ by a factor
of about 100. The effect of various input capacitance values (synaptic weights) on
input-output firing rates is shown in Fig. 9. Also the Fig. 8-b shows many capacitive
inputs/outputs to/from a single IMD. i.e. fan-in and fan-out. For pulses which arrive
at different inputs at about the same time) the effect of the pulses is additive. The
time within which inputs are summed is just the stored charge lifetime. Summation
over many inputs is an important feature of neural information processing.
EXCITATION) INHIBITION) MEMORY
Both excitatory and inhibitory input circuits are shown in Fig. 10. Input pulses
cause the accumulation of charge on C in excitatory circuits and the depletion of
charge on C in inhibitory circuits. Charge associated with input spiketrains is integrated/stored on C. The temporally integrated charge is depleted by the firing of the
IMD. Thus) the storage time is related to the firing rate. After an input spiketrain
raises the potential across C to a value above the firing threshold) the resulting IMD

207

5

O.2}J F
O.03}JF

,--.,.
N

I

.;,<

4

Figure 9: Output pulse
rate vs. the input
pulse rate for different
input capacitance
values Ci values

W
t-

~

3

w

Vl

---1

::J
(L

2

t-

::J
CL
t-

6

1

20

40

80

60

100

INPUT PULSE RATE (Hz )

(0)
R

I NP~ I----'-~-r_{)l__--,----<>
OUTP UT

Figure 10: Circuits which incorporate rectifying synaptic inputs. a) an excitatory
input. b) an inhibitory input.

(b)
R
R'

INP~

c?

L

R'L

output spiketrain codes the input information. The output firing rate is linearly related to the input firing rate times the synaptic coupling strength (linearly related to
Ci). See Fig. 9. If the input ceases, then the potential across C relaxes back to a value
just below the firing threshold. When not firing, the IMD has a high impedance. If
there is negligible leakage of charge from C, then V can remain near V T (threshold
voltage) for a long time and a new input signal will quickly take the IMD over the
firing threshold. See Fig. 11. We have observed stored charge lifetimes of 56 days and
longer times may be acheivable. The lifetime of charge stored on C can be reduced
by adding a resistance in parallel with C.
From the discussion of integration, we see that long term storage of charge on C
is equivalent to long term memory. The memory can be read by seeing if a new input
pulse or spiketrain produces a prompt output pulse or spiketrain. The read signal
input channel in Fig. 8-b can be the same as or different from the channel which
resulted in the charge storage. In either case memory would produce a change in the
pattern of connectivity if the circuit was imbedded in a neural network. Changes in
patterns of connectivity are similar to Hebb's ruie considerations26 in which memory
is associated with increases in the strength (weight) of synaptic couplings. Frequently,

208

-

-QJ 13
o

a::

11

Figure 11: Firing rate vs. the bias voltage.
The region where the firing is negligible is
associated with memory. The state of the
memory is associated with the proximity
to the firing threshold.

Input Potential
the increase in synaptic weights is modeled by increased conductance whereas in the
circuits in Figs. lO(a) and 8-b memory is achieved by integration and charge storage.
Note that for these particular circuits, the memory is not eraseable although volatile
(short term) memory can easily be constructed by adding a resistor in parallel with
C. Thus, a continuous range of memory lifetimes can be achieved.
2-D PARALLEL ASYNCHRONOUS CHIP-TO-CHIP TRANSMISSION
For many IMD's the output pulse heights for a circuit like that in Fig. 1 are
>3 volts. Thus, output from the first stage or any later stage of the network could
easily be transmitted to other parts of an overall system. Two-dimensional arrays
of devices on different chips could be coupled by indium bump bonding to form
the laminar architecture described above. Planar technology could be used for local
lateral interconnections in the processor. (See Fig. 7) In addition to transmission of
electrical pulses, optical transmission is possible because the pulses can directly drive
LED's.
Emerging GaAs-on-Si technology is interesting as a means of fabricating two
dimensional emitter arrays. Optical transmission is not necessary but it might be
useful (A) for processed image data transfer, (B) for coupling to an optical processor, or (C) to provide 2-0 optical interconnects between chips bearing 2-D arrays of
p+ - n - n+ diodes. Note that with optical interconnects between chips, the circuits
employed here would be internal receivers. The p-i-n diodes employed in the present
work would be well suited to the receiver role. An interesting possibility would entail the use optical interconnects between chips to achieve local, lateral interaction.
This would be accomplished by having each optical emitter in a 2-D array broadcast
locally to multiple receivers rather than to a single receiver. Similarly, each receiver
would have a reeeptive field extending over multiple transmitters. It is also possible
that an optical element could be placed in the gap between parallel transmitter and
receiver planes to structure, control or alter 2-D patterns of interconnection. This
would be an alternative to a planar technology approach to lateral interconnection.
IT the optical elements were active then the system would constitute a hybrid optical/electronic processor, whereas if passive optical elements were employed, we would
regard the system as an optoelectronic processor. In either case, we picture the processing functions of temporal integration, spatial summation over inputs, coding and
pulse generation as residing on-chip.

209

ACKNOWLEDGEMENTS
The work was supported in part by U.S. DOE under contract #DE-AC0280ER10667 and NSF under grant # ECS-8603075.

References
[1] L. D. Harmon, Kybernetik 1,89 (1961).
[2] A. L. Hodgkin and A. F. Huxley, J. Physioll17, 500 (1952).
[3] D. D. Coon and A. G. U. Perera, Int. J. Electronics 63, 61 (1987).
[4] K. M. S. V. Bandara, D. D. Coon and R. P. G. Karunasiri, Infrared 'lransient
Sensing, to be published.
[5] J. von Neumann, The Computer and the Brain, Yale University Press, New
Haven and London, 1958.
[6] J. von Neumann, Collected Works, Pergamon Press, New York, 1961.
[7] D. D. Coon and A. G. U. Perera, Int. J. Infrared and Millimeter Waves 7, 1571
(1986).
[8] D. D. Coon and S. D. Gunapala, J. Appl. Phys 57, 5525 (1985).
[9] D. D. Coon, S. N. Ma and A. G. U. Perera, Phys. Rev. Let. 58, 1139 (1987).
[10] D. D. Coon and A. G. U. Perera, Applied Physics Letters 51, 1711 (1987).
[11] D. D. Coon and A. G. U. Perera, Solid-State Electronics 29, 929 (1986).
[12] D. D. Coon and A. G. U. Perera, Applied Physics Letters 51, 1086 (1987).
[13] K. M. S. V. Bandara, D.D. Coon and R. P. G. Karunasiri, Appl. Phys. Lett 51,
961 (1987).
[14] Y. N. Yang, D. D. Coon and P. F. Shepard, Applied Physics Letters 45, 752
(1984).
[15] D. D. Coon and A. G. U. Perera, Int. J. IR and Millimeter Waves 8, 1037 (1987).
[16] M. A. Sivilotti, M. R. Emerling and C. A. Mead, VLSI Arcbitectures for Implementation of Neural Networks, Neural Networks for Computing, A.J.P.,
1986, pp. 408-413.
[17] R. W. Keyes, Proc. IEEE 63, 740 (1975).
[18] E . R. Kandel and J. H. Schwartz, Principles of Neural Science, Elsevier, New
York, 1985.

210

[19] E. R. Kandel and J. H. Schwartz, Principles of Neural Science, Elsevier, New
York, 1985, page 15, Reproduced by permission of Elsevier Science Publishing
Co., N.Y ..
[20] J. J. Hopfield, Proc. Nat!. Acad. Sci. U.S.A 81, 3088 (1984).
[21] J. J. Hopfield and D. W. Tank, BioI. Cybern 52, 141 (1985).
[22] J. J. Hopfield and D. W. Tank, Science 233,625 (1986).
[23] D. W. Tank and J. J. Hopfield, IEEE. Circuits Syst. CAS-33, 533 (1986).
[24] T. J. Sejnowski, J. Math. Biology 4, 303 (1977).
[25] T. J. Sejnowski, Skeleton Filters in tbe Brain, Lawrence Erlbaum, New Jersey,
1981, pp. 189-212, edited by G. E. Hinton and J. A. Anderson.
[26] J. L. McClelland, D. E. Rumelhart and the PDP research group, Parallel Distributed Processing, The MIT Press, Cambridge, Massachusetts, 1986, two volumes.

"
23,1987,"A Computer Simulation of Cerebral Neocortex: Computational Capabilities of Nonlinear Neural Networks","",23-a-computer-simulation-of-cerebral-neocortex-computational-capabilities-of-nonlinear-neural-networks.pdf,"Abstract Missing","715

A COMPUTER SIMULATION OF CEREBRAL NEOCORTEX:
COMPUTATIONAL CAPABILITIES OF NONLINEAR NEURAL NETWORKS

Alexander Singer* and John P. Donoghue**

*Department of Biophysics, Johns Hopkins University,
Baltimore, MD 21218 (to whom all correspondence should
be addressed)
**Center for Neural Science, Brown University,
Providence, RI 02912

? American Institute of Physics 1988

716

A synthetic neural network simulation of cerebral neocortex was
developed based on detailed anatomy and physiology. Processing elements
possess temporal nonlinearities and connection patterns similar to those of
cortical neurons. The network was able to replicate spatial and temporal
integration properties found experimentally in neocortex. A certain level of
randomness was found to be crucial for the robustness of at least some of
the network's computational capabilities. Emphasis was placed on how
synthetic simulations can be of use to the study of both artificial and
biological neural networks.

A variety of fields have benefited from the use of computer simulations. This is
true in spite of the fact that general theories and conceptual models are lacking in many
fields and contrasts with the use of simulations to explore existing theoretical structures that
are extremely complex (cf. MacGregor and Lewis, 1977).

When theoretical

superstructures are missing, simulations can be used to synthesize empirical findings into a
system which can then be studied analytically in and of itself. The vast compendium of
neuroanatomical and neurophysiological data that has been collected and the concomitant
absence of theories of brain function (Crick, 1979; Lewin, 1982) makes neuroscience an
ideal candidate for the application of synthetic simulations. Furthennore, in keeping with
the spirit of this meeting, neural network simulations which synthesize biological data can
make contributions to the study of artificial neural systems as general infonnation
processing machines as well as to the study of the brain. A synthetic simulation of cerebral
neocortex is presented here and is intended to be an example of how traffic might flow on
the two-way street which this conference is trying to build between artificial neural network
modelers and neuroscientists.
The fact that cerebral neocortex is involved in some of the highest fonns of
information processing and the fact that a wide variety of neurophysiological and
neuroanatomical data are amenable to simulation motivated the present development of a
synthetic simulation of neocortex. The simulation itself is comparatively simple;
nevertheless it is more realistic in tenns of its structure and elemental processing units than
most artificial neural networks.
The neurons from which our simulation is constructed go beyond the simple
sigmoid or hard-saturation nonlinearities of most artificial neural systems. For example,

717

because inputs to actual neurons are mediated by ion currents whose driving force depends
on the membrane potential of the neuron. the amplitude of a cell's response to an input. i.e.
the amplitude of the post-synaptic potential (PSP). depends not only on the strength of the
synapse at which the input arrives. but also on the state of the neuron at the time of the
input's arrival. This aspect of classical neuron electrophysiology has been implemented in
our simulation (figure lA). and leads to another important nonlinearity of neurons:
namely. current shunting. Primarily effective as shunting inhibition. excitatory current can
be shunted out an inhibitory synapse so that the sum of an inhibitory postsynaptic potential
and an excitatory postsynaptic potential of equal amplitude does not result in mutual
cancellation. Instead. interactions between the ion reversal potentials. conductance values.
relative timing of inputs. and spatial locations of synapses determine the amplitude of the
response in a nonlinear fashion (figure IB) (see Koch. Poggio. and Torre. 1983 for a
quantitative analysis). These properties of actual neurons have been ignored by most
artificial neural network designers. though detailed knowledge of them has existed for
decades and in spite of the fact that they can be used to implement complex computations
(e.g. Torre and Poggio. 1978; Houchin. 1975).
The development of action potentials and spatial interactions within the model
neurons have been simplified in our simulation. Action potentials involve preprogrammed
\

fluctuations in the membrane potential of our neurons and result in an absolute and a
relative refractory period. Thus. during the time a cell is firing a spike synaptic inputs are
ignored. and immediately following an action potential the neuron is hyperpolarized. The
modeling of spatial interactions is also limited since neurons are modeled primarily as
spheres. Though the spheres can be deformed through control of a synaptic weight which
modulates the amplitudes of ion conductances. detailed dendritic interactions are not
simulated. Nonetheless. the fact that inhibition is generally closer to a cortical neuron's
soma while excitation is more distal in a cell's dendritic tree is simulated through the use of
stronger inhibitory synapses and relatively weaker excitatory synapses.
The relative strengths of synapses in a neural network define its connectivity.
Though initial connectivity is random in many artificial networks. brains can be thought to
contain a combination of randomness and fixed structure at distinct levels (Szentagothai.
1978). From a macroscopic perspective. all of cerebral neocortex might be structured in a
modular fashion analogous to the way the barrel field of mouse somatosensory cortex is
structured (Woolsey and Van der Loos. 1970). Though speculative, arguments for the
existence of some sort of anatomical modularity over the entire cortex are gaining ground

718

(Mountcastle, 1978; Szentagothai, 1979; Shepherd, in press). Thus, inspired by the
barrels of mice and by growing interest in functional units of 50 to 100 microns with on the
order of 1000 neurons, our simulation is built up of five modules (60 cells each) with more
dense local interconnections and fewer intermodular contacts. Furthermore, a wide variety
of neuronal classification schemes have led us to subdivide the gross structure of each
module so as to contain four classes of neurons: cortico-cortical pyramids, output
pyramids, spiny stellate or local excitatory cells, and GABAergic or inhibirtory cells.
At this level of analysis, the impressed structure allows for control over a variety of
pathways. In our simulation each class of neurons within a module is connected to every
other class and intermodular connections are provided along pathways from cortico-cortical
pyramids to inhibitory cells, output pyramids, and cortico-cortical pyramids in immediately
adjacent modules. A general sense of how strong a pathway is can be inferred from the
product of the number of synapses a neuron receives from a particular class and the
strength of each of those synapses. The broad architecture of the simulation is further
structured to emphasize a three step path: Inputs to the network impact most strongly on
the spiny stellate cells of the module receiving the input; these cells in tum project to
cortico-cortical pyramidal cells more strongly than they do to other cell types; and finally,
the pathway from the cortico-cortical pyramids to the output pyramidal cells of the same
module is also particularly strong. This general architecture (figure 2) has received
empirical support in many regions of cortex (Jones, 1986).
In distinction to this synaptic architecture, a fine-grain connectivity is defined in our
simulated network as well. At a more microscopic level, connectivity in the network is
random. Thus, within the confines of the architecture described above, the determination
of which neuron of a particular class is connected to which other cell in a target class is
done at random. Two distinct levels of connectivity have, therefore, been established
(figure 3). Together they provide a middle ground between the completely arbitrary
connectivity of many artificial neural networks and the problem specific connectivities of
other artificial systems. This distinction between gross synaptic architecture and fine-grain
connectivity also has intuitive appeal for theories of brain development and, as we shall
see, has non-trivial effects on the computational capabilities of the network as a whole.
With defintions for input integration within the local processors, that is within the
neurons, and with the establishment of connectivity patterns, the network is complete and
ready to perform as a computational unit. In order to judge the simulation's capabilities in
some rough way, a qualitative analysis of its response to an input will suffice. Figure 4

719

shows the response of the network to an input composed of a small burst of action
potentials arriving at a single module. The data is displayed as a raster in which time is
mapped along the abscissa and all the cells of the network are arranged by module and cell
class along the ordinate. Each marker on the graph represents a single action potential fIred
by the appropriate neuron at the indicated time. Qualitatively, what is of importance is the
fact that the network does not remain unresponsive, saturate with activity in all neurons, or
oscillate in any way. Of course, that the network behave this way was predetermined by
the combination of the properties of the neurons with a judicious selection of synaptic
weights and path strengths. The properties of the neurons were fixed from physiological
data, and once a synaptic architecture was found which produced the results in figure 4,
that too was fixed. A more detailed analysis of the temporal firing pattern and of the
distribution of activity over the different cell classes might reveal important network
properties and the relative importance of various pathways to the overall function. Such an
analysis of the sensitivity of the network to different path strengths and even to intracellular
parameters will, however, have to be postponed. Suffice it to say at this point that the
network, as structured, has some nonzero, finite, non-oscillatory response which,
qualitatively, might not offend a physiologist judging cortical activity.
Though the synaptic architecture was tailored manually and fixed so as to produce
""reasonable"" results, the fine-grain connectivity, i.e. the determination of exactly which
cell in a class connects to which other cell, was random. An important property of artificial
(and presumably biological) neural networks can be uncovered by exploiting the distinction
between levels of connectivity described above. Before doing so, however, a detail of
neural network design must be made explicit. Any network, either artificial or biological,
must contend with the time it takes to communicate among the processing elements. In the
brain, the time it takes for an action potential to travel from one neuron to another depends
on the conduction velocity of the axon down which the spike is traveling and on the delay
that occurs at the synapse connecting the cells. Roughly, the total transmission time from
one cortical neuron to another lies between 1 and 5 milliseconds. In our simulation two

720

paradigms were used. In one case, the transmission times between all neurons were
standardized at 1 msec.* Alternatively, the transmission times were fixed at random,
though admittedly unphysiological, values between 0.1 and 2 msec.
Now, if the time it takes for an action potential to travel from one neuron to another
were fixed for all cells at 1 msec, different fine-grain connectivity patterns are found to
produce entirely distinct network responses to the same input, in spite of the fact that the
gross synaptic architecture remained constant. This was true no matter what particular
synaptic architecture was used. If, on the other hand, one changes the transmission times
so that they vary randomly between 0.1 and 2 msec, it becomes easy to find sets of
synaptic strengths that were robust with respect to changes in the fine-grain connectivity.
Thus, a wide search of path strengths failed to produce a network which was robust to
changes in fine-grain connectivity in the case of identical transmission times, while a set of
synaptic weights that produced robust responses was easy to find when the transmission
times were randomized. Figure 5 summarizes this result. In the figure overall network
activity is measured simply as the total number of action potentials generated by pyramidal
cells during an experiment and robustness can be judged as the relative stability of this
response. The abscissa plots distinct experiments using the same synaptic architecture with
different fine-grain connectivity patterns. Thus, though the synaptic architecture remains
constant, the different trials represent changes in which particular cell is connected to which
other cell. The results show quite dramatically that the network in which the transmission
times are randomly distributed is more robust with respect to changes in fine-grain
connectivity than the network in which the transmission times are all 1 msec.
It is important to note that in either case, both when the network was robust and
when changes of fine-grain connectivity produced gross changes in network output, the
synaptic architectures produced outputs like that in figure 4 with some fine-grain
connectivities. If the response of the network to an input can be considered the result of

*

Because neurons receive varying amounts of input and because integration is performed
by summating excitatory and inhibitory postsynaptic potentials in a nonlinear way, the time
each neuron needs to summate its inputs and produce an action potential varies from neuron
to neuron and from time to time. This then allows for asynchronous fuing in spite of the
identical transmission times.

721

some computation, figure 5 reveals that the same computational capability is not robust
with respect to changes in fine-grain connectivity when transmission times between
neurons are all 1 msec, but is more robust when these times are randomized. Thus, a
single computational capability, viz. a response like that in figure 4 to a single input, was
found to exist in networks with different synaptic architectures and different transmission
time paradigms; this computational capability, however, varied in terms of its robustness
with respect to changes in fine-grain connectivity when present in either of the transmission
time paradigms.
A more complex computational capability emerged from the neural network
simulation we have developed and described. If we label two neighboring modules C2 and
C3, an input to C2 will suppress the response of C3 to a second input at C3 if the second
input is delayed. A convenient way of representing this spatio-temporal integration
property is given in figure 6. The ordinate plots the ratio of the normal response of one
module (say C3) to the response of the module to the same input when an input to a
neighboring module (say C2) preceeds the input to the original module (C3). Thus, a value
of one on the ordinate means the earlier spatially distinct input had no effect on the response
of the module in which this property is being measured. A value less than one represents
suppression, while values greater than one represent enhancement. On the abscissa, the
interstimulus interval is plotted. From figure 6, it can be seen that significant suppression
of the pyramidal cell output, mostly of the output pyramidal cell output, occurs when the
inputs are separated by 10 to 30 msec. This response can be characterized as a sort of
dynamic lateral inhibition since an input is suppressing the ability of a neighboring region
to respond when the input pairs have a particular time course. This property could playa
variety of role in biological and artificial neural networks. One role for this spatio-temporal
integration property, for example, might be in detecting the velocity of a moving stimulus.
The emergent spatio-temporal property of the network just described was not
explicitly built into the network. Moreover, no set of synaptic weights was able to give rise
to this computational capability when transmission times were all set to 1 msec. Thus, in
addition to providing robustness, the random transmission times also enabled a more
complex property to emerge. The important factor in the appearances of both the
robustness and the dynamic lateral inhibition was randomization; though it was
implemented as randomly varying transmission times, random spontaneous activity would
have played the same role. From the viewpoint, then, of the engineer designing artificial
neural networks, the neural network presented here has instructional value in spite of the

722

fact that it was designed to synthesize biological data. Specifically, it motivates the
consideration of randomness as a design constraint.
From the prespective of the biologists attending this meeting, a simple fact will
reveal the importance of synthetic simulations. The dynamic lateral inhibition presented in
figure 6 is known to exist in rat somatosensory cortex (Simons, 1985). By deflecting the
whiskers on a rat's face, Simons was able to stimulate individual barrels of the posteromedial somatosensory barrel field in combinations which revealed similar spatio-temporal
interactions among the responses of the cortical neurons of the barrel field. The temporal
suppression he reported even has a time course similar to that of the simulation. What the
experiment did not reveal, however, was the class of cell in which suppression was seen;
the simulation located most of the suppression in the output pyramidal cells. Hence, for a
biologist, even a simple synthetic simulation like the one presented here can make defmitive
predictions. What differentiates the predictions made by synthetic simulations from those
of more general artificial neural systems, of course, is that the strong biological foundations
of synthetic simulations provide an easily grasped and highly relevant framework for both
predictions and experimental verification.
One of the advertised purposes of this meeting was to ""bring together
neurobiologists, cognitive psychologists, engineers, and physicists with common interest
in natural and artificial neural networks."" Towards that end, synthetic computer
simulations, i.e. simulations which follow known neurophysiological and neuroanatomical
data as if they comprised a complex recipe, can provide an experimental medium which is
useful for both biologists and engineers. The simulation of cerebral neocortex developed
here has information regarding the role of randomness in the the robustness and presence
of various computational capabilities as well as information regarding the value of distinct
levels of connectivity to contribute to the design of artificial neural networks. At the same
time, the synthetic nature of the network provides the biologist with an environment in
which he can test notions of actual neural function as well as with a system which replicates
known properties of biological systems and makes explicit predictions. Providing twoway interactions, synthetic simulations like this one will allow future generations of
artificial neural networks to benefit from the empirical findings of biologists, while the
slowly evolving theories of brain function benefit from the more generalizable results and
methods of engineers.

723

References
Crick, F. H. C. (1979) Thinking about the brain, Scientific American, 241:219 - 232.
Houchin,1. (1975) Direction specificity in cortical responses to moving stimuli -- a simple
model. Proceedings of the Physiological Society, 247:7 - 9.
Jones, E. G. (1986) Connectivity of primate sensory-motor cortex, in Cerebral Cortex,
vol. 5, E. G. Jones and A. Peters (eds), Plenum Press, New York.
Koch, C., Poggio, T., and Torre, V. (1983) Nonlinear interactions in a dendritic tree:
Localization, timing, and role in information processing. Proceedings of the
National Academy of Science, USA, 80:2799 - 2802.
Lewin, R. (1982) Neuroscientists look for theories, Science, 216:507.
MacGregor, R.I. and Lewis, E.R. (1977) Neural Modeling, Plenum Press, New York.
Mountcastle, V. B. (1978) An organizing principle for cerebral function: The unit module
and the distributed system, in The Mindful Brain, G. M. Edelman and V. B.
Mountcastle (eds.), MIT Press, Cambridge, MA.
Shepherd, G.M. (in press) Basic circuit of cortical organization, in Perspectives in Memory
Research, M.S. Gazzaniga (ed.). MIT Press, Cambridge, MA.
Simons, D. J. (1985) Temporal and spatial integration in the rat SI vibrissa cortex, Journal
of Neurophysiology, 54:615 - 635.
Szenthagothai,1. (1978) Specificity versus (quasi-) randomness in cortical connectivity, in
Architectonics of the Cerebral Cortex, M. A. B. Brazier and H. Petsche (eds.),
Raven Press, New York.
Szentagothai, J. (1979) Local neuron circuits in the neocortex, in The Neurosciences.
Fourth Study Program, F. O. Schmitt and F. G. Worden (eds.), MIT Press,
Cambridge, MA.
Torre, V. and Poggio, T. (1978) A synaptic mechanism possibly underlying directional
selectivity to motion, Proceeding of the Royal Society (London) B, 202:409 -416.
Woolsey, T.A. and Van der Loos, H. (1970) Structural organization of layer IV in the
somatosensory region (SI) of mouse cerebral cortex, Brain Research, 17:205-242.

724

Shunting Inhibition

Simultaneous
EPSP & IPSP

IPSP

Figure IA: Intracellular records of post-synaptic potentials resulting from single excitatory and
inhibitory inputs to cells at different resting potentials.

PSP Amplitude Dependence on Membrane Potential

IPSPs

EPSPs
Resting
Potential
? ?40 mV
Resting
Potential
? -60 mV

Resting
Potential
? 40 mV

r-

Resting
Potential
_ -80 mV

L -_ _ _ _ __

I
C'=:-::----

Resting
Potential
- -100 mV .... - - - - - Resting
Potential

_ -120 mV

~

c=

Resting
Potential
- 20 mV

r-

Resting
Potential
- OmV
Resting
Potential
?20 mV

-

I

c----:----L..
_ _ _ _ _ __

Resting
~
Potential
- -40mV

~

Figure IB: Illustration of the current shunting nonlinearity present in the model neurons. Though
the simultaneous arrival of postsynaptic potentials of equal and opposite amplitude would result
in no deflection in the membrane potential of a simple linear neuron model, a variety of factors
contribute to the nonlinear response of actual neurons and of the neurons modeled in the present
simulation.

:-:""~:"":-

~
""""'XX"""""""""",""
:::::. C.a.lls ::::
,, .
, .
, ,, .
,

',,""
.
"" ..................................
"" "" "" '"" '"" "" "" ' ""

;luu
,~,

,,
,,,

. . ,... ,. .. .... ..,
,

~' ..

"". "" ..""' . """" .."" ..' ..

.' . ""..'.'.' .'.""' .. ' . ' ...' ..',""
~,,;

;,"".
.,~

Output

~;.

Pyramids

,,

\.

~."" '.

~~

,,,

,

';

, ,""

.,"",

)

"",~
~

..
,.., ..,..,..,.., .., .., ........ ,..,..,.., ..,.. ,..,.., .."",,:.,'.,',,-.,-,, '.,'.,'.,-,,-,,-.,-,,',,-.,',,'.,'.,'., '.,-.,'.,'.,-,,-,,'.,-.,-,,-,,-,,-.,',,',,',,'.,-,,',, '.,-.,-,,',, -,, -.,',,'.,'.,-,,',,',, -,,-.,-,,',,',, -.,'.,'., -., ',,',,', ......
.'.'.'.' .'.' .' .'

Input

Figure 2: A schematic representation of the simulated cortical network. Five modules are used, each containing sixty neurons. Neurons are
divided into four classes. Numerals within the caricatured neurons represent the number of cells in that particular class that are simulated.
Though all cell classes are connected to all other classes, the pathway from input to spiny stellate to cortico-cortical pyramids to output
pyramids is particularly strong.

....::J

~

01

726

Path Strength Number of synapses X
~,.,.....,.,.
...
of

6.
6.

6.

6.

6.6.

6.

0

0

6
0

0

0
0

6.

Output
Pyramidal Cells

6,.

0

0

6.6. 6.
6. 6.

6.

t:..

6.

0
Inhibitory
Cells

6,.

6,. 6

6
6
6~
Intracorlical
Pyramidal Cells

? ? ?
0?0
? ?
? ?
Spiny Stellate
Cells

Figure 3: Two levels of connectivity are defined in the network. Gross synaptic architecture is
defined among classes of cells. Fine-grain connectivity specifies which cell connects to which
other cell and is determined at random .

727

Sample Raster
Input: 333 Hz input, 6 rns duration applied to Module 3
Module

S

Module
4

Module
3

..

-...-

..
.""

Module
2

.....

~

:

.
.

--

Cortico-c ortical
ramids
- - - py

Inhibitory
cells
-............ Spin y stellate
cells
-Output
pyr amids

..

:

-

Module
1

I
10

..
Time (ms)

I

I

20

30

Figure 4: Sample response of the entire network to a small burst of action potentials delivered to
module 3.

728

Robustness With Respect to Connectivity Pattern
Synaptic Architecture Constant

400

?

III
I/)

c:

300

0

?

c.
C/)
III

a:

\

Q)

Delay times = 1 ms

()

iU
""C

200

?

'E
~

>.

a..

iU

jDera

""0

~

?
y times random

100

??

I

? ?

? ??

?
? ?

??

?
?
? ? ?

?

Individual Trials with Different Fine-grain Connectivity Patterns

Figure 5: Plot of an arbitrary activity measure (total spike activity in all pyramidal cells) versus
various instatiations ofthe same connectional architecture. Along the abscissa are represented the
different fine-grained patterns of connectivity within a fixed connectional architecture. In one
case the conductance times between all cells was I msec and in the other case the times were
selected at random from values between 0.1 msec and 2 msec. This experiment shows the greater
overall stability produced by random conduction times.

2

Spatio-Temporal Integration Properties

Q)

... Outpyr

fY.

'""0c:

a.

a:'""
Q)
Q)

>

'-;a
~
a:

... C?Cpyr
. . Sst
-+- GABA

Randomized Axonal Conduction Times

oI
o

~

20

40

60

80

100

120

Interstimulus Interval

Figure 6: Spatio-temporal integration within the network. Plot of the time course of response suppression in the various cell classes. The
ordinate plots the ratio of average cell activity (in terms of spikes) to a direct input after the presentation of an input to a neighboring mod ule,
and the average reponse to an input in the absence of prior input to an adjacent module. Values greater than one represent an enhancement of
activity in response to the spatially distinct preceeding input, while values less than one represent a suppression of the normal reponse. The
abscissa plots the interstimulus interval. Note that the response suppression is most striking in only one class of cells.

-.J

~

t:O

"
24,1987,"Optimal Neural Spike Classification","",24-optimal-neural-spike-classification.pdf,"Abstract Missing","95

OPTIMAL NEURAL SPIKE CLASSIFICATION
Amir F. Atiya(*) and James M. Bower(**)
(*) Dept. of Electrical Engineering
(**) Division of Biology
California Institute of Technology
Ca 91125

Abstract
Being able to record the electrical activities of a number of neurons simultaneously is likely
to be important in the study of the functional organization of networks of real neurons. Using
one extracellular microelectrode to record from several neurons is one approach to studying
the response properties of sets of adjacent and therefore likely related neurons. However, to
do this, it is necessary to correctly classify the signals generated by these different neurons.
This paper considers this problem of classifying the signals in such an extracellular recording,
based upon their shapes, and specifically considers the classification of signals in the case when
spikes overlap temporally.

Introduction
How single neurons in a network of neurons interact when processing information is likely
to be a fundamental question central to understanding how real neural networks compute.
In the mammalian nervous system we know that spatially adjacent neurons are, in general,
more likely to interact, as well as receive common inputs. Thus neurobiologists are interested
in devising techniques that allow adjacent groups of neurons to be sampled simultaneously.
Unfortunately, the small scale of real neural networks makes inserting one recording electrode
per cell impractical. Therefore, one is forced to use single electrodes designed to sample neural signals evoked by several cells at once. While this approach provides the multi-neuron
recordings being sought, it also presents a rather serious waveform classification problem because the actual temporal sequence of action potentials in each individual neuron must be
deciphered. This paper describes a method for classifying the activities of several individual
neurons recorded simultaneously using a single electrode.

Description of the Problem
Over the last two decades considerable attention 1-8 has been devoted to the problem of
classification of action potentials in multi-neuron recordings. These action potentials (also
referred to as ""spikes"") are the extracellularly recorded signal produced by a single neuron
when it is passing information to other neurons (Fig. 1). Fortunately, spikes recorded from the
same cell are more or less similar in shape, while spikes coming from different neurons usually
have somewhat different shapes, depending on the neuron type, electrode characteristics, the
distance between the electrode and the neuron, and the intervening medium. Fig. 1 illustrates
some representative variations in spike shapes. It is our objective to detect and classify different
spikes based on their shapes. However, relying entirely on the shape of the spikes presents
difficulties. For example spikes from different neurons can overlap temporally producing novel
waveforms (see Fig. 2 for an example of an overlap). To deal with these overlaps, one has first
to detect the occurrence of an overlap, and then estimate the constituent spikes. Unfortunately,
only a few of the available spike separation algorithms consider these events, even though they
are potentially very important in understanding neural networks. Those few tend to rely

? American Institute of Physics 1988

96

on heuristic rules and subtractive methods to resolve overlap cases. No currently published
method we are aware of attempts to use knowledge of the likelihood of overlap events for
detecting them, which is at the basis of the method we will describe.

Fig. 1
An example of a multi-neuron recording

overlapping spikes

Fig. 2
An example of a temporal overlap of action potentials

General Approach
The first step in classifying neural waveforms is obviously to identify the typical spike
shapes occurring in a particular recording. To do this we have applied a learning algorithm
on the beginning portion of the recording, which in an unsupervised fashion (i.e. without the
intervention of a human operator) estimates the shapes. After the learning stage we have
the classification stage, which is applied on the remaining portion of the recording. A new
classification method is proposed, which gives minimum probability of error, even in case of the
occurrence of overlapping spikes. Both the learning and the classification algorithms require
a preprocessing step to detect the position of the spike candidate in the data record.

Detection: For the first task of detection most researchers use a simple level detecting
algorithm, that signals a spike when recorded voltage levels cross a certain voltage threshold.
However, variations in recording position due to natural brain movements during recording
(e.g. respiration) can cause changes in relative height of the positive to the negative peak.
Thus, a level detector (using either a positive or a negative threshold) can miss some spikes.
Alternatively, we have chosen to detect an event by sliding a window of fixed length until a
time when the peak to peak value within the window exceeds a certain threshold.
Learning: Learning is performed on the beginning portion of the sampled data using
the Isodata clustering algorithm 9. The task is to estimate the number of neurons n whose
spikes are represented in the waveform and learn the different shapes of the spikes of the
various neurons. For that purpose we apply the clustering algorithm choosing only one feature

97

from the spike, the peak to peak value which we have found to be quite an effective feature.
Note that using the peak to peak value in the learning stage does not necessitate using it for
classification (one might need additional or different features, especially for tackling the case
of spike overlap) .

The Optimal Olassification Rule: Once we have identified the number of different events
present, the classification stage is concerned with estimating the identities of the spikes in the
recording, based on the typical spike shapes obtained in the learning stage. In our classification
scheme we make use of the information given by the shape of the detected spike as well
as the firing rates of the different neurons. Although the shape plays in general the most
important role in the classification, the rates become a more significant factor when dealing
with overlapping events. This is because in general overlap is considerably less frequent than
single spikes. The shape information is given by set of features extracted from the waveform.
Let x be the feature vector of the detected spike (e.g. the samples of the spike waveform). Let
N I , ... , N n represent the different neurons. The detection algorithm tells us only that at least
one spike occurred in the narrow interval (t - TI,t + T 2) (= say 1) where t is the instant of
the peak of the detected spike, TI and T2 are constants chosen subjectively according to the
smallest possible time separation between two consecutive spikes, identifiable as two separate
(nonoverlapping) spikes. By definition, if more than one spike occurs in the interval I, then
we have an overlap. As a matter of convention, the instant of the occurrence of a spike i...
taken to be that of the spike peak. For simplicity, we will consider the case of two possibly
overlapping spikes, though the method can be extended easily to more. The classification rule
which results in minimum probability of error is the one which chooses the neuron (or pair of
neurons in case of overlap) which has the maximum likelihood. We have therefore to compare
the Pi'S and the P,/s, defined as

a

~

= P(Ni

fired in Ilx, A),

P,j = P(N, and N j fired in Ilx, A),

i

= 1, ... ,n

l,j=I, ... ,n,

j<l

where A represents the event that one or two spikes occurred in the interval I. In other words
Pi the probability that what has been detected is a single spike from neuron i, whereas P,j
is the probability that we have two overlapping spikes from neurons land j (note that spikes
from the same neuron never overlap). Henceforth we will use I to denote probability density.
For the purpose of abbreviation let Bi(t) mean ""neuron Ni fired at t"". The classification
problem can be reduced to comparing the following likelihood functions:

i = 1, ... ,n

(la)

"" j = 1, ... , n, j < I

(lb)

(for a derivation refer to Appendix). Let Ii be the density of the inter-spike interval and Ti be
the most recent firing instant of neuron Ni . IT we are given the fact that neuron Ni has been
idle for at least a period of duration t - Ti, we get

A disadvantage of using (2) is that the available /i's and T&,S are only estimates, which depend
on the previous classification results, Further, for reliable estimation of the densities Ii, one
needs a large number of spikes and therefore a long learning period since we are estimating a

98

whole function. Therefore, we have not used this form, but instead have used the following two
schemes. In the first one, we ignore the knowledge about the previous firing pattern except
for the estimated firing rates >'1, ... , >'n of the different neurons Nl, ... , N n respectively. Then
the probability of a spike coming from neuron Ni in an interval of duration dt is simply >'idt.
Hence

In the second scheme we do not use any previous knowledge except for the total firing rate (of
all neurons), say a. Then

Although the second scheme does not use as much of the information about the firing
pattern as the first scheme does, it has the advantage of obtaining and using a more reliable
estimate of the firing rate, because in general the overall firing rate changes less with time than
the individual rates and because the estimate of a does not depend on previous classification
results. However, it is useful mostly when the firing rates of the different neurons do not vary
much, otherwise the firt scheme is preferred.
In real recording situations, sometimes one encounters voltage signals which are much
different than any of the previously learned typical spike shapes or their pairwise overlaps.
This can happen for example due to a falsely detected noise event, a spike from a class not
encountered in the learning stage, or to the overlap of three or more spikes. To cope with
these cases we use the reject option. This means that we refuse to classify the detected spike
because of the unlikeliness of the assumed event A. The reject option is therefore employed
whenever P(Alx) is smaller than a certain threshold. We know that

P(Alx) = J(A,x)/[J(A,x)

+ J(A C,x)]

where AC is the complement of the event A. The density f(AC,x) can be approximated as
uniform (over the possible values of x) because a large variety of cases are covered by the event
AC. It follows that one can just compare J(A,x) to a threshold. Hence the decision strategy
becomes finally: Reject if the sum of the likelihood functions is less than a threshold. Otherwise
choose the neuron (or pair of neurons) corresponding to the largest likelihood functions. Note
that the sum of the likelihood functions equals J(A,x) (refer to Appendix).
Now, let us evaluate the integrals in (1). Overlapping spikes are assumed to add linearly.
Since we intend to handle the overlap case, we have to use a set of features Xm which obeys
the following. Given the features of two of the waveforms, then one can compute those of their
overlap. A good such candidate is the set of the samples of the spike (or possibly also just
part of the samples). The added noise, partly thermal noise from the electrode and partly
due to firings from distant neurons, can usually be approximated as white Gaussian. Let the
variance be a 2 ? The integrals in the likelihood functions can be approximated as summations
(note in fact that we have samples available, not a continuous waveform). Let yi represent the
typical feature vector (template) associated with neuron N i , with the mth component being
y;"". Then

M

J(xIB/(kI), Bj(kd) =

(21r)~/2aM exp[ - 2~2 '~l (x m

-

y!n-k 1

-

y~_k2)2]

99

where Xm is the mth component of x, and M is the dimension of x. This leads to the following
likelihood functions
M~

L~ = f(Bd k ))

exp[- 2~2

L

kl=-M 1

M)

LL? = f(B,(k))f(Bj(k)) L

Ml

L

kl=-Mlkl=-Ml

M

:L (xm - Y:n_kJ 2]
m=l

exp[- 2~2

M

L (x m -

y!n-k 1

-

y~_kl)2]

m=l

where k is the spike instant, and the interval from -Ml to M2 corresponds to the interval I
defined at the beginning of the Section.
Implementation
The techniques we have just described were tested in the following way. For the first
experiment we identified two spike classes in a recording from the rat cerebellum. A signal
is created, composed of a number of spikes from the two classes at random instants, plus
noise. To make the situation as realistic as possible, the added noise is taken from idle periods
(i.e. non-spiking) of a real recording. The reason for using such an artificially generated
signal is to be able to know the class identities of the spikes, in order to test our approach
quantitatively. We implement the detection and classification techniques on the obtained
signal, with various values of noise amplitude. In our case the ratio of the peak to peak values
of the templates turns out to be 1.375. Also, the spike rate of one of the clases is twice that of
the other class. Fig.3a shows the results with applying the first scheme (i.e. using Eq. 3). The
overall percentage correct classification for all spikes (solid curve) and the percentage correct
classification for overlapping spikes (dashed curve) are plotted versus the standard deviation
of the noise (]"" normalized with respect to the peak h of the large template. Notice that the
overall classification accuracy is near 100% for (]"" I h less than 0.15, which is actually the range
of noise amplitudes we mostly encountered in our work with real recordings. Observe also
the good results for classifying overlapping events. We have applied also the second scheme
(i.e. using Eq. 4) and obtained similar results. We wish to mention that the thresholds for
detection and for the reject option are set up so as to obtain no more than 3% falsely detected
spikes.
A similar experiment is performed with three waveforms (three classes), where two of the
waveforms are the same as those used in the first experiment . The third is the average of
the first two. All the three neurons have the same spike rate (i.e. ..\1 = ..\2 = ..\3)' Hence
both classification schemes are equivalent in this case. Fig. 3b shows the overall as well as
the sub-category of overlap classification results. One observes that the results are worse than
those for the two-class case. This is because the spacings between the templates are in general
smaller. Notice also that the accuracy in resolving overlapping events is now tangibly less
than the overall accuracy. However, one can say that the results are acceptable in the range
of (]""
less than 0.1. The following experiment is also performed using the same data. We
would like to investigate the importance of the information given by the (overall) firing rate on
the problem of classifying overlapping events. In our method the summation in the likelihood
functions for single spikes is multiplied by Otln, while that for overlapping spikes is multiplied
by (Otln)2 . Usually Otln is considerably less than one. Hence we have a factor which gives less
weight for overlapping events. Now, consider the case of ignoring completely the information
given by the firing rate and relying solely on sha.pe information. We assume that overlapping
spikes from any two given classes represent ""new"" class of waveforms and that each of these
overlap classes has the same rate as that of a single-spike cla.ss. In that case we can obtain
expressions for the likelihood functions as consisting just the summations, i.e. free of the rate

Ih

100

..-

-

1?? -

-;

1?? -

..

?
;- 51.?
C
?e d._

-

51.-

""

..... ...

C

;

;

...
It._

It._

I.
I.

....S

...""

1.111

I . ISZ

'.l,'

I.
I.

????? /t.

..

...

1.1""
? I ???

a

I . ISZ

l .ltI

,1.

b

1? ?-

-;
~

??
c

C

?

;?

...

.,-

-

51.-

...

It._
I.

I.

.....

1.11t

1.1""

1.I!Il

????? /t.

c

Fig. 3
a) Overall (solid curve) and overlap (dashed curve)
classification accuracy for a two class case
b) Overall (solid curve) and overlap (dashed curve)
classification accuracy for a three class case
c)Percent of incorrect classification of single spikes as overlap
solid curve: scheme utilzing the spike rate
dashed curve: scheme not utilising the spike rate

factor Olin (refer to Appendix). An experiment is performed using that scheme (on the same
three class data). One observes that the method classifies a number of single spikes wrongly
as overlaps, much more than our original scheme does (see Fig. 3c), especially for the large
noise case. On the other hand, the number of overlaps which are classified wrongly as single
spikes is near zero for both schemes.
Finally, in the last experiment the techniques are implemented on real recordings from the
rat cerebellum. The recorded signal is band-pass-filtered in the frequency range 300 Hz - 10
KHz, then sampled with a rate of 20KHz. For classification, we take 20 samples per spike as
features. Fig. 4 shows the results ofthe proposed method, using the first scheme (Eq. 3). The
number of neurons whose spikes are represented in the waveform is estimated to be four. The

101

detection threshold is set up so that spikes which are too small are disregarded, because they
come from several neurons far away from the electrode and are hard to distinguish. Notice
the overlap of classes 1 and 2, which was detected. We used the second scheme also on the
same portion and it gave similar results as those of the first scheme (only one of the spikes is
classified differently). Overall, the discrepancies between classifications done by the proposed
method and an experienced human observer were found to be small.

3

2

3

3

4

1

2

3

3

1,2

2

3
1

3

1

3

2

4

Fig. 4
Classification results for a recording from the rat cerebellum

Conclusion
Many researchers have considered the problem of spike classification in multi-neuron
recordings, but only few have tackled the case of spike overlap, which could occur frequently,
particularly if the group of neurons under study is stimulated. In this work we propose a
method for spike classification, which can also aid in detecting and classifying overlapping
spikes. By taking into account the statistical properties of the discharges of the neurons sampled, this method minimizes the probability of classification error. The application of the
method to artificial as well as real recordings confirm its effectiveness.

Appendix
Consider first P'i' We can write

102

We can also obtain
R. =

It+T2[t+T2

IJ

t-T1

t-Tl

f(x,AIBI(t d ,Bj (t 2 ))f(B (t ) B ?(t ))dt dt
f( A)
I 1, J 2
1 2?
x,

Now, consider the two events B1(td and B j (t 2 ). In the absense of any information about their
dependence, we assume that they are independent. We get

Within the interval I, both f(B/(tt)) and f(B j (t2)) hardly vary because the duration of
I is very small compared to a typical inter-spike interval. Therefore we get the following
approximation:
f(B/(td) ~ f(B,(t))
f(B j (t2)) ~ f(Bj(t)).
The expression for

P""j

P""j ~

becomes
f(B,(t))f(B ?(t))

f

()J
X,

A

[t+T2
t-Tl

[t-

T2

f(xIB/(td, B j (t2))dt 1 dt 2 ?

t-Tl

Notice that the term A was omitted from the argument of the density inside the integral,
because the occurrence of two spikes at tl and t2El implies the occurrence of A. A similar
derivation for ~ results in

The term f(x, A) is common to all the Pils and the Pi's. Hence one can simply compare the
following likelihood functions:

Aeknow ledgement
Our thanks to Dr. Yaser Abu-Mostafa for his assistance with this work. This project was
supported by the Caltech Program of Advanced Technology (sponsored by Aerojet,GM,GTE,
and TRW), and the Joseph Drown Foundation.

References

II] M. Abeles and M. Goldstein, Proc. IEEE, 65, pp.762-773, 1977.
12] G. Dinning and A. Sanderson, IEEE Trans . Bio - M ed. Eng., BME-28, pp. 804-812,
1981.
13] E. D'Hollander and G. Orban, IEEE Trans . Bio-Med. Eng., BME-26, pp. 279-284, 1979.
14] D. Mishelevich, IEEE Trans. Bio-Med. Eng., BMFr17, pp. 147-150, 1970.
Is] V. Prochazka and H. Kornhuber, Electroenceph. din. Neurophysiol., 32, pp. 91-93, 1973.
16] W . Roberts, Bioi. Gybernet., 35, pp. 73-80, 1979.
17] W. Roberts and D. Hartline, Brain Res., 94, pp. 141-149, 1975.
18] E. Schmidt, J. Neurosci. Methods, 12, pp. 95-111, 1984.
19] R. Duda and P. Hart, Pattern Classification and Scene Analysis, John Wiley, 1973.

"
25,1987,"Computing Motion Using Resistive Networks","",25-computing-motion-using-resistive-networks.pdf,"Abstract Missing","422

COMPUTING MOTION USING RESISTIVE NETWORKS
Christof Koch, Jin Luo, Carver Mead
California Institute of Technology, 216-76, Pasadena, Ca. 91125
James Hutchinson
Jet Propulsion Laboratory, California Institute of Technology
Pasadena, Ca. 91125
INTRODUCTION
To us, and to other biological organisms, vision seems effortless. We open
our eyes and we ""see"" the world in all its color, brightness, and movement.
Yet, we have great difficulties when trying to endow our machines with similar
abilities. In this paper we shall describe recent developments in the theory of
early vision which lead from the formulation of the motion problem as an illposed one to its solution by minimizing certain ""cost"" functions. These cost
or energy functions can be mapped onto simple analog and digital resistive
networks. Thus, we shall see how the optical flow can be computed by injecting
currents into resistive networks and recording the resulting stationary voltage
distribution at each node. These networks can be implemented in cMOS VLSI
circuits and represent plausible candidates for biological vision systems.
APERTURE PROBLEM AND SMOOTHNESS ASSUMPTION
In this study, we use intensity-based schemes for recovering motion. Let us
derive an equation relating the change in image brightness to the motion of the
image (see l ). Let us assume that the brightness of the image is constant over
time: dI(~,y,t)/dt = o. On the basis of the chain rule of differentiation, this
transforms into

81 d~
8~ dt

81 dy

81

+ 8y dt + at = Izu + Iyv + It = 'V I? v + It =

0,

(1)

where we define the velocity v as (u,v) = (d:1)/dt,dy/dt). Because we assume
that we can compute these spatial and temporal image gradients, we are now
left with a single linear equation in two unknowns, u and v, the two components
of the velocity vector (aperture problem). Any measuring system with a finite
aperture, whether biological or artificial, can only sense the velocity component
perpendicular to the edge or along the spatial gradient (-It! 1'V I I). The
component of motion perpendicular to the gradient cannot, in principle, be
registered. The problem remains unchanged even if we measure these velocity
components at many points throughout the image.
How can this problem be made well-posed, that is, having a unique solution depending continuously on the data? One form of ""regularizing"" ill-posed
@ American Institute of Physics 1988

423

problems is to restrict the class of admissible solutions by imposing appropriate
constraints 2 ? Applying this method to motion, we shall argue that in general objects are smooth-except at isolated discontinuities-undergoing smooth
movements. Thus, in general, neighboring points in the world will have similar
velocities and the projected velocity field should reflect this fact. We therefore
impose on the velocity field the constraint that it should be the smoothest as well
as satisfying the data. As measure of smoothness we choose, the square of the
velocity field gradient. The final velocity field (u, v) is the one that minimizes

JJ [(::)' + (::)' + (~:)' + (:~)'] dz dy

A

+

+

+

.,

+

(2)

+

II:,

+

_I~

+

+

+

!al

(b)

Fig. 1. ( a) The location of the horizontal (lfj) and vertical (Iij) line processes
relative to the motion field nngrid. (b) The hybrid resistive network, computing
the optical flow in the presence of discontinuities. The conductances T c - ij connecting both grids depend on the brightness gradient, as do the conductances
gij and gij connecting each node with the battery. For clarity, only two such
elements are shown. The battery Eij depends on both the temporal and the
spatial gradient and is zero if no brightness change occurs. The ~ (resp. y) component of the velocity is given by the voltage in the top (resp. bottom) network.
Binary switches, which make or break the resistive connections between nodes,

424

implement motion discontinuities. These switches could be under the control of
distributed digital processors. Analog cMOS implementations are also feasible 3 ?
The first term implements the constraint that the final solution should follow
as closely as possible the measured data whereas the second term imposes the
smoothness constraint on the solution. The degree to which one or the other
terms are minimized is governed by the parameter).. If the data is very accurate, it should be ""expensive"" to violate the first term and), will be small.
If, conversely, the data is unreliable (low signal-to-noise), much more emphasis
will be placed on the smoothness term. Horn and Schunck1 first formulated this
variational approach to the motion problem.
The energy E( u, v) is quadratic in the unknown u and v. It then follows
from standard calculus of variation that the associated Euler-Lagrange equations
will be linear in u and v:
I~u

+ IzIyv I z I 1I u + I:v -

). \721.?
). \7 2 v

+ IzIt
+ Iylt

= 0
= O.

(3)

We now have two linear equations at every point and our problem is therefore
completely determined.
ANALOG RESISTIVE NETWORKS
Let us assume that we are formulating eqs. (2) and (3) on a discrete 2-D
grid, such as the one shown in fig. 1a. Equation (3) then transforms into

I~ijuij

+ IzijI1Iijvij - ). (UHlj + Uij+l Izijlyijuij + I:ijvij - ). (VHlj + Vij+l -

+ Ui-lj + Uij-l) + IZijltij
4Vij + Vi-lj + Vij-l) + Iyijltij

4Uij

= 0
= 0

(4)
where we replaced the Laplacian with its 5 point approximation on a rectangular
grid. We shall now show that this set of linear equations can be solved naturally
using a particular simple resistive network. Let us apply Kirchhoff's current law
to the nodne i, j in the top layer of the resistive network shown in fig. lb. We
then have the following update equation:
du??

C d;' = T (Ui+lj

+ Uij+l

+ gij (Eij -

- 4Uij

Uij)

+ Ui-lj + Uij-l)

+ Tc-ij( Vij

(5)

- Uij).

where Vij is the voltage at node i, j in the bottom network. Once dUij / dt = 0
and dVij/dt = 0, this equation is seen to be identical with eq. (4), if we identify

425

Tc-ij ~ -IzijIyij

+ IJlij)
gij ~ Iyii (Izii + Iyij)

gij

~ Izij (Izij

(6)

-It

Eij~----

Izii

+ Iyij

(a)

(b)

(c)

(d)

~

(e)

(f)

Fig. 2. Motion sequence using synthetic data. (a) and (b) Two images of
three high contrast squares on a homogeneous background. (c) The initial
velocity data. The inside of both squares contain no data. (d) The final state

426

of the network after 240 iterations, corresponding to the smooth optical flow
field. (e) Optical flow in the presence of motion discontinuities (indicated by
solid lines). (f) Discontinuities are strongly encouraged to form at the location
of intensity edges 4 ? Both (e) and (f) show the state of the hybrid network after
six analog-digital cycles.
Once we set the batteries and the conductances to the values indicated in
eq. (6), the network will settle-following Kirchhoff's laws-into the state of
least power dissipation. The associated stationary voltages correspond to the
sought solution: uii is equivalent to the :c component and Vii to the y component
of the optical flow field.
We simulated the behavior of these networks by solving the above circuit
equations on parallel computers of the Hypercube family. As boundary conditions we copied the initial velocity data at the edge of the image into the nodes
lying directly adjacent but outside the image.
The sequences in figs. 2 and 3 illustrate the resulting optical flow for synthetic and natural images. As discussed by Horn and Schunck 1 , the smoothness
constraint leads to a qualitatively correct estimate of the velocity field. Thus,
one undifferentiated blob appears to move to the lower right and one blob to
the upper left. However, at the occluding edge where both squares overlap, the
smoothness assumption results in a spatial average of the two opposing velocities, and the estimated velocity is very small or zero. In parts of the image
where the brightness gradient is zero and thus no initial velocity data exists (for
instance, the interiors of the two squares), the velocity estimates are simply the
spatial average of the neighboring velocity estimates. These empty areas will
eventually fill in from the boundary, similar to the How of heat for a uniform
flat plate with ""hot"" boundaries.
MOTION DISCONTINUITIES
The smoothness assumption of Horn and Schunck 1 regularizes the aperture
problem and leads to the qualitatively correct velocity field inside moving objects. However, this approach fails to detect the locations at which the velocity
changes abruptly or discontinuously. Thus, it smoothes over the figure-ground
discontinuity or completely fails to detect the boundary between two objects
with differing velocities because the algorithm combines velocity information
across motion boundaries.
A quite successful strategy for dealing with discontinuities was proposed by
Geman and Geman 5 ? We shall not rigorously develop their approach, which is
based on Bayesian estimation theory (for details see 5 ,6). Suffice it to say that
a priori knowledge, for instance, that the velocity field should in general be
smooth, can be formulated in terms of a Markov Random Field model of the
image. Given such an image model, and given noisy data, we then estimate
the ""best"" flow field by some likelihood criterion. The one we will use here

427

is the maximum a posteriori estimate, although other criteria are possible and
have certain advantages 6 ? This can be shown to be equivalent to minimizing an
expression such as eq. (2).
In order to reconstruct images consisting of piecewise constant segments,
Geman and Geman5 further introduced the powerful idea of a line process 1.
For our purposes, we will assume that a line process can be in either one of two
states: ""on"" (1 = 1) or ""off"" (1 = 0). They are located on a regular lattice set
between the original pixel lattice (see fig. 1a), such that each pixel i,j has a
horizontallfi and a verticallij line process associated with it. If the appropriate
line process is turned on, the smoothness term between the two adjacent pixels
will be set to zero. In order to prevent line processes from forming everywhere
and, furthermore, in order to incorporate additional knowledge regarding discontinuities into the line processes, we must include an additional term Vc(l)
into the new energy function:

E( 'IL, v, lh., IV) =

L (Iz'ILii + IyVii + I )2 +
t

i.i

). L

(1 -It) [('lLi+1i - 'lLii)2 + (Vi+li - Vii)2] +

(7)

i.i

). L

(1 -Iii) [('lLij+l - 'lLii)2 + (vii+1 - Vij)2] + Vc(l).

i.i
Vc contains a number of different terms, penalizing or encouraging specific
configurations of line processes:

i.;

i.i

plus the corresponding expression for the vertical line process Iii (obtained by interchanging i with j and Iii with Ifi). The first term penalizes each introduction
of a line process, since the cost C c has to be ""payed"" every time a line process
is turned on. The second term prevents the formation of parallel lines: if either
lfi+l or Ifi+2 is turned on, this term will tend to prevent
from turning on.
The third term, CIVI , embodies the fact that in general, motion discontinuities
occur along extended contours and rarely intersect (for more details see 7 ).
We obtain the optical flow by minimizing the cost function in eq. (7) with
respect to both the velocity v and the line processes Ih. and IV. To find an
optimal solution to this non-quadratic minimization problem, we follow Koch
et a1. 7 and use a purely deterministic algorithm, based on solving Kirchhoff's
equations for a mixed analogi digital network (see also 8). Our algorithm exploits
the fact that for a fixed distribution of line processes, the energy function (7)
is quadratic. Thus, we first initialize the analog resistive network (see fig. 2b)
according to eq. (6) and with no line processes on. The network then converges to

It

428

the smoothest solution. Subsequently, we update the line processes by deciding
at each site of the line process lattice whether the overall energy can be lowered
by setting or breaking the line proceSSj that is, lfi will be turned on if E( u, v, lfi =
1, IV) < E( u, v, Ifi = 0, IV); otherwise, Ifj = o. Line processes are switched on
by breaking the appropriate resistive connection between the two neighboring
nodes. After the completion of one such analog-digital cycle, we reiterate and
compute-for the newly updated distribution of line processes-the smoothest
state of the analog network. Although there is no guarantee that the system will
converge to the global minimum, since we are using a gradient descent rule, it
seems to find next-to-optimal solutions in about 10 to 15 analog-digital cycles.

(8)

(c)

(e)

Figure 3. Optical flow of a moving person. (a) and (b) Two 128 by 128
pixel images captured by a video camera. The person in the foreground is
moving toward the right while the person in the background is stationary. The
noise in the lower part of the image is a camera artifact. (c) Zero-crossings
superimposed on the initial velocity data. (d) The smooth optical flow after 1000
iterations. Note that the noise in the lower part of both images is completely
smoothed away. (e) The final piecewise smooth optical flow. The velocity
field is subsampled to improve visibility. The evolution of the hybrid network is
shown after the 1. (a), 3. (b), 5. (c), 7. (d), 10. (e), and 13. (f) analog-digital
cycle in the right part of the figure.
The synthetic motion sequence in fig. 2 demonstrates the effect of the line

429

processes. The optical flow outside the discontinuities approximately delineating
the boundaries of the moving squares is zero, as it should be (fig. 2e). However,
where the two squares overlap the velocity gradient is high and multiple intersecting discontinuities exist. To restrict further the location of discontinuities, we
adopt a technique used by Gamble and Poggio4 to locate depth discontinuities
by requiring that depth discontinuities coincide with the location of intensity
edges. Our rationale behind this additional constraint is that with very few
exceptions, the physical processes and the geometry of the 3-dimensional scene
giving rise to the motion discontinuity will also give rise to an intensity edge. As
edges we use the zero-crossings of a Laplacian of a Gaussian convolved with the
original image9 ? We now add a new term VZ-Cii to our energy function E, such
that Vz -Cii is zero if Iii is off or if Iii is on and a zero-crossing exists between
locations i and j. If Iii = 1 in the absence of a zero-crossing, V Z - Cii is set
to 1000. This strategy effectively prevents motion discontinuities from forming
at locations where no zero-crossings exist, unless the data strongly suggest it.
Conversely, however, zero-crossings by themselves will not induce the formation
of discontinuities in the absence of motion gradients (figs. 2f and 3).
ANALOG VLSI NETWORKS
Even with the approximations and optimizations described above, the computations involved in this and similar early vision tasks require minutes to hours
on computers. It is fortunate then that modern integrated circuit technology
gives us a medium in which extremely complex, analog real-time implementations of these computational metaphors can be realized3 ?
We can achieve a very compact implementation of a resistive network using
an ordinary cMOS process, provided the transistors are run in the sub-threshold
range where their characterstics are ideal for implementing low-current analog
functions. The effect of a resistor is achieved by a circuit configuration, such as
the one shown in fig. 4, rather than by using the resistance of a special layer in
the process. The value of the resulting resistance can be controlled over three
orders of magnitude by setting the bias voltages on the upper and lower current
source transistors. The current-voltage curve saturates above about 100 mVj a
feature that can be used to advantage in many applications. When the voltage
gradients are small, we can treat the circuit just as if it were a linear resistor.
Resistances with an effective negative resistance value can easily be realized.
In two dimensions, the ideal configuration for a network implementation is
shown in fig. 4. Each point on the hexagonal grid is coupled to six equivalent
neighbors. Each node includes the resistor apparatus, and a set of sample-andhold circuits for setting the confidence and signal the input and output voltages.
Both the sample-and-hold circuits and the output buffer are addressed by a
scanning mechanism, so the stored variables can be refreshed or updated, and
the map of node voltages read out in real time.

430

~
I,

I

v,

VI

(a)

v
(b)

Figure 4. Circuit design for a resistive network for interpolating and smoothing
noisy and sparsely sampled depth measurements. (a) Circuit-consisting of 8
transistors-implementing a variable nonlinear resistance. (b) If the voltage
gradient is below 100 mV its approximates a linear resistance. The voltage VT
controls the maximum current and thus the slope of the resistance, which can
vary between 1 MO and 1 GO 3. This cMOS circuit contains 20 by 20 grid
points on a hexagonal lattice. The individual resistive elements with a variable
slope controlled by VT correspond to the term governing the smoothness, A. At
those locations where a depth measurement dij is present, the battery is set to
this value (Vin = d ij ) and the value of the conductance G is set to some fixed
value. If no depth data is present at that node, G is set to zero. The voltage
at each node corresponds to the discrete values of the smoothed surface fitted
through the noisy and sparse measurements 7 ?
A 48 by 48 silicon retina has been constructed that uses the hexagonal
network of fig. 4 as a model for the horizontal cell layer in the vertebrate
retinal 0 ? In this application, the input potentials were the outputs of logarithmic photoreceptors-implemented via phototransistors-and the potential
difference across the conductance T formed an excellent approximation to the
Laplacian operator.
DISCUSSION
We have demonstrated in this study that the introduction of binary motion

431

discontinuities into the algorithm of Horn and Schunck1 leads to a dramatically
improved performance ~f their method, in particular for the optical flow in the
presence of a number of moving non-rigid objects. Moreover, we have shown
that the appropriate computations map onto simple resistive networks. We are
now implementing these resistive networks into VLSI circuits, using subtheshold
cMOS technology. This approach is of general interest, because a great number
of problems in early vision can be formulated in terms of similar non-convex
energy functions that need to be minimized, such as binocular stereo, edge
detection, surface interpolation, structure from motion, etc. 2 ,6,8.
These networks share several features with biological neural networks. Specifically, they do not require a system-wide clock, they rely on many connections
between simple computational nodes, they converge rapidly-within several time
constants-and they are quite robust to hardware errors. Another interesting
feature is that our networks only consume very moderate amounts of powerj the
entire retina chip requires about 100 J.L W 10
Acknowledgments: An early version of this model was developed and implemented in collaboration with A. L. Yuille8 ? M. Avalos and A. Hsu wrote the
code for the Imaging Technology system and E. Staats for the NCUBE. C.K.
is supported by an ONR Research Young Investigator Award and by the Sloan
and the Powell Foundations. C.M. is supported by ONR and by the System
Development Foundation. A portion of this research was carried out at the Jet
Propulsion Laboratory and was sponsored by NSF grant No. EET-8714710, and
by NASA.
REFERENCES
1. Horn, B. K. P. and Schunck, B. G. Artif. Intell. 17,185-203 (1981).

2. Poggio, T., Torre, V. and Koch, C. Nature 317,314-319 (1985).
3. Mead, C. Analog VLSI and Neural Systems. Addison-Wesley: Reading,
MA (1988).
4. Gamble, E. and Poggio, T. Artif. Intell. Lab. Memo. No. 970, MIT, Cambridge MA (1987).
5. Geman, S. and Geman, D. IEEE Trans. PAMI 6, 721-741 (1984).
6. Marroquin, J., Mitter, S. and Poggio, T. J. Am. Stat. Assoc. 82, 76-89
(1987).
7. Koch, C., Marroquin, J. and Yuille, A. Proc. Natl. Acad. Sci. USA 83,
4263-4267 (1986).
8. Yuille, A. L. Artif. Intell. Lab. Memo. No. 987, MIT, Cambridge, MA
(1987).
9. Marr, D. and Hildreth, E. C. Proc. R. Soc. Lond. B 207, 187-217 (1980).
10. Sivilotti, M. A., Mahowald, M. A. and Mead, C. A. In: 1987 Stanford VLSI
Conference, ed. P. Losleben, pp. 295-312 (1987).

"
26,1987,"Neural Net and Traditional Classifiers","",26-neural-net-and-traditional-classifiers.pdf,"Abstract Missing","387

Neural Net and Traditional Classifiers1
William Y. Huang and Richard P. Lippmann
MIT Lincoln Laboratory
Lexington, MA 02173, USA

Abstract. Previous work on nets with continuous-valued inputs led to generative
procedures to construct convex decision regions with two-layer perceptrons (one hidden
layer) and arbitrary decision regions with three-layer perceptrons (two hidden layers).
Here we demonstrate that two-layer perceptron classifiers trained with back propagation
can form both convex and disjoint decision regions. Such classifiers are robust, train
rapidly, and provide good performance with simple decision regions. When complex
decision regions are required, however, convergence time can be excessively long and
performance is often no better than that of k-nearest neighbor classifiers. Three neural
net classifiers are presented that provide more rapid training under such situations.
Two use fixed weights in the first one or two layers and are similar to classifiers that
estimate probability density functions using histograms. A third ""feature map classifier""
uses both unsupervised and supervised training. It provides good performance with
little supervised training in situations such as speech recognition where much unlabeled
training data is available. The architecture of this classifier can be used to implement
a neural net k-nearest neighbor classifier.

1. INTRODUCTION
Neural net architectures can be used to construct many different types of classifiers [7]. In particular, multi-layer perceptron classifiers with continuous valued inputs trained with back propagation are robust, often train rapidly, and provide performance similar to that provided by Gaussian classifiers when decision regions are convex
[12,7,5,8]. Generative procedures demonstrate that such classifiers can form convex decision regions with two-layer perceptrons (one hidden layer) and arbitrary decision regions
with three-layer perceptrons (two hidden layers) [7,2,9]. More recent work has demonstrated that two-layer perceptrons can form non-convex and disjoint decision regions.
Examples of hand crafted two-layer networks which generate such decision regions are
presented in this paper along with Monte Carlo simulations where complex decision
regions were generated using back propagation training. These and previous simulations [5,8] demonstrate that convergence time with back propagation can be excessive
when complex decision regions are desired and performance is often no better than that
obtained with k-nearest neighbor classifiers [4]. These results led us to explore other
neural net classifiers that might provide faster convergence. Three classifiers called,
""fixed weight,"" ""hypercube,"" and ""feature map"" classifiers, were developed and evaluated. All classifiers were tested on illustrative problems with two continuous-valued
inputs and two classes (A and B). A more restricted set of classifiers was tested with
vowel formant data.

2.

CAPABILITIES OF Two LAYER PERCEPTRONS

Multi-layer perceptron classifiers with hard-limiting nonlinearities (node outputs
of 0 or 1) and continuous-valued inputs can form complex decision regions. Simple
constructive proofs demonstrate that a three-layer perceptron (two hidden layers) can
1 This work was sponsored by the Defense Advanced Research Projects Agency and the Department
of the Air Force. The views expressed are those of the authors and do not reflect the policy or position
of the U. S. Government.

? American Institute of Physics 1988

388

DECISION REGION FOR CLASS A

b,
,

X2

2

b2
,

b4
,

~,

~-1

~-1

I

I

I

----[J'
-: -:
~, .:-):

1 f-----

I

I ---

-"":-<i:/ ___ _
I
I

I
I

o

2

3

FIG. 1. A two-layer perceptron that form! di!joint deci!ion region! for cia!! A (!haded area!). Connection weight! and node ojJ!eb are !hown in the left. Hyperplane! formed by all hidden node! are drawn
a! da!hed line! with node labek Arrow! on theu line! point to the half plane where the hidden node
output i! ""high"".

form arbitrary decision regions and a two-layer perceptron (one hidden layer) can form
single convex decision regions [7,2,9]. Recently, however, it has been demonstrated that
two-layer perceptrons can form decision regions that are not simply convex [14]. Fig. 1,
for example, shows how disjoint decision regions can be generated using a two-layer
perceptron. The two disjoint shaded areas in this Fig. represent the decision region
for class A (output node has a ""high"" output, y = 1). The remaining area represents
the decision region for class B (output node has a ""low"" output, y = 0). Nodes in
this Fig. contain hard-limiting nonlinearities. Connection weights and node offsets are
indicated in the left diagram. Ten other complex decision regions formed using two-layer
perceptrons are presented in Fig. 2.
The above examples suggest that two-layer perceptrons can form decision regions
with arbitrary shapes. We, however, know of no general proof of this capability. A
1965 book by Nilson discusses this issue and contains a proof that two-layer nets can
divide a finite number of points into two arbitrary sets ([10] page 89). This proof
involves separating M points using at most M - 1 parallel hyperplanes formed by firstlayer nodes where no hyperplane intersects two or more points. Proving that a given
decision region can be formed in a two-layer net involves testing to determine whether
the Boolean representations at the output of the first layer for all points within the
decision region for class A are linearly separable from the Boolean representations for
class B. One test for linear separability was presented in 1962 [13].
A problem with forming complex decision regions with two-layer perceptrons is that
weights and offsets must be adjusted carefully because they interact extensively to form
decision regions. Fig. 1 illustrates this sensitivity problem. Here it can be seen that
weights to one hidden node form a hyperplane which influences decision regions in
an entire half-plane. For example, small errors in first layer weights that results in a
change in the slopes of hyperplanes bs and b6 might only slightly extend the Al region
but completely eliminate the A2 region. This interdependence can be eliminated in
three layer perceptrons.
It is possible to train two-layer perceptrons to form complex decision regions using
back propagation and sigmoidal nonlinearities despite weight interactions. Fig. 3, for
example, shows disjoint decision regions formed using back propagation for the problem
of Fig. 1. In this and all other simulations, inputs were presented alternately from
classes A and B and selected from a uniform distribution covering the desired decision
region. In addition, the back propagation rate of descent term, TJ, was set equal to the
momentum gain term, a and TJ = a = .01. Small values for TJ and a were necessary to
guarantee convergence for the difficult problems in Fig. 2. Other simulation details are

389

~llll
I

IEl

I

blEl
I

5)

I

mJ
I

3)

=(3 m1
I

I

I

9)

I

I

6)

rm
I

I

+
10)

4)

1=

~ftfI

r

I

I

I

I

FIG. 2. Ten complex deci6ion region6 formed by two-layer perceptron6. The number6 a66igned to each
ca6e are the ""ca6e"" number6 u6ed in the re6t of thi6 paper.

as in [5,8]. Also shown in Fig. 3 are hyperplanes formed by those first-layer nodes with
the strongest connection weights to the output node. These hyperplanes and weights
are similar to those in the networks created by hand except for sign inversions, the
occurrence of multiple similar hyperplanes formed by two nodes, and the use of node
offsets with values near zero.

3.

COMPARATIVE RESULTS OF TWO-LAYERS VS. THREE-LAYERS

Previous results [5,8], as well as the weight interactions mentioned above, suggest
that three-layer perceptrons may be able to form complex decision regions faster with
back propagation than two-layer perceptrons. This was explored using Monte Carlo
simulations for the first nine cases of Fig. 2. All networks have 32 nodes in the first
hidden layer. The number of nodes in the second hidden layer was twice the number
of convex regions needed to form the decision region (2, 4, 6, 4, 6, 6, 8, 6 and 6 for
Cases 1 through 9 respectively). Ten runs were typically averaged together to obtain
a smooth curve of percentage error vs. time (number of training trials) and enough
trials were run (to a limit of 250,000) until the curve appeared to flatten out with little
improvement over time. The error curve was then low-pass filtered to determine the
convergence time. Convergence time was defined as the time when the curve crossed a
value 5 percentage points above the final percentage error. This definition provides a
framework for comparing the convergence time of the different classifiers. It, however, is
not the time after which error rates do not improve. Fig. 4 summarizes results in terms
of convergence time and final percentage error. In those cases with disjoint decision
regions, back propagation sometimes failed to form separate regions after 250,000 trials.
For example, the two disjoint regions required in Case 2 were never fully separated with

390

,

!...

~2~

JI
J

21-

--=~I
0--

?2

----

""

I

.7.2 :

,

,..

I 12.7 ~ '9.3,-

4.5

7.6

t..-[-

-]-(1--- , __ '

,

I

I
II

""""
""
I

, __

,- ---r--

,--r

I

II....-409

'

I

I

11.9

,
I

I
I

I

I _ _---,I_ _ _~I_ _......I ____I,-----,

~_....

o

?2

2

4

6

FIG. 3. Deci!ion region, formed u,ing bacle propagation for Ca!e! ! of Fig. !. Thiele !olid line! repre!ent
deci,ion boundariu. Da,hed line! and arrow! have the lame meaning a! in Fig. 1. Only hyperplane!
for hidden node, with large weight! to the output node are !hown. Over 300,000 training trial! were
required to form !eparote N!gion!.

a two-layer perceptron but were separated with a three-layer perceptron. This is noted
by the use of filled symbols in Fig. 4.
Fig. 4 shows that there is no significant performance difference between two and
three layer perceptrons when forming complex decision regions using back propagation
training. Both types of classifiers take an excessively long time (> 100,000 trials) to
form complex decision regions. A minor difference is that in Cases 2 and 7 the two-layer
network failed to separate disjoint regions after 250,000 trials whereas the three-layer
network was able to do so. This, however, is not significant in terms of convergence time
and error rate. Problems that are difficult for the two-layer networks are also difficult
for the three-layer networks, and vice versa.

4.

ALTERNATIVE CLASSIFIERS

Results presented above and previous results [5,8] demonstrate that multi-layer perceptron classifiers can take very long to converge for complex decision regions. Three
alternative classifiers were studied to determine whether other types of neural net classifiers could provide faster convergence.
4.1. FIXED WEIGHT CLASSIFIERS
Fixed weight classifiers attempt to reduce training time by adapting only weights
between upper layers of multi-layer perceptrons. Weights to the first layer are fixed
before training and remain unchanged. These weights form fixed hyperplanes which
can be used by upper layers to form decision regions. Performance will be good if the
fixed hyperplanes are near the decision region boundaries that are required in a specific
problem. Weights between upper layers are trained using back propagation as described
above. Two methods were used to adjust weights to the first layer. Weights were
adjusted to place hyperplanes randomly or in a grid in the region (-1 < Xl,X2 < 10).
All decision regions in Fig. 2 fall within this region. Hyperplanes formed by first layer
nodes for ""fixed random"" and ""fixed grid"" classifiers for Case 2 of Fig. 2 are shown as
dashed lines in Fig. 5. Also shown in this Fig. are decision regions (shaded areas) formed

391

12

o 2-1ayers

10

o .~.~.~.~x.~:':"".::.......

8

ERROR RATE

6
04
2

OL-__L-__L-__L-__L-__L-__L-__L-__
200000

L-~~~

CONVERGENCE TIME

FIG. 4. Percentage errOr (top) and convergence time (bottom) for Ca8e6 1 through 9 of Fig. 2 for
two-and three-layer perceptron clauifier6 trained u6ing back propagation. Filled 6ymbol6 indicate that
6eparate di6joint region6 were not formed after 250,000 triak

using back propagation to train only the upper network layers. These regions illustrate
how fixed hyperplanes are combined to form decision regions. It can be seen that decision
boundaries form along the available hyperplanes. A good solution is possible for the
fixed grid classifier where desired decision region boundaries are near hyperplanes. The
random grid classifier provides a poor solution because hyperplanes are not near desired
decision boundaries. The performance of a fixed weight classifier depends both on the
placement of hyperplanes and on the number of hyperplanes provided.

4.2. HYPERCUBE CLASSIFIER
Many traditional classifiers estimate probability density functions of input variables
for different classes using histogram techniques [41. Hypercube classifiers use this technique by fixing weights in the first two layers to break the input space into hypercubes
(squares in the case of two inputs). Hypercube classifiers are similar to fixed weight
classifiers, except weights to the first two layers are fixed, and only weights to output
nodes are trained. Hypercube classifiers are also similar in structure to the CMAC
model described by Albus [11. The output of a second layer node is ""high"" only if the
input is in the hypercube corresponding to that node. This is illustrated in Fig. 6 for a
network with two inputs.
The top layer of a hypercube classifier can be trained using back propagation. A
maximum likelihood approach, however, suggests a simpler training algorithm which
consists of counting. The output of second layer node Hi is connected to the output
node corresponding to that class with greatest frequency of occurrence of training inputs
in hypercube Hi. That is, if a sample falls in hypercube Hi, then it is classified as class
(J* where
(1)
Nj,o. > Ni,O for all (J f:. (J ??
In this equation, Ni,O is the number of training tokens in hypercube Hi which belong to
class (J. This will be called maximum likelihood (ML) training. It can be implemented
by connection second-layer node Hi only to that output node corresponding to class (J.
in Eq. (1). In all simulations hypercubes covered the area (-1 < Xl, X2 < 10).

392

GRID

RANDOM

o

FIG. 5. Deci.ion region. formed with ""fixed random"" and ""fixed grid"" clal6ifier. for Ca.e ! from Fig.
! ruing back propagation training. Line! !hown are hyperplane! formed by the fird layer node!. Shaded

area. repre.ent the deci.ion region for clau A.

FOUR BINS CREATED
BY FIXED LAYERS
A

B

}

TRAINED
LAYER

""2

3

2

FIXED
LAYERS
""1

INPUT

FIG. 6. A hypercube clauifier (left) i! a three-layer perceptron with fixed weight! to the fird two layen,
and trainable weight! to output node!. Weights are initialized !uch that output! of nodes HI through H.
(left) are ""high"" only when the input i! in the corre!ponding hypercube (right).

393

OUTPUT (Only One High)

SElECT
[
CLASS
WITH MAJORITY
IN TOP k
SUPERVISED
ASSOCIATIVE
LEARNING

SELECT TOP [
k EXEMPLARS

CALCULATE
CORRELATION
TO STORED
EXEMPLARS

UNSUPERVISED
KOHONEN
FEATURE MAP
LEARNING
II,

INPUT

FIo. 1. Feature map clauifier.

4.3. FEATURE MAP CLASSIFIER
In many speech and image classification problems a large quantity of unlabeled
training data can be obtained, but little labeled data is available. In such situations
unsupervised training with unlabeled training data can substantially reduce the amount
of supervised training required [3]. The feature map classifier shown in Fig. 7 uses combined supervised/unsupervised training, and is designed for such problems. It is similar
to histogram classifiers used in discrete observation hidden Markov models [11] and the
classifier used in [6]. The first layer of this classifier forms a feature map using a self
organizing clustering algorithm described by Kohonen [6]. In all simulations reported in
this paper 10,000 trials of unsupervised training were used. After unsupervised training, first-layer feature nodes sample the input space with node density proportional to
the combined probability density of all classes. First layer feature map nodes perform a
function similar to that of second layer hypercube nodes except each node has maximum
output for input regions that are more general than hypercubes and only the output of
the node with a maximum output is fed to the output nodes. Weights to output nodes
are trained with supervision after the first layer has been trained. Back propagation, or
maximum likelihood training can be used. Maximum likelihood training requires Ni,8
(Eq. 1) to be the number of times first layer node i has maximum output for inputs
from class 8. In addition, during classification, the outputs of nodes with Ni,8 = 0 for
all 8 (untrained nodes) are not considered when the first-layer node with the maximum
output is selected. The network architecture of a feature map classifier can be used
to implement a k-nearest neighbor classifier. In this case, the feedback connections in
Fig. 7 (large circular summing nodes and triangular integrators) used to select those
k nodes with the maximum outputs must be slightly modified. K is 1 for a feature
map classifier and must be adjusted to the desired value of k for a k-nearest neighbor
classifier.

5.

COMPARISON BETWEEN CLASSIFIERS

The results of Monte Carlo simulations using all classifiers for Case 2 are shown in
Fig. 8. Error rates and convergence times were determined as in Section 3. All alter-

394

Percent Correct

Fixed Weight

Conventional

Hypercube

Feature Map

12

%
8

4

0

Tr ials
2500

Convergence Time

77K

1

I

2000

2-1ay

1500
1000

? ?

500
0

KNN

~id

I
I

GAUSS

32

3&

40

120

Number ot Hidden Nodes

FIG. 8. Comparative performance of clauifier8for Ca8e 2. Training time of the feature map clauifier8
doe8 not include the 10,000 un8upervi8ed training trials.

native classifiers had shorter convergence times than multi-layer perceptron classifiers
trained with back propagation. The feature map classifier provided best performance.
With 1,600 nodes, its error rate was similar to that of the k-nearest neighbor classifiers
but it required fewer than 100 supervised training tokens. The larger fixed weight and
hypercube classifiers performed well but required more supervised training than the
feature map classifiers. These classifiers will work well when the combined probability
density function of all classes varies smoothly and the domain where this function is
non-zero is known. In this case weights and offsets can be set such that hyperplanes and
hypercubes cover the domain and provide good performance. The feature map classifier
automatically covers the domain. Fixed weight ""random"" classifiers performed substantially worse than fixed weight ""grid"" classifiers. Back propagation training (BP) was
generally much slower than maximum likelihood training (ML).

6.

VOWEL CLASSIFICATION

Multi layer perceptron, feature map, and traditional classifiers were tested with
vowel formant data from Peterson and Barney [11]. These data had been obtained
by spectrographic analysis of vowels in /hVd/ context spoken by 67 men, women and
children. First and second formant data of ten vowels was split into two sets, resulting
in a total of 338 training tokens and 333 testing tokens. Fig. 9 shows the test data
and the decision regions formed by a two-layer percept ron classifier trained with back
propagation. The performance of classifiers is presented in Table I. All classifiers had
similar error rates. The feature map classifier with only 100 nodes required less than 50
supervised training tokens (5 samples per vowel class) for convergence. The perceptron
classifier trained with back propagation required more than 50,000 training tokens. The
first stage of the feature map classifier and the multi-layer perceptron classifier were
trained by randomly selecting entries from the 338 training tokens after labels had been
removed and using tokens repetitively.

395

4000

D

..
+
?
..
?
o
(
)

D

..

2000

F2

(lIz)
+

..

..

head
hid
hod
had
hawed
heard
heed
hud
vho' d

"" hood
+

1000

.
+

500

1400

0

F1

(Hz)

FIG. 9. DecilJion regionlJ formed by a two-layer network using BP after 200,000 training tokens from
PeterlJon'lJ steadylJtate vowel data [PeterlJon, 1952}. AllJo shown are samplelJ of the telJting lJet. Legend
IJhow example 0/ the pronunciation of the 10 vowels and the error within each vowel.

I ALGORITHM

I TRAINING

TABLE

I

TOKENS

I % ERROR I

Performance of classifiers on IJteady IJtate vowel data.

396

7.

CONCLUSIONS

Neural net architectures form a flexible framework that can be used to construct
many different types of classifiers. These include Gaussian, k-nearest neighbor, and
multi-layer perceptron classifiers as well as classifiers such as the feature map classifier
which use unsupervised training. Here we first demonstrated that two-layer perceptrons
(one hidden layer) can form non-convex and disjoint decision regions. Back propagation
training, however, can be extremely slow when forming complex decision regions with
multi-layer perceptrons. Alternative classifiers were thus developed and tested. All
provided faster training and many provided improved performance. Two were similar to
traditional classifiers. One (hypercube classifier) can be used to implement a histogram
classifier, and another (feature map classifier) can be used to implement a k-nearest
neighbor classifier. The feature map classifier provided best overall performance. It
used combined supervised/unsupervised training and attained the same error rate as a
k-nearest neighbor classifier, but with fewer supervised training tokens. Furthermore,
it required fewer nodes then a k-nearest neighbor classifier.

REFERENCES
[1] J. S. Albus, Brains, Behavior, and Robotics. McGraw-Hill, Petersborough, N.H., 1981.

[2] D. J. Burr, ""A neural network digit recognizer,"" in Proceedings of the International Conference
on Systems, Man, and Cybernetics, IEEE, 1986.
[3] D. B. Cooper and J. H. Freeman, ""On the asymptotic improvement in the outcome of supervised
learning provided by additional nonsupervised learning,"" IEEE Transactions on Computers,
vol. C-19, pp. 1055-63, November 1970.
[4] R. O. Duda and P. E. Hart, Pattern Classification and Scene Analysis. John-Wiley &. Sons, New
York, 1973.
[5] W. Y. Huang and R. P. Lippmann, ""Comparisons between conventional and neural net classifiers,""
in 1st International Conference on Neural Network, IEEE, June 1987.
[6] T. Kohonen, K. Makisara, and T. Saramaki, ""Phonotopic maps - insightful representation of
phonological features for speech recognition,"" in Proceedings of the 7th International Conference on Pattern Recognition, IEEE, August 1984.
[7] R. P. Lippmann, ""An introduction to computing with neural nets,"" IEEE A SSP Magazine, vol. 4,
pp. 4-22, April 1987.
[8] R. P. Lippmann and B. Gold, ""Neural classifiers useful for speech recognition,"" in 1st International
Conference on Neural Network, IEEE, June 1987.
[9] I. D. Longstaff and J. F. Cross, ""A pattern recognition approach to understanding the multi-layer
perceptron,"" Mem. 3936, Royal Signals and Radar Establishment, July 1986.
[10] N. J. Nilsson, Learning Machines. McGraw Hill, N.Y., 1965.

[11] T. Parsons, Voice and Speech Processing. McGraw-Hill, New York, 1986.
[12] F. Rosenblatt, Perceptrons and the Theory of Brain Mechanisms. Spartan Books, 1962.
[13] R. C. Singleton, ""A test for linear separability as applied to self-organizing machines,"" in SelfOrganization Systems, 1962, (M. C. Yovits, G. T. Jacobi, and G. D. Goldstein, eds.), pp. 503524, Spartan Books, Washington, 1962.
[14] A. Wieland and R. Leighton, ""Geometric analysis of neural network capabilities,"" in 1st International Conference on Neural Networks, IEEE, June 1987.

"
27,1987,"Bit-Serial Neural Networks","",27-bit-serial-neural-networks.pdf,"Abstract Missing","573

BIT - SERIAL NEURAL NETWORKS
Alan F. Murray, Anthony V . W. Smith and Zoe F. Butler.
Department of Electrical Engineering, University of Edinburgh,
The King's Buildings, Mayfield Road, Edinburgh,
Scotland, EH93JL.
ABSTRACT
A bit - serial VLSI neural network is described from an initial architecture for a
synapse array through to silicon layout and board design. The issues surrounding bit
- serial computation, and analog/digital arithmetic are discussed and the parallel
development of a hybrid analog/digital neural network is outlined. Learning and
recall capabilities are reported for the bit - serial network along with a projected
specification for a 64 - neuron, bit - serial board operating at 20 MHz. This technique is extended to a 256 (2562 synapses) network with an update time of 3ms,
using a ""paging"" technique to time - multiplex calculations through the synapse
array.
1. INTRODUCTION
The functions a synthetic neural network may aspire to mimic are the ability to consider many solutions simultaneously, an ability to work with corrupted data and a
natural fault tolerance. This arises from the parallelism and distributed knowledge
representation which gives rise to gentle degradation as faults appear. These functions are attractive to implementation in VLSI and WSI. For example, the natural
fault - tolerance could be useful in silicon wafers with imperfect yield, where the
network degradation is approximately proportional to the non-functioning silicon
area.
To cast neural networks in engineering language, a neuron is a state machine that is
either ""on"" or ""off', which in general assumes intermediate states as it switches
smoothly between these extrema. The synapses weighting the signals from a
transmitting neuron such that it is more or less excitatory or inhibitory to the receiving neuron. The set of synaptic weights determines the stable states and represents
the learned information in a system.
The neural state, VI' is related to the total neural activity stimulated by inputs to
the neuron through an activation junction, F. Neural activity is the level of excitation of the neuron and the activation is the way it reacts in a response to a change
in activation. The neural output state at time t, V[, is related to x[ by
V[

= F (xf)

(1)

The activation function is a ""squashing"" function ensuring that (say) Vi is 1 when
is large and -1 when Xi is small. The neural update function is therefore straightforward:

Xi

.
,
XI,+1 - XI

? ????

+ 0~

i-n-l
~
~

T ii V'J

(2)

J-O

where 8 represents the rate of change of neural activity, Tij is the synaptic weight
and n is the number of terms giving an n - neuron array [1].
Although the neural function is simple enough, in a totally interconnected n - neuron network there are n 2 synapses requiring n 2 multiplications and summations and

? American Institute of Physics 1988

574

a large number of interconnects. The challenge in VLSI is therefore to design a simple, compact synapse that can be repeated to build a VLSI neural network with
manageable interconnect. In a network with fixed functionality, this is relatively
straightforward. H the network is to be able to learn, however, the synaptic weights
must be programmable, and therefore more complicated.
2. DESIGNING A NEURAL NETWORK IN VLSI
There are fundamentally two approaches to implementing any function in silicon digital and analog. Each technique has its advantages and disadvantages, and these
are listed below, along with the merits and demerits of bit - serial architectures in
digital (synchronous) systems.
Digital vs. analog: The primary advantage of digital design for a synapse array is
that digital memory is well understood, and can be incorporated easily. Learning
networks are therefore possible without recourse to unusual techniques or technologies. Other strengths of a digital approach are that design techniques are advanced,
automated and well understood and noise immunity and computational speed can
be high. Unattractive features are that digital circuits of this complexity need to be
synchronous and all states and activities are quantised, while real neural networks
are asynchronous and unquantised. Furthermore, digital multipliers occupy a large
silicon area, giving a low synapse count on a single chip.
The advantages of analog circuitry are that asynchronous behaviour and smooth
neural activation are automatic. Circuit elements can be small, but noise immunity
is relatively low and arbitrarily high precision is not possible. Most importantly, no
reliable analog, non - volatile memory technology is as yet readily available. For
this reason, learning networks lend themselves more naturally to digital design and
implementation.
Several groups are developing neural chips and boards, and the following listing
does not pretend to be exhaustive. It is included, rather, to indicate the spread of
activity in this field. Analog techniques have been used to build resistor I operational amplifier networks [2,3] similar to those proposed by Hopfield and Tank [4].
A large group at Caltech is developing networks implementing early vision and
auditory processing functions using the intrinsic nonlinearities of MaS transistors in
the subthreshold regime [5,6]. The problem of implementing analog networks with
electrically programmable synapses has been addressed using CCDIMNOS technology [7]. Finally, Garth [8] is developing a digital neural accelerator board (""Netsim"") that is effectively a fast SIMD processor with supporting memory and communications chips.
Bit - serial vs. bit - parallel: Bit - serial arithmetic and communication is efficient
for computational processes, allowing good communication within and between
VLSI chips and tightly pipelined arithmetic structures. It is ideal for neural networks as it minimises the interconnect requirement by eliminating multi - wire
busses. Although a bit - parallel design would be free from computational latency
(delay between input and output), pipelining makes optimal use of the high bit rates possible in serial systems, and makes for efficient circuit usage.
2.1 An asynchronous pulse stream VLSI neural network:
In addition to the digital system that forms the substance of this paper, we are
developing a hybrid analOg/digital network family. This work is outlined here, and
has been reported in greater detail elsewhere [9, 10, 11]. The generic (logical and
layout) architecture of a single network of n totally interconnected neurons is shown

575

schematically in figure 1. Neurons are represented by circles, which signal their
states, Vi upward into a matrix of synaptic operators. The state signals are connected to a n - bit horizontal bus running through the synaptic array, with a connection to each synaptic operator in every column. All columns have n operators
(denoted by squares) and each operator adds its synaptic contribution, Tij V j , to the
running total of activity for the neuron i at the foot of the column. The synaptic
function is therefore to multiply the signalling neuron state, Vj , by the synaptic
weight, T ij , and to add this product to the running total. This architecture is common to both the bit - serial and pulse - stream networks.

Synapse

States { Vj }

Neurons
Figure 1. Generic architecture for a network of n totally interconnected neurons.

This type of architecture has many attractions for implementation in 2 - dimensional
j=II -1

silicon as the summation

2

Tij

Vj is distributed in space.

The interconnect

j=O

requirement (n inputs to each neuron) is therefore distributed through a column,
reducing the need for long - range wiring. The architecture is modular, regular and
can be easily expanded.
In the hybrid analog/digital system, the circuitry uses a ""pulse stream"" signalling
method similar to that in a natural neural system. Neurons indicate their state by
the presence or absence of pulses on their outputs, and synaptic weighting is
achieved by time - chopping the presynaptic pulse stream prior to adding it to the
postsynaptic activity summation. It is therefore asynchronous and imposes no fundamental limitations on the activation or neural state. Figure 2 shows the pulse
stream mechanism in more detail. The synaptic weight is stored in digital memory
local to the operator. Each synaptic operator has an excitatory and inhibitory pulse
stream input and output. The resultant product of a synaptic operation, Tij V j , is
added to the running total propagating down either the excitatory or inhibitory
channel. One binary bit (the MSBit) of the stored Tij determines whether the contribution is excitatory or inhibitory.
The incoming excitatory and inhibitory pulse stream inputs to a neuron are
integrated to give a neural activation potential that varies smoothly from 0 to 5 V.
This potential controls a feedback loop with an odd number of logic inversions and

576

.

??

XT ??

V,

.u.u,
?

Figure 2. Pulse stream arithmetic. Neurons are denoted by 0 and synaptic operators
by D.

thus forms a switched ""ring - oscillator"". H the inhibitory input dominates, the feedback loop is broken. H excitatory spikes subsequently dominate at the input, the
neural activity rises to 5V and the feedback loop oscillates with a period determined
by a delay around the loop. The resultant periodic waveform is then converted to a
series of voltage spikes, whose pulse rate represents the neural state, Vi' Interestingly, a not dissimilar technique is reported elsewhere in this volume, although the
synapse function is executed differently [12].

3. A 5 - STATE BIT - SERIAL NEURAL NETWORK
The overall architecture of the 5 - state bit - serial neural network is identical to
that of the pulse stream network. It is an array of n 2 interconnected synchronous
synaptic operators, and whereas the pulse stream method allowed Vj to assume all
values between ""off' and ""on"", the 5 - state network VJ is constrained to 0, ?0.5 Qr
? 1. The resultant activation function is shown in Figure 3. Full digital multiplication is costly in silicon area, but multiplication of Tij by Vj = 0.5 merely requires
the synaptic weight to be right - shifted by 1 bit. Similarly, multiplication by 0.25
involves a further right - shift of Til' and multiplication by 0.0 is trivially easy. VJ
< 0 is not problematic, as a switchable adder/subtractor is not much more complex
than an adder. Five neural states are therefore feasible with circuitry that is only
slightly more complex than a simple serial adder. The neural state expands from a 1
bit to a 3 bit (5 - state) representation, where the bits represent ""add/subtract?"",
""shift?"" and ""multiply by O?"".
Figure 4 shows part of the synaptic array. Each synaptic operator includes an 8 bit
shift register memory block holding the synaptic weight, Til' A 3 bit bus for the 5
neural states runs horizontally above each synaptic row. Single phase dynamic
CMOS has been used with a clock frequency in excess of 20 MHz [13). Details of
a synaptic operator are shown in figure 5. The synaptic weight Til cycles around the
shift register and the neural state Vj is present on the state bus. During the first
clock CYCle, the synaptic weight is multiplied by the neural state and during the
second, the most significant bit (MSBit) of the resultant Tij Vj is sign - extended for

577

State VJ

lHRESHOLD

.....-------=-------..
s?
""5

Activity sJ

STATE""
""Sharper""

""Smoother""

~.....::~-""'--x.&..t------

Activity ""J

Figure 3. ""Hard - threshold"", 5 - state and sigmoid activation functions.

J-a-1 T v
~

J-li

.. J

v,

v,

Figure 4. Section of the synaptic array of the 5 - state activation function neural network.
8 bits to allow for word growth in the running summation. A least significant bit
(LSBit) signal running down the synaptic columns indicates the arrival of the LSBit
of the Xj running total. If the neural state is ?O.5 the synaptic weight is right
shifted by 1 bit and then added to or subtracted from the running total. A multiplication of ? 1 adds or subtracts the weight from the total and multiplication by 0

578

.0.5
.0.0

Add/Subtract

Add!
Subtract
Carry

Figure S. The synaptic operator with a 5 - state activation function.
does not alter the running summation.
The final summation at the foot of the column is thresholded externally according
to the 5 - state activation function in figure 3. As the neuron activity Xj' increases
through a threshold value x"" ideal sigmoidal activation represents a smooth switch
of neural state from -1 to 1. The 5 - state ""staircase"" function gives a superficially
much better approximation to the sigmoid form than a (much simpler to implement) threshold function. The sharpness of the transition can be controlled to
""tune"" the neural dynamics for learning and computation. The control parameter is
referred to as temperature by analogy with statistical functions with this sigmoidal
form. High ""temperature"" gives a smoother staircase and sigmoid, while a temperature of 0 reduces both to the ''Hopfield'' - like threshold function. The effects of
temperature on both learning and recall for the threshold and 5 - state activation
options are discussed in section 4.
4. LEARNING AND RECALL WITH VLSI CONSTRAINTS
Before implementing the reduced - arithmetic network in VLSI, simulation experiments were conducted to verify that the 5 - state model represented a worthwhile
enhancement over simple threshold activation. The ""benchmark"" problem was
chosen for its ubiquitousness, rather than for its intrinsic value. The implications
for learning and recall of the 5 - state model, the threshold (2 - state) model and
smooth sigmoidal activation ( 00 - state) were compared at varying temperatures
with a restricted dynamic range for the weights T ij ? In each simulation a totally
interconnected 64 node network attempted to learn 32 random patterns using the
delta rule learning algorithm (see for example [14]). Each pattern was then corrupted with 25% noise and recall attempted to probe the content addressable
memory properties under the three different activation options.
During learning, individual weights can become large (positive or negative). When
weights are ""driven"" beyond the maximum value in a hardware implementation,

579

which is determined by the size of the synaptic weight blocks, some limiting
mechanism must be introduced. For example, with eight bit weight registers, the
limitation is -128 S Tij S 127. With integer weights, this can be seen to be a problem of dynamic range, where it is the relationship between the smallest possible
weight (? 1) and the largest (+ 127/-128) that is the issue.
Results: Fig. 6 shows examples of the results obtained, studying learning using 5 state activation at different temperatures, and recall using both 5 - state and threshold activation. At temperature T=O, the 5 - state and threshold models are
degenerate, and the results identical. Increasing smoothness of activation (temperature) during learning improves the quality of learning regardless of the activation
function used in recall, as more patterns are recognised successfully. Using 5 - state
activation in recall is more effective than simple threshold activation. The effect of
dynamic range restrictions can be assessed from the horizontal axis, where T/j:6. is
shown. The results from these and many other experiments may be summarised as
follows:5 - State activation vs. threshold:
1) Learning with 5 - state activation was protracted over the threshold activation,
as binary patterns were being learnt, and the inclusion of intermediate values
added extra degrees of freedom.
2) Weight sets learnt using the 5 - state activation function were ""better"" than
those learnt via threshold activation, as the recall properties of both 5 - state
and threshold networks using such a weight set were more robust against
noise.
3) Full sigmoidal activation was better than 5 - state, but the enhancement was
less significant than that incurred by moving from threshold - 5 - state. This
suggests that the law of diminishing returns applies to addition of levels to the
neural state Vi' This issue has been studied mathematically [15], with results
that agree qualitatively with ours.
Weight Saturation:
Three methods were tried to deal with weight saturation. Firstly, inclusion of a
decay, or ""forgetting"" term was included in the learning cycle [1]. It is our view
that this technique can produce the desired weight limiting property, but in the time
available for experiments, we were unable to ""tune"" the rate of decay sufficiently
well to confirm it. Renormalisation of the weights (division to bring large weights
back into the dynamic range) was very unsuccessful, suggesting that information
distributed throughout the numerically small weights was being destroyed. Finally,
the weights were allowed to ""clip"" (ie any weight outside the dynamic range was set
to the maximum allowed value). This method proved very successful, as the learning algorithm adjusted the weights over which it still had control to compensate for
the saturation effect. It is interesting to note that other experiments have indicated
that Hopfield nets can ""forget"" in a different way, under different learning control,
giving preference to recently acquired memories [16]. The results from the saturation experiments were:1) For the 32 pattemJ64 node problem, integer weights with a dynamic range
greater than ?30 were necessary to give enough storage capability.
2) For weights with maximum values TiJ = 50-70, ""clipping"" occurs, but network performance is not seriously degraded over that with an unrestricted
weight set.

580

15

c 10

""0

~

e

,

=
.2

-

~

T=20
T=10
T=O

....--- -- - -

- - ,- ., ...
;A .......;.. f:'-:' :::::7.:::.::-:::-: f'-.

I

en

e
u

T=30 _._.-.-

15

,...?.-.....-.?. _.?. -.-._.-..

,. "".'
i

,..

i
j''''-,,'i
~-------------

!
!

,

5

-..,..

i

j

'"" ?????? ? ???????????????? ??????

j

I
I

,

I

0

O~~~~--~~

0

20

30

40 50 60 70
Limit
5 . state activation function recal1

o

__~~__

40 50 60 70
Limit
tlHopficld"" activation function recall
20

30

Figure 6. Recall of patterns learned with the 5 . state activation function and subsequently restored using the 5-state and the hard - threshold activation functions.
T is the ""temperature"", or smoothness of the activation function, and ""limit"" the value
ofTI; ?
These results showed that the 5 - state model was worthy of implementation as a
VLSI neural board, and suggested that 8 - bit weights were sufficient.
S. PROJECTED SPECIFICATION OF A HARDWARE NEURAL BOARD
The specification of a 64 neuron board is given here, using a 5 - state bit - serial 64
x 64 synapse array with a derated clock speed of 20 MHz. The synaptic weights are
8 bit words and the word length of the running summation XI is 16 bits to allow for
growth. A 64 synapse column has a computational latency of 80 clock cycles or
bits, giving an update time of 4 .... s for the network. The time to load the weights
into the array is limited to 6O .... s by the supporting RAM, with an access time of
12Ons. These load and update times mean that the network is executing 1 x 10'
operations/second, where one operation is ? Tlj Vj ? This is much faster than a
natural neural network, and much faster than is necessary in a hardware accelerator. We have therefore developed a ""paging"" architecture, that effectively ""trades off"" some of this excessive speed against increased network size.
A ""moving - patch"" neural board: An array of the 5 - state synapses is currently
being fabricated as a VLSI integrated circuit. The shift registers and the
adderlsubtractor for each synapse occupy a disappointingly large silicon area, allowing only a 3 x 9 synaptic array. To achieve a suitable size neural network from this
array, several chips need to be included on a board with memory and control circuitry. The ""moving patch"" concept is shown in figure 7, where a small array of
synapses is passed over a much larger n x n synaptic array.
Each time the array is ""moved"" to represent another set of synapses, new weights
must be loaded into it. For example, the first set of weights will be T 11 ?. , T;J ... T 21
... T 2j to Tjj , the second set T j + 1 ,l to Tu etc.. The final weight to be loaded will be

581

Smaller ""Patch""

n neurons .. om synaptic array

moves over array
rr~

~'-

_____)__-..

>

Figure 7. The ""moving patch"" concept, passing a small synaptic ""patch"" over a larger
run synapse array.

TNt? Static, off - the - shelf RAM is used to store the weights and the whole opera-

tion is pipelined for maximum efficiency. Figure 8 shows the board level design for
the network.

Control
Synaptic Accelerator Chips

HOST
Figure 8. A ""moving patch"" neural network board.

The small ""patch"" that moves around the array to give n neurons comprises 4 VLSI
synaptic accelerator chips to give a 6 x 18 synaptic array. The number of neurons to
be simulated is 256 and the weights for these are stored in 0.5 Mb of RAM with a
load time of 8ms. For each ""patch"" movement, the partial runnin~ summatinn ;.

582

calculated for each column, is stored in a separate RAM until it is required to be
added into the next appropriate summation. The update time for the board is 3ms
giving 2 x 107 operations/second. This is slower than the 64 neuron specification,
but the network is 16 times larger, as the arithmetic elements are being used more
efficiently. To achieve a network of greater than 256 neurons, more RAM is
required to store the weights. The network is then slower unless a larger number of
accelerator chips is used to give a larger moving ""patch"".
6. CONCLUSIONS
A strategy and design method has been given for the construction of bit - serial
VLSI neural network chips and circuit boards. Bit - serial arithmetic, coupled to a
reduced arithmetic style, enhances the level of integration possible beyond more
conventional digital, bit - parallel schemes. The restrictions imposed on both synaptic weight size and arithmetic precision by VLSI constraints have been examined
and shown to be tolerable, using the associative memory problem as a test.
While we believe our digital approach to represent a good compromise between
arithmetic accuracy and circuit complexity, we acknowledge that the level of
integration is disappointingly low. It is our belief that, while digital approaches
may be interesting and useful in the medium term, essentially as hardware accelerators for neural simulations, analog techniques represent the best ultimate option in 2
- dimensional silicon. To this end, we are currently pursuing techniques for analog
pseudo - static memory, using standard CMOS technology. In any event, the full
development of a nonvolatile analog memory technology, such as the MNOS technique [7], is key to the long - term future of VLSI neural nets that can learn.

7. ACKNOWLEDGEMENTS
The authors acknowledge the support of the Science and Engineering Research
Council (UK) in the execution of this work.
References

1.
2.

3.

4.
5.
6.

S. Grossberg, ""Some Physiological and Biochemical Consequences of Psychological Postulates,"" Proc. Natl. Acad. Sci. USA, vol. 60, pp. 758 - 765, 1968.
H. P. Graf, L. D. Jackel, R. E. Howard, B. Straughn, J. S. Denker, W.
Hubbard, D. M. Tennant, and D. Schwartz, ""VLSI Implementation of a
Neural Network Memory with Several Hundreds of Neurons,"" Proc. AlP
Conference on Neural Networks for Computing. Snowbird, pp. 182 - 187, 1986.
W. S. Mackie, H. P. Graf, and J. S. Denker, ""Microelectronic Implementation of Connectionist Neural Network Models,"" IEEE Conference on Neural
Information Processing Systems. Denver, 1987.
J . J. Hopfield and D. W. Tank, ""Neural"" Computation of Decisions in Optimisation Problems,"" BioI. Cybern., vol. 52, pp. 141 - 152, 1985.
M. A. Sivilotti, M. A. Mahowald, and C. A. Mead, Real - Time Visual Computations Using Analog CMOS Processing Arrays, 1987. To be published
C. A. Mead, ""Networks for Real - Time Sensory Processing,"" IEEE Conference on Neural Information Processing Systems, Denver, 1987.

583

7.

8.
9.

10.
11.

12.

13.

14.

15.

16.

J. P. Sage, K. Thompson. and R. S. Withers, ""An Artificial Neural Network
Integrated Circuit Based on MNOSlCCD Principles,"" Proc. AlP Conference on
Neural Networlcs for Computing, Snowbird, pp. 381 - 385, 1986.
S. C. J. Garth, ""A Chipset for High Speed Simulation of Neural Network Systems,"" IEEE Conference on Neural Networlc.s, San Diego, 1987.
A. F. Murray and A. V. W. Smith, ""A Novel Computational and Signalling
Method for VLSI Neural Networks,"" European Solid State Circuits Conference
, 1987.
A. F. Murray and A. J. W. Smith, ""Asynchronous Arithmetic for VLSI
Neural Systems,"" Electronics Letters, vol. 23, no. 12, p. 642, June, 1987.
A. F. Murray and A. V. W. Smith, ""Asynchronous VLSI Neural Networks
using Pulse Stream Arithmetic,"" IEEE Journal of Solid-State Circuits and Systems, 1988. To be published
M. E. Gaspar, ""Pulsed Neural Networks: Hardware, Software and the Hopfield AID Converter Example,"" IEEE Conference on Neural Information Processing Systems. Denver, 1987.
M. S. McGregor, P. B. Denyer, and A. F. Murray, ""A Single - Phase Clocking Scheme for CMOS VLSI,"" Advanced Research in VLSI "" Proceedings of the
1987 Stanford Conference, 1987.
D. E. Rumelhart, G. E. Hinton, and R. J. Williams, ""Learning Internal
Representations by Error Propagation,"" Parallel Distributed Processing ""
Explorations in the Microstructure of Cognition, vol. 1, pp. 318 - 362, 1986.
M. Fleisher and E. Levin, ""The Hopfiled Model with Multilevel Neurons
Models,"" IEEE Conference on Neural Information Processing Systems. Denver,
1987.
G. Parisi, ""A Memory that Forgets,"" J. Phys. A .' Math. Gen., vol. 19, pp.
L617 - L620, 1986.

"
28,1987,"On Tropistic Processing and Its Applications","",28-on-tropistic-processing-and-its-applications.pdf,"Abstract Missing","262

ON TROPISTIC PROCESSING AND ITS APPLICATIONS
Manuel F. Fernandez
General Electric Advanced Technology Laboratories
Syracuse, New York 13221
ABSTRACT
The interaction of a set of tropisms is sufficient in many
cases to explain the seemingly complex behavioral responses
exhibited by varied classes of biological systems to combinations of
stimuli. It can be shown that a straightforward generalization of
the tropism phenomenon allows the efficient implementation of
effective algorithms which appear to respond ""intelligently"" to
changing environmental conditions. Examples of the utilization of
tropistic processing techniques will be presented in this paper in
applications entailing simulated behavior synthesis, path-planning,
pattern analysis (clustering), and engineering design optimization.
INTRODUCTION
The goal of this paper is to present an intuitive overview of
a general unsupervised procedure for addressing a variety of system
control and cost minimization problems. This procedure is hased on
the idea of utilizing ""stimuli"" produced by the environment in which
the systems are designed to operate as basis for dynamically
providing the necessary system parameter updates.
This is by no means a new idea: countless examples of this
approach abound in nature, where innate reactions to specific
stimuli (""tropisms"" or ""taxis"" --not to be confused with
""instincts"") provide organisms with built-in first-order control
laws for triggering varied responses [8]. (It is hypothesized that
""knowledge"" obtained through evolution/adaptation or through
learning then refines or suppresses most of these primal reactions).
Several examples of the implicit utilization of this approach
can also be found in the literature, in applications ranging from
behavior modeling to pattern analysis. Ve very briefly depict some
these applications, underlining a common pattern in their
formulation and generalizing it through the use of basic field
theory concepts and representations. A more rigorous and detailed
exposition --regarding both mathematic and
application/implementation aspects-- is presently under preparation
and should be ready for publication sometime next year ([6]).
TROPISMS
Tropisms can be defined in general as class-invariant systemic
responses to specific sets of stimuli [6]. All time-invariant
systems can thus be viewed as tropistic provided that we allow all
possible stimuli to form part of our set of inputs. In most
tropistic systems, however, response- (or time-) invariance applies
only to specific inputs: green plants, for example, twist and grow
in the direction of light (phototropism), some birds' flight
patterns follow changes in the Earth's magnetic field
(magnetotropism), various organisms react to gravitational field
? American Institute of Physics 1988

263

variations (geotropism), etc.
Tropism/stimuli interactions can be portrayed in term~ of the
superposition of scalar (e.g., potential) or vector (e.g., force)
fields exhibiting properties paralleling those of the suitably
constrained ""reactions"" we wish to model [1J,[6J. The resulting
field can then be used as a basis for assessing the intrinsic cost
of pursuing any given path of action, and standard techniques (e.g.,
gradient-following in the case of scalar fields or divergence
computation in the case of vector fields) utilized in determining a
response*. In addition, the global view of the situation provided by
field representations suggest that a basic theory of tropistic
behavior can also be formulated in terms of energy expenditure
minimization (Euler-Lagrange equations). This formulation would
yield integral-based representations (Feynman path integrals
[4],[11]) satisfying the observation that tropistic processes
typically obey the principle of least action.
Alternatively, fields may also be collapsed into ""attractors""
(points of a given ""mass"" or ""charge"" in cost space) through laws
defining the relationships that are to exist among these
""at tractors"" and the other particles traveling through the space.
This provides the simplification that when updating dynamically
changing situations only the effects caused by the interaction of
the attractors with the particles of interest --rather than the
whole cost field-- may have to be recalculated.
For example, appropriately positioned point charges exerting
on each other an electrostatic force inversely proportional to the
square of their distance can be used to represent the effects of a
coulombic-type cost potential field. A particle traveling through
this field would now be affected by the combination of forces
ensuing from the interaction of the attractors' charges with its
own. If this particle were then to passively follow the composite of
the effects of these forces it would be following the gradient of
the cost field (i.e., the vector resulting from the superposition of
the forces acting on the particle would point in the direction of
steepest change in potential).
Finally, other representations of tropism/stimuli interactions
(e.g., Value-Driven Decision Theory approaches) entail associating
""profit"" functions (usually sigmoidal) with each tropism, modeling
the relative desirability of triggering a reaction as a function of
the time since it was last activated [9]. These representations are

* In order to bring extra insight into
tropism/stimuli
interactions and simplify their formulation, one may exchange vector
and scalar field representations through the
utilization
of
appropriately selected mappings. Some of the most important of such
mappings are the gradient operator (particularly so because the
gradient of a scalar --potential-- field is proportional to a
""force"" --vector-- field), the divergence (which may be thought of
as performing in vector fields a function analogous to that
performed in scalar fields by the gradient), and their combinations
(e.g., the Laplacian, a scalar-to-scalar mapping which can be
visualized as performing on potential fields the equivalent of a
second derivative operation.

264

./.~

.'

?
?
?

Model fly as a positive geotropislic point of mass M.
Model fence slakes as negalive geotropislic poinls
with masses m 1 , m z ? ???? mit?
At each update time compute sum offorces acting on
frog:
H

F ? k

d2

""
?

Compute frog's heading and acceleration based on
the ensuing force; then update frog's position.

Figure 1: Attractor-based representation of a frog-fenee-fly
scenario (see [1) for a vector-field representation). The objective
is to model a frog's path-planning decision-making process when
approaching a fly in the presence of obstacles. (The picket fence is
represented by the elliptical outline with an opening in the back,
the fly --inside the fenced space-- is represented by a ""+~ sign,
and arrows are used to indicate the direction of a frog's trajectory
into and out of fenced area).

265

particularly amenable to neural-net implementations [6J.
TROPISTIC PROCESSING
Tropistic processing entails building into systems tropisms
appropriate for the environment in which these systems are expected
to operate. This allows taking advantage of environment-produced
""stimuli"" for providing the required control for the systems'
behavior.
The idea of tropistic processing has been utilized with good
results in a variety of applications. Arbib et.al., for example,
have implicitly utilized tropistic processing to describe a
batrachian's reaction to its environment in terms of what may be
visualized as magnetic (vector) fields' interactions [1].
Vatanabe (12) devised for pattern analysis purposes an
interaction of tropisms (""geotropisms"") in which pattern ""atoms"" are
attracted to each other, and hence ""clustered"", subject to a
squared-inverse-distance (""feature distance"") law similiar to that
from gravitational mechanics. It can be seen that if each pattern
atom were considered an ""organism"", its behavior would not be
conceptually different from that exhibited by Arbibian frogs: in
both cases organisms passively follow the force vectors resulting
from the interaction of the environmental stimuli with the
organisms' tropisms. It is interesting, though, to note that the
""organisms'"" behavior will nonetheless appear ""intelligent"" to the
casual observer.
The ability of tropistic processes to emulate seemingly
rational behavior is now begining to be explored and utilized in the
development of synthetic-psychological models and experiments.
Braitenberg, for example, has placed tropisms as the primal building
block from which his models for cognition, reason, and emotions
evolve [3]**; Barto [2] has suggested the possibility of combining
tropisms and associative (reinforced) learning, with aims at
enabling the automatic triggering of behavioral responses by
previously experienced situations; and Fernandez [6] has used
CROBOTS [10], a virtual multiprocessor emulator, as laboratory for
evaluating the effects of modifying tropistic responses on the basis
of their projected future consequences.
Other applications of tropistic processing presently being
investigated include path-planning and engineering design
optimization [6]. For example, consider an air-reconnaissance
mission deep behind enemy lines; as the mission progresses and
unexpected SAM sites are discovered, contingency flight paths may be
developed in real time simply by modeling each SAM or interdiction
site as a mass point towards which the aircraft exhibits negative
geotropistic tendencies (i.e., gravitational forces repel it), and
modeling the objective as a positive geotropistic point. A path to

** Of particular interest within the sole context of Tropistic
Processing is Dewdney's [5] commented version of the first chapters
of Braitenberg's book [3J, in which the ""behavior"" of mechanically
very simple cars, provided with ""~yes"" and phototropism-supporting
connections (including Ledley-type ""neurons"" [4J), is ""analyzed"".

266

.

?

??

"""":,~

?

??
?

,.

?
???

?

?

-.

ill' "",:""

-

?

?

??

?

? ??

?
A ??

?
??
? ??
??? ?
??
?

?

e
,,-

?? ?
??
? ,""
?

~:::

*'

?

--?

?

?

~!::.

?

??

.

?? ?
?

8

?

e

.~~

..

Figure ~ (Geotropistic clustering ~2]): The problem being portrayed
here is that of clustering dots distributed in [x,y]-space as shown
and uniformly in color ([red,blue,green]). The approach followed is
that outlined in Figure 1, with the differences that normalized
(Hahalanobis) distances are used and when merges occur, conservation
of momentum is observed. Tags are also kept --specifying with which
dots and in what order merges occur-- to allow drawing cluster
boundaries in the original data set. (Efficient implementation of
this clustering technique entails using a ring of processors, each
of which is assigned the ""features"" of one or more ""dots"" and the
task of carrying out computations with respect to these features. If
the features of each dot are then transmitted through the ring, all
the forces imposed on it by the rest will have been determined upon
completion of the circuit).

267

the target will then be automatically drawn by the interaction of
the tropisms with the gravitational forces. (Once the mission has
been completed, the target and its effects can be eliminated,
leaving active only the repulsive forces, which will then ""guide""
the airplane out of the danger zone).
In engineering design applications such as lens modeling and
design, lenses (gradient-index type, for example) can be modeled in
terms of photons attempting to reach an objective plane through a
three-dimensional scalar field of refraction indices; modeling the
process tropistically (in a manner analogous to that of the
air-reconnaissance example above) would yield the least-action paths
that the individual photons would follow. Similarly, in
""surface-of-revolution"" fuselage design (""Newton's Problem""), the
characteristics of the interaction of forces acting within a sheet
of metal foil when external forces (collisions with a fluid's
molecules) are applied can be modeled in terms of tropistic
reactions which will tend to reconfigure the sheet so as to make it
present the least resistance to friction when traversing a fluid.
Additional applications of tropistic processing include target
tracking and multisensor fusion (both can be considered instances of
""clustering"") [6], resource allocation and game theory (both closely
related to path-planning) [9], and an assortment of other
cost-minimization functions. Overall, however, one of the most
important applications of tropistic processing may be in the
modeling and understanding of analog processes [6], the imitation of
which may in turn lead to the development of effective strategies
PAST EXPERIENCE
(e.g. MEMORY MAPS)

M
PREDICTED (i.e . MODELLED)
OUTCOUE

OBSERVATlONS

BASIC
mOPISM
FUNCTION

p

RESPONSE
RESPONSE
FUNCTION

TROPISM-BASED SYSTEM
Figure 3: The combination of tropisms and associative (reinforced)
learning can be used to enable the automatic triggering of
behavioral responses by previously experienced situations [2]. Also,
the modeled projection of the future consequences of a tropistic
decision can be utilized in the modification of such decision (6J.
(Note analogy to filtering problem in which past history and
predicted behavior are used to smooth present observations).

268

i

-5000.0

-33?.3

? ? ''''.7

-I

i,

.lll3.J

5000.'

-5000.0

-3l?.l

?

-,

?

''''.7

lJl3.J

5000.0

3lJ3.J

5000.0

i,

i,
oD

01

i,
""',
to

Figure 4: Simplified representation of air-reconnaissance mission
example (see text): objective is at center of coordinate axis, thick
dots represent SAM sites, and arrows denote airplane's direction of
flight (airplane's maximum attainable speed and acceleration are
constrained). All portrayed scenarios are identical except for
tropistic control-law parameters (mainly objective to SAM-sites mass
ratios in the first three scenarios). Varying the masses of the
objective and SAM sites can be interpreted as trading off the
relative importance of the mission vs. the aircraft's safety, and
can produce dramatically differing flight paths, induce chaotic
behavior (bottom-left scenario), or render the system unstable. The
bottom-right scenario portrays the situation in which a tropistic
decision is projected into the future and, if not meeting some
criterion, modified (altering the direction of flight --e.g.,
following an isokline--, re-evaluating the mission's relative
importance --revising masses--, changing the update rate, etc.).

269

for taking full advantage of parallel architectures [11]***. It is
thus expected that the flexibility of tropistic processes to adapt
to changing environmental conditions will prove highly valuable to
the advancement of areas such as robotics, parallel processing and
artificial intelligence, where at the very least they will provide
some decision-making capabilities whenever unforeseen circumstances
are encountered.
ACKNOVLEDGEMENTS
Special thanks to D. P. Bray for the ideas provided in our
many discussions and for the development of the finely detailed
simulations that have enabled the visualization of unexpected
aspects of our work.
REFERENCES
[1] Arbib, M.A. and House, D.H.: ""Depth and Detours: Decision Making
in Parallel Systems"". IEEE Vorkshop on Languages for Automation:
Cognitive Aspects in Information Processing; pp. 172-180 (1985).
[2] Barto, A.G. (Editor): ""Simulation Experiments with Goal-Seeking
Adaptive Elements"". Avionics Laboratory, Vright-Patterson Air
Force Base, OH. Report # AFVAL-TR-84-1022. (1984).
[3] Braitenberg, V.: Vehicles: Experiments in Synthetic Psychology.
The MIT Press. (1984).
[4] Cheng, G.C.; Ledley, R.S.; and Ouyang, B.: ""Pattern Recognition
with Time Interval Modulation Information Coding"". IEEE
Transactions on Aerospace and Electronic Systems. AES-6, No.2;
pp. 221-227 (1970).
[5] Dewdney, A.K.: ""Computer Recreations"". Scientific American.
Vol.256, No.3; pp. 16-26 (1987).
[6] Fern6ndez, M.F.: ""Tropistic Processing"". To be published (1988).
[7J Feynman, R.P.: Statistical Mechanics: A Set of Lectures.
Frontiers in Physics Lecture Note Series-zI982).
[8] Hirsch, J.: ""Nonadaptive Tropisms and the Evolution of
Behavior"". Annals of the New York Academy of Sciences. Vol.223;
pp. 84-88 (1973).
[9] Lucas, G. and Pugh, G.: ""Applications of Value-Driven
Automation Methodology for the Control and Coordination of
Netted Sensors in Advanced C**3"". Report # RADC-TR-80-223.
Rome Air Development Center, NY. (1980).
[10] Poindexter, T.: ""CROBOTS"". Manual, programs, and files (1985).
2903 Vinchester Dr., Bloomington, IL., 61701.
[11J Vallqvist, A.; Berne, B.J.; and Pangali, C.: ""Exploiting
Physical Parallelism Using Supercomputers: Two Examples from
Chemical Physics"". Computer. Vol.20, No.5; pp. 9-21 (1987).
[12] Vatanabe, S.: Pattern Recognition: Human and Mechanical.
John Viley & Sons; pp. 160-168 (1985).

*** Optical Fourier transform operations, for instance, can be
modeled in high-granularity machines through a procedure analogous
to the gradient-index lens simulation example, with processors
representing diffraction-grating ""atoms"" [6].

"
29,1987,"Basins of Attraction for Electronic Neural Networks","",29-basins-of-attraction-for-electronic-neural-networks.pdf,"Abstract Missing","524

BASINS OF ATTRACTION FOR
ELECTRONIC NEURAL NETWORKS
C. M. Marcus
R. M. Westervelt
Division of Applied Sciences and Department of Physics
Harvard University, Cambridge, MA 02138
ABSTRACT
We have studied the basins of attraction for fixed point and
oscillatory attractors in an electronic analog neural network. Basin
measurement circuitry periodically opens the network feedback loop,
loads raster-scanned initial conditions and examines the resulting
attractor.
Plotting the basins for fixed points (memories), we show
that overloading an associative memory network leads to irregular
basin shapes. The network also includes analog time delay circuitry,
and we have shown that delay in symmetric networks can introduce
basins for oscillatory attractors. Conditions leading to oscillation
are related to the presence of frustration; reducing frustration by
diluting the connections can stabilize a delay network.
(1) - INTRODUCTION
The dynamical system formed from an interconnected network of
nonlinear neuron-like elements can perform useful parallel
computation l - 5 .
Recent progress in controlling the dynamics has
focussed on algorithms for encoding the location of fixed pOints 1 ,4
and on the stability of the flow to fixed points 3 ? 5-8. An equally
important aspect of the dynamics is the structure of the basins of
attraction, which describe the location of all pOints in initial
condition space which flow to a particular attractor 10 . 22 .
In a useful associative memory, an initial state should lead
reliably to the ""closest"" memory.
This requirement suggests that a
well-behaved basin of attraction should evenly surround its attractor
and have a smooth and regular shape. One dimensional basin maps
plotting ""pull in"" probability against Hamming distance from an
attract or do not reveal the shape of the basin in the high
dimensional space of initial states 9. 19 . Recently, a numerical study
of a Hopfield network with discrete time and two-state neurons showed
rough and irregular basin shapes in a two dimensional Hamming space,
suggesting that the high dimensional basin has a complicated
structure 10 . It is not known how the basin shapes change with the
size of the network and the connection rule.
We have investigated the basins of attraction in a network with
continuous state dynamics by building an electronic neural network
with eight variable gain sigmoid neurons and a three level (+,0,-)
interconnection matrix.
We have also built circuitry that can map
out the basins of attraction in two dimensional slices of initial
state space (Fig .1) .
The network and the basin measurements are
described in section 2.

@ American Institute of Physics 1988

525

In section 3, we show that the network operates well as an
associative memory and can retrieve up to four memories (eight fixed
points) without developing spurious attractors, but that for storage
of three or more memories, the basin shapes become irregular.
In section 4, we consider the effects of time delay. Real network
components cannot switch infinitely fast or propagate signals
instantaneously, so that delay is an intrinsic part of any hardware
implementation of a neural network. We have included a controllable
CCD (charge coupled device) analog time delay in each neuron to
investigate how time delay affects the dynamics of a neural network.
We find that networks with symmetric interconnection matrices, which
are guaranteed to converge to fixed points for no delay, show
collective sustained oscillations when time delay is present. By
discovering which configurations are maximally unstable to
oscillation, and looking at how these configurations appear in
networks, we are able to show that by diluting the interconnection
matrix, one can reduce or eliminate the oscillations in neural
networks with time delay.
(2) - NETWORK AND BASIN MEASUREMENT

A block diagram of the network and basin measurement circuit is
shown in fig.1.
digital
comparator

and

oscillation
detector

desired
memory

?c

sigmoid amplifiers
with

Block diagram
of the network and
basin measurement
system.
Fi~.l

The main feedback loop consists of non-linear amplifiers
(""neurons"", see fig.2) with capacitive inputs and a resistor matrix
allowing interconnection strengths of -l/R, 0, +l/R (R = 100 kn). In
all basin measurements, the input capacitance was 10 nF, giving a
time constant of 1 ms. A charge coupled device (CCD) analog time
del ay l l was built into each neuron, providing an adjustable delay per
neuron over a range 0.4 - 8 ms.

526

50k
Inverting
output

1/

Fig.2 Electronic neuron.
Non-linear gain provided
by feedback diodes.
Inset: Nonlinear
behavior at several
different values of
gain.

Analog switches allow the feedback path to be periodically
disconnected and each neuron input charged to an initial voltage. The
network is then reconnected and settles to the attractor associated
with that set of initial conditions. Two of the initial voltages are
raster scanned (on a time scale that is long compared to the load/run
switching time) with function generators that are also connected to
the X and Y axes of a storage scope.
The beam of the scope is
activated when the network settles into a de sired at tractor,
producing an image of the basin for that attractor in a twodimensional slice of initial condition space.
The ""attractor of
8
interest"" can be one of the 2 fixed points or an oscillatory
attractor.
A simple example of this technique is the case of three neurons
with symmetric non-inverting connection shown in fig.3.

"",

""

"", ""

3-D
STATE
SPACE ?

"" ....

..

G??gBASIN FORt t t
_
BASIN FOR ~ ??

-1.0V

1V

?

CIRCUIT:

j~

-1 V

.~.
+

-1 V

1V

Basin
of
Fig.3
attraction for three
neurons
with
symmetric non-inverting
coupling. Slices are
in
plane
of
the
initial voltages on
neurons 1 and 2. The
two fixed points are
all neurons saturated
all
positive
or
negative.
The data
are photographs of
the scope screen.

(3) BASINS FOR FIXED POINTS - ASSOCIATIVE MEMORY
Two dimensional slices of the eight dimensional initial condition
space (for the full network) reveal important qualitative features
about the high dimensional basins.
Fig. 4 shows a typical slice for
a network programmed with three memories according to a clipped Hebb
rule1, 12:

527

(1 )

where ~ is an N-component memory vector of l's and -l's, and m is
the number of memories. The memories were chosen to be orthogonal
(~a .~~ = N 8a~) .

1V- r - - - r - - - - - - - - . ,
1, ?1,
1,?1,
1,?1,
1,?1 \

0-

_\

'1,1,?1,?1,
1,1,1,1

.w._ ?.w.....""""..
L.:.:.~

_ _~~~~_""""'_

1,1, ?1,?1,
1,1,?1,?1

MEMORIES:
1,1,1,1,-1,-1,-1,-1
1 ,-1,1 ,-1,1 ,-1,1 ,-1
1,1,-1,-1,1 ,1,-1,-1

1,1,1,1,
?1,?1,?1,?1

-1,1,-1,1,
?1,1,-1,1

-1 V- """"'=====:;:===~
.I
-IV
0?
~
IV

Fi~.
4 A slice of initial condition space shows the basins of
attraction for five of the six fixed points for three memories
in eight-neuron Hopfield net. Learning rule was clipped Hebb
(Eq.1). Neuron gain = 15.

Because the Hebb rule (eq. 1) makes ~a and _~a stable attractors, a
three-memory network will have six fixed point attractors. In fig.4,
the basins for five of these attractors are visible, each produced
with a different rastering pattern to make it distinctive. Several
characteristic features should be noted:
-- All initial conditions lead to one of the memories (or
inverses), no spurious attractors were seen for three or four
memories.
This is interesting in light of the well documented
emergence of spurious attractors at miN -15% in larger networks with
discrete time 2 ,lS.
-- The basins have smooth and continuous edges.
-- The shapes of the basins as seen in this slice are irregular.
Ideally, a slice with attractors at each of the corners should have
rectangular basins, one basin in each quadrant of the slice and the
location of the lines dividing quadrants determined by the initial
conditions on the other neurons (the ""unseen"" dimensions). With three
or more memories the actual basins do not resemble this ideal form.
(4) TIME DELAY, FRUSTRATION AND SUSTAINED OSCILLATION
Arguments defining conditions which guarantee convergence to
fixed points 3 , 5,6 (based, for example, on the construction of a
Liapunov function) generally assume instantaneous communication
between elements of the network.
In any hardware implementation,
these assumptions break down due to the finite switching speed of
amplifiers and the charging time of long interconnect lines. 13 It is
the ratio of delay/RC which is important for stability, so keeping
this ratio small limits how fast a neural network chip can be
designed to run.
Time delay is also relevant to biological neural
nets where propagation and response times are comparable. 14 ,lS

528

Our particular interest in this section is how time delay can
lead to sustained oscillation in networks which are known to be
stable when there is no delay.
We therefore restrict our attention
to networks with symmetric interconnection matrices (Tlj = Tjl)'
An obvious ingredient in producing oscillations in a delay
network is feedback, or stated another way, a graph representing the
connections in a network must contain loops.
The simplest oscillatory structure made of delay elements is the
ring oscillator (fig.Sa).
Though not a symmetric configuration, the
ring oscillator illustrates an important point: the ring will
oscillate only when there is negative feedback at dc - that is, when
the product of'interconnection around the loop is negative. Positive
feedback at dc (loop product of connections > 0) will lead to
saturation.
Observing various symmetric configurations (e.g. fig.Sb) in the
delayed-neuron network, we find that a negative product of
connections around a loop is also a necessary condition for sustained
oscillation in symmetric circuits.
An important difference between
the ring (fig.Sa) and the symmetric loop (fig.Sb) is that the period
of oscillation for the ring is the total accumulated delay around the
ring - the larger the ring the longer the period. In contrast, for
those symmetric configurations which have oscillatory attractors, the
period of oscillation is roughly twice the delay, regardless of the
size of the configuration or the value of delay. This indicates that
for symmetric configurations the important feedback path is local,
not around the loop.

I ?\:~~~illator

?

(NEGATIVE

???,............

/;\\

FEEDBACK)

~bJmmetric

1/ \ \ (FI~~~TRATED)
................

=lime delay
neuron

/ ' =non-inverting
connection

,,:1' .. inverting
.?'

connection

Fir;;r . S (a) A ring oscillator:
needs negative feedback at dc
to oscillate. (b) Symmetrically connected triangle. This
configuration is ""frustrated""
(defined in text), and has
both oscillatory and fixed
point attractors when neurons
have delay .

otl ~ ?????. h."",

Configurations with loop connection product < 0 are important in
the theory of spin glasses 16 , where such configurations are called
""frustrated."" Frustration in magnetic (spin) systems, gives a measure
of ""serious"" bond disorder (disorder that cannot be removed by a
change of variables) which can lead to a spin glass state. 16.17
Recent results based on the similarity between spin glasses and
symmetric neural networks has shown that storage capacity limitations
can be understood in terms of this bond disorder. 18 ,19 Restating our
observation above: We only find stable oscillatory modes in symmetric
networks with delay when there is frustration. A similar result for a
sign-symmetric network (Tlj, Tjl both ~o or $0) with no delay is
described by Hirsch. 6
We can set up the basin measurement system (fig.l) to plot the
basin of attraction for the oscillatory mode. Fig.6 shows a slice of
the oscillatory basin for a frustrated triangle of delay neurons.

529

. .. .

1.5V

..

.
""

? .'

.. :,'.,""
... f....
'I

.l,,?

o
,

'i\""

,

""

.

.:

'

'I

O

'.'.'

'

.,
,

.

,:,

:,1.
;

'

?1.5V
I

?1.5V

I

o

I

1.5V

Fig.6 Basin for oscillatory attractor (cross-hatched region)
in frustrated triangle of delay-neurons.
Connections were
all symmetric and inverting; other frustrated configurations
(e.g. two non-inverting, one inverting, all symmetric) were
similar. (6a): delay = O.48RC, inset shows trajectory to fixed
point and oscillatory mode for two close-lying initial
conditions.
(6b): delay = O. 61RC, basin size increases.
A fully connected feedback associative network with more that one
memory will contain frustration. As more memories are added, the
amount of frustration will increases until memory retrieval
disappears. But before this point of memory saturation is reached,
delay could cause an oscillatory basin to open.
In order to design
out this possibility, one must understand how frustration, delay and
global stability are related. A first step in determining the
stability of a delay network is to consider which small
configurations are most prone to oscillation, and then see how these
""dangerous"" configurations show up in the network. As described
above, we only need to consider frustrated configurations.
A frustrated configuration of neurons can be sparsely connected,
as in a loop, or densely connected, with all neurons connected to all
others, forming what is called in graph theory a ""clique.""
Representing a network with inverting and non-inverting connections
as a signed graph (edges carry + and -), we define a frustrated clique
as a fully connected set of vertices (r vertices,' r (r-l) /2 edges)
with all sets of three vertices in the clique forming frustrated
triangles. Some examples of frustrated loops and cliques are shown in
fig. 7.
Notice that neurons connected with all inverting symmetric
connections, a configuration that is useful as a ""winner-take-all""
circuit, is a frustrated clique.

<> . .
\???????1

\!.....?????~FRUSTRATED

FiQ.7 Examples of frustrated
loops
and
frustrated
cliques.
In
the
graph
,~
representation
vertices
/ \
.... =inverting
/"",non-inverting
(black dots) are neurons
,..
..
symmetric connection symmetric connection
,
.~~----------------~--------------~
?...............?
..?..
..'
FRUSTRATED (with delay) and undirected
edges
are
symmetric
;
/i~;~/' CLIQUES
connections.
:
\"">'"" ,.:(/ ~~);;.::~:. (fully connected;
.'

,/

~
................

\!

........
!

.

LOOPS

. :::.j..\.>.
: ! ?..?... ~:
... ,'
'.""
?...........?

~:"" ;;.!: .1'''. :
;.~~r.~

'""

..,'-'

all triangles
frustrated)

530

We find that delayed neurons connected in a frustrated loop
longer than three neurons do not show sustained oscillation for any
value of delay (tested up to delay = 8RC).
In contrast, when delayed
neurons are connected in any frustrated clique configuration, we do
find basins of attraction for sustained oscillation as well as fixed
point attractors, and that the larger the frustrated clique, the more
easily it oscillates in the following ways: (1) For a given value of
delay/RC, the size of the oscillatory basin increases with r, the
size of the frustrated clique (fig. 8). (2) The critical value of
delay at which the volume of the oscillatory basin goes to zero
decreases with increasing r (fig.9); For r=8 the critical delay is
already less than 1/30 RC.

/\

?..............?

1

1.1\

Fig.8
Size of basin
for
oscillatory mode
increases with size of
frustrated clique.
The
delay
is
0.46RC per
neuron in each picture.
Slices are in the space
of initial voltages on
neurons 1 and 2, other
initial voltages near
zero.

.:..............=-

?

iG
u

-u

.

-0:-

?

~

4:
.......
>-

?

co

Fig.9 The critical valu,? of delay
where the oscillatory mode vanishes .
Measured by reducing delay until
system leaves oscillatory attractor .
Delay plotted in units of the
characteristic time RioC, where Rio
= (Lj 1 /Rij) -1=10Sn/ (r-1) and C=10nF,
indicating that the critical delay
decreases faster than 1/(r-1).

? ??

Q)

- .1

""0

1

size of frustrated clique (r)

10

Having identified frustrated cliques as the maximally unstable
configuration of time delay neurons, we now ask how many cliques of a
given size do we expect to find in a large network.
A set of r vertices (neurons) can be fully connected by r(r-1)/2
edges of two types (+ or -) to form 2 r (r-1)/2 different cliques. Of
these, 2 (r-1) will be frustrated cliques.
Fig .?10 shows all 2 (4-1) =8
cases for r=4.

~

,':11
""

""
r.III'

~

: II
,', II

A
:

i

.

1'1',1
...............
~ .---.
............... .-------'.

Eig.10 All graphs of size r=4 that are frustrated cliques
(fully connected, every triangle frustrated.) Solid lines =
positive edges, dashed lines = negative edges.

531

For a randomly connected network, this result combined with
results from random graph th eory 20 gives an expected number of
frustrated cliques of size r in a network of size N, EN(r):
N

(2)

EN(r) = (r) c(r,p)
c(r,p) =
where

N
(r)

r ( r - l ) (r-2)/2 pr(r-l)/2

is the binomial coefficient and c(r,p)

(3)

is defined as the

concentration of frustrated cliques. p is the connectance of the
network, defined as the probability that any two neurons are
connected. Eq.3 is the special case where + and - edges (noninverting, inverting connections) are equally probable. We have also
generalized this result to the case p(+)~p(-).
Fig.11 shows the dramatic reduction in the concentration of all
frustrated configurations in a diluted random network. For the
general case (p(+)~p(-?
we find that the negative connections
affect the concentrations of frustrated cliques more strongly than
the positive connections,
as expected (Frustration requires
negatives, not positives, see fig. 10) .
10?y---------~------~--~--r__r~~~_,

Fig.11 Concentration of
frustrated cliques of size
r=3,4,S,6 in an unbiased
random network, from eq.3.
Concentrations
decrease
rapidly as the network is
diluted,
especially for
large cliques (note: log
scale) .
connectance (p)
1
When the interconnections in a network are specified by a
learning rule rather than at random, the expected numbers of any
configuration will differ from the above results.
We have compared
the number of frustrated triangles in large three-valued (+1,0,-1)
Hebb interconnection matrices (N=100,300,600) to the expected number
in a random matrix of the same size and connectance. The Hebb matrix
was constructed according to the rule:

?

Tij = Zk (La=l,m ~ia ~ja) ; Tii =
Zk(X) = +1 for x > k; 0 for -k $x $k; -1 for x < -k;

(4a)
(4b)

m is the number of memories, Zkis a threshold function with cutoff
k, and ~a is a random string of l's and -l's. The matrix constructed
by eq.4 is roughly unbiased (equal number of positive and negative
connections) and has a connectance p(k).
Fig.12 shows the ratio of
frustrated triangles in a diluted Hebb matrix to the expected number
in a random graph with the same connectance for different numbers of

532

memories stored in the Hebb matrix. At all values of connectance, the
Hebb matrix has fewer frustrated triangles than the random matrix by
a ratio that is decreased by diluting the matrix or storing fewer
memories. The curves do not seem to depend on the size of the matrix,
N.
This result suggests that diluting a Hebb matrix breaks up
frustration even more efficiently than diluting a random matrix.
.""

CD

?

?a
??

0.9

~

-~

I'l!
?c

0.7

""C

~

ratio
ratio
ratio
ratio
ratio

1TI=o15
m-25
m-40
maS5
1TI=o100

N .. 300

0.5

::l

.::

'0
.2

0.3

T?

0.1
.1

connectance

FiQ'.12 The number of frustrated
triangles in a (+,0,-) Hebb rule
matrix (300x300) divided by the
expected number in a random
with
equal
signed
graph
connectance.
The different sets
of points are for different
numbers of random memories in the
The lines are
Hebb matrix.
guides to the eye.

The sensitive dependence of frustration on connectance suggests
that oscillatory modes in a large neural network with delay can be
eliminated by diluting the interconnection matrix.
As an example,
consider a unbiased random network with delay = RC/10.
From fig.9,
only frustrated cliques of size r=5 or larger have oscillatory basins
for this value of delay; frustration in smaller configurations in the
network cannot lead to sustained oscillation in the network.
Diluting the connectance to 60% will reduce the concentration of
frustrated cliques with r=5 by a factor of over 100 and r=6 by a
factor of 2000.
The reduction would be even greater for a clipped
Hebb matrix.
Results from spin glass theory 21 suggest that diluting a clipped
Hebb matrix can actually improve the storage capacity for moderated
dilution, with a maximum in the capacity at a connectance of 61%. To
the extent this treatment applies to an analog continuous-time
network, we should expect that by diluting connections, oscillatory
modes can be killed before memory capacity is compromised.
We have confirmed the stabilizing effect of dilution in our
network: For a fully connected eight neuron network programmed with
three orthogonal memories according to eq.l, adding a delay of 0.4RC
opens large basins for sustained oscillation.
By randomly diluting
the interconnections to
p . . . 0.85, we were able to close the
oscillatory basins and recover a useful associative memory.
SUMMARY

We have investigated the structure of fixed point and oscillatory
basins of attraction in an electronic network of eight non-linear
amplifiers with controllable time delay and a three value (+,0,-)
interconnection matrix.
For fixed point attractors, we find that the network performs
well as an associative memory - no spurious attractors were seen for
up to four stored memories - but for three or more memories, the
shapes of the basins of attraction became irregular.

533

A network which is stable with no delay can have basins for
oscillatory at tractors when time delay is present. For symmetric
networks with time delay, we only observe sustained oscillation when
there
is
frustration.
Frustrated cliques
(fully connected
configurations with all triangles frustrated), and not loops, are
most prone to oscillation, and the larger the frustrated clique, the
more easily it oscillates. The number of the se ""dangerous""
configurations in a large network can be greatly reduced by diluting
the connections. We have demonstrated that a network with a large
basin for an oscillatory attractor can be stabilized by dilution.
ACKNOWLEDGEMENTS
We thank K.L.Babcock, S.W.Teitsworth, S.Strogatz and P.Horowitz for
useful discussions. One of us (C.M.M) acknowledges support as an AT&T
Bell Laboratories Scholar.
This work was supported by JSEP contract
no. N00014-84-K-0465.
REFERENCES
1)
2)
3)
4)
5)
6)
7)
8)
9)
10)
11)
12)
13)
14)
15)
16)
17)
18)
19)

20)
21)
22)

J.S.Denker, Physica 22ll, 216 (1986).
J.J. Hopfield, Proc.Nat.Acad.Sci. ~, 2554 (1982).
J.J. Hopfield, Proc.Nat.Acad.Sci. al, 3008 (1984).
J.S. Denker, Ed. Neural Networks for Computing, AlP Conf. Proc.
l.5..l. (1986).
M.A. Cohen, S. Grossberg, IEEE Trans. SMC-13, 815 (1983).
M.W.Hirsch, Convergence in Neural Nets, IEEE Conf.on Neural
Networks, 1987.
K.L. Babcock, R.M. Westervelt, Physica 2Jll,464 (1986).
K.L. Babcock, R.M. Westervelt, Physica zau,305 (1987).
See, for example: D.B.Schwartz, et aI, Appl.Phys.Lett.,~ (16),
1110 (1987); or M.A.Silviotti,et aI, in Ref.4, pg.408.
J.D. Keeler in Ref.4, pg.259.
CCD analog delay: EG&G Reticon RD5106A.
D.O.Hebb, The Organization of Behavior, (J.Wiley, N.Y., 1949).
Delay in VLSI discussed in: A. Muhkerjee, Introduction to nMOS
and CMOS VLSI System Design, (Prentice Hall, N.J.,1985).
U. an der Heiden, J.Math.Biology, ~, 345 (1979).
M.C. Mackey, U. an der Heiden, J.Math.Biology,~, 221 (1984).
Theory of spin glasses reviewed in: K. Binder, A.P. Young,
Rev. Mod. Phys. ,.5,a (4),801, (1986).
E. Fradkin,B.A. Huberman,S.H. Shenker, Phys.Rev.lila (9),4789
(1978) .
D.J. Amit, H. Gutfreund, H. Sompolinski, Ann.Phys. ~, 30,
(1987) and references therein.
J.L. van Hemmen, I. Morgenstern, Editors, Heidelberg Colloquium
on Glassy Dynamics, Lecture Notes in Physics~, (SpringerVerlag, Heidelberg, 1987).
P. Erdos, A. Renyi, Pub. Math. Inst. Hung .Acad. Sci., .5.,17, (1960).
I.Morgenstern in Ref.19, pg.399;H.Sompolinski in Ref.19, pg.485.
J. Guckenheimer, P.Holmes, Nonlinear Oscillations,Dynamical
Systems and Bifurcations of Vector Fields (Springer,N.Y.1983).

"
30,1987,"A 'Neural' Network that Learns to Play Backgammon","",30-a-neural-network-that-learns-to-play-backgammon.pdf,"Abstract Missing","794

A 'Neural' Network that Learns to Play Backgammon
G. Tesauro
Center for Complex Systems Research, University of Illinois
at Urbana-Champaign, 508 S. Sixth St., Champaign, IL 61820

T. J. Sejnowski
Biophysics Dept., Johns Hopkins University, Baltimore, MD 21218

ABSTRACT

We describe a class of connectionist networks that have learned to play backgammon at an intermediate-to-advanced level. TIle networks were trained by a
supervised learning procedure on a large set of sample positions evaluated by a
human expert. In actual match play against humans and conventional computer
programs, the networks demonstrate substantial ability to generalize on the basis of
expert knowledge. Our study touches on some of the most important issues in network learning theory, including the development of efficient coding schemes and
training procedures, scaling, generalization, the use of real-valued inputs and outputs, and techniques for escaping from local minima. Practical applications in
games and other domains are also discussed.
INTRODUCTION
A potentially quite useful testing ground for studying issues of knowledge representation and
learning in networks can be found in the domain of game playing. Board games such as chess, go,
backgammon, and Othello entail considerable sophistication and complexity at the advanced level,
and mastery of expert concepts and strategies often takes years of intense study and practice for
humans. However, the complexities in board games are embedded in relatively ""clean"" structured
tasks with well-defined rules of play, and well-defined criteria for success and failure. This makes
them amenable to automated play, and in fact most of these games have been exten')ively studied
with conventional computer science techniques. Thus, direct comparisons of the results of network
learning can be made with more conventional approaches.
In this paper, we describe an application of network learning to the game of backgammon.
Backgammon is a difficult board game which appears to be well-suited to neural networks, because
the way in which moves are selected is primarily on the basis of pattern-recognition or ""judgemental"" reasoning, as opposed to explicit ""look-ahead,"" or tree-search computations. This is due to
the probabilistic dice rolls in backgammon, which greatly expand the branching factor at each ply in
the search (to over 400 in typical positions).

Our learning procedure is a supervised one 1 that requires a database of positions and moves
that have been evaluated by an expert ""teacher."" In contrast, in an unsupervised procedure 2-4
learning would be based on the consequences of a given move (e.g., whether it led to a won or lost
position), and explicit teacher instructions would not be required. However, unsupervised learning
procedures thus far have been much less efficient at reaching high levels of performance than supervised learning procedures. In part, this advantage of supervised learning can be traced to the higher

? American Institute of Physics 1988

795

quantity and quality of information available from the teacher.
Studying a problem of the scale and complexity of backgammon leads one to confront important general issues in network learning. Amongst the most important are scaling and generalization.
Most of the problems that have been examined with connectionist learning algorithms are relatively
small scale and it is not known how well they will perform on much larger problems. Generalization
is a key issue in learning to play backgammon since it is estimated that there are 1020 possible board
positions, which is far in excess of the number of examples that can be provided during training. In
this respect our study is the most severe test of generalization in any connectionist network to date.
We have also identified in this study a novel set of special techniques for training the network
which were necessary to achieve good performance. A training set based on naturally occurring or
random examples was not sufficient to bring the network to an advanced level of performance.
Intelligent data-base design was necessary. Performance also improved when noise was added to
the training procedure under some circumstances. Perhaps the most important factor in the success
of the network was the method of encoding the input information. The best perfonnance was
achieved when the raw input infonnation was encoded in a conceptually significant way, and a certain number of pre-computed features were added to the raw infonnation. These lessons may also
be useful when connectionist learning algorithms are applied to other difficult large-scale problems.
NElWORK AND DATA BASE SET-UP
Our network is trained to select moves (i.e. to produce a real-valued score for any given
move), rather than to generate them. This avoids the difficulties of having to teach the network the
concept of move legality. Instead, we envision our network operating in tandem with a preprocessor which would take the board position and roll as input, and produce all legal moves as output. The network would be trained to score each move, and the system would choose the move with
the highest network score. Furthermore, the network is trained to produce relative scores for each
move, rather than an absolute evaluation of each final position. This approach would have greater
sensitivity in distinguishing between close alternatives, and corresponds more closely to the way
humans actually evaluate moves.
The current data base contains a totaJ of 3202 board positions, taken from various sources 5?
For each position there is a dice roll and a set of legal moves of that roll from that pOSition. The
moves receive commentary from a human expert in the form of a relative score in the range [100,+100), with +100 representing the best possible move and -100 representing the worst possible
move. One of us (G.T.) is a strong backgammon player, and played the role of human expert in
entering these scores. Most of the moves in the data base were not scored, because it is not feasible
for a human expert to comment on all possible moves. (The handling of these unscored lines of
data in the training procedure will be discussed in the following section.)

An important result of our study is that in order to achieve the best perfonnance, the data base
of examples must be intelligently designed, rather than haphazardly accumulated. If one simply
accumulates positions which occur in actual game play, for example, one will find that certain principles of play will appear over and over again in these positions, while other important principles
may be used only rarely. This causes problems for the network, as it tends to ""overlearn"" the commonly used principles, and not learn at aJl the rarely used principles. Hence it is necessary to have
both an intelligent selection mechanism to reduce the number of over-represented situations, and an
intelligent design mechanism to enhance the number of examples which illustrate under-represented
situations. This process is described in more detail elsewhere 5 .
We use a detenninistic, feed-forward network with an input layer, an output layer, and either
one or two layers of hidden units, with full connectivity between adjacent layers. (We have tried a
number of experiments with restricted receptive fields, and generally have not found them to be useful.) Since the desired output of the network is a single real value, only one output unit is required.

796

TIle coding of the input patterns is probably the most difficult and most important design
issue. In its current configuration the input layer contains 459 input units. A location-based
representation scheme is used, in which a certain number of input units are assigned to each of the
26 locations (24 basic plus White and Black bar) on the board. TIle input is inverted if necessary so
that the network always sees a problem in which White is to play.

An example of the coding scheme used until very recently is shown in Fig. I. This is essentially a unary encoding of the number of men at each board location, with a few exceptions as indicated in the diagram. This representation scheme worked fairly well, but had one peculiar problem
in that after training, the network tended to prefer piling large numbers of men on certain points, in
particular White's 5 point (the 20 point in the 1-24 numbering scheme). Fig. 2 illustrates an example
of this peculiar behavior. In this position White is to play 5-1. Most humans would play 4-5,4-9 in
this position; however, the network chose the move 4-9,19-20. This is actually a bad move, because
it reduces White's chances of making further points in his inner board. The fault lies not with the
data base used to train the network, but rather with the representation scheme used. In Fig. I a,
notice that unit 12 is turned on whenever the final position is a point, and the number of men is different from the initial position. For the 20 point in particular, this unit will develop strong excitatory
weights due to cases in which the initial position is not a point (i.e., the move makes the point). The
20 point is such a valuable point to make that the excitation produced by turning unit 12 on might
overwhelm the inhibition produced by the poor distribution of builders.

(0)

( b)

~-5

-4 -3

oI 02

~-5

~-2

-I

000
3

4

5

-4 -3 5-2 -I

oI DOD
0
234 5

I

~2

o6 ?7
I

~2

3

4

~5

0 0 0
8

9 10

3

4 >5

o6 7? 8DOn
910

o

I

oII 120
o

It

~2

3

4 ~5

? ? 0 0

13 14 15 16

I~ ~2t 2~

oII 12000
13 14

3

4

~5

0 .00

15 16 17 18

Figure 1-- Two schemes used to encode the raw position infonnation in the network's input.
illustrated in each case is the encoding of two White men p~sent befo~ the move, and three
White men p~Jent after the move. (a) An essentiaUy unary coding of the number of men at a
particular board location. Units 1-10 encode the initial position, units 11-16 encode the final
position if the~ has been a change from the initial position. Units are tumed on in the cases
indicated on top of each unit, e.g., unit 1 is turned on if the~ are 5 or more Black men p~sent,
etc.. (b) A superior coding scheme with more units u~ed to characterize the type of transition
from initial to final position. An up arrow indicates an increase in the number of men. a down
arrow indicates a decrease. Units 11-15 have conceptual interpretations: l1=""dearing.""
12=""slotting,"" 13=""b~aking,"" 14=""making,"" 15=""stripping"" a point.

797

12 11 10 9

8

7

6

5

4

321

DO

13 14 15 16 17 18

19 20 21 22 23 24

Figure 2-- A sample position illustrating a defect of the coding scheme in Fig. 1a. White is to
play 5-1. With coding scheme (1a). the network prefers 4-9. 19-20. With coding scheme (lb).
the network prefers 4-9. 4-5. The graphic display was generated on a Sun Microsystems
workstation using the Garnmontool program.

In conceptual tenns, humans would say that unit 12 participates in the representation of two
different concepts: the concept of making a point, and the concept of changing the number of men
occupying a made point. These two concepts are unrelated, and there is no point in representing
them with a common input unit. A superior representation scheme in which these concepts are
separated is shown in Fig. 1b: In this representation unit 13 is turned on only for moves which
make the point. Other moves which change the number of men on an already-made point do not
activate unit 13, and thus do not receive any undeserved excitation. With this representation
scheme the network no longer tends to pile large numbers of men on certain points, and its overall
perfonnance is significantly better.
In addition to this representation of the raw board position, we also utilize a number of input
units to represent certain ""pre-computed"" features of the raw input. The principal goal of this
study has been to investigate network learning, rather than simply to obtain high perfonnance, and
thus we have resisted the temptation of including sophisticated hand-crafted features in the input
encoding. However, we have found that a few simple features are needed in practice to obtain
minimal standards of competent play. With only' 'raw"" board infonnation, the order of the desired
computation (as defined by Minsky and Papert6 ) is probably quite high, and the number of examples
needed to learn such a difficult computation might be intractably large. By giving the network
""hints"" in the fonn of pre-computed features, this reduces the order of the computation, and thus
might make more of the problem learnable in a tractable number of examples.

798

TRAINING AND TESTING PROCEDURES
To train the network, we have used the standard ""back-propagation"" learning algorithm 7-9
for modifying the connections in a multilayer feed-forward network. (A detailed discussion of
learning parameters, etc., is provided elsewhere s.) However, our procedure differs from the standard procedure due to the necessity of dealing with the large number of uncommented moves in the
data base. One solution would be simply to avoid presenting these moves to the network. However,
this would limit the variety of input patterns presented to the network in training, and certain types
of inputs probably would be eliminated completely. TIle alternative procedure which we have
adopted is to skip the uncommented moves most of the time (75% for ordinary rolls and 92% for
double rolls), and the remainder of the time present the pattern to the network and generate a random teacher signal with a slight negative bias. This makes sense, because if a move has not received
comment by the human expert, it is more likely to be a bad move than a good move. The random
teacher signal is chosen uniformly from the interval [-65,+35].
We have used the following four measures to assess the network's performance after it has
been trained: (i) performance on the training data, (ii) perfonnance on a set of test data (1000 positions) which was not used to train the network, (iii) perfonnance in actual game play against a conventional computer program (the program Gammontool of Sun Microsystems Inc.), and (iv) performance in game play against a human expert (G.T.). In the first two measures, we define the performance as the fraction of positions in which the network picks the correct move, i.e., those positions
for which the move scored highest by the network agrees with the choice of the human expert. In
the latter two measures, the perfonnance is defined simply as the fraction of games won, without
considering the complications of counting gammons or backgammons.

QUANTITATIVE RESULTS
A summary of our numerical results as measured by perfonnance on the training set and
against Gammontool is presented in Table 1. The best network that we have produced so far
appears to defeat Gammontool nearly 60% of the time. Using this as a benchmark, we find that the
most serious decrease in performance occurs by removing aU pre-computed features from the input
coding. This produces a network which wins at most about 41 % of the time. 'The next most important effect is the removal of noise from the training procedure; this results in a network which wins
45% of the time. Next in importance is the presence of hidden units; a network without hidden units
wins about 50% of the games against Gammontool. In contrast, effects such as varying the exact
number of hidden units, the number of layers, or the size of the training set, results in only a few
(1-3) percentage point decrease in the number of games won.
Also included in Table 1 is the result of an interesting experiment in which we removed our
usual set of pre-computed features and substituted instead the individual tenns of the Gammontool
evaluation function. We found that the resulting network, after being trained on our expert training
set, was able to defeat the Gammontool program by a small margin of 54 to 46 percent. 'The purpose
of this experiment was to provide evidence of the usefulness of network learning as an adjunct to
standard AI techniques for hand-crafting evaluation functions. Given a set of features to be used in
an evaluation function which have been designed, for example; by interviewing a human expert, the
problem remains as to how to ""tune"" these features, i.e., the relative weightings to associate to
each feature, and at an advanced level, the context in which each feature is relevant. Little is known
in general about how to approach this problem, and often the human programmer must resort to
painstaking trial-and-error tuning by hand. We claim that network learning is a powerful, generaJpurpose, automated method of approaching this problem, and has the potentiaJ to produce a tuning
which is superior to those produced by humans, given a data base of sufficiently high quality, and a
suitable scheme for encoding the features. The result of our experiment provides evidence to support this claim, although it is not firmly established since we do not have highly accurate statistics,
and we do not know how much human effort went into the tuning of the Gammontool evaluation

799

function. More conclusive evidence would be provided if the experiment were repeated with a more
sophisticated program such as Berliner's BKO lO, and similar results were obtained.

Network
sIZe

Training
cycles

Perf. on
test set

Perf. va.
Ga.mmontool

(a) 459-24-24-1
(b) 459-24-1
(c) 459-24-1
(d) 459-12-1

20
22
24
10

.540
.542
.518
.538

.59
.57
.58
.54

?
?
?
?

.03
.05
.05
.05

(e) 410-24-12-1
(f) 459-1
(g) 459-24-12-1
(h) 393-24-12-1

16
22
10
12

.493
.485
.499
.488

.54
.50
.45
.41

?
?
?
?

.03
.03
.03
.02

Comments

1600 posn. D.B .

Gammontool features
No hidden units
No training noise
No features

Table 1-- Summary of perfonnance statistics for various networks. (a) The best network we
have produced. containing two layers of hidden units. with 24 units in each layer. (b) A
network with only one layer of 24 hidden units. (c) A network with 24 hidden units in a single
layer, trained on a training set half the nonnal size. (d) A network with half the number of
hidden units as in (b). (e) A network with features from the Gammontool evaluation function
substituted for the nonnal features. (f) A network without hidden units. (g) A network trained
with no noise in the training procedure. (h) A network with only a raw board description as
input.

QUALITATIVE RESULTS
Analysis of the weights produced by training a network is an exceedingly difficult problem,
which we have only been able to approach qualitatively. In Fig. 3 we present a diagram showing the
connection strengths in a network with 651 input units and no hidden units. lbe figure shows the
weights from each input unit to the output unit. (For purposes of illustration, we have shown a coding scheme with more units than nonnal to explicitly represent the transition from initial to final
position.) Since the weights go directly to the output, the corresponding input units can be clearly
interpreted as having either an overall excitatory or inhibitory effect on the score produced by the
network.
A great deal of columnar structure is apparent in Fig. 3. This indicates that the network has
learned that a particular number of men at a given location, or a particular type of transition at a
given location, is either good or bad independent of the exact location on the board where it occurs.
Furthennore, we can see the importance of each of the pre-computed features in the input coding.
The most significant features seem to be the number of points made in the network's inner board,
and the total blot exposure.

800

features {

roll

{ ........
bar
24
23
22

21
20

19
18
17
16
15
14
13

12
11
10
9
8
7
6

5
4

3
2
1
ABC 0 E F G H I J K L M N 0 P Q R STU V W

Figure 3-- A Hinton diagram for a network with 651 input units and no hidden units. Small
squares indicate weights from a particular input unit to the output unit. White squares indicate
positive weights, and black squares indicate negative weights. Size of square indicates
24 rows from bottom up indicate raw board infonnation. Letting
magnitude of weight.
x=number of men before the move and y=number of men after the move, the interpretations of
columns are as follows: A: x<=-5; B: x=-4; C: x=-3; D: x<=-2; E: x=-I: F: x=l: G: x>=2; H:
x=3: I: x=4: J: x>=5: K: x<1 & y=l; L: x<2 & y>=2: M: x<3 & y=3: N: x<4 & y=4: 0: x<y &
y>=5: P: x=1 & y=O; Q: x>=2 & y=O; R: x>=2 & y=l: S: x>=3 & y=2: T: x>=4 & y=3: U:
x>=5 & y=4: V: x>y & y>=5: W: prob. of a White blot at thi~ location being hit (precomputed feature). The next row encodes number of men on White and Blnck bar~. The next
3 rows encode roll infonnation. Remaining rows encode various pre-computed feature~.

rust

Much insight into the basis for the network's judgement of various moves has been gained by
actually playing games against it. In fact, one of the most revealing tests of what the network has
and has not learned came from a 20-game match played by G.T. against one of the latest generation
of networks with 48 hidden units. (A detailed description of the match is given in Ref. II.) The
surprising result of this match was that the network actually won, 11 games to 9. However, a

801

detailed analysis of the moves played by the network during the match indicates that the network
was extremely lucky to have won so many games, and could not reasonably be expected to continue
to do so well over a large number of games. Out of the 20 games played, there were 11 in which
the network did not make any serious mistakes. The network won 6 out of these 11 games, a result
which is quite reasonable. However, in 9 of the 20 games, the network made one or more serious
(i.e. potentially fatal) ""blunders."" The seriousness of these mistakes would be equivalently to dropping a piece in chess. Such a mistake is nearly always fatal in chess against a good opponent; however in backgammon there are still chances due to the element of luck involved. In the 9 games in
which the network blundered, it did manage to survive and win 5 of the games due to the element of
luck. (We are assuming that the mistakes made by the human, if any, were only minor mistakes.) It
is highly unlikely that this sort of result would be repeated. A much more likely result would be that
the network would win only one or two of the games in which it made a serious error. This would
put the network's expected perfonnance against expert or near-expert humans at about the 35-40%
level. (This has also been confinned in play against other networks.)
We find that the network does act as if it has picked up many of the global concepts and strategies of advanced play. The network has also learned many important tactical elements of play at
the advanced level. As for the specific kinds of mistakes made by the network, we find that they are
not at all random, senseless mistakes, but instead fall into clear, well-defined conceptual categories,
and furthennore, one can understand the reasons why these categories of mistakes are made. We do
not have space here to describe these in detail, and refer the reader instead to Ref. 5.
To summarize, qualitative analysis of the network's play indicates that it has learned many
important strategies and tactics of advanced backgammon. This gives the network very good overall
perfonnance in typical positions. However, the network's worst case perfonnance leaves a great
deal to be desired. The network is capable of making both serious, obvious, ""blunders,"" as well
more subtle mistakes, in many different types of positions. Worst case perfonnance is important,
because the network must make long sequences of moves throughout the course of a game without
any serious mistakes in order to have a reasonable chance of winning against a skilled opponent.
The prospects for improving the network's worst case perfonnance appear to be mixed. It seems
quite likely that many of the current ""blunders"" can be fixed with a reasonable number of handcrafted examples added to the training set. However, many of the subtle mistakes are due to a lack
of very sophisticated knowledge, such as the notion of timing. It is difficult to imagine that this kind
of knowledge could be imparted to the network in only a few examples. Probably what is required is
either an intractably large number of examples, or a major overhaul in either the pre-computed
features or the training paradigm.
DISCUSSION
We have seen from both quantitative and qualitative measures that the network has learned a
great deal about the general principles of backgammon play, and has not simply memorized the
individual positions in the training set. Quantitatively, the measure of game perfonnace provides a
clear indication of the network's ability to generalize, because apart from the first couple of moves
at the start of each game, the network must operate entirely on generalization. Qualitatively, one can
see after playing several games against the network that there are certain characteristic kinds of
positions in which it does well, and other kinds of positions in which it systematically makes welldefined types of mistakes. Due to the network's frequent ""blunders,"" its overall level of play is
only intennediate level, although it probably is somewhat better than the average intennediate-Ievel
player. Against the intennediate-level program Gammontool, our best network wins almost 60% of
the games. However, against a human expert the network would only win about 35-40% of the time.
Thus while the network does not play at expert level, it is sufficiently good to give an expert a hard
time, and with luck in its favor can actually win a match to a small number of games.
Our simple supervised learning approach leaves out some very important sources of

802

infonnation which are readily available to humans. 1be network is never told that the underlying
topological structure of its input space really corresponds to a one-dimensional spatial structure; all
it knows is that the inputs form a 459-dimensional hypercube. It has no idea of the object of the
game, nor of the sense of temporal causality, i.e. the notion that its actions have consequences, and
how those consequences lead to the achievement of the objective. The teacher signal only says
whether a given move is good or bad, without giving any indication as to what the teacher's reasons
are for making such a judgement. Finally, the network is only capable of scoring single moves in
isolation, without any idea of what other moves are available. 1bese sources of knowledge are
essential to the ability of humans to play backgammon well, and it seems likely that some way of
incorporating them into the network learning paradigm will be necessary in order to achieve further
substantial improvements in performance.
111ere are a number of ways in which these additional sources of knowledge might be incorporated, and we shall be exploring some of them in future work. For example, knowledge of alternative moves could be introduced by defining a more sophisticated error signal which takes into
account not only the network and teacher scores for the current move, but also the network and
teacher scores for other moves from the same position. However, the more immediate plans involve
a continuation of the existing strategies of hand-crafting examples and coding scheme modifications
to eliminate the most serious errors in the network's play. If these errors can be eliminated, and we
are confident that this can be achieved, then the network would become substantially better than any
commercially available program, and would be a serious challenge for human experts. We would
expect 65% performance against Gammontool, and 45% performance against human experts.
Some of the results of our study have implications beyond backgammon to more general
classes of difficult problems. One of the limitations we have found is that substantial human effort
is required both in the design of the coding scheme and in the design of the training set. It is not
sufficient to use a simple coding scheme and random training patterns, and let the automated network learning procedure take care of everything else. We expect this to be generally true when
connectionist learning is applied to difficult problem domains.
On the positive side, we foresee a potential for combining connectionist learning techniques
with conventional AI techniques for hand-crafting knowledge to make significant progress in the
development of intelligent systems. From the practical point of view, network learning can be
viewed as an ""enhancer"" of traditional techniques, which might produce systems with superior perfonnance. For this particular application, the obvious way to combine the two approaches is in the
use of pre-computed features in the input encoding. Any set of hand-crafted features used in a conventional evaluation function could be encoded as discrete or continuous activity levels of input
units which represent the current board state along with the units representing the raw information.
Given a suitable encoding scheme for these features, and a training set of sufficient size and quality
(i.e., the scores in the training set should be better than those of the original evaluation function), it
seems possible that the resulting network could outperform the original evaluation function, as evidenced by our experiment with the Gammontool features.
Networlc learning might also hold promise as a means of achieving the long-sought goal of
automated feature discovery2. Our network certainly appears to have learned a great deal of
knowledge from the training set which goes far beyond the amount of knowledge that was explicitJy
encoded in the input features. Some of this knowledge (primarily the lowest level components) is
apparent from the weight diagram when there are no hidden units (Fig. 3). However, much of the
network's knowledge remains inaccessible. What is needed now is a mean'! of disentangling the
novel features discovered by the network from either the patterns of activity in the hidden units, or
from the massive number of connection strengths which characterize the network. This is one our
top priorities for future research, although techniques for such ""reverse engineering"" of parallel
networlcs are only beginning to be developed l2 .

803

ACKNOWLEDGEMrnNTS
lhis work was inspired by a conference on ""Evolution, Games and Learning"" held at Los
Alamos National Laboratory, May 20-24, 1985. We thank Sun Microsystems Inc. for providing the
source code for their Gammontool program, Hans Berliner for providing some of the po!>itions used
in the data base, Subutai Ahmad for writing the weight display graphics package, Bill Bogstad for
assistance in programming the back-propagation simulator, and Bartlett Mel, Peter Frey, and Scott
Kirkpatrick for critical reviews of the manuscript. G.T. was supponed in part by the National
Center for Supercomputing Applications. TJ.S. was supponed by a NSF Presidential Young Investigator Award, and by grants from the Seaver Institute and the Lounsbury Foundation.
REFERENCES
1. D. E. Rumelart and J. L. McClelland, eds., Parallel Distributed Processing: Explorations in the
Microstructure o/Cognition, Vols. 1 and 2 (Cambridge: MIT Press, 1986).
2. A. L. Samuel, ""Some studies in machine learning using the game of checkers."" IBM J. Res.
Dev. 3, 210--229 (1959).
3. J. H. Holland, ""Escaping brittleness: the possibilities of general-purpose learning algorithms
applied to parallel rule-based systems."" In: R. S. Michalski et aI. (eds.), Machine learning: an
artificial ;ntelligence approach. Vol. II (Los Altos CA: Morgan-Kaufman, 1986).
4. R. S. Sutton, ""Learning to predict by the methods of temporal differences,"" GTE Labs Tech.
Repon TR87-509.1 (1987).
5. G. Tesauro and T. J. Sejnowski, ""A parallel network that learns to play backgammon."" Univ. of
Illinois at Urbana-Champaign, Center for Complex Systems Research Technical Repon (1987).
6. M. Minsky and S. Papen, Perceptrons (Cambridge: MIT Press, 1969).
7. D. E. Rumelhart, G. E. Hinton, and R. J. Williams, ""Learning representations by backpropagating errors."" Nature 323,533--536 (1986).
8. Y. Le Cun, ""A learning procedure for asymmetric network."" Proceedings o/Cognitiva (Par;s)
85,599--604 (1985).
9. D. B. Parker, ""Learning-logic."" MIT Center for Computational Research in Economics and
Management Science Tech. Repon TR-47 (1985).
10. H. Berliner, ""Backgammon computer program beats world champion."" Artificial Intelligence
14,205--220 (1980).
11. G. Tesauro, ""Neural network defeats creator in backgammon match."" Univ. of llIinois at
Urbana-Champaign, Center for Complex Systems Research Technical Repon (1987).
12. C. R. Rosenberg, ""Revealing the structure of NETtalk's internal representations."" Proceedings
of the Ninth Annual Conference of the Cognitive Science Society (Hillsdale, NJ: Lawrence Erlbaum
Associates, 1987).

"
31,1987,"Phase Transitions in Neural Networks","",31-phase-transitions-in-neural-networks.pdf,"Abstract Missing","192

PHASE TRANSITIONS IN NEURAL NETWORKS

Joshua Chover
University of Wisconsin, Madison, WI

53706

ABSTRACT

Various simulat.ions of cort.ical subnetworks have evidenced
something like phase transitions with respect to key parameters.
We demonstrate that. such transi t.ions must. indeed exist. in analogous
infinite array models. For related finite array models classical
phase transi t.ions (which describe steady-state behavior) may not.
exist., but. there can be distinct. quali tative changes in
(""metastable"") transient behavior as key system parameters pass
through crit.ical values .
INTRODUCTION

Suppose that one st.imulates a neural network - actual or
simulated - and in some manner records the subsequent firing
activity of cells. Suppose further that. one repeats the experiment.
for different. values of some parameter (p) of the system: and that
one finds a ""cri t.ical value"" (p) of the parameter, such that.
(say) for values

p

it. is for values

p

> pc

< p.
c

c

the act.ivity tends to be much higher than
Then, by analogy with statist.ical

mechanics (where, e.g., p may be temperature, with criUcal
values for boiling and freezing) one can say that. the neural
network undergoes a ""phase transition"" at. p. Intracellular phase
c

transi t.ions, parametrized by membrane potential, are well mown.
Here we consider intercellular phase transi t.ions. These have been
evidenced in several detailed cort.ical simulations: e.g., of the
1
2
piriform cortex and of the hippocampus
In the piriform case,
the parameter p represented the frequency of high amplitude
spontaneous EPSPs received by a typical pyramidal cell; in the
hippocampal case, the parameter was the ratio of inhibitory to
excitatory cells in the system.
By what. mechanisms could approach to, and retreat. from, a
cri t.ical value of some parameter be brought about.? An intriguing
conjecture is that. neuromodulators can play such a role in certain
3
networks; temporarily raising or depressing synaptic efficacies
What. possible interesting consequences could approach to
criticality have for system performance. Good effects could be
these: for a network with plasticity, heightened firing response
to a stimulus can mean faster changes in synaptic efficacies, which
would bring about. faster memory storage. More and longer activi ty
could also mean faster access to memory. A bad effect. of
? American Institute of Physics 1988

193

near-criticality - depending on other parameters - can be wild,
epileptiform activity.
Phase transitions as they might. relate to neural networks have
4
been studied by many authors
Here, for clarity, we look at. a
particular category of network models - abstracted from the
piriform cortex set.ting referred to above - and show the following:
a) For ""elementary"" reasons, phase transition would have to
exist if there were infinitely many cells; and the near-subcrit.ical
state involves prolonged cellular firing activity in response to an
ini t.ial stimulation.
b) Such prolonged firing activity takes place for analogous
large finite cellular arrays - as evidenced also by computer
simulat.i ons.
What. we shall be examining is space-time patterns which
describe the mid-term transient. activity of (Markovian) systems
that. tend to silence (with high probability) in the long run.
(There is no reference to energy functions, nor to long-run stable
firing rates - as such rates would be zero in most. of our cases.)
In the following models time will proceed in discrete steps.
(In the more complicated set.tings these will be short. in comparison
to other time constants, so that. the effect of quant.ization becomes
smaller.) The parameter p will be the probability that at. any
given t.ime a given cell will experience a certain amount. of
exci tatory ""spontaneous firing"" input.: by itself this amount. will
be insufficient. to cause the cell to fire, but. in conjunction wi th
sufficiently many exci tatory inputs from other cells it. can assist.
in reaching firing threshold. (Other related parameters such as
average firing threshold value and average efficacy value give
similar results.) In all the models there is a refractory period
after a cell fires, during which it cannot fire again; and there
may be local (shunt. type) inhibition by a firing cell on near
neighbors as well as on itself - but. there is no long-distance
inhibi tion. We look first. at. limi ting cases where there are
infini tely many cells and - classically - phase transi tion appears
in a sharp form.
A ""SIMPLE"" MODEL
We consider an infinite linear array of similar cells which
obey the following rules, pictured in Fig. lA:
(i) If cell k fires at. time n, then it. must. be silent.
at. t.ime n+l;
(11) if cell k is silent. at. time n but. both of its
neighbors k-l and k+l do fire at. time n, then cell k fires
at. t .ime n+l;
(iii) if cell k is silent at time n and just one of its
neighbors (k-l or k+ I) fires at. time n, then ce 11 k wi 11
fire at t .ime n+l with probability p and not. fire with
probability l-p, independently of similar decisions at. other
cells and at. other times.

194

A

~

TIM~

CELLS""""""'>

~ ???0. 0

~

i

000
1'\

~

oollio

DOD
i

Fig. 1. ""Simple model"". A: firing rules; cells are represented
horizontally, time proceeds downwards: filled squares
denote firing. B: sample development.

Thus, effecUvely, signal propagat ion speed here is one cell
per uni t . time, and a cell's firing threshold value is 2 (EPSP
units). If we sUmulate ~ cell to fire at time n::O, will its
influence necessarily die out or can it. go on forever? (See
Fig. lB.) For an answer we note that. in this simple case the
firing paUern (if any) at. Ume n must. be an alternat.ing stretch
of firing/silent. cells of some length, call it. L. Moreover,
n

2

=

L I
L +2 with probability p
(when there are sponteneous
n+
n
firing assists on both ends of the stretch), or
Ln+l
Ln -2 with

=

2

probability (l-p)
(when there is no assist at. either. end of the
stretch), or
Ln+l = Ln with probability 2p(l-p) (when there is
an assist. at. just. one end of the stretch).
Start.ing wi th any fini te al ternating stretch
successive values

L
n

nonnegat.ive integers.
same conclusion:

La,

the

consUtute a ""random walk"" among the
Intui t.ion and simple analysis 5 lead to the

if the probability for

L
n

2

to decrease

?1_p)2)

is greater than that. for it. to increase (p) - i.e. if the average
step taken by the random walk is negative - then ul t .imately L
n
will reach a and the firing response dies out. COntrariwise, if

195

P

2

) (l-p)

2

then the

L

n

can drift. to even higher values wi th

positive probability. In Fig. 2A we sketch the probability for
ultimate die-out as a function of p: and in Fig. 2B, the average
time until die out. Figs. 2A and B show a classic example of phase
transition (p = 1/2) for this infinite array.
c

,
\

A

\

8

I

-

?1?-- - - I'~ l<'I)

f.

Fig. 2. Critical behavior. A: probability of ultimate die out. (or
of reaching other traps. in finite array case).
B: average time until die-out (or for reaching other
traps). Solid curves refer to an infinite array; dashed,
to finite arrays.

MORE mMPLEX MODELS

For an infinite linear array of cells, as sketched in Fig. 3 .
we describe now a much more general (and hopefully more realistic)
set of rules:
(i') A cell cannot fire, nor receive excitatory inputs. at.
time n if it has fired at any time during the preceding ~ Hme
units (refraction and feedback inhibition).
(11 .) Each cell x has a local ""inhibitory neighborhood""
consisting of a number (j) of cells to its immediate right. and
left.. The given cell x cannot. fire or receive excitatory inputs
at Hme n if any other cell y in its inhibi tory neighborhood
has fired at. any t .ime between t. and t+m I uni ts preceding n,
where
to x

t . is the t .ime it. would take for a message to travel from
at. a speed of VI cells per unit time. (This rule

y

represents local shunt~type inhibition.)
(iii') Each cell x has an ""excitatory neighborhood""
consisting of a number (e) of cells to the immediate right. and left
of its inhibitory neighborhood. If a cell y in that. neighborhood
fires at a certain time. that firing causes a unit impulse to
travel to cell x at a speed of vE cells per uni t. time. The
impulse is received at. x subject to rules (i') and (11').

196

(iv') All cells share a ""firing threshold"" value 9 and an
""integraUon Ume constant."" s (s < 9). In addition each cell. at.
each t.ime n and independent ly of other times and other cells. can
receive a random amount. X
of ""spontaneous excitatory input."" .
n

The variable

Xn

can have a general distribution: however. for

simplicity we suppose here that. it. assumes only one of two values:
b or O. with probabilities p and 1-p respecUvely. (We
suppose that. b <. e. so that. the spontaneous ""assist."" itself is
insufficient. for firing.) The above quant.i ties enter into the
following firing rule: a cell will fire at. time n if it. is not.
prevented by rules (i') and (ii') and if the total number of inputs
from other cells. received during the integration ""window"" last.ing
between t.imes n-s+1 and n inclusive. plus the assist. X ,
n

equals or exceeds the threshold 9.
(The propagat.ion speeds vI and

VE and the neighborhoods

are here given left.-right. syrrmetry merely for ease in exposi tion.)

o0

0 0 tl 0 ?

[J ?

I~h

t
t

'""""

~

Jl tl tl

?

[J U ' 0

I

0 0 D ? 11 0
~Iit'

0 Jl 0 '""

I
I

)l,.

Fig. 3. Message travel in complex model:
(i')-(iv').

see text. rules

Wi 11 such a mode 1 d i sp lay phase trans i t i on a t. some cr i t .i cal
value of the spontaneous firing frequency p? The dependence of
responses upon the ini t.ial condi tions and upon the various
parameters is intricate and wi 11 affect. the answer. We briefly
discuss here conditions under which the answer is again yes.
(1) For a given configuration of parameters and a given
ini Ual stimulation (of a stretch of cont.iguous cells) we compare
the development. of the model's firing response first. to that. of an
auxil iary ""more act.ive"" system: Suppose that. L
now denotes the
n

distance at. t.ime n between the left:- and right.- most cells which
are either firing or in refractory mode. Because no cell can fire
wi thout. influence from others and because such influence travels at.
a given speed, there is a maximal amount. (D) whereby L 1 can
n+
exceed L. There is also a maximum probability Q(p) - which
n

197

depends on the spontaneous firing parameter
(whatever

n).

'We can compare

defined so that. An+l = An+D
An+l = An-1

with probability

A

L

n

n

with probability
l-Q(p).

more likely to increase than
ou t . than

p - that. Ln+ 1 ~ Ln
with a random walk ""A""

L.

In the many cases where

n

does, the average step size of
wi 11 become negat.ive for

p

A

L

n

Q(p)

(viz.,

n

and

At each transition,

Hence

n

Q(p)

An

is

is more likely to die
tends to zero as

p

DQ(p)+(-I)(I-Q(b?)

below a ""cri tical"" value

p.
a

Thus,

as in the ""simple"" model above, the probability of ultimate die-out
for the A, hence also for the L
of the complex model, will be
n

1 when

0

~

p

< pa .

n

(2) There will be a phase transition for the complex model if
its probability of die out. - given the same parameters and initial
stimulation is in (1) - becomes less than 1 for some p values
with p < p < 1. Comparison of the complex process with a simpler
a

""less act.ive"" process is difficul t. in general. However, there are
parameter configurat.ions which ul timately can channel all or part.
of the firing activity into a (space-t.ime) sublat.t .ice analgous to
that. in Fig. 1. Fig. 4 illustrates such a case. For p
sufficiently large there is posi tive probabili ty that. the act.ivity
will not. die out, just as in the ""simple"" model.

Fig. 4. Activity on a sublattice. (Parameter values: j=2, e=6,
MR=2, M1=I, VR=V 1=I, 9=3, s=2, and b=I.) Rectangular
areas indicate refract.ionlinhibi tion: diagonal lines,
excitatory influence.

198

LARGE FINITE ARRAYS
Consider now a large finite array of N cells, again as
sketched in Fig. 3 ; and operating according to rules similar to
(i')-(iv') above, with suitable modifications near the edges.
Appropriately encoded, its activity can be described by a (huge)
Markov transit.ion matrix, and - depending on the initial
st.imulation - must. tend 5 to one of a set. of steady-state
distribut.ions over firing patterns. For example, (a) if N is
odd and the rules are those for Fig. I, then extinct.ion is the
unique steady state, for any p (1 (since the L
form a random
n

walk with ""reflecUng"" upper barrier). But, ?(3) if N is even
and the cells are arranged in a ring, then, for any P with
o < p < 1. both ext.inction and an alternate flip-flop firing
pat.tern of period 2 are ""traps"" for the system - wi th relative long
run probabilities determined by the initial state. See the dashed
line in Fig. 2A for the extinction probability in the ?(3) case,
and in Fig. 2B for the expected time until hitting a trap in the

(a)

case

1

(P(2)

and the

{(3)

case.

What quali tat.ive properties related to phase transi tion and
critical p values carryover from the infinite to the finite
array case? The (a) example above shows that long term activity
may now be the same for all 0 ( p (1 but. that parameter
intervals can exist. whose key feature is a particularly large
expected t.ime before the system hi ts a trap. (Again. the cri tical
region can depend upon the ini tial st.imulation.) Prior to being
trapped the system spends its time among many states in a kind of
""metastable"" equilibrium. (We have some preliminary theoretical
results on this conditional equilibrium and on its relation to the
infinite array case. See also Ref. 6 concerning time scales for
which certain corresponding infinite and finite stochastic automata
systems display similar behavior . )
Simulat.ion of models satisfying rules (i' )-( iv') does indeed
display large changes in length of firing activity corresponding to
parameter changes near a critical value. See Fig. 5 for a typical
example: As a function of p, the expected time until the system
is trapped (for the given parameters) rises approximately linearly
in the interval .05<p( .12, wi th most. runs resul ting in extinction
- as is the case in Fig. 5A at. time n=115 (for p=.10). But. for
p).15 a relatively rigid patterning sets in which leads with high
probability to very long runs or to traps other than extinction as is the case in Fig. 5B (p=.20) where the run is arbitrarity
truncated at. n=525. (The patterning is highly influenced by the
large size of the excitatory neighborhoods.)

199

A

_........ - . ...._...
0'

..- .: .... ... ._.... .
- -"" .- ..""

"" -""

'.

_

...? _.. _... ..
-_'0 ., .

. -,'

.....

"" ' : ', '

- '

??_

?

, ,-

.

: . ,0.

.. .

'

?

?

'0'

,0

... -.'

?

?

.

-

,.- . -. ....

.

?
? ..

O' ' 0' ,0

?

---""-' .. "":... . .. . . ...
.'
... .
--- -- .....- _...._..... ..
. ...
...... - ..... -.
.
.:.
.'
...... .... "".
....
......... ' . ' . .. .. .
.
....

_.... -

o

.:

. .. . . . ..... . . ..

_-

--.0

?

_ ... - ? ? _

?

.. ' 0 ?? ..... ' -

?

?
._ '_

, _.

'0'

'

.

. ..: ....: ...: .---. ,.

.... ,0

'0 -

?

' 0 '

?? _ . . .. ...

?
,0

-- .. -.-

_ 0? - .. .. : . ...

? ?

.

?

?

. . .. _

--......:. _.-

? ?? _,'

"" ,_

?.' . . ... '0 ,. ' 0 ... '
?
,' . : ?? ? ? _ ....

.

.

0 ?. ?? ???? ""
. . . - 0 . ? ..._. . ... ?,.....
. ' . "" ' - ', .
... . ,0 ,
..... -...... _.,.- ... _....
. ..

? ?? ___ ?? _ ..... : ?? - ....... _ .

'.'

,-.- ,'.'""
.0_ ' .... . .... . -. .

--'- -- ....__._-.... . .-..

'.

""

B
. __ . . .-.. -...... _... ....... .::.:. : __ . .........: ........_..- ..... .---_0_

__ ,

... .

_ ,0

?

.'

. .... . . ,0 ?

... . . . . . _

..
.. ,. .
.._-_
......... .-_. .._-_._ ..:.'. -'. '-----._-.... .- .. .
-----_._-_ .. .'--- ----_ ...- ......__._---

'

'

'

..----,..... -

,

--- --- ,--""--- .-- .. ..- . .... -.
-------- .---....?....?'------_ . ' - ..'---- ---------- .-... _.....--_._..
--.......--_ . .-.
--------------.
---_.-._- - '--.
'

1

TIME

---- ""- -'.'._-'. ""
---------........--.---- ------- . .. ---. --.._-- ...
------- --------.
------------ . .. _.. _-- .. _------------ --- ....? -.._- .._------------_._
....... -._ ......._. ----'----_.
-'-'- .'-'--...... ---.- -' . .. _"",--. _.._-----.- ------- ----. ---

'

...

~.

Fig. 5. Space t .ime firing patterns for one configuration of basic
parameters. (There are 200 cells; j=2, e=178, MR=10,
M1=9, VR=V 1=7, 9=25, s=2, and b=12; 50 are stimulated
init.ially.)

A:

p=.10.

B:

p=.20.

mNa..USION
Mechanisms such as neuromodulators, which can (temporarily)
bring spontaneous firing levels - or synapt.ic efficacies, or
average firing thresholds, or other similar parameters - to
near-critical values, can thereby induce large amplification of
response act.ivi ty to selected stimul i"" The repertoire of such
responses is an important. aspect- of the system's function.

200

[Acknowledgement.: Thanks to C. Bezuidenhout. and J. Kane for help
wi th simulat.ions.]
REFERENCES

1.
2.
3.
4.

5.
6.

M. Wilson. J. Bower. J. Chover. L. Haberly. 16th Neurosci.
Soc. Mtg. Abstr. 370.11 (1986).
R. D. Traub. R. Miles. R.K.S. Wong. 16th Neurosci. Soc. Mtg.
Abstr. 196.12 (1986).
A. Selverston. this conference. also. Model Neural Networks
and Behavior. Plenum (1985); E. Marder. S. Hooper. J. Eisen.
SynapUc Function. Wiley (1987) p.305.
E.g.: W. Kinzel. Z. Phys. B58, p. 231 (1985); A. Noest..
Phys. Rev. Let.. 57( 1), p. 90 (1986); R. DurreU. (to appear);
G. Carpenter, J. Diff. Eqns. 23, p.335 (1977); G. Ermentraut,
S. Cohen. BioI. Cyb. 34, p.137 (1979); H. Wilson. S. Cowan.
Biophys. J. 12 (1972).
W. Feller. An Introd. to Prob. Th?y. and Appl?ns. I. Wiley
(1968) Ch. 14. 15.
T. Cox and A. Graven (to appear).

"
32,1987,"Synchronization in Neural Nets","",32-synchronization-in-neural-nets.pdf,"Abstract Missing","824

SYNCHRONIZATION IN NEURAL NETS

Jacques J. Vidal
University of California Los Angeles, Los Angeles, Ca. 90024
John Haggerty?
ABSTRACT

The paper presents an artificial neural network concept (the
Synchronizable Oscillator Networks) where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons. This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks. Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages.
In our model, neurons fire spontaneously and regularly in the
absence of perturbation. When interaction is present, the scheduled
firings are advanced or delayed by the firing of neighboring neurons.
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors. From arbitrary initial states,
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events.
INTRODUCTION

Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks. This is
the case in particular with the networks proposed by Fukushima I,
Hopfield 2 , Rumelhart 3 and many others. In every case, the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed (integrated). The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons.
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity.
Indeed, it can be observed with many real neurons that action
potentials (spikes) are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
3030 W. 6th St. LA, Ca. 90020

@)

American Institute of Physics 1988

825

input rates levels result in more rapid firing.
Behind these
traditional models, there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons. Because of integration, the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply ""frequency coded"". The exact timing of individual firing is
ignored.
This view however does not cover some other well known
aspects of neural communication. Indeed, the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions. One classic example is that of pre-synaptic
inhibition, a widespread mechanism in the brain machinery. Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks 4 . 5 .
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event. On the input side of each node, the firing of
other nodes (the presynaptic neurons) either delay (inhibit) or
advance (excite) the node firing. As seen earlier, this type of
neuronal interaction which would be called phase-modulation in
engineering systems, can also find its rationale in experimental
neurophysiology. Neurophysiological plausibility however is not the
major concern here. Rather, we propose to explore a potentially
useful mechanism for parallel distributed computing. The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages. The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems.
NEURONS AS SYNCHRONIZABLE OSCILLATORS:

In our model, the proceSSing elements (the ""neurons"") are
relaxation oscillators with built-in self-inhibition. A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached. At that point the energy is abruptly released, and a new
cycle begins.
The description above fits the dynamic behavior of neuronal
membranes. A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley 6 and in a simplified version given by Fitzhugh7. These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing.
When the membrane
potential enters the critical region, an abrupt depolarization, i.e., a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery. This brief electrical

826

shorting of the membrane is called the action potential or ""spike""
and constitutes the output event for the neuron. If the causes for the
initial depolarization are maintained,
oscillation ( ""limit-cycles"")
develops, generating multiple firings. Depending on input level and
membrane parameters, the oscillation can be limited to a single
spike, or may produce an oscillatory burst, or even continually
sustained activity.
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure 1.
Activation
EnergyE(t)

Exdt3tOIJ
OJ

Input

Out

InJrjh1~olJ

Input perturbation

~~utl

Intemilf
l!neJU Inpul

r

1

u (t -

ty

t

Figure 1 Relaxation Oscillator with perturbation input
Firing occurs when the energy level E(t) reaches some critical
level Ec. Assuming a constant rate of energy influx a, firing will
occur with the natural period
Ec?
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation, the firing schedule is disturbed. Letting to represent
the instant of the last firing of the cell and tj. U = 1.2 ?... J), the
intants of impinging arrivals from other cells:
E(t - to) = aCt - to) +

L

Wj ?? uo(t - til ; E

$

Ec

where uo(t) represents the unit impulse at t=O.
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case, that of a
master slave interaction between two regularly firing oscillator units
A and B, with natural periods TA and TB. At the instants of firing,
unit A unidirectionally sends a spike Signal to unit B which is
received at some interval <I> measured from the last time B fired.

827

Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time 4>. The
relationship 6E(4)) can be shaped to represent refractoriness and
other post-spike properties. Here it is assumed to be a simple ramp
function. If the interaction is inhibitory. the consequence of this
arrival is that the next firing of unit B is delayed (with respect to
what its schedule would have been in absence of perturbation) by
some positive interval 5 (Figure 2). Because of the shape of 6E(4)) .
the delaying action. nil immediately after firing. becomes longer for
impinging pre-synaptic spikes that arrive later in the interval. If the
interaction is excitatory. the delay is negative. Le. a shortening of the
natural firing interval. Under very general assumptions regarding the
function 6E( 4?. B will tend to synchronize to A. Within a given
range of coupling gains,
the phase 4> will self-adjust until
equilibrium is achieved. With a given 6E(4)) , this equilibrium
corresponds to a distribution of maximum entropy, i.e., to the point
where both cells receive the same amouint of activation. during their
common cycle.

I

I
~h ~ $~~
~

~

.. ) Inhibition

B ( .. ) Excitation
Figure 2 Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval

The synchronization dynamiCS presents an attractor for each
rational frequency pair. To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking (Figure 3). The wider stability wnes correspond to a one to
one ratio between fA and fB (or between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which, within each stability region,

828

takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates 8, 5.
The areas between these ranges of stability have the appearance
of unstable transitions but in fact. as recently pOinted out by Bak9 ?
form an infinity of locking steps known as the Devil's Staircase.
corresponding to the infinity of intermediate rational pairs (figure 3).
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems.
1/2

~

;;:
I

1/2

)

Excitation

Inhibiti~~v'/ I

:7

lI?L

It.?'

Figure 3 Unilateral SynchroniZation:
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS

The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem. For each synchronization equilibrium, the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios.
The often cited ""Traveling Salesman Problem"". the archetype
for a class of important ""hard"" problems. is a special case when the
ratio must be 1 / 1: all nodes must fire at the same frequency. Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle. Furthermore. the
firings must be ordered along a minimal path.
Using stochastic energy minimization and simulated annealing. the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes. The TSP is isomorphic to many
other sequencing problems which involve distributed constraints. and
fall into the oscillator array neural net paradigm in a particularly
natural way. Work is being pursued to more rigorously establish the
limits of applicability of the model..

829

~~~~~-L~~~~~~T-

171~~~~~~~~~-L~-

I

Annea/./ng

~
a~~~--~~--~----~--

171--~L-~~--~~--~~-

c~--~~--~--~----~?
Gf~--~~--~----L-----~

e

t-A-----.&--------.?.----

Figure 4. The Traveling Salesman Problem: In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path.

ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. D8412I1, and by NASA NAG 2-302.

REFERENCES
l.
2.

3.

K. Fukushima. BioI. Cybern. 20. 121 (1975).
J.J. Hopfield. Proc. Nat. Acad. Sci. 79.2556 (1982).
D.E. Rumelhart. G.E. Hinton. and R.J. Williams. Parallel
Distributed Processing: Explorations in the
Microstructure oj Cognition, (MIT Press. Cambridge.

4.
5.
6.
7.
8.
9.
10.

MA .. 1986) p. 318.
J.P. Segundo. G.P. Moore. N.J. Stensaas. and T.H. Bullock. J. Exp.
BioI. 40. 643. (1963).
J.P. Segundo and A.F. Kohn. BioI Cyber 40. 113 (1981).
A.L. Hodgkin and A.F. Huxley. J. PhysiOI. 117.500 (1952).
Fitzhugh. Biophysics J .. 1. 445 (1961).
A.F. Kohn. A. Freitas da Rocha. and J.P. Segundo. BioI. Cybem.
41. 5 (1981).
P. Bak. Phys. Today (Dec 1986) p. 38 .
J. Haggerty and J.J. Vidal. UCLA BCI Report. 1975.

"
33,1987,"LEARNING BY STATE RECURRENCE DETECTION","",33-learning-by-state-recurrence-detection.pdf,"Abstract Missing","642

LEARNING BY STATE RECURRENCE DETECfION
Bruce E. Rosen, James M. Goodwint, and Jacques J. Vidal
University of California, Los Angeles, Ca. 90024

ABSTRACT
This research investigates a new technique for unsupervised learning of nonlinear
control problems. The approach is applied both to Michie and Chambers BOXES
algorithm and to Barto, Sutton and Anderson's extension, the ASE/ACE system, and
has significantly improved the convergence rate of stochastically based learning
automata.
Recurrence learning is a new nonlinear reward-penalty algorithm. It exploits
information found during learning trials to reinforce decisions resulting in the
recurrence of nonfailing states. Recurrence learning applies positive reinforcement
during the exploration of the search space, whereas in the BOXES or ASE algorithms,
only negative weight reinforcement is applied, and then only on failure. Simulation
results show that the added information from recurrence learning increases the learning
rate.
Our empirical results show that recurrence learning is faster than both basic failure
driven learning and failure prediction methods. Although recurrence learning has only
been tested in failure driven experiments, there are goal directed learning applications
where detection of recurring oscillations may provide useful information that reduces
the learning time by applying negative, instead of positive reinforcement.
Detection of cycles provides a heuristic to improve the balance between evidence
gathering and goal directed search.

INTRODUCflON
This research investigates a new technique for unsupervised learning of nonlinear
con trol problems with delayed feedback. Our approach is compared to both Michie and
Chambers BOXES algorithml, to the extension by Barto, et aI., the ASE (Adaptive
Search Element) and to their ASE/ACE (Adaptive Critic Element) system2 , and shows
an improved learning time for stochastically based learning automata in failure driven
tasks.
We consider adaptively controlling the behavior of a system which passes
through a sequence of states due to its internal dynamics (which are not assumed to be
known a priori) and due to choices of actions made in visited states. Such an adaptive
controller is often referred to as a learning automaton. The decisions can be
deterministic or can be made according to a stochastic rule. A learning automaton has
to discover which action is best in each circumstance by producing actions and
observing the resulting information.
This paper was motivated by the previous work of Barto, et al. to investigate
neuronlike adaptive elements that affect and learn from their environment. We were
inspired by their current work and the recent attention to neural networks and
connectionist systems, and have chosen to use the cart-pole control problem 2, to enable
a comparison of our results with theirs .
...
!

Permanent address: California State University, Stanislaus; Turlock, California.

@ American Institute of Physics 1988

643

THE CART?POLE PROBLEM
In their work on the cart-pole problem, Barto, Sutton and Anderson considered a
learning system composed of an automaton interacting with an environment. The
problem requires the automaton to balance a pole acting as an inverted pendulum hinged
on a moveable cart. The cart travels left or right along a bounded one dimensional track;
the pole may swing to the left or right about a pivot attached to the cart. The automaton
must learn to keep the pole balanced on the cart, and to keep the cart within the bounds
of the track. The parameters of the cart/pole system are the cart po~ition and velocity,
and the pole angle and angular velocity. The only actions available to the automaton are
the applications of a fixed impulsive force to the cart in either right or left direction; one
of these actions must be taken.
This balancing is an extremely difficult problem if there is no a priori knowledge
of the system dynamics, if these dynamics change with time, or if there is no
preexisting controller that can be imitated (e.g. Widrow and Smith's3 ADALINE
controller). We assumed no a priori knowledge of the dynamics nor any preexisting
controller and anticipate that the system will be able to deal with any changing
dynamics.
Numerical simulations of the cart-pole solution via recurrence learning show
substantial improvement over the results of Barto et aI., and of Michie and Chambers,
as is shown in figure 1. The algorithms used, and the results shown in figure 1, will
be discussed in detail below.
500000 ~------------------------------

T'unc
Until
Fai1\R
100000

25

so

75

110

Trial No.

Figure 1: Perfonnance of the ASE, ASE/ACE, Constant Recurrence (HI) and
Shon Recurrence (H2) Algorithms.
THE GENERAL PROBLEM: ASSIGNMENT OF CREDIT
The cart-pole problem is one of a class of problems known as ""credit
assignment""4, and in particular temporal credit assignment. The recurrence learning
algorithm is an approach to the general temporal credit assignment problem. It is
characterized by seeking to improve learning by making decisions about early actions.
The goal is to find actions responsible for improved or degraded perfonnance at a much
later time.
An example is the bucket brigade algorithmS. This is designed to assign credit to
rules in the system according to their overall usefulness in attaining their goals. This is
done by adjusting the strength value (weight) of each rule. The problem is of
modifying these strengths is to permit rules activated early in the sequence to result in
successful actions later.

644

Samuels considered the credit assignment problem for his checkers playing
program6 . He noted that it is easy enough to credit the rules that combine to produce a
triple jump at some point in the game; it is much harder to decide which rules active
earlier were responsible for changes that made the later jump possible.
State recurrence learning assigns a strength to an individual rule or action and
modifies that action's strength (while the system accumulates experience) on the basis
of the action's overall usefulness in the situations in which it has been invoked. In this
it follows the bucket brigade paradigm of Holland.

PREVIOUS WORK
The problems of learning to control dynamical systems have been studied in the
past by Widrow and Smith 3, Michie and Chambers!, Barto, Sutton, and Anderson 2,
and Conne1l 7 . Although different approaches have been taken and have achieved
varying degrees of success, each investigator used the cart/pole problem as the basis for
empirically measuring how well their algorithms work.
Michie and Chambers l built BOXES, a program that learned to balance a pole on
a cart. The BOXES algorithm choose an action that had the highest average time until
failure. After 600 trials (a trial is a run ending in eventual failure or by some time limit
expiration), the program was able to balance the pole for 72,000 time steps. Figure 2a
describes the BOXES learning algorithm. States are penalized (after a system failure)
according to recency. Active states immediately preceding a system failure are
punished most.
Barto, Sutton and Anderson 2 used two neuronlike adaptive elements to solve the
control problem. Their ASE/ACE algorithm chose the action with the highest
probability of keeping the pole balanced in the region, and was able to balance the pole
for over 60,000 time steps before completion of the lOOth trial.

Figure 2a and 2b: The BOXES and ASE/ACE (Associative Search Elelement Adpative Critic Element) algorithms
Figure 2a shows the BOXES (and ASE) learning algorithm paradigm When the
automaton enters a failure state (C), all states that it has traversed (shaded rectangles)
are punished, although state B is punished more than state A. (Failure states are those
at the edges of the diagram.) Figure 2b describes the ASE/ACE learning algorithm. If
a system failure occurs before a state's expected failure time, the state is penalized. If a
system failure occurs after its expected failure time, the state is rewarded. State A is
penalized because a failure occurred at B sooner than expected. State A's expected

645
failure time is the time for the automaton to traverse from state A to failure point C.
When leaving state A, the weights are updated if the new state's expected failure time
differs from that of state A.
Anderson 8 used a connectionist system to learn to balance the pole. Unlike the
previous experiments, the system did provide well-chosen states a priori. On the
average, 10,000 trials were necessary to learn to balance the pole for 7000 time steps.
Connell and Utgoff'7 developed an approach that did not depend on partitioning
the state space into discrete regions. They used Shepard's function 9,l0 to interpolate
the degree of desirability of a cart-pole state. The system learned the control task after
16 trials. However, their system used a knowledge representation that had a priori
information about the system.

O'n-lER RELATED WORK
Klopfll proposed a more neurological class of differential learning mechanisms
that correlates earlier changes of inputs with later changes of outputs. The adaptation
formula used multiplies the change in outputs by the weighted sum of the absolute
value of the t previous inputs weights (~Wj)' the t previous differences in inputs (~Xj)'
and the t previous time coefficients (c/
Sutton's temporal differences (TD)12 approach is one of a class of adaptive
prediction methods. Elements of this class use the sum of previously predicted output
values multiplied by the gradient and an exponentially decaying coefficient to modify
the weights. Barto and Sutton 13 used temporal differences as the underlying learning
procedure for classical conditioning.
THERECURRENCELE~G~HOD

DEFINITIONS
A state is the set of values (or ranges) of parameters sufficient to specify the
instantaneous condition of the system.
The input decoder groups the environmental states into equivalence classes:
elements of one class have identical system responses. Every environmental input is
mapped into one of n input states. (All further references to ""states"" assumes that the
input values fall into the discrete ranges determined by the decoder, unless otherwise
specified. )
States returned to after visiting one or more alternate states recur.
An action causes the modification of system parameters, which may change the
system state. However, no change of state need occur, since the altered parameter
values may be decoded within the same ranges.
A weight, wet), is associated with each action for each state, with the probability
of an allowed action dependent on the current value of its weight.
A rule determines which of the allowable actions is taken. The rule is not
deterministic. It chooses an action stochastically, based on the weights.
Weight changes, ~w(t), are made to reduce the likelihood of choosing an action
which will cause an eventual failure. These changes are made based on the idea that the
previous action of an element, when presented with input x(t), had some influence in
causing a similar pattern to occur again. Thus, weight changes are made to increase the
likelihood that an element produces the same action f(t) when patterns similar to x(t)
occur in the future.

646

For example, consider the classic problem of balancing a pole on a moving cart.
The state is specified by the positions and velocities of both the cart and the pole. The
allowable actions are fixed velocity increments to the right or to the left, and the rule
determines which action to take, based on the current weights.

THE ALGORITHM
The recurrence learning algorithm presented here is a nonlinear reward-penalty
method 14. Empirical results show that it is successful for stationary environments. In
contrast to other methods, it also may be applicable to nonstationary environments'.
Our efforts have been to develop algorithms that reward decision choices that lead the
controller/environment to quasi-stable cycles that avoid failure (such as limit cycles,
converging oscillations and absorbing points).
Our technique exploits recurrence information obtained during learning trials.
The system is rewarded upon return to a previous state, however weight changes are
only permitted when a state transition occurs. If the system returns to a state, it has
avoided failure. A recurring state is rewarded. A sequence of recurring states can be
viewed as evidence for a (possibly unstable) cycle. The algorithm forms temporal
""cause and effect"" associations.
To optimize performance, dynamic search techniques must balance between
choosing a search path with known solution costs, and exploring new areas of the
search space to find better or cheaper solutions. This is known as the two armed bandit
problem l5 , i.e. given a two handed slot machine with one arm's observed reward
probabilities higher than the other, one should not exclude playing with the arm with
the lesser payoff. Like the ASE/ACE system, recurrence learning learns while
searching, in contrast to the BOXES and ASE algorithms which learn only upon
failure.

RANGE DECODING
In our work, as in Barto and others, the real valued input parameters are analyzed
as members of ranges. This reduces computing resource demands. Only a limited
number of ranges are allowed for each parameter. It is possible for these ranges to
overlap, although this aspect of range decoding is not discussed in this paper, and the
ranges were considered nonoverlapping. When the parameter value falls into one of the
ranges that range is active. The specification of a state consists of one of the active
ranges for each of the parameters. If the ranges do not overlap, then the set of
parameter values specify one unique state; otherwise the set of parameter values may
specify several states. Thus, the parameter values at any time determine one or several
active states Si from the set of n possible states.
The value of each environmental parameter falls into one of a number of ranges,
which may be different for different parameters. A state is specified by the active range
for each parameter.
The set of input parameter values are decoded into one (or more) of n ranges Si'
0<= i <= n. For this problem, boolean values are used to describe the activity level of
a state Si. The activity value of a state is 1 if the state is active, or 0 if it is inactive.

ACfION DECISIONS
Our model is the same as that of the BOXES and ASE/ACE systems, where only
one input (and state) is active at any given time. All states were nonoverlapping and
mutually exclusive, although there was no reason to preclude them from overlapping

647

other than for consistency with the two previous models. In the ASE/ACE system and
in ours as well, the output decision rule for the controller is based on the weighted sum
of its inputs plus some stochastic noise. The action (output) decision of the controller
is either + 1 or -1, as given by:
( 1)

where
f( )

z

= [+-llfz<O
1 .i f z ~ 0 ]

(2)

and noise is a real randomly (Gaussian) distributed value with some mean 11 and
variance 0'2. An output, fez), for the car/pole controller is interpreted as a push to the
left if fez) =-lor to the right if fez) = +1.
RECURRENCELE~G

The goal of the recurrence learning algorithm is to avoid failure by moving toward
states that are part of cycles if such states exist, or quasi-stable oscillations if they
don't. This concept can be compared to juggling. As long as all the balls are in the air,
the juggler is judged a success and rewarded. No consideration is given to whether the
balls are thrown high or low, left or right; the controller, like the juggler, tries for the
most stable cycles. Optimum performance is not demanded from recurrence learning.
Two heuristics have been devised. The fundamental basis of each of them is to
reward a state for being repeatedly visited (or repeatedly activated). The first heuristic
is to reward a state when it is revisited, as part of a cycle in which no failure had
occurred. The second heuristic augments the first by giving more reward to states
which panicipate in shorter cycles. These heuristics are discussed below in detail.
HEURISTIC HI: If a state has been visited more than once during one trial,
reward it by reinforcing its weight.

RATIONALE
This heuristic assumes that states that are visited more than once have been part of
a cycle in which no failure had occurred. The action taken in the previous visit is
assumed to have had some influence on the recurrence. By reinforcing a weight upon
state revisitation, it is assumed to increase the likelihood that the cycle will occur again.
No assumptions are made as to whether other states were responsible for the cycle.

RESTRICfION
An action may not immediately cause the environment to change to a different
state. There may be some delay before a transition, since small changes of parameters
may be decoded into the same input ranges, and hence the same state. This inertia is
incorporated into the heuristics. When the same state appears twice in succession, its
weight is not reinforced, since that would assume that the action, rather than inertia,
directly caused the state's immediate recurrence.

648

THE RECURRENCE EQUATIONS
The recurrence learning equations stem in part from the weight alteration formula
used in the ASE system. The weight of a state is a sum of its previous weight, and the
product of the learning rate (a), the reward (r), and the state's eligibility (e).

ret)

E

{-I,O}

(3)

The eligibility index e/t) is an exponentially decaying trace function.

(4)
where O<=P<=I, Xi

E

{0,1}, and Yi

E

{-I,I}. The output value Yi is the last output

decision, and P determines the decay rate.
The reward function is:

ret)

=

?

{ -1

when the system fails at time t }
otherwise

(5)

REINFORCEMENT OF CYCLES
Equations (1) through (5) describe the basic ASE system. Our algorithm extends
the weight updating procedure as follows:

(6)
The term ar(t)ei(t) is the same as in (3), providing failure reinforcement. The
term a2r2(t)e2,i(t) provides reinforcement for success. When state i is eligible (by
virtue of Xi > 0), there is a weight change by the amount: CXz multiplied by the reward
value, r2(t), and the current eligibility e2,i(t). For simplicity, the reward value, r2(t),
may be taken to be some positive constant, although it need not be; any environmental
feedback, yielding a reinforcement value as a function of time could be used instead.
The second eligibility function e2,i(t) yields one of three constant values for HI: -P2' 0,
or P2 according to formula (7) below:
if t-ti,last = 1 or ti,last =
otherwise

?}

?

(7)

?

where ti,last is the last time that state was active. If a state has not previously been
active (i.e. xi(t) = for all t) then ti,last=O. As the formula shows, e2,i(t) = if the state
has not been previously visited or if no state transition occurred in the last time step;
otherwise, e2,i(t) = P2Xj(t)y(ti,last)?
The direction (increase or decrease) of the weight change due
(6) is that of the last action taken, y(ti,last).

to

the final term in

649

Heuristic HI is called constant recurrence learning because the eligibility function
is designed to reinforce any cycle.
HEURISTIC H2: Reward a short cycle more than a longer one.

Heuristic 82 is called short recurrence learning because the eligibility function is
designed to reinforce shorter cycle more than longer cycles.

REINFORCEMENT OF SHORTER CYCLES
The basis of the second heuristic is the conjecture that short cycles converge more
easily to absorbing points than long ones, and that long cycles diverge more easily than
shorter ones, although any cycle can ""grow"" or diverge to a larger cycle. The
following extension to the our basic heuristic is proposed.
The formula for the recurrence eligibility function is:

o
e2,i(t)

{

=

if t-ti,last = 1 or li,last

P2
xi(t) y(ti,last) otherwise
(P2+t - ti,last)

=0 }
(8)

The current eligibility function e2/t) is similar to the previous failure eligibility
function in (7); however, e2 i(t) reinforces shorter cycles more, because the eligibility
decays with time. The value'returned from e2it) is inversely proportional to the period
of the cycle from ti,last to t. H2 reinforces converging oscillations; the term
(X.2r2(t)e2/t) in (6) ensures weight reinforcement for returning to an already visited
state.

Figure 3a and 3b: The Constant Recurrence algorithm and Short Recurrence
algorithms
Figure 3A shows the Constant Recurrence algorithm (HI). A state is rewarded
when it is reactivated by a transition from another state. In the example below. state A
is reward by a constant regardless of weather the cycle traversed states B or C. Figure
3b describes the Short Recurrence algorithm (m). A state is rewarded according to the
difference between the current time and its last activation time. Small differences are
rewarded more than large differences In the example below, state A is rewarded more

650

when the cycle (through state C) traverses the states shown by the dark heavy line
rather than when the cycle (through state B) traverses the lighter line, since state A
recurs sooner when traversing the darker line.
SIMULATION RESULTS

We simulated four algorithms: ASE, ASE/ACE and the two recurrence
algorithms. Each experiment consisted of ten runs of the cart-pole balancing task, each
consisting of 100 trials. Each trial lasted for 500,000 time steps or until the cart-pole
system failed (i.e. the pole fell or the cart went beyond the track boundaries). In an
effort to conserve cpu time, simulations were also terminated when the system achieved
two consecutive trials each lasting for over 500,000 time steps; all remaining trials were
assumed to also last 500,000 time steps. This assumption was reasonable: the resulting
weight space causes the controller to become deterministic regardless of the influence of
stochastic noise. Because of the long time require to run simulations, no attempts were
made to optimize parameters of the algorithm.
As in Bart0 2, each trial began with the cart centered, and the pole upright. No
assumptions were made as to the state space configuration, the desirability of the initial
states, or the continuity of the state space.
The first experiment consisted of failure and recurrence reward learning. The
ASE failure learning runs averaged 1578 time steps until failure after 100 trials*. Next,
the predictive ASE/ACE system was run as a comparative metric, and it was found that
this method caused the controller to average 131,297 time steps until failure; the results
are comparable to that described by Barto, Sutton and Anderson.
In the next experiment, short recurrence learning system was added to the ASE
system. Again, ten 100 trial learning session were executed. On the average, the short
recurrence learning algorithm ran for over 400,736 time steps after 100th trial, bettering
the ASE/ACE system by 205%.
In the final experiment, constant recurrence learning with the ASE system was
simulated. The constant recurrence learning eliminated failure after only 207,562 time
steps.
Figure 1 shows the ASE, ASE/ACE, Constant recurrence learning (HI) and
Short recurrence learning (H2) failure rates averaged over 10 simulation runs.
DISCUSSION

Detection of cycles provides a heuristic for the ""two armed bandit"" problem to
decide between evidence gathering, and goal directed search. The algorithm allows the
automaton to search outward from the cycle states (states with high probability of
revisitation) to the more unexplored search space. The rate of exploration is
proportional to the recurrence learning parameter~; as ~ is decreased, the influence
of the cycles governing the decision process also decreases and the algorithm explores
more of the search space that is not part of any cycle or oscillation path.

* However,

there was a relatively large degree of variance in the final trials. The last
10 trails (averaged over each of the 10 simulations) ranged from 607 to 15,459 time
steps until failure

651

THEFUfURE
Our future experiments will study the effects of rewarding predictions of cycle
lengths in a manner similar to the prediction of failure used by the ASE/ACE system.
The effort will be to minimize the differences of predicted time of cycles in order to
predict their period. Results of this experiment will be shown in future reports. We
hope to show that this recurrence prediction system is generally superior to either the
ASE/ACE predictive system or the short recurrence system operating alone.

CONCLUSION
This paper presented an extension to the failure driven learning algorithm based
on reinforcing decisions that cause an automaton to enter environmental states more
than once. The controller learns to synthesize the best values by reinforcing areas of
the search space that produce recurring state visitation. Cycle states, which under
normal failure driven learning algorithms do not learn, achieve weight alteration from
success. Simulations show that recurrence reward algorithms show improved overall
learning of the cart-pole task with a substantial decrease in learning time.

REFERENCES
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.

D. Michie and R. Chambers, Machine Intelligence, E. Dale and D. Michie, Ed.:
(Oliver and Boyd, Edinburgh, 1968), p. 137.
A. Barto, R. Sutton, and C. Anderson, Coins Tech. Rept., No. 82-20, 1982.
B. Widrow and F. Smith, in Computer and Information Sciences, 1. Tou and
R. Wilcox Eds., (Clever Hume Press, 1964).
M. Minsky, in Proc. IRE, 49, 8, (1961) .
J. Holland, in Proc. Int. Conj., Genetic Algs. and their Appl., 1985, p. 1.
A. Samuel, IBM Journ. Res.and Dev. 3, 211, (1959)
M. Connell and P. Utgoff, in Proc. AAAl-87 (Seattle, 1987), p. 456.
C. Anderson, Coins Tech . Rept., No. 86-50: Amherst, MA. 1986.
R. Barnhill, in Mathematical Software I II, (Academic Press, 1977).
L. Schumaker, in Approximation Theory II. (Academic Press, 1976).
A. H. Klopf, in IEEE Int. Conf. Neural Networks"" June 1987.
R. Sutton, GTE Tech. Rept.TR87-509.1, GTE Labs. Inc., Jan. 1987
R. Sutton and A. G. Barto, Tech . Rept. TR87-5902.2 March 1987
A. Barto and P. Anandan, IEEE Trans. SMC 15, 360 (1985).
M. Sato, K. Abe, and H. Takeda, IEEE Trans .SMC 14,528 (1984).

"
34,1987,"A Computer Simulation of Olfactory Cortex with Functional Implications for Storage and Retrieval of Olfactory Information","",34-a-computer-simulation-of-olfactory-cortex-with-functional-implications-for-storage-and-retrieval-of-olfactory-information.pdf,"Abstract Missing","114

A Computer Simulation of Olfactory Cortex With Functional Implications for
Storage and Retrieval of Olfactory Information
Matthew A. Wilson and James M. Bower
Computation and Neural Systems Program
Division of Biology, California Institute of Technology, Pasadena, CA 91125
ABSTRACT
Based on anatomical and physiological data, we have developed a computer simulation of piriform (olfactory) cortex which is capable of reproducing spatial and temporal patterns of actual
cortical activity under a variety of conditions. Using a simple Hebb-type learning rule in conjunction with the cortical dynamics which emerge from the anatomical and physiological organization of the model, the simulations are capable of establishing cortical representations for different input patterns. The basis of these representations lies in the interaction of sparsely distributed, highly divergent/convergent interconnections between modeled neurons. We have shown that
different representations can be stored with minimal interference. and that following learning
these representations are resistant to input degradation, allowing reconstruction of a representation following only a partial presentation of an original training stimulus. Further, we have
demonstrated that the degree of overlap of cortical representations for different stimuli can
also be modulated. For instance similar input patterns can be induced to generate distinct cortical
representations (discrimination). while dissimilar inputs can be induced to generate overlapping
representations (accommodation). Both features are presumably important in classifying olfactory stimuli.

INTRODUCTION
Piriform cortex is a primary olfactory cerebral cortical structure which receives
second order input from the olfactory receptors via the olfactory bulb (Fig. 1). It
is believed to play a significant role in the classification and storage of olfactory
information 1?2?3 . For several years we have been using computer simulations as a
tool for studying information processing within this cortex4?5. While we are ultimately interested in higher order functional questions, our fITst modeling objective
was to construct a computer simulation which contained sufficient neurobiological
detail to reproduce experimentally obtained cortical activity patterns. We believe
this first step is crucial both to establish correspondences between the model and
the cortex, and to assure that the model is capable of generating output that can
be compared to data from actual physiological experiments. In the current case,
having demonstrated that the behavior of the simulation at least approximates
that of the actual cortex4 (Fig. 3), we are now using the model to explore the
types of processing which could be carried out by this cortical structure. In particular, in this paper we will describe the ability of the simulated cortex to store and
recall cortical activity patterns generated by stimulus various conditions. We
believe this approach can be used to provide experimentally testable hypotheses
concerning the functional organization of this cortex which would have been difficult to deduce solely from neurophysiological or neuroanatomical data.
@ American Institute of Physics 1988

115

Olfactory
Receptors

l

Higher Cortical Areas 1'- Hippocampus

1

Piriform Cortex
Olfactory I+and Other
Bulb
Olfactory Structures

Entorhinal
Cortex

T
LOT
Fig. 1. Simplified block diagram of the olfactory system and closely related sbUctures.

MODEL DESCRIPTION

This model is largely instructed by the neurobiology of piriform cortex3. Axonal conduction velocities, time delays, and the general properties of neuronal integration and the major intrinsic neuronal connections approximate those currently
described in the actual cortex. However, the simulation reduces both the number
and complexity of the simulated neurons (see below). As additional infonnation
concerning the these or other important features of the cortex is obtained it will be
incorporated in the model. Bracketed numbers in the text refer to the relevent
mathematical expressions found in the appendix.
Neurons. The model contains three distinct populations of intrinsic cortical
neurons, and a fourth set of cells which simulate cortical input from the olfactory
bulb (Fig. 2). The intrinsic neurons consist of an excitatory population of pyramidal neurons (which are the principle neuronal type in this cortex), and two populations of inhibitory interneurons. In these simulations each population is modeled
as 100 neurons arranged in a 10x10 array (the actual piriform cortex of the rat
contains on the order of 106 neurons). The output of each modeled cell type consists of an all-or-none action potential which is generated when the membrane
potential of the cell crosses a threshold [2.3]. This output reaches other neurons
after a delay which is a function of the velocity of the fiber which connects them
and the cortical distance from the originating neuron to each target neuron [2.0,
2.4]. When an action potential arrives at a destination cell it triggers a conductance change in a particular ionic channel type in that cell which has a characteristic time course, amplitude, and waveform [2.0, 2.1]. The effect of this conductance
change on the transmembrane potential is to drive it towards the equilibrium
potential of that channel. Na+, CI-, and K+ channels are included in the model.
These channels are differentially activated by activity in synapses associated with
different cell types (see below).

116

LOT Afferent Fiber

r

Ceudelly Directed
A. .oelatlOn Fiber

Locel
....oclellon
Flbe,
locel FMdbeck InhlblUon
Roatrelly Directed

Caudally DlrectecI

..._llIlon Fiber

Aasoclllion Fiber

Fig. 2. Schematic diagram of piriform cortex showing an excitatory pyramidal cell and two
inhibitory intemeurons with their local interactions. Circles indicate sites of synaptic modifiability.

Connection Patterns. In the olfactory system, olfactory receptors project to the
olfactory bulb which, in turn, projects directly to the pirifonn cortex and other olfactory structures (Fig. 1). The input to the pirifonn cortex from the olfactory bulb is
delivered via a fiber bundle known as the lateral olfactory tract (LOT). This fiber
tract appears to make sparse, non-topographic, excitatory connections with pyramidal and feedforward inhibitory neurons across the extent of the cortex3,6. In the
model this input is simulated as 100 independent cells each of which make random connections (p=O.05) with pyramidal and feedforward inhibitory neurons
(Fig. 1 and 2).
In addition to the input connections from the olfactory bulb, there is also an
extensive set of connections between the neurons intrinsic to the cortex (Fig. 2).
For example, the association fiber system arises from pyramidal cells and makes
sparse, distributed excitatory connections with other pyramidal cells all across the
cortex7,8.9 ? In the model these connections are randomly distributed with 0.05
probability. In the model and in the actual cortex, pyramidal cells also make excitatory connections with nearby feedforward and feedback inhibitory cells. These
intemeurons, in turn, make reciprocal inhibitory connections with the group of
nearby pyramidal cells. The primary effect of the feedback inhibitory neurons is to
inhibit pyramidal cell firing through a CI- mediated current shunting mechanism lO?ll ?12. Feedforward intemeurons inhibit pyramidal cells via a long latency,
long duration, K+ mediated hyperpolarizing potential 12,13. Pyramidal cell axons
also constitute the primary output of both the model and the actual pirifonn cortex 7?14?

117

Synaptic Properties and Modification Rules. In the model, each synaptic connection has an associated weight which determines the peak amplitude of the conductance change induced in the postsynaptic cell following presynaptic activity
[2.0]. To study learning in the model, synaptic weights associated with some of
the fiber systems are modifiable in an activity-dependent fashion (Fig. 2). The
basic modification rule in each case is Hebb-like; i.e. change in synaptic strength
is proportional to presynaptic activity multiplied by the offset of the postsynaptic
membrane potential from a baseline potential. This baseline potential is set
slightly more positive than the CI- equilibrium potential associated with the shunting feedback inhibition. This means that synapses activated while a destination
cell is in a depolarized or excited state are strengthened, while those activated
during a period of inhibition are weakened. In the model, synapses which follow
this rule include the association fiber connections between excitatory pyramidal
neurons as well as the connections between inhibitory neurons and pyramidal neurons. Whether these synapses are modifiable in this way in the actual cortex is a
subject of active research in our lab. However, the model does mimic the actual
synaptic properties associated with the input pathway (LOT) which we have
shown to undergo a transient increase in synaptic strength following activation
which is independent of postsynaptic potential 15. This increase is not pennanent
and the synaptic strength subsequently returns to its baseline value.
Generation of Physiological Responses. Neurons in the model are represented
as fIrst-order ""leaky"" integrators with multiple, time-varying inputs [1.0]. During
simulation runs, membrane potentials and currents as well as the time of
occurence of action potentials are stored for comparison with actual data. An
explicit compartmental model (5 compartments) of the pyramidal cells is used to
generate the spatial current distributions used for calculation of field potentials
(evoked potentials, EEGs) [3.0,4.0].
Stimulus Characteristics. To compare the responses of the model to those of
the actual cortex, we mimicked actual experimental stimulation protocols in the
simulated cortex and contrasted the resulting intracellular and extracellular
records. For example, shock stimuli applied to the LOT are often used to elicit
characteristic cortical evoked potentials in vivo 16,17,18. In the model we simulated
this stimulus paradigm by simultaneously activating all 100 input fibers. Another
measure of cortical activity used most successfully by Freeman and colleagues
involves recording EEG activity from pirifonn cortex in behaving animals 19,20.
These odor-like responses were generated in the model through steady, random
stimulation of the input fibers.
To study learning in the model, once physiological measures were established,
it was required that we use more refined stimulation procedures. In the absence of
any specific infonnation about actual input activity patterns along the LOT, we
constructed each stimulus out of a randomly selected set of 10 out of the 100 input

118

fibers. Each stimulus episode consisted of a burst of activity in this subset of
fibers with a duration of 10 msec at 25 msec intervals to simulate the 40 Hz periodicity of the actual olfactory bulb input. This pattern of activity was repeated in
trials of 200 msec duration which roughly corresponds to the theta rhythm periodicity of bulbar activity and respiration 21 ?22 . Each trial was then presented 5 times
for a total exposure time of 1 second (cortical time). During this period the Hebbtype learning rule could be used to modify the connection weights in an activitydependent fashion.

Output Measure for Learning. Given that the sole output of the cortex is in the
fonn of action potentials generated by the pyramidal cells, the output measure of
the model was taken to be the vector of spike frequency for all pyramidal neurons
over a 200 msec trial, with each element of the vector corresponding to the firing
frequency of a single pyramidal cell. Figures 5 through 8 show the 10 by 10 array
of pyramidal cells. The size of the box placed at each cell position represents the
magnitude of the spike frequency for that cell. To evaluate learning effects, overlap
comparisons between response pairs were made by taking the nonnalized dot
product of their response vectors and expressing that value as a percent overlap
(Fig. 4).

Simulated

~\~f"".-.-

lj
Fig. 3. Simulated physiological responses of the model compared with actual cortical responses. Upper: Simulated intracellular response of a single cell to paired stimulation of the input
system (LOn (left) compared with actual response (right) (Haberly & Bower: 84). Middle:
Simulated extracellular response recorded at the cortical surface to stimulation of the LOT
(left), compared with actual response (right) (Haberly:73b). Lower: Stimulated EEG
response recorted at the cortical surface to odor-like input (left), for actual EEG see Freeman
1978.

119

Computational Requirements. All simulations were carried out on a Sun
Microsystems 3/260 model microcomputer equipped with 8 Mbytes of memory and
a floating point accelerator. Average time for a 200 msec simulation was 3 cpu
minutes.
RESULTS
Physiological Responses
As described above, our initial modeling objective was to accurately simulate
a wide range of activity patterns recorded, by ourselves and others, in piriform
cortex using various physiological procedures. Comparisons between actual and
simulated records for several types of response are shown in figure 3. In general,
the model replicated known physiological responses quite well (Wilson et al in
preparation describes, in detail, the analysis of the physiological reSUlts). For
example in response to shock stimulation of the input pathway (LOT), the model
reproduces the principle characteristics of both the intracellular and locationdependent extracellular waveforms recorded in the actual cortex9,17,18 (Fig. 3).
100
Percent Overlap
with
Final Response
Pattern
60 0
Number of Trials

5

Fig. 4. Convergence of the cortical response during training with a single stimulus with synaptic
modification.

56% overlap

? ????? ??? ?? ? ? ?? ? ??
? ? ?? ? ? ? ? ?
? ??? ?? ? ??
?
? ? ???
?
?
?? ? ?? ? ? ? ? ? ?
Full Stimulus
50% Simulus
Before Training

80% overlap

??
??
? ????
?
?
?? ?? ? ? ??
??? ?? ?? ?? ?? ??
?? ? ?? ? ?
Full Stimulus
50% Simulus
After Training

Fig. S. Reconstruction of cortical response patterns with partially degraded stimuli. Left:
Response, before training, to the full stimulus (left) and to the same stimulus with 50% of the
input fibers inactivated (right). There is a 44% degradation in the response. Right: Response
after ttaining, to the full stimulus (left), and to the same stimulus with 50% of the input
fibers inactivated (right). As a result of ttaining, the degradation is now only 20%.

120

Trained on A

?? ?? ??
?
?????
? ??
?? ??? ?

Trained on B

?

?

? ?
?
???
?
?
?
?
? ??? ? ?

Retains A Response

?? ???
? ?? ?
?
? ??? ?
?? ?? ?

Fig. 6. Storage of multiple patterns. Left Response to stimulus A afler training. Middle:
Response to stimulus B afler training on A followed by training on B. Right: Response to
stimulus A after training on A followed by training on B. When compared with the original
response (left) there is an 85% congruence.

Further, in response to odor-like stimulation the model exhibits 40 Hz oscillations
which are characteristic of the EEG activity in olfactory cortex in awake, behaving
animals 19. Although beyond the scope of the present paper, the simulation also
duplicates epileptiform9 and damped oscillatory16 type activity seen in the cortex
under special stimulus or pharmacological conditions4 .
Learning
Having simulated characteristic physiological responses, we wished to
explore the capabilities of the model to store and recall information. Learning in
this case is defined as the development of a consistent representation in the activity of the cortex for a particular input pattern with repeated stimulation and synaptic modification. Figure 4 shows how the network converges, with training, on a
representation for a stimulus. Having demonstrated that, we studied three properties of learned responses - the reconstruction of trained cortical response patterns
with partially degraded stimuli, the simultaneous storage of separate stimulus
response patterns, and the modulation of cortical response patterns independent
of relative stimulus characteristics.
Reconstruction of Learned Cortical Response Patterns ""with Partially Degraded Stimuli. We were interested in knowing what effect training would have on the
sensitivity of cortical responses to fluctuations in the input signal. First we presented the model with a random stimulus A for one trial (without synaptic modification). On the next trial the model was presented with a degraded version of A
in which half of the original 10 input fibers were inactivated. Comparison of the
responses to these two stimuli in the naive cortex showed a 44% variation. Next,
the model was trained on the full stimulus A for 1 second (with synaptic modification). Again, half of the input was removed and the model was presented with the
degraded stimulus for 1 trial (without synaptic modification). In this case the dif-

121

27% overlap

? ?
? ?? ?
? ?

?? ?
?

??

46% overlap

?

? ?? ?

Stimulus A
Stimulus B
Before Training

? ?
?? ???? ?
?
? ? ??

?

????

?? ? ??
?

Stimulus A
Stimulus B
After Training

Fig. 7. Results of merging cortical response patterns for dissimilar
stimulus A and stimulus B before training. Stimuli A and B do not
common but still have a 27% overlap in cortical response patterns.
lus A and stimulus B after training in the presence of a common
overlap in cortical response patterns is now 46%.

stimuli. Left: Response to
activate any input fibers in
Right: Response to stimumodulatory input E 1. The

ference between cortical responses was only 20% (Fig. 5) showing that training
increased the robustness of the response to degradation of the stimulus.
Storage of Two Patterns. The model was frrst trained on a random stimulus A
for 1 second. The response vector for this case was saved. Then, continuing with
the weights obtained during this training, the model was trained on a new nonoverlapping (Le. different input fibers activated) stimulus B. Both stimulus A and
stimulus B alone activated roughly 25% of the cortical pyramidal neurons with 25%
overlap between the two responses. Following the second training period we
assessed the amount of interference in recalling A introduced by training with B
by presenting stimulus A again for a single trial (without synaptic modification).
The variation between the response to A following additional training with B and
the initially saved reponse to A alone was less than 15% (Fig. 6) demonstrating
that learning B did not substantially interfere with the ability to recall A.
Modulation of Cortical Response Patterns.
It has been previously demonstrated that the stimulus evoked response of olfactory cortex can be modulated by
factors not directly tied to stimulus qualities, such as the behavioral state of the
animal 1,20,23. Accordingly we were interested in knowing whether the representations stored in the model could be modulated by the influence of such a ""state""
input.
One potential role of a ""state"" input might be to merge the cortical response
patterns for dissimilar stimuli; an effect we refer to as accomodation. To test this
in the model, we presented it with a random input stimulus A for 1 trial. It was
then presented with a random input stimulus B (non-overlapping input fibers).
The amount of overlap in the cortical responses for these untrained cases was
27%. Next, the model was trained for 1 second on stimulus A in the presence of an
additional random ""state"" stimulus El (activity in a set of 10 input fibers distinct

122

77% overlap

45% overlap

~----------~

r--~------~

?
??
??
?
?
?
?
?
???
?? ?
?
?
? ?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?

?

?

?? ? ?

?

?

? ?? ??

Stimulus A
Stimulus B
Before Training

?

??

? ? ???

? ? ??

?
?
?

?
?

?

??

??

?

Stimulus A
Stimulus B
After Training

Fig. 8. Results of differentiating cortical response patterns for similar stimuli. Left:
Response to stimulus A and stimulus B before training. Stimuli A and B activate 75% of
their input fibers in common and have a 77% overlap in cortical response patterns. Right:
Respon~ to stimulus A and stimulus B after training A in the presence of modulatory input
El and training B with a different modulatory input E2. The overlap in cortical response patterns is now 45%.

from both A and B). The model was then trained on stimulus B in the presence of
the same ""state"" stimulus El. After training, the model was presented with stimulus A alone for 1 trial and stimulus B alone for 1 trial. Results showed that now.
even without the coincident E 1 input, the amount of overlap between A and B
responses was found to have increased to 46% (Fig 7). The role of El in this case
was to provide a common stimulus component during learning which reinforced
shared components of the responses to input stimuli A and B.
To test the ability of a state stimulus to induce differentiation of cortical
response patterns for similar stimuli, we presented the model with a random input
stimulus A for 1 trial, followed by 1 trial of a random input stimulus B (75% of the
input fibers overlapping), The amount of overlap in the cortical responses for these
untrained cases was 77%. Next, the model was trained for a period of 1 second on
stimulus A in the presence of an additional random ""state"" stimulus El (a set of
10 input fibers not overlapping either A or B). It was then trained on input stimulus B in the presence of a different random ""state"" stimulus E2 (10 input fibers not
overlapping either A, B, or El) After this training the model was presented with
stimulus A alone for 1 trial and stimulus B alone for 1 trial. The amount of overlap
was found to have decreased to 45% (Fig 8). In this situation EI and E2 provided
a differential signal during learning which reinforced distinct components of the
responses to input stimuli A and B.
DISCUSSION
PhYSiological Responses. Detailed discussion of the mechanisms underlying
the simulated patterns of physiological activity in the cortex is beyond the scope
of the current paper. However, the model has been of value in suggesting roles for

123

specific features of the cortex in generating physiologically recorded activity. For
example, while actual input to the cortex from the olfactory bulb is modulated into
40 Hz bursts24 , continuous stimulation of the model allowed us to demonstrate
the model's capability for intrinsic periodic activity independent of the complementary pattern of stimulation from the olfactory bulb. While a similar ability has
also been demonstrated by models of Freeman25 , by studying this oscillating
property in the model we were able to associate these oscillatory characteristics
with specific interactions of local and distant network properties (e.g. inhibitory
and excitatory time constants and trans-cortical axonal conduction velocities).
This result suggests underlying mechanisms for these oscillatory patterns which
may be somewhat different than those previously proposed.
Learning. The main subject of this paper is the examination of the learning
capabilities of the cortical model. In this model, the apparently sparse, highly distributed pattern of connectivity characteristic of piriform cortex is fundamental to
the way in which the model learns. Essentially, the highly distributed pattern of
connections allows the model to develop stimulus-specific cortical response patterns by extracting correlations from randomly distributed input and association
fiber activity. These correlations are, in effect, stored in the synaptic weights of
the association fiber and local inhibitory connections.
The model has also demonstrated robustness of a learned cortical response
against degradation of the input signal. A key to this property is the action of
sparsely distributed association fibers which provide reinforcment for previously
established patterns of cortical activity. This property arises from the modification
of synaptic weights due to correlations in activity between intra-cortical association fibers. As a result of this modification the activity of a subset of pyramidal
neurons driven by a degraded input drives the remaining neurons in the response.
In general, in the model, similar stimuli will map onto similar cortical responses and dissimilar stimuli will map onto dissimilar cortical responses. However, a
presumably important function of the cortex is not simply to store sensory information, but to represent incoming stimuli as a function of the absolute stimulus
qualities and the context in which the stimulus occurs. The fact that many of the
structures that piriform cortex projects to (and receives projections from) may be
involved in multimodal ""state"" generation14 is circumstantial evidence that such
modulation may occur. We have demonstrated in the model that such a modulatory input can modify the representations generated by pairs of stimuli so as to
push the representations of like stimuli apart and pull the representations of dissimilar stimuli together. It should be pointed out that this modulatory input was
not an ""instructive"" signal which explicitly directed the course of the representation, but rather a ""state"" signal which did not require a priori knowledge of the
representational structure. In the model, this modulatory phenomenon is a simple
consequence of the degree of overlap in the combined (odor stimulus + modulator)
stimulus. Both cases approached approximately 50% overlap in cortical responses
reflecting the approximately 50% overlap in the combined stimuli for both cases.

124

Of interest was the use of the model's reconstructive capabilities to maintain the
modulated response to each input stimulus even in the absence of the modulatory
input.
CA YEATS AND CONCLUSIONS
Our approach to studying this system involves using computer simulation to
investigate mechanisms of information processing which could be implemented
given what is known about biological constraints. The significance of results presented here lies primarily in the finding that the structure of the model and the
parameter settings which were appropriate for the reproduction of physiological
responses were also appropriate for the proper convergence of a simple, biologically plausible learning rule under various conditions. Of course, the model we
have developed is only an approximation to the actual cortex limited by our knowledge of its organization and the computing power available. For example, the
actual piriform cortex of the rat contains on the order of 106 cells (compared with
1()2 in the simulations) with a sparsity of connection on the order of p=O.OOI
(compared with p=0.05 in the simulations). Our continuing research effort will
include explorations of the scaling properties of the network.
Other assumptions made in the context of the current model include the
assumption that the representation of information in piriform cortex is in the form
of spatial distributions of rate-coded outputs. Information contained in the spatiotemporal patterns of activity was not analyzed, although preliminary observation
suggests that this may be of significance. In fact, the dynamics of the model itself
suggest that temporally encoded information in the input at various time scales
may be resolvable by the cortex. Additionally, the output of the cortex was
assumed to have spatial uniformity, Le. no differential weighting of information
was made on the basis of spatial location in the cortex. But again, observation of
the dynamics of the model, as well as the details of known anatomical distribution
patterns for axonal ?connections, indicate that this is a major oversimplification.
Preliminary evidence from the model would indicate that some form of hierarchical
structuring of information along rostraVcaudal lines may occur. For example it
may be that cells found in progressively more rostral locations would have
increasingly non-specific odor responses.
Further investigations of learning within the model will explore each of these
issues more fully, with attempts to correlate simulated findings with actual recordings from awake, behaving animals. At the same time, new data pertaining to the
structure of the cortex will be incorporated into the model as it emerges.
ACKNOWLEDGEMENTS
We wish to thank Dr. Lewis Haberly and Dr. Joshua Chover for their roles in
the development and continued support of the modeling effort. We also wish to
thank Dave Bilitch for his technical assistance. This work was supported by NIH
grant NS22205, NSF grant EET-8700064, the Lockheed Corporation, and a fellowship from the ARCS foundation.

125

APPENDIX
E,-V, (r) ]
-dV, = - 1 ["",1: lik(r) + - - dl

c'"" i=1

(1.0)

r,

SOl1UJric Inregrarion
(1.1)

n

l'u ..

=

number of input types

resting potential
r, ==membrane
leakage resistance

E,

V.(t) membrane potential of i th cell
lit (t ) .. current into cell i due to input type Ie
E t - equilibrium potential associated with input type Ie

c... = membrane capacitance
goJ:(t) .. conductance due to input type Ie in cell i

(2.0)

Spilce Propagation
and SynaptiC l""Pur

Aiji = (l-p:"","")e -L., P. +

P:""'''

(2.2)

V) (r?T) , S)O..)=O for

A.=t .. r-ru,
(2.3)

otherwise

L'j = Ii - j

I~

nc61ls .. number of cells in the simulation
~ .. distance between adjacent cells

di = duration of conductance change due to input type Ie
Vi '"" velocity of signals for input type Ie
Et = latency for input type Ie
Pt = spatial anenuation factor for input type Ie
P:""''' .. minimum spatial anenuation for input type Ie
ru, = refractory period

(2.4)

= threshold for cell j
distance from cell i to cell j
~')t = distribution of synaptic density for input type Ie
w'} = synaptic weight from cell j to cell i
goJ: (t) = conductance due to input type Ie in cell i
Ft (t) = conductance waveform for input type k
~J (I) = spike output of cell j at time t
U (t) = unit step function
T)

L,)

OK

(3.0)

Field Poren/ials

nc61ls

=number of cells in the simulation

nugs = number of segments in the companmental model
V (r) .. approximate extracellular field potential at cell j
I ... (r) membrane current for segment n in cell i

k

=

Zr/ec
1""

=depth of recording site

= depth of segment n

x .. x location of the jth cell
= extracellular resistance per unit length

R.

(4.0)

Dendriric Model
(4.1)

126

(4.2)

nc"""",,, = number of different channels per segment
V"" (r) membrane potential of nth segment
= membrane capacitance for segment n

c,:

=

r; = axial resistance for segment n
r:' - membrane resistance for segment n

=membrane current for segment n

/"" = length of segment n
d"" = diameter of segment n

R"". = membrane resistivity
Rj

BPI< (r) = conductance of channel c in segment n
Ec = equilibrium potential associated with channel c
I:%(r) axial current between segment nil and n

=

l:'(r)

R.

e"",

= intracellular resistiviry per unit length

=extracellular resistance per unit length
=capacitance per unit surface area

REFERENCES
1.
2.
3.
4.

W. J. Freeman, J. Neurophysiol., 23, 111 (1960).
T. Tanabe, M. lino, and S. F. Takagi, J. Neurophysiol., 38,1284 (1975).
L. B. Haberly, Chemical Senses, 10,219 (1985).
M. Wilson, J. M. Bower, J. Chover, and L. B. Haberly, Soc. Neuro. Abs., 11,
317 (1986).
5. M. Wilson and J. M. Bower, Soc. Neurosci. Abs., 12, 310 (1987).
6. M. Devor, J. Compo Neur., 166,31 (1976).
7. L. B. Haberly and 1. L. Price, J. Compo Neurol., 178, 711 (1978a).
8. L. B. Haberly and S. Presto, J. Compo Neur., 248, 464 (1986).
9. L. B. Haberly andJ. M. Bower, J. Neurophysiol., 51, 90 (1984).
10. M. A. Biedenbach and C. F. Stevens, J. Neurophysiol., 32, 193 (1969).
11. M. A. Biedenbach and C. F. Stevens, J. Neurophysiol., 32, 204 (1969).
12. M. Satou, K. Mori, Y. Tazawa, and S. F. Takagi, J. Neurophysiol., 48, 1157
(1982).
13. O. F. Tseng and L. B. Haberly, Soc. Neurosci. Abs. 12,667 (1986).
14. L. B. Luskin and J. L. Price, J. Compo Neur., 216, 264 (1983).
15. J. M. Bower and L. B. Haberly,L.B., Proc. Natl. Acad. Sci. USA, 83, 1115
(1985).
16. W. J. Freeman, J. Neurophysiol., 31, 1 (1968).
17. L. B. Haberly, J. Neurophysiol., 36, 762 (1973).
18. L. B. Haberly, J. Neurophysiol., 36, 775 (1973).
19. W. J. Freeman, Electroenceph. and Clin. Neurophysiol., 44, 586 (1978).
20. W.J. Freeman and W. Schneider, Psychophysiology, 19,44 (1982).
21. F. Macrides and S. L. Chorover, Science, 175,84 (1972).
22. F. Macrides, H. B. Eigenbaum, and W. B. Forbes, J. Neurosci., 2, 12, 1705
(1982).
23. P. D. MacLean, N. H. Horwitz, and F. Robinson, Yale J. BioI. Med., 25, 159
(1952).
24. E. D. Adrian, Electroenceph. and Clin. Neurophysiol., 2, 377 (1950).
25. W. J. Freeman, Exp. Neuro!., 10, 525 (1964).

"
35,1987,"Introduction to a System for Implementing Neural Net Connections on SIMD Architectures","",35-introduction-to-a-system-for-implementing-neural-net-connections-on-simd-architectures.pdf,"Abstract Missing","804

INTRODUCTION TO A SYSTEM FOR IMPLEMENTING NEURAL NET
CONNECTIONS ON SIMD ARCHITECTURES
Sherryl Tomboulian
Institute for Computer Applications in Science and Engineering
NASA Langley Research Center, Hampton VA 23665
ABSTRACT
Neural networks have attracted much interest recently, and using parallel
architectures to simulate neural networks is a natural and necessary application. The SIMD model of parallel computation is chosen, because systems of
this type can be built with large numbers of processing elements. However,
such systems are not naturally suited to generalized communication. A method
is proposed that allows an implementation of neural network connections on
massively parallel SIMD architectures. The key to this system is an algorithm
that allows the formation of arbitrary connections between the ""neurons"". A
feature is the ability to add new connections quickly. It also has error recovery ability and is robust over a variety of network topologies. Simulations of
the general connection system, and its implementation on the Connection Machine, indicate that the time and space requirements are proportional to the
product of the average number of connections per neuron and the diameter of
the interconnection network.
INTRODUCTION
Neural Networks hold great promise for biological research, artificial intelligence, and even as general computational devices. However, to study systems
in a realistic manner, it is highly desirable to be able to simulate a network
with tens of thousands or hundreds of thousands of neurons. This suggests the
use of parallel hardware. The most natural method of exploiting parallelism
would have each processor simulating a single neuron.
Consider the requirements of such a system. There should be a very large
number of processing elements which can work in parallel. The computation
that occurs at these elements is simple and based on local data. The processing
elements must be able to have connections to other elements. All connections
in the system must be able to be traversed in parallel. Connections must be
added and deleted dynamically.
Given current technology, the only type of parallel model that can be constructed with tens of thousands or hundreds of thousands of processors is an
SIMD architecture. In exchange for being able to build a system with so many
processors, there are some inherent limitations. SIMD stands for single instruction multiple datal which means that all processors can work in parallel, but
they must do exactly the same thing at the same time. This machine model
is sufficient for the computation required within a neuron, however in such a
system it is difficult to implement arbitrary connections between neurons. The
Connection Machine2 provides such a model, but uses a device called the router
This work was supported by the National Aeronautics and Space Administration under
NASA Constract No. NASl-18010-7 while the author was in residence at ICASE.

? American Institute of Physics 1988

805

to deliver messages. The router is a complex piece of hardware that uses significant chip area, and without the additional hardware for the router, a machine
could be built with significantly more processors. Since one of the objectives is
to maximize the number of ""neurons"" it is desirable to eliminate the extra cost
of a hardware router and instead use a software method.
Existing software algorithms for forming connections on SIMD machines
are not sufficient for the requirements of a neural networks. They restrict the
form of graph (neural network) that can be embedded to permutations!?? or
sorts5.6combinedwith7, the methods are network specific, and adding a new connection is highly time consuming.
The software routing method presented here is a unique algorithm which allows arbitrary neural networks to be embedded in machines with a wide variety
of network topologies. The advantages of such an approach are numerous: A
new connection can be added dynamically in the same amount of time that it
takes to perform a parallel traversal of all connections. The method has error
recovery ability in case of network failures. This method has relationships with
natural neural models. When a new connection is to be formed, the two neurons
being connected are activated, and then the system forms the connection without any knowledge of the ""address"" of the neuron-processors and without any
instruction as to the method of forming the connecting path. The connections
are entirely distributed; a processor only knows that connections pass through
it - it doesn't know a connection's origin or final destination.
Some neural network applications have been implemented on massively parallel architectures, but they have run into restrictions due to communication.
An implementation on the Connection Machines discovered that it was more
desirable to cluster processors in groups, and have each processor in a group
represent one connection, rather than having one processor per neuron, because
the router is designed to deliver one message at a time from each processor. This
approach is contrary with the more natural paradigm of having one processor
represent a neuron. The MPP 9, a massively parallel architecture with processors arranged in a mesh, has been used to implement neural nets10 , but because
of a lack of generalized communication software, the method for edge connections is a regular communication pattern with all neurons within a specified
distance. This is not an unreasonable approach, since within the brain neurons
are usually locally connected, but there is also a need for longer connections
between groups of neurons. The algorithms presented here can be used on
both machines to facilitate arbitrary connections with an irregular number of
connections at each processor.
MACHINE MODEL
As mentioned previously, since we desire to build a system with an large
number of processing elements, the only technology currently available for building such large systems is the SIMD architecture model. In the SIMD model
there is a single control unit and a very large number of slave processors that
can execute the same instruction stream simultaneously. It is possible to disable
some processors so that only some execute an instruction, but it is not possible
to have two processor performing different instructions at the same time. The
processors have exclusively local memory which is small (only a few thousand
bits), and they have no facilities for local indirect addressing. In this scheme
an Instruction involves both a particular operation code and the local memory

806

address. All processors must do this same thing to the same areas of their local
memory at the same time.
The basic model of computation is bit-serial - each instruction operates on
a bit at a time. To perform multiple bit operations, such as integer addition,
requires several instructions. This model is chosen because it requires less
hardware logic, and so would allow a machine to be built with a larger number
of processors than could otherwise be achieved with a standard word-oriented
approach. Of course, the algorithms presented here will also work for machines
with more complex instruction abilities; the machine model described satisfies
the minimal requirements.
An important requirement for connection formation is that the processors
are connected in some topology. For instance, the processors might be connected in a grid so that each processor has a North, South, East, and West
neighbor. The methods presented here work for a wide variety of network
topologies. The requirements are: (1) there must be some path between any
two proeessors; (2) every neighbor )ink must be bi-directional, i.e. if A is a
neighbor of B, then B must be a neighbor of A; (3) the neighbor relations
between processors must have a consistent invertible labeling. A more precise definition of the labeling requirements can be found in 11. It suffices that
most networks 12, including grid, hypercube, cube connected cycles 1S , shuffle
exchange14 , and mesh of trees15 are admissible under the scheme. Additional
requirements are that the processors be able to read from or write to their
neighbors' memories, and that at least one of the processors acts as a serial
port between the processors and the controller.
COMPUTATIONAL REQUIREMENTS
The machine model described here is sufficient for the computational requirements of a neuron. Adopt the paradigm that each processor represents one
neuron. While several different models of neural networks exist with slightly
different features, they are all fairly well characterized by computing a sum or
product of the neighbors values, and if a certain threshold is exceeded, then
the processor neuron will fire, Le. activate other neurons. The machine model
described here is more efficient at boolean computation, such as described by
McCulloch and Pitts16 , since it is bit serial. Neural net models using integers
and floating point arithmetic 17,18 will also work but will be somewhat slower
since the time for computation is proportional to the number of bits of the
operands.
The only computational difficulty lies in the fact that the system is SIMD,
which means that the processes are synchronous. For some neural net models
this is sufficient18 however others require asynchronous behavior 17. This can
easily be achieved simply by turning the processors on and off based on a specified probability distribution. (For a survey of some different neural networks
see 19).
CONNECTION ASSUMPTIONS
Many models of neural networks assume fully connected systems. This
model is considered unrealistic, and the method presented here will work better
for models that contain more sparsely connected systems. While the method
will work for dense connections, the time and space required is proportional to

807

the number of edges, and becomes prohibitively expensive.
Other than the sparse assumptions, there are no restrictions to the topological form of the network being simulated. For example, multiple layered
systems, slightly irregular structures, and completely random connections are
all handled easily. The system does function better if there is locality in the
neural network. These assumptions seem to fit the biological model of neurons.
THE CONNECTION FORMATION METHOD
A fundamental part of a neural network implementation is the realization of
the connections between neurons. This is done using a software scheme first presented in 11,20. The original method was intended for realizing directed graphs
in SIMD architectures. Since a neural network is a graph with the neurons
being vertices and the connections being arcs, the method maps perfectly to
this system. Henceforth the terms neuron and vertex and the terms arc and
connection will be used interchangeably.
The software system presented here for implementing the connections has
several parts. Each processor will be assigned exactly one neuron. (Of course
some processors may be ""free"" or unallocated, but even ""free"" processor participate in the routing process.) Each connection will be realized as a path
in the topology of processors. A labeling of these paths in time and space is
introduced which allows efficient routing algorithms and a set-up strategy is
introduced that allows new connections to be added quickly.
The standard computer science approach to forming the connection would
be to store the addresses of the processors to which a given neuron is connected.
Then, using a routing algorithm, messages could be passed to the processors
with the specified destination. However, the SIMD architecture does not lend
itself to standard message passing schemes because processors cannot do indirect addressing, so buffering of values is difficult and costly.
Instead, a scheme is introduced which is closer to the natural neuron-synapse
structures. Instead of having an address for each connection, the connection
is actually represented as a fixed path between the processors, using time as a
virtual dimension. The path a connection takes through the network of processors is statically encoded in the local memories of the neurons that it passes
through. To achieve this, the following data structures will be resident at each
processor.

ALLOCATED ---- boolean flag indicating
whether this processor is assigned
a vertex (neuron) in the graph
VERTEX LABEL --- label of graph vertex (neuron)
HAS_NEIGHBOR[l .. neighbor_limit] flag
indicating the existence of neighbors
SLOTS[l .. T] OF
arc path information
START----------new arc starts here
DIRECTION------direction to send
{l .. neighbor_limit.FREE}
END-----------arc ends here
ARC LABEL-----label of arc

808

The ALLOCATED and VERTEX LABEL field indicates that the processor
has been assigned a vertex in the graph (neuron). The HAS NEIGHBOR field
is used to indicate whether a physical wire exists in the particular direction; it
allows irregular network topologies and boundary conditions to be supported.
The SLOTS data structure is the key to realizing the connections. It is used
to instruct the processor where to send a message and to insure that paths are
constructed in such a way that no collisions will occur.
SLOTS is an array with T elements. The value T is called the time quantum.
Traversing all the edges of the embedded graph in parallel will take a certain
amount of time since messages must be passed along through a sequence of
neighboring processors. Forming these parallel connections will be considered
an uninterruptable operation which will take T steps. The SLOTS array is used
to tell the processors what they should do on each relative time position within
the time quantum.
One of the characteristics of this algorithm is that a fixed path is chosen to
represent the connection between two processors, and once chosen it is never
changed. For example, consider the grid below.
I

I

I

I

I

--A--B--C--D--E-I

I

I

I

I

--F--G--H--I--J-I

I

I

I

I

Fig. 1. Grid Example

If there is an arc between A and H, there are several possible paths: EastEast-South, East-South-East, and South-East-East. Only one of these paths
will be chosen between A and H, and that same path will always be used.
Besides being invariant in space, paths are also invariant in time. As stated
above, traversal is done within a time quantum T. Paths do no have to start
on time 1, but can be scheduled to start at some relative offset within the
time quantum. Once the starting time for the path has been fixed, it is never
changed. Another requirement is that a message can not be buffered, it must
proceed along the specified directions without interruption. For example, if
the path is of length 3 and it starts at time 1, then it will arrive at time
4. Alternatively, if it starts at time 2 it will arrive at time 5. Further, it is
necessary to place the paths so that no collisions occur; that is, no two paths
can be at the same processor at the same instant in time. Essentially time
adds an extra dimension to the topology of the network, and within this spacetime network all data paths must be non-conflicting. The rules for constructing
paths that fulfill these requirements are listed below .
? At most one connection can enter a processor at a given time, and at
most one connection can leave a processor at a given time. It is possible
to have both one coming and one going at the same time. Note that this
does not mean that a processor can have only one connection; it means
that it can have only one connection during anyone of the T time steps.
It can have as many as T connections going through it .

? Any path between two processors (u,v) repr('senting a connection must
consist of steps at contiguous times. For example, if the path from processor u to processor v is u,f,g,h,v, then if the arc from u-f is assigned
time 1, f-g must have time 2, g-h time 3, and h-v time 4. Likewise if u-f
occurs at time 5, then arc h-v will occur time 8.

809

When these rules are used when forming paths, the SLOTS structure can
be used to mark the paths. Each path goes through neighboring processors at
successive time steps. For each of these time steps the DffiECTION field of
the SLOTS structure is marked, telling the processor which direction it should
pass a message if it receives it on that time. SLOTS serves both to instruct the
processors how to send messages, and to indicate that a processor is busy at a
certain time slot so that when new paths are constructed it can be guaranteed
that they won't conflict with current paths.
Consider the following example. Suppose we are given the directed graph
with vertices A,B,C,D and edges A - > C, B - > C,B - > D, and D - >
A. This is to be done where A,B,C, and D have been assigned to successive
elements of a linear array. (A linear array in not a good network for this
scheme, but is a convenient source of examples.)
Lo~ical

Faa. 2.

Connections

GIapb Example

A.B.C.D are successive members in a linear array
1---2---3---4
A---B---C---D
First. A ->C can be completed with the map East-East. so
Slots[A][1].direction = E. Slots[B][2].direction=E.
Slots[C][2].end = 1 .
B->C can be done with the map East. it can start at time 1.
since Slots[B] [1] . direction and Slots[C] [1].end are free.
B->D goes through C then to D. its map is East-East. B is
occupied at time 1 and 2. It is free at time 3.
so Slots[B] [3].direction = E. Slots[C] [4].direction = E.
Slots[D] [4].end = 1.
D->A must go through C.B.A. using map West-West-West.
D is free on time 1. C is free on time 2. but B is occupied
on time 3. D is free on time 2. but C is occupied on time 3.
It can start from D at time 3. Slots[D] [3].direction = W.
Slots[C] [4] . direction = W. Slots[B] [5].direction = W.
Slots [A] [5].end=1

810

Every processor acts as a conduit for its neighbors messages. No processor
knows where any message is going to or coming from, but each processor knows
what it must do to establish the local connections.
The use of contiguous time slots is vital to the correct operation of the
system. If all edge-paths are established according to the above rules, there is
a simple method for making the connections. The paths have been restricted
so that there will be no collisions, and paths' directions use consecutive time
slots. Hence if all arcs at time i send a message to their neighbors, then each
processor is guaranteed no more than 1 message coming to it. The end of a
path is specified by setting a separate bit that is tested after each message
is received. A separate start bit indicates when a path starts. The start bit
is needed because the SLOTS array just tells the processors where to send a
message, regardless of how that message arrived. The start array indicates
when a message originates, as opposed to arriving from a neighbor.
The following algorithm is basic to the routing system.

for i = time 1 to T
FORALL processors
/* if an arc starts or is passing through at this time*/
if SLOT[i] . START = 1 or active = 1
for j=1 to neighbor-limit
if SLOT[i].direction= j
write message bit to in-box
of neighbor j:
set active = 0:
FORALL processor that just received a message
if end[i]
move in-box to message-destination;
else
move in-box to out-box:
set active bit = 1:
This code follows the method mentioned above. The time slots are looped
through and the messages are passed in the appropriate directions as specified
in the SLOTS array. Two bits, in-box and out-box, are used for message passing
so that an out-going message won't be overwritten by an in-coming message
before it gets transferred. The inner loop lor j = 1 to neighbor limit checks
each of the possible neighbor directions and sends the message to the correct
neighbor. For instance, in a grid the neighbor limit is 4, for North, South, East,
and West neighbors. The time complexity of data movement is O(T times
neighbor-limi t) .
SETTING UP CONNECTIONS
One of the goals in developing this system was to have a method for adding
new connections quickly. Paths are added so that they don't conflict with any
previously constructed path. Once a path is placed it will not be re-routed

811

by the basic placement algorithm; it will always start at the same spot at the
same time. The basic idea of the method for placing a connection is to start
from the source processor and in parallel examine all possible paths outward
from it that do not conflict with pre-established paths and which adhere to the
sequential time constraint. As the trial paths are flooding the system, they
are recorded in temporary storage. At the end of this deluge of trial paths all
possible paths will have been examined. If the destination processor has been
reached, then a path exists under the current time-space restrictions. Using
the stored information a path can be backtraced and recorded in the SLOTS
structure. This is similar to the Lee-Moore routing algorithm21 ?22 for finding a
path in a system, but with the sequential time restriction.
For example, suppose that the connection (u,v) is to be added. First it is
assumed that processors for u and v have already been determined, otherwise
(as a simplification) assume a random allocation from a pool of free processors. A parallel breadth-first search will be performed starting from the source
processor. During the propagation phase a processor which receives a message
checks its SLOTS array to see if they are busy on that time step, if not it will
propagate to its neighbors on the next time step. For instance, suppose a trial
path starts at time 1 and moves to a neighboring processor, but that neighbor is
already busy at time 1 (as can be seen by examining the DIRECTION-SLOT.)
Since a path that would go through this neighbor at this time is not legal, the
trial path would commit suicide, that is, it stops propagating itself. If the processor slot for time 2 was free, the trial path would attempt to propagate to all
of its' neighbors at time 3.
Using this technique paths can be constructed with essentially no knowledge of the relative locations of the ""neurons"" being connected or the underlying topology. Variations on the outlined method, such as choosing the shortest
path, can improve the choice of paths with very little overhead. If the entire network were known ahead of time, an off-line method could be used to construct
the paths more efficiently; work on off-line methods is underway. However, the
simple elegance of this basic method holds great appeal for systems that change
slowly over time in unpredictable ways.
PERFORMANCE
Adding an edge (assuming one can be added), deleting any set of edges, or
traversing all the edges in parallel, all have time complexity O(T x neighborlimit). If it is assumed that neighbor limit is a small constant then the complexity is O(T). Since T is related both to the time and space needed, it is
a crucial factor in determining the value of the algorithms presented. Some
analytic bounds on T were presented inll, but it is difficult to get a tight bound
on T for general interconnection networks and dynamically changing graphs. A
simulator was constructed to examine the behavior of the algorithms. Besides
the simulated data, the algorithms mentioned were actually implemented for
the Connection Machine. The data produced by the simulator is consistent
with that produced by the real machine. The major result is that the size of T
appears proportional to the average degree of the graph times the diameter of
the interconnection network20 ?

812

FURTHER RESEARCH
This paper has been largely concerned with a system that can realize the
connections in a neural network when the two neurons to be joined have been
activated. The tests conducted have been concerned with the validity of the
method for implementing connections, rather than with a full simulation of a
neural network. Clearly this is the next step.
A natural extension of this method is a system which can form its .own
connections based solely on the activity of certain neurons, without having
to explicitly activate the source and destination neurons. This is an exciting
avenue, and further results should be forthcoming.
Another area of research involves the formation of branching paths. The
current method takes an arc in the neural network and realizes it as a unique
path in space-time. A variation that has similarities to dendritic structure
would allow a path coming from a neuron to branch and go to several target
neurons. This extension would allow for a much more economical embedding
system. Simulations are currently underway.
CONCLUSIONS
A method has been outlined which allows the implementation of neural nets
connections on a class of parallel architectures which can be constructed with
very large numbers of processing elements. To economize on hardware so as to
maximize the number of processing element buildable, it was assumed that the
processors only have local connections; no hardware is provided for communication. Some simple algorithms have been presented which allow neural nets
with arbitrary connections to be embedded in SIMD architectures having a variety of topologies. The time for performing a parallel traversal and for adding
a new connection appears to be proportional to the diameter of the topology
times the average number of arcs in the graph being embedded. In a system
where the topology has diameter O(logN), and where the degree of the graph
being embedded is bounded by a constant, the time is apparently O(logN).
This makes it competitive with existing methods for SIMD routing, with the
advantages that there are no apriori requirements for the form of the data, and
the topological requirements are extremely general. Also, with our approach
new arcs can be added without reconfiguring the entire system. The simplicity
of the implementation and the flexibility of the method suggest that it could be
an important tool for using SIMD architectures for neural network simulation.
BIBLIOGRAPHY
1. M.J. Flynn, ""Some computer organizations and their effectiveness"", IEEE
Trans Comput., vol C-21, no.9, pp. 948-960.
2. W. Hillis, ""The Connection Machine"", MIT Press, Cambridge, Mass, 1985.
3. D. Nassimi, S. Sahni, ""Parallel Algorithms to Set-up the Benes Permutation
Network"", Proc. Workshop on Interconnection Networks for Parallel and Distributed Processing, April 1980.
4. D. Nassimi, S. Sahni, ""Benes Network and Parallel Permutation Algorithms"",
IEEE Transactions on Computers, Vol C-30, No 5, May 1981.
5. D. Nassimi, S. Sahni, ""Parallel Permutation and Sorting Algorithms and a

813

New Generalized Connection Network"" , JACM, Vol. 29, No.3, July 1982 pp.
642-667
6. K.E. Batcher, ""Sorting Networks and their Applications"", The Proceedings
of AFIPS 1968 SJCC, 1968, pp. 307-314.
7. C. Thompson, ""Generalized connection networks for parallel processor intercommunication"", IEEE Tran. Computers, Vol C, No 27, Dec 78, pp. 1119-1125.
8. Nathan H. Brown, Jr., ""Neural Network Implementation Approaches for the
Connection Machine"", presented at the 1987 conference on Neural Information
Processing Systems - Natural and Synthetic.
9. K.E. Batcher, ""Design of a massively parallel processor"", IEEE Trans on
Computers, Sept 1980, pp. 836-840.
10. H.M. Hastings, S. Waner, ""Neural Nets on the MPP"" , Frontiers of Massively
Parallel Scientific Computation, NASA Conference Publication 2478, NASA
Goddard Space Flight Center, Greenbelt Maryland, 1986.
11. S. Tomboulian, ""A System for Routing Arbitrary Communication Graphs
on SIMD Architectures"", Doctoral Dissertation, Dept of Computer Science,
Duke University, Durham NC.
12. T. Feng, ""A Survey of Interconnection Networks"", Computer, Dec 1981,
pp.12-27.
13. F. Preparata and J. Vuillemin, ""The Cube Connected Cycles: a Versatile
Network for Parallel Computation"", Comm. ACM, Vol 24, No 5 May 1981, pp.
300-309.
14. H. Stone, ""Parallel processing with the perfect shuffle"", IEEE Trans. Computers, Vol C, No 20, Feb 1971, pp. 153-161.
15. T. Leighton, ""Parallel Computation Using Meshes of Trees"", Proc. International Workshop on Graph Theory Concepts in Computer Science, 1983.
16. W.S. McCulloch, and W. Pitts, ""A Logical Calculus of the Ideas Imminent
in Nervous Activity,"" Bulletin of Mathematical Biophysics, Vol 5, 1943, pp.115133.
17. J.J. Hopfield, ""Neural networks and physical systems with emergent collective computational abilities"", Prot!. Natl. Aca. Sci., Vol 79, April 1982, pp.
2554-2558.
18. T. Kohonen, ""Self-Organization and Associative Memory, Springer-Verlag,
Berlin, 1984.
19. R.P. Lippmann, ""An Introduction to Computing with Neural Nets"", IEEE
AASP, Apri11987, pp. 4-22.
20. S. Tomboulian, ""A System for Routing Directed Graphs on SIMD Architectures"", ICASE Report No. 87-14, NASA Langley Research Center, Hampton,
VA.
21. C.Y. Lee, ""An algorithm for path connections and its applications"", IRE
Trans Elec Comput, Vol. EC-I0, Sept. 1961, pp. 346-365.
22. E. F. Moore, ""Shortest path through a maze"", A nnals of Computation
Laboratory, vol. 30. Cambridge, MA: Harvard Univ. Press, 1959, pp.285-292.

"
36,1987,"Stability Results for Neural Networks","",36-stability-results-for-neural-networks.pdf,"Abstract Missing","554

STABILITY RESULTS FOR NEURAL NETWORKS
A. N. Michell, J. A. FarreUi , and W. Porod 2
Department of Electrical and Computer Engineering
University of Notre Dame
Notre Dame, IN 46556
ABSTRACT
In the present paper we survey and utilize results from the qualitative theory of large
scale interconnected dynamical systems in order to develop a qualitative theory for the
Hopfield model of neural networks. In our approach we view such networks as an interconnection of many single neurons. Our results are phrased in terms of the qualitative
properties of the individual neurons and in terms of the properties of the interconnecting
structure of the neural networks. Aspects of neural networks which we address include
asymptotic stability, exponential stability, and instability of an equilibrium; estimates
of trajectory bounds; estimates of the domain of attraction of an asymptotically stable
equilibrium; and stability of neural networks under structural perturbations.
INTRODUCTION
In recent years, neural networks have attracted considerable attention as candidates
for novel computational systems l - 3 . These types of large-scale dynamical systems, in
analogy to biological structures, take advantage of distributed information processing
and their inherent potential for parallel computation 4 ,5. Clearly, the design of such
neural-network-based computational systems entails a detailed understanding of the
dynamics of large-scale dynamical systems. In particular, the stability and instability
properties of the various equilibrium points in such networks are of interest, as well
as the extent of associated domains of attraction (basins of attraction) and trajectory
bounds.
In the present paper, we apply and survey results from the qualitative theory oflarge
scale interconnected dynamical systems6 - 9 in order to develop a qualitative theory for
neural networks. We will concentrate here on the popular Hopfield model3 , however,
this type of analysis may also be applied to other models. In particular, we will address
the following problems: (i) determine the stability properties of a given equilibrium
point; (ii) given that a specific equilibrium point of a neural network is asymptotically
stable, establish an estimate for its domain of attraction; (iii) given a set of initial conditions and external inputs, establish estimates for corresponding trajectory bounds; (iv)
give conditions for the instability of a given equilibrium point; (v) investigate stability
properties under structural perturbations. The present paper contains local results. A
more detailed treatment of local stability results can be found in Ref. 10, whereas global
results are contained in Ref. 1l.
In arriving at the results of the present paper, we make use of the method of analysis advanced in Ref. 6. Specifically, we view high dimensional neural network as an
IThe work of A. N. Michel and J. A. Farrell was supported by NSF under grant ECS84-19918.
2The work of W. Porod was supported by ONR under grant NOOOI4-86-K-0506.

? American Institute of Physics 1988

555

interconnection of individual subsystems (neurons). This interconnected systems viewpoint makes our results distinct from others derived in the literature 1 ,12. Our results
are phrased in terms of the qualitative properties of the free subsystems (individual
neurons, disconnected from the network) and in terms of the properties of the interconnecting structure of the neural network. As such, these results may constitute useful
design tools. This approach makes possible the systematic analysis of high dimensional
complex systems and it frequently enables one to circumvent difficulties encountered in
the analysis of such systems by conventional methods.
The structure of this paper is as follows. We start out by defining the Hopfield
model and we then introduce the interconnected systems viewpoint. We then present
representative stability results, including estimates of trajectory bounds and of domains
of attraction, results for instability, and conditions for stability under structural perturbations. Finally, we present concluding remarks.
THE HOPFIELD MODEL FOR NEURAL NETWORKS
In the present paper we consider neural networks of the Hopfield type 3 ? Such systems
can be represented by equations of the form
N

Ui

= . . . biUi + I:Aij Gj(Uj) + Ui(t),

for i

= 1, ... ,N,

(1)

j=1

= *""Ui(t) = l~g) and bi = *..
(-00,00),':. = ~ +E.f=IITiil, Ri > O,Ii:

where Aij

As usual, Ci > O,Tij

= [0,00)

i:;,RijfR =

~ R,Ii is continuous,
Ui = ~,Gi : R ~ (-1,1), Gi is continuously differentiable and strictly monotonically increasing (Le., Gi( uD > G i ( u~') if and only if u~ > u~'), UiGi( Ui) > 0 for all Ui ::j; 0,
and Gi(O) = O. In (1), C i denotes capacitance, Rij denotes resistance (possibly including a sign inversion due to an inverter), G i (?) denotes an amplifier nonlinearity, and Ii(')
denotes an external input.
In the literature it is frequently assumed that Tij = Tji for all i,j = 1, ... , N and
that Tii = 0 for all i = 1, ... , N. We will make these assumptions only when explicitly
stated.
We are interested in the qualitative behavior of solutions of (1) near equilibrium
points (rest positions where Ui == 0, for i = 1, ... , N). By setting the external inputs
Ui(t), i = 1, ... , N, equal to zero, we define U* = [ui, ... , u""NV fRN to be an equilibrium
for (1) provided that -biui' + E.f=l Aij Gj(uj) = 0, for i = 1, ... ,N. The locations
of such equilibria in RN are determined by the interconnection pattern of the neural
network (i.e., by the parameters Aij, i,j = 1,. "", N) as well as by the parameters bi and
the nature of the nonlinearities Gi(')' i = 1, ... ,N.
Throughout, we will assume that a given equilibrium u* being analyzed is an isolated
equilibrium for (1), i.e., there exists an r > 0 such that in the neighborhood B( u*, r) =
{( u - u*)fR N : lu - u*1 < r} no equilibrium for (1), other than u = u*, exists.
When analyzing the stability properties of a given equilibrium point, we will be able
to assume, without loss of generality, that this equilibrium is located at the origin u = 0
of RN. If this is not the case, a trivial transformation can be employed which shifts the
equilibrium point to the origin and which leaves the structure of (1) the same.
R+

556

INTERCONNECTED SYSTEMS VIEWPOINT
We will find it convenient to view system (1) as an interconnection of N free subsystems (or isolated sUbsystems) described by equations of the form

Pi =

-biPi

+ Aii Gi(Pi) + Ui(t).

(2)

Under this viewpoint, the interconnecting structure of the system (1) is given by

Gi(Xb"" . ,x n )

~

N

L

AijGj(Xj), i

= 1, ... ,N.

(3)

j=1

ii:i
Following the method of analysis advanced in6 , we will establish stability results
which are phrased in terms of the qualitative properties of the free subsystems (2) and
in terms of the properties of the interconnecting structure given in (3). This method
of analysis makes it often possible to circumvent difficulties that arise in the analysis
of complex high-dimensional systems. Furthermore, results obtained in this manner
frequently yield insight into the dynamic behavior of systems in terms of system com.
ponents and interconnections.

GENERAL STABILITY CONDITIONS
We demonstrate below an example of a result for exponential stability of an equilibrium point. The principal Lyapunov stability results for such systems are presented,
e.g., in Chapter 5 of Ref. 7.
We will utilize the following hypotheses in our first result.
(A-I) For system (1), the external inputs are all zero, i.e.,
Ui(t) == 0, i = 1, ... , N.

(A-2) For system (1), the interconnections satisfy the estimate

for all

Ixil < ri, Ix;1 < rj,

i,j = 1, ... , N, where the ail are real constants.

?

(A-3) There exists an N-vector a> (i.e., aT = (al, ... ,aN) and ai > 0, for all ~ =
1, ... ,N) such that the test matrix S = [Sij]

is negative definite, where the bi are defined in (1) and the aij are given in (A-2).

557

We are now in a position to state and prove the following result.
Theorem 1 The equilibrium x = 0 of the neural network (1) is exponentially stable
if hypotheses (A-l), (A-2) and (A-3) are satisfied.
Proof. For (1) we choose the Lyanpunov function

(4)
where the ai are given in (A-3). This function is clearly positive definite. The time
deri vati ve of v along the solutions of (1) is given by
N 1

DV(1)(X) =

N

2: 2ai(2xd[-biXi + 2: Aij Gj(Xj)]
i=1

j=1

where (A-l) has been invoked. In view of (A-2) we have

DV(1)( x) <

N

N

i=1

j=1

2: ai( -bix~ + Xi 2: aijX j)
for all

where r

IxI2 < r

= mini(ri), IxI2 = (Ef:1 X~) 1/2, and the matrix R =
r;j

-bi + aii),
= { ai(
ai aij,

t

i

[rij] is given by

=J
::J j.

But it follows that

x T Rx = x T ( R

~ RT) X = x T Sx ::; )w(S) Ixl1

(5)

where S is the matrix given in (A-3) and AM(S) denotes the largest eigenvalue of
the real symmetric matrix S. Since S is by assumption negative definite, we have
AM(S) < O. It follows from (4) and (5) that in some neighborhood of the origin x = 0,
we have c1lxl~ ~ v(x) ~ c2lxl~ and DV(1)(X) ~ -c3Ixl~, where C1 = mini ai > 0,
C2 =
maxi ai > 0, and C3 = -AM(S) > O. Hence, the equilibrium x = of the neural
network (1) is exponentially stable (c.f. Theorem 9.10 in Ref. 7).
Consistent with the philosophy of viewing the neural network (1) as an interconnection of N free subsystems (2), we think of the Lyapunov function (4) as consisting
of a weighted sum of Lyapunov functions for each free subsystem (2) (with Ui(t) == 0) .
The weighting vector a > 0 provides flexibility to emphasize the relative importance
of the qualitative properties of the various individual subsystems. Hypothesis (A - 2)
provides a measure of interaction between the various subsystems (3). Furthermore, it
is emphasized that Theorem 1 does not require that the parameters Aij in (1) form a
symmetric matrix.

!

!

?

558

WEAK COUPLING CONDITIONS
The test matrix S given in hypothesis (A - 3) has off-diagonal terms which may be
positive or nonpositive. For the special case where the off-diagonal terms of the test
matrix S = [Sij] are non-negative, equivalent stability results may be obtained which are
much easier to apply than Theorem 1. Such results are called weak-coupling conditions
in the literature6 ,9. The conditions 8ij ~ 0 for all i ::J j may reflect properties of the
system (1) or they may be the consequence of a majorization process.
In the proof of the subsequent result, we will make use of some of the properties
of M- matrices (see, for example, Chapter 2 in Ref. 6). In addition we will use the
following assumptions.

(A-4) For system (1), the nonlinearity Gi(Xi) satisfies the sector condition

(A-S) The successive principal minors of the N

X

N test matrix D = [d ij ]

are all positive where, the bi and Aij are defined in (1) and Ui2 is defined in (A - 4).
Theorem 2 The equilibrium x = 0 of the neural network (1) is asymptotically stable if hypotheses (A-1), (A-4) and (A-5) are true.
Proof. The proof proceeds 10 along lines similar to the one for Theorem 1, this time
with the following Lyapunov function
N

v(x)

= L: Qilxd?

(6)

i=l

The above Lyapunov function again reflects the interconnected nature of the whole
system. Note that this Lyapunov function may be viewed as a generalized Hamming
distance of the state vector from the origin.
ESTIMATES OF TRAJECTORY BOUNDS
In general, one is not only interested in questions concerning the stability of an
equilibrium of the system (1), but also in performance. One way of assessing the qualitative properties of the neural system (1) is by investigating solution bounds near an
equilibrium of interest. We present here such a result by assuming that the hypotheses
of Theorem 2 are satisfied.
In the following, we will not require that the external inputs Ui(t), i = 1, ... , N be
zero. However, we will need to make the additional assumptions enumerated below.

559

(A-6) Assume that there exist .xi

> 0, for i = 1, ... , N, and an ( > 0 such that

N

L: (~~) IAjil

> ( > 0,

i = 1, ... ,N

j=1

i:/;j
where bi and Aij are defined in (1) and (Ti2 is defined in (A-4).

(A-7) Assume that for system (1),
N

L: .xiIUi(t)1 ~ k

for all t ~ 0

i=l
for some constant k > 0 where the .xi, i

= 1, ... , N

are defined in (A-6).

In the proof of our next theorem, we will make use of a comparison result. We
consider a scalar comparison equation of the form iJ = G(y) where y(R,G : B(r) - R
for some r > 0, and G is continuous on B(r) = {XfR: Ixl < r}. We can then prove the
following auxiliary theorem: Let p(t) denote the maximal solution of the comparison
equation with p(to) = Yo(B(r), t ~ to > O. If r(t), t ~ to ~ 0 is a continuous
function such that r(to) $ Yo, and if r(t) satisfies the differential inequality Dr(t) =
limk-+O+ sup[r(t + k) - r(t)] $ G(r(t)) almost everywhere, then r(t) $ p(t) for t ~
to ~ 0, for as long as both r(t) and p(t) exist. For the proof of this result, as well as
other comparison theorems, see e.g., Refs. 6 and 7.
For the next theorem, we adopt the following notation. We let 6 = mini (Til
where (Til is defined in (A - 4), we let c = (6 , where ( is given in (A-6), and
we let ?(t,to,xo) = [?I(t,to,xo)'''',</>N(t,to,xo)]T denote the solution of (1) with
?(to, to, xo) = Xo = (XlO,"""" xNol for some to ~ O.
We are now in a position to prove the following result, which provides bounds for
the solution of(1).

t

Theorem 3 Assume that hypotheses (A-6) and (A-7) are satisfied. Then

11?(t, to, xo)11 =~ ~
L..."" .xil?i(t, to, xo) I ::; (a - -k) e- c(t - t)
0
i=l

C

k
+ -,

t

~

to

~ 0

C

provided that a > k/c and IIxoll = E~l .xilxiOI ~ a, where the .xi, i = 1,. "", N are
given in (A-6) and k is given in (A-7).
Proof. For (1) we choose the Lyapunov function
N

v(x) =

L .xilxil?
i=l

(7)

560

Along the solutions of (1), we obtain

z: Ai!Ui(t)\
N

DV(l)(X) ~ AT Dw +

(8)

i=l

where wT = [G1J;d\Xl\,'''' G'Z~N)lxN\]' A = (A}, ... ,ANf, and D = [dij] is the test
matrix given in (A-5). Note that when (A-6) is satisfied, as in the present theorem,
then (A-5) is automatically satisfied. Note also that w ~ 0 (Le., Wi ~ 0, i = 1, ... , N)
and w = 0 if and only if x = O.
Using manipulations involving (A-6), (A-7) and (8), it is easy to show that DV(l)(X) ~
-cv(x) + k. This ineqUality yields now the comparison equation iJ = -cy + k, whose
unique solution is given by

pet, to, Po) =
H we let r

(Po - ~) e-c(t-to) +~,

for all t

~ to.

= v, then we obtain from the comparison result
N

pet) ~ ret) = v(4)(t,to,xo)) =

2: Ail4>i(t,to,xo)1 = 114>(t,to,xo)\I,
i=l

i.e., the desired estimate is true, provided that Ir(to)\

= Ef:l Ai/XiOI = IIxoll

~ a and

a> kjc.
ESTIMATES OF DOMAINS OF ATTRACTION
Neural networks of the type considered herein have many equilibrium points. If
a given equilibrium is asymptotically stable, or exponentially stable, then the extent
of this stability is of interest. As usual, we assume that x = 0 is the equilibrium of
interest. If 4>(t, to, xo) denotes a solution of the network (1) with 4>(to, to, xo) = xo, then
we would like to know for which points Xo it is true that 4>( t, to, xo) tends to the origin
as t ---+ 00. The set of all such points Xo makes up the domain of attraction (the basin of
attraction) of the equilibrium x = O. In general, one cannot determine such a domain
in its entirety. However, several techniques have been devised to estimate subsets of
a domain of attraction. We apply one such method to neural networks, making use
of Theorem 1. This technique is applicable to our other results as well, by making
appropriate modifications.
We assume that the hypotheses (A-I), (A-2) and (A-3) are satisfied and for the free
subsystem (2) we choose the Lyapunov function

Vi(Pi)

= 21 Pi'2

(9)

Then DVi(2) (Pi) ~ (-bi + aii)p~, \Pi/ < ri for some ri > O. If (A-3) is satisfied, we
must have (-bi + aii) < 0 and DVi(2)(Pi) is negative definite over B(ri).
Let Gvo ; = {PifR : Vi(Pi) = !p~ < trl ~ Voi}. Then GVo ; is contained in the domain
of attraction of the equilibrium Pi = 0 for the free subsystem (2).
To obtain an estimate for the domain of attraction of x = 0 for the whole neural
network (1), we use the Lyapunov function

561

N

1

N

v(x) -LJ2
- '""' -""'?x~
- '""' o?v?(x?)
.....?? -LJ
???.
i=l

(10)

i=l

It is now an easy matter to show that the set
N

C>.

= {uRN: v(x) = LOiVi(Xi) < oX}
i=l

will be a subset of the domain of attraction of x
oX =

= 0 for the neural network (1), where

min (OiVOi) = min

l$.i$.N

1$.i$.N

(~Oir~)
.
2 ?

In order to obtain the best estimate of the domain of attraction of x = 0 by the
present method, we must choose the 0i in an optimal fashion. The reader is referred to
the literature9 ,l3,l4 where several methods to accomplish this are discussed.
INSTABILITY RESULTS
Some of the equilibrium points in a neural network may be unstable. We present
here a sample instability theorem which may be viewed as a counterpart to Theorem
2. Instability results, formulated as counterparts to other stability results of the type
considered herein may be obtained by making appropriate modifications.

(A-B) For system (1), the interconnections satisfy the estimates

XiAiiGi(Xi)
IXiAjjGj(xj)1
where OJ

= O""il

when Aii

< OiAiiX;,
$

IxdlAijlO""j2l xil, if; j

< 0 and Oi = O""i2 when Aii > 0 for all IXil < ri, and for

alllXjl < Tj,i,j = 1, ... ,N.

(A-9) The successive principal minors of the N x N test matrix D

= [dij ] given by

are positive, where O""i = ~ - Au when ifFIl (i.e., stable subsystems) and O""i
+ Aji when ifFu (i.e., unstable subsystems) with F = FII U Fu and F =
{I, ., . , N} and Fu f; </>.

-!:;

We are now in a position to prove the following result.
Theorem 4 The equilibrium x = 0 of the neural network (1) is unstable if hypotheses
(A-l), (A-8) and (A-g) are satisfied. If in addition, FII = </> (</> denotes the empty set),
then the equilibrium x = 0 is completely unstable.

562

Proof. We choose the Lyapunov function

(11)
ifF.

ifF..

where ai > 0, i = 1, ... ,N. Along the solutions of (1) we have (following the proof of
Theorem 2), DV(l)(X) $ -aTDw for all x?B(r), r = miniri where aT = (a}, ... ,aN),
D is defined in (A-9), and w T = [ G 1
IXll, ... , GNx~N) IXNI]. We conclude that

l;d

?

DV(l)(X) is negative definite over B(r). Since every neighborhood of the origin x =
contains at least one point x' where v(x') < 0, it follows that the equilibrium x = 0 for
(1) is unstable. Moreover, when F, = </>, then the function v(x) is negative definite and
the equilibrium x = 0 of (1) is in fact completely unstable (c.f. Chapter 5 in Ref. 7).
STABILITY UNDER STRUCTURAL PERTURBATIONS

In specific applications involving adaptive schemes for learning algorithms in neural
networks, the interconnection patterns (and external inputs) are changed to yield an
evolution of different sets of desired asymptotica.l1y stable equilibrium points with appropriate domains of attraction. The present diagonal dominance conditions (see, e.g.,
hypothesis (A-6)) can be used as constraints to guarantee that the desired equilibria
always have the desired stability properties.
To be more specific, we assume that a given neural network has been designed with a
set of interconnections whose strengths can be varied from zero to some specified values.
We express this by writing in place of (1),
N

Xi = -biXi

+ L:8ij Aij Gj(Xj) + Ui(t),

for i = 1, ... ,N,

(12)

j=l

where 0 $ 8ij $ 1. We also assume that in the given neural network things have been
arranged in such a manner that for some given desired value ~ > 0, it is true that
~ = mini
8iiAii). From what has been said previously, it should now be clear
that if Ui( t) == 0, i = 1, ... ,N and if the diagonal dominance conditions

(!:; -

~

- t=

(~~)

8ij A iji > 0, for i = 1, ... ,N

(13)

1

j
1
i:f;j

?

are satisfied for some Ai > 0, i = 1, ... , N, then the equilibrium x = for (12) will be
asymptotically stable. It is important to recognize that condition (13) constitutes a single stability condition for the neural network under structural perturbations. Thus, the
strengths of interconnections of the neural network may be rearranged in any manner
to achieve some desired set of equilibrium points. If (13) is satisfied, then these equilibria will be asymptotically stable. (Stability under structural perturbations is nicely
surveyed in Ref. 15.)

563

CONCLUDING REMARKS
In the present paper we surveyed and applied results from the qualitative theory
of large scale interconnected dynamical systems in order to develop a qualitative theory for neural networks of the Hopfield type. Our results are local and use as much
information as possible in the analysis of a given eqUilibrium. In doing so, we established cri-teria for the exponential stability, asymptotic stability, and instability of an
equilibrium in such networks. We also devised methods for estimating the domain of
attraction of an asymptotically stable equilibrium and for estimating trajectory bounds
for such networks. Furthermore, we showed that our stability results are applicable
to systems under structural perturbations (e.g., as experienced in neural networks in
adaptive learning schemes).
In arriving at the above results, we viewed neural networks as an interconnection
of many single neurons, and we phrased our results in terms of the qualitative properties of the free single neurons and in terms of the network interconnecting structure.
This viewpoint is particularly well suited for the study of hierarchical structures which
naturally lend themselves to implementations 16 in VLSI. Furthermore, this type of approach makes it possible to circumvent difficulties which usually arise in the analysis
and synthesis of complex high dimensional systems.
REFERENCES
[1] For a review, see, Neural Networks for Computing, J. S. Denker, Editor, American
Institute of Physics Conference Proceedings 151, Snowbird, Utah, 1986.
[2] J. J. Hopfield and D. W. Tank, Science 233, 625 (1986).
[3] J. J. Hopfield, Proc. Natl. Acad. Sci. U.S.A. 79,2554 (1982), and ibid. 81,3088
(1984).
[4] G. E. Hinton and J. A. Anderson, Editors, Parallel Models of Associative Memory,
Erlbaum, 1981.
[5] T. Kohonen, Self-Organization and Associative Memory, Springer-Verlag, 1984.
[6] A. N. Michel and R. K. Miller, Qualitative Analysis of Large Scale Dynamical
Systems, Academic Press, 1977.
[7] R. K. Miller and A. N. Michel, Ordinary Differential Equations, Academic Press,
1982.
[8] I. W. Sandberg, Bell System Tech. J. 48, 35 (1969).
[9] A. N. Michel, IEEE Trans. on Automatic Control 28, 639 (1983).
[10] A. N. Michel, J. A. Farrell, and W. Porod, submitted for publication.
[11] J.-H. Li, A. N. Michel, and W. Porod, IEEE Trans. Cire. and Syst., in press.
[12] G. A. Carpenter, M. A. Cohen, and S. Grossberg, Science 235, 1226 (1987).
[13] M. A. Pai, Power System Stability, Amsterdam, North Holland, 1981.
[14] A. N. Michel, N. R. Sarabudla, and R. K. Miller, Circuits, Systems and Signal
Processing 1, 171 (1982).
[15] Lj. T. Grujic, A. A. Martynyuk and M. Ribbens-Pavella, Stability of Large-Scale
Systems Under Structural and Singular Perturbations, Nauka Dumka, Kiev, 1984.
[16] D. K. Ferry and W. Porod, Superlattices and Microstructures 2, 41 (1986).

"
37,1987,"Time-Sequential Self-Organization of Hierarchical Neural Networks","",37-time-sequential-self-organization-of-hierarchical-neural-networks.pdf,"Abstract Missing","709

TIME-SEQUENTIAL SELF-ORGANIZATION OF HIERARCHICAL
NEURAL NETWORKS
Ronald H. Silverman
Cornell University Medical College, New York, NY 10021
Andrew S. Noetzel
polytechnic University, Brooklyn, NY 11201
ABSTRACT
Self-organization of multi-layered networks can be realized
by time-sequential organization of successive neural layers.
Lateral inhibition operating in the surround of firing cells in
each layer provides for unsupervised capture of excitation
patterns presented by the previous layer. By presenting patterns
of increasing complexity, in co-ordination with network selforganization, higher levels of the hierarchy capture concepts
implicit in the pattern set.
INTRODUCTION
A
fundamental
difficulty
in
self-organization
of
hierarchical, multi-layered, networks of simple neuron-like cells
is the determination of the direction of adjustment of synaptic
link weights between neural layers not directly connected to input
or output patterns.
Several different approaches have been used
to address this problem. One is to provide teaching inputs to the
cells in internal layers of the hierarchy.
Another is use of
1
back-propagated error signals ,2 from the uppermost neural layer,
which is fixed to a desired outfut pattern.
A third is the
""competitive learning"" mechanism,
in which a Hebbian synaptic
modification rule is used, with mutual inhibition among cells of
each layer preventing them from becoming conditioned to the same
patterns.
The use of explicit teaching inputs is generally felt to be
undesirable because such signals must,
in essence, provide
individual direction to each neuron in internal layers of the
network. This requires extensive control signals, and is somewhat
contrary to the notion of a self-organizing system.
Back-propagation
provides
direction
for
link
weight
modification of internal layers based on feedback from higher
neural layers. This method allows true self-organization, but at
the cost of specialized neural pathways over which these feedback
signals must travel.
In this report, we describe a simple feed-forward method for
self-organization of hierarchical neural networks. The method is
a variation of the technique of competitive learning.
It calls
for successive neural layers to initiate modification of their
afferent synaptic link weights only after the previous layer has
completed its own self-organization. Additionally, the nature of
the patterns captured can be controlled by providing an organized

? American Institute of Physics 1988

710

group of pattern sets which would excite the lowermost (input)
layer of the network in concert with training of successive
such a collection of pattern sets might be viewed as a
layers.
""lesson plan.""
MODEL
The network is composed of neuron-like cells, organized in
hierarchical layers.
Each cell is excited by variably weighted
afferent connections from the outputs of the previous (lower)
layer. Cells of the lowest layer take on the values of the input
pattern.
The cells themselves are of the McCulloch-pitts type:
they fire only after their excitation exceeds a threshold, and are
otherwise inactive.
Let Si(t) do,,} be the state of cell i at
time t.
Let Wij' a real number ranging from 0 to ""
be the
weight, or strength, of the synapse connecting cell i to cell j.
Let eij be the local excitation of cell i at the synaptic
connect~on
from cell j .
The excitation received along each
synaptic connection is integrated locally over time as follows:
e? . (t) = e .. ( t-l) + w? . S? (t)
~J

~J

~J

~

(1)

Synaptic connections may, therefore be viewed as capacitive.
The total excitation, Ej , is the sum of the local excitations of
cell j.
= Ee .. (t)
~

~J

( 2)

The use of the time-integrated activity of a synaptic
connection between two neurons,
instead of the more usual
instantaneous classification of neurons as ""active"" or ""inactive"",
permits each synapse to provide a statistical measure of the
activity of the input, which is assumed to be inherently
stochastic.
It also embodies the principle of learning based on
locally available information and allows for implementations of
the synapse as a capacitive element.
Over time, the total excitation of individual neurons on a
give layer will increase. When excitation exceeds a threshold, a,
then the neuron fires, otherwise it is inactive.
=

if
else

Sj (t)

=

E j (t)

>

a

( 3)

o

During a neuron I s training phase, a modified Hebbian rule
results in changes in afferent synaptic link weights such that,
upon firing, synapses with integrated activity greater than mean
activity are reinforced, and those with less than mean activity
are weakened.
More formally, if Sj(t) = 1 then the synapse
weights are modified by
(4 )

Here, n represents the fan-in to a cell, and k is a small,
positive constant. The ""sign"" function specifies the direction of
change and the ""sine"" function determines the magnitude of
change.
The sine curve provides the property that intermediate

711

link weights are subject to larger modifications than weights near
zero or saturation.
This helps provide for stable end-states
after learning.
Another effect of the integration of synaptic activity may be
seen.
A synapse of small weight is allowed to contribute to the
firing of a cell (and hence have its weight incremented) if a
series of patterns presented to the network consistently excite
that synapse.
The sequence of pattern presentations, therefore,
becomes a factor in network self-organization.
Upon firing, the active cell inhibits other cells in its
vicinity
(lateral
inhibi tion) ?
This
mechanism
supports
unsupervised, competi ti ve learning.
By preventing cells in the
neighborhood of an active cell from modifying their afferent
connections in response to a pattern, they are left available for
capture of new patterns.
Suppose there are n cells in a
particular level.
The lateral inhibitory mechanism is specified
as follows:
eik(t)

=

0

If S . (t) = 1 then
for all i, tor k = (j-m)mod(n) to (j+m)mod(n)

(5)

Here, m specifies the size of a ""neighborhood.""
A neighborhood
significantly larger than a pattern set will result in a number of
untrained cells. A neighborhood smaller than the pattern set will
tend to cause cells to attempt to capture more than one pdttern.
Schematic representations of an individual cell and the
network organization are provided in Figures 1 and 2.
It is the pattern generator, or ""instructor"", that controls
the form that network organization will take. The initial set of
patterns are repeated until the first layer is trained.
Next, a
new pattern set is used to excite the lowermost (trained) level of
the network, and so, induce training in the next layer of the
hierarchy.
Each of the patterns of the new set is composed of
elements (or subpatterns) of the old set.
The structure of
successive pattern sets is such that each set is either a more
complex combination of elements from the previous set (as words
are composed of letters) or a generaliza tlon of some concept
implicit in the previous set (such as line orientation).
Network organization, as described above, requires some
exchange of control
signals between the
network and
the
instructor.
The instructor requires information regarding firing
of cells during training in order to switch to a new patterns
appropriately.
Obviously, if patterns are switched before any
cells fire, learning will either not take place or will be smeared
over a number of patterns.
If a single pattern excites the
network until one or more cells are fully trained, subsequent
presentation of a non-orthogonal pattern could cause the trained
cell to fire before any naive cell because of its saturated link
weights.
The solution is simply to allow gradual training over
the full complement of the pattern set.
After a few firings, a
new pattern should be provided.
After a layer has been trained,
the instructor provides a control signal to that layer which
permanently fixes the layer's afferent synaptic link weights.

712
Excitation

Lateral
Inhibtio~n
__~

Lateral
Inhibtion

Excitatory Inputs

Fig. 1.
Schematic of neuron.
Shading of afferent synaptic connections
indicates variations in levels of local
time-integrated excitation.

Fig. 2.
Schematic of network showing
lateral inhibition and forward excitation.
Shading of neurons, indicating degree of
training, indicates time-sequential
organization of successive neural layers.

713

SIMULATIONS
an example, simulations were run in which a network was
taught
to
differentiate
vertical
from
horizontal
line
orientation. This problem is of interest because it represents a
case in which pattern sets cannot be separated by a single layer
of connections.
This is so because the set of vertical (or
horizontal) lines has activity at all positions within the input
matrix.
Two variations were simulated. In the first simulation, the
input was a 4x4 matrix.
This was completely connected with
These cell$ had fixed
unidirectional links to 25 cells.
inhibi tory connections to the nearest five cells on either side
(using a circular arrangement), and excited, using complete
connectivity, a ring of eight cells, wi th inhibition over the
nearest neighbor on either side.
Ini tially, all excitatory link weights were small, random
numbers. Each pattern of the initial input consisted of a single
active row or column in the input matrix.
Active elements had,
during any clock cycle, a probability of 0.5 of being ""on"", while
inactive elements had a 0.05 probability of being ""on.""
After exposure to the initial pattern set, all cells on the
first layer captured some input pattern, and all eight patterns
had been captured by two or more cells.
The next pattern set consisted of two subsets of four
vertical and four horizontal lines.
The individual lines were
presented until a few firings took place within the trained layer,
and then another line from the same subset was used to excite the
network.
After the upper layer responed with a few firings, and
some training occured, the other set was used to excite the
network in a similar manner. After five cycles, all cells on the
uppermost layer had become sensitive, in a postionally independent
manner, to lines of a vertical or a horizontal orientation. Due
to
lateral
inhibition,
adj acent
cells
developed
opposite
orientation specificities.
In the second simulation, a 6x6 input matrix was connected to
six cells, which were, in turn, connected to two cells. For this
network, the lateral inhibitory range extended over the entire set
of cells of each layer.
The initial input set consisted of six
patterns, each of which was a pair of either vertical lines or
horizontal lines.
After excitation by this set, each of the six
middle level cells became sensitized to one of the input
patterns. Next, the set of vertical and horizontal patterns were
grouped into two sUDsets:
vertical lines and horizontal lines.
Individual patterns from one subset were presented until a cell,
of the previously trained layer, fired.
After one of the two
cells on the uppermost layer fired, the procedure was repeated
with the pattern set of opposite orientation.
After 25 cycles,
the two cells on the uppermost layer had developed opposite
orientation specificities.
Each of these cells was shown to be
responsive, in a positionally independent manner, to any single
As

714

line of appropriate orientation.
CONCLUSION
Competitive learning mechanisms, when applied sequentially to
successive layers in a hierarchical structure, can capture pattern
elements,
at
lower
levels
of
the
hierarchy,
and
their
generalizations, or abstractions, at higher levels.
In the above mechanism, learning is externally directed, not
by explicit teaching signals or back-propagation, but by provision
of
instruction
sets
consisting
of
patterns
of
increasing
complexity, to be input to the lowermost layer of the network in
concert with successive organization of higher neural layers.
The central difficulty of this method involves the design of
pattern sets - a procedure whose requirements may not be obvious
in all cases.
The method is, however, attractive due to its
simplicity of concept and design, providing for multi-level selforganization without direction by elaborate control signals.
Several research goals suggest themselves: 1) simplification
or elimination of control signals, 2) generalization of rules for
structuring of pattern sets, 3) extension of this learning
principle to recurrent networks,
and 4) gaining a deeper
understanding of the role of time as a factor in network selforganization.
REFERENCES
t.
2.
3.

D. E. Rumelhart and G.E. Hinton, Nature 323, 533 (1986).
K. A. Fukushima, BioI. Cybern. 55, 5 (1986).
D. E. Rumelhart and D. Zipser, Cog. Sci. 9, 75 (1985).

"
38,1987,"Distributed Neural Information Processing in the Vestibulo-Ocular System","",38-distributed-neural-information-processing-in-the-vestibulo-ocular-system.pdf,"Abstract Missing","457

DISTRIBUTED NEURAL INFORMATION PROCESSING
IN THE VESTIBULO-OCULAR SYSTEM
Clifford Lau
Office of Naval Research Detach ment
Pasadena, CA 91106
Vicente Honrubia*
UCLA Division of Head and Neck Surgery
Los Angeles, CA 90024
ABSTRACT
A new distributed neural information-processing
model is proposed to explain the response characteristics
of the vestibulo-ocular system and to reflect more
accurately the latest anatomical and neurophysiological
data on the vestibular afferent fibers and vestibular nuclei.
In this model, head motion is sensed topographically by hair
cells in the semicircular canals. Hair cell signals are then
processed by multiple synapses in the primary afferent
neurons which exhibit a continuum of varying dynamics. The
model is an application of the concept of ""multilayered""
neural networks to the description of findings in the
bullfrog vestibular nerve, and allows us to formulate
mathematically the behavior of an assembly of neurons
whose physiological characteristics vary according to their
anatomical properties.
INTRODUCTION
Traditionally the physiological properties of
individual vestibular afferent neurons have been modeled as
a linear time-invariant system based on Steinhausents
description of cupular motion. 1 The vestibular nerve input
to different parts of the central nervous system is usually
represented by vestibular primary afferents that have
*Work supported by grants NS09823 and NS08335 from the National
Institutes of Health (NINCDS) and grants from the Pauley Foundation and the
Hope for Hearing Research Foundation.

? American Institute of Physics 1988

458

response properties defined by population averages from
individual neurons. 2
A new model of vestibular nerve organization is
proposed to account for the observed variabilities in the
primary vestibular afferent's anatomical and physiological
characteristics. The model is an application of the concept
of ""multilayered"" neural networks,3,4 and it attempts to
describe the behavior of the entire assembly of vestibular
neurons based on new physiological and anatomical findings
in the frog vestibular nerve. It was found that primary
vestibular afferents show systematic differences in
sensitivity and dynamics and that there is a correspondence
between the individual neuron's physiological properties and
the location of innervation in the area of the crista and also
the sizes of the neuron's fibers and somas. This new view
of topological organization of the receptor and vestibular
nerve afferents is not included in previous models of
vestibular nerve function. Detailed findings from this
laboratory on the anatomical and physiological properties of
the vestibular afferents in the bullfrog have been
published. 5 ,6
REVIEW OF THE ANATOMY AND PHYSIOLOGY
OF THE VESTIBULAR NERVE

The most pertinent anatomical and physiological data
on the bullfrog vestibular afferents are summarized here.
In the vestibular nerve from the anterior canal four major
branches (bundles) innervate different parts of the crista
(Figure 1). From serial histological sections it has been
shown that fibers in the central bundle innervate hair cells
at the center of the crista, and the lateral bundles project
to the periphery of the crista. I n each nerve there is an
average of 1170 ? 171 (n = 5) fibers, of which the thick
fibers (diameter > 7.0 microns, large dots) constitute 8%
and the thin fibers ? 4.0 microns, small dots) 76%. The
remaining fibers (16%) fall into the range between 4.0 and
7.0 microns. We found that the thick fibers innervate only
the center of the crista, and the thinner ones predominantly
innervate the periphery.

459

400
(f)
~

w

())

H
LL

LL

o

~

w

())

L
::)

Z

00

2

4

6

8

DIAMETER

10

12

14

16

18

20

(micron)

Fig. 1. Number of fibers and their diameters in the anterior
semicircular canal nerve in the bullfrog.
There appears to be a physiological and anatomical
correlation between fiber size and degree of regularity of
spontaneous activity. By recording from individual neurons
and subsequently labeling them with horseradish peroxidase
intracellularly placed in the axon, it is possible to visualize
and measure individual ganglion cells and axons and to
determine the origin of the fiber in the crista as well as the
projections in different parts of the vestibular nuclei.
Figure 2 shows an example of three neurons of different
sizes and degrees of regularity of spontaneous activity. In
general, fibers with large diameters tend to be more
irregular with large coefficients of variation (CV) of the
interspike intervals, whereas thin fibers tend to be more
regular. There is also a relationship for each neuron
between CV and the magnitude of the response to
physiological rotatory stimuli, that is, the response gain.
(Gain is defined as the ratio of the response in spikes per
second to the stimulus in degrees per second.) Figure 3
shows a plot of gain as a function of CV as well as of fiber
diameter. For the more regular fibers (CV < 0.5), the gain
tends to increase as the diameter of the fiber increases.

460

y

-'x~
300um

THIN

MEDIUM

c v

c . V. = 0 . 25

11

o

200

THICK

= 0 39

,l. ,

o

200

c

V

=

0 61

..... I

I

200

MILLISECONDS

Fig. 2. Examples of thin, medium and thick fibers and their
spontaneous activity. CV - coefficient of variation.
For the more irregular fibers (CV > 0.5), the gain tends to
remain the same with increasing fiber diameter (4.9 ? 1.9
spikes/second/deg rees/seco nd).
Figure 4 shows the location of projection of the
afferent fibers at the vestibular nuclei from the anterior,
posterior, and horizontal canals and saccule. There is an
overall organization in the pattern of innervation from the
afferents of each vestibular organ to the vestibular nuclei,
with fibers from different receptors overlapping in various

461

-...?? 10

? ? ? ? ..
..
...???
.?I..? ....
..
.
...
.
.....
.
.
......
.
?
?
??
?
?
?

??

CI)

?

C)

-...?
CD
""C

??
?
?

CI)

?

~
.::t!!
a.
CI)

1

?

-

?

~.

~

?

?

??

?

?:?,i .....

?

?

?
?
? ?
?

I ?

? ?

c:

3.8

as

6. 1

(!)

8.4
10.7
Ff3ER DIAMETER

13.0

15.3

0.1r-~~~--~~~~--~~~~~

o

0.2

0.4

0.6

0.8

1

1.2

Coefficient of Variation
Fig. 3. Gain versus fiber diameters and CV. Stimulus was a
sinusoidal rotation of 0.05 Hz at 22 degrees/second peak
velocity.
parts of the vestibular nuclei. Fibers from the anterior
semicircular canal tend to travel ventrally, from the
horizontal canal dorsally, and from the posterior canal the
most dorsally.
For each canal nerve the thick fibers (indicated by
large dots) tend to group together to travel lateral to the
thin fibers (indicated by diffused shading); thus, the
topographical segregation between thick and thin fibers at
the periphery is preserved at the vestibular nuclei.
In following the trajectories of individual neurons in
the central nervous system, however, we found that each
fiber innervates all parts of the vestibular nuclei, caudally
to rostrally as well as transversely, and because of the
spread of the large number of branches, as many as 200
from each neuron, there is a great deal of overlap among the
projections.
DISTRIBUTED NEURAL INFORMATION-PROCESSING MODEL

Figure 5 represents a conceptual organization, based
on the above anatomical and physiological data, of Scarpa's

462

POST.

ANT.

-

..-

.. .

- - ? . "":r..~_..r""""

--:-.- .,.;,~??<'::-

..?
-,--i!'

HOIII.

/

;

-

SAC.
:.::~~C

--:-;~~

-~

-

-;7""

-~~

-~?

.;:.:::= =~~
--~

--..--

-~~

-;#'---

'"" -~ -~~-

,

Z~n_!=l.

r ~8
3OO)J
.,

Fig. 4. Three-dimensional reconstruction of the primary
afferent fibers' location in the vestibular nuclei.
ganglion cells of the vestibular nerve and their innervation
of the hair cells and of the vestibular nuclei. The diagram
depicts large Scarpa's ganglion cells with thick fibers
in nervating restricted areas of hair cells near the center of
the crista (top) and smaller Scarpa's ganglion cells with
thin fibers on the periphery of the crista innervating
multiple hair cells with a great deal of overlap among
fibers. At the vestibular nuclei, both thick and thin fibers
innervate large areas with a certain gradient of overlapping
among fibers of different diameters.
The new distributed neural information-processing
model for the vestibular system is based on this anatomical
organization, as shown in Figure 6. The response

463

H. C.

S. G.

v.

N.

Fig. 5. ft.natomical
organization of the
vestibular nerve.
H.C. - hair cells.
S.G. - Scarpa's
ganglion cells.
V.N. - vestibular
n ucle i.

H. C.

s.G.

V. N.

Fig. 6. Distributed neural information-processing model of
the vestibular nerve.

464

characteristic of the primary afferent fiber is represented
by the transfer function SGj(s). This transfer function
serves as a description of the gain and phase response of
individual neurons to angular rotation. The simplest model
would be a first-order system with d.c. gain Kj (spikesl
second over head acceleration) and a time constant Tj
(seconds) for the jth fiber as shown in equation (1):

SGj(s) = 1 + sT ..

(1 )

J

For the bullfrog, Kj can range from about 3 to 25
spikes/second/degree/second 2 , and Tj from about 10 to 0.5
second. The large and high-gain neurons are more phasic
than the small neurons and tend to have shorter time
constants. As described above, Kj and Tj for the jth neuron
are functions of location and fiber diameter. Bode plots
(gain and phase versus frequency) of experimental data
seem to indicate, however, that a better transfer function
would consist of a higher-order system that includes
fractional power. This is not surprising since the afferent
fiber response characteristic must be the weighted sum of
several electromechanical steps of transduction in the hair
cells. A plausible description of these processes is given in
equation (2):

SGj(s)

= 1:

Wjk 1 + s T k '

(2)

k
where gain Kk and time constant Tk are the electromechanical properties of the hair cell-cupula complex and
are functions of location on the crista, and Wjk is the
synaptic efficacy (strength) between the jth neuron and the
kth hair cell. In this context, the transfer function given
in equation (1) provides a measure of the ""weighted
average"" response of the multiple synapses given in
equation (2).

465

We also postulate that the responses of the vestibular
nuclei neurons reflect the weighted sums of the responses
of the primary vestibular afferents, as follows:
V N?1 = f ( l: T..IJ SG?)
J'

(3)

j
where f(.) is a sigmoid function describing the change in
firing rates of individual neurons due to physiological
stimulation. It is assumed to saturate between 100 to 300
spikes/second, depending on the neuron. Tij is the synaptic
efficacy (strength) between the ith vestibular neuron and
the jth afferent fiber.
C(l\JCLUSIONS
Based on anatomical and physiological data from the
bullfrog we presented a description of the organization of
the primary afferent vestibular fibers. The responses of
the afferent fibers represent the result of summated
excitatory processes. The information on head movement in
the assemblage of neurons is codified as a continuum of
varying physiological responses that reflect a sensoritopic
organization of inputs from the receptor to the central
nervous system. We postulated a new view of the
organization in the peripheral vestibular organs and in the
vestibular nuclei. This view does not require unnecessary
simplification of the varying properties of the individual
neurons. The model is capable of extracting the weighted
average response from assemblies of large groups of
neurons while the unitary contribution of individual neurons
is preserved. The model offers the opportunity to
incorporate further developments in the evaluation of the
different roles of primary afferents in vestibular function.
Large neurons with high sensitivity and high velocity of
propagation are more effective in activating reflexes that
require quick responses such as vestibulo-spinal and
vestibulo-ocular reflexes. Small neurons with high
thresholds for the generation of action potentials and lower
sensitivity are more tuned to the maintenance of posture

466

and muscle tonus. We believe the physiological differences
reflect the different physiological roles.
I n this emerging scheme of vestibular nerve
organization it appears that information about head
movement, topographically filtered in the crista, is
distributed through multiple synapses in the vestibular
centers. Consequently, there is also reason to believe that
different neurons in the vestibular nuclei preserve the
variability in response characteristics and the topological
discrimination observed in the vestibular nerve. Whether
this idea of the organization and function of the vestibular
system is valid remains to be proven experimentally.
REFERENCES
1. W. Steinhausen, Arch. Ges. Physio!. 217,747 (1927).
2. J. M. Goldberg and C. Fernandez, in: Handbook of
Physiology, Sect. 1, Vol. III, Part 2 (I. Darian-Smith,
ed., Amer. Physio!. Soc., Bethesda, MD, 1984), p. 977.
3. D. E. Rumelhart, G. E. Hinton and J. L. McClelland, in:
Parallel Distributed Processing: Explorations in the
Microstructure of Cognition, Vol. 1: Foundations
(D. E. Rumelhart, J. L. McClelland and the PDP Research
Group, eds., MIT Press, Cambridge, MA, 1986), p. 45.
4. J. Hopfield, Proc. Nat!. Acad. Sci. la, 2554 (1982).
5. V. Honrubia, S. Sitko, J. Kimm, W. Betts and I. Schwartz,
Intern. J. Neurosci. ~, 197 (1981).
6. V. Honrubia, S. Sitko, R. Lee, A. Kuruvilla and I. Schwartz,
Laryngoscope .aA., 464 (1984).

"
39,1987,"Capacity for Patterns and Sequences in Kanerva's SDM as Compared to Other Associative Memory Models","",39-capacity-for-patterns-and-sequences-in-kanervas-sdm-as-compared-to-other-associative-memory-models.pdf,"Abstract Missing","412

CAPACITY FOR PATTERNS AND SEQUENCES IN KANERVA'S SDM
AS COMPARED TO OTHER ASSOCIATIVE MEMORY MODELS
James O. Keeler

Chemistry Department, Stanford University, Stanford, CA 94305
and RIACS, NASA-AMES 230-5 Moffett Field, CA 94035.
e-mail: jdk@hydra.riacs.edu
ABSTRACT

The information capacity of Kanerva's Sparse, Distributed Memory (SDM) and Hopfield-type
neural networks is investigated. Under the approximations used here, it is shown that the total information stored in these systems is proportional to the number connections in the network. The proportionality constant is the same for the SDM and HopJreld-type models independent of the particular model, or the order of the model. The approximations are
checked numerically. This same analysis can be used to show that the SDM can store sequences of spatiotemporal patterns, and the addition of time-delayed connections allows the
retrieval of context dependent temporal patterns. A minor modification of the SDM can be
used to store correlated patterns.
INTRODUCTION
Many different models of memory and thought have been proposed by scientists over the
years. In (1943) McCulloch and Pitts prorosed a simple model neuron with two states of activity
(on and off) and a large number of inputs. Hebb (1949) considered a network of such neurons and
postulated mechanisms for changing synaptic strengths 2 to learn memories. The learning rule
considered here uses the outer-product of patterns of +Is and -Is. Anderson (1977) discussed the
effect of iterative feedback in such a system.) Hopfield (1982) showed that for symmetric connections,4 the dynamics of such a network is governed by an energy function that is analogous to the
energy function of a spin glass ..5 Numerous investigations have been carried out on similar
models. 6-8
Several limitations of these binary interaction, outer-product models have been pointed out.
For example, the number of patterns that can be stored in the system (its capacity) is limited to a
fraction of the length of the pattern vectors. Also, these models are not very successful at storing
correlated patterns or temporal sequences.
Other models have been proposed to overcome these limitations. For example, one can
allow higher-order interactions among the neurons. 9 ?10 In the following, I focus on a model
developed by Kanerva (1984) called the Sparse, Distributed Memory (SOM) model. J1 The SOM
can be viewed as a three layer network that uses an outer-product learning between the second and
third layer. As discussed below, the SDM is more versatile than the above mentioned networks
because the number of stored patterns can increased independent of the length of the pattern. and
the SDM can be used to store spatiotemporal patterns with context retrieval. and store correlated
patterns.
The capacity limitations of outer-product models can be alleviated by using higher-order
interaction models or the SOM, but a price must be paid for this added capacity in tenns of an
increase in the number of connections. How much information is gained per connection? It is
shown in the following that the total infonnation stored in each system IS proportional to the
number of connections in the network. and that the proportionality constant is independent of the
particular model or the order of the model. This result also holds if the connections are limited to
one bit of precision (clipped weights). The analysis presented here requires certain simplifying
assumptions. The approximate results are compared numerically to an exact calculation developed
by Chou. 12
SIMPLE OUTER?PRODUCT NEURAL NETWORK MODEL
As an example or a simple first-order neural network model, I consider in detail the model
developed by Hopfield.4 This model will be used to introduce the mathematics and the concepts
that will be generalized for the analysis of the SOM. The ""neurons"" are simple two-state

? American Institute of Phv!lir.s 19M

413

threshold devices: The state of the i'"" neuron. Uj. is either either +1 (on). or -1 (off). Consider a
set of n such neurons with net input (local field). h j ? to the i'"" neuron given by
/I

=V j j

hj

(1)

Uj.

j

where T jj represents the interaction strength between the i'"" neuron and the j""'. The state of each
neuron is updated asynchronously (at random) according to the rule

+-g (h j ).
where the function g is a simple threshold function g (x)

(2)

Uj

= sign (x).

Suppose we are given M randomly chosen patterns (strings of length n of ?ls) which we
wish to store in this system. Denote these M memory patterns as pattern vectors:
pQ = (p f,pf .... ,p""Q).
ex = 1.2.3, ... ,M.
For
example.
pI
might
look
like
(+1,-1.+1,-1.-1 ?...?+1). One method of storing these patterns is the outer-product (Hebbian) learning rule: Start with T=O, and accumulate the outer-products of the pattern vectors. The resulting
connection matrix is given by
T jj

=

M

LPjQpt,

Tjj

=o.

(3)

=1

The system described above is a dynamical system with attracting fixed points. To obtain
an approximate upper bound on the total information stored in this network. we sidestep the issue
of the basins of attraction, and we check to see if each of the patterns stored by Eq. (3) is actually
a fixed point of (2). Suppose we are given one of the patterns, p~, say, as the initial configuration
of the neurons. I will show that p~ is expected to be a fixed point of Eq. (2). After inserting (3)
for T into (1), the net input to the i'"" neuron becomes
hj

M

""

=1

j

= LPt[ L ptpl]?

(4)

The important term in the sum on ex is the one for which ex =~ . This term represents the ? 'signal"" between the input p~ and the desired output. The rest of the sum represents ""noise"" resulting from crosstalk with all of the other stored patterns. The expression for the net input becomes
h j = signal; + noisej where

signalj

=Pj~[L"" pI pI],

(5)

j

noisej

M

=L

pjQ[

""

2. pt pI]?

(6)

Q;t~

Summing on all of the h, in (6) yields signalj = (n-l)pj~. Since n is positive, the sign of
the signal term and pj~ will be the same. Thus. if the noise term were exactly zero, the signal
would give the same sign as pj~ with a magnitude of:: n d ? and p~ would be a fixed point of (2).
Moreover, patterns close to pI' would give nearly the same signal, so that p~ should be an attracting fixed point.
For randomly chosen patterns. <noise> = 0, where < > indicates statistical expectation. and
its variance will be a'- = (n-l)d (M -1). The probability that there will be an error on recall of pj~
is given by the probability that the noise is greater than the signal. For n large, the noise distribution is approximately gaussian, and the probability that there is an error in the i'"" bit is
(7)

INFORMATION CAPACITY
The number of patterns that can be stored in the network is known as its capacityP?14 However, for a fair comparison between all of the models discussed here. it is more relevant to compare the total number of bits (total information) stored in each model rather than the number of

414

patterns. This allows comparison of information storage in models with different lengths of the
pattern vectors. If we view the memory model as a black box which receives input bit strings and
outputs them with some small probability of error in each bit, then the definition of bit-capacity
used here is exactly the definition of channel capacity used by Shannon. 1S
Define the bit-capacity as the number of bits that can be stored in a network with fixed probability of ~etting an error in a recalled bit, i.e. Pe = constant in (10). Explicitly, the bit-capacity
is given by 6

B

= bit

capacity

=nMll,

(8)

where 11 = (I + Pelog2fJe + (l-Pe )log2(I-Pe)). Note that 11=1 for Pe =0. Setting Pe to a constant is
tantamount to keeping the signal-to-noise ratio (fidelity) constant, where the fidelity, R, is given by
R
I signail/a. Explicitly, the relation between (constant) Pe and R, is just R = ~-I(l - Pe ),
where

=

R

~R)

= (1I2Jt)'h Je-t212dt.

(9)

Hence, the bit-capacity of these networks can be investigated by examining the fidelity of the
models as a function of n, M, and R. From (8) and (9) the fidelity of the Hopfield model is is
R2 nl(n(M-l?Y.. (n>I). Solving for M in terms of (fixed) R and 11, the bit-capacity becomes

=

B

=l1[(n 2IR 2)+n].

The results above can be generalized to models with d th order interactions.17,18 The resulting
expression for the bit-capacity for d,h order interaction models is just
n d +1
B =11[-2 +n].
(10)
R
Hence, we see that the number of bits stored in the system increases with the order d. However,
to store these bits, one must pay a price by including more connections in the connection tensor.
To demonstrate the relationship between the number of connections and the information stored,
define the information capacity, y, to be the total information stored in the network divided by the
number of bits in the connection tensor (note that this is different than the definition used by AbuMostafa et al.).19 Thus y is just the bit-capacity divided by the number of bits in the tensor T {
and represents the efficiency with which information is stored in the network. Since T has n d +
elements, the information capacity is found to be
Y -....!L
2

- R b'

(11)

where b is the number of bits of precision used per tensor element (b ~ log2M for no clipping of
the weights). For large n, the information stored per neuronal coimection is y = lllR 2b, independent of the order of the model (compare this result to that of Peretto, et al.).11J To illustrate this
point, suppose one decides that the maximum allowed probability of getting an error in a recalled
bit is Pe = 111000, then this would fix the minimum value of R at 3.1. Thus, to store 10,000 bits
with a probability of getting an error of a recalled bit of 0.001, equation (15) states that it would
take =96,OOOb bits, independent of the order of the model, or =O.ln patterns can be stored with
probability 111000 of getting an error in a recalled bit.
KANERVA'S SDM
Now we focus our attention on Ka.nerva's Sparse, Distributed Memory model (SDM).l1 The
SDM can be viewed as a 3-layer network with the middle layer playing the role of hidden units.
To get an autoassociative network, the output layer can be fed back into the input layer, effectively
making this a two layer network. The first layer of the SDM is a layer of n, ?l input units (the
input address, a), the middle layer is a layer of m, hidden units, S, and the third layer consists of
the n ?l output units (the data, d). The connections between the input units and the hidden units
are random weights of ?I and are given by the m xn matrix A. The connections between the hidden units and the output units are given by the n xm connection matrix C, and these matrix elements are modified by an outer-product learning rule (C ii analogous to the matrix T of the
Hopfield model).

415

Given an input pattern a, the hidden unit activations are determined by
s = Or (A a),

(12)

where Or is the Hamming-distance threshold function: The k'"" element is 1 if the input a is at
most r Hamming units away from the k,1t row in A, and 0 if it is further than r units away, i.e.,
?r(x)j =

{

I if Y2(n -Xj)~
0 if Y2(n-x;?r .

(13)

The hidden-units vector, or select vector, s, is mostly Os with an average of Sm 1s, where S is
some small number dependent on r; S<l. Hence, s represents a large. sparsely coded vector of Os
and SIs representing the input address. The net input, h. to the final layer can be simply expressed
as the product of C with s:

h= Cs.

(14)

Finally, the output data is given by d = g(h), where gj (h j ) = sign (h j ).
To store the M patterns, pl,p2, ... pM, form the outer-product of these pattern vectors and
their corresponding select vectors,
(15)

where T denotes the trampose of the vector, and where each select vector is formed by the
corresponding address, so. = Or (A pa). The storage algorithm (15) is an outer-product learning rule
similar to (3).
Suppose that the M patterns (pl,p2, ... pM) have been stored according to (15). Following
the analysis presented for the Hopfield model, I show that if the ~stem is presented with p~ as
input, the output will be p~. (i.e. p~ is a fixed point). Setting a = p in (16) and separating terms
as before. the net input (18) becomes
M

h

= dl3(s~'s~) + L

pa(sa?s~).

(16)

a.t~

where the first term represents the signal and the second is the noise. Recall that the select vectors
have an average of Sm Is and the remainder Os, so that the expected value of the signal is &n srJ.
Assuming that the addresses and data are randomly chosen, the expected value of the noise
is zero. To evaluate the fidelity, I make certain approximations. First, I assume that the select vectors are independent of each other. Second, I assume that the variance of the signal alone is zero
or small compared to the variance of noise term alone. The first assumption will be valid for
m S2<1, and the second assumption will be valid for M S>l. With these assumptions, we can
easily calculate the variance of the noise term, because each of the select vectors are i.i.d. vectors
of length m with mostly Os and::&n Is. With these assumptions, the fidelity is given by
(17)

In the limit of large m , with Sm :: constant, the number of stored bits scales as
mn
B - n[
+ n]
- '. R2(1+S2m)

.

(18)

If we divide this by the number of elements in C, we find the information capacity, y = 1l1R2b,
just as before, so the information capacity is the same for the two models. (If we divide the bit
capacity by the number of elements in C and A then we get y =1lIR2(b+1), which is about the
same for large M .)
A few comments before we continue. FIrst, it should be pointed out that the assumption
made by Kanerva 11 and Keeler 17 ,18 that the variance of the signal term is much less than that of
the noise is not valid over the entire range. If we took this infO account, then the magnitude of the
denominator would be increased by the variance of the signal term. Further, if we read at a distance I away from the write address, then it is easy to see that the signal changes to be m S(l),
where &(1) the overlap of two spheres of radius r length I apart in the binomial space n

416

(8 = ~O?. The fidelity for reading at a distance I away from the write address is

m 2 82(l)
R2-----------------~~----~~----- m~IXl~l) + (M-l)m82+(M-l)84m2(I-lIm) '

(19)

Compare this to the formula derived by ChOU,12 for the exact signal-to-noise ratio:

m 282(l)
R2-----------------~~~
- m~IXI_8(I?

____ ________
~

+ (M-l)mJ.l.. "".+(M-l)0;"".m2(I-lIm? '

(20)

where J.l.. "" is the average overlap of the spheres of radius r binomially distributed with parameters
is the square of this overlap. The difference in these two formulas lies in the
denominator in the terms 82 verses J.l.. "". and 84 vs. 0;"".. The difference comes from the fact that
Chou correctly calculates the overlap of the spheres without using the independence assumption.
How do these formula's differ? First of all, it is found numerically that 82 is identical with
J.l.. "".. Hence, the only difference comes from 84 verses 0;"".. For m82 < 1, the 84 term is negligible compared to the other terms in the denominator. In addition, 84 and 0 2 are approximately
equal for large n and r=n 12. Hence, in the limit n ~oo the two fonnulas agree over most of the
range if M=O.lm, m<2"". However, for finite n, the two fonnulas can disagree when m82=1 (see
Figure 1).
(n ,112) and

cr

30

Signal-to-Noise Ratios

20

+ Eq. (17)
o Eq. (19)
* Eq. (20)

10

o

o

20

40

60

80

Hamming Radius
Figure 1: A ~omparison of the fidelity calculations of the SDM for typical n, M, andm

values. Eq~atlon (17) .was derived assuming no variance of the signal term, and is shown
~y the + line. Equauon (19) ~ses the approximation that all of the select vectors are
indePf2ndeot denoted by the 0 line. EquatIon (20) (?'s) is the exact derivation done by
Chou . The values used here were n 150, m = 2000, M = 100.

=

417

Equation (20) suggests that the5 is a best read-write Hamming radius for the SOM. By setting I

=0

in (19) and by setting

~ = 0,

we get an approximate expression for the best Ham-

8""..., =(2Mntll3. This ttend is qualitatively shown in Figure 2.

ming radius:

II)
Q)

u

c:
o

L.

:>
I.)
I.)

o

......o
o

Figure 2: Numerical investigation of the capacity of the SOM. The vertical axis is the percent of recovered patterns with no errors. The x-axis (left to right) is the Hamming distance used for reading and writing. The y-axis (back to forward) is the number of patterns
that were written into the memory. For this investigation, n = 128, m = 1024, and M
ranges from 1 to 501. Note the similarity of a cross-section of this graph at constant M
with Figure 1. This calculation was performed by Oavid Cohn at RIACS, NASA-Ames.

Figure 1 indicates that the fonnula (17) that neglected the variance of the signal term is
incorrect over much of the range. However, a variant of the SOM is to constrain the number of
selected locations to be constant; circuitry for doing this is easily built. 21 The variance of the signal term would be zero in that case, and the approximate expression for the fidelity is given by Eq.
(17). There are certain problems where it would be better to keep 8 = constant, as in the case of
correlated patterns (see below).
The above analysis was done assuming that the elements (weights) in the outer-product
matrix are not clipped i.e. that there are enough bits to store the largest value of any matrix element It is interestmg to consider what happens if we allow these values to be represented by only
a few bits. If we consider the case case b = 1, i.e. the weights are clipped at one bit, it is easy
to show l7 that r-2llf1tR:Z for the d th older models and for the SOM, which yields y = 0.07 for reasonable R, (this is substantially less than Willsbaw's 0.69).

418

SEQUENCES
In an autoassociative memory, the system relaxes to one of the stored patterns and stays
fixed in time until a new input is presented. However, there are many problems where the recalled
patterns must change sequentially in time. For example, a song can be remembered as a string of
notes played in the correct sequence; cyclic patterns of muscle contractions are essential for walking, nding a bicycle, or dribbling a basketball. As a first step we consider the very simplistic
sequence production as put forth by Hopfield (1982) and Kanerva (1984).
Suppose that we wished to store a sequence of patterns in the SOM. Let the pattern vectors
be given by (p 1,p2, ...? pM). This sequence of patterns could be stored by having each pattern
point to the next pattern in the se~uence. Thus, for the SOM, the patterns would be stored as
mput-output pairs (aIX,dIX), where a =pIX and d lX = pa+l for a = 1,2.3,... ,M -1. Convergence to
this sequence works as follows: If the SOM is presented with an address that is close to p i the
read data will be close to p2. Iterating the system with p2 as the new input address, the read data
will be even closer to p3. As this iterative process continues, the read data will converge to the
stored sequence, with the next pattern in the sequence being presented at each time step.
The convergence statistics are essentially the same for sequential patterns as that shown
above for autoassociative patterns. Presented with pIX as an input address, the signal for the stored
sequence is found as before

<signal>

= Om pIX+l.

(21)

Thus, given pIX, the read data is expected to be pCX+l. Assuming that the patterns in the sequence
are randomly chosen, the mean value of the noise is zero, with variance

<a2>

= (M-l)82m(I+82(m-l?.

(22)

Hence, the length of a sequence that can be stored in the SOM increases linearly with m for large

m.
Attempting to store sequences like this in the Horfield model is not very successful due to
the asynchronous updating use in the Hopfield mode. A synchronously updated outer-product
model (for example [6]) would work just as described for the SOM, but it would still be limited to
storing fraction of the word size as the maximum sequence length.
Another method for storing sequences in HOp'field-like networks has been proposed independently by Kleinfeld 22 and Sompolinsky and Kanter. 23 These models relieve the problem created by
asynchronous updating by using a time-delayed sequential term. This time-delay storage algorithm
has different dynamics than the synchronous SOM model. In the time-delay algorithm, the system
allows time for the units to relax to the first pattern before proceeding on to the next pattern.
whereas in the synchronous algorithms, the sequence is recalled imprecisely from imprecise input
for the first few iterations and then correctly after that. In other words. convergence to the
sequence takes place ""on the fly"" in the synchronous models - the system does not wait to zero
in on the fitst pattern before proceeding on to recover the following patterns. 1bis allows the synchronous algorithms to proceed k times as fast as the asynchronous time-delay algorithms with
half as many (variable) matrix elements. This difference should be able to be detected in biological
systems.
TIME DELAYS AND HYSTERESIS: FOLDS

The above scenario for storing sequences is inadequate to explain speech recognition or pattern generation. For example, the above algorithm cannot store sequences of the form ABAC ? or
overlapping sequences. In Kanerva's original work, he included the concept of time delays as a
general way of storing sequences with hysteresis. The problem addressed by this is the following:
Suppose we wish to store two sequences of patterns that overlap. For example, the two pattern
sequences (a,b,c,d,e,f.... ) and (x,y,z,d,w,v, ... ) overlap at the pattern d. If the system only has
knowledge of the present state, then when given the input d, it cannot decide whether to output w
or e. To store two such sequences, the system must have some knowledge of the immediate past.
Kanerva incoIporates this idea into the SOM by using .. folds."" A system with F +1 folds has a
time history of F past states. These F states may be over the past F time steps or they may go
even further back in time, skipping some time steps. The algorithm for reading from the SOM with
folds becomes
d(t+l)

= g(Co's(t) + C l'S(t-'tl) + ... + C F 'S(t-'tF?,

(23)

419

where

s(t-'t~= 9r(Aa(t-'t~?.

(Pi.pi..... P2

(pl.Pf..... p~l).

Tg store the Q pattern sequences
2)?... (P~.pJ .... ,PQCl), construct the matrix of the W"" fold as follows:
~

QMtJ

C~ = w~IL.p~+lxsa tJ.

(24)

a.1~1

where any vector with a superscript less than 1 is taken to be zero. s~~"" = 9r(Ap~-~""), and w~ is a
weighting factor that would normally decrease with increasing ~.
Why do 3tese folds work? Suppose that the system is presented with the pattern sequence
(pl,pr..... PI I). with each pattern presented sequentially as input until the 'tF time step. For
simplicity. assume that w~ = 1 for all~. Each tenn in Eq. (39) will contribute a signal similar to
the signal for the single-fOld system. Thus. on the i!"" time step. the signal term coming from Eq.
(39) is <signal(t+l? = F&nptl. The signal will have this value until the end of the pattern
'The mean of the noise tenns is zero. with variance
sequence is reached.
<noiseZ:> = F (M -1 )82m (1 +82(m -1?. Hence. the signal-to-noise ratio is ff times as strong as it
is for the SDM without folds.
Suppose further that the second stored pattern sequence happens to match the first stored
sequence at t = 'to The signal term would then be
signal(t+l) = F8mp(+""1 + ampr l .
(25)
With no history of the past (F = 1) the signal is split between p~+l and JJ21+I. and the output is
ambiguous. However. for F>I. the signal for the first pattern sequence dominates and allows
retrieval of the remainder of the correct sequence. lbis formulation allows context to aid in the
retrieval of stored sequences. and can differentiate between overlapping sequences by using time
delays.
The above formulation is still too simplistic in terms of being able to do real recognition
problems such as speech recognition. First. the above algorithm can only recall sequences at a
fixed time rate, whereas speech recognition occurs at widely varying rates. Second. the above
algorithm does not allow for deletions in the incoming data. For example ""seqnce"" can be recot
nized as ""sequence"" even though some letters are missing. Third, as pointed out by Lashley
speech processing relies on hierarchical structures.
Although Kanerva's original algorithm is too simplistic. a straightforward modification
allows retrieval at different rates with deletions. To achieve this, we can add on the time-delay
terms with weights which are smeared out in time. Kanerva's (1984) formulation can thus be
viewed as a discrete-time formulation of that put forth by Hopfield and Tank, (1987).15 Explicitly
we could write
F

h

~

= L. I

W~C~s(t-'t~),

(26)

~= I A:=~F

where the coefficients W ~ are a discrete approximation to a smooth function which spreads the
delayed signal out over tlme. As a further step, we could modify these weights dynamically to
optimize the signal coming out. The time-delay patterns could also be placed in a hierarchical
structure as in the matched filter avalanche structure put forth by Grossberg et al. (1986).26
CORRELATED PAITERNS
In the above associative memories. all of the patterns were taken to be randomly chosen.
unifonnly distributed binary vectors of length n. However, there are many applications where the
set of input patterns is not uniformly distributed; the input patterns are correlated. In mathematical
terms, the set K of input patterns would not be uniformly distributed over the entire space of 2/1
possible patterns. Let the probabi1i!)' distribution function for the Hamming distance between two
randomly chosen vectors pQ and p~ from the distribution K be given by the function p(d(pQ-p~?,
where d(x-y) is the Hamming distance between x and y.
'The SDM can be generalized from Kanerva's original fonnulation so that correlated input
patterns can be associated with output patterns. For the moment, assume that the distribution set
K and the probability density function p(x) are known a priori. Instead of constructing the rows
of the matrix A from the entire space of 2"" patterns, construct the rows of A from the distribution
1C. Adjust the Hamming distance r so that ~ =
= constant number of locations are selected.

am

420

In other words, adjust r so that the value of
by

a is the same as given above, where a is detennined

r

[P(X )dx

a=--2/1

(27)

This implies that r would have to be adjusted dynamical!-y. This could be done, for example, by a
feedback loop. Circuitry for doing this is easily built, and a similar structure appears in the
Golgi cells in the Cerebellum.27.
Using the same distribution for the rows of A as the distribution of the patterns in 1C. and
using (27) to specify the choice of r, all of the above analysis is applicable (assuming randomly
chosen output patterns). If the outputs do not have equal Is and -Is the mean of the noise is not
O. However, if the distribution of outputs is also known, the system can still be made to work by
storing IIp+ and IIp_ for Is and -Is respectively, where p? is the probability of getting a 1 or a-I
respectively. Using this storage algorithm, all of the above formulas hold, (as long as the distribution is smooth enough and not extremely dense). The SOM will be able to recover data stored
with correlated inputs with a fidelity given by Equation (17).
What if the distribution function K is not known a priori? In that case, we would need to
have the matrix A learn the distribution p(x). There are many ways to build A to mimic p. One
such way is to start with a random A matrix and modify the entries of randomly chosen rows of
A at each step accordinft!o the statistics of the most recent input patterns. Another method is to
use competitive learning 30 to achieve the proper distribution of At.
The competitive learning algorithm is a method for adjusting the wei~hts A;j between the
first and second layer to match this probability density function, p(x). The i row of the address
matrix A can be viewd as a vector A,. The competitive learning algorithm holds a competition
between these vectors, and a few vectors that are the closest (within the Hamming sphere r) to the
input pattern x are the winners. Each of these winners are then modified slightly in the direction
of x. For large eno~ m, this algorithm almost always converges to a distribution of the Aj that
is the same as p(x).
The updating equation for the selected addresses is just

a

A;'''""''' = Arid - 'A.{Arld - x)
Note for A. = I, this reduces to the so-called unary representation of Baum et al.
the maximum efficiency in terms of capacity.

(28)
31

Which gives

DISCUSSION
The above analysis said nothing about the basins of attraction of these memory states. A
measure of the perfonnance of a content addressable memory shoUld also say something about the
avera~e radius of convergence of the basin of attraction. The basins are in general quite complicated and have been investigated numerically for the unclipped models and values of n and m
ranging in the 100S.21 The basins of attraction for the SOM and the d=1 model are very similar in
their characteristics and their average radius of convergence. However, the above results give an
upper bound on the capacity by looking at the fixed points of the system (if there is no fixed point,
there is no basin).
In summary, the above arguments show that the total information stored in outer-product
neural networks is a constant times the number of connections between the neurons. This constant
is independent of the order of the model and is the same (1lIR2b) for the SOM as well as higherorder Hopfield-type networks. The advantage of going to an architecture like the SOM is that the
number of patterns that can be stored in the network is independent of the size of the pattern,
whereas the number of stored patterns is limited to a fraction of the word size for the Wills haw or
Hopfield architecture. The point of the above analysis is that the efficiency of the SOM in terms
of information stored per bit is the same as for Hopfield-type models.
It was also demonstrated how sequences of patterns can be stored in the SOM, and how time
delays can be used to recover contextual information. A minor modification of the SOM could be
used to recover time sequences at slightly different rates of presentation. Moreover, another minor
modification allows the storage of correlated patterns in the SOM. With these modifications, the
SOM presents a versatile and efficient tool for investigating properties of associative memory.

421

Acknowledgements: Discussions with John Hopfield and Pentti Kanerva are gratefully acknowledged. This work: was supported by DARPA contract # 86-A227500-000.

[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
[18]
[20]
[21]

[22]
[23]
[24]
[25]
[26]
[27]
[28]
[29]
[30]
[31]

REFERENCES
McCulloch, W. S. & Pitts, W. (1943), Bull. Math. Biophys. 5, 115-133.
Hebb, D. O. (1949) The Organization of Behavior. John Wiley, New York.
Anderson, J. A., Solverstein, J. W., Ritz, S. A. & Jones, R. S. (1977) Psych. Rev., 84,
412-451.
Hopfield, J. J. (1982) Proc. Natn'l. Acad. Sci. USA 79 2554-2558.
Kirkpatrick, S. & Sherringtoo, D. (1978) Phys Rev. 174384-4405.
Little, W. A. & Shaw, G. L.(l978)Math. Biosci. 39, 281-289.
Nakano, K. (1972), Association - A model of associative memory. IEEE Trans. Sys. Man
Cyber.2,
Willshaw, D. 1., Buneman, O. P. & Longuet-Higgins, H. c., (1969) Nature, 222 960-962.
Lee, Y. c.; Doolen, G.; Chen. H. H.; Sun, G. Z.; Maxwell, T.; Lee, H. Y.; & Giles, L.
(1985) Physica , 22D, 276-306.
Baldi, P., and Venkatesh. S. S .? (1987) Phys. Rev. Lett. 58, 913-916.
Kanerva, P. (1984) Self-propagating Search: A Unified Theory of Memory, Stanford
University Ph.D. Thesis, and Bradford Books (MIT Press). In press (1987 est).
Chou, P. A., The capacity of Kanerva's Associative Memory these proceedings.
McEliece, R. J., Posner, E. C., Rodemich, E. R., & Venkatesh, S. S. (1986), IEEE Trans.
on Information Theory.
Amit, D. J., Gutfreund, H. & Sompolinsky, H. (1985) Phys. Rev. Lett. 55, 1530-1533.
Shannon, C. E., (1948), Bell Syst. Tech. J., 27, 379,623 (Reprinted in Shannon and Weaver
1949) .
Kleinfeld, D. & Pendergraft, D. B., (1987) Biophys. J. 51, 47-53.
Keeler, J. D. (1986), Comparison of Sparsely Distributed Memory and Hopfield-type Neural
Network Models. RIACS Technical Report 86-31, also submitted to J. Cog. Sci.
Keeler, J. D. (1987) Physics Letters 124A, 53-58.
Abu-Mostafa, Y. & St. Jacques, (1985), IEEE Trans. on Info. Theor., 31, 461.
Keeler, J. D .? Basins of Attraction of Neural Network Models AIP Conf. Proc. #151, Ed:
John Denker, Neural Networks for Computing, Snowbird Utah, (1986).
Peretto, P. & J.J. Niez, (1986) BioI. Cybem., 54. 53-63.
Keeler, J. D., Ph. D. Dissertation. Collective phenomena of coupled lattice maps: Reactiondiffusion systems and neural networks. Department of Physics. University of California, San
Diego, (1987).
Kleinfeld, D. (1986). Proc. Nat. Acad. Sci. 83 9469-9473.
Sompolinsky, H. & Kanter, I. (1986). Physical Review Letters.
Lashley, K. S. (1951). Cerebral Mechanisms in Behavior. Edited by Jeffress, L. A. Wiley,
New York, 112-136.
Hopfield, J. 1. & Tank, D. W. (1987). ICNN San Diego preprint.
Grossberg, S. & Stone, G. (1986). Psychological Review, 93, 46-74
Marr, D. (1969). A Journal of Phisiology, 202, 437-470.
Grossberg, S. (1976). Biological Cybernetics 23, 121-134.
Kohonen, T. (1984) Self-organization and associative memory. Springer-Verlag, Berlin.
Rumelhart, D. E. & Zipser, D. J. Cognitive Sci .. 9, (1985), 75.
Baum, E., Moody J., Wilczek F. (1987). Preprint for Biological Cybernetics

"
40,1987,"Neural Networks for Template Matching: Application to Real-Time Classification of the Action Potentials of Real Neurons","",40-neural-networks-for-template-matching-application-to-real-time-classification-of-the-action-potentials-of-real-neurons.pdf,"Abstract Missing","103

NEURAL NETWORKS FOR TEMPLATE MATCHING:
APPLICATION TO REAL-TIME CLASSIFICATION
OF THE ACTION POTENTIALS OF REAL NEURONS
Yiu-fai Wongt, Jashojiban Banikt and James M. Bower!
tDivision of Engineering and Applied Science
!Division of Biology
California Institute of Technology
Pasadena, CA 91125

ABSTRACT
Much experimental study of real neural networks relies on the proper classification of
extracellulary sampled neural signals (i .e. action potentials) recorded from the brains of experimental animals. In most neurophysiology laboratories this classification task is simplified
by limiting investigations to single, electrically well-isolated neurons recorded one at a time.
However, for those interested in sampling the activities of many single neurons simultaneously,
waveform classification becomes a serious concern. In this paper we describe and constrast
three approaches to this problem each designed not only to recognize isolated neural events,
but also to separately classify temporally overlapping events in real time. First we present two
formulations of waveform classification using a neural network template matching approach.
These two formulations are then compared to a simple template matching implementation.
Analysis with real neural signals reveals that simple template matching is a better solution to
this problem than either neural network approach.

INTRODUCTION
For many years, neurobiologists have been studying the nervous system by
using single electrodes to serially sample the electrical activity of single neurons in the brain. However, as physiologists and theorists have become more
aware of the complex, nonlinear dynamics of these networks, it has become
apparent that serial sampling strategies may not provide all the information
necessary to understand functional organization. In addition, it will likely be
necessary to develop new techniques which sample the activities of multiple
neurons simultaneouslyl. Over the last several years, we have developed two
different methods to acquire multineuron data. Our initial design involved
the placement of many tiny micro electrodes individually in a tightly packed
pseudo-floating configuration within the brain 2 . More recently we have been
developing a more sophisticated approach which utilizes recent advances in
silicon technology to fabricate multi-ported silicon based electrodes (Fig. 1) .
Using these electrodes we expect to be able to readily record the activity patterns of larger number of neurons.
As research in multi-single neuron recording techniques continue, it has become very clear that whatever technique is used to acquire neural signals from
many brain locations, the technical difficulties associated with sampling, data
compressing, storing, analyzing and interpreting these signals largely dwarf the
development of the sampling device itself. In this report we specifically consider
the need to assure that neural action potentials (also known as ""spikes"") on
each of many parallel recording channels are correctly classified, which is just
one aspect of the problem of post-processing multi-single neuron data. With
more traditional single electrode/single neuron recordings, this task usually in? American Institute or Physics 1988

104

volves passing analog signals through a Schmidt trigger whose output indicates
the occurence of an event to a computer, at the same time as it triggers an
oscilloscope sweep of the analog data. The experimenter visually monitors the
oscilloscope to verify the accuracy of the discrimination as a well-discriminated
signal from a single neuron will overlap on successive oscilloscope traces (Fig.
Ic). Obviously this approach is impractical when large numbers of channels
are recorded at the same time. Instead, it is necessary to automate this classification procedure. In this paper we will describe and contrast three approaches
we have developed to do this .

Traces
on upper
layer

~

'a.
E

IV

1~
0

Traces

4

2
Ume (msec)

on lower
layer

C. ,

&.

Recording s~e

b.

75sq.jllT1

Fig. 1. Silicon probe being developed in our lababoratory for multi-single unit recording
in cerebellar cortex. a) a complete probe; b) surface view of one recording tip; c) several
superimposed neuronal action potentials recorded from such a silicon electrode ill cerebellar
cortex.

While our principal design objective is the assurance that neural waveforms
are adequately discriminated on multiple channels, technically the overall objective of this research project is to sample from as many single neurons as
possible. Therefore, it is a natural extention of our effort to develop a neural
waveform classification scheme robust enough to allow us to distinguish activities arising from more than one neuron per recording site. To do this, however,
we now not only have to determine that a particular signal is neural in origin,
but also from which of several possible neurons it arose (see Fig. 2a). While
in general signals from different neurons have different waveforms aiding in
the classification, neurons recorded on the same channel firing simultaneously
or nearly simultaneously will produce novel combination waveforms (Fig. 2b)
which also need to be classified. It is this last complication which particularly

105

bedevils previous efforts to classify neural signals (For review see 5, also see
3-4). In summary, then, our objective was to design a circuit that would:
1. distinguish different waveforms even though neuronal discharges tend
to be quite similar in shape (Fig. 2a);
2. recognize the same waveform even though unavoidable movements
such as animal respiration often result in periodic changes in the amplitude
of a recorded signal by moving the brain relative to the tip of the electrode;
3. be considerably robust to recording noise which variably corrupts all
neural recordings (Fig. 2);
4. resolve overlapping waveforms, which are likely to be particularly interesting events from a neurobiological point of view;
5. provide real-time performance allowing the experimenter to detect
problems with discrimination and monitor the progress of the experiment;
6. be implementable in hardware due to the need to classify neural signals on many channels simultaneously. Simply duplicating a software-based
algorithm for each channel will not work, but rather, multiple, small, independent, and programmable hardware devices need to be constructed.

I
b.

50 Jl.V

signal recorded

c.

electrode
a.

Fig. 2. a) Schematic diagram of an electrode recording from two neuronal cell bodies b) An
actual multi-neuron recording. Note the similarities in the two waveforms and the overlapping
event. c) and d) Synthesized data with different noise levels for testing classificat.ion algorithms
(c : 0.3 NSR ; d: 1.1 NSR) .

106

METHODS
The problem of detecting and classifying multiple neural signals on single voltage records involves two steps. First, the waveforms that are present
in a particular signal must be identified and the templates be generated;
second, these waveforms must be detected and classified in ongoing data
records. To accomplish the first step we have modified the principal component analysis procedure described by Abeles and Goldstein 3 to automatically extract templates of the distinct waveforms found in an initial sample of the digitized analog data. This will not be discussed further as it is
the means of accomplishing the second step which concerns us here. Specifically, in this paper we compare three new approaches to ongoing waveform classification which deal explicitly with overlapping spikes and variably meet other design criteria outlined above. These approaches consist of
a modified template matching scheme, and two applied neural network implementations. We will first consider the neural network approaches. On
a point of nomenclature, to avoid confusion in what follows, the real neurons whose signals we want to classify will be referred to as ""neurons"" while
computing elements in the applied neural networks will be called ""Hopons.""

Neural Network Approach - Overall, the problem of classifying neural
waveforms can best be seen as an optimization problem in the presence of
noise. Much recent work on neural-type network algorithms has demonstrated
that these networks work quite well on problems of this sort 6- 8 . In particular,
in a recent paper Hopfield and Tank describe an A/D converter network and
suggest how to map the problem of template matching into a similar context 8 .
The energy functional for the network they propose has the form:
- 1

E = - 2 ~~
'"" '"" T.I] v..v.
I]
1

]

- '""
~ VI

II

(1)

1

where Tij = connectivity between Hopon i and Hopon y', V; = voltage output
of Hopon i, Ii = input current to Hopon i and each Hopon has a sigmoid
input-output characteristic V = g(u) = 1/(1 + exp( -au)).
If the equation of motion is set to be:

du;fdt

=

-oE/oV =

L

T;jVj

+ Ii

(la)

j

then we see that dE/dt = -(I:iTijVj + Ii)dV/dt = - (du/dt)(dV/dt) =
-g'{u)(du/dt)2 :s: O. Hence E will go to to a minimum which, in a network
constructed as described below, will correspond to a proposed solution to a
particular waveform classification problem.

Template Matching using a Hopfield-type Neural Net - We have
taken the following approach to template matching using a neural network. For
simplicity, we initially restricted the classification problem to one involving two
waveforms and have accordingly constructed a neural network made up of two
groups of Hopons, each concerned with discriminating one or the other waveform. The classification procedure works as follows: first, a Schmidt trigger

107

is used to detect the presence of a voltage on the signal channel above a set
threshold . When this threshold is crossed, implying the presence of a possible
neural signal, 2 msecs of data around the crossing are stored in a buffer (40
samples at 20 KHz). Note that biophysical limitations assure that a single real
neuron cannot discharge more than once in this time period, so only one waveform of a particular type can occur in this data sample. Also, action potentials
are of the order of 1 msec in duration, so the 2 msec window will include the full
signal for single or overlapped waveforms. In the next step (explained later)
the data values are correlated and passed into a Hopfield network designed to
minimize the mean-square error between the actual data and the linear combination of different delays of the templates. Each Hopon in the set of Hopons
concerned with one waveform represents a particular temporal delay in the
occurrence of that waveform in the buffer. To express the network in terms of
an energy function formulation: Let x(t) = input waveform amplitude in the
tth time bin, Sj(t) = amplitude of the ph template, Vjk denote if Sj(t - k)(J?th
template delayed by k time bins)is present in the input waveform. Then the
appropriate energy function is:

(2)

The first term is designed to minimize the mean-square error and specifies
the best match. Since V E [0,1]' the second term is minimized only when each
Vjk assumes values 0 or 1. It also sets the diagonal elements Tij to o. The
third term creates mutual inhibition among the processing nodes evaluating
the same neuronal signal, which as described above can only occur once per
sample.
Expanding and simplifying expression (2), the connection matrix is :

(3a)
and the input current

(3b)
As it can be seen, the inputs are the correlations between the actual data and
the various delays of the templates subtracting a constant term.

Modified Hopfield Network - As documented in more detail in Fig.
3-4, the above full Hopfield-type network works well for temporally isolated
spikes at moderate noise levels, but for overlapping spikes it has a local minima
problem. This is more severe with more than two waveforms in the network.

108

Further, we need to build our network in hardware and the full Hopfield network is difficult to implement with current technology (see below) . For these
reasons, we developed a modified neural network approach which significantly
reduces the necessary hardware complexity and also has improved performance.
To understand how this works, let us look at the information contained in the
quantities Tij and Iij (eq. 3a and 3b ) and make some use of them. These
quantities have to be calculated at a pre-processing stage before being loaded
into the Hopfield network. If after calculating these quantities, we can quickly
rule out a large number of possible template combinations, then we can significantly reduce the size of the problem and thus use a much smaller (and
hence more efficient) neural network to find the optimal solution. To make the
derivation simple, we define slightly modified versions of 1';j and Iij (eq. 4a
and 4b) for two-template case.

Iij

= L x(t) [~SI(t - i) + ~S2(t - j)] t

~L

si(t - i) -

t

~ L s~(t -

j)

(4b)

t

In the case of overlaping spikes the 1';j'S are the cross-correlations between SI (t)
and S2(t) with different delays and Ii;'s are the cross-correlations between input
x(t) and weighted combination of SI(t) and S2(t). Now if x(t) = SI(t - i) +
S2(t - J') (i.e. the overlap of the first template with i time bin delay and the
second template with j time bin delay), then I:::.ij = l1';j - Iijl = O. However
in the presence of noise, I:::. ij will not be identically zero, but will equal to the
noise, and if I:::.ij > l:::.1';j (where l:::.1';j = l1';j - 1';'j.1 for i =f: i' and j =f: l) this
simple algorithm may make unacceptable errors. A solution to this problem
for overlapping spikes will be described below, but now let us consider the
problem of classifying non-overlapping spikes. In this case, we can compare
the input cross-correlation with the auto-correlations (eq. 4c and 4d).

T! = Lsi(t - i); T!, = Ls~(t - i)

(4c)

t

(4d)
So for non-overlapping cases, if x(t) = SI(t - i), then I:::.~ = IT: - 1:1 = O. If
x(t) = S2(t - i), then 1:::.:' = IT:' - 1:'1 = o.
In the absence of noise, then the minimum of I:::. ij , 1:::.: and I:::.? represents the
correct classification. However, in the presence of noise, none of these quantities
will be identically zero, but will equal the noise in the input x(t) which will
give rise to unacceptible errors. Our solution to this noise related. problem is
to choose a few minima (three have chosen in our case) instead of one. For
each minimum there is either a known corresponding linear combination of
templates for overlapping cases or a simple template for non-overlapping cases.
A three neuron Hopfield-type network is then programmed so that each neuron
corresponds to each of the cases. The input x(t) is fed to this tiny network to
resolve whatever confusion remains after the first step of ""cross-correlation""
comparisons. (Note: Simple template matching as described below can also be
used in the place of the tiny Hopfield type network.)

109

Simple Template Matching ~ To evaluate the performances of these
neural network approaches, we decided to implement a simple template matching scheme, which we will now describe. However, as documented below, this
approach turned out to be the most accurate and require the least complex
hardware of any of the three approaches. The first step is, again, to fill a buffer
with data based on the detection of a possible neural signal. Then we calculate
the difference between the recorded waveform and all possible combinations of
the two previously identified templates. Formally, this consists of calculating
the distances between the input x(m) and all possible cases generated by all
the combinations of the two templates.
d,j =

L

Ix(t) - {Sl(t - i)

+ S2(t - Jonl

t

d~

=

L
t

Ix(t) - Sl(t - i)l;

d~'

= L Ix(t) - S2(t - i)1
t

dmin = min(dij,d~,dn
dm,n gives the best fit of all possible combinations of templates to the actual
voltage signal.
TESTING PROCEDURES
To compare the performance of each of the three approaches, we devised a
common set of test data using the following procedures. First, we used the principal component method of Abeles and Goldstein 3 to generate two templates
from a digitized analog record of neural activity recorded in the cerebellum
of the rat. The two actual spike waveform templates we decided to use had
a peak-to-peak ratio of 1.375. From a second set of analog recordings made
from a site in the cerebellum in which no action potential events were evident,
we determined the spectral characteristics of the recording noise. These two
components derived from real neural recordings were then digitally combined,
the objective being to construct realistic records, while also knowing absolutely
what the correct solution to the template matching problem was for each occurring spike. As shown in Fig. 2c and 2d, data sets corresponding to different
noise to signal ratios were constructed. We also carried out simulations with
the amplitudes of the templates themselves varied in the synthesized records to
simulate waveform changes due to brain movements often seen in real recordings. In addition to two waveform test sets, we also constructed three waveform
sets by generating a third template that was the average of the first two templates. To further quantify the comparisons of the three diffferent approaches
described above we considered non-overlapping and overlapping spikes separately. To quantify the performance of the three different approaches, two
standards for classification were devised. In the first and hardest case, to be
judged a correct classification, the precise order and timing of two waveforms
had to be reconstructed. In the second and looser scheme, classification was
judged correct if the order of two waveforms was correct but timing was allowed to vary by ?lOO Jlsecs(i.e. ?2 time bins) which for most neurobiological
applications is probably sufficient resolution . Figs. 3-4 compare the performance results for the three approaches to waveform classification implemented
as digital simulations.

110

PERFORMANCE COMPARISON
Two templates - non-overlapping waveforms: As shown in Fig. 3a, at
low noise-to-signal ratios (NSRs below .2) each of the three approaches were
comparable in performance reaching close to 100% accuracy for each criterion.
As the ratio was increased, however the neural network implementations did
less and less well with respect to the simple template matching algorithm with
the full Hopfield type network doing considerably worse than the modified
network. In the range of NSR most often found in real data (.2 - .4) simple
template matching performed considerably better than either of the neural
network approaches. Also it is to be noted that simple template matching
gives an estimate of the goodness of fit betwwen the waveform and the closest
template which could be used to identify events that should not be classified
(e.g. signals due to noise).
a.

.

b.

,

..
c.

,.

..

. ..

..

..

1.1

noise level: 3a/peak amplitude

.,

,

?

//

\,

.
,

.

1.1

,.-.-..-----------.

/

,
,,

,,

I

,,

,:

.

.

.

noise level: 3a/peak amplitude

I

I

I

:'
I

,I

\,'
-14

-12

-tli

-I

-2

12

degrees of overlap
light line - absolute criteria
heavy line - less stringent criteria

simple template matching
Hopfield network
modified Hopfield network

Fig. 3. Comparisons of the three approaches detecting two non-overlapping (a), and overlapping (b) waveforms, c) compares the performances of the neural network approaches for
different degrees of waveform overlap.

Two' templates - overlapping waveforms: Fig. 3b and 3c compare performances when waveforms overlapped. In Fig. 3b the serious local minima problem encountered in the full neural network is demonstrated as is the improved
performance of the modified network. Again, overall performance in physi-

111

ological ranges of noise is clearly best for simple template matching. When
the noise level is low, the modified approach is the bet ter of the two neural
networks due to the reliability of the correlation number which reflects the
resemblence between the input data and the template. When the noise level
is high, errors in the correlation numbers may exclude the right combination
from the smaller network. In this case its performance is actually a little worse
than the larger Hopfield network. Fig. 3c documents in detail which degrees
of overlap produce the most trouble for the neural network approaches at average NSR levels found in real neural data. It can be seen that for the neural
networks, the most serious problem is encountered when the delays between
the two waveforms are small enough that the resulting waveform looks like the
larger waveform with some perturbation.
Three templates - overlapping and non-overlapping: In Fig. 4 are shown
the comparisons between the full Hopfield network approach and the simple
template matching approach. For nonoverlapping waveforms, the performance
of these two approaches is much more comparable than for the two waveform
case (Fig. 4a), although simple template matching is still the optimal method.
In the overlapping waveform condition, however, the neural network approach
fails badly (Fig. 4b and 4c). For this particular application and implementation, the neural network approach does not scale well.
b.

a.
~

!:!...

.

o ..
v

~

..

.

28

.2

c.
~

......'""
o
V

~

.

1. 1

.S

.2

noise level: 3a /peak amplitude

..
..

.4

..

.S

.. I

noise level: 3a /peak amplitude

Hopfield network
simple template matching
light line - absolute criteria
heavy line - less stringent criteria
a = variance of the noise

50

2.

.2

.6

.8

1. ?

noise level: 3a /peak amplitude
Fig. 4. Comparisons of performance for three waveforms. a) nonoverlapping waveforms; b)
two waveforms overlapping; c) three waveforms overlapping.

HARDWARE COMPARISONS
As described earlier, an important design requi~ement for this work was the
ability to <letect neural signals in analog records in real-time originating from

112

many simultaneously active sampling electrodes. Because it is not feasible to
run the algorithms in a computer in real time for all the channels simultaneously, it is necessary to design and build dedicated hardware for each channel.
To do this, we have decided to design VLSI implementations of our circuitry.
In this regard, it is well recognized that large modifiable neural networks need
very elaborate hardware implementations. Let us consider, for example, implementing hard wares for a two-template case for comparisons. Let n = no.
of neurons per template (one neuron for each delay of the template), m =
no. of iterations to reach the stable state (in simulating the discretized differential equation, with step size = 0.05), [ = no. of samples in a template
tj(m). Then, the number of connections in the full Hopfield network will be
4n 2 ? The total no. of synaptic calculations = 4mn 2 ? So, for two templates
and n = 16, m = 100,4mn 2 = 102,400. Thus building the full Hopfield-type
network digitally requires a system too large to be put in a single VLSI chip
which will work in real time. If we want to build an analog system, we need
to have many (O{ 4n 2 )) easily modifiable synapses. As yet this technology is
not available for nets of this size. The modified Hopfield-type network on the
other hand is less technically demanding . To do the preprocessing to obtain
the minimum values we have to do about n 2 = 256 additions to find all possible
Iijs and require 256 subtractions and comparisons to find three minima. The
costs associated with doing input cross-correlations are the same as for the full
neural network (i.e. 2nl = 768(l = 24) mUltiplications). The saving with the
modified approach is that the network used is small and fast (120 multiplications and 120 additions to construct the modifiable synapses, no. of synaptic
calculations = 90 with m = 10, n = 3).
In contrast to the neural networks, simple temrlate matching is simple
indeed. For example, it must perform about n 2 [ + n = 10,496 additions and
n 2 = 256 comparisons to find the minimum d ij . Additions are considerably less
costly in time and hardware than multiplications. In fact, because this method
needs only addition operations, our preliminary design work suggests it can be
built on a single chip and will be able to do the two-template classification
in as little as 20 microseconds. This actually raises the possibility that with
switching and buffering one chip might be able to service more than one channel
in essentially real time.

CONCLUSIONS
Template matching using a full Hopfield-type neural network is found to
be robust to noise and changes in signal waveform for the two neural waveform
classification problem. However, for a three-waveform case, the network does
not perform well. Further, the network requires many modifiable connections
and therefore results in an elaborate hardware implementation. The overall
performance of the modified neural network approach is better than the full
~Iopfield network approach. The computation has been reduced largly and
the hardware requirements are considerably less demanding demonstrating the
value of designing a specific network to a specified problem. However, even the
modified neural network performs less well than a simple template-matching
algorithm which also has the simplest hardware implementation. Using the
simple template matching algorithm, our simulations suggest it will be possible to build a two or three waveform classifier on a single VLSI chip using
CMOS technology that works in real time with excellent error characteristics.
Further, such a chip will be able to accurately classify variably overlapping

113

neural signals.

REFERENCES
[1] G. L. Gerstein, M. J. Bloom, 1. E. Espinosa, S. Evanczuk & M. R. Turner,
IEEE Trans. Sys. Cyb. Man., SMC-13, 668(1983).
2 J. M. Bower & R . Llinas, Soc. Neurosci. Abst.,~, 607(1983).
3 M. Abeles & M. H. Goldstein, Proc. IEEE, 65, 762(1977).
4 W. M. Roberts & D. K. Hartline, Brain Res., 94, 141(1976).
5 E. M. Schmidt, J. of Neurosci. Methods, 12, 95(1984).
6 J. J. Hopfield, Proc. Natl. Acad. Sci. (USA), 81, 3088(1984).
7 J. J. Hopfield & D. W. Tank, BioI. Cybern., 52, 141(1985).
8 D. W. Tank & J. J. Hopfield, IEEE Trans. Circuits Syst., CAS-33,
533(1986).

ACKNOWLEDGEMENTS
We would like to acknowledge the contribution of Dr. Mark Nelson to the intellectual
development of these projects and the able assistance of Herb Adams, Mike Walshe and John
Powers in designing and constructing support equipment. This work was supported by NIH
grant NS22205, the Whitaker Foundation and the Joseph Drown Foundation.

"
41,1987,"Neuromorphic Networks Based on Sparse Optical Orthogonal Codes","",41-neuromorphic-networks-based-on-sparse-optical-orthogonal-codes.pdf,"Abstract Missing","814

NEUROMORPHIC NETWORKS BASED
ON SPARSE OPTICAL ORTHOGONAL CODES

Mario P. Vecchi and Jawad A. Salehi
Bell Communications Research
435 South Street
Morristown, NJ 07960-1961
Abstrad
A family of neuromorphic networks specifically designed for communications
and optical signal processing applications is presented. The information is encoded
utilizing sparse Optical Orthogonal Code sequences on the basis of unipolar, binary
(0,1) signals. The generalized synaptic connectivity matrix is also unipolar, and
clipped to binary (0,1) values. In addition to high-capacity associative memory,
the resulting neural networks can be used to implement general functions, such as
code filtering, code mapping, code joining, code shifting and code projecting.

1

Introduction

Synthetic neural nets[1,2] represent an active and growing research field . Fundamental
issues, as well as practical implementations with electronic and optical devices are being
studied. In addition, several learning algorithms have been studied, for example stochastically adaptive systems[3] based on many-body physics optimization concepts[4,5].
Signal processing in the optical domain has also been an active field of research.
A wide variety of non-linear all-optical devices are being studied, directed towards applications both in optical computating and in optical switching. In particular, the
development of Optical Orthogonal Codes (OOC)[6] is specifically interesting to optical communications applications, as it has been demonstrated in the context of Code
Division Multiple Access (CDMA)[7] .
In this paper we present a new class of neuromorphic networks, specifically designed
for optical signal processing and communications, that encode the information in sparse
OOC's. In Section 2 we review some basic concepts. The new neuromorphic networks
are defined in Section 3, and their associative memory properties are presented in Section
4. In Section 5 other general network functions are discussed. Concluding remarks are
given in Section 6.

2
2.1

Neural Networks and Optical Orthogonal Codes
Neural Network Model

Neural network are generally based on multiply-threshold-feedback cycles. In the Hopfield model[2], for instance, a connectivity T matrix stores the M different memory
elements, labeled m, by the sum of outer products,
M

Tij=Lu'iuj; i,j=1,2 ... N
m

? American Institute of Physics 1988

(1)

815

where the state vectors ym represent the memory elements in the bipolar (-1,1) basis.
The diagonal matrix elements in the Hopfield model are set to zero, Tii = O.
For a typical memory recall cycle, an input vector .!lin, which is close to a particular
memory element m = k, multiplies the T matrix, such that the output vector .!lout is
given by
N
? out

Vi

~T.

= L.J

in

ijVj

i,j = l,2 ... N

(2)

j=l

and can be seen to reduce to

vit ~ (N - l)u~ + J(N -

l)(M - 1)

(3)

for large N and in the case of randomly coded memory elements ym.
In the Hopfield model, each output ~out is passed through a thresholding stage
around zero. The thresholded output signals are then fed back, and the multiply and
threshold cycle is repeated until a final stable output .!lout is obtained. IT the input .!lin is
sufficiently close to y1c, and the number of state vectors is small (Le. M ~ N), the final
output will converge to memory element m = k, that is, .!lout -+ y1c. The associative
memory property of the network is thus established.

2.2

Optical Orthogonal Codes

The OOC sequences have been developed[6,7] for optical CDMA systems. Their properties have been specifically designed for this purpose, based on the following two conditions: each sequence can be easily distinguished from a shifted version of itself, and
each sequence can be easily distinguished from any other shifted or unshifted sequence
in the set. Mathematically, the above two conditions are expressed in terms of autoand crosscorrelation functions. Because of the non-negative nature of optical signals 1 ,
OOC are based on unipolar (0,1) signals[7].
In general, a family of OOC is defined by the following parameters:
- F, the length of the code,
- K, the weight of the code, that is, the number of l's in the sequence,

- >.a,

the auto-correlation value for all possible shifts, other than the zero shift,

- Ac , the cross-correlation value for all possible shifts, including the zero shift.
For a given code length F, the maximum number of distinct sequences in a family
of OOC depends on the chosen parameters, that is, the weight of the code K and the
allowed overlap AaandAc. In this paper we will consider OOC belonging to the minimum
overlap class, Aa
Ac 1.

= =

lWe refer to optical inten6ity signals, and not to detection systems sensitive to phase information.

816

3

Neuromorphic Optical Networks

Our neuromorphic networks are designed to take full advantage of the properties of the
~OC. The connectivity matrix T is defined as a sum of outer products, by analogy with
(1), but with the following important modifications:
1. The memory vectors are defined by the sequences of a given family of OOC, with a
basis given by the unipolar, binary pair (0,1). The dimension of the sparse vectors
is given by the length of the code F, and the maximum number of available items
depends on the chosen family of ~OC.

2. All ofthe matrix elements Ti; are clipped to unipolar, binary (0,1) values, resulting
in a sparse and simplified connectivity matrix, without any loss in the functional
properties defined by our neuromorphic networks.
3. The diagonal matrix elements Tii are not set to zero, as they reflect important
information implicit in the OOC sequences.
4. The threshold value is not zero, but it is chosen to be equal to K, the weight of
the ~OC.
5. The connectivity matrix T is generalized to allow for the possibility of a variety

of outer product options: self-outer products, as in (1), for associative memory,
but also cross-outer products of different forms to implement various other system
functions.
A simplified schematic diagram of a possible optical neuromorphic processor is shown
in Figure 1. This implementation is equivalent to an incoherent optical matrix-vector
multiplier[8], with the addition of nonlinear functions. The input vector is clipped using
an optical hard-limiter with a threshold setting at 1, and then it is anamorphic ally
imaged onto the connectivity mask for T. In this way, the ith pixel of the input vector
is imaged onto the ith column of the T mask. The light passing through the mask is
then anamorphically imaged onto a line of optical threshold elements with a threshold
setting equal to K, such that the jth row is imaged onto the lh threshold element.

4

Associative Memory

The associative memory function is defined by a connectivity matrix

TMEM

given by:

(4)
where each memory element ~m corresponds to a given sequence of the OOC family,
with code length F. The matrix elements of TMEM are all clipped, unipolar values, as
indicated by the function gn, such that,

g{ (}

? ifif (( <~ 1

={ 1

1

(5)

817
We will now show that an input vector ~Ie, which corresponds to memory element
m = k, will produce a stable output (equal to the wanted memory vector) in a single
pass of the multiply and threshold process.
The multiplication can be written as:

(6)
We remember that the non-linear clipping function
T
. Hence,

-MEM

an is to be applied first to obtain

v~t
= ~:z:'!
~. J:z:~:z:'!'}
,
L.JJ a {:z:'!:z:'!
'J + L
'J
j

(7)

m#;1e

For :z:~ = 0, only the second term in (7) contributes, and the pseudo-orthogonality
properties of the OOC allow us to write:

(8)
where the cross-correlation value is Ac < K.
For :z:~ = 1, we again consider the properties of the OOC to obtain for the first term
of (7):

(9)
where K is the weight of the OOC.
Therefore, the result of the multiplication operation given by (7) can be written as:
A

out

Vi

=

K

Ie
:Z:i

+

[value strictly
less than K

1

(10)

The thresholding operation follows, around the value K as explained in Section 3.
That is, (10) is thresholded such that:

vit =

{

1 if v~t

o

>K
<K,

,-

,

ifv~t

(11)

hence, the final output at the end of a single pass will be given by: v:u t = :z:~.
The result just obtained can be extended to demonstrate the single pass convergence
when the input vector is close, but not necessarily equal, to a stored memory element.
We can draw the following conclusions regarding the properties of our neuromorphic
networks based on OOC:
? For any given input vector ~in, the single pass output will correspond to the
memory vector ~m which has the smallest Hamming distance to the input .
? If the input vector ~in is missing a single 1-element from the K l's of an OOC,
the single pass output will be the null or zero vector.

818

? If the input vector !lin has the same Hanuning distance to two (or more) memory
vectors ~m , the single pass output will be the logical sum of those memory vectors.
The ideas just discussed were tested with a computer simulation. An example of
associative memory is shown in Table 1, corresponding to the OOC class of length
F = 21 and weight K = 2. For this case, the maximum number of independent
sequences is M = 10. The connectivity matrix TMEM is seen in Table 1, where one can
clearly appreciate the simplifying features of our model, both in terms of the sparsity
and of the unipolar, clipped values of the matrix elements. The computer simulations for
this example are shown in Table 2. The input vectors ~ and Qshow the error-correcting
memory recovery properties. The input vector ~ is equally distant to memory vectors
e3 and ~8, resulting in an output which is the sum (e 3 EB e8 ). And finally, input vector
d is closest to ~\ but one 1 is missing, and the output is the zero vector. The mask
in Figure 1 shows the optical realization of the Table 1, where the transparent pixels
correspond to the l's and the opaque pixels to the O's ofthe connectivity matrix TMEM.
It should be pointed out that the capacity of our network is significant. From the
previous example, the capacity is seen to be ::::: F /2 for single pass memory recovery.
This result compares favorably with the capacity of a Hopfield model[9], of ~ F / 41n F.

5

General Network Functions

Our neuromorphic networks, based on OOC, can be generalized to perform functions
other than associative memory storage by constructing non-symmetrical connectivity
matrices. The single pass convergence of our networks avoids the possibility of limitcycle oscillations. We can write in general:

Tii =

g{t Yf'Zj} ,

(12)

m=l

where each pair defined by m includes two vectors ym and em, which are not necessarily
equal. The clipping function 9 {} insures that all m;:trix elements are binary (0,1) values.
The possible choice of vector pairs is not completely arbitrary, but there is a wide variety
of functions that can be implemented for each family of OOC. We will now discuss some
of the applications that are of particular interest in optical communication systems.

S.l

Code Filtering (CDMA)

Figure 2 shows an optical CDMA network in a star configuration. M nodes are interconnected with optical fibers to a passive MxM star coupler that broadcasts the optical
signals. At each node there is a data encoder that maps each bit of information to the
OOC sequence corresponding to the user for which the transmission is intended. In
addition, each node has a filter and decoder that recognizes its specific OOC sequence.
The optical transmission rate has been expanded by a factor F corresponding to the
length of the OOC sequence. Within the context of a CDMA communication system[7],
the filter or decoder must perform the function of recognizing a specific OOC sequence
in the presence of other interfering codes sent on the common transmission medium.

819

We can think, then, of one of our neuromorphic networks as a filter, placed at a given
receiver node, that will recognize the specific code that it was programmed for.
We define for this purpose a connectivity matrix as
TijCDMA

Ie Ie
=ziZj;

??

1.,}=

1 , 2 ... F ,

(13)

where only one vector ~Ie is stored at each node. This symmetric, clipped connectivity
matrix will give an output equal to ~Ie whenever the input contains this vector, and a
null or zero output vector otherwise. It is clear by comparing (13) with (4) that the
CDMA filtering matrix is equivalent to an associative memory matrix with only one
item imprinted in the memory. Hence the discussion of Section 4 directly applies to the
understanding of the behaviour of T CDMA
In order to evaluate the performance of our neuromorphic network as a CDMA
filter, computer simulations were performed. Table 3 presents the T CDM A matrix for
a particular node defined by ~Ie of a CDMA system based on the OOC family F = 21,
K = 2. The total number of distinct codes for this OOC family is M = 10, hence there
are 9 additional OOC sequences that interfere with ~Ie, labeled in Table 3 ~l to ~9.
The performance was simulated by generating random composite sequences from the
set of codes ~l to ~9 arbitrarily shifted. All inputs are unipolar and clipped (0,1) signals.
The results presented in Table 4 give examples of our simulation for the T CDMA matrix
shown in Table 3. The input Q is the (logical) sum of a I-bit (vector ~Ie), plus interfering
signals from arbitrarily shifted sequences of ~2, ~3, ~4, ~6 and ~9. The output of the
neuromorphic network is seen to recover accurately the desired vector ~Ie. The input
vector Q contains a O-bit (null vector), plus the shifted sequences of ~l, ~2, ~3, ~6, ~7
and ~8, and we see that the output correctly recovers a O-bit.
As discussed in Section 4, our neuromorphic network will always correctly recognize
a I-bit (vector ~Ie) presented to its input. On the other hand 2, there is the possibility of
making an error when a O-bit is sent, and the interfering signals from other nodes happen
to generate the chip positions of ~Ie. This case is shown by input vector ~ of Table 4,
which contains a O-bit (null vector), plus shifted sequences of ~2, ~3, ~4, ~6, ~6, ~7 and
~8 in such a way that the output is erroneously given as a I-bit. The properties of the
OOC sequences are specifically chosen to minimize these errors(7], and the statistical
results of our simulation are also shown in Table 4. It is seen that, as expected, when
a I-bit is sent it is always correctly recognized. On the other hand, when O-bits are
sent, occasional errors occur. Our simulation, yields an overall bit error rate (BER) of
BER.im 5.88%, as shown in Table 4.
These results can be compared with theoretical calculations[7] which yield an estimate for the BER for the CDMA system described:

=

K-l

1
B ER calc~-

2

IT [1-qM-l-le] ,

(14)

Ie=O

=

where q 1 - ~. For the example of the OOC family F = 21, K = 2, with M = 10,
the above expression yields BERcalc :::::: 5.74%.
20 ur channel can be described, then, as a binary Z-channel between each two nodes dynamically
establishing a communication path

820

It is seen, therefore, that our neuromorphic network approaches the minimum possible BER for a given family of OOC. In fact, the results obtained usin~ our T CDMA
are equivalent CDMA detection scheme based on ""optical-AND-gates,,[1 1, which corresponds to the limiting BER determined by the properties of the OOC themselves 3 .
The optical mask corresponding to the code filtering function is shown in Figure 3.

5.2

Other Functions

As a first example of a non-symmetric T matrix, let us consider the function of mapping
an input code to a corresponding different output code. We define our mapping matrix
as:

T;fAP

= g {~Y'Zj}

; i,i =

l,2 ... F,

(15)

where an input vector ~m will produce a different output vector code llm.
The function of code joining is defined by a transfer function that takes a given
input code and produces at the output a chosen combination of two or more codes.
This function is performed by expressing the general matrix given by 12 as follows:
TijJ01N

where an input vector

--

~m

r!
""(
'!:I {~

Yim + wim + .. ,)Zjm}

. &,1
. . -- 1 , 2 ... F ,
I

(16)

will result in an output that joins several vector codes (Il m E9

wmffi ... ).

The code shifting matrix TSHIFT will allow for the shift of a given code sequence,
such that both input and output correspond to the same code, but shifted with respect
to itself. That is,

(17)
where we have indicated an unshifted code sequence by ~(O)m, and its corresponding
output pair as a shifted version of itself ~(s)m.
The code projecting function corresponds to processing an input vector that contains
the logical sum of several codes, and projecting at the output a selected single code
. glven
.
b y:
? T PROJ IS
sequence. The corresponding matrIx
TijPROJ

m( Yjm +Wjm +... ) }1.&
. ., 1
- -1, 2 ... F ,

- r! {~Zi
""
-'!:I

(18)

where each input vector (~m ffi w m ffi ... ) will project at the output to a single code
~m. In general, the resulting output code sequence ~m could correspond to a code not
necessarely contained in the input vector.
The performance and error correcting properties of these, and other, general functions follow a similar behaviour as discussed in Section 4.
3The BER for the OOC family shown in this example are far too large for a useful CDMA communications system. Our choice intended to show computer simulated results within a reasonable
computation time.

821

6

Conclusions

The neuromorphic networks presented, based on sparse Optical Orthogonal Code (OOC)
sequences, have been shown to have a number of attractive properties. The unipolar,
clipped nature of the synaptic connectivity matrix simplifies the implementation. The
single pass convergence further allows for general network functions that are expected
to be of particular interest in communications and signal processing systems.
The coding of the information, based on ~OC, has also been shown to result in high
capacity associative memories. The combination of efficient associative memory properties, plus a variety of general network functions, also suggests the possible application
of our neuromorphic networks in the implementation of computational functions based
on optical symbolic substitution.
The family of neuromorphic networks discussed here emphasizes the importance of
understanding the general properties of non-negative systems based on sparse codes[lll.
It is hoped that our results will stimulate further work on the fundamental relationship
between coding, or representations, and the information processing properties of neural
nets.

Acknowledgement
We thank J. Y. N. Hui and J. Alspector for many useful discussions, and C. A. Brackett for his support
and encouragement of this research.

References
[1] S. Grossberg. In K. Schmitt, editor, Delay and Functional-Differential Equation6 and Their ApplicatioN, page 121, Academic Press, New York, NY, 1972.
[2] J. J. Hopfield. Neural Networks and Physical Systems with Emergent Collective Computational
Abilities. Proc. Nat. Acad. Sci. USA, 79:2254, 1982.
[3] D. H. Ackley, G. E. Hinton, and T. J. Sejnowski. A Learning Algorithm for Boltzmann Machines.
Cogn. Sci., 9:147, 1985.
[4] S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchio Optimization by Simulated Annealing. Science,
220:671, 1983.
[5] M. P. Vecchi and S. Kirkpatrick. Global Wiring by Simulated Annealing. IEEE Tran6. CAD of
Integrated Circuit. and Sydem6, CAD-2:215, 1983.
[6] F. R. K. Chung, J. A. Salehi, and V. K . Wei. Optical Orthogonal Codes: Design, Analysis and
Applications. In IEEE International Symp06ium on Information Theory, Catalog No. 86CH!374-7,
1986. Accepted for publication in IEEE Trans. on Information Theory.
[7] J. A. Salehi and C. A. Brackett. Fundamental Principles of Fiber Optics Code Division Multiple
Access. In IEEE International Conference on CommunicatiON, 1987.
[8] N. H. Farhat, D. Psaltis, A. Prata, and E. Paek. Optical Implementation of the Hopfield Model.
Appl. Opt., 24:1469, 1985.
[9] R. J. McEliece, E. C. Posner, E. R. Rodemich, and S. S. Venkatesh. The Capacity of Hopfield
Associative Memory. IEEE Tran6. on Information Theory, IT-33:461, 1987.
[10] J. A . Salehi. Principles and Applications of Optical AND Gates in Fiber Optics Code Division
Multiple Access Networks. In preparation, 1987.
[11] G. Palm. Technical comments. Science, 235:1226, 1987.

822
T.... I: A_wi .. Yo..,. Eo .......

~.....

_ ... 0110 wI ...
0OCf.....

. . . ~ .. ~IO .........

r .,

OOC J'anolq.

II. It

=I

? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ??
?
.
,
?
.- ?? ?? ?? ? ?? ?, ? ?? ?? ? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ??
,
,
,,

CodoVod_
1 1 ??

OOC J'aaoi\r1
I....,."",.'"" Co4e ... H . .
?

?

??????? I

I

I

1

I
I'

Cotuoec,a.II, Wain.

1

??????? ??
, ?? ?? ?? ?? ?? ?? ?? ?? ??? ?? ? ???, ?? ??? ?? ??? ??? ?? ??? ???, ???
? ?? ?? ?? ?? ?, ?? ?? ?? ?? ?? ?? ? ?? ?, ?? ?,? ?? ?? ?? ? ??
????? ?????? ?? ? ? ? ? ??
eo..-lintJ
r??1
? ?? ?? ?? ??
?
?
?
?
?
?
,
??? ??? ??? ??? ???
?? ?? ?, ? ? ?? ?, ?? ?? ?? ?? ??
? ? ? ?? ??
?? ?? ? ? ? ?? ? ? ?? ??
? ??
?
? ?
???
??
???
???
?
?
?
??
??
???
?? ?
?
?
??
???
??
?,??
?? '?. ??? ??? ??? ???
??,
?? ?? ? ?? ?? ?? ??
?
? :1
I'

r

I:

II. It

=I

????? I

r v. ' ,

1

I'

I-

1

1 I ?
1 1
I

Malrb
? ? ?

I

,
?
???
??

I

I

I

1

1

I

I

1

I

.1 ,..?' ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?
"" ? ?
????????????
,"" ? ? ? ? ?? ?, ? ?? ?? ? ?? ?? ?? ?? ?? ?? ?? ?? ?? ?? ??
. ?? ?? ?? ?? ?? ?? ?? ? ?? ?? ?, ??, ? ?? ?? ?? ?? ? ?? ?? ??
,?"" ?? ?? ?? ?? ? ??, ?? ?? ?? ?? ?? ? ?? ? ?? ?? ?? ?? ?? ? ??
????? ????????? ????

....

~._IaJ
I

~

I

I

?

I

Co4.I

? ?
1

?

I

I

1

I

1

I

I

I

I

T.... I: A-o.&i.. 11-.,. ~ ~ ~ ...
- _ .... - ... ,..."" _ria P. ;;. 'bWo I.
1IIr ............

'bWo.,

a.-a.. ........... .....,._

....

('

ooc ...."" r ?

, ? ? ? ? ? ? ? ? ? ? ? ? ? ? .:
? , ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? '1
? ?.u.'-""-,
? ? ???? ? ? ? ? ? ? ""
...........
......
. ??????? ???? ???????
??
IIIanmoI.& ..
r:: ?...? ? ? ? ? ? ? ? ?
, ???,??
? , ?????? ? ?
.. v.....

I
I
I
.............W - _ ? ? ?
0.1,.. V ......
I

I

I

I

o..~v

I

I

D

Ll.,.. V _
C

...

I

1 ............

Out,.. v ......

~

I

?

?

I

?

I

?

I

I

I

lot.... "" 4Iot_""-~
I

?

?

?

I

I:

a""

????????

l

I

' 0

? ????

????

'.,

????

I

""

?

?

:&CHl ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?

, ?.-a-., , ?a""!, , ? ? , ?
????????, ????? ??? ? ? ?
, ??

I.loop.. v_ .. r.....~l.a-' .,' ? ? ? ""

c T' ?? I
Ou'_V_ _
C

I

I ?

I

I

I

s..,.....aI .....no..

I

????????????????????

? ? ? ? ? ?J
??????
??

r.... V_= _ . '????..-??.? , .o'

I? WI

...11

MIOJf

N?I
ltol

Outp.. V......
UN

r. 1I,1t. I

.1""1"""".""'1

.1????? ............. 0,
................., . . . . "" - .

~

................

~;~.--).""""""

OOC hili?!

?

I

.....

........ - . -'iInriIr ................... - .

II, It .. I

~

I

p_.

c.. _
FI\orioc
_
_IC'DIIU).
..... _~
... SOC""',, so-IalioL
_ ..

.'

""'1. EMIl ............ .., ................. ...

r -..... -

L..... V _
I
l

???
??
?

?

I

?

??

??
???
???,

I

I

??????

BU""

0-

?

Il.""""

TogJ I
I_II

ltol
I ...

823

Figure 1:
Schematic diagram of an optical neuromorphic processor using sparse Optical Orthogonal Codes. Notice the absence oHeedback because ofthe single-pass
convergence. The mask shown represents the realisation of the content-addressable memory of Table 1.

Figure 3:
Optical realization oC a code filtering (CDMA) maslc
o( Table 3. The l's are represented by the transpar'
ent pixels, and the 0'. by the opaque pixels.

Nkll
PASSM
STAll
COUI'lEIIS

Figure 2:
Schematic diagram of a COMA communications system over an Optical Fiber interconnection network.
Each node represents one of the M possible distinct
users in the system.

"
42,1987,"Static and Dynamic Error Propagation Networks with Application to Speech Coding","",42-static-and-dynamic-error-propagation-networks-with-application-to-speech-coding.pdf,"Abstract Missing","632

STATIC AND DYNAMIC ERROR PROPAGATION
NETWORKS WITH APPLICATION TO SPEECH
CODING
A J Robinson, F Fallside
Cambridge University Engineering Department
Trumpington Street, Cambridge, England
Abstract
Error propagation nets have been shown to be able to learn a variety of tasks in
which a static input pattern is mapped outo a static output pattern. This paper
presents a generalisation of these nets to deal with time varying, or dynamic
patterns, and three possible architectures are explored. As an example, dynamic
nets are applied to tbe problem of speech coding, in which a time sequence of
speech data are coded by one net and decoded by another. The use of dynamic
nets gives a better signal to noise ratio than that achieved using static nets.

1. INTRODUCTION
This paper is based upon the use of the error propagation algorithm of Rumelbart, Hinton
and Williams l to train a connectionist net. The net is defined as a set of units, each witb an
activation, and weights between units which determine the activations. The algorithm uses a
gradient descent technique to calculate the direction by which each weight should be changed
in order to minimise the summed squared difference between the desired output and the actual
output. Using this algorithm it is believed that a net can be trained to make an arbitrary
non-linear mapping of the input units onto the output units if given enough intermediate
units. This 'static' net can be used as part of a larger system with more complex behaviour.
The static net has no memory for past inputs, but many problems require the context of
the input in order to c.ompute the answer. An extension to the static net is developed, the
'dynamic' net, which feeds back a section of the output to the input, so creating some internal
storage for context, and allowing a far greater class of problems to be learned. Previously this
method of training time dependence into uets has suffered from a computational requirement
which increases linearly with the time span of the desired context. The three architectures
for dynamic uets presented here overcome this difficulty.
To illustrate the power of these networks a general coder is developed and applied to the
problem of speech coding. The non-liuear solution found by training a dynamic net coder is
compared with an established linear solution, and found to have an increased performance as
measured by the signal to noise ratio .

2. STATIC ERROR PROPAGATION NETS
A static Ret is defined by a set of units and links between the units. Denoting 0i as the value
of the ith unit, and wi,l as the weight of the link between Oi and OJ, we may divide up the
units into input units, hidden units and output units. If we assign 00 to a. constant to form a

@ American Institute of Physics 1988

633

bias, the input units run from 01 up to on"",\., followed by the hidden units to onh?.t and then
the output units to On."".' The values of the input units are defined by the problem and the
values of the remaining units are defined by:
i-I

neti
?i

~1LJ'',1'0'J

(2.1)

j=O
!(net;)

(2.2)

where !( x) is any continuous monotonic non-linear function and is known as the activation
function. The function used the application is:
2
----1
1 + e- z"",

!(x)

(2 .3)

These equations define a net which has the maximum number of interconnections. This
arrangement is commonly restricted to a layered structure in which units are only connected
to the immediately preceding layer . The architecture of these nets is specified by the number
of input, output and hidden units. Diagrammatically the static net is transformation of an
input 'U, onto the output y, as in figure 1.

static
net

figure 1

The net is trained by using a gradient descent algorithm which mlDlsmises an energy
term, E, defined as the summed squared error between the actual outputs, ai, and the target
outputs, t i . The algorithm also defines an error signal, Oi, for each unit:

E
[Ii

1

2

""lint

~

(ti --

i=nl w l+1
!' (netd(t i

-

od 2

0;)

(2.4)
nhid

< i ::;

nout

(2.5 )

ninp

< i ::;

nhid

(2 .6)

"" lint

.f' (net;) ~

OiWj,i

j=i+l

where f' (x) is the derivative of !( x). The error signal and the adivations of the units define
the change in each weight, D. Wi,j'
(2.7)

where '1 is a constant of proportionality which determines the learning rate. The above
equations define the error signal, 0;, for the input units as well as for the hidden units. Thus
any number of static nets can be connected together, the values of Oi being passed from input
units of one net to output units of the preceding net. It is this ability of error propagation
nets to be 'glued' together in this way that enables the construction of dynamic nets.

3. DYNAMIC ERROR PROPAGATION NETS
The essential quality of the dynamic net is is that its behaviour is determined both by the
external input to the net, and also by its own internal state. This state is represented by the

634

activation of a group of units. These units form part of the output of a st.atic net and also
part of the input to another copy of the same static net in the next time period. Thus the
state units link multiple copies of static nets over time to form a dynamk net.

3.1. DEVELOPMENT FROM LINEAR CONTROL THEORY
The analogy of a dynamic net in linear systems 2 may be stated as:

(3.1.1)
(3.1.2)
where up is the input vector,

zp

the state vector, and Yp the output vector at the integer time

p. A, Band C are matrices.

The structure of the linear systems solution may be implemented as a non-linear dynamic
net by substituting the matrices A, Band C by statk nets, represented by the non-linear
functions A[.]' B[.] and C[.]. The summation operation of Azp and Bup could be achieved
using a net with one node for each element in z and u and with unity weights from the two
inputs to the identity activation function f( x) = z. Alternatively this net can be incorporated
into the A[.] net giving the architecture of figure 2.

B [.]

y(p+l)

dynamic t---of
A[.]

e[.]

y(p+l)
net
x(p+l)

Time

Time

Delay

Delay

figure 2

figure 3

The three networks may be combined into one, as in figure 3. Simplicity of architecture
is not just an aesthetic consideration. If three nets are used then each one must have enough
computational power for its part of the task, combining the nets means that only the combined
power must be sufficient and it allows common computations can be shared.
The error signal for thf' output Yp+l, can be calculated by comparison with the desired
output. However, the error signal for thf' state units, x P ' is only given by the net at time p+l,
which is not known at time p. Thus it is impossible to use a single backward pass to train
this net . It is this difficulty which introduces the variation in the architectures of dynamic
nets.

3.2. THE FINITE INPUT DURATION (FID) DYNAMIC NET
If the output of a dynamic net, YP' is df'pendf'nt on a finite number of previous inputs, up_p
to up, or if this assumption is a good approximation, then it is possible to formulate the

635

learning algorithm by expansion of the dynamk net for a finite time, as in figure 4. This
formulation is simlar to a restricted version of the recurrent net of Rumelhart, Hinton and
Williams. 1

x(p+l)
dynamic
net
(p)

y(p+l)
dynamic
net

(p-l)
yep)
dynamic
net
(p-2)

figure 4

Consider only the component of the error signal in past instantiations of the nets which
is the result of the error signal at time t. The errot signal for YP is calculated from the target
output and the ('rror signal for xr is zero. This combined error signal is propagated back
though the dynamic net at p to yield the error signals for up and xp' Similarly these error
signals can then be propagated back through the net at t - P, and so on for all relevant inputs.
The summed error signal is then used to change the weights as for a static net.
Formalising the FID dynamic net for a general time q, q ~ p:
n, is the number of state units
is the output value of unit i at time q
?q,i
is the target value of unit i at time q
tq,i
is
the error value of unit i at time q
6'1,'
is the weight between 0; and OJ
Wi,j
is the weight change for this iteration at time q
~Wq,i,i
is the total weight change for this iteration
~wi,i
These values are calculated in the same way as in a static net,
i-1

netq,i

L

(3.2.1)

Wi,jOq,j

j=O

(3 .2.2)

f(net q ,.)

f' (netq,d( tq,i

-

0'1,;)

+ n, < i :S nout
nhid < i :S nhid + n,

nhid

(3 .2.3)
(3.2.4)

nullt

!'(n('t q ,;)

L

6q ,jWj ,i

(3 .2.5)

j-=i+l

(3.2.6)

and the total weight change is given by the summation of the partial weight changes for all

636

previous times.
p

L

Llu'q,i,j

(3.2.7)

7]6 q,i O q,j

(3.2.8)

q=p-P
p

L
q=p-P

Thus, it is possible to train a dynamic net to incorporate the information from any time
period of finite length, and so l~arn any function which has a finite impulse response.?
In some situations the approximation to a finite length may not be valid, or the storage
and computational requirements of such a net may not be feasible. In such situations another
approach is possible, the infinite input duration dynamic net .

3.3. THE INFINITE INPUT DURATION (lID) DYNAMIC NET
Although the forward pass of the FID net of the previous section is a non-linear process, th..
backward pass computes the efred of small variations on the forward pass, and is a linear
process. Thus the recursive learning procedure described in the previous section may be
compressed into a single operation.
Given the target values for the output of the net at time p, equations (3.2.3) and (3.2.4)
define valu~s of 6p ,i at the outputs. If we denote this set of 6p ,i by Dp then equation (3.2.5)
states that any 6p ,i in the net at time p is simply a linear transformation o( Dp. Writing the
transformation matrix as S:

(3.3.1)
In particular the set of 6p ,i which is to be fed back into the network at time p - 1 is also
a linear transformation of Dp

(3.3.2)
or for an arbitrary time q:

(3.3.3)
so substituting equations (3.3.1) and (3.3.3) into equation (3.2.8):
p

LlU'i,j

7]L

Sq,i

q=-oo

( IT T,) D,o""j

(3.3.4)

7=q+l

(3.3.5)

7]Mp ,i,i D p
where:
p

M p,',)
.,

L

q=-oo

Sq,i

( IT T}""j

(3.3.6)

""=q+l

? This is a restriction on the class of functions which can be learned, the output will always be affected
in some way by all previous inputs giving an infinite impulse response performance.

637

and note that Mp,i,i can be written in terms of Mp-1,i,i :

MP,-.,,J

Sp,i (

IT

T,.) 0p,i

,.=p+l

Sp,iop,i

+

(I:

Sq,i

(3.3.7)

q=-oo

+ Mp-1,i,iTp

(3.3 .8)

Hence we can calculate the weight changes for an infinite recursion using only the finite
matrix M,

3.3. THE STATE COMPRESSION DYNAMIC NET
The previous architectures for dynamic nets rely on the propagation of the error signal hack
ill time to define the format of the information in the state units. All alternative approach
is to use another error propagation net to define the format of the state units. The overall
architecture is given in figure 5.

Bncoder
net

1-----\1 Tranlllatort---""""'""
x(p+1)
y(p+1)
net

Decoder
net

figure 5

The encoder net is trained to code the current input and current state onto the next state,
while the decoder net is trained to do the reverse operation. The tran81ator net code8 the
next state onto the desired output. This encoding/decoding attempts to represent the current
input and the current state in the next state, and by the recursion, it will try to represent all
previous inputs. Feeding errors back from the translator directs this coding of past inputs to
those which are useful in forming the output.

3.4. COMPARISON OF DYNAMIC NET ARCHITECTURES

III comparing the three architectures for dynamic nets, it is important to consider the computational and memory requirements, and how these requirements scale with increasing context.
To train an FID net the net must store the past activations of the all the units within
the time span of thel'necessary context, Using this minimal storage, the computational load
scales proportiona.lly to the time span considered, as for every new input/output pair the
net must propagate an error signal back though all the past nets. However, if more sets
of past activations are stored in a buffer, then it is possible to wait until this buffer is full
before computing the weight changes. As the buffer size increases the computational load in

638

calculating the weight changes tends to that of a single backward pass through the units, and
so becomes independent of the amount of coutext.
The largest matrix required to compute the 110 net is M, which requires a factor of the
number of outputs of the net more storage than the weight matrix. This must be updated
on each iteration, a computational requirement larger than that of the FlO net for smaJl
problems 3 . However, if this architecture were implemented on a paraJlel machine it would be
possible to store the matrix M in a distributed form over the processors, and locally calculate
the weight changes. Thus, whilst the FID net requires the error signal to be propagated back
in time in a strictly sequential manner, the 110 net may be implemented in paraJld, with
possible advantages on parallel machines.
The state compression net has memory and computational requirements independent of
the amount of context. This is achieved at the expense of storing recent information in the
state units whether it is required to compute the output or not . This results in an increased
computational and memory load over the more efficient FID net when implemented with a
buffer for past outputs. However, the exclusion of external storage during training gives this
architecture more biological plausibili ty, constrained of course by the plausibility of the error
propagation algorithm itself.
With these considerations in mind, the FlO net was chosen to investigate a 'real world'
problem, that of the coding of the speech waveform.

4. APPLICATION TO SPEECH CODING
The problem of speech coding is one of finding a suitable model to remove redundancy and
hence reduce the data rate of the speech. The Boltzmann machine learning algorithm has
already been extended to deal to the dynamic case and applied to speech recognition4. However, previous use of error propagation nets for speech processing has mainly been restricted to
explicit presentation of the context 5,6 or explicit feeding back the output units to the input 7,8,
with some work done in usillg units with feedback links to themselves 9 . In a similar area,
static error propagation nets have been used to perform image coding as well as cOllventional
techniques 1o .

4.1. THE ARCHITECTURE OF A GENERAL CODER
The coding principle used in this section is not restricted to c.oding speech data. The general
problem is one of encoding the present input using past input context to form the transmitted
signal, and decoding this signal using the context ofthe coded signals to regenerate the original
input. Previous sections have shown that dynamic nets are able to represent context, so two
dynamic, nets in series form the architecture of the coder, as in figure 6.
This architecture may be specified by the number of input, state, hidden and transmission
units. There are as many output units as input units and, in this application, both the
transmitter and receiver have the same number of state and hidden units.
The input is combined with the internal state of the transmitter to form the coded signal,
and then decoded by the receiver using its internal state. Training of the net involves the
comparison of the input and output to form the error signal, which is thell propagated back
through past instantiations of the receiver and transmitter in the same way as a for a FID
dynamic net.
It is useful to introduce noise into the coded signal during the training to reduce the
information capacity of the transmission line. This forces the dynamic 11ets to incorporate
time information, without this constraint both nets can learn a simple transformation without
any time dependence. The noise can be used to simulate quantisation of the coded signal so

639

input

,

coded signal

J

?

I

TX

r-\

output

?

ax

r-\

rI
io-

..,

rI

~

Time

V-

Delay

~

I-

I""""

Time

I

Delay

\--

figure 6

quantifying the transmission rate. Unfortunately, a
violates tbe requirement of the activation function
train the net. Instead quantisation to n levels may
distributed uniformly in the range + 1/ n to -1 / n to

straight implementation of quantisation
to be continuous, which is necessary to
be simulated by adding a random value
each of the channels in the coded signal.

4.2. TRAINING OF THE SPEECH CODER
The chosen problem was to present a sinJZ;le sample of digitised speech to the input, code to
a single value quantised to fifteen levels, and then to reconstruct tile original speech at the
output . Fifteen levels was chosen as the point where there is a marked loss in the intelligibility
of the speech, so implementation of these coding schemes gives an audible improvement. Two
version of the coder net were implemented, both nets had eight hidden units, with no state
units for the static time independent case and four state units for the dynamic time dependent
case.
The data for this problem was 40 seconds of speech from a single male speaker, digit,ised
to 12 bits at 10kHz and recorded in a laboratory environment. The speech was divided into
two halves, the first was used for training and the second for testing.
The static and the dynamic versions of the architecture were trained on about 20 passes
through the training data. After training the weights were frozen and the inclusion of random
noise was replaced by true quantisation of the coded representation. A further pass was then
made through the test data to yield the performance measurements.
The adaptive training algorithm of Chan 11 was used to dynamically alter the learning
rates during training. Previously these machines were trained with fixed learning rates and
weight update after every sample 3 , and the use of the adaptive t.raining algorithm has been
found to result in a substantially deeper energy minima. Weights were updated after every
1000 samples, that is about 200 times in one pass of the training data.

4.3. COMPARISON OF PERFORMANCE
The performance of a coding schemes can be measured by defining the noise energy as half the
summed squared difference between the actual output and the desired output. This energy
is the quantity minimised by the error propagation algorithm. The lower the noise energy in
relation to the energy of the signal, the higher the performance.
Three non-connectionist coding schemes were implemented for comparison with the static

640

and dynamic net coders. In the first the signal is linearly quantised within the dynamic range
of the original signal. In the second the quantiser is restricted to operate over a reduced
dynamic range, with values outside that range thresholded to the maximuJn and minimum
outputs of the quantiser. The thresholds of the quantiser were chosen to optimise the signal
to noise ratio. The third scheme used the technique of Differential Pulse Code Modulation
(DPCM)12 which involves a linear filter to predict the speech waveform, and the transmitted
signal is the difference between the real signal and the predicted signal. Another linear filter
reconstructs the original signal from the difference signal at the receiver. The filter order of
the DPCM coder was chosen to be the same as the number of state units in the dynamic net
coder, thus both coders can store the same amount of context enabling a comparison with
this established technique.
The resulting noise energy when the signal energy was normalised to unity, and the corresponding signal to noise ratio are given in table 1 for the five coding techniques.
coding method
linear, original thresholds
linear, optimum thresholds
static net
DPCM, optimum thresholds
dynamic net

normalised
nOise energy
0.071
0.041
0.049
0.037
0.028

signal to noise
ratio in dB
11.5
13.9
13.1
14.3
15.5

table 1
The static net may be compared with the two forms of the linear quantiser. Firstly note
that a considerable improvemeut in the signal to noise ratio may be achieved by reducing the
thresholds of the qllantiser from the extremes of the input. This improvement is achieved
because the distribution of samples in the input is concentrated around the mean value, with
very few values near the extremes. Thus many samples are represented with greater accuracy
at the expense of a few which are thresholded. The static net has a poorer performance than
the linear quantiser with optimum thresholds. The form of the linear quantiser solution is
within the class of problems which the static net can represent . It's failure to do so can be
attributed to finding a local minima, a plateau in weight space, or corruption of the true
steepest descent direction by noise introduced by updating the weights more than once per
pass through the training data.
The dynamic net may be compared with the DPCM coding. The output from both these
coders is no longer constrained to discrete signal levels and the resulting noise energy is lower
than all the previous examples. The dynamic net has a significantly lower noise energy than
any other coding scheme, although, from the static net example, this is unlikely to be an
optimal solution. The dynamic net achieves a lower noise energy than the DPCM coder by
virtue of the non-linear processing at each unit, and the flexibility of data storage in the state
units.
As expected from the measured noise energies, there is an improvement in signal quality
and intelligibility from the linear quantised speech through to the DCPM and dynamic net
quantised speech.

5. CONCLUSION
This report has developed three architectures for dynamic nets. Each architecture can be
formulated in a way where the computational requirement is independent of the degree of
context necessary to learn the solution. The FID architecture appears most suitable for

641
implementation on a sf'rial processor, t.hf' nn archit.f'd,11fe has possihle a(lvant,ages for implementation on parallel processors, and the state compression net has a higher degree of
biological plausibility.
Two FID dynamic nets have been coupled together to form a coder, and this has been
applied to speech coding. Although the dynamic net coder is unlikely to have learned the
optimum coding strategy, it does delUonstrate that dynamic nets can be used to 8.Chieve an
improved performance in a real world task over an estaBlished conventional technique.

One of the authors, A J Robinson, is supported by a maintenance grant from the U.K.
Science and Engineering Research Council, and gratefully acknowledges this support.

References
[1] D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning internal representations by
error propagation. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed
Processing: E2:plorations in the M1crostructure of Cognition, Vol. 1: Foundations., Bradford Books/MIT Press, Cambridge, MA , 1986,
[2] O. L. R. Jacobs. IntroductIOn to Contml Theory. Clarendon Press, Oxford, 1974.
[3J A. J. Robinson and F. Fallside. The Utility Drit'en Dynamic Error Propagation Network. Technical Report CUED/F-INFENG/TR.l, Cambridge University Engineering
Department, 1987.
[4J R. W. Prager, T. D. Harrison, and F. Fallside, Boltzmann machines for speech recognition. Compllter Speech and Language, 1:3-27, 1986,
[5] J. L. Elman and D. Zipser. Learning the Hidden Structure of Speech. ICS Report 8701,
University of California, San Diego, 1987.
[6] A. J. Robinson. Speech Rerognition wIth Associatille Networks. M.Phil Computer Speech
and Language Processing thesis, Cambridge University Engineering Department, 1986.
[7] M. I. Jordan. Serial Order: A Parallel Distributed Processing Approach. ICS Report 8604, Institute for Cognitive Science, University of California, San Diego, May
1986.
[8] D. J, C. MacKay. A Method of Increa,sing the Conte2:tual Input to Adaptive Pattern
Recognition Systems. Technical Report RIPRREP /1000 /14/87, Research Initiative in
Pattern Recognition, RSRE, Malvern, 1987.
[9) R. L. Watrous, L. Shastri, and A. H. Waibel. Learned phonetic discrimination using
connectionist networks. In J . Laver and M. A. Jack, editors, Proceedings of the Etl.ropea,n
Conference on Speech Technology, CEP Consultants Ltd, Edinburgh, September 1987.
(10) G. W. Cottrell, P. Munro, and D Zipser. Image Compression by Back Propagation: An
E2:ample of Existential Programming. ICS Report 8702, Institute for Cognitive Science,
University of California, San Diego, Febuary 1986.
[11) L. W . Chan and F. Fallside. An Adaptive Learning Algori.thm for Back Propaga.tion Networks . Technical Report CUED / F-INFENG/TR.2, Cambridge University Engineering
Department, 1987, submitted to Compute?' Speech and Language.
[12] L, R. Rabiner and R. W, Schefer . DIgital Processmg of Speech Signals. Prentice Hall,
Englewood Cliffs, New Jersey, 1978.

"
44,1987,"PARTITIONING OF SENSORY DATA BY A CORTICAL NETWORK","",44-partitioning-of-sensory-data-by-a-cortical-network.pdf,"Abstract Missing","317

PARTITIONING OF SENSORY DATA BY A CORTICAL NETWORK1
Richard Granger, Jose Ambros-Ingerson, Howard Henry, Gary Lynch
Center for the Neurobiology of Learning and Memory
University of California
Irvine, CA. 91717

SUMMARY
To process sensory data, sensory brain areas must preserve information about both
the similarities and differences among learned cues: without the latter, acuity would
be lost, whereas without the former, degraded versions of a cue would be erroneously
thought to be distinct cues, and would not be recognized. We have constructed a
model of piriform cortex incorporating a large number of biophysical, anatomical and
physiological parameters, such as two-step excitatory firing thresholds, necessary and
sufficient conditions for long-term potentiation (LTP) of synapses, three distinct types
of inhibitory currents (short IPSPs, long hyperpolarizing currents (LHP) and long cellspecific afterhyperpolarization (AHP)), sparse connectivity between bulb and layer-II
cortex, caudally-flowing excitatory collateral fibers, nonlinear dendritic summation, etc.
We have tested the model for its ability to learn similarity- and difference-preserving
encodings of incoming sensory cueSj the biological characteristics of the model enable it
to produce multiple encodings of each input cue in such a way that different readouts of
the cell firing activity of the model preserve both similarity and difference 'information.
In particular, probabilistic quantal transmitter-release properties of piriform synapses
give rise to probabilistic postsynaptic voltage levels which, in combination with the activity of local patches of inhibitory interneurons in layer II, differentially select bursting
vs. single-pulsing layer-II cells. Time-locked firing to the theta rhythm (Larson and
Lynch, 1986) enables distinct spatial patterns to be read out against a relatively quiescent background firing rate. Training trials using the physiological rules for induction of
LTP yield stable layer-II-cell spatial firing patterns for learned cues. Multiple simulated
olfactory input patterns (Le., those that share many chemical features) will give rise
to strongly-overlapping bulb firing patterns, activating many shared lateral olfactory
tract (LOT) axons innervating layer Ia of piriform cortex, which in tum yields highly
overlapping layer-II-cell excitatory potentials, enabling this spatial layer-II-cell encoding to preserve the overlap (similarity) among similar inputs . At the same time, those
synapses that are enhanced by the learning process cause stronger cell firing, yielding
strong, cell-specific afterhyperpolarizing (AHP) currents. Local inhibitory intemeurons
effectively select alternate cells to fire once strongly-firing cells have undergone AHP.
These alternate cells then activate their caudally-flowing recurrent collaterals, activating distinct populations of synapses in caudal layer lb. Potentiation of these synapses
in combination with those of still-active LOT axons selectively enhance the response of
caudal cells that tend to accentuate the differences among even very-similar cues.
Empirical tests of the computer simulation have shown that, after training, the
initial spatial layer II cell firing responses to similar cues enhance the similarity of
the cues, such that the overlap in response is equal to or greater than the overlap in
lThis research was supported in part by the Office of Naval Research under grants NOOOl4-84-K-0391
and NOOOl4-87-K-0838 and by the National Science Foundation under grant IST-8S-12419.

? American Institute of Physics 1988

318

input cell firing (in the bulb): e.g., two cues that overlap by 65% give rise to response
patterns that overlap by 80% or more. Reciprocally, later cell firing patterns (after
AHP), increasingly enhance the differences among even very-similar patterns, so that
cues with 90% input overlap give rise to output responses that overlap by less than 10%.
This difference-enhancing response can be measured with respect to its acuity; since 90%
input overlaps are reduced to near zero response overlaps, it enables the structure to
distinguish between even very-similar cues. On the other hand, the similarity-enhancing
response is properly viewed as a partitioning mechanism, mapping quite-distinct input
cues onto nearly-identical response patterns (or category indicators). We therefore use
a statistical metric for the information value of categorizations to measure the value of
partitionings produced by the piriform simulation network.

INTRODUCTION
The three primary dimensions along which network processing models vary are their
learning rules, their performance rules and their architectural structures. In practice,
performance rules are much the same across different models, usually being some variant
of a 'weighted-sum' rule (in which a unit's output is calculated as some function of the
sum ofits inputs multiplied by their 'synaptic' weights). Performance rules are usually
either 'static' rules (calculating unit outputs and halting) or 'settling' rules (iteratively
calculating outputs until a convergent solution is reached). Most learning rules are
either variants of a 'correlation' rule, loosely based on Hebb's (1949) postulate; or a
'delta' rule, e.g., the perceptron rule (Rosenblatt, 1962), the adaline rule (Widrow and
Hoff, 1960) or the generalized delta or 'backpropagation'rule (Parker, 1985; Rumelhart
et al., 1986). Finally, architectures vary by and large with learning rules: e.g., multilayered feedforward nets require a generalized delta rule for convergence; bidirectional
connections usually imply a variant of a Hebbian or correlation rule, etc.
Architectures and learning and performance rules are typically arrived at for reasons
of their convenient computational properties and analytical tractability. These rules
are sometimes based in part on some results borrowed from neurobiology: e.g., 'units'
in some network models are intended to correspond loosely to neurons, and 'weights'
loosely to synapses; the notions of parallelism and distributed processing are based on
metaphors derived from neural processes.
An open question is how much of the rest of the rich literature of neurobiological
results should or could profitably be incorporated into a network modeL From the
point of view of constructing mechanisms to perform certain pre-specified computatonal
functions (e.g., correlation, optimization), there are varying answers to this question.
However, the goal of understanding brain circuit function introduces a fundamental
problem: there are no known, pre-specified functions of any given cortical structures.
We have constructed and studied a physiologically- and anatomically-accurate model of
a particular brain structure, olfactory cortex, that is strictly based on biological data,
with the goal of elucidating the local function of this circuit from its performance in a
'bottom-up' fashion. We measure our progress by the accuracy with which the model
corresponds to known data, and predicts novel physiological results (see, e.g., Lynch
and Granger, 1988; Lynch et al., 1988).
Our initial analysis of the circuit reveals a mechanism consisting of a learning rule
that is notably simple and restricted compared to most network models, a relatively
novel architecture with some unusual properties, and a performance rule that is ex-

319

traordinarily complex compared to typical network-model performance rules. Taken
together, these rules, derived directly from the known biology of the olfactory cortex,
generate a coherent mechanism that has interesting computational properties. This paper describes the learning and performance rules and the architecture of the model; the
relevant physiology and anatomy underlying these rules and structures, respectively;
and an analysis of the coherent mechanism that results.

LEARNING RULES DERIVED FROM LONG-TERM POTENTIATION
Long-term potentiation (LTP) of synapses is a phenomenon in which a brief series
of biochemical events gives rise to an enhancement of synaptic efficacy that is extraordinarily long-lasting (Bliss and L{lJmo, 1973; Lynch and Baudry, 1984; Staubli and Lynch,
1987); it is therefore a candidate mechanism underlying certain forms of learning, in
which few training trials are required for long-lasting memory. The physiological characteristics of LTP form the basis for a straightforward network learning rule.
It is known that simultaneous pre- and post-synaptic activity (i.e., intense depolarization) result in LTP (e.g., Wigstr{IJm et al., 1986). Since excitatory cells are embedded
in a meshwork of inhibitory interneurons, the requisite induction of adequate levels of
pre- and postsynaptic activity is achieved by stimulation of large numbers of afferents
for prolonged periods, by voltage clamping the postsyna.ptic cell, or by chemically blocking the activity of inhibitory interneurons . In the intact animal, however, the q~estion
of how simultaneous pre- and postsynaptic activity might be induced has been an open
question. Recent work (Larson and Lynch, 1986) has shown that when hippocampal
afferents are subjected to patterned stimulation with particular temporal and frequency
parameters, inhibition is naturally eliminated within a specific time window, and LTP
can arise as a result . Figure 1 shows that LTP naturally occurs using short (3-4 pulse)
bursts of high-frequency (100Hz) stimulation with a 200ms interburst interval; only the
second of a pair of two such bursts causes potentiation. This occurs because the normal
short inhibitory currents (IPSPs), which prevent the first burst from depolarizing the
postsynaptic cell sufficiently to produce LTP, are maximally refractory at 200ms after
being stimulated, and therefore, although the second burst arrives against a hyperpolarized background resulting from the long hyperpolarizing currents (LHP) initiated by the
first burst, the second burst does not initiate its own IPSPs, since they are then refractory. The studies leading to these conclusions were performed in in vitro hippocampal
slices; LTP induced by this patterned stimulation technique in intact animals shows no
measurable decrement prior to the time at which recording arrangements deteriora.te:
more than a month in some cases (see Staubli and Lynch, 1987).
PERFORMANCE RULES DERIVED FROM
OLFACTORY PHYSIOLOGY AND BEHAVIOR
From the above data we may infer that LTP itself depends on simultaneous pre- and
postsynaptic activity, as Hebb postulated, but that a sufficient degree of the latter occurs
only under particular conditions. Those conditions (patterned stimulation) suggest the
beginnings of a performance rule for the network. Drawing this out requires a review
of the inhibitory currents active in hippocampus and in piriform cortex. Three classes
of such currents are known to be present: short IPSPs, long LHPs and extremely long,
cell-specific afterhyperpolarization, or AHP (see Figure 2). Short IPSPs arise from both
feedforward and feedback activation of inhibitory interneurons which in turn synapse

320

on excitatory cells (e.g., layer IT cells, which are primary excitatory cells in piriform).
IPSPs develop more slowly than excitatory postsynaptic potentials (EPSPs) but quickly
shunt the EPSP, thus reversing the depolarization that arises from EPSPs, and bringing
the cell voltage down below its original resting potential. IPSPs last approximately 50lOOms, and then enter a refractory period during which they cannot be reactivated
from about 100-30Oms after they have been once activated. Longer hyperpolarization
(LHP) is presumably dependent on a distinct type of inhibitory interneuron or inhibitory
receptor, and arises in much the same way; however, these cells are apparently not
refractory once activated. LHP lasts for 300-500ms.
Taken together, IPSPs and LHP constitute a form of high-pass frequency filter:
200ms after an input burst, a subsequent input will arrive against a background of
hyperpolarization due to LHP, yet this input will not initiate its own IPSP due to
the refractory period. If the input is a single pulse, its EPSP will fail to trigger the
postsynaptic cell, since it will not be able to overcome the LHP-induced hyperpolarized
potential of the cell. Yet if the input is a high-frequency burst, the pulses comprising
the burst will give rise to different behavior. Ordinarily, the first EPSP would have been
driven back to resting potential by its accompanying IPSP, before the second pulse in the
burst could arrive. But when the IPSP is absent, the first EPSP is not driven rapidly
down to resting potential, and the second pulse sums with it, raising the voltage of
the postsynaptic cell and allowing voltage-dependent channels to open, thereby further
depolarizing the cell, and causing it to spike (Figure 3). Hence these high-frequency
bursts fire the cell, while single pulses or lower-frequency bursts would not do so. When
these cells fire, then active synapses can be potentiated.
The third inhibitory mechanism, AHP, is a current that causes an excitatory cell
to become refractory after it has fired strongly or rapidly. This mechanism is therefore
specific to those cells that have fired, unlike the first two mechanisms. AHP can prevent
a cell from firing again for as long as 1000ms (1 second).
It has long been observed that EEG waves in the hippocampi of learning animals are
dominated by the theta rhythm, Le., activity occuring at about 4-8Hz. This is now seen
to correspond to the optimal rate for firing postsynaptic cells and for enhancing synapses
via LTP; i.e., this rhythmic aspect of the performance rules of these networks is suggested
by the physiology ofLTP. The resulting activation patterns may take the following form:
relatively synchronized cell firing occurring approximately once every 200ms, i.e., spatial
patterns of induced activity occurring at the rate of one new spatial cell-firing pattern
every 200ms. The cells most strongly participating in anyone firing pattern will not
participate in subsequent patterns (at least the next 4-5 patterns, i.e., SOO-lOOOms),
due to AHP. This raises the interesting possibility that different spatial patterns (at
different times) may be conveying different information about their inputs. In summary,
postsynaptic cells fire in pulses or bursts depending on the synaptically-weighted sums
of their active axonal inputs; this firing is synchronized across the cells in a structure,
giving rise to a spatial pattern of activity across these cells; once cells fire they will
not fire again in subsequent patterns; each pattern (occuring at the theta rhythm, i.e.,
approximately once every 200ms) will therefore consist of extremely different spatial
patterns of cell activity. Hence the 'output' of such a network is a sequence of spatial
patterns.
In an animal engaged in an olfactory discrimination learning task, the theta rhythm

321

dominates the animals behavior: the animals literally sniff at theta. We have been
able to sustitute direct stimulation (in theta-burst mode) of the lateral olfactory tract
(LOT), which is the input to the olfactory cortex, for odors: these 'electrical odors'
are learned and discriminated by the animals, either from other electrical odors (via
different stimulating electrodes) or from real odors. Furthermore, behavioral learning
in this paradigm is accompanied by LTP of piriform synapses (Roman et al., 1987).
This experimental paradigm thus provides us with a known set of behaviorally-relevant
inputs to the olfactory cortex that give rise to synaptic potentiation that apparently
underlies the learning of the stimuli.

ARCHITECTURE OF OLFACTORY CORTEX
Nasal receptor cells respond differentially to different chemicals; these cells topographically innervate the olfactory bulb, which is arranged such that combinations of
specific spatial 'patches' of bulb characteristically respond to specific odors. Bulb also
receives a number of centrifugal afferents from brain, most of which terminate on the
inhibitory granule cells. The excitatory mitral cells in bulb send out axons that form
the lateral olfactory tract (LOT), which constitutes the only major input to olfactory
(piriform) cortex. This cortex in turn has some feedback connections to bulb via the
anterior olfactory nucleus.
Figure 4 illustrates the anatomy of the superficial layers of olfactory cortex: the
LOT axons flow across layer la, synapsing with the dendrites of piriform layer-IT cells.
Those cells in turn give rise to collateral axon outputs which flow, in layer Ib, parallel
and subjacent to the LOT, in a predominantly rostral-to-caudal direction, eventually
terminating in entorhinal cortex. Layer 180 is very sparsely connected; the probability
of synapses between LOT axons and layer-IT cell dendrites is less than 0.10 (Lynch,
1986), and decreases caudally. Layer Ib (where collaterals synapse with dendrites) is
also sparse, but its density increases caudally, as the number of collaterals increases; the
overall connectivity density on layer-IT-cell dendrites is approximately constant throughout most of piriform. Layer IT also contains, in addition to the principal excitatory cells
(modified stellates), inhibitory interneurons which synapse on excitatory cells within a
specified radius, forming a 'patchwork' of cells affected by a particular inhibitory cell;
the spheres of influence of inhibitory cells almost certainly overlap somewhat. There are
approximately 50,000 LOT axons, 500,000 piriform layer IT cells, and a much smaller
number of inhibitory cells that divide layer IT roughly into functional patches. (See
Price, 1973; Luskin and Price, 1983; Krettek and Price, 1977; Price and Slotnick, 1983;
Haberly and Price, 1977, 197880, 1978b).
The layer IT cell collateral axons flow through layer ill for a distance before rising
up to layer Ib (Haberly, 1985); taken in combination with the predominantly caudal
directionality of these collaterals, this means that rostral piriform will be dominated by
LOT inputs. Extreme caudal piriform (and all of lateral entorhinal cortex) is dominated
by collaterals from more rostral cells; moving from rostral to caudal piriform, cells
increasingly can be thought of as 'hybrid cells': cells receiving inputs from both the
bulb (via the LOT) and from rostral piriform (via collateral axons). The architectural
characteristics of rostral piriform is therefore quite different from that of caudal piriform,
and differential analysis must be performed of rostral cells vs. hybrid cells, as will be
seen later in the paper.

322

SIMULATION AND FORMAL ANALYSIS: INTRODUCTION
We have conducted several simulations of olfactory cortex incorporating many of
the physiological features discussed earlier. Two hundred layer IT cells are used with
100 input (LOT) lines and 200 collateral axons; both the LOT and collateral axons
flow caudally. LOT axons connect with rostral dendrites with a probability of 0.2,
which decreases linearly to 0.05 by the caudal end of the model. The connectivity is
arranged randomly, subject to the constraint that the number of contacts for axons and
dendrites is fixed within certain narrow b01llldaries (in the most severe case, each axon
forms 20 synapses and each dendrite receives 20 contacts). The resulting matrix is thus
hypergeometric in both dimensions. There are 20 simulated inhibitory interneurons,
such that the layer IT cells are arranged in 20 overlapping patches, each within the
influence of one such inhibitory cell. Inhibition rules are approximately as discussed
above; i.e., the short IPSP is longer than an EPSP but only one fifth the length of the
LHP; cell-specific AHP in tum is twice as long as LHP.
Synaptic activity in the model is probabilistic and quantal: for any presynaptic
activation, there is a fixed probability that the synapse will allow a certain amount
of conductance to be contributed to the postsynaptic cell. Long-term potentiation
was represented by a 40% increase in contact strength, as well as an increase in the
probability of conductance being transmitted. These effects would be expected to arise,
in situ, from modifying existing synapses as well as adding new ones (Lynch, 1986),
two results obtained in electron microscopic studies (Lee et al., 1980). Only excitatory
cell synapses are subject to LTP. LTP occurred when a cell was activated twice at a
simulated 200ms interval: the first input 'primes' the synapse so that a subsequent
burst input can drive it past a threshold value; following from the physiological results,
previously potentiated synapses were much less different from ""naive"" synapses when
driven at high frequency (see Lynch et al., 1988). The simulation used theta burst
activation (i.e., bursts of pulses with the bursts occurring at 5Hz) of inputs during
learning, and operated according to these synchronized fixed time steps, as discussed
above.
The network was trained on sets of ""odors"" , each of which was represented as a group
of active LOT lines, as in the ""electric odor"" experiments already described. Usually
three or four ""components"" were used in an odor, with each component consisting of a
group of contiguous LOT lines. We assumed that the bulb normalized the output signal
to about 20% of all LOT fibers. In some cases, more specific bulb rules were used and
in particular inhibition was assumed to be greatest in areas surrounding an active bulb
""patch"" .
The network exhibited several interesting behaviors. Learning, as expected, increased the robustness of the response to specific vectors; thus adding or subtracting
LOT lines from a previously learned input did not, within limits, greatly change the
response. The model, like most network simulations, dealt reasonably well with degraded or noisy known signals. An unexpected result developed after the network had
learned a succession of cues. In experiments of this type, the simulation would begin to
generate two quite distinct output signals within a given sampling episode; that is, a single previously learned cue would generate two successive responses in successive 'sniffs'
presented to an ""experienced"" network. The first of these response patterns proved to
be common to several signals while the second was specific to each learned signal. The

323

common signal was found to occur when the network had learned 3-5 inputs which
had substantial overlap in their components (e.g., four odors that shared ::::::70% of their
components). It appeared then that the network had begun to produce ""category"" or
""clustering"" responses, on the first sniff of a simulated odor, and ""individual"" or ""differentiation"" responses on subsequent sniffs of that same odor. When presented with a
novel cue which contained elements shared with other, previously learned signals, the
network produced the cluster response but no subsequent individual or specific output
signal. Four to five cluster response patterns and 20 - 25 individual responses were
produced in the network without distortion.
In retrospect, it was clear that the model accomplished two necessary and in some
senses opposing operations: 1) it detected similarities in the members of a cue category
or cluster, and, 2) it nonetheless distinguished between cues that were quite similar. Its
first response was to the similarity-based category and its second to the specific signal.

ANALYSIS OF CATEGORIZATION IN ROSTRAL PIRIFORM
Assume that a set of input cues (or 'simulated odors') XCI, Xf3 .. . X' differ from each
other in the firing of dx LOT input lines; similarly, inputs Y CI , yf3 ... y' differ in dy
lines, but that inputs from the sets X and Y differ from each other in D X,y > > d lines,
such that the XS and the Ys form distinct natural categories. Then the performance of
the network should give rise to output (layer II cell) firing patterns that are very similar
among members of either category, but different for members of different categories;
i.e., there should be a single spatial pattern of response for members of X, with little
variation in response across members, and there should be a distinct spatial pattern of
response for members of Y.
Considering a matrix constructed by uniform selection of neurons, each with a hypergeometric distribution for its synapses, as an approximation of the bidimensional
hypergeometric matrix described above, the following results can be derived. The expected value of el, the Hamming distance between responses for two input cues differing
by 2d LOT lines (input Hamming distance of d) is:

where No is the number of postsynaptic cells, each Si is the probability that a cell will
have precisely i active contacts from one of the two cues, and I(i, j) is the probability
that the number of contacts on the cell will increase (or decrease) from i to j with
the change in d LOT lines; Le., changing from the first cue to the second. Hence, the
first term denotes the probability of a cell decreasing its number of active contacts from
above to below some threshold, (), such that that cell fired in response to one cue but not
the other (and therefore is one of the cells that will contribute to the difference between
responses to the two cues). Reciprocally, the second term is the probability that the
cell increases its number of active synapses such that it is now over the threshold; this
cell also will contribute to the difference in response. We restrict our analysis for now
to rostral piriform, in which there are assumed to be few if any collateral axons. We
will return to this issue in the next subsection.

324

The value for each Sa., the probability of a active contacts on a cell, is a hypergeometric function, since there are a fixed number of contacts anatomically between LOT
and (rostral) piriform cells:

where N is the number of LOT lines, A is the number of active (firing) LOT lines, n is
the number of synapses per dendrite formed by the LOT, and a is the number of active
such synapses. The formula can be read by noting that the first binomial indicates
the number of ways of choosing a active synapses on the dendrite from the A active
incoming LOT lines; for each of these, the next expression calculates the number of
ways in which the remaining n - a (inactive) synapses on the dendrite are chosen from
the N - A inactive incoming LOT lines; the probability of active synapses on a dendrite
depends on the sparseness ofthe matrix (Le., the probability of connection between any
given LOT line and dendrite); the solution must be normalized by the number of ways
in which n synapses on a dendrite can be chosen from N incoming LOT lines.
The probability of a cell changing its number of contacts from a to a is:

I(a, a)

= 2:

11-'=
a.-4

where N, n, A, and a are as above, I is the ""loss"" or reduction in the number of active
synapses, and 9 is the gain or increase. Hence the left expression is the probability of
losing I active synapses by changing d LOT lines, and the right-hand expression is the
probability of gaining 9 active synapses. The product of the expressions are summed
over all the ways of choosing I and 9 such that the net change 9 - I is the desired
difference a-a.
If training on each cue induces only fractional LTP, then over trials, synapses contacted by any overlapping parts of the input cues should become stronger than those
contacted only by unique parts of the cue. Comparing two cues from within a category,
vs. two cues from between categories, there may be the same number of active synapses
lost across the two cues in either case, but the expected strength of the synapses lost in
the former case (within category) should be significantly lower than in the latter case
(across categories). Hence, for a given threshold, the difference J between output firing
patterns will be smaller for two within-category cues than for cues from two different
categories.
It is important to note that clustering is an operation that is quite distinct from
stimulus generalization. Observing that an object is a car does not occur because of a
comparison with a specific, previously learned car. Instead the category ""car"" emerges
from the learning of many different cars and may be based on a ""prototype"" that has
no necessary correspondence with a specific, real object. The same could be said of
the network. It did not produce a categorical response when one cue had been learned

325

and second similar stimulus was presented. Category or cluster responses, as noted,
required the learning of several exemplars of a similarity-based cluster. It is the process
of extracting corrunonalities from the environment that defines clustering, not the simple
noting of similarities between two cues.
An essential question in clustering concerns the location of the boundaries of a given
group; i.e., what degree of similarity must a set of cues possess to be grouped together?
This issue has been discussed from any number of theoretical positions (e.g., information
theory) i all these analyses incorporate the point that the breadth of a category must
reflect the overall homogeneity or heterogeneity of the environment. In a world where
things are quite similar, useful categories will necessarily be composed of objects with
much in common. Suppose, for instance, that subjects were presented with a set of
four distinct coffee cups of different colors, and asked later to recall the objects. The
subjects might respond by listing the cups as a blue, red, yellow and green coffee cup,
reflecting a relatively specific level of description in the hierarchy of objects that are
coffee cups. In contrast, if presented with four different objects, a blue coffee cup, a
drinking glass, a silver fork and a plastic spoon, the cup would be much more likely
to be recalled as simply a cup, or a coffee cup, and rarely as a blue coffee cup; the
specificity of encoding chosen depends on the overall heterogeneity of the environment.
The categories formed by the simulation were quite appropriate when judged by an
information theoretic measure, but how well it does across a wide range of possible
worlds has not been addressed.

ANALYSIS OF PROBLEMS ARISING FROM CAUDAL AXON FLOW
The anatomical feature of directed flow of collateral axons gives rise to an immediate
problem in principle. In essence, the more rostral cells that fire in response to an input,
the more active inputs there are from these cells to the caudal cells, via collateral axons,
such that the probability of caudal cell firing increases precipitously with probability of
rostral cell firing. Conversely, reducing the number of rostral cells from firing, either
by reducing the number of active input LOT axons or by raising the layer II cell firing
threshold, prevents sufficient input to the caudal cells to enable their probability of
firing to be much above zero.
This problem can be stated formally, by making assumptions about the detailed
nature of the connectivity of LOT and collateral axons in layer I as these axons proceed
from rostral to caudal piriform. The probability of contact between LOT axons and
layer-II-cell dendrites decreases caudally, as the number of collateral axons is increasing,
given their rostral to caudal flow tendency. This situation is depicted in Figure 4.
Assuming that probability of LOT contact tends to go to zero, we may adopt a labelling
scheme for axons and synaptic contacts, as in the diagram, in which some combination
of LOT axons (a:k) and collateral axons (h"",,) contact any particular layer II cell dendrite
(hn), each of which is itself the source of an additional collateral axon flowing to cells
more caudal than itself. Then the cell firing function for layer II cell hn is:

where the a:k denote LOT axon activity of those axons still with nonzero probability
of contact for layer II cell hn, the hm. denote activity of layer II cells rostral of hn, 0 is

326

the cell firing threshold, Wnm is the synaptic strength between axon m and dendrite n,
and H is the Heaviside step function, equal to 1 or 0 according to whether its argument
is positive or negative. H we assume instead that probability of cell firing is a graded
function rather than a step function, we may eliminate the H step function and calculate
the firing of the cell (hn) from its inputs (hn,net) via the logistic:

hn,net

=L

m<n

hmWnm +

L

Zk Wnk

k~n

1

hn

= 1 + e- (khn,net + 9n )

Then we may expand the expression for firing of cell h n as follows:

hn =

[1 + e-(l:m<n hmwnm + l:k~n ZkWnk + 9)]-1

By assuming a fixed firing threshold, and varying the number of active input LOT
lines, the probability of cell firing can be examined. Numerical simulation of the above
expressions across a range of LOT spatial activation patterns demonstrates that probability of cell firing remains near zero until a critical number of LOT lines are active, at
which point the probability flips to close to 100% (Figure 5). This means that, for any
given firing threshold, given fewer than a certain amount of LOT input, practically no
piriform cells will fire, whereas a slight increase in the number of active LOT lines will
mean that practically all piriform cells should fire.
This excruciating dependence of cell firing on amount of LOT input indicates that
normalization of the size of the LOT input alone will be insufficient to stabilize the
size of the layer II response; even slight variation of LOT activity in either direction has
extreme consequences. A number of solutions are possible; in particular, the known local
anatomy and physiology of layer II inhibitory intemeurons provides a mechanism for
controlling the amount of layer II response. As discussed, inhibitory interneurons give
rise to both feedforward (activated by LOT input) and feedback (activated by collateral
axons) activity; the influence of any particuar interneuron is limited anatomically to
a relatively small radius around itself within layer II, and the influence of multiple
interneurons probably overlap to some extent. Nonetheless, the 'sphere of influence' of
a particular inhibitory interneuron can be viewed as a local patch in layer II, within
which the number of active excitatory cells is in large measure controlled by the activity
of the inhibitory cell in that patch. If a number of excitatory cells are firing with varying
depolarization levels within a patch in layer II, activation of the inhibitory cells by the
excitatory cells will tend to weaken those excitatory cells that are less depolarized than
the most strongly-firing cell within the patch, leading to a competition in which only
those cells firing most strongly within a patch will burst, and these cells will, via the
interneuron, suppress multiple firing of other cells within the patch. Thus the patch
takes on some of the characteristics of a 'winner-take-all' network (Feldman, 1982): only
the most strongly firing cells will be able to overcome inhibition sufficiently to burst,
some additional cells will pulse once and then be overwhelmed by inhibition, and the
rest of the cells in the patch will be silent, even though that patch may be receiving a
large amount of excitatory input via LOT and collateral axon activity in layer I.

327

EMERGENT CATEGORIZATION BEHAVIOR IN THE MODEL
The probabilistic quantal transmitter-release properties of piriform synapses described above give rise to probabilistic levels of postsynaptic depolarization. This inherent randomness of cell firing, in combination with activity oflocal inhibitory patches
in layer IT, selects different sets of bursting and pulsing cells on different trials if no
synaptic enhancement has taken place. The time-locked firing to the theta rhythm
enables distinct spatial patterns of firing to be read out against a relatively quiescent
background firing rate. Synaptic LTP enhances the conductances and alters the probabilistic nature of corrununication between a given axon and dendrite, which tends to
overcome the randomness of the cell firing patterns in untrained cells, yielding a stable
spatial pattern that will reliably appear in response to the same input in the future,
and in fact will appear even in response to degraded or noisy versions of the input pattern. Furthermore, subsequent input patterns that differ in only minor respects from a
learned LOT input pattern will contact many of the already-potentiated synapses from
the original pattern, thereby tending to give rise to a very similar (and stable) output
firing pattern. Thus as multiple cues sharing many overlapping LOT lines are learned,
the layer IT cell responses to each of these cues will strongly resemble the responses
to the others. Hence, the response(s) behave as though simply labelling a category
of very-similar cues; sufficiently different cues will give rise to quite-different category
responses.
EMERGENT DIFFERENTIATION BEHAVIOR IN THE MODEL
Potentiated synapses cause stronger depolarization and firing of those cells participating in a 'category' response to a learned cue. This increased depolarization causes
strong, cell-specific afterhyperpolarization (AHP), effectively putting those cells into a
relatively long-lasting (~ lsec) refractory period that prevents them from firing in response to the next few sampling sniffs of the cue. Then the inhibitory 'winner-take-all'
behavior within patches effectively selects alternate cells to fire, once these stronglyfiring (learned) cells have undergone AHP. These alternates will be selected with some
randomness, given the probabilistic release characteristics discussed above, since these
cells will tend not to have potentiated synapses. These alternate cells then activate
their caudally-flowing recurrent collaterals, activating distinct populations of synapses
in caudal layer Th. Potentiation of these synapses in combination with those of stillactive LOT axons tends to 'recruit' stable subpopulations of caudal cells that are distinct
for each simulated odor. They are distinct for each odor because first rostral cells are
selected from the population of unpotentiated or weakly-potentiated cells (after the
strongly potentiated cells have been removed via AHP)i hence they will at first tend to
be selected randomly. Then, of the caudal cells that receive some activation from the
weakening caudal LOT lines, those that also receive collateral innervation from these
semi-randomly selected rostrals will be those that will tend to fire most strongly, and
hence to be potentiated.
The probability of a cell participating in the rostral semi-randomly selected groups
for more than one odor (e.g., for two similar odors) is lower than the probability of
cells being recruited by these two odors initially, since the population are those that
receive not enough input from the LOT to have been recruited as a category cell and
potentiated, yet receive enough input to fire as an alternate cell. The probability of any
caudal cell then being recruited for more than one odor by these rostral cell collaterals

328

in combination with weakening caudal LOT lines is similarly low. The product of these
two probabilities is of course lower still. Hence, the probability that any particular
caudal cell potentiated as part of this process will participate in response to more than
one odor is very low.
This means that, when sampling (sniffing), the first pattern of cell firing will indicate
similarity among learned odors, causing AHP of those patterns; thus later sniffs will
generate patterns of firing that tend to be quite different for different odors, even when
those odors are very similar. Empirical tests of the simulation have shown that odors
consisting of 90%-overlapping LOT firing patterns will give rise to overlaps of between
85% and 95% in their initial layer IT spatial firing patterns, whereas these same cues
give rise to layer IT patterns that overlap by less than 20% on 2nd and 3rd sniffs.
The spatia-temporal pattern of layer IT firing over multiple samples thus can be taken
as a strong differentiating mechanism for even very-similar cues, while the initial sniffresponse for those cues will nonetheless give rise to a spatial firing pattern that indicates
the similarity of sets of learned cues, and therefore their 'category membership' in the
clustering sense.
CLUSTERING
Incremental clustering of cues into similarity-based categories is a more subtle process than might be thought and while it is clear that the piriform simulation performs
this function, we do not know how optimal its performance is in an information-theoretic
sense, relative to some measure of the value or cost of information in the encoding.
Building a categorical scheme is a non-monotonic, combinatorial problem: that is, each
new item to be learned can have disproportionate effects on the existing scheme, and
the number of potential categories (clusters) climbs factorially with the number of items
to be categorized. Algorithmic solutions to problems of this type are computationally
very expensive. Calculation of an ideal categorization scheme (with respect to particular cost measures in a performance task), using a hill-climbing algorithm derived from
an information-theoretic measure of category value, applied to a problem involving 22
simulated odors, required more than 4 hours on a 68020-based processor. The simulation network reached the same answer as the game-theoretic program, but did so in
seconds. It is worth mentioning again that the simulation did so while simultaneously
learning unique encodings for the cues, as described above, which is itself a nontrivial
task.
Humans, on at least some tasks, may carry out clustering by building initial clusters
and then merging or splitting them as more cues are presented. Thus far, the networks
do not pass through successive categorization schema. However, experiments on human categorization have almost exclusively involved situations in which all cues were
presented in rapid succession and category membership is taught explicitly, rather than
developed independently by the subject. Hence, it is not clear from the experimental
literature whether or not stable clusters develop in this way from stimuli presented at
widely spaced intervals with no category membership information given, which is the
problem corresponding to that given the network (and that is likely common in nature). It will be of interest to test categorizing skills of rats learning successive olfactory
discriminations over several days. Using appropriately selected stimuli, it should be possible to determine if stable clusters are constructed and whether merging and splitting
occurs over trials.

329

Any useful clustering device must utilize information about the heterogenity of the
stimulus world in setting the heterogeneity of individual categories. Heterogeneity of
categories refers to the degree of similarity that is used to determine if cues are to be
grouped together or not. Several network parameters will influence category size and we
are exploring how these influence the individuation function; one particularly interesting
possibility involves a shifting threshold function, an idea used with great success by
Cooper in his work on visual cortex. The problems presented to the simulation thus far
involve a totally naive system, one that has had no ""developmental"" history. We are
currently exploring a model in which early experiences are not learned by the network
but instead set parameters for later (""adult"") learning episodes. The idea is that early
experience determines the heterogenity of the stimulus world and imprints this on the
network, not by specific changes in synaptic strengths, but in a more general fashion.

CONCLUSIONS
Neurons have a nearly bewildering array of biophysical, chemical, electrophysiological and anatomical properties that control their behavior; an open question in neural network research is which of these properties need be incorporated into networks in order to
simulate brain circuit function. The simulation described here incorporates an extreme
amount of biological data, and in fact has given rise to novel physiological questions,
which we have tested experimentally with results that are counterintuitive and previously unsuspected in the existing physiological literature (see, e.g., Lynch and Granger,
1988; Lynch et al., 1988). Incorporation of this mass of physiological parameters into
the simulation gives rise to a coherent architecture and learning and performance rules,
when interpreted in terms of computational function of the network, which generates a
robust capability to encode multiple levels of information about learned stimuli. The
coherence of the data in the model is useful in two ways: to provide a framework for
understanding the purposes and interactions of many apparently-disparate biological
properties of neurons, and to aid in the design of novel artificial network architectures
inspired by biology, which may have useful computational functions.
It is instructive to note that neurons are capable of many possible biophysical functions, yet early results from chronic recording of cells from olfactory cortex in animals
actively engaged in learning many novel odors in an olfactory discrimination task clearly
shows a particular operating mode of this cortical structure when it is actively in use
by the animal (Larson et al., unpublished data). The rats in this task are very familiar
with the testing paradigm and exhibit very raid learning, with no difficulty in acquiring
large numbers of discriminations. Sampling, detection and responding occur in fractions
of a second, indicating that the utilization of recognition memories in the olfactory system can be a rapid operation; it is not surprising, then, that the odor-coded units so
far encountered in our physiological experiments have rapid and stereotyped responses.
Given the dense innervation of the olfactory bulb by the brain, it is possible that the
type of spatial encoding that appears to be responsible for the preliminary results of
these chronic experiments would not appear in animals that were not engaged in active sampling or were confronted with unfamiliar problems. That is, the operation of
the olfactory cortex might be as dependent upon the behavioral 'state' and behavioral
history of the rat as upon the actual odors presented to it. It will be of interest to
compare the results from well-trained freely-moving animals with those obtained using
more restrictive testing conditions.

330

The temporal properties of synaptic currents and afterpotentials, results from simulations and chronic recording studies, taken together, suggest two useful caveats for
biological models:
? Cell firing in cortical structures (e.g., piriform, hippocampus and possibly neocortex) is linked to particular rhythms (theta in the case of piriform and hippocampus) during real learning behavior, and thus it is likely that the 'coding language'
of these structures involves spatial cell firing patterns within a brief time window.
This stands in contrast to other methods such as frequency coding that appears
in other structures (such as peripheral sensory structures, e.g., retina and cochlea;
see, e.g., Sivilotti et al., 1987).
? Temporal sequences of spatial patterns may encode different types of information,
such as hierarchical encodings of perceptions, in contrast with views in which
either asynchronous 'cycling' activity occurs or a system yields a single punctate
output and then halts.
In particular, simulation of piriform gives rise to temporal sequences of spatial patterns
of synchronized cell firing in layer IT, and the patterns change over time: the physiology
and anatomy of the structure cause successive 'sniffs' of the same olfactory stimulus
to give rise to a sequence of spatial patterns, each of which encodes successively more
specific information about the stimulus, beginning with its similarity to other previouslylearned stimuli, and ending with a unique encoding of its characteristics. It is possible
that both the early similarity-based 'cluster' information and the late unique encodings
are used, for different purposes, by brain structures that receive these signals as output
from piriform.

ACKNOWLEDGEMENTS
Much of the theoretical underpinning of this work depends critically on data generated by John Larson; we are grateful for his insightful advice and help. This work has
benefited from discussions with Michel Baudry, Mark Gluck, and Ursula Staubli. Jose
Ambros-Ingerson is supported by a fellowship from Hewlett-Packard, Mexico, administered by UC MEXUS.
REFERENCES

Bliss, T.V.P. and L~mo, T. (1973). Long-lasting potentiation of synaptic transmission
in the dentate area of the anesthetized rabbit following stimulation of the perforant
path. 1.Physiol.Lond. 232:357-374.
Feldman, J.A. (1982). Dynamic connections in neural networks. Biological Cybernetics
46:27-39.
Haberly, L.B. (1985). Neuronal circuitry in olfactory cortex: Anatomy and functional
implications. Chemical Senses 10:219-238.
Haberly, L.B. and J.L. Price (1977). The axonal projection patterns of the mitral and
tufted cells of the olfactory bulb in the rat. Brain Res 129:152-157.

331

Haberly, L.B. and J.L. Price (1978a). Association and commissural fiber systems of
the olfactory cortex of the rat. I. Systems originating in the piriform cortex and
adjacent areas. J. Compo Neurol. 178:711-740.
Haberly, L.B. and J.L. Price (1978b). Association and commissural fiber systems of
the olfactory cortex of the rat. II. Systems originating in the olfactory peduncle.
J. Compo Neurol. 181:781-808.
Hebb, D.O. (1949). The Organization of Behavior. New York: Wiley.
Krettek, J.E. and J.L. Price (1977). Projections from the amygdaloid complex and
adjacent olfactory structures to the entorhinal cortex and to the subiculum in the
rat and cat. J Comp NeuroI172:723-752.
Larson, J. and G. Lynch (1986). Synaptic potentiation in hippocampus by patterned
stimulation involves two events. Science 232:985-988.
Lee, K., Schottler, F., Oliver, M. and Lynch, G. (1980). Brief bursts of high-frequency
stimulation produce two types of structural change in rat hippocampus.
J.Neurophysiol. 44:247-258.
Lynch, G. and Baudry, M. (1984). The biochemistry of memory: a new and specific
hypothesis. Science 224:1057-1063.
Lynch, G. (1986). Synapses, circuits, and the beginnings of memory. Cambridge,
Mass: MIT Press.
Lynch, G., Larson, J., Staubli, U., and Baudry, M. (1987). New perspectives on the
physiology, chemistry and pharmacology of memory. Drug Devel.Res. 10:295-315.
Lynch, G., Granger, R., Levy, W. and Larson, J. (1988). Some possible functions
of simple cortical networks suggested by computer modeling. In: Neural Models
of Plasticity: Theoretical and Empirical Approaches, Byrne, J. and Berry, W.O.
(Eds.), (in press).
Lynch, G. and Granger, R. (1988). Simulation and analysis of a cortical network. The
Psychology of Learning and Motivation, Vo1.22 (in press).
Luskin, M.B. and J.L. Price (1983). The laminar distribution of intracortical fibers
orginating in the olfactory cortex of the rat . J Comp NeuroI216:292-302.
Parker, D.B. (1985). Learning-logic. MIT TR-47, Massachusetts Institute of Technology, Center for Computational Research in Economics and Management Science,
Cambridge, Mass.
Price, J.L. (1973). An autoradiographic study of complementary laminar patterns of
termination of afferent fibers to the olfactory cortex. J.Comp.Neur. 150:87-108.
Price, J .L. and B.M. Slotnick (1983). Dual olfactory representation in the rat thalamus:
An anatomical and electrophysiological study. J Comp NeuroI215:63-77.
Roman, F., Staubli, U. and Lynch, G. (1987). Evidence for synaptic potentiation in a
cortical network during learning. Brain Res. 418:221-226.
Rosenblatt, F. (1962). Principles ofneurodynamics. New York: Spartan.
Rumelhart, D., Hinton, G. and Williams, R. (1986). Learning Internal Representations by Error Propagation. In D.Rumelhart and J.McClelland (Eds.), Parallel

332

Distributed Processing, Cambridge: MIT Press.
Sivilotti, M.A., Mahowald, M.A. and Mead, C.A. (1987). Real-time visual computations using analog CMOS processing arrays. In: Advanced Research in VLSI (Ed.
Paul Losleben), MIT Press, Cambridge.
Staubli, U. and Lynch, G. (1987). Stable hippocampal long-term potentiation elicited
by ""theta"" pattern stimulation. Brain Res. (in press).
Widrow, G. and Hoff, M.E. (1960). Adaptive Switching Circuits. Institute of Radio
Engineers, Western Electronic Convention Record, Part ., pp.96-104.
Wigstrf/Sm, H., B. Gustaffson, Y.Y. Huang and W.C. Abraham (1986). Hippocampal
long-term potentiation is induced by pairing single afferent volleys with intracellularly injected depolarizing current pulses. Acta Physiol Scand 126:317-319.

333

A

....... ID

SI HI!
I

I

200

11\8

B
,...

I]

In

ID

S2

2

8ec

? ?

? ? ?

?.. . .......... . . . . ..

I] .s~

? ? ?

? .. . . . ... .... . ..

:::>

51

e

'V

Il-

en

Il-

""""

I

,...
M
'V

....
....en

""""

140

80

? ......

3

:-:.~

10

20

30

.A.

.
40

?

?

.,.,.......

??

? ?

??

50

60

70

TIME (MINUTES)

C

BEFORE

AFTER

SUPERIMPOSED

Figure 1. LTP induction by short high-frequency bursts involves sequential ""priming"" and ""consolidation"" events.
A) Sl and S2 represent separate groups of Shaffer/commissural fibers converging on a
single CAl pyramidal neuron. The stimulation pattern employed consisted of pairs of
bursts (each 4 pulses at 100Hz) given to Sl and S2 respectively, with a 200ms delay
between them. The pairs were repeated 10 times at 2 sec intervals.
B) Only the synapses activated by the delayed burst (52) showed LTP. The top panel
shows measurements of amplitudes of intracellular EPSPs evoked by single pulses to
Sl before and after patterned stimulation (given at 20 min into the experiment). The
middle panel shows the amplitude of EPSPs evoked by 52. Bottom panel shows EP5P
amplitudes for both pathways expressed as a percentage of their respective sizes before
burst stimulation.
C) Shown are records of EPSPs evoked by 51 and 52 five min. before and 40 min. after
patterned burst stimulation. Calibration bar: SmV, 5msec. (From Larson and Lynch,
1986).

334

-------1[>

12

----~t>

<]-----

EPSP -20 msec No
IPSP ~IOO msec CI
LHP -.5sec
K
AHP -lsec
K

Figure 2. Onset and duration of events comprising stimulation of a layer IT cell
in piriform cortex. Axonal stimulation via the lateral olfactory tract (LOT) activates
feedforward EPSPs with rapid onset and short duration (:::::20msec) and two types of
feedforward inhibition: short feedforward IPSPs with slower onset and somewhat longer
duration (~10Omsec) than the EPSPs, and longer hyperpolarizing potentials (LHP)
lasting :::::500msec. These two types of inhibition are not specific to firing cells; an
additional, very long-lasting (:::::1sec) inhibitory afterhyperpolarizing current (AHP) is
induced in a cell-specific fashion in those cells with intense firing activity. Finally,
feedback EPSPs and IPSPs are induced by activation via recurrent collateral axons
from layer IT cells.

335

FIRST

SECOND

TENTH

Sl-AHP

L
S2 CONTROL

~S2

Figure 3. When short, high-frequency bursts are input to cells 200ms after an
initial 'priming' event, the broadened EPSPs (see Figure 1) will allow the contributions
ofthe second and subsequent pulses comprising the burst to sum with the depolarization
of the first pulse, yielding higher postsynaptic depolarization sufficient to cause the cell
to spike. (From Lynch, Larson, Staubli and Baudry, 1987).

336

KIDDLI

NlTE1lIOll

rOsntllOI

to layer IV

.nt.- po.t.
"" ""
..
,rob.bUity of LOT cont.ct p.r uoa. cI.cr..... - n ia conn.at
.
_ _......
~

,robabUity of ???oc. coa.t.cc p.r

UOD

ia coa.eaa.t- ""n"" acr ?????

Aa.oc

lel.elv.
contribution
to .,lUna
cell

LOT

.aterior

~.rior

Figure 4. Organization of extrinsic and feedback inputs to layer-II cells of piriform
cortex. The axons comprising the lateral olfactory tract (LOT), originating from the
bulb, innervate distal dendrites, whereas the feedback collateral or associational fibers
contact proximal dendrites. Layer II cells in anterior (rostral) piriform are depicted as
being dominated by extrinsic (LOT) input, whereas feedback inputs are more prominent
on cells in posterior (caudal) piriform.

337

Tapered Feedforward Firing Probabilities
10?r-----------------------~~~~~~~1

80

60

...
-Go

~

.c
m
.c
a

4-

40

....

000-

~

0..

StirrufusA
Stirrufus B
Stirrufus C
Stirrufus 0
CumHypergmt

20

O~~~~~~~~~~~~~
o

1

2

3

4

5 6 7
8 9 10 11 12 13
Number Firing (of 40 Connections)

14 15

Figure 5. Probability onayer-ll-cell firing as a function of number of LOT axons active, in the absence of local inhibitory patches. The hypergeometric function ('CumHypergmt ') specifies the probability o{layer II cell firing in the absence of caudally-directed
feedback collaterals, i.e., assuming that all collaterals are equally probable to travel either rostrally or caudally. In this case, there is a smooth S-shaped function for probability of cell firing with increasing LOT activity, so that adjustment of global firing threshold (e.g., via nonspecific cholinergic inputs affecting all piriform inhibitory interneurons)
can effectively normalize piriform layer II cell firing. However, when feedback axons are
caudally directed, then probability steepens markedly, becoming a near step function,
in which the probability of cell firing is exquisitely sensitive to the number of active
inputs, across a range of empirically-tested LOT stimulation patterns (A - D in the
figure). In this case, global adjustment of inhibition will fail to adequately normalize
layer II cell firing: the probability of cell firing will always be either near zero or near
1.0; i.e., either nearly all cells will fire or almost none will fire. Local inhibitory control
of 'patches' oflayer II solve this problem (refer to text).

"
45,1987,"An Optimization Network for Matrix Inversion","",45-an-optimization-network-for-matrix-inversion.pdf,"Abstract Missing","397

AN OPTIMIZATION NETWORK FOR MATRIX INVERSION
Ju-Seog Jang, S~ Young Lee, and Sang-Yung Shin
Korea Advanced Institute of Science and Technology,
P.O. Box 150, Cheongryang, Seoul, Korea
ABSTRACT
Inverse matrix calculation can be considered as an optimization. We have
demonstrated that this problem can be rapidly solved by highly interconnected
simple neuron-like analog processors. A network for matrix inversion based on
the concept of Hopfield's neural network was designed, and implemented with
electronic hardware. With slight modifications, the network is readily applicable to
solving a linear simultaneous equation efficiently. Notable features of this circuit
are potential speed due to parallel processing, and robustness against variations of
device parameters.
INTRODUCTION
Highly interconnected simple analog processors which mmnc a biological
neural network are known to excel at certain collective computational tasks. For
example, Hopfield and Tank designed a network to solve the traveling salesman
problem which is of the np -complete class,l and also designed an AID converter
of novel architecture2 based on the Hopfield's neural network model?' 4 The network could provide good or optimum solutions during an elapsed time of only a
few characteristic time constants of the circuit.
The essence of collective computation is the dissipative dynamics in which initial voltage configurations of neuron-like analog processors evolve simultaneously
and rapidly to steady states that may be interpreted as optimal solutions. Hopfield
has constructed the computational energy E (Liapunov function), and has shown
that the energy function E of his network decreases in time when coupling coefficients are symmetric. At the steady state E becomes one of local minima.
In this paper we consider the matrix inversion as an optimization problem,
and apply the concept of the Hopfield neural network model to this problem.
CONSTRUCTION OF THE ENERGY FUNCTIONS
Consider a matrix equation AV=I, where A is an input n Xn matrix, V is
the unknown inverse matrix, and I is the identity matrix. Following Hopfield we
define n energy functions E Ie' k = 1, 2, ... , n,
n

E 1 = (1I2)[(~ A 1j V j1 -1)2
)-1
n

E2 =

n

n

j-1

)-1

+ (~A2) V j1 )2 + ... + (~Anj Vj1)2]
n

(1/2)[(~A1)V)2l + (~A2)V)2-1)2 +
)=1

)=1

? American Institute of Physics 1988

n

+ (~An)V}2)2]
}-1

398

n

En =

n

n

(1/2)[(~ A1J VJn)2 + (~A2J V jn )2 + ... + (~An) VJn _1)2]
j=l

(1)

J-1

}=1

where AiJ and ViL.are the elements of ith row and jth column of matrix A and
V, respectively. when A is a nonsingular matrix, the minimum value (=zero) of
each energy function is unique and is located at a point in the corresponding
hyperspace whose coordinates are { V u:, V 2k ' "" ' , V nk }, k = 1, 2, ""', n. At
this minimum value of each energy function the values of V 11' V 12' ... , Vnn
become the elements of the inverse matrix A -1. When A is a singular matrix the
minimum value (in general, not zero) of each energy function is not unique and is
located on a contour line of the minimum value. Thus, if we construct a model
network in which initial voltage configurations of simple analog processors, called
neurons, converge simultaneously and rapidly to the minimum energy point, we can
say the network have found the optimum solution of matrix inversion problem.
The optimum solution means that when A is a nonsingular matrix the result is the
inverse matrix that we want to know, and when A is a singular matrix the result
is a solution that is optimal in a least-square sense of Eq. (1).
DESIGN OF THE NETWORK AND THE HOPFIELD MODEL

Designing the network for matrix inversion, we use the Hopfield model
without inherent loss terms, that is,

a

- - = ---Ek(V 11' V 2k' . . . , V nk )
dt
aV ik

(2)

i,k=1,2, ... ,n

where u ik is the input voltage of ith neuron in the kth network, V ik is its output,
and the function gik is the input-output relationship. But the neurons of this
scheme operate in all the regions of gik differently from Hopfield's nonlinear 2state neurons of associative memory models.3 ? 4
From Eq. (1) and Eq. (2), we can define coupling coefficients Tij between
ith and jth neurons and rewrite Eq. (2) as
n

n

- - = - ~ TiJ V)k
dt
j=l

+

Aki ,

TiJ =

~ AliAIJ

= Tji

'

1=1

(3)
It may be noted that Ti ? is independent of k and only one set of hardware is
needed for all k. The implemented network is shown in Fig. 1. The same set of
n

hardware with bias levels, ~ A Ji h), can be used to solve a linear simultaneous
)=1

399

equation represented by Ax=b for a given vector b.

INPUT

OUTPUT

Fig. 1. Implemented network for matrix inversion with externally
controllable coupling coefficients. Nonlinearity between
the input and the output of neurons is assumed to be
distributed in the adder and the integrator.
The application of the gradient Hopfield model to this problem gives the result
that is similar to the steepest descent method. s But the nonlinearity between the
input and the output of neurons is introduced. Its effect to the computational
capability will be considered next.
CHARACTERISTICS OF THE NETWORK
For a simple case of 3 x3 input matrices the network is implemented with
electronic hardware and its dynamic behavior is simulated by integration of the
Eq. (3). For nonsingular input matrices, exact realization of Tij connection and
bias Ali is an important factor for calculation accuracy, but the initial condition
and other device parameters such as steepness, shape and uniformity of gil are
not. Even a complex gik function shown in Fig. 2 can not affect the computational capability. Convergence time of the output state is determined by the
characteristic time constant of the circuit. An example of experimental results is
shown in Fig. 3. For singular input matrices, the converged output voltage configuration of the network is dependent upon the initial state and the shape of gil'

400

,...-_ _ _ _ _
Vm-t-_ _ _--::==----r Aik >1

=1

<1

Vm

Ui\<

Fig. 2. gile functions used in computer simulations where
Aile is the steepness of sigmoid function tanh (Aile uile)'

input
A=
matrix

[-I1 2r 1I]

0.5 -I

(cf) A-I = [

1 0-1

0

1

-o.~]

0.5 -I -1.5

0.50 -0.98 -0.49J
output
V = [ 0.02 0.99 1.00
matrix
0.53 -0.98 - 1.50

0.5

o

?

Fig. 3. An example of experimental results

401

COMPLEXITY ANALYSIS
By counting operations we compare the neural net approach with other wellknown methods such as Triangular-decomposition and Gauss-Jordan elimination.6
(1) Triangular-decomposition or Gauss-Jordan elimination method takes 0 (8n 3/3)
multiqlications/divisions and additions for large n Xn matrix inversion, and
o (2n /3) multiplications/divisions and additions for solving the linear simultaneous
equation Ax=b.
(2) The neural net approach takes the number of operations required to calculate
Tij (nothing but matrix-matrix multiplication), that is, 0 (n 3 /2) multiplications and
additions for both matrix inversion and solving the linear simultaneous equation.
And the time required for output stablization is about a few times the characteristic time constant of the network. The calculation of coupling coefficients can
be directly executed without multiple iterations by a specially designed optical
matrix-matrix multiplier,' while the calculation of bias values in solving a linear
simultaneous equation can be done by an optical vector-matrix multiplier. 8 Thus,
this approach has a definite advantage in potential calculation speed due to global
interconnection of simple parallel analog processors, though its calculation accuracy may be limited by the nature of analog computation. A large number of
controllable Tij interconnections may be easily realized with optoelectronic devices.9
CONCLUSIONS
We have designed and implemented a matrix inversion network based on the
concept of the Hopfield's neural network model. 1bis network is composed of
highly interconnected simple neuron-like analog processors which process the information in parallel. The effect of sigmoid or complex nonlinearities on the computational capability is unimportant in this problem. Steep sigmoid functions reduce
only the convergence time of the network. When a nonsingular matrix is given as
an input, the network converges spontaneously and rapidly to the correct inverse
matrix regardless of initial conditions. When a singular matrix is given as an
input, the network gives a stable optimum solution that depends upon initial conditions of the network.
REFERENCES
1. J. J. Hopfield and D. W. Tank, BioI. Cybern. 52, 141 (1985).

2.
3.
4.
5.
6.

D. W. Tank and J. J. Hopfield, IEEE Trans. Circ. Sys. CAS-33, 533 (1986).
J. J. Hopfield, Proc. Natl. Acad. Sci. U.S.A. 79, 2554 (1982).
J. J. Hopfield, Proc. Natl. Acad. Sci. U.S.A. 81 , 3088 (1984).
G. A. Bekey and W. J. Karplus, Hybrid Computation (Wiley, 1968), P. 244.
M . J. Maron, Numerical Analysis: A Practical Approach (Macmillan, 1982),
p. 138.
7. H . Nakano and K. Hotate, Appl. Opt. 26, 917 (1987).
8. J. W. Goodman, A. R. Dias, and I. M. Woody, Opt. Lett. ~ 1 (1978).
9. J. W. Goodman, F. J. Leonberg, S-Y. Kung, and R. A. Athale, IEEE Proc.
72, 850 (1984).

"
46,1987,"Performance Measures for Associative Memories that Learn and Forget","",46-performance-measures-for-associative-memories-that-learn-and-forget.pdf,"Abstract Missing","432

Performance Measures for Associative Memories
that Learn and Forget
Anthony /(uh
Department of Electrical Engineering
University of Hawaii at Manoa
Honolulu HI, 96822

ABSTRACT
Recently, many modifications to the McCulloch/Pitts model have been proposed
where both learning and forgetting occur. Given that the network never saturates (ceases
to function effectively due to an overload of information), the learning updates can continue indefinitely. For these networks, we need to introduce performance measmes in addition to the information capacity to evaluate the different networks. We mathematically
define quantities such as the plasticity of a network, the efficacy of an information vector,
and the probability of network saturation. From these quantities we analytically compare
different networks.

1. Introduction

Work has recently been undertaken to quantitatively measure the computational
aspects of network models that exhibit some of the attributes of neural networks. The
McCulloch/Pitts model discussed in [1] was one of the earliest neural network models to be
analyzed. Some computational properties of what we call a Hopfield Associative Memory
Network (HAMN) :similar to the McCulloch/Pitts model was discussed by Hopfield in [2].
The HAMN can be measured quantitatively by defining and evaluating the information
capacity as [2-6] have shown, but this network fails to exhibit more complex computational
capabilities that neural network have due to its simplified structure. The HAMN belongs
to a class of networks which we call static. In static networks the learning and recall procedures are separate. The network first learns a set of data and after learning is complete,
recall occurs. In dynamic networks, as opposed to static networks, updated learning and
associative recall are intermingled and continual. In many applications such as in adaptive
communications systems, image processing, and speech recognition dynamic networks are
needed to adaptively learn the changing information data. This paper formally develops
and analyzes some dynamic models for neural networks. Some existing models [7-10] are
analyzed, new models are developed, and measures are formulated for evaluating the performance of different dynamic networks.
In [2-6]' the asymptotic information capacity of the HAMN is defined and evaluated.
In [4-5]' this capacity is found by first assuming that the information vectors (Ns) to be
stored have components that are chosen randomly and independently of all other components in all IVs. The information capacity then gives the maximum number of Ns that
can be stored in the HAMN such that IVs can be recovered with high probability during
retrieval. At or below capacity, the network with high probability, successfully recovers
the desired IVs. Above capacity, the network quickly degrades and eventually fails to
recover any of the desired IVs. This phenomena is sometimes referred to as the ""forgetting
catastrophe"" [10]. In this paper we will refer to this phenomena as network saturation.
There are two ways to avoid this phenomena. The first method involves learning a
limited number of IVs such that this number is below capacity. After this leaming takes
place, no more learning is allowed. Once learning has stopped, the network does not
change (defined as static) and therefore lacks many of the interesting computational

@

American Institute of Physics 1988

433

capabilities that adaptive learning and neural network models have . The second method is
to incorporate some type oC forgetting mechanism in the learning structure so that the
inCormation stored in the network can never exceed capacity. This type of network would
be able to adapt to the changing statistics of the IVs and the network would only be able
to recall the most recently learned IVs. This paper focuses on analyzing dynamic networks
that adaptively learn new inCormation and do not exhibit network saturation phenomena
by selectively Corgetting old data. The emphasis is on developing simple models and much
oC the analysis is performed on a dynamic network that uses a modified Hebbian learning
rule.
Section 2 introduces and qualitatively discusses a number of network models that are
classified as dynamic networks. This section also defines some pertinent measures Cor
evaluating dynamic network models. These measures include the plasticity of a network,
the probability oC network saturation, and the efficacy of stored IVs. A network with no
plasticity cannot learn and a network with high plasticity has interconnection weights that
exhibit large changes. The efficacy oC a stored IV as a function oC time is another important parameter as it is used in determining the rate at which a network forgets information.
In section 3, we mathematically analyze a simple dynamic network referred to as the
Attenuated Linear Updated Learning (AL UL) network that uses linear updating and a
modified Hebbian rule. Quantities introduccd in section 3 are analytically dctcrmincd for
the ALUL network. By adjusting the attenuation parameter of the AL UL network, the
Corgetting factor is adjusted. It is shown that the optimal capacity for a large AL UL network in steady state defined by (2.13,3.1) is a factor of e less than the capacity of a
HAMN. This is the tradeoff that must be paid for having dynamic capabilities. We also
conjecture that no other network can perform better than this network when a worst case
criterion is used. Finally, section 4 discusses further directions for this work along with possible applications in adaptive signal processing.
2. Dynamic Associative Memory Networks

The network models discussed in this paper are based on the concept of associative
memory. Associative memories are composed of a collection of interconnected elements
that have data storage capabilities. Like other memory structures, there are two operations that occur in associative memories. In the learning operation (referred to as a write
operation for conventional memories), inCormation is stored in the network structure. In
the recall operation (referred to as a read operation for conventional memories), information is retrieved from the memory structure. Associative memories recall information on
the basis of data content rather than by a specific address. The models that we consider
will have learning and recall operations that are updated in discrete time with the activation state XU) consisting of N cells that take on the values {-l,1}.
2.1. Dynamic Network MeasureS

General associative memory networks are described by two sets of equations. If we
let XU) represent the activation state at time i and W( k) represent the weight matrix 01?
interconnection state at time k then the activation or recall equation is described by

X(j+ 1) = f (XU), W(k)),

i? 0, k? 0, X(O)

=

X

(2.1 )

where X is the data probe vector used for reca.ll. The learning algorithm or int.erconnection equation is described by

W(k+ 1) = g(V(i),O::; i< k, W(O))
where {V( i)} are the information vectors (IV)s to be stored and W(O) is the initial state of
the interconnection matrix. Usually the learning algorithm time scale is much longer than

434

the recall equation time scale so that W in (2.1) can be considered time invariant. Often
(2.1) is viewed as the equation governing short term memory and (2 .2) is the equation
governing long term memory. From the Hebbian hypothesis we note that the data probe
vectors should have an effect on the interconnection matrix W. If a number of data p!'Obe
vectors recall an IV V( a') , the strength of recall of the IV V( i) should be increased by
appropriate modification of W. If another IV is never recalled, it should gradually be forgotten by again adjusting terms of W. Following the analysis in [4,5] we assume that all
components of IVs introduced are independent and identically distributed Bernoulli random
variables with the probability of a 1 or -1 being chosen equal to ~.
Our analysis focuses on learning algorithms. Before describing some dynamic learning
algorithms we present some definitions. A network is defined as dynamic if given sorne
period of time the rate of change of W is never nonzero. In addition we will primarily discuss networks where learning is gradual and updated at discrete times as shown in (2.2).
By gradual, we want networks where each update usually consists of one IV being learned
and/or forgotten. IVs that have been introduced recently should have a high probability of
recovery. The probability of recall for one IV should also be a monotonic decreasing function of time, given that the IV is not repeated. The networks that we consider should also
have a relatively low probability of network saturation.
Quantitatively, we let e(k,l,i} be the event that an IV introduced at time l can be
recovered at time k with a data probe vector which is of Hamming distance i f!'Om the
desired IV. The efficacy of network recovery is then given as p(k,l,i) = Pr(e(k,l,i)). In
the analysis performed we say a a vector V can recover V(I), if V(I) = 6(V) where 6(.)
is a synchronous activation update of all cells in the network. The capacity for dynamic
networks is then given by

O(k,i,l)

=

maxm3-Pr(r(e(k,l,i),05:I<k)= m)

> l-l

O<i<
N
2

(2.3)

where r(X} gives the cardinality of the number of events that occur in the set X. Closely
related to the capacity of a network is network saturation. Saturation occurs when the
network is overloaded with IVs such that few or none of the IVs can be successfully
recovered. When a network at time 0 starts to leal'll IVs, at some time l < i we have that
O(l,i,l? OU,i,l). For k>1 the network saturation probability is defined by S(k,m)
where S describes the probability that the network cannot recover m IVs.
Another important measure in analyzing the performance of dynamic networks is t.he
plasticity of the interconnections of the weight matrix W. Following definitions that are
similar to [10], define
N

2: 2: V AR{ Wi,j(k) - Wi,j(k-l)}

h(k) =

i"".

ii-I

N(N-l)

(2.4)

as the incremental synaptic intensity and
N

2: 2:V AR{ Wi,j(k)}

H(k) =

i""..;;= 1

N(N-l)

(2 .5)

as the cumulative synaptic intensity . From these definitions we can define the plasticity of
the network as

P(k)

=

h(k)

H(k)

(2.6)

When network plasticity is zero, the network does not change and no learning takes place.
When plasticity is high, the network interconnections exhibit large changes.

435

When analyzing dynamic networks we are often interested if the network reaches a
steady state. We say a dynamic network reaches steady state if

limH(k) = H

(2.7)

Ie--.oo

where H is a finite nonzero constant. If the IVs have stationary statistics and given that
the learning operations are time invariant, then if a network reaches steady state, we have
that

(2.8)

limP(k) = P

Ie-+oo

where P is a finite constant. It is also easily verified from (2.6) that if the plasticity converges to a nonzero constant in a dynamic network, then given the above conditions on the
IVs and the learning operations the network will eventually reach steady state.
Let us also define the synaptic state at time k for activation state V as

s(k, V) = W(k)V
From the synaptic state, we Can define the SNR of V, which we show
closely related to the efficacy of an IV and the capacity of the network .

SNR(k, V,i) =

(E(s.(k V)))2
.,

VAR(si(k, V))

(2.9)
III

section 3 is

(2.1O)

Another quantity that is important in measuring dynamic networks is the complexity
of implementation. Quantities dealing with network complexity are discussed in [12] and
this paper focuses on networks that are memory less. A network is memoryless if (2.2) can
be expressed in the following form:

W(k+ 1) = 9 #( W(k), V(k))

(2.11)

Networks that are not memoryless have the disadvantage that all Ns need t.o be saved during all learning updates. The complexity of implementation is greatly increased in terms of
space complexity and very likely increased in terms of time complexity.
2.2. Examples of Dynamic Associative Memory Networks

The previous subsection discussed some quantities to measure dynamic networks.
This subsection discusses some examples of dynamic associative memo!,y networks and
qualitatively discusses advantages and disadvantages of different networks . All the networks considered have the memoryless propel?ty.
The first network that we discuss is described by the following difference equation

W(k+ 1)

=

a(k)W(k) + b(k)L(V(k))

(2.12)

with W(O) being the initial value of weights before any learning has taken place . Networks
with these learning rules will be labeled as Linear Updated Learning (LUL) networks and
in addition if O<a(k)<l for k2::0 the network is labeled as an Attenuated Linear Updated
Learning (ALUL) network. We will primarily deal with ALUL where O<a(k)<l and b(k)
do not depend on the position in W. This model is a specialized version of Grossberg's
Passive Decay LTM equation discussed in [11]. If the learning algorithm is of the conelation type then

L(V(J.?))

=

V(k)V(kf-1

(2.13)

This learning scheme has similarities to the marginalist learning schemes introduced in [10].
One of the key parameters in the ALUL network is the value of the attenuation coefficient
a. From simulations and intuition we know that if the attenuation coefficient is to high,
the network will saturate and if the attenuation parameter is to low, the network will

436

forget all but the most recently introduced IVs. Fig. 1 uses Monte Carlo methods to show
a plot of the number of IVs recoverable in a 64 cell network when a = 1, (the HAMN) as a
function of the learning time scale. From this figure we clearly see that network saturation
is exhibited and for the time k ~ 25 no IV are recoverable with high probability. Section 3
further analyzes the AL UL network and derives the value of different measUl'es introduced
in section 2.1.
Another learning scheme called bounded learning (BL) can be described by

L(V(k)) = {

V(k)V(k)T - I

F(W(k)~A

0

F( W(J.:))<A

(2.14)

By setting the attenuation parameter a = 1 and letting

F(W(k)) = ~a;<Wi.i(k)

(2 .15)

I,J

this is identical to the learning with bounds scheme discussed in [10]. Unfortunately there
is a serious drawbacks to this model. If A is too large the network will saturate with high
probability. If A is set such that the probability of network saturation is low then the network has the
characteristic of not learning for almost all
values of
k > k(A) = min I :7 F( W(I))~ A. Th~efore we have that the efficacy of netwOl'k
recovery, p (k,1 ,0) ~ 0 for all J.: ~ I ~ k{A).
In order for the (BL) scheme to be classified as dynamic learning, the attenuation
parameter a must have values between 0 and 1. This learning scheme is just a more complex version of the learning scheme derived from (2.10,2 .11). Let us qualitatively analyze
the learning scheme when a and b are constant. There are two cases to consider. When
A> H, then the network is not affected by the bounds and the network behaves as the
AL UL network. When A <H, then the network accepts IVs until the bound is reached.
When the bound is reached, the network waits until the values of the interconnection
matrix have attenuated to the prescribed levels where learning can continue. If A is judiciously chosen, BL with a < 1 provides a means for a network to avoid saturation. By
holding an IV until H(k )<A, it is not too difficult to show that this learning scheme is
equivalent to an AL UL network with b(k) time varying.
A third learning scheme called refresh learning (RL) can be described by (2 .12) with

b(k)=I, W(O)=O, and
a(k) = 1 -.5(kmod(l))

(2.16)

This learning scheme learns a set of IV and periodically refreshes the weighting matrix so
that all interconnections are O. RL can be classified as dynamic learning, but learning is
not gradual during the periodic l'efresh cycle. Another problem with this learning scheme is
that the efficacy of the IVs depend on where during the period they were learned. IVs
learned late in a period are quickly forgotten where as IVs learned eady in a period have a
longer time in which they are recoverable.
In all the learning schemes introduced, the network has both learning and forgetting
capabilities, A network introduced in [7,8] separates the learning and forgetting tasks by
using the standard HAMN algorithm to learn IV and a random selective forgetting algorithm to unlearn excess information. The algorithm which we call random selective forgetting (RSF) can be described formally as follows.

W(k+ 1)

=

Y(J.:) + L(V(k))

(2.17)

where
n(FU!::(k)))

Y(k) = W(k) -Jl(k)

2..;
i= 1

(V(k,a')V(k,i)T -n(F(W(k)))I)

(2.18)

437

Each of the vectors V( k, i) are obtained by choosing a random vector V in the same
manner IVs are chosen and letting V be the initial state of the HAMN with interconnection
matrix W(k). The recall operation described by (2.1) is repeated until the activation has
settled into a local minimum state . V(k,i) is then assigned this state. /L(k) is the rate at
which the randomly selected local minimum energy states are forgotten, W(k) is given by
(2.15), and n (X) is a nonnegative integer valued function that is a monotonically increasing
function of X.
The analysis of the RSF algorithm is difficult, because the energy manifold that
describes the energy of each activation state and the updates allowable for (2.1) must be
well understood. There is a simple transformation between the weighting matrix and the
energy of an activation state given below,

E(X(k)) = -~~~Wi,jX;?(j)Xj(k)
i

k>O

(2 .19)

j

but aggregately analyzing all local minimum energy activation states is complex. Through
computer simulations and simplified assumptions [7,8] have come up with a qualitative
explanation of the RSF algorithm based on an eigenvalue approach.

3. Analysis of the ALUL Network
Section 2 focused on defining properties and analytical measures for dynamic AMN
along with presenting some examples of some learning algorithms for dynamic AMN. This
section will focus on the analysis of one of the simpler algorithms, the ALUL network.
From (2.12) we have that the time invariant ALUL network can be described by the following interconnection state equation.

W(k+ 1) = aW(k)

+ bL(V(k))

(3.1 )

where a and b are nonnegative real numbers . Many of the measures introduced in section
2 can easily be determined for the AL UL network.
To calculate the incremental synaptic intensity h (k) and the cumulative synaptic
intensity H(k) let the initial condition of the interconnection state W"",i(O) be independent
of all other interconnections states and independent of all IVs. If E W"",i(O) = 0 and
V AR W.. ,j(O) = ""Y then

(3.2)
and

(3.3)
In steady state when a < 1 we have that
p = 2(1~)

(3.4)

From this simple relationship between the attenuation parameter a and the plasticity
measure P, we can directly relate plasticity to other measures such as the capacity of the
network.
We define the steady state capacity as C(i,i)= lim C(k,i,i) for networks where
k--o.o

steady

state

exists.

To analytically determine the capacity first assume that
S(k, V(j)) = S(k-i) is a jointly Gaussian random vector. Further assume that Si(l) for
1~ i< N, 1~ 1< m are all independent and identically distributed. Then for N sufficiently
large, f(a) = a2(k...,.-,l}(1~2), and

438

SNR(k, VU))

=

= (N-l)f(a)

SNR(k-n

I-f{a)

= c{a )logN

?

1

j<k

(3.5)

we have that

p{k,j,O) =
1~

~l _

N

2

V21rC (a )logN

(3.6)

j<k

Given a we first find the largest m= k-j>O where
~~p{k,j,O)= 1 when

lim p(k,j,O)

~

1.

Note that

N-oo

c(a?2. By letting c(a)= 2 the maximum m is given when
2logN
f(a)
=
N
I-f (a)

(3.7)

Solving for m we get that

1

I [
210gN
og (N + 21ogN)(1-a2)

m =

1

2

-.......::.-------~

loga

+1

(3.8)

It is also possible to find the value of a that maximizes m. If we let f = 1 - a2 , then

I [
2logN
og (N+ 2logN)f

1

m ~

(3.9)
f

.
m .IS at a maximum
vaI ue wh en f

2elogN or w h en m ~
NT
. h ?IS correspon ds to
N
2elogN
a ~ 2m -l. Note that this is a factor of e less than the maximum number of Ns allowable
2m
in a static HAMN [4,5], such that one of the Ns is recoverable. By following the analysis
in [5], the independence assumption and the Gaussian assumptions used earlier can be
removed. The arguments involve using results from exchangeability theory and normal
approximation theory.
~

A similar and somewhat more cumbersome analysis can be performed to show that in
steady state the maximum capacity achievable is when a ~ 2m -l and given by
2m
lim C(k,O,f)

N-oo

=

~N

4e og

(3.10)

This again is a factor of e less than the maximum number of Ns allowable in a static
HAMN [4,5]' such that all Ns are recoverable. Fig. 2 shows a Monte Carlo simulation of
the number of Ns recoverable in a 64 cell network versus the learning time scale for a
varying between .5 and .99. We can see that the network reaches approximate steady state
when k:2: 35. The maximum capacity achievable is when a ~ .9 and the capacity is around
5. This is slightly more than the theoretical value predicted by the analysis just shown
when we compare to Fig. 1. For smaller simulations conducted with larger networks the
simulated capacity was closer to the predicted value. From the simulations and the
analysis we observe that when a is too small Ns are forgotten at too high a rate and when

439

a is too high network saturation occurs.

Using the same arguments, it is possible to analyze the capacity of the network and
efficacy of rvs when k is small. Assuming zero initial conditions and a

~ 2m-l we can

2m
The learning behavior can be

summarize the learning behavior of the AL UL network.

divided into three phases. In the first phase for k<
N
all Ns are remembered and
- 4elogN
the characteristics of the network are similar to the HAMN below saturation. In the
second phase some rvs are forgotten as the rate of forgetting becomes nonzero. During this
phase the maximum capacity is reached as shown in fig . 2. At this capacity the network
cannot dynamically recall all IVs so the network starts to forget more information then it
receives. This continues until steady state is reached where the learning and forgetting
rates are equal. If initial conditions are nonzero the network starts in phase 1 or the beginning of phase 2 if H( k) is below the value corresponding to the maximum capacity and at
the end of phase 2 for larger H( k).
The calculation of the network saturation probabilities S( k, m) is trivial for large networks when the capacity curves have been found. When m~ C(k,O,E) then S(k,m) ~ 0
otherwise S(k ,m) ~ 1.
Before leaving this section let us briefly examine AL UL networks where a (k) and
b(k) are time varying. An example of a time varying network is the marginalist learning
scheme

introduced in [10]. The network is defined by fixing the value of the
= D(N) for all k. This value is fixed by setting a= 1 and varying b. Since
the VARSi(k,V(k-l)) is a monotonic increasing function of k, b(k) must also be a monotonic increasing function of k. It is not too difficult to show that when k is large, the marginalist learning scheme is equivalent to the steady state AL UL defined by (3.1). The argument is based on noting that the steady state SNR depends not on the update time, but
on the difference between the update time and when the rv was stored as is the case with
the marginalist learning scheme. The optimal value of D( N) giving the highest capacity is
when D(N) = 4elogN and

SNR(k,k-l,i)

b(k+ 1) =
where m

=

2m b(k)
2m-l

(3.11)

N
4elogN'

If performance is defined by a worst case criterion with the criterion being

J(I,N) =

min(C(k,O,E),k~/)

(3.12)

then we conjecture that for I large, no AL UL as defined in (2.12,2.13) can have larger
J(I,N) than the optimal ALUL defined by (3.1). If we consider average capacity, we note
that the RL network has an average capacity of

N

810gN

which is larger than the optimal

AL UL network defined in (3.1). However, for most envisioned applications a worst case
criterion is a more accurate measure of performance than a criterion based on average
capacity.
4. Summary
This paper has introduced a number of simple dynamic neural network models and
defined several measures to evaluate the performance of these models. All parameters for
the steady state AL UL network described by (3.1) were evaluated and the attenuation
parameter a giving the largest capacity was found. This capacity was found to be a factor
of e less than the static HANIN capacity. Furthermore we conjectured that if we consider
a worst case performance criteria that no AL UL network could perform better than the

440

optimal ALUL network defined by (3.1). Finally, a number of other dynamic models
including BL, RL, and marginalist learning were stated to be equivalent to AL UL networks
under certain conditions.
The network models that were considered in this paper all have binary vector valued
activation states and may be to simplistic to be considered in many signal processing application. By generalizing the analysis to more complicated models with analog vector valued
activation states and continuous time updating it may be possible to use these generalized
models in speech and image processing. A specific example would be a controller for a
moving robot. The generalized network models would learn the input data by adaptively
changing the interconnections of the network. Old data would be forgotten and data that
was repeatedly being recalled would be reinforced. These network models could also be
used when the input data statistics are nonstationary.

References
[I]

W. S. McCulloch and W . Pitts, ""A Logical Calculus of the Ideas Iminent in Nervous
Activity"", Bulletin of Mathematical Biophysics, 5, 115-133, 1943.

[2)

J. J. Hopfield, ""Neural Networks and Physical Systems with Emergent Collective Computational Abilities "", Proc. Natl. Acad. Sci. USA 79, 2554-2558, 1982.

[3J

Y. S. Abu-Mostafa and J. M. St. Jacques, ""The Information Capacity of the Hopfield
Model"", IEEE Trans. Inform. Theory, vol. IT-31, 461-464, 1985.

[4)

R. J. McEliece, E. C. Posner, E. R. Rodemich and S. S. Venkatesh, ""The Capacity of
'the Hopfield Associative Memory"", IEEE Trans. Inform. Theory, vol. IT-33, 461-482,
1987.

[5J

A. Kuh and B. W. Dickinson, ""Information Capacity of Associative Memories "", to be
published IEEE Trans. Inform. Theory.

[6]

D. J. Amit, H. Gutfreund, and H. Sompolinsky, ""Spin-Glass Models of Nev.ral Networks"", Phys. Rev. A, vol. 32, 1007-1018, 1985.

[7J

J. J. Hopfield, D. I. Feinstein, and R. G. Palmer, "" 'Unlearning' has a StabIlizing
effect in Collective Memories"", Nature, vol. 304, 158-159, 1983.

[8]

R. J. Sasiela, ""Forgetting as a way to Improve Neural-Net Behavior"" , AIP Conference Proceedings 151, 386-392, 1986.

[9]

J. D. Keeler, ""Basins of Attraction of Neural Network Models"",
Proceedings 151, 259-265, 1986.

[10]

J. P. Nadal, G. Toulouse, J. P. Changeux, and S. Dehaene, ""Networks of Formal

AlP Conference

Neurons and Memory Palimpsests"", Europhysics Let., Vol. 1,535-542, 1986.
[11)

S. Grossberg, ""Nonlinear Neural Networks: Principles, Mechanisms, and Architectures "", Neural Networks in press.

[12J

S. S. Venkatesh and D. Psaltis, ""Information Storage and Retrieval in Two Associative Nets "", California Institute of Technology Pasadena, Dept. of Elect. Eng., preprint, 1986.

441

""HAMN Capacity""
10
N=64,

1024 trials

8

>
0

-a- Average # of IV

6

::ea:

co

C)

CIS

4

""-

co

>

<

2
0
0

10

20
Update Time

30

40

Fig. 1

""ALUL Capacity""

10

......

a=.5
a=.7
-II- a=.90
a=.95
a=.99
-Go

N=64, 1024 trials

~0

8

en

6

...en

~

....

0

::ea:

co

4

C)

CIS
""-

co

>

<

2

0

0

10

20
Update Time

Fig. 2

30

40

"
47,1987,"Hierarchical Learning Control - An Approach with Neuron-Like Associative Memories","",47-hierarchical-learning-control-an-approach-with-neuron-like-associative-memories.pdf,"Abstract Missing","249

HIERARCHICAL LEARNING CONTROL AN APPROACH WITH NEURON-LIKE ASSOCIATIVE MEMORIES
E. Ersu
ISRA Systemtechnik GmbH, Schofferstr. 15, D-6100 Darmstadt, FRG
H. Tolle
TH Darmstadt, Institut fur Regelungstechnik,
Schlo~graben 1, D-6100 Darmstadt, FRG
ABSTRACT
Advances in brain theory need two complementary approaches:
Analytical investigations by in situ measurements and as well synthetic modelling supported by computer simulations to generate
suggestive hypothesis on purposeful structures in the neural
tissue. In this paper research of the second line is described:
Starting from a neurophysiologically inspired model of stimulusresponse (S-R) and/or associative memorization and a psychologically motivated ministructure for basic control tasks, pre-conditions
and conditions are studied for cooperation of such units in a
hierarchical organisation, as can be assumed to be the general
layout of macrostructures in the brain.
I. INTRODUCTION
Theoretic modelling in brain theory is a highly speculative
subject. However, it is necessary since it seems very unlikely to
get a clear picture of this very complicated device by just analyzing the available measurements on sound and/or damaged brain parts
only. As in general physics, one has to realize, that there are
different levels of modelling: in physics stretching from the atomary level over atom assemblies till up to general behavioural
models like kinematics and mechanics, in brain theory stretching
from chemical reactions over electrical spikes and neuronal cell
assembly cooperation till general human behaviour.
The research discussed in this paper is located just above the
direct study of synaptic cooperation of neuronal cell assemblies as
studied e. g. in /Amari 1988/. It takes into account the changes of
synaptic weighting, without simulating the physical details of such
changes, and makes use of a general imitation of learning situation
(stimuli) - response connections for building up trainable basic
control loops, which allow dynamic S-R memorization and which are
themsel ves elements of some more complex behavioural loops. The
general aim of this work is to make first steps in studying structures, preconditions and conditions for building up purposeful
hierarchies and by this to generate hypothesis on reasons and
@) American Institute of Physics 1988

250

meaning behind substructures in the brain like the columnar organization of the cerebral cortex (compare e. g. /Mountcastle 1978/).
The paper is organized as follows: In Chapter II a short description is given of the basic elements for building up hierarchies,
the learning control loop LERNAS and on the role of its subelement
AMS, some ~ssociati ve memory ~stem inspired by neuronal network
considerations. Chapter III starts from certain remarks on substructures in the brain and discusses the cooperation of LERNASelements in hierarchies as possible imitations of substructures.
Chapter IV specifies the steps taken in this paper in the direction
of Chapter III and Chapter V presents the results achieved by computer simulations. Finally an outlook will be given on further
investigations.
II. LERNAS AND AMS
Since the formal neuron was introduced by /McCulloch and Pitts
1943/, various kinds of neural network models have been proposed,
such as the percept ron by /Rosenblatt 1957/ the neuron equation of
/Caianello 1961/, the cerebellar model articulation controller CMAC
by /Albus 1972, 1975/ or the associative memory models by
/Fukushima 1973/, /Kohonen 1977/ and / Amari 1977/. However, the
abili ty of such systems to store information efficiently and to
perform certain pattern recognition jobs is not adequate for survival of living creatures. So they can be only substructures in the
overall brain organization; one may call them a microstructure.
Purposeful acting means a goal driven coordination of sensory information and motor actions. Al though the human brain is a very
complex far end solution of evolution, the authors speculated in
1978 that it might be a hierarchical combination of basic elements,
which would perform in an elementary way like the human brain in
total, especially since there is a high similarity in the basic
needs as well as in the neuronal tissue of human beings and relati vely simple creatures. This led to the design of the learning
control loop LERNAS in 1981 by one of the authors - /Ersu 1984/ on the basis of psychological findings. He transformed the statement of /Piaget 1970/, that the complete intelligent action needs
three elements: ""1) the question, which directs possible search
actions, 2) the hypothesis, which anticipates eventual solutions,
3) the control, which selects the solution to be chosen"" into the
structure shown in Fig. 1, by identifying the ""question"" with an
performance criterion for assessment of possible advantages/disadvantages of certain actions, the ""hypothesis"" with a predictive
model of environment answers and the ""control"" with a control strategy which selects for known situations the best action, for unknown situations some explorative action (active learning).
In detail, Fig. 1 has to be understood in the following way: The
predictive model is built up in a step by step procedure from a
characterization of the actual situation at the time instant k-T
s

251

T sampling time) and the measured response of the unknown ens
vironment at time instant (k+1)T . The actual situation consists of
s
measurements regarding the stimuli and responses of the environment
at time instant keTs plus - as far as necessary for a unique characterization - of the situation-stimuli and responses at time instants (k-1)T s , (k-2)T s ... , provided bv- the short term memory. To
reduce learning effort, the associative memory system used to store
the predictive model has the ability of local generalization, that
means making use of the trained response value not only for the
corresponding actual situation, but also in similar situations. The
assessment module generates on the basis of a given goal - a wanted
environment response - with an adequate performance criterion an
evaluation of possible actions through testing them with the predictive model, as far as this is already built up and gives meaningful answers. The result is stored in the control strategyAMS
together with its quality: real optimal action for the actual situation or only relatively optimal action, if the testing reached the
border of the known area in the predictive model of the environment. In the second case, the real action is changed in a sense of
curiosity, so that by the action the known area of the predictive
model is extended. By this, one reaches more and more i:he first
case, in which the real optimal actions are known. Since the first
guess for a good action in the optimization phase is given to the
assessment module from the control strategy AMS - not indicated in
Fig. 1 to avoid unnecessary complication - finally the planning
level gets superfluous and one gets very quick optimal reactions,
the checking with the planning level being necessary and helpful
only to find out, whether the environment has not changed, possibly. Again the associative memory system used for the control strategy is locally generalizing to reduce the necessary training
effort.
The AMS storage elements for the predictive model, and for optimized actions are a refinement and implementation for on-line
application of the neuronal network model CMAC from J. Albus - see
e. g. /Ersu, Militzer 1982/ -, but it could be any other locally
generalizing neural network model and even a storage element based
on pure mathematical considerations, as has been shown in
/Militzer, Tolle 1986/.
The important property to build up an excellent capability to
handle different tasks in an environment known only by some sensory
information - the property which qualifies LERNAS as a possible
basic structure (a ""ministructure"") in the nervous system of living
creatures - has been proven by its application to the control of a
number of technical processes, starting with empty memories for the
predictive model and the control strategy storage. Details on this
as well as on the mathematical equations describing LERNAS can be
found in /Ersu, Mao 1983/, /Ersu, Tolle 1984/ and /Ersu, Militzer
1984/.

252

It should be mentioned that the concept of an explicit predictive
environmental model - as used in LERNAS - is neither the only meaningful description of human job handling nor a necessary part of
our basic learning element. It suffices to use a prediction whether
a certain action is advantegeous to reach the actual goal or
whether this is not the case. More information on such a basic
element MINLERNAS, which may be used instead of LERNAS in general
(however, with the penalty of some performance degradation) are
given in /Ersa, Tolle 1988/.
III. HIERARCHIES
There are a number of reasons to believe, that the brain is
built up as a hierarchy of control loops, the higher levels having
more and more coordinative functions. A very simple example shows
the necessity in certain cases. The legs of a jumping jack can move
together, only. If one wants to move them separately, one has to
cut the connection, has to build up a separate controller for each
leg and a coordinating controller in a hierarchically higher level
to restore the possibility of coordinated movements. Actually, one
can find such an evolution in the historical development of certain
animals. In a more complex sense a multilevel hierarchy exists in
the extrapyramidal motor system. Fig. 2 from /Albus 1979/ specifies
five levels of hierarchy for motor control. It can be speculated,
that hierarchical organizations are not existing in the senso-motoric level only, but also in the levels of general abstractions and
thinking. E. g. /Dorner 1974/ supports this idea.
If one assumes out of these indications,

that hierarchies are a
fundamental element of brain structuring - the details and numbers
of hierarchy-levels not being known - one has to look for certain
substructures and groupings of substructures in the brain. In this
connection one finds as a first subdivision the cortical layers,
but then as another more detailed subdivision the columns, cell
assemblies heavily connected in the axis vertical to cortical
layers and sparsely connected horizontally. /Mountcastle 1978/
defines minicolumns, which comprise in some neural tissue roughly
100 in other neural tissue roughly 250 individual cells. In addition to these mini columns certain packages of minicolumns, consisting out of several hundreds of the minicolumns, can be located.
They are called macrocolumns by /Mountcastle 1978/. Fig. 3 gives
some abstraction, how such structures could be interpreted: each
minicolumn is considered to be a ministructure of the type LERNAS,
a number of LERNAS units - here shown in a ring structure instead
of a filled up cylindrical structure - building up a macrocolumn.
The signals between the LERNAS elements could be overlapping and
cooperating. Minicolumns being elements of macrocolumns of a higher
cortical layer - here layer j projecting to layer k - could initiate and/or coordinate this cooperation in a hierarchical sense.
Such a complex system is difficult to simulate. One has to go into
this direction in a step by step procedure. In a first step the

253

overlapping or crosstalk between the minicolumns may be suppressed
and the number of ministructures LERNAS representing the minicolumns should be reduced heavily. This motivates Fig. 4 as a fundamental blockdiagram for research on cooperation of LERNAS elements.
IV. TOPICS ADDRESSED
From Fig. 4 only the lowest level of coordination (layer 1),
that means the coordination of two subprocesses was implemented up
to now - right half of Fig. 5. This has two reasons: Firstly, a
number of fundamental questions can be posed and discussed with
such a formulation already. Secondly, it is difficult to set up
meaningful subprocesses and coordination goals for a higher order
system.
The problem discussed in the following can be understood as the
coordination of two minicolumns as described in Chapter III, but
also as the coordination of higher level subtasks, which may be
detailed themselves by ministructures and/or systems like Fig. 4.
This is indicated in the left half of Fig. 5.
Important questions regarding hierarchies of learning control loops
are:
I.

What seem to be meaningful interventions from the coordinator
onto the lower level systems?

II.

Is parallel learning in both levels possible or requires a
meaningful learning strategy that the control of subtasks has
to be learned at first before the coordination can be learned?

III. Normally one expects, that the lower level takes care of short
term requirements and the upper level of long term strategies.
Is that necessary or what happens if the upper level works on
nearly the same time horizon as the lower levels?
IV.

Furtheron one expects, that the upper level may look after
other goals than the lower level, e. g. the lower level tries
to suppress disturbances effects since the upper level tries
to minimize overall energy consumption. But can such different
strategies work without oscillations or destabilization of the
system?

Question I can be discussed by some general arguments, for questions II-IV only indications of possible answers can be given from
simulation results. This will be postponed to Chapter V.
Fig. 6 shows three possible intervention schemes from the coordinator.
By case a) an intervention into the structure or the parameters of

254

the sublevel (=local) controllers is meant. Since associative
mappings like AMS have no parameters being directly responsible for
the behaviour of the controller - as would be the case with a parametrized linear or non-linear differential equation being the description of a conventional controller - this does not make sense
for the controller built up in LERNAS. However, one could consider
the possibility to change parameters or even elements, that means
structural terms of the performance criterion, which is responsible
for the shaping of the controller. But this would require to learn
anew, which takes a too long time span in general.
By case b) a distribution of work load regarding control commands
is meant. The possible idea could be, that the coordinator gives
control inputs to hold the long range mean value required, since
the local controllers take into account fast dynamic fluctuations
only. However, this has the disadvantage that the control actions
of the upper level have to be included into the inputs to the local
controllers, extending the dimension of in-put space of these
storage devices, since otherwise the process appears to be highly
time variant for the local controllers, which is difficult to
handle for LERNAS.
So case c) seems to be the best solution. In this case the coordinator commands the set points of the local controllers, generating
by this local subgoals for the lower level controllers. Since this
requires no input space extension for the local controllers and is
in full agreement with the working conditions of single LERNAS
loops, it is a meaningful and effective approach.
Fig. 7 shows the accordingly built up structure in detail. The
control strategy of Fig. 1 is divided here in two parts the storage
element (the controller C) and the active learning AL. The elements
are explicitly characterized for the upper level only. The whole
lower level is considered by the coordinator as a single pseudoprocess to be controlled (see Fig. 4).

v.

SIMULATION RESULTS

For answering questions II and III the very simple non-linear
process shown in Fig. 8 - detailing the subprocesses SPl, SP2 and
their coupling in Fig. 7 - was used. For the comparison of bottom
up and parallel learning suitably fixed PI-controllers were used
for bottom up learning instead of LERNAS land LERNAS 2, simulating
optimally trained local controllers. Fig. 9a shows the result due
to which in the first run a certain time is required for achieving
a good set point following through coordinator assistance. However,
with the third repetition (4th run) a good performance is reached
from the first set point change on already. For parallel learning
all (and not only the coordinator AMS-memories) were empty in the
beginning. Practically the same performance was achieved as in
bottom up training - Fig. 9b -, indicating, that at least in simple
problems, as considered here, parallel learning is a real possibi-

255

lity. However - what is not illustrated here - the coordinator
sampling time must be sufficiently long, so that the local controllers can reach the defined subgoals at least qualitatively in this
time span.
For answering question III, in which respect a higher difference in
the time horizon between local controller and coordinator changes
the picture, a doubling of the sampling rate for the coordinator
was implemented. Fig. 10 give the results. They can be interpreted
as follows: Smaller sampling rates allow the coordinator to get
more information about the pseudo-sub-processes, the global goal is
reached faster. Larger sampling rates lead to a better overall
performance when the goal is reached: there is a higher amount of
averaging regarding informations about the pseudo-sub-processes.
Up to now in both levels the goal or performance criterion was the
minimization of differences between the actual plant output and the
requested plant output. The influence of different coordinator
goals - question IV - was investigated by simulating a two stage
waste water neutralization process. A detailed description of this
process set up and the simulation results shall not be given here
out of space reasons. It was found that:
?

in hierarchical systems satisfactory overall behaviour may be
reached by well defined subgoals with clearly different coordinator goals.

?

since learning is goal driven, one has to accept that implicit
wishes on closed loop behaviour are fulfilled by chance only.
Therefore important requirements have to be included in the
performance criteria explicitly.

It should be remarked finally, that one has to keep in mind, that
simulation results with one single process are indications of
possible behaviour only, not excluding that in other cases a fundamentally different behaviour can be met.
VI. OUTLOOK
As has been mentioned already in Chapter III and IV, this work
is one of many first steps of investigations regarding hierarchical
organization in the brain, its preconditions and possible behaviour.
Subjects of further research should be the self-organizing task
distribution between the processing units of each layer, and the
formation of inter layer projections in order to build up meta-tasks
composed of a sequence of frequently occuring elementary tasks.
These investigations will on the other hand show to what extent
this kind of higher-learning functions can be achieved by a hierarchy of LERNAS-type structures which model more or less low-level
basic learning behaviour.

256

VII. ACKNOWLEDGEMENTS
The work presented has been supported partly by the Stiftung
Volkswagenwerk. The detailed evaluations of Chapter IV and V have
been performed by Dipl.-Ing. M. Zoll and Dipl.-Ing. S. Gehlen. We
are very thankful for this assistance.
VIII. REFERENCES
Albus, J. S.

Theoretical and Experimental Aspects of a
Cerebellar Model, Ph.D. Thesis, Univ. of
Maryland, 1972

Albus, J. S.

A New Approach to Manipulator Control:
The Cerebellar Model Articulation Controller
(CMAC), Trans. ASmE series, G, 1975

Albus, J. S.

A Model of the Brain for Robot Control Part 3: A Comparison of the Brain and Our
Model, Byte, 1979

Amari, S. 1.

Neural Theory of Association and Concept
Formation, BioI. Cybernetics, Vol. 26, 1977

Amari, S. 1.

Mathematical Theory of Self-Organization in
Neural Nets, in: Organization of Neural
Networks, Structures and Models, ed. by
von Seelen, Shaw, Leinhos, VHC-Verlagsges.
Weinheim, W.-Germany, 1988

Caianello, E. R.

Outline of a Theory of Thought Process and
Thinking Machines, Journal of Theoretical
Biology, Vol. 1, 1961

Dorner, D.

Problemlosen als Informationsverarbeitung
Verlag H. Huber, 1974

Ersil, E.

On the Application of Associative Neural
Network Models to Technical Control Problems,
in: Localization and Orientation in Biology and
Engineering, ed. by Varju, Schnitzler,
Springer Verlag Berlin, W.-Germany, 1984

Ersu, E.
Mao, X.

Control of pH by Use of a Self-Organizing
Concept with Associative Memories, ACI'83,
Kopenhagen (Denmark), 1983

257

Ersu, E.
Militzer, J.

Software Implementation of a Neuron-Like
Associative Memory System for Control
Application, Proceedings of the 2nd lASTED
Conference on Mini- and Microcomputer Applications, MIMI'82, Davos (Switzerland), 1982

Ersu, E.
Militzer, J.

Real-Time Implementation of an Associative
Memory-Based Learning Control Scheme for NonLinear Multivariable Processes, Symposium
""Applications of Multivariable System
Techniques"", Plymouth (UK), 1984

Ersu, E.
Tolle, H.

A New Concept for Learning Control Inspired by
Brain Theory, Proceed. 9th IFAC World Congress,
Budapest (Hungary), 1984

Ersu, E.
Tolle, H.

Learning Control Structures with Neuron-Like
Associative Memory Systems, in: Organization of
Neural Networks, Structures and Models, ed. by
von Seelen, Shaw, Leinhos, VCH Verlagsgesellschaft Weinheim, W.-Germany, 1988

Fukushima, K.

A Model of Associative Memory in the Brain
BioI. Cybernetics, Vol. 12, 1973

Kohonen, T.

Associative Memory, Springer Verlag Berlin,
W.-Germany, 1977

McCulloch, W. S.
Pitts, W. H.

A Logical Calculus of the Ideas, Immanent in
Nervous Activity, Bull. Math. Biophys. 9, 1943

Militzer, J.
Tolle, H.

Vertiefungen zu einem Teilbereiche der menschlichen Intelligenz imitierenden Regelungsansatz
Tagungsband-DGLR-Jahrestagung, Munchen,
W.-Germany, 1986

Mountcastle, V. B. An Organizing Principle for Cerebral Function:
The Unit Module and the Distributed System, in:
The Mindful Brain by G. M. Edelman,
V. B. Mountcastle, The MIT-Press, Cambridge,
USA, 1978
Piaget, J.

Psychologie der Intelligenz, Rascher Verlag,
4th printing, 1970

Rosenblatt, F.

The Perceptron: A Perceiving and Recognizing
Automation, Cornell Aeronautical Laboratory,
Report No. 85-460-1, 1957

258

FIGURES
~

?

LUKAS

-

0

-r)'p~Clt-Cl-

I""9r.'OO:'5

Dr

l

!IIv-ro-,,""';""'-

~================--

PROCESS /'oDlL

LEU.IM' AND
GoA\. Os I YEll
Actio. OPtllllZAllOR

I

I
'-I\-s-ts-s"",-en-""--' p'lrwyd r.tiol'lS
pt..ning

I

t===~~~[=~~j
rudio ..

~'i"",ilrd

Idion

1-?

'-'-1-

=g=Oaf=U=""il=b'=U=~+t>o=t>I control s'r""t91

='

t - ' - -__

1==:;-;=====IC='iors==:tll

Ar'S

u""k""ow""

."" ..r on""""""'

_ 0- '_0_._._ 0_ ._._
(ZZZ::Zjg Associative Situalion- Response Yapping (lDng Term Yemory)
.

_oJ

Fig. 1. Architectural element LERNAS

SUBTHAl.APnC NUCLEUS
NUClEUS

PiE COHH:I S Sl'RALIS

INTERSTITIAL NUCLEUS

PiESTITIAL - - - - - - ' ""
NUCLEUS

IETI CUI..AR - - - - - - - - ' ; - - - - : : : -

FORMATION

Fig. 2. The hierarchy of aotor control that exists in the extrapyramidal motor system. Basic reflexes remain even if the brain
stem is cut at A-A. Coordination of these reflexes for standing is
possible if the cut is at B-B. The sequential coordination required
for walking requires the area below c-c to be operable. Simple
tasks can be executed if the region below D-D is intact. Lengthy
tasks and complex goals require the cerebral cortex. (/Albus 1979/)

259

Fig. 3. Generic scetch of macrocolumns - drawn as ring
structures - from different cortical layers with
LERNAS-subunits representing ainicolumns

laytT n

~i

1

li!fIT 2

T

L.ERNA52i

~l lDNlSl'1

I

1'1......

~.oemi

f

JI'~ l
.1

It LDM&;i J l~
.J,

'""

'""

l;yrr ?

~

'f

1

~.l

J I

I

L.?JMjij

J

'""

~ J
--r t

Ir?caDk

l'

[lENjil J
J.
l'
~l}

,-

rig. C. LERNAS-hierarchy as a si.plified research .odel
for cooperation of columnar .tructures

260

LERNAS 3

lERNAS 1

SUBPROCESS

Fig. 6. Methods of
intervention from the
coordinator

Fig. 5. Hierarchical work!
control distribution

flOOIL

113

PsEUDC-~ ...fI-.cU$

r------------------------,I
I
I
I
I
I
I

I
I
I
I

I
I

I

_ _ _ _ _ _ _ _______________ J

Fig. 7. Implementation of the hierarchical structure

261

DOD-llneer
1rl
C""':)

...

~

1

Z

0::

~

'Wz

Fig. 8. Hierarchical structure with non-linear
multivariable test-process
reference value
/

.i'II

run)
run)

y

y
500

1DOC

I!IOO

reference value

toOC

eoo

!IOO

IOOC

1000

I soc

Fig. 9. Learning on coordinator level using already
trained (a) and untrained (b) lower levels
(T
= 2 sec, Tioc = 0.5 sec)
coord

T

IIC

coor d=4 sec

Tcoor d=2sec

I~

y (1st run)
y (4th run)
100

'DOC

'soc

aooo .

BIle _

100

lDOC

,_

_

1000

Fig. 10. Coordinator learning behaviour using different
coordinator borizons (T I oc = 0.5 sec)

BDCI

_

"
48,1987,"A NEURAL NETWORK CLASSIFIER BASED ON CODING THEORY","",48-a-neural-network-classifier-based-on-coding-theory.pdf,"Abstract Missing","174

A Neural Network Classifier Based on Coding Theory
Tzt-Dar Chlueh and Rodney Goodman
eanrornla Instltute of Technology. Pasadena. eanromla 91125
ABSTRACT

The new neural network classifier we propose transforms the
classification problem into the coding theory problem of decoding a noisy
codeword. An input vector in the feature space is transformed into an internal
representation which is a codeword in the code space, and then error correction
decoded in this space to classify the input feature vector to its class. Two classes
of codes which give high performance are the Hadamard matrix code and the
maximal length sequence code. We show that the number of classes stored in an
N-neuron system is linear in N and significantly more than that obtainable by
using the Hopfield type memory as a classifier.
I. INTRODUCTION

Associative recall using neural networks has recently received a great deal
of attention. Hopfield in his papers [1,2) deSCribes a mechanism which iterates
through a feedback loop and stabilizes at the memory element that is nearest the
input, provided that not many memory vectors are stored in the machine. He has
also shown that the number of memories that can be stored in an N-neuron
system is about O.15N for N between 30 and 100. McEliece et al. in their work (3)
showed that for synchronous operation of the Hopfield memory about N/(2IogN)
data vectors can be stored reliably when N is large. Abu-Mostafa (4) has predicted
that the upper bound for the number of data vectors in an N-neuron Hopfield
machine is N. We believe that one should be able to devise a machine with M, the
number of data vectors, linear in N and larger than the O.15N achieved by the
Hopfield method.
Feature Space

=

N
B

= {-1

N
, 1 }

L

Code Space

= B = {-1

L
?1 }

Figure 1 (a) Classification problems versus (b) Error control decoding problems
In this paper we are specifically concerned with the problem of
classification as in pattern recognition. We propose a new method of building a
neural network classifier, based on the well established techniques of error
control coding. ConSider a typical classification problem (Fig. l(a)), in which one
is given a priori a set of classes, C( a), a = 1, .... M. Associated with each class is a
feature vector which labels the class ( the exemplar of the class), I.e. it is the

? American Institute of Physics 1988

175

most representative point in the class region. The input is classified into the
class with the nearest exemplar to the input. Hence for each class there is a
region in the N-dimensional binary feature space BN == (I. -I}N. in which every
vector will be classified to the corresponding class.
A similar problem is that of decoding a codeword in an error correcting
code as shown in Fig. I(b). In this case codewords are constructed by design and
are usually at least dmtn apart. The received corrupted codeword is the input to
the decoder. which then finds the nearest codeword to the input. In principle
then. if the distance between codewords is greater than 2t +1. it is possible to
decode (or classify) a noisy codeword (feature vector) into the correct codeword
(exemplar) provided that the Hamming distance between the noisy codeword and
the correct codeword is no more than t. Note that there is no guarantee that the
exemplars are uniformly distributed in BN. consequently the attraction radius
(the maximum number of errors that can occur in any given feature vector such
that the vector can st111 be correctly classified) will depend on the minimum
distance between exemplars.
Many solutions to the minimum Hamming distance classification have
been proposed. the one commonly used is derived from the idea of matched filters
in communication theory. Lippmann [5) proposed a two-stage neural network
that solves this classification problem by first correlating the input with all
exemplars and then picking the maximum by a ""winner-take-all"" circuit or a
network composed of two-input comparators. In Figure 2. fI.f2 .... .fN are the N
input bits. and SI.S2 .... SM are the matching score s(Similartty) of f with the M
exemplars. The second block picks the maximum of sI.S2 ..... SM and produces the
index of the exemplar with the largest score. The main disadvantage of such a
classifier is the complexity of the maximum-picking circuit. for example a
''winner-take-all'' net needs connection weights of large dynamic range and
graded-response neurons. whilst the comparator maximum net demands M-I
comparators organized in log2M stages.
f= d

M
A

(0:)

M

(0:)

g = c

+e

?

,,-_;_~~ DECODER~SS(f)

X
I
M
U

+ e

....

cloSS(f)
Feature
Space

Code
Space

Fig. 2 A matched filter type classifier Fig. 3 Structure of the proposed classifier
Our main idea is thus to transform every vector in the feature space to a
vector in some code space in such a way that every exemplar corresponds to a
codeword in that code. The code should preferably (but not necessarily) have the
property that codewords are uniformly distributed in the code space. that is, the
Hamming distance between every pair of codewords is the same. With this
transformation. we turn the problem of classification into the coding problem of
decoding a noisy codeword. We then do error correction decoding on the vector in
the code space to obtain the index of the noisy codeword and hence classify the
original feature vector. as shown in Figure 3.
This paper develops the construction of such a classification machine as
follows. First we conSider the problem of transforming the input vectors from the
feature space to the code space. We describe two hetero-associative memories for
dOing this. the first method uses an outer product matrix technique Similar to

176

that of Hopfield's. and the second method generates its matrix by the
pseudoinverse techruque[S.7J. Given that we have transformed the problem of
associative recall. or classification. into the problem of decoding a noisy
codeword. we next consider suitable codes for our machine. We require the
codewords in this code to have the property of orthogonality or
pseudo-orthogonality. that is. the ratio of the cross-correlation to the
auto-correlation of the codewords is small. We show two classes of such good
codes for this particular decoding problem l.e. the Hadamard matrix codes. and
the maximal length sequence codes[8J. We next formulate the complete decoding
algorithm. and describe the overall structure of the classifier in terms of a two
layer neural network. The first layer performs the mapping operation on the
input. and the second one decodes its output to produce the index of the class to
which the input belongs.
The second part of the paper is concerned with the performance of the
classifier. We first analyze the performance of this new classifier by finding the
relation between the maximum number of classes that can be stored and the
classification error rate. We show (when using a transform based on the outer
product method) that for negligible misclassification rate and large N. a not very
tight lower bound on M. the number of stored classes. is 0.22N. We then present
comprehensive simulation results that confirm and exceed our theoretical
expectations. The Simulation results compare our method with the Hopfield
model for both the outer product and pseudo-inverse method. and for both the
analog and hard limited connection matrices. In all cases our classifier exceeds
the performance of the Hopfield memory in terms of the number of classes that
can be reliably recovered.
D. TRANSFORM TECHNIQUES

Our objective is to build a machine that can discriminate among input
vectors and classify each one of them into the appropriate class.
Suppose
d(a) E BN is the exemplar ofthe corresponding class e(a.). a. = 1.2 ..... M . Given the
input f . we want the machine to be able to identify the class whose exemplar is
closest to f. that is. we want to calculate the follOWing function.
class ( f) =

a.

if f

I f - d( a) I

< I f - dH3)

I

where I I denotes Hamming distance in BN.
We approach the problem by seeking a transform ~ that maps each
exemplar d(a) in BN to the corresponding codeword w(a) in BL. And an input
feature vector f = dey) + e is thus mapped to a noisy codeword g = wlY) + e' where e
is the error added to the exemplar, and e' is the corresponding error pattern in the
code space. We then do error correction decoding on g to get the index of the
corresponding codeword. Note that e' may not have the same Hamming weight as
e, that is, the transformation ~ may either generate more errors or eliminate
errors that are present in the original input feature vector. We require ~ to
satisfy the following equation,
0.=0,1 ..... M-l
and

~

will be implemented uSing a Single-layer feedfoIWard network.

177

Thus we first construct a matrix according to the sets of d(a)'s and w(a)'s, call it T,
and define r:, as

where sgn is the threshold operator that maps a vector in RL to BL and R is the
field of real numbers.
Let D be an N x M matrix whose <lth column is d( a) and W be an L x M
matrix whose ~th column Is w(~). The two possible methods of constructing the
matrix for r:, are as follows:
Scheme A (outer product method) [3,6] : In this scheme the matrix T Is
defined as the sum of outer products of all exemplar-codeword pairs, i.e.
M-l

=

T(A)y

L

Wl(e:)? die:)

or equivalently.
T(A)

= WDt

Scheme B (pseudo-Inverse method) [6.7] : We want to find a matrix
satisfying the follOWing equation,

T(B)

'f{B) D = W

In general D is not a square matrix, moreover D may be singular, so D-l
may not exist. To circumvent this difficulty, we calculate the pseudo-inverse
(denoted Dt) of the matrix D instead of its real Inverse, let Dt::= (DtD)-lDt. T(B) can
be formulated as,
'f{B) = W Dt = W (ot D)-l nt

m.

CODES

The codes we are looking for should preferably have the property that its
codewords be distributed uniformly in BL, that is, the distance between each two
codewords must be the same and as large as pOSSible. We thus seek classes of
eqUidistant codes. Two such classes are the Hadamard matrix codes, and the
maximal length sequence codes.
First define the word pseudo-orthogonal.
Defmition: Let w(a) = (wO(a),Wl (a), ..... , WL-l (a)) E BL be the ath codeword of
code C, where a = 1,2, ... ,M. Code C is said to be pseudo-orthogonal iff
L-l
(w(a) , w(~)) =
Wl(a) Wl(~)

L

1=0

=(~

:::

where

E

?L

where ( , ) denotes inner product of two vectors.
Hadamard Matrices: An orthogonal code of length L whose L codewords are
rows or columns of an L x L Hadamard matrix. In this case e = 0 and the
distance between any two codewords is L/2. It is conjectured that there exist such
codes for all L which are multiples of 4, thus providing a large class of codes[8].

178

Mazlmal Length Sequence Codes: There exists a family of maximal length
sequence (also called pseudo-random or PN sequence) codes(8). generated by shift
registers. that satisfy pseudo-orthogonality with e = -1. Suppose 9 (x) is a
primitive polynomial over OF (2) of degree D. and let L = 2D -1. and if
00

f(xl

= l/g (xl = L

ck? xk

k=O

then CO.Cl ?.??... is a periodic sequence of period L ( since 9 (x) I x L - 1). If code C is
made up of the L cyclic shifts of

c = ( 1 - 2 CO. 1 - 2 cl ?... 1 - 2 c L - Il
then code C satisfies pseudo-orthogonality with E = -1. One then easily sees that
the minimum distance of this code is (L - 1)/2 which gives a correcting power of
approximately L/4 errors for large L.
IV. OVERALL CLASSIFIER STRUCTURE

We shall now describe the overall classifier structure. essentially it
consists of the mapping ~ followed by the error correction decoder for the
maximal length sequence code or Hadamard matrix code. The decoder operates
by correlating the input vector with every codeword and then thresholding the
result at (L + e)/2. The rationale of this algorithm is as follows. since the distance
between every two codewords in this code is exactly (L - e)/2 bits. the decoder
should be able to correct any error pattern with less than (L - e) / 4 errors if the
threshold is set halfway between Land e I.e. (L + e )/2.
Suppose the input vector to the decoder is g = w< a) + e and e has Hamming
weight s (i.e. s nonzero components) then we have
(g. w (0:)) = L - 2s
(g ? w (~) ~ 2s + E

where ~ i= a

From the above equation. if g is less than (L - e) /4 errors away from w( a)
(I.e. s < (L - e)/4) then (g ? W<a)) will be more than (L + e)/2 and (g ? w(~)) will be
less than (L + e)/2. for all ~ #= a. As a result. we arrive at the following decoding
algorithm.
deax1e (g) = sgn ( w t g - ( (L + E)/2)j )
where j = [ 1 1 ..... 1 )t ? which is an M x 1 vector.
In the case when E = -1 and less than (L+l)/4 errors in the input. the output
will be a vector in SM == {l.-I}M with only one component positive (+1). the index
of which is the index of the class that the input vector belongs. However if there
are more than (L+ 1) / 4 errors. the output can be either the all negative( -1) vector
(decoder failure) or another vector with one pOSitive component(decoder error).
The function class can now be defined as the composition of ~ and decode.
the overall structure of the new classifier is depicted in Figure 4. It can be viewed
as a twO-layer neural network with L hidden units and M output neurons. The
first layer is for mapping the input feature vector to a noisy codeword in the code
space ( the ""internal representation"" ) while the second one decodes the first's
output and produces the index of the class to which the input belongs.

179

T(A) or T

(8)

W

91

f1

t

f2

?
?
?
f N-1
fN

9L
Figure 4

Overall architecture of the new neural network classifier

v.

PERFORMANCE ANALYSIS

From the previous section, we know that our classifier will make an error
only if the transformed vector in the code space, which is the input to the decoder,
has no less than (L - e)/4 errors. We now proceed to find the error rate for this
classifier in the case when the input is one of the exemplars (i.e. no error), say
f = d(~) and an outer product connection matrix for~. Following the approach of
McEl1ece et. al.[31, we have
N-l M-l

(~ d(~)h

= sgl (

L L

Wl(a) dj(a) dj(~) )

j=o a= 0

N-l

= sgn( N wl(f3) +

M-l

L L

Wl(a) dl a ) dj(~) )

j=o a=O
a~~

Assume without loss of generality that Wl(~) = -I, and if
N-l

X

==

M-l

L L

j=O

Wl(a) dl a ) dj(~) ~

N

a=o
a~~

then

Notice that we assumed all d(a)'s are random, namely each component of
any d(a) is the outcome of a Bernoulli trial, accordingly, X is the sum of N(M-l)
independent identically distributed random variables with mean 0 and variance
1. In the asymptotic case, when Nand M are both very large, X can be
approximated by a normal distribution with mean 0, variance NM. Thus
p

-

Pr { (~d(~)h ~ Wl(~)}

-

Q(vlN/M)

_1_

where Q(x) =

vi 2 TT

fOO t 2 /2
x

e

dt

180

Next we calculate the misclassification rate of the new classifier as follows
(assuming E? L),
L

Pe

=

~
k=IL/4J

(L) pk(l_p)L-k
k

where L J is the integer floor. Since in generallt is not possible to express the
summation expliCitly, we use the Chernoff method to bound Pe from above.
Multiplying each term in the summation by a number larger than unity
( et(k - L/4) with t > 0 ) and summing from k = 0 instead of k = L
L/ 4 J'
L

Pe

<

L (L )P k (l-p) L- k e t(k - L/4)
k=O

=

e -L t/4

(1 _ P + p

et ) L

k

Differentiating the RHS of the above equation w.r.t. t and set it to 0, we find
the optimal to as eto = (l-p)/3p. The condition that to > 0 implies that p < 1/4,
and since we are dealing with the case where p is small, it is automatically
satisfied. Substituting the optimal to, we obtain
where c =4/(33 / 4 ) =1.7547654
From the expression for Pe ,we can estimate M, the number of classes that
can be classified with negllgible misclassification rate, in the following way,
suppose Pe = () where ()? land p ? 1, then

For small x we have g-l(Z) - ../2 Log ( i/z) and since () is a fixed value, as L
approaches infinity, we have
M>

N
=.l:L
810gc
4.5

From the above lower bound for M, one easily see that this new machlne is able to
classify a constant times N classes, which is better than the number of memory
items a Hopfield model can store Le. N/(210gN). Although the analysis is done
assumlng N approaches lnfinlty, the simulation results in the next section show
that when N is moderately large (e.g. 63) the above lower bound applles.
VI. SIMULATION RESULTS AND A CHARACTER RECOGNITION EXAMPLE

We have Simulated both the Hopfield model and our new machine(using
maxlmallength sequence codes) for L = N =31, 63 and for the following four cases
respectively.
(1) connection matrix generated by outer product method
(ti) connection matrix generated by pseudo-inverse method
(ill) connection matrix generated by outer product method, the components of the
connection matrix are hard limited.
(iv) connection matrix generated by pseudo-inverse method, the components of
the connection matrix are hard limited.

181

For each case and each choice of N. the program fixes M and the number of
errors in the input vector. then randomly generates 50 sets of M exemplars and
computes the connection matrix for each machine. For each machine it
randomly picks an exemplar and adds nOise to it by randomly complementing
the specified number of bits to generate 20 trial input vectors. it then simulates
the machine and checks whether or not the input is classified to the nearest class
and reports the percentage of success for each machine.
The simulation results are shown in Figure 5. in each graph the hOrizontal
axis is M and the vertical axis is the attraction radius. The data we show are
obtained by collecting only those cases when the success rate is more than 98%,
that is for fixed M what is the largest attraction radius (number of bits in error of
the input vector) that has a success rate of more than 98%. Here we use the
attraction radiUS of -1 to denote that for this particular M. with the input being
an exemplar. the success rate is less than 98% in that machine .

_e_ Hopfield Model

.0-

?-

New Classifier{Op)

New Classtfier{PI)

N=31

N=31

Analog Connection Matrix

Binary Connection Matrix

-,

?
..... CIl
....
:s
(,).~

... ..
~'1.:!

::;:0::
.....

23
21

. .++++++++. .~~~~~~
a ,0 12 '"" ,. 18 'o It lit II , . '0

- ,~~~

""18101114

f

,.

:tD

""

:1'

I.

II

,

'0

(a)

(h)

.2

,

23

en

tl.a
f!

Binary Connection Matrix

, ....

?

M

d

15
13

""

M

N=63

'9~
17

u

N=63

21

Analog Connection Matrix

19
~ 17

~~

?

<:

15

13

11

11

9

9
7

7

5

5
3

3
~~~~~~~++~~I

-1
3

7

11

1519

23

27

31

35 39 43

47 51

55

59

83

3

7

11

1519

23

27

31

35

M

M

(c)

(d)

39 43

47 61

Figure 5 Simulation results of the Hopfield memory and the new classifier

182

_e_

Hopfield Model

.0-

New Classifier(OP.L=63)

.... New Classifier(OP.L=31)

1

~

23
21
19 .""--II.I--"".~o.......
~""C 17 ......... -=-.~

1

.9 rIl

u.a

:::~15
< 13

,~

\

'~

-.~~

~-:~

-1 +---+-_e _ _ -4eO-,e _ _ _ e_-4e__..
e

3

5

7

9

11

13

15

17

19

21

23

25

e _..
e __
e
27

29

31

M

Figure 6 Perfonnance of the new classifier using codes of different lengths
In all cases our classifier exceeds the perfonnance of the Hopfield model
in tenns of the number of classes that can be reliably recovered_ For example.
consider the case of N = 63 and a hard limited connection matrix for both the new
classifier and the Hopfield model. we find that for an attraction radius of zero.
that is. no error in the input vector. the Hopfield model has a classification
capacity of approximately 5. while our new model can store 47. Also. for an
attraction radius of 8. that is. an average of N/8 errors in the input vector. the
Hopfield model can reliably store 4 classes while our new model stores 27
classes. Another Simulation (Fig. 6) USing a shorter code (L = 31 instead of L = 63)
reveals that by shortening the code. the performance of the classifier degrades
only slightly. We therefore conjecture that it is pOSSible to use traditional error
correcting codes (e.g. BCH code) as internal representations. however. by going to
a higher rate code, one is trading minimum distance of the code (error tolerance)
for complexity (number of hidden units). which implies pOSSibly poorer
performance of the classifier.
We also notice that the superiority of the pseudoinverse method over the
outer product method appears only when the connection matrices are hard
limited. The reason for this is that the pseudOinverse method is best for
decorrelating the dependency among exemplars, yet the exemplars in this
simulation are generated randomly and are presumably independent.
consequently one can not see the advantage of pseudoinverse method. For
correlated exemplars, we expect the pseudoinverse method to be clearly better
(see next example).
Next we present an example of applying this classifier to recognizing
characters. Each character is represented by a 9 x 7 pixel array, the input is
generated by flipping every pixel with 0.1 and 0.2 probability. The input is then
passed to five machines: Hopfield memory. the new classifier with either the
pseudotnverse method or outer product method, and L = 7 or L = 31. Figure 7 and 8
show the results of all 5 machines for 0.1 and 0.2 pixel flipping probability
respectively, a blank output means that the classifier refuses to make a decision.
First note that the L = 7 case is not necessarily worse than the L =31 case. this
confirms the earlier conjecture that fewer hidden units (shorter code) only
degrades perfonnance slightly. Also one eaSily sees that the pseudoinverse
method is better than the outer product method because of the correlation
between exemplars. Both methods outperform the Hopfield memory since the
latter mixes exemplars that are to be remembered and produces a blend of
exemplars rather than the exemplars themselves, accordingly it cannot classify
the input without mistakes.

183

(a)

(b)

?"" ..
?-.

??...? ..
.
...
??
??.-..
?...

~

:':'J

L:.)

..
?....
?.
?...._..
?.
?.
~

(c)

(d)

(e)

(f)

(a)

.
...
.??.."" .. ??-"" -. ??-?"" .-.. ~~
? . ? . .. ..
?? . ? ..
~;
....
:...
:.. '
:-'
..
?
.
?
?? ?? .
??...
?..- ??--...
,
_..
.. U
.?. ?-.
,...
?-.. ?:..L. ??.- ?[~
? _.
t:: j'.?
tF
. ?:... ?..
,.',
??...
Lo::
??.,. L L-; t'::l
""

""

~.

;

...,'.., ,
...
-

;

;

;
;

l.:1i

Figure 7 The character recognition
example with 10% pixel reverse
probability (a) input (b) correct
output (c) Hopfield Model (d)-(g) new
classifier (d) OP, L =7 (e)OP, L =31
(1) PI, L = 7 (g) PI, L = 31

..-"" ...
??--..

(b)

""
?-..-..
?? ..
~;_. ?,...
-""?""...'.:..'_.-. ??--..
???....., ??.-_...
?.
?."". ?.?-.
~. ?
..?. ??_.
?? .
.. ??
?""- ?, ~

~

J'""l

""

II

_

(c)

(d)

(e)

.'.
??.-..

??,.?.? .-...
..
??? ...
-.

,"" .
???--...

E

???

""

..
?? ? ?... U
~.'

,

?...,
?? F
? ..
....

:

i

:.:::

(f)

{g}

. ? . ?.
??_.-.. ???-.....
- ?...
:'L' b
..
??-- ?-. ??..
:L ?-..
.
?,? -. ? -. ?: -:
?? -. L.J..- L~?L. ?,_.
.. ???
!
?? . ,..
?....-: ?.
""

'

L_

'

Figure 8 The character recognition
example with 20016 pixel reverse
probability (a) input (b) correct
output (c) Hopfield Model (d)-(g) new
classifier (d) OP, L =7 (e)OP. L =31
(1) PI. L 7 (g) PI. L = 31

=

Vll. CONCLUSION

In this paper we have presented a new neural network classifier design
based on coding theory techniques. The classifier uses codewords from an error
correcting code as its internal representations. Two classes of codes which give
high performance are the Hadamard matrix codes and the maximal length
sequence codes. In penormance terms we have shown that the new machine is
significantly better than using the Hopfield model as a classifier. We should also
note that when comparing the new classifier with the Hopfield model. the
increased performance of the new classifier does not entail extra complexity.
since it needs only L + M hard limiter neurons and L(N + M) connection weights
versus N neurons and N2 weights in a Hopfield memory.
In conclusion we believe that our model forms the basis of a fast. practical
method of classification with an effiCiency greater than other previOUS neural
network techniques.
REFERENCES

[1) J. J. Hopfield. Proc. Nat. Acad. Set USA, Vol. 79. pp. 2554-2558 (1982).
[2) J. J. Hopfield. Proc. Nat. Acad. Set USA, Vol. 81, pp. 3088-3092 (1984).
[3) R J. McEliece, et. aI, IEEE Tran. on Infonnation. Theory. Vol. IT-33.
pp. 461-482 (1987).
[4) Y. S. Abu-Mostafa and J. St. Jacques. IEEE Tran. on Information Theory ?
Vol. IT-3I, pp. 461-464 (1985).
[5) R Lippmann, IEEEASSP Magazine, Vol. 4, No.2. pp. 4-22 (April 1987).
[6) T. Kohonen. Associative Memory - A System-Theoretical Approach
(Springer-Verlag. Berlin Heidelberg. 1977).
[7) S . S. Venkatesh,Linear Map with Point Rules ,Ph. D Thesis, Caltech, 1987.
[8) E . R Berlekamp. Algebraic Coding Theory. Aegean Park Press. 1984.

"
49,1987,"Connecting to the Past","",49-connecting-to-the-past.pdf,"Abstract Missing","505

CONNECTING TO THE PAST
Bruce A. MacDonald, Assistant Professor
Knowledge Sciences Laboratory, Computer Science Department
The University of Calgary, 2500 University Drive NW
Calgary, Alberta T2N IN4
ABSTRACT
Recently there has been renewed interest in neural-like processing systems, evidenced for example in the two volumes Parallel Distributed Processing edited by Rumelhart and McClelland,
and discussed as parallel distributed systems, connectionist models, neural nets, value passing
systems and multiple context systems. Dissatisfaction with symbolic manipulation paradigms
for artificial intelligence seems partly responsible for this attention, encouraged by the promise
of massively parallel systems implemented in hardware. This paper relates simple neural-like
systems based on multiple context to some other well-known formalisms-namely production
systems, k-Iength sequence prediction, finite-state machines and Turing machines-and presents
earlier sequence prediction results in a new light.

1

INTRODUCTION

The revival of neural net research has been very strong, exemplified recently by Rumelhart
and McClelland!, new journals and a number of meetings G ? The nets are also described as
parallel distributed systems!, connectionist models 2 , value passing systems3 and multiple context
learning systems4 ,5,6,7,8,9. The symbolic manipulation paradigm for artificial intelligence does
not seem to have been as successful as some hoped!, and there seems at last to be real promise
of massively parallel systems implemented in hardware. However, in the flurry of new work it
is important to consolidate new ideas and place them solidly alongside established ones. This
paper relates simple neural-like systems to some other well-known notions-namely production
systems, k-Iength sequence prediction, finite-state machines and Turing machines-and presents
earlier results on the abilities of such networks in a new light.
The general form of a connectionist system lO is simplified to a three layer net with binary
fixed weights in the hidden layer, thereby avoiding many of the difficulties-and challengesof the recent work on neural nets, The hidden unit weights are regularly patterned using a
template. Sophisticated, expensive learning algorithms are avoided, and a simple method is
used for determining output unit weights. In this way we gain some of the advantages of multilayered nets, while retaining some of the simplicity of two layer net training methods. Certainly
nothing is lost in computational power-as I will explain-and the limitations of two layer
nets are not carried over to the simplified three layer one. Biological systems may similarly
avoid the need for learning algorithms such as the ""simulated annealing"" method commonly
used in connectionist models l l . For one thing, biological systems do not have the same clearly
distinguished training phase.
Briefly, the simplified net b is a production system implemented as three layers of neuron-like
units; an output layer, an input layer, and a hidden layer for the productions themselves. Each
hidden production unit potentially connects a predetermined set of inputs to any output. A
k-Iength sequence predictor is formed once Ie levels of delay unit are introduced into the input
layer. k-Iength predictors are unable to distinguish simple sequences such as ba . .. a and aa ... a
since after Ie or more characters the system has forgotten whether an a or b appeared first. If
the k-Iength predictor is augmented with ""auxiliary"" actions, it is able to learn this and other
regular languages, since the auxiliary actions can be equivalent to states, and can be inputs to
aAmong them the 1st International Conference on Neural Nets, San Diego,CA, June 21-24, 1987, and this
con.ference.
bRoughly equivalent to a single context system in Andreae's multiple context system 4. 5,6,7,8,9. See also
MacDonald 12 .

@)

American Institute of Physics 1988

506

Figure 1: The general form of a connectionist system 10 .
(a) Form of a unit

(a) Operations within a unit

in~uts ;::; L'"" excitation-.I
weIghts
sum

1:.. aCtiVation--W'"" output

?--==
Typical F

Typical f

the production units enabling predictions to depend on previous states 7 . By combining several
augmented sequence predictors a Thring machine tape can be simulated along with a finite-state
controller 9 , giving the net the computational power of a Universal Turing machine. Relatively
simple neural-like systems do not lack computational ability. Previous implementations 7,9 of
this ability are production system equivalents to the simplified nets.
1.1

Organization of the paper

The next section briefly reviews the general form of connectionist systems. Section 2 simplifies
this, then section 3 explains that the result is equivalent to a production system dealing only
with inputs and outputs of the net. Section 4 extends the simplified version, enabling it to learn
to predict sequences. Section 5 explains how the computational power of the sequence predictor
can be increased to that of a Thring machine if some input units receive auxiliary actions; in fact
the system can learn to be a TUring machine. Section 6 discusses the possibility of a number of
nets combining their outputs, forming an overall net with ""association areas"".
1.2

General form of a connectionist system

Figure 1 shows the general form of a connectionist system unit, neuron or ce1l 10 . In the figure
unit i has inputs, which are the outputs OJ of possibly all units in the network, and an output of
its own, 0i' The net input excitation, net"" is the weighted sum of inputs, where !Vij is the weight
connecting the output from unit j as an input to unit i. The activation, ai of the unit is some
function Fi of the net input excitation. Typically Fi is semilinear, that is non-decreasing and
differentiable 13 , and is the same function for all, or at least large groups of units. The output is
a function fi of the activation; typically some kind of threshold function. I will assume that the
quantities vary over discrete time steps, so for example the activation at time t + 1 is ai (t + 1)
and is given by Fi((neti(t)).
In general there is no restriction on the connections that may be made between units.
Units not connected directly to inputs or outputs are hidden units. In more complex nets
than those described in this paper, there may be more than one type of connection. Figure 2
shows a common connection topology, where there are three layers of units-input, hidden and
output-with no cycles of connection.
The net is trained by presenting it with input combinations, each along with the desired
output combination. Once trained the system should produce the desired outputs given just

507

Figure 2: The basic structure of a three layer connectionist system.

input units

hidden
units

output units

inputs . During training the weights are adjusted in some fashion that reduces the discrepancy
between desired and actual output. The general method is lO :
(1)

where t; is the desired, ""training"" activation . Equation 1 is a general form of Hebb's classic
rule for adjusting the weight between two units with high activations lO ? The weight adjustment
is the product of two functions, one that depends on the desired and actual activations--often
just the difference-and another that depends on the input to that weight and the weight itself.
As a simple example suppose 9 is the difference and h as just the output OJ. Then the weight
change is the product of the output error and the input excitation to that weight:

where the constant T} determines the learning rate. This is the Widrow-Hoff or Delta rule which
may be used in nets without hidden units. 1o
The important contribution of recent work on connectionist systems is how to implement
equation 1 in hidden units; for which there are no training signals ti directly available . The
Boltzmann learning method iteratively varies both weights and hidden unit training activations
using the controlled, gradually decreasing randomizing method ""simulated annealing"" 14. Backpropagation 13 is also iterative, performing gradient descent by propagating training signal errors
back through the net to hidden units. I will avoid the need to determine training signals for
hidden units, by fixing the weights of hidden units in section 2 below.

2

SIMPLIFIED SYSTEM

Assume these simplifications are made to the general connectionist system of section 1.2:
1. The system has three layers, with the topology shown in Figure 2 (ie no cycles)
2. All hidden layer unit weights are fixed, say at unity or zero
3. Each unit is a linear threshold unit lO , which means the activation function for all units
is the identity function, giving just net;, a weighted sum of the inputs, and the output
function is a simple binary threshold of the form:

!- I

output

threshold /

?
activation

508

so that the output is binary; on or oft'. Hidden units will have thresholds requiring all
inputs to be active for the output to be active (like an AND gate) while output units will
have thresholds requiring only 1 or two active highly weighted inputs for an output to be
generated (like an OR gate). This is in keeping with the production system view of the
net, explained in section 3.
4. Learning-which now occurs only at the output unit weights-gives weight adjustments
according to:
Wij
Wij

1

if ai =

OJ

=1

0 otherwise

so that weights are turned on if their input and the unit output are on, and off otherwise.
That is, Wij = ai A OJ. A simple example is given in Figure 3 in section 3 below.
This simple form of net can be made probabilistic by replacing 4 with 4' below:
4'. Adjust weights so that Wij estimates the conditional probability of the unit i output being
on when output j is on. That is,
Wij

= estimate of P(odoj).

Then, assuming independence of the inputs to a unit, an output unit is turned on when the
conditional probability of occurrence of that output exceeds the threshold of the output
function.
Once these simplifications are made, there is no need for learning in the hidden units. Also no
iterative learning is required; weights are either assigned binary values, or estimate conditional
probabilities. This paper presents some of the characteristics of the simplified net. Section 6
discusses the motivation for simplifying neural nets in this way.

3

PRODUCTION SYSTEMS

The simplified net is a kind of simple production system. A production system comprises a
global database, a set of production rules and a control system 15 . The database for the net is
the system it interacts with, providing inputs as reactions to outputs from t.he net. The hidden
units of the network are the production rules, which have the form
IF

precondition

THEN

action

The precondition is satisfied when the input excitation exceeds the threshold of a hidden unit.
The actions are represented by the output units which the hidden production units activate.
The control system of a production system chooses the rule whose action to perform, from the
set of rules whose preconditions have been met. In a neural net the control system is distributed
throughout the net in the output units. For example, the output units might form a winner-takeall net. In production systems more complex control involves forward and backward chaining to
choose actions that seek goals . This is discussed elsewhere4.12.16. Figure 3 illust.rates a simple
production implemented as a neural net. As the figure shows, the inputs to hidden units are
just the elements of the precondition. When the appropriate input combination is present the
associated hidden (production) unit is fired. Once weights have been leamed connecting hidden
units to output units, firing a production results in output. The simplified neural net is directly
equivalent to a production system whose elements are inputs and outputs e .
Some production systems have symbolic elements, such as variables, which can be given
values by production actions. The neural net cannot directly implement this, since it can
have outputs only from a predetermined set. However, we will see later that extensions t.o the
framework enable this and other abilities.
CThis might be referred to as a ""sensory-motor"" production system, since when implemented ill a l'eal system
such as a robot, it deals only with sensed inputs and executable motor actions, which may include the auxiliary
actions of section 4.3.

509

Figure 3: A production implemented in a simplified neural net .
(a) A production rule
rr==~--r=======~~~==~
IF

Icloudy I Ipressure falling I
AND

THEN

Iit will rain I

(b) The rule implemented as a hidden unit. The threshold of the hidden unit is 2 so it is.
an AND gate. The threshold of the output unit is 1 so it is an OR gate. The learned
weight will be 0 or 1 if the net is not probabilistic, otherwise it will be an estimate of
P(it will rainlclouds AND pressure falling)

It will
rain

weight

Figure 4: A net that predicts the next character in a sequence, based on only the last character .
(a) The net . Production units (hidden units) have been combined with input units.
For example this net could predict the sequence abcabcabc . . .. Productions have the
form : IF last character is . .. THEN next character will be . . .. The learning rule is
Wij
1 if (inputj AND outputi). Output is ai
~R WijOj

=

=

input

neural net

output

a

a
b
c

b

c

(b) Learning procedure.
1. Clamp inputs and outputs to desired values
2. System calculates weight values
3. Repeat 4 and 4 for all required input/output combinations

4

SEQUENCE PREDICTION

A production system or neural net can predict sequences. Given examples of a repeating sequence, productions are learned which predict future events on the basis of recent ones . Figure 4
shows a trivially simple sequence predictor. It predicts the next character of a sequence based
on the previous one. The figure also gives the details of the learning procedure for the simplified
net. The net need be trained only once on each input combination, then it will ""predict"" as
an output every character seen after the current one. The probabilistic form of the net would
estimate conditional probabilities for the next character , conditional on the current one. Many

510

Figure 5: Using delayed inputs, a neural net can implement a k-length sequence predictor.
(a) A net with the last three characters as input.
input

hidden

output

a':""""'""-......:;;;;;;;::::~;:-

a

{ a'

a

b':-;-'----.."",

{:';;g 'J.,o

b

e""

{e'_~
0-""
e -_ _ _

c

z

2nd last
(b) An example production.
~----------------------------------,

IF

last three characters were ~ THEN

0

presentations of each possible character pair would be needed to properly estimate the probabilities. The net would be learning the probability distribution of character pairs. A predictor like
the one in Figure 4 can be extended to a general k-Iength 17 predictor so long as inputs delayed
by 1,2, ... , k steps are available. Then, as illustrated in Figure 5 for 3-length prediction, hidden
production units represent all possible combinations of k symbols. Again output weights are
trained to respond to previously seen input combinations, here of three characters. These delays
can be provided by dedicated neural nets d , such as that shown in Figure 6. Note that the net
is assumed to be synchronously updated, so that the input from feedback around units is not
changed until one step after the output changes. There are various ways of implementing delay
in neurons, and Andreae 4 investigates some of them for the same purpose-delaying inputs-in
a more detailed simulation of a similar net.
4.1

Other work on sequence prediction in neural nets

Feldman and Ballard 2 find connectionist systems initially not suited to representing changes
with time. One form of change is sequence, and they suggest two methods for representing
sequence in nets. The first is by units connected to each other in sequence so that sequential
tasks are represented by firing these units in succession. The second method is to buffer the
inputs in time so that inputs from the recent past are available as well as current inputs; that
is, delayed inputs are available as suggested above. An important difference is the necessary
length of the buffer; Feldman and Ballard suggest the buffer be long enough to hold a phrase of
natural language, but I expect to use buffers no longer than about 7, after Andreae 4 . Symbolic
inputs can represent more complex information effectively giving the length seven buffers more
information than the most recent seven simple inputs, as discussed in section 5.
The method of back-propagation13 enables recurrent networks to learn sequential tasks in a
dFeldman and Ballard2 give some dedicated neural net connections for a variety of flUlctions

511

Figure 6: Inputs can be delayed by dedicated neural subnets. A two stage delay is shown.
(a) Delay network.

(b) Timing diagram for (a).

--.r-

1.0

IL..-_-_-_-_-_-.:-_-.:-_-.:-_-_-_-_..._ tml
_?_e_

B -r-0.5

0.75 ~ 0.375 ....,L-_ _ __

A

C
D

__________

E

original signal
delay of one step

~r--------r--------~------~L

delay of two steps

manner similar to the first suggestion in the last paragraph, where sequences of connected units
represent sequenced events. In one example a net learns to complete a sequence of characters;
when given the first two characters of a six character sequence the next four are output. Errors
must be propagated around cycles in a recurrent net a number of times.
Seriality may also be achieved by a sequence of states of distributed activation 18. An example
is a net playing both sides of a tic-tac-toe game 18 . The sequential nature of the net's behavior is
derived from the sequential nature of the responses to the net's actions; tic-tac-toe moves. A net
can model sequence internally by modeling a sequential part of its environment. For example,
a tic-tac-toe playing net can have a model of its opponent.
k-Iength sequence predictors are unable to learn sequences which do not repeat more frequently that every k characters. Their k-Iength context includes only information about the last
k events. However, there are two ways in which information from before the kth last input can
be retained in the net. The first method latches some inputs, while the second involves auxiliary
actions.
4.2

Latch units

Inputs can be latched and held indefinitely using the combination shown in Figure 7. Not all
inputs would normally be latched. Andreae 4 discusses this technique of ""threading"" latched
events among non-latched events, giving the net both information arbitrarily far back in its
input-output history and information from the immediate past . Briefly, the sequence ba . .. a
can be distinguished from aa ... a if the first character is latched . However, this is an ad hoc
solution to this problem e .
4-3

Auxiliary actions

When an output is fed back into the net as an input signal, this enables the system to choose the
next output at least partly based on the previous one, as indicated in Figure 8. If a particular
fed back output is also one without external manifestation, or whose external manifestation
is independent of the task being performed, then that output is an auxiliary action. It Las
""The interested reader should refer to Andreae 4 where more extensive analysis is given.

512

Figure 7: Threading. A latch circuit remembers an event until another comes along. This is a
two input latch, e.g. for two letters a and b, but any number of units may be similarly connected.
It is formed from a mutual inhibition layer, or winner-take-all connection, along with positive
feedback to keep the selected output activated when the input disappears.

a
b---;~..!!J

Figure 8: Auxiliary actions-the S outputs-are fed back to the inputs of a net, enabling the
net to remember a state. Here both part of a net and an example of a production are shown.
There are two types of action, characters and S actions.

Sinputs

S outputs

character inputs
IF

S input is

[?l] and character input is 0

character outputs

THEN

output character

lliJ and S [ill

no direct effect on the task the system is performing since it evokes no relevant inputs, and
so can be used by the net as a symbolic action. If an auxiliary action is latched at the input
then the symbolic information can be remembered indefinitely, being lost only when another
auxiliary action of that kind is input and takes over the latch. Thus auxiliary actions can act
like remembered states; the system performs an action to ""remind"" itself to be in a particular
state. The figure illustrates this for a system that predicts characters and state changes given
the previous character and state. An obvious candidate for auxiliary actions is speech. So
the blank oval in the figure would represent the net's environment, through which its own
speech actions are heard. Although it is externally manifested, speech has no direct effect on
our physical interactions with the world. Its symbolic ability not only provides the power of
auxiliary actions, but also includes other speakers in the interaction.

5

SIMULATING ABSTRACT AUTOMATA

The example in Figure 8 gives the essence of simulating a finite state automaton with a production system or its neural net equivalent . It illustrates the transition function of an automaton;
the new state and output are a function of the previous state and input. Thus a neural net can
simulate a finite state automaton, so long as it has additional, auxiliary actions.
A Thring machine is a finite state automaton controller plus an unbounded memory. A
neural net could simulate a 'lUring machine in two ways, and both ways have been demonstrated
with production system implementations-equivalent to neural nets----(;alled ""multiple context
learning systems""', briefly explained in section 6. The first Thring machine simulation 7 has the
system simulate only the finite state controller, but is able to use an unbounded external memory
fSee John Andreae's and his colleagues' work4 ,5,6,7,8,9,12 ,16

513

Figure 9: Multiple context learning system implementation as multiple neural nets. Each:3
layer net has the simplified form presented above, with a number of elaborations such as extra
connections for goal-seeking by forward and backward chaining .

Output
channels

from the real world, much like the paper of Turing's original work 19 . The second simnlat.ion["" 1'2
embeds the memory in the multiple context learning system, along with a counter for accessing
this simulated memory. Both learn all the productions-equivalent to learning output unit
weights-required for the simulations. The second is able to add internal memory as required,
up to a limit dependent on the size of the network (which can easily be large enough to allow 70
years of computation!). The second could also employ external memory as the first did. Briefly,
the second simulation comprised multiple sequence predictors which predicted auxiliary actions
for remembering the state of the controller, and the current memory position . The memory
element is updated by relearning the production representing that element; the precondition is
the address and the production action the stored item.

6

MULTIPLE SYSTEMS FORM ASSOCIATION AREAS

A multiple context learning system is production system version of a multiple neural net, although a simple version has been implemented as a simulated net 4 ?20 . It effectively comprises
several nets--or ""association"" areas-which may have outputs and inputs in common, as indicated in Figure 9. Hidden unit weights are specified by templates ; one for each net . A template
gives the inputs to have a zero weight for the hidden units of a net and the inputs to have a
weight of unity. Delayed and latched inputs are also available . The actual outputs are selected
from the combined predictions of the nets in a winner-take-all fashion .
I see the design for real neural nets, say as controllers for real robots, requiring a large
degree of predetermined connectivity. A robot controller could not be one three layer net wit.h
every input connected to every hidden unit in turn connected to every output. There will
need to be some connectivity constraints so the net reflects the functional specialization in the
control requirements 9 . The multiple context learning system has all the hidden layer connections
predetermined, but allows output connections to be learned. This avoids the ""credit assignment""
problem and therefore also the need for learning algorithms such as Boltzmann learning and
back-propagation. However, as the multiple context learning system has auxiliary actions, and
delayed and latched inputs, it does not lack computational power. Future work in this area
should investigate , for example, the ability of different kinds of nets to learn auxiliary act.ions.
This may be difficult as symbolic actions may not be provided in training inputs and output.s .
9 For

example a controller for a robot body would have to deal with vision, manipulation, motion, etc.

514

7

CONCLUSION

This paper has presented a sImplified three layer connectionist model, with fixed weights for
hidden units, delays and latches for inputs, sequence prediction ability, auxiliary ""state"" actions,
and the ability to use internal and external memory. The result is able to learn to simulate a
Turing machine. Simple neural-like systems do not lack computational power.
ACKNOWLEDGEMENTS

This work is supported by the Natural Sciences and Engineering Council of Canada.
REFERENCES
1. Rumelhart,D.E. and McClelland,J .L . Parallel distributed processing. Volumes 1 and 2. MIT

2.
3.
4.
5.

6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.

17.
18.

19.
20.

Press. (1986)
Feldman,J .A. and Ballard,D.H. Connectionist models and their properties. Cognitive Science
6, pp.205-254. (1982)
Fahlman,S .E. Three Flavors of Parallelism. Proc.4th Nat.Conf. CSCSI/SCSEIO, Saskatoon.
(1982)
Andreae,J .H. Thinking with the teachable machine. Academic Press. (1977)
Andreae,J.H. Man-Machine Studies Progress Reports UC-DSE/1-28. Dept Electrical and
Electronic Engineering, Univ. Canterbury, Christchurch, New Zealand. editor. (1972-87)
(Also available from NTIS, 5285 Port Royal Rd, Springfield, VA 22161)
Andreae,J .H. and Andreae,P.M. Machine learning with a multiple context. Proc.9th
Int.Conf.on Cybernetics and Society. Denver. October. pp.734-9. (1979)
Andreae,J.H. and Cleary,J.G. A new mechanism for a brain. Int.J.Man-Machine Studies
8(1): pp.89-1l9. (1976)
Andreae,P.M. and Andreae,J.H. A teachable machine in the real world. Int.J.Man-Machine
Studies 10: pp.301-12. (1978)
MacDonald,B.A. and Andreae,J .H. The competence of a multiple context learning system.
Int.J.Gen.Systems 7: pp.123-37. (1981)
Rumelhart,D.E., Hinton,G.E. and McClelland,J .L. A general framework for parallel distributed processing. chapter 2 in Rumelhart and McClelland l , pp.45-76. (1986)
Hinton,G.E. and Sejnowski,T.L. Learning and relearning in Boltzmann machines . chapter 7
in Rumelhart and McClelland l , pp.282-317. (1986)
MacDonald,B.A. Designing teachable robots. PhD thesis, University of Canterbury,
Christchurch, New Zealand. (1984)
Rumelhart,D.E., Hinton,G.E. and Williams,R.J. Learning Internal Representations by Error
Propagation. chapter 8 in Rumelhart and McClelland l , pp.318-362. (1986)
Ackley,D.H., Hinton,G.E. and Sejnowski,T.J. A Learning Algorithm for Boltzmann Machines. Cognitive Science 9, pp.147-169. (1985)
Nilsson,N.J. Principles of Artificial Intelligence. Tioga. (1980)
Andreae,J .H. and MacDonald,B~_A. Expert control for a robot body. Research Report
87/286/34 Dept. of Computer Science, University of Calgary, Alberta, Canada, T2N-1N4.
(1987)
Witten,I.H. Approximate, non-deterministic modelling of behaviour sequences. Int. 1. General Systems, vol. 5 pp.1-12 . (1979)
Rumelhart,D.E.,Smolensky,P.,McClelland,J.L. and Hinton,G .E. Schemata and Sequential
thought Processes in PDP Models. chapter 14, vol 2 in Rumelhart and McClelland 1 . pp.757. (1986)
Thring,A.M. On computable numbers, with an application to the entscheidungsproblem.
Proc. London Math. Soc. vol 42(3). pp. 230-65. (1936)
Dowd,R.B. A digital simulation of mew-brain. Report no. UC-DSE/10 5 . pp.25-46. (1977)

"
50,1987,"An Adaptive and Heterodyne Filtering Procedure for the Imaging of Moving Objects","",50-an-adaptive-and-heterodyne-filtering-procedure-for-the-imaging-of-moving-objects.pdf,"Abstract Missing","662

AN ADAPTIVE AND HETERODYNE FILTERING PROCEDURE
FOR THE IMAGING OF MOVING OBJECTS
F. H. Schuling, H. A. K. Mastebroek and W. H. Zaagman
Biophysics Department, Laboratory for General Physics
Westersingel 34, 9718 eM Groningen, The Netherlands

ABSTRACT
Recent experimental work on the stimulus velocity dependent time resolving
power of the neural units, situated in the highest order optic ganglion of the
blowfly, revealed the at first sight amazing phenomenon that at this high level of
the fly visual system, the time constants of these units which are involved in the
processing of neural activity evoked by moving objects, are -roughly spokeninverse proportional to the velocity of those objects over an extremely wide range.
In this paper we will discuss the implementation of a two dimensional heterodyne
adaptive filter construction into a computer simulation model. The features of this
simulation model include the ability to account for the experimentally observed
stimulus-tuned adaptive temporal behaviour of time constants in the fly visual
system. The simulation results obtained, clearly show that the application of such
an adaptive processing procedure delivers an improved imaging technique of
moving patterns in the high velocity range.

A FEW REMARKS ON THE FLY VISUAL SYSTEM
The visual system of the diptera, including the blowfly Calliphora
erythrocephala (Mg.) is very regularly organized and allows therefore very precise
optical stimulation techniques. Also, long term electrophysiological recordings can
be made relatively easy in this visual system, For these reasons the blowfly (which
is well-known as a very rapid and 'clever' pilot) turns out to be an extremely
suitable animal for a systematic study of basic principles that may underlie the
detection and further processing of movement information at the neural level.
In the fly visual system the input retinal mosaic structure is precisely
mapped onto the higher order optic ganglia (lamina, medulla, lobula), This means
that each neural column in each ganglion in this visual system corresponds to a
certain optical axis in the visual field of the compound eye. In the lobula complex
a set of wide-field movement sensitive neurons is found, each of which integrates
the input signals over the whole visual field of the entire eye, One of these wide
field neurons, that has been classified as H I by Hausen J has been extensively
studied both anatomically2, 3, 4 as well as electrophysiologically5, 6, 7, The
obtained results generally agree very well with those found in behavioral
optomotor experiments on movement detection 8 and can be understood in terms of
Reichardts correlation model 9, 10.
The H I neuron is sensitive to horizontal movement and directionally
selective: very high rates of action potentials (spikes) up to 300 per second can be
recorded from this element in the case of visual stimuli which move horizontally
inward, i.e. from back to front in the visual field (pre/erred direction), whereas
movement horizontally outward, i.e, from front to back (null direction) suppresses
its activity,

? American Institute of Physics 1988

663

EXPERIMENTAL RESULTS AS A MODELLING BASE
When the H I neuron is stimulated in its preferred direction with a step wise
pattern displacement, it will respond with an increase of neural activity. By
repeating this stimulus step over and over one can obtain the averaged response:
after a 20 ms latency period the response manifests itself as a sharp increase in
average firing rate followed by a much slower decay to the spontaneous activity
level. Two examples of such averaged responses are shown in the Post Stimulus
Time Histograms (PSTH's) of figure 1. Time to peak and peak height are related
and depend on modulation depth, stimulus step size and spatial extent of the
stimulus. The tail of the responses can be described adequately by an exponential
decay toward a constant spontaneous firing rate:
R(t)=c+a - e( -t/1)

(1)

For each setting of the stimulus parameters, the response parameters,
defined by equation (1), can be estimated by a least-squares fit to the tail of the
PSTH. The smooth lines in figure 1 are the results of two such fits.

tlmsl
300

!~,

.o ""
o

""o

'00 -

OJ

8

)0

w= 11'/s

~ I'JO

""

0\

~

tf

10

100

? M:O.'O
o MoO IO

"" Mdl05

1.00

Fig.l

600

800

_ _ .L... _ - - ' -_

0.3

I

_---',_ _

L-'

_-----L,_ _-'--_ _

10)0
W (""lsI

100

A veraged responses (PSTH's) obtained from the H I neuron, being
adapted to smooth stimulus motion with velocities 0.36 /s (top) and
11 /s (bottom) respectively. The smooth lines represent least-squares
fits to the PSTH's of the form R(t)=c+a-e(-t/1). Values of f for the
two PSTH's are 331 and 24 ms respectively (de Ruyter van Steveninck et
al.7).
Fitted values of f as a function of adaptation velocity for three
modulation depths M. The straight line is a least-squares fit to represent
the data for M=0.40 in the region w:0.3-100 o/s. It has the form
f=Q - w-13 with Q=150 ms and 13=0.7 (de Ruyter van Steveninck et al. 7 ).
0

0

Fig.2

)00

664

Figure 2 shows fitted values of the response time constant T as a function of
the angular velocity of a moving stimulus (a square wave grating in most
experiments) which was presented to the animal during a period long enough to let
its visual system adapt to this moving pattern and before the step wise pattern
displacement (which reveals 1') was given. The straight line, described by
(2)

(with W in Is and T in ms) represents a least-squares fit to the data over the
velocity range from 0.36 to 125 0 Is. For this range, T varies from 320 to roughly
10 ms, with a=150?1O ms and ~=0.7?0.05. Defining the adaptation range of 1 as
that interval of velocities for which 1 decreases with increasing velocity, we may
conclude from figure 2 that within the adaptation range, 1 is not very sensitive to
the modulation depth.
The outcome of similar experiments with a constant modulation depth of the
pattern (M=0.40) and a constant pattern velocity but with four different values of
the contrast frequency fc (Le. the number of spatial periods per second that
traverse an individual visual axis as determined by the spatial wavelength As of the
pattern and the pattern velocity v according to fc=v lAs) reveal also an almost
complete independency of the behaviour of 1 on contrast frequency. Other
experiments in which the stimulus field was subdivided into regions with different
adaptation velocities, made clear that the time constants of the input channels of
the H I neuron were set locally by the values of the stimulus velocity in each
stimulus sub-region. Finally, it was found that the adaptation of 1 is driven by
the stimulus velocity, independent of its direction.
These findings can be summarized qualitatively as follows: in steady state,
the response time constants 1 of the neural units at the highest level in the fly
visual system are found to be tuned locally within a large velocity range
exclusively by the magnitude of the velocity of the moving pattern and not by its
direction, despite the directional selectivity of the neuron itself. We will not go
into the question of how this amazing adaptive mechanism may be hard-wired in
the fly visual system. Instead we will make advantage of the results derived thus
far and attempt to fit the experimental observations into an image processing
approach. A large number of theories and several distinct classes of algorithms to
encode velocity and direction of movement in visual systems have been suggested
by, for example, Marr and Ullman I I and van Santen and Sperling12.
We hypothesize that the adaptive mechanism for the setting of the time
constants leads to an optimization for the overall performance of the visual system
by realizing a velocity independent representation of the moving object. In other
words: within the range of velocities for which the time constants are found to be
tuned by the velocity, the representation of that stimulus at a certain level within
the visual circuitry, should remain independent of any variation in stimulus
velocity.
0

OBJECT MOTION DEGRADATION: MODELLING
Given the physical description of motion and a linear space invariant model,
the motion degradation process can be represented by the following convolution
integral:
co co

JJ

g(x,y)=
-00

(h(x - u,y-v) ? flu, v? dudv

-00

(3)

665

where f(u,v) is the object intensity at position (u,v) in the object coordinate
frame, h(x-u,y-v) is the Point Spread Function (PSF) of the imaging system,
which is the response at (x,y) to a unit pulse at (u,v) and g(x,y) is the image
intensity at the spatial position (x,y) as blurred by the imaging system. Any
possible additive white noise degradation of the already motion blurred image is
neglected in the present considerations.
For a review of principles and techniques in the field of digital image
degradation and restoration, the reader is referred to Harris 13, Sawchuk 14,
Sondhi 15, Nahi 16, A boutalib et al. 17, 18, Hildebrand 19, Rajala de Figueiredo20 .
It has been demonstrated first by Aboutalib et al.17 that for situations in which
the motion blur occurs in a straight line along one spatial coordinate, say along the
horizontal axis, it is correct to look at the blurred image as a collection of
degraded line scans through the entire image. The dependence on the vertical
coordinate may then be dropped and eq. (3) reduces to:

g~~

J~x-u)

-f(u)du

Given the mathematical description of the relative movement,
corresponding PSF can be derived exactly and equation (4) becomes:
g(x)=

k

b(x - u) - f(u)du

(4)

the

(5)

where R is the extent of the motion blur. Typically, a discrete version of (5),
applicable for digital image processing purposes, is described by:
L

g(k)=l: h(k-I)? f(l)

; k=I, ... ,N

(6)

I

where k and I take on integer values and L is related to the motion blur extent.
According to Aboutalib et al. 18 a scalar difference equation model (M,a,b,c)
can then be derived to model the motion degradation process:
x(k+l)

=

M? x(k)+a? f(k)

g(k) = b? x(k)+c ? f(k)

; k=I, ... ,N

(7)

h(i) = cof1(i)+Cl~(i-l)+ ...... +cmA(i-m)
where x(k) is the m-dimensional state vector at position k along a scan line, f(k) is
the input intensity at position k, g(k) is the output intensity, m is the blur extent,
N is the number of elements in a line, c is a scalar, M, a and b are constant
matrices of order (mxm), (mxl) and (lxm) respectively, containing the discrete
values Cj of the blurring PSF h(j) for j=O, ... ,m and 1::.(.) is the Kronecker delta
function.

666

INFLUENCE OF BOTH TIME CONSTANT AND VELOCITY
ON THE AMOUNT OF MOTION BLUR IN AN ARTIFICIAL
RECEPTOR ARRAY
To start with, we incorporate in our simulation model a PSF, derived from
equation (1), to model the performance of all neural columnar arranged filters in
the lobula complex, with the restriction that the time constants f remain fixed
throughout the whole range of stimulus velocities. Realization of this PSF can
easily be achieved via the just mentioned state space model.

300
250
I.

200
\

150

\

\

\

\
\

:3 100

.

<{

w

0

50

,,,
7

\
\

..

I.

..
"", ,

,

.

\
\
\

\

\

\

\

\

\

\

\

"", ,

\

""""

""-

0

1a..::i 250
:::>

.....

~
<{

200
150
100

""

50

O~--~~----~~~~--~~--~

o

Fig.3

5

10

15

20

POSITION IN
ARTIFICIAL RECEPTOR ARRAY
?

upper part. Demonstration of the effect that an increase in magnitude of

the time constants of an one-dimensional array of filters will result in
increase in motion blur (while the pattern velocity remains constant).
Original pattern shown in solid lines is a square-wave grating with a
spatial wavelength equal to 8 artificial receptor distances. The three
other wave forms drawn, show that for a gradual increase increase in
magnitude of the time constants, the representation of the original
square-wave will consequently degrade. lower part. A gradual increase in
velocity of the moving square-wave (while the filter time constants are
kept fixed) results also in a clear increase of degradation.

667

First we demonstrate the effect that an increase in time constant (while the
pattern velocity remains the same) will result in an increase in blur. Therefore we
introduce an one dimensional array of filters all being equipped with the same
time constant in their impulse response. The original pattern shown in square and
solid lines in the upper part of figure 3 consists of a square wave grating with a
spatial period overlapping 8 artificial receptive filters. The 3 other patterns drawn
there show that for the same constant velocity of the moving grating, an increase
in the magnitude of the time constants of the filters results in an increased blur in
the representation of that grating. On the other hand, an increase in velocity
(while the time constants of the artificial receptive units remain the same) also
results in a clear increase in motion blur, as demonstrated in the lower part of
figure 3.
Inspection of the two wave forms drawn by means of the dashed lines in
both upper and lower half of the figure, yields the conclusion, that (apart from
rounding errors introduced by the rather small number of artificial filters
available), equal amounts of smear will be produced when the product of time
constant and pattern velocity is equal. For the upper dashed wave form the
velocity was four times smaller but the time constant four times larger than for its
equivalent in the lower part of the figure.

ADAPTIVE SCHEME
In designing a proper image processing procedure our next step is to
incorporate the experimentally observed flexibility property of the time constants
in the imaging elements of our device. In figure 4a a scheme is shown, which
filters the information with fixed time constants, not influenced by the pattern
velocity. In figure 4b a network is shown where the time constants also remain
fixed no matter what pattern movement is presented, but now at the next level of
information processing, a spatially differential network is incorporated in order to
enhance blurred contrasts.
In the filtering network in figure 4c , first a measurement of the magnitude
of the velocity of the moving objects is done by thus far hypothetically introduced
movement processing algorithms, modelled here as a set of receptive elements
sampling the environment in such a manner that proper estimation of local pattern
velocities can be done. Then the time constants of the artificial receptive elements
will be tuned according to the estimated velocities and finally the same
differential network as in scheme 4b , is used.
The actual tuning mechanism used for our simulations is outlined in figure
5: once given the range of velocities for which the model is supposed to be
operational, and given a lower limit for the time constant 'f min ('f min can be the
smallest value which physically can be realized), the time constant will be tuned to
a new value according to the experimentally observed reciprocal relationship, and
will, for all velocities within the adaptive range, be larger than the fixed minimum
value. As demonstrated in the previous section the corresponding blur in the
representation of the moving stimulus will thus always be larger than for the
situation in which the filtering is done with fixed and smallest time constants
.,. min. More important however is the fact that due to this tuning mechanism the
blur will be constant since the product of velocity and time constant is kept
constant. So, once the information has been processed by such a system, a velocity
independent representation of the image will be the result, which can serve as the
input for the spatially differentiating network as outlined in figure 4c .
The most elementary form for this differential filtering procedure is the one

668

in which the gradient of two filters K-I and K+l which are the nearest neighbors
of filter K, is taken and then added with a constant weighing factor to the central
output K as drawn in figure 4 b and 4 c , where the sign of the gradient depends on
the direction of the estimated movement. Essential for our model is that we claim
that this weighing factor should be constant throughout the whole set of filters
and for the whole high velocity range in which the heterodyne imaging has to be
performed. Important to notice is the existence of a so-called settling time, i.e. the
minimal time needed for our movement processing device to be able to accurately
measure the object velocity. [Note: this time can be set equal to zero in the case
that the relative stimulus velocity is known a priori, as demonstrated in figure 3].
Since, without doubt, within this settling period estimated velocity values will
come out erroneously and thus no optimal performance of our imaging device can
be expected, in all further examples, results after this initial settling procedure
will be shown.
2
3
,
5
A

B

;

C

Fig. 4

~

v

yV

9'

r39 rYO

/ y

i

7.' r~ ;/Y ?. Y
[~l [~l i~J
~'

't""if ~' n

Pattern movement in this figure is to the right.
A: Network consisting of a set of filters with a fixed, pattern velocity
independent, time constant in their impulse response.
B: Identical network as in figure 4A now followed by a spatially
differentiating circuitry which adds the weighed gradients of two
neighboring filter outputs K-l and K+I to the central filter output

K.
C: The time constants of the filtering network are tuned by a
hypothetical movement estimating mechanism, visualized here as a
number of receptive elements, of which the combined output tunes
the filters. A detailed description of this mechanism is shown in
figure 5. This tuned network is followed by an identical spatially
differentiating circuit as described in figure 4B.

669

increasing velocity

?

v

(<?s)

1:

1:
----_
.
decreasing time constant

Fig. 5

min

Detailed description of the mechanism used to tune the time constants.
The time constant f of a specific neural channel is set by the pattern
velocity according to the relationship shown in the insert, which is
derived from eq. (2) with cx=- I and 13= I.
6 r
i',

4r

""

,,'I,
,, ,,
""

I,

'""

\

2

=f

< 0

~

,

v
,

~

I
I
I

, ,,

w

o::;)

-

I

I
I

~

,,-

\

h

,/'

,

I

:J:

<

4V

r;-""
, ::-:-

- ~be-.--1
,

=-.:!

I

I

, -... -

-~

""
""\

:'

a.

2V

""V

2

- /,-----

o Wi

8V

12 V

I

J/---'1;""- -- ---

1:

16 V
J

\

. r------l...- --

POSITION IN ARTIFICIAL RECEPTOR ARRAY

Fig.6

Thick lines: square-wave stimulus pattern with a spatial wavelength
overlapping 32 artificial receptive elements. Thick lines: responses for 6
different pattern velocities in a system consisting of paralleling neural
filters equipped with time constants, tuned by this velocity, and followed
by a spatially differentiating network as described.
Dashed lines: responses to the 6 different pattern velocities in a filtering
system with fixed time constants, followed by the same spatial
differentiating circuitry as before. Note the sharp over- and under
shoots for this case.

670

Results obtained with an imaging procedure as drawn in figure 4 b and 4c
are shown in figure 6. The pattern consists of a square wave, overlapping 32
picture elements. The pattern moves (to the left) with 6 different velocities v, 2v,
4v, 8v, 12v, 16v. At each velocity only one wavelength is shown. Thick lines:
square wave pattern. Dashed lines: the outputs of an imaging device as depicted in
figure 4 b: constant time constants and a constant weighing factor in the spatial
processing stage. Note the large differences between the several outputs. Thin
continuous lines: the outputs of an imaging device as drawn in figure 4c: tuned
time constants according to the reciprocal relationship between pattern velocity
and time constant and a constant weighing factor in the spatial processing stage.
For further simulation details the reader is referred to Zaagman et al. 21 . Now the
outputs are almost completely the same and in good agreement with the original
stimulus throughout the whole velocity range.
Figure 7 shows the effect of the gradient weighing factor on the overall
filter performance, estimated as the improvement of the deblurred images as
compared with the blurred image, measured in dB. This quantitative measure has
been determined for the case of a moving square wave pattern with motion blur
7.-------~------~r-------_r------~

6

5

IX)

""0

4
0)

u
C
ItI

E

-

3

c-

o

~ 2

a.
c-

O)

~

;z:

1

0
-1

0

1

2
weighing factor

Fig. 7

3

4

?

Effect of the weighing factor on the overall filter performance. Curve
measured for the case of a moving square-wave grating. Filter
performance is estimated as the improvement in signal to noise ratio:
1=10? 1010g (

I:iI:j?V(i,j)-U(i,j?2)
I:iI: j? O(i,j) - u(i,j? 2

where u(i,j) is the original intensity at position (i,j) in the image, v(i,j)
is the intensity at the same position (i,j) in the motion blurred image and
O(i,j) is the intensity at (i,j) in the image, generated with the adaptive
tuning procedure.

671

extents comparable to those used for the simulations to be discussed in section IV.
From this curve it is apparent that for this situation there is an optimum value for
this weighing factor. Keeping the weight close to this optimum value will result in
a constant output of our adaptive scheme, thus enabling an optimal deblurring of
the smeared image of the moving object.
On the other hand, starting from the point of view that the time constants
should remain fixed throughout the filtering process, we should had have to tune
the gradient weights to the velocity in order to produce a constant output as
demonstrated in figure 6 where the dashed lines show strongly differing outputs of
a fixed time constant system with spatial processing with constant weight (figure
4b ). In other words, tuning of the time constants as proposed in this section results
in: I) the realization of the blur-constancy criterion as formulated previously, and
2) -as a consequence- the possibility to deblur the obtained image oPtimally with
one and the same weighing factor of the gradient in the final spatial processing
layer over the whole heterodyne velocity range.

COMPUTER SIMULATION RESULTS AND
CONCLUSIONS
The image quality improvement algorithm developed in the present
contribution has been implemented on a general purpose DG Eclipse Sjl40 minicomputer for our two dimensional simulations. Figure Sa shows an undisturbed
image, consisting of 256 lines of each 256 pixels, with S bit intensity resolution.
Figure Sb shows what happens with the original image if the PSF is modelled
according to the exponential decay (2). In this case the time constants of all
spatial information processing channels have been kept fixed. Again, information
content in the higher spatial frequencies has been reduced largely. The
implementation of the heterodyne filtering procedure was now done as follows:
first the adaptation range was defined by setting the range of velocities. This
means that our adaptive heterodyne algorithm is supposed to operate adequately
only within the thus defined velocity range and that -in that range- the time
constants are tuned according to relationship (2) and will always come out larger
than the minimum value 1 min. For demonstration purposes we set Q=I and /3=1 in
eq. (2), thus introducing the phenomenon that for any velocity, the two
dimensional set of spatial filters with time constants tuned by that velocity, will
always produce a constant output, independent of this velocity which introduces
the motion blur. Figure Sc shows this representation. It is important to note here
that this constant output has far more worse quality than any set of filters with
smallest and fixed time constants 1 min would produce for velocities within the
operational range. The advantage of a velocity independent output at this level in
our simulation model, is that in the next stage a differential scheme can be
implemented as discussed in detail in the preceding paragraph. Constancy of the
weighing factor which is used in this differential processing scheme is guaranteed
by the velocity independency of the obtained image representation.
Figure Sd shows the result of the differential operation with an optimized
gradient weighing factor. This weighing factor has been optimized based on an
almost identical performance curve as described previously in figure 7. A clear
and good restoration is apparent from this figure, though close inspection reveals
fine structure (especially for areas with high intensities) which is unrelated with
the original intensity distribution. These artifacts are caused by the phenomenon
that for these high intensity areas possible tuning errors will show up much more
pronounced than for low intensities.

672

Fig.8a
Fig.8b
Fig. 8c
Fig.8d

a

(

b

d

Original 256x256x8 bit picture.
Motion degraded image with a PSF derived from R(t)=c+a -e( -t/r).
where T is kept fixed to 12 pixels and the motion blur extent is 32
pixels.
Worst case, i.e. the result of motion degradation of the original image
with a PSF as in figure 8b , but with tuning of the time constants based
on the velocity.
Restored version of the degraded image using the heterodyne adaptive
processing scheme.

In conclusion: a heterodyne adaptive image processing technique, inspired by
the fly visual system, has been presented as an imaging device for moving objects.
A scalar difference equation model has been used to represent the motion blur
degradation process. Based on the experimental results described and on this state
space model, we developed an adaptive filtering scheme. which produces at a
certain level within the system a constant output, permitting further differential
operations in order to produce an optimally deblurred representation of the
moving object.

ACKNOWLEDGEMENTS
The authors wish to thank mT. Eric Bosman for his expert programming

673

assistance, mr. Franco Tommasi for many inspiring discussions and advises during
the implementation of the simulation model and dr. Rob de Ruyter van Steveninck
for experimental help. This research was partly supported by the Netherlands
Organization lor the Advancement 01 Pure Research (Z.W.O.) through the
foundation Stichting voor Biolysica.

REFERENCES
I. K. Hausen, Z. Naturforschung 31c, 629-633 (1976).
2. N. J. Strausfeld, Atlas of an insect brain (Springer Verlag, Berlin, Heidelberg,
New York, 1976).
3. K. Hausen, BioI. Cybern. 45, 143-156 (1982).
4. R. Hengstenberg, J. Compo Physiol. 149, 179-193 (1982).
5. W. H. Zaagman, H. A. K. Mastebroek, J. W. Kuiper, BioI. Cybern. 31, 163-168
( 1978).
6. H. A. K. Mastebroek, W. H. Zaagman, B. P. M. Lenting, Vision Res. 20, 467474 (1980)
7. R. R. de Ruyter van Steveninck, W. H. Zaagman, H. A. K. Mastebroek, BioI.
Cybern., 54, 223-236 (1986).
8. W. Reichardt, T. Poggio, Q. Rev. Biophys. 9, 311-377 (1976).
9. W. Reichardt, in Reichardt, W. (Ed.) Processing of optical Data by Organisms
and Machines (Academic Press, New York, 1969), pp. 465-493.
10. T. Poggio, W. Reichardt, Q. Rev. Bioph. 9, 377-439 (1976).
11. D. Marr, S. Ullman, Proc. R. Soc. Lond. 211, 151-180 (1981).
12. J. P. van Santen, G. Sperling, J. Opt. Soc. Am. A I, 451-473 (1984).
13. J. L. Harris SR., J. Opt. Soc. Am. 56, 569-574 (1966).
14. A. A. Sawchuk, Proc. IEEE, Vol. 60, No.7, 854-861 (1972).
15. M. M.Sondhi, Proc. IEEE, Vol. 60, No.7, 842-853 (1972).
16. N. E. Nahi, Proc. IEEE, Vol. 60, No.7, 872-877 (1972).
17. A. O. Aboutalib, L. M. Silverman, IEEE Trans. On Circuits And Systems TCAS 75, 278-286 (1975).
18. A. O. Aboutalib, M. S. Murphy, L.M. Silverman, IEEE Trans. Automat. Contr.
AC 22, 294-302 (1977).
19. Th. Hildebrand, BioI. Cybern. 36, 229-234 (1980).
20. S. A. Rajala, R. J. P. de Figueiredo, IEEE Trans. On Acoustics, Speech and
Signal Processing, Vol. ASSSP-29, No.5, 1033-1042 (1981).
21. W. H. Zaagman, H. A. K. Mastebroek, R. R. de Ruyter van Steveninck, IEEE
Trans, Syst. Man Cybern. SMC 13, 900-906 (1983).

"
51,1987,"REFLEXIVE ASSOCIATIVE MEMORIES","",51-reflexive-associative-memories.pdf,"Abstract Missing","495

REFLEXIVE ASSOCIATIVE MEMORIES
Hendrlcus G. Loos
Laguna Research Laboratory, Fallbrook, CA 92028-9765
ABSTRACT
In the synchronous discrete model, the average memory capacity of
bidirectional associative memories (BAMs) is compared with that of
Hopfield memories, by means of a calculat10n of the percentage of good
recall for 100 random BAMs of dimension 64x64, for different numbers
of stored vectors. The memory capac1ty Is found to be much smal1er than
the Kosko upper bound, which Is the lesser of the two dimensions of the
BAM. On the average, a 64x64 BAM has about 68 %of the capacity of the
corresponding Hopfield memory with the same number of neurons. Orthonormal coding of the BAM Increases the effective storage capaCity by
only 25 %. The memory capacity limitations are due to spurious stable
states, which arise In BAMs In much the same way as in Hopfleld
memories. Occurrence of spurious stable states can be avoided by
replacing the thresholding in the backlayer of the BAM by another
nonl1near process, here called ""Dominant Label Selection"" (DLS). The
simplest DLS is the wlnner-take-all net, which gives a fault-sensitive
memory. Fault tolerance can be improved by the use of an orthogonal or
unitary transformation. An optical application of the latter is a Fourier
transform, which is implemented simply by a lens.
INTRODUCT ION
A reflexive associative memory, also called bidirectional associative memory, is a two-layer neural net with bidirectional connections
between the layers. This architecture is implied by Dana Anderson's
optical resonator 1, and by similar configurations 2,3. Bart KoSk0 4 coined
the name ""Bidirectional Associative Memory"" (BAM), and Investigated
several basic propertles 4 - 6. We are here concerned with the memory
capac1ty of the BAM, with the relation between BAMs and Hopfleld
memories 7, and with certain variations on the BAM.
? American Institute of Physics 1988

496

BAM STRUCTURE
We will use the discrete model In which the state of a layer of
neurons Is described by a bipolar vector. The Dirac notationS will be
used, In which I> and <I denote respectively column and row vectors. <al
and la> are each other transposes, <alb> Is a scalar product, and la><bl is
an outer product. As depicted in Fig. 1, the BAM has two layers of
neurons, a front layer of Nneurons w tth state vector If>, and a back layer
back layer. P neurons
back
of P neurons with state vector
state vector b
stroke
Ib>. The bidirectional connectlons between the layers allow
signal flow In two directions.
frOnt1ay~r. 'N ~eurons forward
The front stroke gives Ib>=
state vector f
stroke
s(Blf?, where B 15 the connecFig. 1. BAM structure
tlon matrix, and s( ) Is a threshold function, operating at
zero. The back stroke results 1n an u~graded front state <f'I=s( <biB),
whIch also may be wr1tten as !r'>=s(B Ib> >. where the superscr1pt T
denotes transpos1t10n. We consider the synchronous model. where all
neurons of a layer are updated s1multaneously. but the front and back
layers are UPdated at d1fferent t1mes. The BAM act10n 1s shown 1n F1g. 2.
The forward stroke entalls takIng scalar products between a front
state vector If> and the rows or B, and enter1ng the thresholded results
as elements of the back state vector Ib>. In the back stroke we take

11

f

threshold ing
& reflection

lID

NxP
FIg. 2. BAM act 10n

v
threshold ing
& reflection

~ ~hreShOlding

4J
&

NxN

feedback

V

b
Ftg. 3. Autoassoc1at1ve
memory act10n

scalar products of Ib> w1th column vectors of B, and enter the
thresholded results as elements of an upgraded state vector 1('>. In
contrast, the act10n of an autoassoc1at1ve memory 1s shown 1n F1gure 3.
The BAM may also be described as an autoassoc1at1ve memory5 by

497

concatenating the front and back vectors tnto a s1ngle state vector
Iv>=lf,b>,and by taking the (N+P)x(N+P) connection matrtx as shown in F1g.
4. This autoassoclat1ve memory has the same number of neurons as our
f . b'----""""
BAM, viz. N+P. The BAM operat1on where
----!'
initially only the front state 1s specif thresholding
zero [IDT
& feedback
f1ed may be obtained with the corresponding autoassoc1ative memory by
lID zero b
initially spectfying Ib> as zero, and by
Fig. 4. BAM as autoassoarranging the threshold1ng operat1on
ctative memory
such that s(O) does not alter the state
vector component. For a Hopfteld
memory7 the connection matrix 1s
M
(1)
H=( 1m> <mD -MI ,
m=l

I

where 1m>, m= 1 to M, are stored vectors, and I is the tdentity matr1x.
Writing the N+P d1mens1onal vectors 1m> as concatenations Idm,c m>, (1)
takes the form
H-(

I

M

(ldm><dml+lcm><cml+ldm><cml+lcm><dmD)-MI ,
m=l

(2)

w1th proper block plactng of submatr1ces understood. Writing

M
K= Llcm><dml ,
M
m=l
M
Hd=(Lldm><dmD-MI,
Hc=( L'lcm><cml>-MI,
m=l
m=l

(3)
(4)

where the I are identities in appropriate subspaces, the Hopfield matrix
H may be partitioned as shown in Fig. 5. K is just the BAM matrix given
by Kosko 5, and previously used by Kohonen 9 for linear heteroassoclatjve
memories. Comparison of Figs. 4 and 5 shows that in the synchronous
discrete model the BAM with connection matrix (3) is equivalent to a
Hopfield memory in which the diagonal blocks Hd and Hc have been

498

deleted. Since the Hopfleld memory is robust~ this ""prun1ng"" may not
affect much the associative recall of stored vectors~ if M is small;
however~ on the average~ pruning will not improve the memory capaclty.
It follows that, on the average~ a discrete synchronous BAM with matrix
(3) can at best have the capacity of a Hopfleld memory with the same
number of neurons.
We have performed computations of the average memory capacity
for 64x64 BAMs and for corresponding 128x 128 Hopfleld memories.
Monte Carlo calculations were done for 100 memories) each of which
stores M random bipolar vectors. The straight recall of all these vectors
was checked) al10wtng for 24 Iterations. For the BAMs) the iterations
were started with a forward stroke in which one of the stored vectors
Idm> was used as input. The percentage of good recall and its standard
deviation were calculated. The results plotted in Fig. 6 show that the
square BAM has about 68~ of the capacity of the corresponding Hopfleld
memory. Although the total number of neurons is the same) the BAM only
needs 1/4 of the number of connections of the Hopfield memory. The
storage capacity found Is much smaller than the Kosko 6 upper bound)
which Is min (N)P).

JR[=
10

Fig. 5. Partitioned
Hopfield matrix

20

30

40

50

60

M. number of stored vectors

Fig. 6.

~

of good recall versus M

CODED BAM
So far) we have considered both front and back states to be used for
data. There is another use of the BAM in which only front states are used
as data) and the back states are seen as providing a code) label, or
pOinter for the front state. Such use was antiCipated in our expression
(3) for the BAM matrix which stores data vectors Idm> and their labels or
codes lem>. For a square BAM. such an arrangement cuts the Information
contained in a single stored data vector jn half. However, the freedom of

499

choosing the labels fC m> may perhaps be put to good use. Part of the
problem of spurious stable states which plagues BAMs as well as
Hopf1eld memories as they are loaded up, is due to the lack of
orthogonality of the stored vectors. In the coded BAM we have the
opportunity to remove part of this problem by choosing the labels as
orthonorma1. Such labels have been used previously by Kohonen 9 1n linear
heteroassociative memories. The question whether memory capacity can
be Improved In this manner was explored by taking 64x64 BAt1s In which
the labels are chosen as Hadamard vectors. The latter are bipolar vectors
with Euclidean norm ,.fp, which form an orthonormal set. These vectors
are rows of a PxP Hadamard matrix; for a discussion see Harwtt and
Sloane 10. The storage capacity of such Hadamard-coded BAMs was
calculated as function of the number M of stored vectors for 100 cases
for each value of M, in the manner discussed before. The percentage of
good recall and its standard deviation are shown 1n Fig. 6. It Is seen that
the Hadamard coding gives about a factor 2.5 in M, compared to the
ordinary 64x64 BAM. However, the coded BAM has only half the stored
data vector dimension. Accounting for this factor 2 reduction of data
vector dimension, the effective storage capacity advantage obtained by
Hadamard coding comes to only 25 ~.
l

HALF BAt1 WITH HADAMARD CODING
For the coded BAM there is the option of deleting the threshold
operation In the front layer. The resulting architecture may be called
""half BAt1"". In the half BAM, thresholding Is only done on the labels, and
consequently, the data may be taken as analog vectors. Although such an
arrangement diminishes the robustness of the memory somewhat, there
are applications of interest. We have calculated the percentage of good
recall for 100 cases, and found that giving up the data thresholding cuts
the storage capacity of the Hadamard-coded BAt1 by about 60 %.
SELECTIVE REFLEXIVE MEMORY
The memory capacity limitations shown in Fig. 6 are due to the
occurence of spurious states when the memories are loaded up.
Consider a discrete BAM with stored data vectors 1m>, m= 1 to M,
orthonormal labels Icm>, and the connection matrix

500

(5)

For an input data vector Iv> which is closest to the stored data vector
11 >, one has 1n the forward stroke
M

Ib>=s(clc 1>+

L amlcm?

(6)

,

m=2
where
c=< llv> ?

and

(7)

am=<mlv>
M

Although for m# 1 am<c, for some vector component the sum

L

amlc m>

m=2
may accumulate to such a large value as to affect the thresholded result
Ib>. The problem would be avoided jf the thresholding operation s( ) in the
back layer of the BAM were to be replaced by another nonl1near operation
which selects, from the I inear combination
M

clc 1>+

L amlcm>

(8)

m=2
the dominant label Ic 1>. The hypothetical device which performs this
operation is here called the ""Dominant Label Selector"" (DLS) 11, and we
call the resulting memory architecture ""Selective Reflexive Memory""
(SRM). With the back state selected as the dominant label Ic 1>, the back
stroke gives <f'I=s( <c ,IK)=s(P< 1D=< 11, by the orthogonal ity of the labels
Icm>. It follows 11 that the SRM g1ves perfect assoc1attve recall of the
nearest stored data vector, for any number of vectors stored. Of course,
the llnear independence of the P-dimensionallabel vectors Icm>, m= 1 to
M, requires P>=M.
The DLS must select, from a linear combination of orthonormal
labels, the dominant label. A trivial case is obtained by choosing the

501

labels Icm>as basis vectors Ium>, which have all components zero except
for the mth component, which 1s unity. With this choice of labels, the
f
DLS may be taken as a winnertake-all net W, as shown in Fig. 7.
winner?
This case appears to be Included in
b take-all
net
Adapt Ive Resonance Theory
(ART) 12 as a special sjmpllf1ed
case. A relationship between
Flg.7. Simplest reflexive
the ordinary BAM and ART was
memory with DLS
pOinted out by KoskoS. As in ART,
there Is cons1derable fault sensitivity tn this memory, because the
stored data vectors appear in the connectton matrix as rows.
A memory with better fault tolerance may be obtained by using
orthogonal labels other than basis vectors. The DLS can then be taken as
an orthogonal transformation 6 followed by a winner-take-an net, as
shown 1n Fig. 8. 6 is to be chosen such that 1t transforms the labels Icm>

~

f

,.0 rthogonal

I

1

(G
i

1[

u

l

transformation

winner/' take-all
net

F1g. 8. Select1ve reflex1ve
memory

tnto vectors proportional to the
1
basts vectors um>. This can always
be done by tak1ng
p

(9)

G=[Iup><cpl ,

p=l
where the Icp>, p= 1 to P, form a

complete orthonormal set which
contains the labels Icm>, m=l to M. The neurons in the DLS serve as
grandmother cells. Once a single winning cell has been activated, I.e.,
the state of the layer Is a single basis vector, say lu I ) this vector
J

must be passed back, after appllcation of the transformation G- 1, such
as to produce the label IC1> at the back of the BAM. Since G 1s
orthogonal. we have 6- 1=6T, so that the reQu1red 1nverse
transformation may be accompl1shed sfmply by sending the bas1s vector
back through the transformer; this gives
P
(10)
<u 116=[<u 1IUp><cpl=<c 11
p=l

502

as required.
HAlF SRM
The SRM may be modified by deleting the thresholding operation in
the front layer. The front neurons then have a I inear output, which is
reflected back through the SRM, as shown in Fig. 9. In this case, the
stored data vectors and the
input data vectors may be taken
f I i near neurons
/
orthogonal
as analog vectors, but we re,1
transfor.1
Qu1re all the stored vectors to
mation
(G
~
have the same norm. The act i on
T
winnerof the SRM proceeds in the same
I '/' take-all
U
net
way as described above, except
that we now require the orthoFig. 9. Half SRM with l1near
normal labels to have unit
norm. It follows that, just l1ke
neurons in front layer
the full SRM, the half SRM gives
perfect associative recall to the nearest stored vector, for any number
of stored vectors up to the dimension P of the labels. The latter
condition 1s due to the fact that a P-dimensional vector space can at
most conta1n P orthonormal vectors.
In the SRM the output transform Gis 1ntroduced in order to improve
the fauJt tolerance of the connection matrix K. This is accomplished at
the cost of some fault sensitivity of G, the extent of which needs to be
investigated. In this regard 1t is noted that in certatn optical implementat ions of reflexive memories, such as Dana Anderson's resonator I and
Similar conflgurations 2,3, the transformation G is a Fourier transform,
which is implemented simply as a lens. Such an implementation ts quite
insentive to the common semiconductor damage mechanisms.
EQUIVALENT AUTOASSOCIATIVE MEMORIES
Concatenation of the front and back state vectors allows description of the SRMs tn terms of autoassociative memories. For the SRM
which uses basis vectors as labels the corresponding autoassociative
memory js shown tn Fjg. 10. This connect jon matrtx structure was also
proposed by Guest et. a1. 13. The wtnner-take-all net W needs to be

503

given t1me to settle on a basis
vector state before the state Ib>
slow thres / ' /'
holding &
can influence the front state If>.
feedback
b
f
This may perhaps be achieved by
zero I[T [~ ~
arranging the W network to have a
""I' f ast thres thresholding and feedback which
!r WI bl J h olding&
feedback
are fast compared with that of the
K network. An alternate method
Fig. 10. Equivalent automay be to equip the W network
associat lve memory
w1th an output gate which is
opened only after the W net has
sett led. These arrangements
present a compUcatlon and cause a delay, which in some appllcations
may be 1nappropriate, and In others may be acceptable in a trade
between speed and memory density.
For the SRM wtth output transformer and orthonormal1abels other
than basis vectors, a corresponf b , w ~eedback
ding autoassoclat1ve memory may
be composed as shown In Fig.l1.
f thresholded
(OJ [T (OJ
An output gate in the w layer is
b
linear
(OJ
(GT
I[
chosen as the device which
W thresholded
(Q) (G WI
prevents the backstroke through
+ output gate
the BAM to take place before the
w1nner-take-al net has settled.
Fig. 11. Autoassoc1at1ve memory
equivalent to SRM with transform
The same effect may perhaps be
achieved by choosing different
response times for the neuron
output gate
layers f and w. These matters
wr ~winner-take-all
require investigation. Unless
.......... Woutput
the output transform G 1s already
:t@
b back layer,
required for other reasons, as in
linear
some optical resonators, the DLS
'--_ _ _-' f front layer
II = BAM connections
with output transform is clumsy.
@ =orthogonal transformat i on
I t would far better to combine
W! ~ winner-take-all net
the transformer G and the net W
into a single network. To find
Fig. 12. Structure of SRM
such a DLS should be considered
a cha 11 enge.

""""

504

The wort< was partly supported by the Defense Advanced Research
projects Agency, ARPA order -5916, through Contract DAAHOI-86-C
-0968 with the U.S. Army Missile Command.
REFERENCES
1. D. Z. Anderson, ""Coherent optical eigenstate memory"", Opt. Lett. 11,
56 (1986).
2. B. H. Soffer, G. J. Dunning, Y. Owechko, and E. Marom, ""Associative
holographic memory with feedback using phase-conjugate mirrors"", Opt.
Lett. II, 118 ( 1986).
3. A. Yarrtv and S. K. Wong, ""Assoctat ive memories based on messagebearing optical modes In phase-conjugate resonators"", Opt. Lett. 11,
186 (1986).
4. B. Kosko, ""Adaptive Cognitive ProceSSing"", NSF Workshop for Neural
Networks and Neuromorphlc Systems, Boston, Mass., Oct. &-8, 1986.
5. B. KOSKO, ""Bidirectional Associative Memories"", IEEE Trans. SMC, In
press, 1987.
6. B. KOSKO, ""Adaptive Bidirectional Associative Memories"", Appl. Opt.,
1n press, 1987.
7. J. J. Hopfleld, ""Neural networks and physical systems with emergent
collective computational ablJ1tles"", Proc. NatJ. Acad. Sct. USA 79, 2554
( 1982).
8. P. A. M. Dirac, THE PRINCI PLES OF QUANTLt1 MECHANICS, Oxford, 1958.
9. T. Kohonen, ""Correlation Matrix Memories"", HelsinsKi University of
Technology Report TKK-F-A 130, 1970.
10. M. Harwit and N. J. A Sloane, HADAMARD TRANSFORM OPTICS,
Academic Press, New York, 1979.
11. H. G. Loos, Adaptive Stochastic Content-Addressable Memory"", Final
Report, ARPA Order 5916, Contract DAAHO 1-86-C-0968, March 1987.
12. G. A. Carpenter and S. Grossberg, ""A Massively Parallel Architecture
for a Self-Organizing Neural Pattern Recognition Machine"", Computer
Vision, Graphics, and Image processing, 37, 54 (1987).
13. R. D. TeKolste and C. C. Guest, ""Optical Cohen-Grossberg System
with Ali-Optical FeedbaCK"", IEEE First Annual International Conference
on Neural Networks, San Diego, June 21-24, 1987.
It

"
52,1987,"Teaching Artificial Neural Systems to Drive: Manual Training Techniques for Autonomous Systems","",52-teaching-artificial-neural-systems-to-drive-manual-training-techniques-for-autonomous-systems.pdf,"Abstract Missing","693

Teaching Artificial Neural Systems to Drive:
Manual Training Techniques for Autonomous Systems

J. F. Shepanski and S. A. Macy

TRW, Inc .
One Space Park, 02/1779
Redondo Beach, CA 90278

Abetract
We have developed a methodology for manually training autononlous control systems
based on artificial neural systems (ANS). In applications where the rule set governing an expert's
decisions is difficult to formulate, ANS can be used to ext.ra.c:t rules by associating the information
an expert receives with the actions h~ takes . Properly constructed networks imitate rules of
behavior that permits them to function autonomously when they are trained on the spanning set
of possible situations. This training can be provided manually, either under the direct. supervision
or a system trainer, or indirectly using a background mode where the network assimilates training
data as the expert perrorms his day-to-day tasks. To demonstrate these methods we have trained
an ANS network to drive a vehicle through simulated rreeway traffic.

I ntJooducticn
Computational systems employing fine grained parallelism are revolutionizing the way we
approach a number or long standing problems involving pattern recognition and cognitive processing. The field spans a wide variety or computational networks, rrom constructs emulating neural
runctions, to more crystalline configurations that resemble systolic arrays. Several titles are used
to describe this broad area or research, we use the term artificial neural systems (ANS). Our concern in this work is the use or ANS ror manually training certain types or autonomous systems
where the desired rules of behavior are difficult to rormulate.
Artificial neural systems consist of a number or processing elements interconnected in a
weighted, user-specified fashion, the interconnection weights acting as memory ror the system.
Each processing element calculatE',> an output value based on the weighted sum or its inputs. In
addition, the input data is correlated with the output or desired output (specified by an instructive
agent) in a training rule that is used to adjust the interconnection weights. In this way the ne~
work learns patterns or imitates rules of behavior and decision making.
The partiCUlar ANS architecture we use is a variation of Rummelhart et. al. [lJ multi-layer
perceptron employing the generalized delta rule (GD R). Instead of a single, multi-layer ,structure, our final network has a a multiple component or ""block"" configuration where one blOt'k'~
output reeds into another (see Figure 3). The training methodology we have developed is not
tied to a particular training rule or architecture and should work well with alternative networks
like Grossberg's adaptive resonance model[2J.

? American Institute of Physics 1988

694

The equations describing the network are derived and described in detail by Rumelhart et.
al.[l]. In summary, they are:
Transfer function:

Sj =

?

E WjiOi;

(1)

i-O

Weight adaptation rule:
Error calculation:

Awl'?? =( 1- a l'..)n., l'??0 J?0??

OJ

+ a l'??Awp.revious
.'
l'

'""

=0j{1- OJ) E0.tW.ti,

( 2)

( 3)

.t=1

where OJ is the output or processing element j or a sensor input, wi is the interconnection weight
leading from element ito i, n is the number of inputs to j, Aw is the adjustment of w, '1 is the
training constant, a is the training ""momentum,"" OJ is the calculated error for element i, and m
is the Canout oC a given element. Element zero is a constant input, equal to one, so that. WjO is
equivalent to the bias threshold of element j. The (1- a) factor in equation (2) differs from standard GDR formulation, but. it is useful for keeping track of the relative magnitudes of the two
terms. For the network's output layer the summation in equation (3) is replaced with the
difference between the desired and actual output value of element j.
These networks are usually trained by presenting the system with sets of input/output data
vectors in cyclic fashion, the entire cycle of database presentation repeated dozens of times . This
method is effective when the training agent is a computer operating in batch mode, but would be
intolerable for a human instructor. There are two developments that will help real-time human
training. The first is a more efficient incorporation of data/response patterns into a network. The
second, which we are addressing in this paper, is a suitable environment wherein a man and ANS
network can interact in training situation with minimum inconvenience or boredom on the
human's part. The ability to systematically train networks in this fashion is extremely useful for
developing certain types of expert systems including automatic signal processors, autopilots,
robots and other autonomous machines. We report a number of techniques aimed at facilitating
this type of training, and we propose a general method for teaching these networks .
System. Development

Our work focuses on the utility of ANS for system control. It began as an application of
Barto and Sutton's associative search network[3]. Although their approach was useful in a
number of ways, it fell short when we tried to use it for capturing the subtleties of human
decision-making. In response we shifted our emphasis rrom constructing goal runctions for
automatic learning, to methods for training networks using direct human instruction. An integral
part or this is the development or suitable interraces between humans, networks and the outside
world or simulator. In this section we will report various approaches to these ends, and describe a
general methodology for manually teaching ANS networks . To demonstrate these techniques we
taught a network to drive a robot vehicle down a simulated highway in traffic. This application
combines binary decision making and control of continuous parameters.
Initially we investigated the use or automatic learning based on goal functions[3] for training control systems. We trained a network-controlled vehicle to maintain acceptable following
distances from cars ahead or it. On a graphics workstation, a one lane circular track was

695

constructed and occupied by two vehicles: a network-controlled robot car and a pace car that
varied its speed at random .. Input data to the network consisted of the separation distance and
the speed of the robot vehicle . The values of a goal function were translated into desired output
for GDR training. Output controls consisted of three binary decision elements : 1) accelerate one
increment of speed, 2) maintain speed, and 3) decelerate one increment of speed. At all times
the desired output vector had exactly one of these three elements active . The goal runction was
quadratic with a minimum corresponding to the optimal following distance. Although it had no
direct control over the simulation, the goal function positively or negatively reinforced the
system's behavior.
The network was given complete control of the robot vehicle, and the human trainer had
no influence except the ability to start and terminate training. This proved unsatisractory because
the initial system behavior--governed by random interconnection weights--was very unstable. The
robot tended to run over the car in rront of it before significant training occurred . By carerully
halting and restarting training we achieved stable system behavior. At first the rollowing distance
maintained by the robot car oscillated as ir the vehicle was attached by a sj)ring to the pace car.
This activity gradually damped. Arter about one thousand training steps the vehicle maintained
the optimal following distance and responded quickly to changes in the pace car's speed.
Constructing composite goal functions to promote more sophisticated abilities proved
difficult, even ill-defined, because there were many unspecified parameters. To generate goal
runctions ror these abilities would be similar to conventional programming--the type or labor we
want to circumvent using ANS. On the other hand, humans are adept at assessing complex situations and making decisions based on qualitative data, but their ""goal runctions"" are difficult ir not
impossible to capture analytically. One attraction of ANS is that it can imitate behavior based on
these elusive rules without rormally specifying them. At this point we turned our efforts to
manual training techniques.
The initially trained network was grafted into a larger system and augmented with additional inputs: distance and speed inrormation on nearby pace cars in a second traffic lane, and an
output control signal governing lane changes . The original network's ability to maintain a safe
following distance was retained intact. Thts grafting procedure is one of two methods we studied
for adding ne .... abilities to an existin, system. (The second, which employs a block structure, is
described below.) The network remained in direct control of the robot vehicle, but a human
trainer instructed it when and when not to change lanes. His commands were interpreted as the
desired output and used in the GDR training algorithm. This technique, which we call coaching,
proved userul and the network quickly correlated its environmental inputs with the teacher's
instructions. The network became adept at changing lanes and weaving through traffic. We found
that the network took on the behavior pattern or its trainer. A conservative teacher produced a
timid network, while an aggressive tzainer produced a network that tended to cut off other automobiles and squeeze through tight openings . Despite its success, the coaching method of training
did not solve the problem or initial network instability.
The stability problem was solved by giving the trainer direct control over the simulation.
The system configuration (Figure 1), allows the expert to exert control or release it to the n~t?
work. During initial tzaining the expert is in the driver's seat while the network acts the role of

696

apprentice. It receives sensor information, predicts system commands, and compares its predictions. against the desired output (ie. the trainer's commands) . Figure 2 shows the data and command flow in detail. Input data is processed through different channels and presented to the
trainer and network. Where visual and audio formats are effective for humans, the network uses
information in vector form. This differentiation of data presentation is a limitation of the system;
removing it is a cask for future ~search. The trainer issues control commands in accordance with
his assigned ~k while the network takes the trainer's actions as desired system responses and
correlates these with the input. We refer to this procedure as master/apprentice training, network
training proceeds invisibly in the background as the expert proceeds with his day to day work. It
avoids the instability problem because the network is free to make errors without the adverse
consequence of throwing the operating environment into disarray.
I

Input

World (--> sensors)

l+

or

Simulation
~------------------~

~

Actuation

I

Ne',WOrk

~-

I

Expert

Commands
+
~------~---------------------------~
J

Figure 1. A scheme for manually training ANS networks. Input data is received by both
the network and trainer. The trainer issues commands that are actuated (solid command
line). or he coaches the network in how it ought to respond (broken command line).

--+ Commands

Preprocessing
tortunan
Input
data
Preprocessing
for network

N twork
e

t

--+

Predicted
commands

~
9'l. Actuation

.1-r""

'-------------.
Coaching/emphasis

Training
rule

Fegure 2. Data and convnand flow In the training system. Input data is processed and presented

to the trainer and network. In master/appre~ice training (solid command Hne). the trainer's
orders are actuated and the network treats his commands as the system's desired output. In
coaching. the network's predicted oonvnands are actuated (broken command line). and the
trainer influences weight adaptation by specifying the desired system output and controlHng
the values of trailing constants-his -suggestions- are not cirec:tty actuated.
Once initial. bacqround wainmg is complete, the expert proceeds in a more formal
manner to teach the network. He releases control of the command system to the network in
order to evaluate ita behavior and weaknesses. He then resumes control and works through a

697

series of scenarios designed to train t.he network out of its bad behavior. By switching back and
forth. between human and network control, the expert assesses the network's reliability and
teaches correct responses as needed. We find master/apprentice training works well for behavior
involving continuous functions, like steering. On the other hand, coaching is appropriate for decision Cunctions, like when Ule car ought to pass. Our methodology employs both techniques.
The Driving Network
The fully developed freeway simulation consists of a two lane highway that is made of
joined straight and curved segments which vary at. random in length (and curvature). Several
pace cars move at random speeds near the robot vehicle. The network is given the tasks of tracking the road, negotiating curves. returning to the road if placed far afield, maintaining safe distances from the pace cars, and changing lanes when appropriate. Instead of a single multi-layer
structure, the network is composed of two blocks; one controls the steering and the other regulates speed and decides when the vehicle should change lanes (Figure 3). The first block receives
information about the position and speed of the robot vehicle relative to other ears in its vicinity.
Its output is used to determine the automobile's speed and whet.her the robot should change
lanes . The passing signal is converted to a lane assignment based on the car's current lane position. The second block receives the lane assignment and data pertinent to the position and orientation of the vehicle with respect to the road. The output is used to determine the steering angle
of the robot car.

Block 1

Inputs

Outputs

Constant.
Speed.
Disl. Ahead, Pl ?
Disl. Ahead, Ol ?
Dist. Behind, Ol ?
ReI. Speed Ahead, Pl ?
ReI. Speed Ahead, Ol ?
ReI. Speed Behind, Ol ?

I

Speed
Change lanes

?

Steering Angle

Convert lane change to lane number
Constant
Rei. Orientation
-..--t~ lane Nurmer
lateral Dist.
Curvature

?
?
?
?
?

??
?

Figure 3. The two blocks of the driving ANS network. Heavy arrows Indicate total interconnectivity
between layers. PL designates the traffic lane presently oca.apied by the robot vehicle, Ol refers
to the other lane, QJrvature refers to the road, lane nurrber is either 0 or 1, relative orientation and
lateral distance refers to the robot car's direction and podion relative to the road'l direction and
center line. respectively.
.

698

The input data is displayed in pictorial and textual form to the driving instructor. He views
the road and nearby vehicles from the perspective of the driver's seat or overhead. The network
receives information in the form of a vector whose elements have been scaled to unitary order,
O( 1) . Wide ranging input parameters, like distance, are compressed using the hyperbolic tangent
or logarithmic functions . In each block , the input layer is totally interconnected to both the ou~
put and a hidden layer. Our scheme trains in real time, and as we discuss later, it trains more
smoothly with a small modification of the training algorithm .
Output is interpreted in two ways: as a binary decision or as a continuously varying parameter. The first simply compares the sigmoid output against a threshold. The second scales the
output to an appropriate range for its application . For example, on the steering output element, a
0.5 value is interpreted as a zero steering angle. Left and right turns of varying degrees are initiated when this output is above or below 0.5, respectively.
The network is divided into two blocks that can be trained separately. Beside being conceptually easier to understand , we find this component approach is easy to train systematically.
Because each block has a restricted, well-defined set of tasks, the trainer can concentrate
specifically on those functions without being concerned that other aspects of the network behavior
are deteriorating.
""'e trained the system from bottom up, first teaching the network to stay on the road ,
negotiate curves , chan~e lanes, and how to return if the vehicle strayed off the highway. Block 2,
responsible for steering, learned these skills in a few minutes using the master/apprentice mode.
It tended to steer more slowly than a human but further training progressively improved its
responsiveness.
We experimented with different trammg constants and ""momentum"" values. Large ""
values, about 1, caused weights to change too coarsely. "" values an order of magnitude smaller
worked well . We found DO advantage in using momentum for this method of training , in fact,
the system responded about three times more slowly when 0 =0.9 than when the momentt:m
term was dropped. Our standard training parameters were"" =0.2, and Cl' =00

a)

~

Db)~~

=D-=-~=~~--=~--= ~

Figure 4. Typical behavior of a network-controlled vehicle (dam rectangle) when trained by
a) a conservative miYer, ItI:I b}. reckless driver. Speed Is indicated by the length of the arrows.
After Block 2 ""Was trained, we gave steering control to the network and concentrated on
teaching the network to change lanes and adjust speed. Speed control in this ('""asP. was a continuous variable and was best taught using master/apprentice training. On the other hand, the binary
decision to change lanes was best taught by coaching . About ten minutes of training were needed
to teach the network to weave through traffic. We found that the network readily adapts the

699

behavioral pattern of its trainer. A conservative trainer generated a network that hardly ever
passed, while an aggressive trainer produced a network that drove recklessly and tended to cut off
other-cars (Figure 4).
Discussion
One of the strengths of el:pert 5ystf'mS based on ANS is that the use of input data in the
decision making and control proc~ss does not have to be specified . The network adapts its internal weights to conform to input/ output correlat.ions it discovers . It is important, however, that
data used by the human expert is also available to the network. The different processing of sensor data for man and network may have important consequences, key information may be
presented to the man but not. the machine.
This difference in data processing is particularly worrisome for image data where human
ability to extract detail is vastly superior to our au tomatic image processing capabilities. Though
we would not require an image processing system to understand images, it would have to extract
relevant information from cluttered backgrounds. Until we have sufficiently sophisticated algorithms or networks to do this, our efforts at constructing expert systems which halldle image data
are handicapped .
Scaling input data to the unitary order of magnitude is important for training stability. 111is
is evident from equations (1) and (2) . The sigmoid transfer function ranges from 0.1 to 0.9 in
approximat.eiy four units, that is, over an 0(1) domain. If system response must change in reaction to a large, O( n) swing of a given input parameter, the weight associated with that input will
be trained toward an O( n- 1) magnitude. On the other hand, if the same system responds to an
input whose range is O( 1), its associated weight will also be 0(1). The weight adjustment equation does not recognize differences in weight magnitude, therefore relatively small weights will
undergo wild magnitude adjustments and converge weakly. On the other hand, if all input parameters are of the same magnitude their associated weights will reflect this and the training constant
can be adjusted for gentle weight convergence . Because the output of hidden units are constrained between zero and one, O( 1) is a good target range for input parameters. Both the hyperbolic tangent and logarithmic functions are useful for scaling wide ranging inputs . A useful form
of the latter is
.8[I+ln(x/o)]
.8x/o
-.8[I+ln(-%/o)]

if o<x,
if-o::;x::;o,
ifx<-o,

( 4)

where 0>0 and defines the limits of the intermediate linear section, and .8 is a scaling factor.
This symmetric logarithmic function is continuous in its first derivative, and useful when network
behavior should change slowly as a parameter increases without bound. On the othl'r hand, if the
system should approach a limiting behavior, the tanh function is appropriate.
Weight adaptation is also complicated by relaxing the common practice of restricting interconnections to adjacent layers. Equation (3) shows that the calculated error for a hidden layergiven comparable weights, fanouts and output errors-will be one quarter or less than that of the

700

output layer. This is caused by the slope ractor, 0 .. ( 1- oil. The difference in error magnitudes is
not noticeable in networks restricted to adjacent layer interconnectivity. But when this constraint
is released the effect of errors originating directly from an output unit has 4"" times the magnitude
and effect of an error originating from a hidden unit removed d layers from the output layer.
Compared to the corrections arising from the output units, those from the hidden units have little
influence on weight adjustment, and the power of a multilayer structure is weakened . The system
will train if we restrict connections to adjacent layers, but it trains slowly. To compensate for this
effect we attenuate the error magnitudes originating from the output layer by the above factor.
This heuristic procedure works well and racilitates smooth learning.
Though we have made progress in real-time learning systems using GDR, compared to
humans-who can learn from a single data presentation-they remain relatively sluggish in learning
and response rates. We are interested in improvements of the GDR algorithm or alternative
architectures that facilitate one-shot or rapid learning. In the latter case we are considering least
squares restoration techniquesl4] and Grossberg and Carpenter's adaptive resonance modelsI3,5].
The construction of automated expert systems by observation of human personnel is
attractive because of its efficient use of the expert's time and effort. Though the classic AI
approach of rule base inference is applicable when such rules are clear cut and well organized, too
often a human expert can not put his decision making process in words or specify the values of
parameters that influence him . The attraction or ANS based systems is that imitations of expert
behavior emerge as a natural consequence of their training.

Referenees
1) D. E. Rumelhart, G . E. Hinton, and R. J. Williams, ""Learning Internal Representations by
Error Propagation,"" in Parallel D~tributed Proceuing: Ezploration~ in the Micro~trvcture 0/ Cognition,
Vol. I, D. E . Rumelhart and J. L. McClelland (Eds.)' chap. 8, (1986), Bradford BooksjMIT Press,
Cambridge

2) S. Grossberg,

Studie~

0/ Mind and Brain, (1982), Reidel, Boston

3) A. Barto and R. Sutton, ""Landmark Learning: An Illustration of Associative Search,"" BiologicaIC,6emetiu,42, (1981), p.l
4) A. Rosenfeld and A . Kak, Digital Pieture Proeming, Vol. 1, chap. 7, (1982), Academic Press,
New York

5) G. A. Carpenter and S. Grossberg, ""A Massively Parallel Architecture for a Self-organizing
Neural Pattern Recognition Machine,"" Computer Vision, Graphiu and Image Procu,ing, 37,
( 1987), p.54

"
53,1987,"The Connectivity Analysis of Simple Association","",53-the-connectivity-analysis-of-simple-association.pdf,"Abstract Missing","338

The Connectivity Analysis of Simple Association
- orHow Many Connections Do You Need!
Dan Hammerstrom *
Oregon Graduate Center, Beaverton, OR 97006
ABSTRACT
The efficient realization, using current silicon technology, of Very Large Connection
Networks (VLCN) with more than a billion connections requires that these networks exhibit
a high degree of communication locality. Real neural networks exhibit significant locality,
yet most connectionist/neural network models have little. In this paper, the connectivity
requirements of a simple associative network are analyzed using communication theory.
Several techniques based on communication theory are presented that improve the robustness of the network in the face of sparse, local interconnect structures. Also discussed are
some potential problems when information is distributed too widely.

INTRODUCTION
Connectionist/neural network researchers are learning to program networks that exhibit a broad range of cognitive behavior. Unfortunately, existing computer systems are limited in their ability to emulate such networks efficiently. The cost of emulating a network,
whether with special purpose, highly parallel, silicon-based architectures, or with traditional
parallel architectures, is directly proportional to the number of connections in the network.
This number tends to increase geometrically as the number of nodes increases. Even with
large, massively parallel architectures, connections take time and silicon area. Many existing neural network models scale poorly in learning time and connections, precluding large
implementations.
The connectivity 'costs of a network are directly related to its locality. A network
exhibits locality 01 communication 1 if most of its processing elements connect to other physically adjacent processing elements in any reasonable mapping of the elements onto a planar
surface. There is much evidence that real neural networks exhibit locality2. In this paper,
a technique is presented for analyzing the effects of locality on the process of association.
These networks use a complex node similar to the higher-order learning units of Maxwell et
al. 3

NETWORK MODEL
The network model used in this paper is now defined (see Figure 1).
Definition 1: A recursive neural network, called a c-graph is a graph structure,

r( V,E, e), where:
?

There is a set of CNs (network nodes), V, whose outputs can take a range of positive
real values, Vi, between 0 and 1. There are N. nodes in the set.

?

There is a set of codons, E, that can take a range of positive real values, eij (for
codon j of node i), between 0 and 1. There are Ne codons dedicated to each CN (the
output of each codon is only used by its local CN), so there are a total of Ne N. codons
in the network. The fan-in or order of a codon is Ie. It is assumed that leis the
same for each codon, and Ne is the same for each CN.

*This work was supported in part by the Semiconductor Research Corporation contract no. 86-10-097, and
jointly by the Office of Naval Research and Air Force Office of Scientific Research, ONR contract no. NOOO14 87 K
0259.

? American Institute of Physics 1988

339

Ie

codon j

Figure 1 - A ON

?

Cijk E C is a set of connections of ONs to codons, 1<i ,k<N. and 1<j <Ne , Cijk can
take two values {O,l} indicating the existence of a connection from ON k to codon j
of ON i . 0

Definition 2: The value of ON i is

Vi

=

F[8+~eijl

(1)

J-l

The function, F, is a continuous non-linear, monotonic function, such as the sigmoid function. 0

Definition 9: Define a mapping, D(i,j,x)_y, where x is an input vector to rand y is
the Ie element input vector of codon j of ON i. That is, y has as its elements those elements of Zk of x where Cijk=1, \;/ k. 0
The D function indicates the subset of x seen by codon j of ON i. Different input vectors may map to the same codon vectors, e.g., D(i,j,x)-y and D(i,j,Zj-y, where x~7.

Definition 4: The codon values eij are determined as follows. Let X( m) be input vector
m of the M learned input vectors for ON i. For codon eij of ON i, let Tij be the set of I cdimensional vectors such that lij(m)E T ij , and D(i,j,X(m))-lij(m). That is, each vector,
lij( m) in Tij consists of those subvectors of X( m) that are in codon ii's receptive field.
The variable 1 indexes the L ( i ,i) vectors of T ij . The number of distinct vectors in Tij
may be less than the total number of learned vectors (L(i,j)<M). Though the X(m) are
distinct, the subsets, lij(m), need not be, since there is a possible many to one mapping of
the x vectors onto each vector lij.
Let Xl be the subset of vectors where vi=l (ON i is supposed to output a 1), and
those vectors where vi=O, then define

0#(/) - .izeof {D(i,i ,Z'( m)) ""

.,-q}

for q=O,1, and \;/ m that map to this I. That is, ni~(I) is the number of

.xo be
(2)

x vectors that map

340

into ""Iij{l) where

tlj-O

and ni}{I) is the number of 7 vectors that map into ""Iii (I), where

tI;-1.

The compreaaion of a codon for a vector ""Iii(1) then is defined as

n.1.(/)

He.?( I) = _ _I.:....;;J- ' - - IJ

(3)

nj}(I)+nj~(I)

(Hqj(l)=O when both nt, nO-O.) The output of codon

I),

eii' is the maximum-likelyhood

decoding

(4)
Where He indicates the likely hood of t l j - l when a vector 7 that maps to , is input, and'
is that vector 1'(') where min[d.(1'('),y)] \I I, D(i,j,7)-V, and 7 is the current input vector. In other words, , is that vector (of the set of subset learned vectors that codon ij
receives) that is closest (using distance measure d.) to V (the subset input vector). 0
The output of a codon is the ""most-likely"" output according to its inputs. For example, when there is no code compression at a codon, eji-1, if the ""closest"" (in terms of some
measure of vector distance, e.g. Hamming distance) subvector in the receptive field of the
codon belongs to a learned vector where the CN is to output a 1. The codons described here
are very similar to those proposed by Marr 4 and implement ne!'Lrest-neighbor classification.
It is assumed that codon function is determined statically prior to network operation, that
is, the desired categories have already been learned.
To measure performance, network capacity is used.

Definition 5: The input noiae, Or, is the average d. between an input vector and the
closest (minimum d.) learned vector, where d. is a measure of the ""difference"" between two
vectors - for bit vectors this can be Hamming distance. The output noise, 0 0 , is the average
distance between network output and the learned output vector associated with the closest
learned input vector. The in/ormation gain, Gr , is just
Gt

=-10.[ ~~

I

(5)

o
Definition 6: The capacity of a network is the maximum number of learned vectors such
that the information gain, Gr , is strictly positive (>0). 0

COMMUNICATION ANALOGY
Consider a single connection network node, or CN. (The remainder of this paper will
be restricted to a single CN.) Assume that the CN output value space is restricted to two
values, 0 and 1. Therefore, the CN must decide whether the input it sees belongs to the
class of ""0"" codes, those codes for which it remains off, or the class of ""I"" codes, those codes
for which it becomes active. The inputs it sees in its receptive field constitute a subset of
the input vectors (the D( ... ) function) to the network. It is also assumed that the CN is an
ideal I-NN (Nearest Neighbor) classifier or feature detector. That is, given a particular set
of learned vectors, the CN will classify an arbitrary input according to the class of the
nearest (using d. as a measure of distance) learned vector. This situation is equivalent to
the case where a single CN has a single codon whose receptive field size is equivalent to that
of the CN.
Imagine a sender who wishes to send one bit of information over a noisy channel. The
sender has a probabilistic encoder that choses a code word (learned vector) according to
some probability distribution. The receiver knows this code set, though it has no knowledge
of which bit is being sent. Noise is added to the code word during its transmission over the

341
channel, which is analogous to applying an input vector to a network's inputs, where the
vector lies within some learned vector's region. The ""noise"" is represented by the distance
( d,,) between the input vector and the associated learned vector.
The code word sent over the channel consists of those bits that are seen in the receptive field of the ON being modeled. In the associative mapping of input vectors to output
vectors, each ON must respond with the appropriate output (0 or 1) for the associated
learned output vector. Therefore, a ON is a decoder that estimates in which class the
received code word belongs. This is a classic block encoding problem, where increasing the
field size is equivalent to increasing code length. As the receptive field size increases, the
performance of the decoder improves in the presence of noise. Using communication theory
then, the trade-off between interconnection costs as they relate to field size and the functionality of a node as it relates to the correctness of its decision making process (output
errors) can be characterized.
As the receptive field size of a node increases, so does the redundancy of the input,
though this is dependent on the particular codes being used for the learned vectors, since
there are situations where increasing the field size provides no additional information.
There is a point of diminishing returns, where each additional bit provides ever less reduction in output error. Another factor is that interconnection costs increase exponentially
with field size. The result of these two trends is a cost performance measure that has a single global maximum value. In other words, given a set of learned vectors and their probabilities, and a set of interconnection costs, a ""best"" receptive field size can be determined,
beyond which, increasing connectivity brings diminishing returns.

SINGLE CODON, WITH NO CODE COMPRESSION
A single neural element with a single codon and with no code compression can be
modelled exactly as a communication channel (see Figure 2). Each network node is assumed
to have a single codon whose receptive field size is equal to that of the receptive field size of
the node.

sender

I I
encoder

~

nOIsy

I

I

Ch.nne11~1 : ~

transmitter

receiver

I

decoder
ON

Figure 2 - A Transmission Channel

recelver

342

The operation of the channel is as follows. A bit is input into the channel encoder,
which selects a random code of length N and transmits that code over the channel. The
receiver then, using nearest neighbor classification, decides if the original message was either
a 0 or a 1.
Let M be the number of code words used by the encoder. The rate* then indicates the
density of the code space.

Definition 7: The rate, R, of a communication channel is

R = 10gM

-

(6)

N

o
The block length, N, corresponds directly to the receptive field size of the codon, i.e.,

N=/e. The derivations in later sections use a related measure:
Definition 8: The code utilization, b, is the number of learned vectors assigned to a particular code or
(7)
b can be written in terms of R
b

=

2N (R-l)

(8)

As b approaches 1, code compression increases. b is essentially unbounded, since M may be
significantly larger than 2N. 0
The decode error (information loss) due to code compression is a random variable that
depends on the compression rate and the a priori probabilities, therefore, it will be different
with different learned vector sets and codons within a set. As the average code utilization
for all codons approaches 1, code compression occurs more often and codon decode error is
unavoidable.
Let Zi be the vector output of the encoder, and the input to the channel, where each
element of Zi is either a 1 or o. Let Vi be the vector output of the channel, and the input to
the decoder, where each element is either a 1 or a o. The Noisy Channel Coding Theorem is
now presented for a general case, where the individual M input codes are to be distinguished. The result is then extended to a CN, where, even though M input codes are
used, the ON need only distinguish those codes where it must output a 1 from those where it
must output a o. The theorem is from Gallager (5.6.1)5. Random codes are assumed
throughout.

Theorem 1: Let a discrete memoryless channel have transition probabilities PNU/k)
and, for any positive integer N and positive number R, consider the ensemble of (N,R)
block codes in which each letter of each code word is independently selected according to

fe

l

the probability assignment Q(k). Then, for each message m, l<m< NR
and all p,
O<p<l, the ensemble average probability of decoding error using maximum-likelyhood
decoding satisfies

(9)
where
?In the definitions given here and the theorems below, the notation of Gall ager 6 is used. Many of the
definitions and theorems are also from Gallager.

343

Eo(p,Q)=-ln~ [ ~1 Q(k)PU/kp!p ]
i-il

l+P

(10)

k-il

o

These results are now adjusted ror our special case.

Theorem 2: For a single CN, the average channel error rate ror random code vectors is
Pc.,.~2q(l-q )Pe ? m

where q=Q(k)

\I k

(11)

is the probability or an input vector bit being a 1. 0

These results cover a wide range or models. A more easily computable expression can
be derived by recognizing some or the restrictions inherent in the CN model. First, assume
that all channel code bits are equally likely, that is, \I k, Q( k )=q, that the error model is
the Binary Symmetric Channel (BSC), and that the errors are identically distributed and
independent - that is, each bit has the same probability, f, or being in error, independent
or the code word and the bit position in the code word.
A simplified version or the above theorem can be derived. Maximizing P gives the
tightest bounds:

Pc.,.

< 0.5 O$p~l
maxPe(p)

(12)

where (letting codon input be the block length, N = I c)

P,(p)

:'> eXP{-f,IE,(P)-PR1}

(13)

The minimum value or this expression is obtained when p=1 (for q=0.5):

Eo; -log 2 [

(o.sV,+O.SVl-,)'

1

(14)

SINGLE-CODON WITH CODE COMPRESSION
Unfortunately, the implementation complexity of a codon grows exponentially with the
size or the codon, which limits its practical size. An alternative is to approximate single
codon function of a single CN with many smaller, overlapped codons. The goal is to maintain performance and reduce implementation costs, thus improving the cost/performance of
the decoding process. As codons get smaller, the receptive field size becomes smaller relative
to the number of CNs in the network. When this happens there is codon compression, or
vector alia6ing, that introduces its own errors into the decoding process due to information
loss. Networks can overcome this error by using multiple redundant codons (with overlapping receptive fields) that tend to correct the compression error.
Compression occurs when two code words requiring different decoder output share the
same representation (within the receptive field or the codon) . The following theorem gives
the probability of incorrect codon output with and without compression error.

Theorem 9: For a BSC model where q=0.5, the codon receptive field is Ic, the code utilization is b, and the channel bits are selected randomly and independently, the probability
of a codon decoding error when b > 1 is approximately

Pc.,.

< (l-f)""Pc- [1-(I-f)""

]0.5

where the expected compression error per codon is approximated by

(15)

344

Pc = 0.5

(16)

and from equations 13-14, when 6<1

P,,,, < exp { -

j, [-log [

[(O .?V.+O .?Vl-' J'

I-RI}

(17)

Proof is given in Hammerstrom6 . 0

As 6 grows, Pc approaches 0.5 asymptotically. Thus, the performance of a single codon
degrades rapidly in the presence of even small amounts of compression.

MULTIPLE CODONS WITH CODE COMPRESSION
The use or mUltiple small codons is more efficient than a few large codons, but there
are some fundamental performance constraints. When a codon is split into two or more
smaller codons (and the original receptive field is subdivided accordingly), there are several
effects to be considered. First, the error rate of each new codon increases due to a decrease
in receptive field size (the codon's block code length). The second effect is that the code
utilization, II, will increase for each codon, since the same number of learned vectors is
mapped into a smaller receptive field. This change also increases the error rate per codon
due to code compression. In fact, as the individual codon receptive fields get smaller,
significant code compression occurs. For higher-order input codes, there is an added error
that occurs when the order of the individual codons is decreased (since random codes are
being assumed, this effect is not considered here). The third effect is the mass action of
large numbers of codons. Even though individual codons may be in error, if the majority
are correct, then the ON will have correct output. This effect decreases the total error rate.
Assume that each ON has more than one codon, c>1. The union of the receptive fields
for these codons is the receptive field for the ON with no no restrictions on the degree of
overlap of the various codon receptive fields within or between ONs. For a ON with a large
number of codons, the codon overlap will generally be random and uniformly distributed.
Also assume that the transmission errors seen by different receptive fields are independent.
Now consider what happens to a codon's compression error rate (ignoring transmission
error for the time being) when a codon is replaced by two or more smaller co dons covering
the same receptive field. This replacement process can continue until there are only 1..
codons, which, incidentally, is analogous to most current neural models. For a multiple
codon ON, assume that each codon votes a 1 or o. The summation unit then totals this
information and outputs a 1 if the majority of codons vote for a 1, etc.

Theorem 4: The probability of a ON error due to compression error is
1

Pc = ""'\7?';

00

J

21r c!2-cp.-l!2
V cP.(i-p.)

where

Pc

J.2
e 2 dy

(18)

is given in equation 16 and q=0.5.

Pc incorporates the two effects of moving to mUltiple smaller codons and adding more
codons. Using equation 17 gives the total error probability (per bit), PeN:

(19)
Proof is in Hammerstrom6 . 0

345

For networks that perform association as defined in this paper, the connection weights
rapidly approach a single uniform value as the size of the network grows. In information
theoretic terms, the information content of those weights approaches zero as the compression increases. Why then do simple non-conjunctive networks (1-codon equivalent) work at
alI? In the next section I define connectivity cost constraints and show that the answer to
the first question is that the general associative structures defined here do not scale costeffectively and more importantly that there are limits to the degree of distribution of information.

CONNECTIVITY COSTS
It is much easier to assess costs if some implementation medium is assumed. I have
chosen standard silicon, which is a two dimensional surface where ON's and codons take up
surface area according to their receptive field sizes. In addition, there is area devoted to
the metal lines that interconnect the ONs. A specific VLSI technology need not be assumed,
since the comparisons are relative, thus keeping ONs, codons, and metal in the proper proportions, according to a standard metal width, m. (which also includes the inter-metal
pitch). For the analyses performed here, it is assumed that
levels of metal are possible.

m,

In the previous section I established the relationship of network performance , in terms
of the transmission error rate, E, and the network capacity, M. In this section I present an
implementation cost, which is total silicon area, A. This figure can then be used to derive a
cost/performance figure that can be used to compare such factors as codon size and receptive field size. There are two components to the total area: A ON , the area of a ON, and
AMI, the area of the metal interconnect between ONs. AON consists of the silicon area
requirements of the codons for all ONs. The metal area for local, intra-ON interconnect is
considered to be much smaller than that of the codons themselves and of that of the more
global, inter-ON interconnect, and is not considered here. The area per ON is roughly
m.

AON = cfeme(-)

2

(20)

m,

where me is the maximum number of vectors that each codon must distinguish, for 6>1,
me = 2"".

Theorem 5: Assume a rectangular, un6ounded* grid of ONs (all ONs are equi-distant
from their four nearest neighbors), where each ON has a bounded receptive field of its nON
nearest ONs, where ""ON is the receptive field size for the ON, nON =

C~e

,

where c is the

number of codons, and R is the intra-ON redundancy, that is, the ratio of inputs to
synapses (e.g., when R=l each ON input is used once at the ON, when R=2 each input is
used on the average at two sites). The metal area required to support each ON's receptive
field is (proof is giving by Hammerstrom6 ):

AMI = [

----w-+
""ON3

3""ON

2

~

+9""ON

21 [ m.j2
m,

(21)

The total area per ON, A, then is
?Another implementation IItrategy ill to place &II eNII along a diagonal, which givell n 2 area. However, thill
technique only works ror a bounded number or eNII and when dendritic computation can be lipread over a large
area, which limits the range or p08llible eN implementationll. The theorem IItated here covers an infinite plane or
eNII each with a bounded receptive Held.

346

(22)
o

Even with the assumption of maximum locality, the total metal interconnect area
increases as the cube of the per CN receptive field size!

SINGLE CN SIMULATION
What do the bounds tell us about CN connectivity requirements? From simulations,
increasing the CN's receptive field size improves the performance (increases capacity), but
there is also an increasing cost, which increases faster than the performance! Another
observation is that redundancy is quite effective as a means for increasing the effectiveness
of a CN with constrained connectivity. (There are some limits to R, since it can reach a
point where the intra-CN connectivity approaches that of inter-CN for some situations.)
With a fixed nON, increasing cost-effectiveness (A 1m) is possible by increasing both order
and redundancy.
In order to verify the derived bounds, I also wrote a discrete event simulation of a CN,
where a random set of learned vectors were chosen and the CN's codons were programmed
according to the model presented earlier. Learned vectors were chosen randomly and subjected to random noise, L The CN then attempted to categorize these inputs into two
major groups (CN output = 1 and CN output = 0). For the most part the analytic bounds
agreed with the simulation, though they tended to be optimistic in slightly underestimating
the error. These differences can be easily explained by the simplifying assumptions that
were made to make the analytic bounds mathematically tractable.

DISTRmUTED VS. LOCALIZED
Throughout this paper, it has been tacitly assumed that representations are distributed
across a number of CNs, and that any single CN participates in a number of representations. In a local representation each CN represents a single concept or feature . It is the distribution of representation that makes the CN's decode job difficult, since it is the cause of
the code compression problem.
There has been much debate in the connectionist/neuromodelling community as to the
advantages and disadvantages of each approach; the interested reader is referred to Hinton7 , Baum et al. 8, and BallardQ ? Some of the results derived here are relevant to this
debate. A1s the distribution of representation increases, the compression per CN increases
accordingly. It was shown above that the mean error in a codon's response quickly
approaches 0.5, independent of the input noise . This result also holds at the CN level. For
each individual CN, this error can be offset by adding more codons, but this is expensive
and tends to obviate one of the arguments in favor of distributed representations, that is,
the multi-use advantage, where fewer CNs are needed because of more complex, redundant
encodings. A1s the degree of distribution increases, the required connectivity and the code
compression increases, so the added information that each codon adds to its CN's decoding
process goes to zero (equivalent to all weights approaching a uniform value) .

SUMMARY AND CONCLUSIONS
In this paper a single CN (node) performance model was developed that was based on
Communication Theory. Likewise, an implementation cost model was derived .
The communication model introduced the codon as a higher-order decoding element
and showed that for small codons (much less than total CN fan-in, or convergence) code
compression, or vector aliasing, within the codon's receptive field is a severe problem for

347

large networks. As code compression increases, the information added by any individual
codon to the CN's decoding task rapidly approaches zero .
The cost model showed that for 2-dimensional silicon, the area required for inter-node
metal connectivity grows as the cube of a CN's fan-in.
The combination of these two trends indicates that past a certain point, which is
highly dependent on the probability structure of the learned vector space, increasing the
fan-in of a CN (as is done, for example, when the distribution of representation is increased)
yields diminishing returns in terms of total cost-performance. Though the rate of diminishing returns can be decreased by the use of redundant, higher-order connections.
The next step is to apply these techniques to ensembles of nodes (CNs) operating in a
competitive learning or feature extraction environment.

REFERENCES
[I]

J. Bailey, ""A VLSI Interconnect Structure for Neural Networks,"" Ph.D.
Dissertation, Department of Computer SciencejEngineering, OGC. In Preparation.

[2]

V. B. Mountcastle, ""An Organizing Principle for Cerebral Function: The Unit
Module and the Distributed System,"" in The Mindful Brain, MIT Press, Cambridge,
MA,1977.

[3]

T. Maxwell, C . L. Giles, Y . C. Lee and H. H. Chen, ""Transformation Invariance
Using High Order Correlations in Neural Net Architectures,"" Proceeding8
International Con! on SY8tem8, Man, and Cybernetic8, 1986.

[4]

D. Marr, ""A Theory for Cerebral Neocortex,"" Proc. Roy. Soc . London, vol.
176(1970), pp . 161-234.

[5]

R. G. Gallager, Information Theory and Reliable Communication, John Wiley and
Sons, New York, 1968.

[6]

D. Hammerstrom, ""A Connectivity Analysis of Recursive, Auto-Associative
Connection Networks,"" Tech. Report CS/E-86-009, Dept. of Computer
SciencejEngineering, Oregon Graduate Center, Beaverton, Oregon, August 1986.

[7]

G. E . Hinton, ""Distributed Representations,"" Technical Report CMU-CS-84-157,
Computer Science Dept., Carnegie-Mellon University, Pittsburgh, PA 15213, 1984.

[8]

E. B. Baum, J. Moody and F . Wilczek, ""Internal Representations for Associative
Memory,"" Technical Report NSF-ITP-86-138, Institute for Theoretical Physics,
Santa Barbara, CA, 1986.

[9]

D. H . Ballard, ""Cortical Connections and Parallel Processing: Structure and
Function,"" Technical Report 133, Computer Science Department, Rochester, NY,
January 1985.

"
54,1987,"A Method for the Design of Stable Lateral Inhibition Networks that is Robust in the Presence of Circuit Parasitics","",54-a-method-for-the-design-of-stable-lateral-inhibition-networks-that-is-robust-in-the-presence-of-circuit-parasitics.pdf,"Abstract Missing","860

A METHOD FOR THE DESIGN OF STABLE LATERAL INHIBITION
NETWORKS THAT IS ROBUST IN THE PRESENCE
OF CIRCUIT PARASITICS
J.L. WYATT, Jr and D.L. STANDLEY
Department of Electrical Engineering and Computer Science
Massachusetts Institute of Technology
Cambridge, Massachusetts 02139
ABSTRACT
In the analog VLSI implementation of neural systems, it is
sometimes convenient to build lateral inhibition networks by using
a locally connected on-chip resistive grid. A serious problem
of unwanted spontaneous oscillation often arises with these
circuits and renders them unusable in practice. This paper reports
a design approach that guarantees such a system will be stable,
even though the values of designed elements and parasitic elements
in the resistive grid may be unknown. The method is based on a
rigorous, somewhat novel mathematical analysis using Tellegen's
theorem and the idea of Popov multipliers from control theory. It
is thoroughly practical because the criteria are local in the sense
that no overall analysis of the interconnected system is required,
empirical in the sense that they involve only measurable frequency
response data on the individual cells, and robust in the sense that
unmodelled parasitic resistances and capacitances in the interconnection network cannot affect the analysis.
I.

INTRODUCTION

The term ""lateral inhibition"" first arose in neurophysiology to
describe a common form of neural circuitry in which the output of
each neuron in some population is used to inhibit the response of
each of its neighbors. Perhaps the best understood example is the
horizontal cell layer in the vertebrate retina, in which lateral
inhibition simultaneously enhances intensity edges and acts as an
automatic lain control to extend the dynamic range of the retina
as a whole. The principle has been used in the design of artificial
neural system algorithms by Kohonen 2 and others and in the electronic
design of neural chips by Carver Mead et. al. 3 ,4.
In the VLSI implementation of neural systems, it is convenient
to build lateral inhibition networks by using a locally connected
on-chip resistive grid. Linear resistors fabricated in, e.g.,
polysilicon, yield a very compact realization, and nonlinear
resistive grids, made from MOS transistors, have been found useful
for image segmentation. 4 ,5 Networks of this type can be divided into
two classes: feedback systems and feedforward-only systems. In the
feedforward case one set of amplifiers imposes signal voltages or
? American Institute of Physics 1988

861

currents on the grid and another set reads out the resulting response
for subsequent processing, while the same amplifiers both ""write"" to
the grid and ""read"" from it in a feedback arrangement. Feedforward
networks of this type are inherently stable, but feedback networks
need not be.
A practical example is one of Carver Meadls retina chips3 that
achieves edge enhancement by means of lateral inhibition through a
resistive grid. Figure 1 shows a single cell in a continuous-time
version of this chip. Note that the capacitor voltage is affected
both by the local light intensity incident on that cell and by the
capacitor voltages on neighboring cells of identical design. Any
cell drives its neighbors, which drive both their distant neighbors
and the original cell in turn. Thus the necessary ingredients for
instability--active elements and signal feedback--are both present
in this system, and in fact the continuous-time version oscillates
so badly that the original design is scarcely usable in practice
with the lateral inhibition paths enabled. 6 Such oscillations can

I

incident
light

v

out

Figure 1. This photoreceptor and signal processor Circuit, using two
MOS transconductance amplifiers, realizes lateral inhibition by
communicating with similar units through a resistive grid.
readily occur in any resistive grid circuit with active elements and
feedback,even when each individual cell is quite stable. Analysis
of the conditions of instability by straightforward methods appears
hopeless, since any repeated array contains many cells, each of
which influences many others directly or indirectly and is influenced
by them in turn, so that the number of simultaneously active feedback loops is enormous.
This paper reports a practical design approach that rigorously
guarantees such a system will be stable. The very simplest version
of the idea is intuitively obvious: design each individual cell so
that, although internally active, it acts like a passive system as
seen from the resistive grid. In circuit theory language, the
design goal here is that each cellis output impedance should be a
positive-real? function. This is sometimes not too difficult in
practice; we will show that the original network in Fig. 1 satisfies
this condition in the absence of certain parasitic elements. More
important, perhaps, it is a condition one can verify experimentally

862

by frequency-response measurements.
It is physically apparent that a collection of cells that
appear passive at their terminals will form a stable system when
interconnected through a passive medium such as a resistive grid.
The research contributions, reported here in summary form, are
i) a demonstration that this passivity or positive-real condition
is much stronger than we actually need and that weaker conditions,
more easily achieved in practice, suffice to guarantee stability of
the linear network model, and ii) an extension of i) to the nonlinear
domain that furthermore rules out large-signal oscillations under
certain conditions.
II.

FIRST-ORDER LINEAR ANALYSIS OF A SINGLE CELL

We begin with a linear analysis of an elementary model for the
circuit in Fig. 1. For an initial approximation to the output
admittance of the cell we simplify the topology (without loss of
relevant information) and use a naive'model for the transconductance
amplifiers, as shown in Fig. 2.

e

+

Figure 2. Simplified network topology and transconductance amplifier
model for the circuit in Fig. 1. The capacitor in Fig. 1 has been
absorbed into CO2 ?
Straightforward calculations show that the output admittance is
given by
yes)

(1)

This is a positive-real, i.e., passive, admittance since it can always
be realized by a network of the form shown in Fig. 3, where

= (gm2+

-1 -1

-1

Ro2 ) , R2= (gmlgm2Rol)
, and L = COI/gmlgm2?
Although the original circuit contains no inductors, the
realization has both capacitors and inductors and thus is capable
of damped oscillations. Nonetheless, i f the transamp model in
Fig. 2 were perfectly accurate, no network created by interconnecting
such cells through a resistive grid (with parasitic capacitances)
could exhibit sustained oscillations. For element values that may
be typical in practice, the model in Fig. 3 has a lightly damped
resonance around I KHz with a Q ~ 10. This disturbingly high Q
suggests that the cell will be highly sensitive to parasitic elements
not captured by the simple models in Fig. 2. Our preliminary
Rl

863

yes)

Figure 3. Passive network realization of the output admittance (eq.
(1) of the circuit in Fig. 2.
analysis of a much more complex model extracted from a physical
circuit layout created in Carver Mead's laboratory indicates that
the output impedance will not be passive for all values of the transamp bias currents. But a definite explanation of the instability
awaits a more careful circuit modelling effort and perhaps the design
of an on-chip impedance measuring instrument.
III.

POSITIVE-REAL FUNCTIONS, e-POSITlVE FUNCTIONS, AND
STABILITY OF LINEAR NETWORK MODELS

In the following discussion s = cr+jw is a complex variable,
H(s) is a rational function (ratio of polynomials) in s with real
coefficients, and we assume for simplicity that H(s) has no pure
imaginary poles. The term closed right halE plane refers to the set
of complex numbers s with Re{s} > o.
Def. I
The function H(s) is said to be positive-real if a) it has no
poles in the right half plane and b) Re{H(jw)} ~ 0 for all w.
If we know at the outset that H(s) has no right half plane poles,
then Def. I reduces to a simple graphical criterion: H1s} is positivereal if and only if the Nyquist diagram of H(s) (i.e. the plot of
H(jW) for w ~ 0, as in Fig. 4) lies entirely in the closed right half
plane.
Note that positive-real functions are necessarily stable since
they have no right half plane poles, but stable functions are not
necessarily positive-real, as Example 1 will show.
A deep link between positive real functions, physical networks
and passivity is established by the classical result 7 in linear
circuit theory which states that H(s) is positive-real if and only if
it is possible to synthesize a 2-terminal network of positive linear
resistors, capacitors, inductors and ideal transformers that has H(s)
as its driving-point impedance or admittance.

864

Oef. 2
The function H(s) is said to be a-positive for a particular value
of e(e ~ 0, e ~ ~), if a) H{s) has no poles in the right half plane,
and b) the Nyquist plot of H(s) lies strictly to the right of the
straight line passing through the origin at an angle a to the real
positive axis.
Note that every a-positive function is stable and any function
that is e-positive with e = ~/2 is necessarily positive-real.
I {G(jw)}
m
Re{G(jw) }

Figure 4. Nyquist diagram for a fUnction that is a-positive but
not positive-real.
Example 1
The function
G (s)

=

(s+l) (s+40)
(s+5) (s+6) (s+7)

(2)

is a-positive (for any e between about 18? and 68?) and stable, but it
is not positive-real since its Nyquist diagram, shown in Fig. 4,
crosses into the left half plane.
The importance of e-positive functions lies in the following
observations: 1) an interconnection of passive linear resistors and
capacitors and cells with stable linear impedances can result in an
unstable network, b) such an instability cannot result if the
impedances are also positive-real, c) a-positive impedances form a
larger class than positive-real ones and hence a-positivity is a less
demanding synthesis goal, and d) Theorem 1 below shows that such an
instability cannot result if the impedances are a-positive, even if
they are not positive-real.
Theorem 1
Consider a linear network of arbitrary topology, consisting of
any number of passive 2-terminal resistors and capacitors of arbitrary
value driven by any number of active cells. If the output impedances

865
'II"" ,
of all the active cells are a-positive for some common a, 0<a 22
then the network is stable.
The proof of Theorem 1 relies on Lemma 1 below.
Lemma 1
If H(s) is a-positive for some fixed a, then for all So in the
closed first quadrant of the complex plane, H(so) lies strictly to
the right of the straight line passing through the origin at an angle
a to the real positive axis, i.e., Re{so} ~ 0 and Im{so} ~ 0 ~
a-'II"" < L H (so) < a.
Proof of Lemma 1 (Outline)
Let d be the function that assigns to each s in the closed right
half plane the perpendicular distance des) from H(s) to the line
defined in Def. 2. Note that des) is harmonic in the closed right
half plane, since H is analytic there. It then follows, by application
of the maximum modulus principle8 for harmonic functions, that d takes
its minimum value on the boundary of its domain, which is the
imaginary axis. This establishes Lemma 1.
Proof of Theorem 1 (OUtline)
The network is unstable or marginally stable if and only if it
has a natural frequency in the closed right half plane, and So is a
natural frequency if and only if the network equations have a nonzero
solution at so. Let {Ik} denote the complex branch currents Of such
a solution. By Tellegen I s theorern9 the sum of the complex powers
absorbed by the circuit elements must vanish at such a solution, i.e.,

~

IIk12/s0Ck +

capac~tances

L

cell
terminal pairs

(3)
where the second term is deleted in the special case so=O, since the
complex power into capacitors vanishes at so=O.
If the network has a natural frequency in the closed right half
plane, it must have one in the closed first quadrant since natural
frequencies are either real or else occur in complex conjugate pairs.
But (3) cannot be satisfied for any So in the closed first quadrant,
as we can see by dividing both sides of (3) by
IIkI2, where the

k

sum is taken over all network branches. After this division, (3)
asserts that zero is a convex combination of terms of the form Rk,
terms of the form (CkSo)-I, and terms of the form Zk(So).
Visualize where these terms lie in the complex plane: the first set lies
on the real positive axis, the second set lies in the closed 4-th
~adrant since So lies in the closed 1st quadrant by assumption, and
the third set lies to the right of a line passing through the origin
at an angle a by Lemma 1. Thus all these terms lie strictly to the
right of this line, which implies that no convex combination of them
can equal zero. Hence the network is stable!

866

IV.

STABILITY RESULT FOR NETWORKS WITH NONLINEAR
RESISTORS AND CAPACITORS

The previous result for linear networks can afford some limited
insight into the behavior of nonlinear networks. First the nonlinear
equations are linearized about an equilibrium point and Theorem 1 is
applied to the linear model. If the linearized model is stable, then
the equilibrium point of the original nonlinear network is locally
stable, i.e., the network will return to that equilibrium point if
the initial condition is sufficiently near it. But the result in this
section, in contrast, applies to the full nonlinear circuit model and
allows one to conclude that in certain circumstances the network
cannot oscillate even if the initial state is arbitrarily far from
the equilibrium point.
Def. 3
A function H(s) as described in Section III is said tc satisfy
the Popov criterion lO if there exists a real number r>O such that
Re{(l+jwr) H(jw)} ~ 0 for all w.
Note that positive real functions satisfy the Popov criterion
with r=O. And the reader can easily verify that G(s) in Exam~le I
satisfies the Popov criterion for a range of values of r. The important
effect of the term (l+jwr) in Def. 3 is to rotate the Nyquist plot
counterclockwise by progressively greater amounts up to 90? as w
increases.
Theorem 2
Consider a network consisting of nonlinear 2-terminal resistors
and capacitors, and cells with linear output impedances ~(s). Suppose
i) the resistor curves are characterized by continuously
diffefentiable functions i k = gk(vk ) where gk(O) = 0 and
o < gk(vk ) < G < 00 for all values of k and vk'
ii) the capacitors are characterized by i k = Ck(Vk)~k with
< CI < Ck(v k ) < C2 < 00 for all values of k and vk'

o

iii) the impedances Zk(s) have no poles in the closed right
half plane and all satisfy the Popov criterion for some common
value of r.
If these conditions are satisfied, then the network is stable in the
sense that, for any initial condition,

f oo(
o

I

all branches

i~(t) )

dt

<

00

?

The proof, based on Tellegen's theorem, is rather involved.
will be omitted here and will appear elsewhere.

(4)

It

867

ACKNOWLEDGEMENT
We sincerely thank Professor Carver Mead of Cal Tech for
enthusiastically supporting this work and for making it possible for
us to present an early report on it in this conference proceedings.
This work was supportedJ::? Defense Advanced Research Projects Agency
(DoD), through the Office of Naval Research under ARPA Order No.
3872, Contract No. N00014-80-C-0622 and Defense Advanced Research
Projects Agency (DARPA) Contract No. N00014-87-R-0825.
REFERENCES
1.
2.
3.

4.
5.
6.
7.
8.
9.
10.

F.S. Werblin, ""The Control of Sensitivity on the Retina,""
Scientific American, Vol. 228, no. 1, Jan. 1983, pp. 70-79.
T. Kohonen, Self-Organization and Associative Memory, (vol. 8 in
the Springer Series in Information Sciences), Springer Verlag,
New York, 1984.
M.A. Sivilotti, M.A. Mahowald, and C.A. Mead, ""Real Time Visual
Computations Using Analog CMOS processing Arrays,"" Advanced
Research in VLSI - Proceedings of the 1987 Stanford Conference,
P. Losleben, ed., MIT Press, 1987, pp. 295-312.
C.A. Mead, Analog VLSI and Neural Systems, Addison-Wesley, to
appear in 1988.
J. Hutchinson, C. Koch, J. Luo and C. Mead, ""Computing Motion
Using Analog and Binary Resistive Networks,"" submitted to IEEE
Transactions on Computers, August 1987.
M. Mahowald, personal communication.
B.D.O. Anderson and S. Vongpanitlerd, Network Analysis and
synthesis - A Modern Systems Theory Approach, Prentice-Hall,
Englewood Cliffs, NJ., 1973.
L.V. Ahlfors, Complex Analysis, McGraw-Hill, New York, 1966,
p. 164.
P. penfield, Jr., R. Spence, and S. Duinker, Tellegen's Theorem
and Electrical Networks, MIT Press, Cambridge, MA,1970.
M. Vidyasagar, Nonlinear Systems Analysis, Prentice-Hall,
Englewood Cliffs, NJ, 1970, pp. 211-217.

"
55,1987,"Mathematical Analysis of Learning Behavior of Neuronal Models","",55-mathematical-analysis-of-learning-behavior-of-neuronal-models.pdf,"Abstract Missing","164

MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS

By
JOHN Y. CHEUNG
MASSOUD OMIDVAR
SCHOOL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCE
UNIVERSITY OF OKLAHOMA
NORMAN, OK 73019

Presented to the IEEE Conference on ""Neural Information Processing SystemsNatural and Synthetic,"" Denver, November ~12, 1987, and to be published in
the Collection of Papers from the IEEE Conference on NIPS.

Please address all further correspondence to:
John Y. Cheung
School of EECS
202 W. Boyd, CEC 219
Norman, OK 73019
(405)325-4721

November, 1987
? American Institute of Physics 1988

165

MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
John Y. Cheung and Massoud Omidvar
School of Electrical Engineering
and Computer Science
ABSTRACT

In this paper, we wish to analyze the convergence behavior of a number
of neuronal plasticity models. Recent neurophysiological research suggests that
the neuronal behavior is adaptive. In particular, memory stored within a neuron
is associated with the synaptic weights which are varied or adjusted to achieve
learning. A number of adaptive neuronal models have been proposed in the
literature. Three specific models will be analyzed in this paper, specifically the
Hebb model, the Sutton-Barto model, and the most recent trace model. In this
paper we will examine the conditions for convergence, the position of convergence and the rate at convergence, of these models as they applied to classical
conditioning. Simulation results are also presented to verify the analysis.
INTRODUCTION
A number of static models to describe the behavior of a neuron have been
in use in the past decades. More recently, research in neurophysiology suggests
that a static view may be insufficient. Rather, the parameters within a neuron
tend to vary with past history to achieve learning. It was suggested that by
altering the internal parameters, neurons may adapt themselves to repetitive
input stimuli and become conditioned. Learning thus occurs when the neurons
are conditioned. To describe this behavior of neuronal plasticity, a number
of models have been proposed. The earliest one may have been postulated
by Hebb and more recently by Sutton and Barto 1. We will also introduce a
new model, the most recent trace (or MRT) model in this paper. The primary
objective of this paper, however, is to analyze the convergence behavior of these
models during adaptation.
The general neuronal model used in this paper is shown in Figure 1. There
are a number of neuronal inputs x,(t), i = 1, ... , N. Each input is scaled by
the corresponding synaptic weights w,(t), i = 1, ... , N. The weighted inputs
are arithmetically summed.
N

y(t) =

L x,(t)w,(t) - 9(t)
,=1

where 9(t) is taken to be zero.

(1)

166

Neuronal inputs are assumed to take on numerical values ranging from zero
to one inclusively. Synaptic weights are allowed to take on any reasonable values
for the purpose of this paper though in reality, the weights may very well be
bounded. Since the relative magnitude of the weights and the neuronal inputs
are not well defined at this point, we will not put a bound on the magnitude
of the weights also. The neuronal output is normally the result of a sigmoidal
transformation. For simplicity, we will approximate this operation by a linear
transformation.

Sigmodial
Transfonution
neuronal
output
H+-+y

rilure 1.

A leneral aeuronal .adel.

For convergence analysis, we will assume that there are only two neuronal
inputs in the traditional classical conditioning environment for simplicity. Of
course, the analysis techniques can be extended to any number of inputs. In
classical conditioning, the two inputs are the conditioned stimulus Xc (t) and
the unconditioned stimulus xu(t).
THE SUTTON-BARTO MODEL
More recently, Sutton and Barto 1 have proposed an adaptive model based
on both the signal trace x,(t) and the output trace y(t) as given below:

w,(t + 1) =w,(t) + cx,(t)(y(t)) - y(t)
y(t + 1) ={Jy(t) + (1 - {J)y(t)
Xi(t + 1) =axi(t) + Xi(t)
where both a and {J are positive constants.

(2a)
(2b)
(2c)

167

Condition of Convergence

In order to simplify the analysis, we will choose

Q

= 0 and (3 = 0, i.e.:

%,(t) = x,(t - 1)
and

y(t) = y(t - 1)
In other words, (2a) becomes:

Wi(t

+ 1) = Wi(t) + CXi(t)(y(t) - y(t -

I)}

(3)

The above assumption only serves to simplify the analysis and will not affect the
convergence conditions because the boundedness of %i(t) and y(t) only depends
on that for Xi(t) and y(t - 1) respectively.
As in the previous section, we recognize that (3) is a recurrence relation so
convergence can be checked by the ratio test. It is also possible to rewrite (3)
in matrix format. Due to the recursion of the neuronal output in the equation,
we will include the neuronal output y(t) in the parameter vector also:

(4)
or

To show convergence, we need to set the magnitude of the determinant of
A (S-B) to be less than unity.

(5)
Hence, the condition for convergence is:

(6)
From (6), we can see that the adaptation constant must be chosen to be less
than the reciprocal of the Euclidean sum of energies of all the inputs. The
same techniques can be extended to any number of inputs. This can be proved
merely by following the same procedures outlined above.
Position At Convergence

168

Having proved convergence of the Sutton-Barto model equations of neuronal plasticity, we want to find out next at what location the system remains
when converged. We have seen earlier that at convergence, the weights cease to
change and so does the neuronal output. We will denote this converged position
as (W(S-B?- W(S-B) (00). In other words:

=

(7)
Since any arbitrary parameter vector can always be decomposed into a weighted
sum of the eigenvectors, i.e.

(8)
The constants Ql, Q2, and Q3 can easily be found by inverting A(5-B). The
eigenvalues of A(5-B) can be shown to be 1, 1, and c(%j + %~}. When c is
within the region of convergence, the magnitude of the third eigenvalue is less
than unity. That means that at convergence, there will be no contribution from
the third eigenvector. Hence,

(9)
From (9), we can predict precisely what the converged position would be given
only with the initial conditions.
Rate of Convergence
We have seen that when c is carefully chosen, the Sutton-Barto model will
converge and we have also derived an expression for the converged position.
Next we want to find out how fast convergence can be attained. The rate
of convergence is a measure of how fast the initial parameter approaches the
optimal position. The asymptotic rate of convergence is 2 :

(10)
where SeA (5-B? is the spectral radius and is equalled to c(%~ + %~) in this
case. This completes the convergence analysis on the Sutton-Barto model of
neuronal plasticity.
THE MRT MODEL OF NEURONAL PLASTICITY
The most recent trace (MRT) model of neuronal plasticity 3 developed by
the authors can be considered as a cross between the Sutton-Barto model and
the Klopf's model "". The adaptation of the synaptic weights can he expressed
as follows:
(11)

169

A comparison of (11) and the Sutton-Barto model in (3) ahOWl that the .cond
term on the right hand aide contains an extra factor, Wi(t), which iI used to
apeed up the convergence as ahoWD later. The output trace hu been replaced
by If(t - 1), the most recent output, hence the name, the most recent trace
model. The input trace is also replaced by the most recent input.
Condition of Convergence
We can now proceed to analyze the condition of convergence for the MRT
model. Due to the presence of the Wi(t) factor in the second term in (31), the
ratio test cannot be applied here. To analyze the convergence behavior further,
let us rewrite (11) in matrix format:

0)o (
o

WI(t)
W2(t) )
y(t - 1)
(12)

or

The superscript T denotes the matrix transpose operation. The above equation
is quadratic in W(MRT)(t). Complete convergence analysis of this equation is
extremely difficult.
In order to understand the convergence behavior of (12), we note that
the dominant term that determines convergence mainly relates to the second
quadratic term. Hence for convergence analysis only, we will ignore the first
term:

(13)
We can readily see from above that the primary convergence factor is BT c.
Since C is only dependent on %,(t), convergence can be obtained if the duration
of the synaptic inputs being active is bounded. It can be shown that the
condition of convergence is bounded by:

(14)

170

We can readily see that the adaptation constant c can be chosen according
to (14) to ensure convergence for t < T.
SIMULATIONS
To verify the theoretical analysis of these three adaptive neuronal models
based on classical conditioning, these models have been simulated on the mM
3081 mainframe using the FORTRAN language in single precision. Several test
scenarios have been designed to compare the analytical predictions with actual
simulation results.
To verify the conditions for convergence, we will vary the value of the
adaptation constant c. The conditioned and unconditioned stimuli were set
to unity and the value of c varies between 0.1 to 1.0. For the Sutton-Barto
model the simulation given in Fig. 2 shows that convergence is obtained for
c < 0.5 as expected from theoretical analysis. For the MRT model, simulation
results given in Fig. 3 shows that convergence is obtained for c < 0.7, also as
expected from theoretical analysis. The theoretical location at convergence for
the Sutton and Barto model is also shown in Figure 2. It is readily seen that
the simulation results confirm the theoretical expectations.

I .?

,v. . .?. ???. ?. ?. ???.
,./r ????????????????????????
i

""'r.al
Output

I.'

,

'..,...._....-_--------1:

...

2:
3:

4:

s:
6:
1:

.

c
c
c
c
c
c
c

? 0.1
? 0.2
? 0.3
? 0.4
?0.5
? 0.6
? 0.7

?~----~--~M----~JI-----.~--~a~--~.

Figure 2. 'lou or MuroD&l _tpuu YeT.US Ule . . . .er of 1urat1011& for the
Suttoa-Barto ~el witb '1frerent .alues of ~aptat1on CODstant c.

171

...
1.1

lleuroul
Output

.,

. ........ . ... ..

""""1""""
.................................
..... ...
. ..... . ..

I.'

?

~

...

?.??

1:
2:

I

??

,

I

I

1

e - 0.1

e - 0.2
e - 0.3
4: e - 0.4
S: e - 0.5
6: e - 0.6
~1~?~,~-~o~,7~__~,
3:

... I~,____~____~,____~____
?

. "" .

a

?

Ju.ber of iteratiOGa
Figure 3. Plotl of oeuroaal outputl .craus the uuaber of iteratious
for the MaT ~el with different .alues of adantatlon
I:DDStaut c.

To illustrate the rate of convergence, we will plot the trajectory of the
deviation in synaptic weights from the optimal values in the logarithmic scale
since this error is logarithmic as found earlier. The slope of the line yields the
rate of convergence. The trajectory for the Sutton-Barto Model is given in
Figure 4 while that for the MRT model is given in Figure 5. It is clear from
Figure 4 that the trajectory in the logarithmic form is a straight line. The
slope Rn(A(S-B)) can readily be calculated. The curve for the MRT model
given in Figure 5 is also a straight line but with a much larger slope showing
faster convergence.
SUMMARY
In this paper, we have sought to discover analytically the convergence
behavior of three adaptive neuronal models. From the analysis, we see that
the Hebb model does not converge at all. With constant active inputs, the
output will grow exponentially. In spite of this lack of convergence the Hebb
model is still a workable model realizing that the divergent behavior would
be curtailed by the sigmoidal transformation to yield realistic outputs. The

172

,._)
'II

\'.~

....
I
t

""uroul

Output
Dniatiotl
Lto

1
I

2:
3:
4:

\\\~ "" '---'\
\

\

\

\\

I

..

e -.0.1
C - 0.2
e ? 0.3
e - 0.4

1:

\

\

'\
\

\

\
II

',,--

""

.

?

..

""

?

.u.ber of iterationa
Figure 4.

Trajectories of Deuronal output deviationa froa atatic .alues
for the Sutton-""rt~ ~el with ~lfferent value. ~f adaptation
cOIIstallt C.

I.-

80 ..

lleuroD&l.
Output
Deviation

1:
2:
3:
4:

~

\.\
(\

\
\

""'

0.1
0.2
c ? 0.3
C . 0.4
C?

C?

\\ \

.'

\\ \

,\

\\
... """"
Ltl

!

~

'I

\

\

\

\:

,

,

~

\ \ \
\ '\ \

.""~

'. i
\ ~
\

i

,

..) \ \

,
""

n

..

..,

'""

Nuaber of iterations
Figure 5.

Trajectories of neuronal output deviations fra. atatic
values for tbe KRT ~el witb different values of
adaptation constant c.

173

analysis on the Sutton and Barto model shows that this model will converge
when the adaptation constant c is carefully chosen. The bounds for c is also
found for this model. Due to the structure of this model, both the location at
convergence and the rate of convergence are also found. We have also introduced
a new model of neuronal plasticity called the most recent trace (MRT) model.
Certain similarities exist between the MRT model and the Sutton-Barto model
and also between the MRT model and the Klopf model. Analysis shows that the
update equations for the synaptic weights are quadratic resulting in polynomial
rate of convergence. Simulation results also show that much faster convergence
rate can be obtained with the MRT model.
REFERENCES
1. Sutton, R.S. and A.G. Barto, Psychological Review, vol. 88, p. 135, (1981).
2. Hageman, L. A. and D.M. Young. Applied Interactive Methods. (Academic Press, Inc. 1981).
3. Omidvar, Massoud. Analysis of Neuronal Plasticity. Doctoral dissertation, School of Electrical Engineering and Computer Science, University of
Oklahoma, 1987.
4. Klopf, A.H. Proceedings of the American Institute of Physics Conference
#151 on Neural Networks for Computing, p. 265-270, (1986).

"
56,1987,"Discovering Structure from Motion in Monkey, Man and Machine","",56-discovering-structure-from-motion-in-monkey-man-and-machine.pdf,"Abstract Missing","701

DISCOVERING STRUCfURE FROM MOTION IN
MONKEY, MAN AND MACHINE
Ralph M. Siegel?
The Salk Institute of Biology, La Jolla, Ca. 92037
ABSTRACT
The ability to obtain three-dimensional structure from visual motion is
important for survival of human and non-human primates. Using a parallel processing model, the current work explores how the biological visual system might solve
this problem and how the neurophysiologist might go about understanding the
solution.
INTRODUcnON

1

Psychophysical experiments have shown that monke and man are equally
adept at obtaining three dimensional structure from motion . In the present work,
much effort has been expended mimicking the visual system. This was done for one
main reason: the model was designed to help direct physiological experiments in the
primate. It was hoped that if an approach for understanding the model could be
developed, the approach could then be directed at the primate's visual system.
Early in this century, von Helmholtz2 described the problem of extracting
three-dimensional structure from motion:
Suppose, for instance, that a person is standing still in a thick woods,
where it is impossible for him to distinguish, except vaguely and roughly,
in the mass of foliage and branches all around him what belongs to one
tree and what to another, or how far apart the separate trees are, etc. But
the moment he begins to move forward, everything disentangles itself,
and immediately he gets an apperception of the material content of the
woods and their relation to each other in space, just as if he were looking
at a good stereoscopic view of it.
If the object moves, rather than the observer, the perception of threedimensional structure from motion is still obtained. Object-centered structure from
motion is examined in this report. Lesion studies in monkey have demonstrated that
two extra-striate visual cortices called the middle temporal area (abbreviated MT

?Current address: Laboratory of Neurobiology, The Rockefeller University, 1230
York Avenue, New York, NY 10021
? American Institute of Physics 1988

702

or V5) and the medial superior temporal area (MST)3,4 are involved in obtaining
structure from motion. The present model is meant to mimic the V5-MST part of
the cortical circuitry involved in obtaining structure from motion. The model
attempts to determine ifthe visual image corresponds to a three-dimensional object.

TIlE STRUCfURE FROM MOTION STIMULUS
The problem that the model solved was the same as that posed in the studies
of monkey and man 1. Structured and unstructured motion displays of a hollow,
orthographically projected cylinder were computed (Figure 1). The cylinder rotates
about its vertical axis. The unstructured stimulus was generated by shuffling the
velocity vectors randomly on the display screen. The overall velocity and spatial
distribution for the two displays are identical; only the spatial relationships have
been changed in the unstructured stimulus. Human subjects report that the points
are moving on the surface of a hollow cylinder when viewing the structured stimulus.
With the unstructured stimulus, most subjects report that they have no sense of
three-dimensional structure.
c.

B. Orthographic
Projection

A. Rotating Cylinder

Unstructured
Display

~

~

~

....+--~

+-..

,

~

+

~~

~~

-:/'
~
~

~

~

+-.. ~~

)

~

~~

~~

-+

~

,.

~

~

---+

---+~

~

+ ~

~
~

~

~

Figure 1. The structured and unstructured motion stimulus. A) ""N"" pomts are
randomly placed on the surface of a cylinder. B) The points are orthographically projected. The motion gives a strong percept of a hollow cylinder. C) The unstructured
stimulus was generated by shuffling the velocity vectors randomly on the screen.

FUNCTIONALARCHITECfUREOFTIlEMODEL
As with the primate subjects, the model was required to only indicate whether
or not the display was structured. Subjects were not required to describe the shape,
velocity or size of the cylinder. Thus the output cell* of the model signaled ""1"" if

*By cell, I mean a processing unit of the model which may correspond to a single
neuron or group of neurons. The term neuron refers only to the actual wetware
in the brain.

703

structured and ""0"" if not structured. This output layer corresponds to the cortical
area MST of macaque monkey which appear to be sensitive to the global organization of the motion image5. It is not known if MST neurons will distinguish between
structured and unstructured images.
The input to the model was based on physiological studies in the maca~ue
monkey. Neurons in area V5 have a retinotopic representation of visual space ,7.
For each retinotopic location there is
an encoding of a wide range of velocitiesS. Thus in the model's input rep1
resentation, there were cells that
<l.I
CIl
represent different combinations of
C
o
velocity and retinotopic spatial posi0CIl
<l.I
tion. Furthermore motion velocity
s....
neurons in V5 have a center-surround opponent organization9. The
width of the receptive fields was
-O.~-+-~I--""""-""""""-+-""'""
taken from the data of Albright et
-3 -2 -1 0
1
2
3
retinal position (deg)
al. S. A typical receptive field of the
model is shown in Figure 2.
Figure 2. The receptive field of an input
layer cell. The optimal velocity is ""vo"".

lt was possible to determine what the activity of the input cells would be for
the rotating cylinder given this representation. The activation pattern of the set of
input cells was computed by convolving the velocity points with the difference of
gaussians. The activity of the 100 input cells for an image of 20 points, with an angular velocity of SO/sec is presented in Figure 3.
Relinotopic map

Retinotopic map

>.

..-'. .

()

o

Q)

>

Structure = 1

Structure = 0

Figure 3. The input cell's activation pattern for a structured and unstructured stimuIus. The circles correspond to the cells of the input layer. The contours were com-

704

puted using a linear interpolation between the individual cells. The horizontal axis
corresponds to the position along the horizontal meridian. The vertical axis corresponds to the speed along the horizontal meridian. Thus activation of a cell in the
upper right hand corner of the graph correspond to a velocity of 300 / sec towards the
right at a location of 30 to the right along the horizontal meridian.
Inspection of this input pattern suggested that the problem of detecting
three-dimensional structure from motion may be reduced to a pattern recognition
task. The problem was then: ""Given a sparsely sampled input motion flow field, determine whether it corresponds best to a structured or unstructured object.""
Itwas next necessary to determine the connections between the two input and
output layers such that the model will be able to correctly signal structure or no structure (1 or 0) over a wide range of cylinder radii and rotational velocities. A parallel
distributed network of the type used by Rosenberg and Sejnowski 10 provided the
functional architecture (Figure 4).

o
M
I

Figure 4. The parallel architecture used to extract structure
from motion. The input layer (I), corresponding to area V5,
mapped the position and speed along the horizontal axis.
The output layer (0) corresponded to area MST that, it is
proposed, signals structure or not. The middle layer (M)
may exist in either V5 or MST.

The input layer of cells was fully connected to the middle layer of cells. The
middle layer of cells represented an intermediate stage of processing and may be in
either V5 or MST. All of the cells of the middle layer were then fully connected to
the output cell. The inputs from cells of the lower layer to the next higher level were
summed linearly and then ""thresholded"" using the Hill equation X3/(X3 + 0.5 3).
The weights between the layers were initially chosen between.?.1. The values of the
weights were then adjusted using back-propagation methods (steepest descent) so
that the network would ""learn"" to correctly predict the structure of the input image.
The model learned to correctly perform the task after about 10,000 iterations
(Figure 5).
Figure 5. The ""education"" of the network to
o.
perform the structure from motion problem.
The iteration number is plotted against the
mean square error. The error is defined as the
difference between the model's prediction and
o.
the known structure. The model was trained on
a set of structured and unstructured cylinders
a wi?e range o~ ~adii, number of points,
o 100002000030000 40000 with
and rotatlOnal velOCItIes.
Iteration number

705

PSYCHOPHYSICAL PERFORMANCE OF THE MODEL
The model's performance was comparable to that of monkey and man with
respect to fraction of structure and number of points in the display (Figure 6). The
model was indeed performing a global analysis as shown by allowing the model to
view only a portion of the image. Like man and monkey, the model's performance
suffers. Thus it appears that the model's performance was quite similar to known
monkey and human psychophysics.

1 Output

1

-..- monkey
..... man
machine

0.8
0.6

.8
0.6

0.4

0.4

0.2

0.2

0

0
0

0.2

0.4

0.6

0.8

1

monkey
-man
machine

-.l-

0

Fraction structure

32

64

96

128

Number of points

Figure 6. Psychophysical performance of the model. A. The effect of varying the
fraction of structure. As the fraction of structure increase, the model's performance
improves. Thirty repetitions were averaged for each value of structure for the model.
The fraction of structure is defined as (1-Rs/Rc), where Rs is the radius of shuffling
of the motion vectors and Rc is the radius of the cylinder. The human and monkey
data are taken from psychophysical studies 1.
HOW IS IT DONE?
The model has similar performance to monkey and man. It was next possible
to examine this artificial network in order to obtain hints for studying the biological
system. Following the approach of an electrophysiologist, receptive field maps for
all the cells of the middle and ou tput layers were made by activating individual inpu t
cells. The receptive field of some middle layer cells are shown in Figure 7. The layout
of these maps are quite similar to that of Figure 4. However, now the activity of one
cell in the middle layer is plotted as a function of the location and speed of a motion
stimulus in the input layer. One could imagine that an electrode was placed in one
of the cells of the middle layer while the experimentalist moved a bar about the

706

horizontal meridian with different locations and speeds. The activity of the cell is
then plotted as a function of position and space.
~

-f

Relinolopic map

30

~
""'::>:->::::':-:-""
...

rJ

\
00
(I')

I
~~=-~~-L~~~~~~~~

Figure 7. The activity of two different cells in the middle layer. Activity is plotted
as a contour map as a function of horizontal position and speed. Dotted lines
indicate inhibition.
These middle layer receptive field maps were interesting because they
appear to be quite simple and symmetrical. In some, the inhibitory central regions
of the receptive field were surrounded by excitatory regions (Figure 7A). Complementary cells were also found. In others, there are inhibitory bands adjacent to
excitatory bands (Figure 7B). The above results suggest that neurons involved in
extracting structure from motion may have relatively simple receptive fields in the
spatial velocity domain. These receptive fields might be thought of as breaking the
image down into component parts (i.e. a basis set). Correct recombination of these
second order cells could then be used to detect the presence of a three-dimensional
structure.
The output cell also had a simple receptive field again with interesting
symmetries (Figure 8). However, the receptive field analysis is insufficient to
indicate the role of the cell. Therefore in order to properly understand the ""meaning"" of the cell's receptive field, it is necessary to use
stimuli that are ""real world relevant"" - in this case the
structure from motion stimuli. The output cell would
give its maximal response only when a cylinder stimulus
is presented.
Figure 8. The receptive field map of the output layer cell.
Nothing about this receptive field structure indicates the
cell is involved in obtaining structure from motion.

707

This work predicts that neurons in cortex involved in extracting structure
from motion will have relatively simple receptive fields. In order to test this
hypothesis, it will be necessary to make careful maps of these cells using small
patches of motion (Figure 9). Known qualitative results in areas V5 and MST are
consistent with, but do not prove, this hypothesis. As well, it will be necessary to use
""relevant"" stimuli (e.g. three-dimensional objects). If such simple receptive fields
are indeed used in structure from motion, then support will be found for the idea that
a simple cortical circuit (e.g. center-surround) can be used for many different visual
analyses.

?

Motion patches consisting of random dots with
variable velocity.

ru

Fix point

Figure 9. It may be necessary to make careful
maps of these neurons using small patches of
motion, in order to observe the postulated simple
receptive field properties of cortical neurons involved in extracting structure from
motion. Such structures may not be apparent using hand moved bar stimuli.
DISCUSSION
In conclusion, it is possible to extract the three-dimensional structure of a
rotating cylinder using a parallel network based on a similar functional architecture
as found in primate cortex. The present model has similar psychophysics to monkey
and man. The receptive field structures that underlie the present model are simple
when viewed using a spatial-velocity representation. It is suggested that in order to
understand how the visual system extracts structure from motion, quantitative
spatial-velocity maps of cortical neurons involved need to be made. One also needs
to use stimuli derived from the ""real world"" in order to understand how they may
be used in visual field analysis. There are similarities between the shapes of the
receptive fields involved in analyzing structure from motion and receptive fields in
striate cortex 11. It may be that similar cortical mechanisms and connections are used
to perform different functions in different cortical areas. Lastly, this model demonstrates that the use of parallel architectures that are closely modeled on the cortical
representation is a computationally efficient means to solve problems in vision. Thus
as a final caveat, I would like to advise the creators of networks that solve
ethologically realistic problems to use solutions that evolution has provided.

708

REFERENCES
1. R.M. Siegel and R.A. Andersen, Nature {Lond.} (1988).
2. H. von Helmholtz, Treatise on Physiological Optics {Dover Publications, N.Y.,
1910}, p. 297.
.
3. R.M. Siegel and R.A. Andersen, Soc. Neurosci. Abstr., 12, p. 1183 {1986}.
4. R.M. Siegel and R.A Andersen, Localization of function in extra-striate cortex:
the effect of ibotenic acid lesions on motion sensitivity in Rhesus monkey, {in
preparation}.
5. K. Tanaka, K. Hikosaka, H. Saito, M. Yukie, Y. Fukada, and E. Iwai, J., Neurosci.,
~, pp. 134-144 {1986}.
6. S.M. Zeki, Brain Res.,~, pp. 528-532 {1971}.
7. J.H.R. Maunsell and D.C. VanEssen, J. Neurophysiol., 49, pp. 1127-1147 {1983}.
8. T.D. Albright, R. Desimone, and C.G. Gross, J. NeurophysioI., 51, pp. 16-31
{1984}.
9. J. Allman, F. Miezen, and E. McGuinness, Ann. Rev. Neurosci., 8, pp. 407-430
(1985).
10. C.R. Rosenberg and T.J. Sejnowski, in: Reports of the Cognitive Neuropsychology Laboratory, John-Hopkins University {1986}.
11. D.H. Hubel and T.N. Wiesel, Proc. R. Soc. Lond. B., 198, pp.I-59 {1977}.

This work was supported by the Salk Institute for Biological Studies, The San Diego
Supercomputer Center, and PHS NS07457-02.

"
58,1987,"Analysis of Distributed Representation of Constituent Structure in Connectionist Systems","",58-analysis-of-distributed-representation-of-constituent-structure-in-connectionist-systems.pdf,"Abstract Missing","730

Analysis of distributed representation of
constituent structure in connectionist systems
Paul Smolensky
Department of Computer Science, University of Colorado, Boulder, CO 80309-0430

Abstract
A general method, the tensor product representation, is described for the distributed representation of
value/variable bindings. The method allows the fully distributed representation of symbolic structures:
the roles in the structures, as well as the fillers for those roles, can be arbitrarily non-local. Fully and
partially localized special cases reduce to existing cases of connectionist representations of structured
data; the tensor product representation generalizes these and the few existing examples of fuUy
distributed representations of structures. The representation saturates gracefully as larger structures
are represented; it penn its recursive construction of complex representations from simpler ones; it
respects the independence of the capacities to generate and maintain multiple bindings in parallel; it
extends naturally to continuous structures and continuous representational patterns; it pennits values to
also serve as variables; it enables analysis of the interference of symbolic structures stored in
associative memories; and it leads to characterization of optimal distributed representations of roles
and a recirculation algorithm for learning them.

Introduction
Any model of complex infonnation processing in networks of simple processors must solve the
problem of representing complex structures over network elements. Connectionist models of realistic
natural language processing, for example, must employ computationally adequate representations of
complex sentences. Many connectionists feel that to develop connectionist systems with the
computational power required by complex tasks, distributed representations must be used: an
individual processing unit must participate in the representation of multiple items, and each item must
be represented as a pattern of activity of multiple processors. Connectionist models have used more or
less distributed representations of more or less complex structures, but little if any general analysis of
the problem of distributed representation of complex infonnation has been carried out This paper
reports results of an analysis of a general method called the tensor product representation.
The language-based fonnalisms traditional in AI pennit the construction of arbitrarily complex
structures by piecing together constituents. The tensor product representation is a connectionist
method of combining representations of constituents into representations of complex structures. If the
constituents that are combined have distributed representations, completely distributed representations
of complex structures can result each part of the network is responsible for representing multiple
constituents in the structure, and each constituent is represented over multiple units. The tensor
product representation is a general technique, of which the few existing examples of fully distributed
representations of structures are particular cases.
The tensor product representation rests on identifying natural counterparts within connectionist
computation of certain fundamental elements of symbolic computation. In the present analysis, the
problem of distributed representation of symbolic structures is characterized as the problem of taking
complex structures with certain relations to their constituent symbols and mapping them into activity
vectors--patterns of activation-with corresponding relations to the activity vectors representing their
constituents. Central to the analysis is identifying a connectionist counterpart of variable binding: a
method for binding together a distributed representation of a variable and a distributed representation
of a value into a distributed representation of a variable/value binding-a representation which can
co-exist on exactly the same network units with representations of other variable/value bindings, with

@ American Institute of Physics 1988

731

limited confusion of which variables are bound to which values.
In summary, the analysis of the tensor product representation
(1)
(2)
(3)
(4)

provides a general technique for constructing fully distributed representations of
arbitrarily complex structures;
clarifies existing representations found in particular models by showing what particular
design decisions they embody;
allows the proof of a number of general computational properties of the representation;
identifies natural counterparts within connectionist computation of elements of symbolic
computation, in particular, variable binding.

The recent emergence to prominence of the connectionist approach to AI raises the question of the
relation between the non symbolic computation occurring in connectionist systems and the symbolic
computation traditional in AI. The research reported here is part of an attempt to marry the two types
of computation, to develop for AI a form of computation that adds crucial aspects of the power of
symbolic computation to the power of connectionist computation: massively parallel soft constraint
satisfaction. One way to marry these approaches is to implement serial symbol manipulation in a
connectionist system 1.2. The research described here takes a different tack. In a massively parallel
system the processing of symbolic structures-for example, representations of parsed sentences-need
not be limited to a series of elementary manipulations: indeed one would expect the processing to
involve massively parallel soft constraint satisfaction. But in order for such processing to occur, a
satisfactory answer must be found for the question: How can symbolic structures. or structured data in
general. be naturally represented in connectionist systems? The difficulty here turns on one of the
most fundamental problems for relating symbolic and connectionist computation: How can variable

binding be naturally performed in connectionist systems?
This paper provides an overview of a lengthy analysis reported elsewhere3 of a general
connectionist method for variable binding and an associated method for representing structured data.
The purpose of this paper is to introduce the basic idea of the method and survey some of the results;
the reader is referred to the full report for precise defmitions and theorems, more extended examples.
and proofs.

The problem
Suppose we want to represent a simple structured object, say a sequence of elements, in a
connectionist system. The simplest method, which has been used in many models, is to dedicate a
network processing unit to each possible element in each possible position4-9. This is a purely local
representation. One way of looking at the purely local representation is that the binding of
constituents to the variables representing their positions is achieved by dedicating a separate unit to
every possible binding, and then by activating the appropriate individual units.
Purely local representations of this sort have some advantages 10, but they have a number of serious
problems. Three immediately relevant problems are these:
(1)
(2)
(3)

The number of units needed is #elements * #positions; most of these processors are
inactive and doing no work at any given time.
The number of positions in the structures that can be represented has a fixed, rigid upper
limit.
If there is a notion of similar elements, the representation does not take advantage of this:
similar sequences do not have similar representations.

The technique of distributed representation is a well-known way of coping with the first and third
problems ll - 14. If elements are represented as patterns of activity over a population of processing units,
and if each unit can participate in the representation of many elements, then the number of elements
that can be represented is much greater than the number of units, and similar elements can be
represented by similar patterns, greatly enhancing the power of the network to learn and take
advantage of generalizations.

732

Distributed representations of elements in structures (like sequences) have been successfully used
in many modelsl.4.S.1S-18. For each position in the structure, a pool of units is dedicated. The element
occurring in that position is represented by a pattern of activity over the units in the pool.
Note that this technique goes only part of the way towards a truly distributed representation of the
entire structure. While the values of the variables defming the roles in the structure are represented by
distributed patterns instead of dedicated units, the variables themselves are represented by localized,
dedicated pools. For this reason I will call this type of representation semi-local.
Because the representation of variables is still local, semi-local representations retain the second of
the problems of purely local representations listed above. While the generic behavior of connectionist
systems is to gradually overload as they attempt to hold more and more information, with dedicated
pools representing role variables in structures, there is no loading at all until the pools are
exhausted-and then there is complete saturation. The pools are essentially registers, and the
representation of the structure as a whole has more of the characteristics of von Neumann storage than
connectionist representation. A fully distributed connectionist representation of structured data would
saturate gracefully.
Because the representation of variables in semi-local representations is local, semi-local
representations also retain part of the third problem of purely local representations. Similar elements
have similar representations only if they occupy exactly the same role in the structure. A notion of
similarity of roles cannot be incorporated in the semi-local representation.

Tensor product binding
There is a way of viewing both the local and semi-local representations of structures that makes a
generalization to fully distributed representations immediately apparent. Consider the following
structure: strings of length no more than four letters. Fig. 1 shows a purely local representation and
Fig. 2 shows a semi-local representation (both of which appeared in the letter-perception model of
McClelland and Rumelharr4,s). In each case, the variable binding has been viewed in the same way.
On the left edge is a set of imagined units which can represent an element in the structure-a ftller of a
role; these are the filler units. On the bottom edge is a set of imagined units which can represent a
role: these are the role units. The remaining units are the ones really used to represent the structure:
the binding units. They are arranged so that there is one for each pair offiller and role units.
In the purely local case, both the filler and the role are represented by a ""pattern of activity""
localized to a single unit In the semi-local case, the ftiler is represented by a distributed pattern of
activity but the role is still represented by a localized pattern. In either case, the binding of the filler to
the role is achieved by a simple product operation: the activity of each binding unit is the product of
the activities of the associated ftller and role unit In the vocabulary of matrix algebra, the activity
representing the value/variable binding forms a matrix which is the outer product of the activity vector
representing the value and the activity vector representing the variable. In the terminology of vector
spaces, the value/variable binding vector is the tensor product of the value vector and the variable
vector. This is what I refer to as the tensor product representation for variable bindings.
Since the activity vectors for roles in Figs. 1 and 2 consist of all zeroes except for a single activity
of 1, the tensor product operation is utterly trivial. The local and semi-local cases are trivial special
cases of a general binding procedure capable of producing completely distributed representations. Fig.
3 shows a distributed case designed for visual transparency. Imagine we are representing speech data,
and have a sequence of values for the energy in a particular formant at successive times. In Fig. 3,
distributed patterns are used to represent both the energy value and the variable to which it is bound:
the position in time. The particular binding shown is of an energy value 2 (on a scale of 1-4) to the
time 4. The peaks in the patterns indicate the value and variable being represented.

733

Filler

(L."".')

!3

0

(0

(8

8

8

[i]

G)

(8

,e

8

e

El

0

0

0

0

0

0

6)

@

@

8

0

0

@)

@>

@

?

El

.?

.!::

?

0

0

0

0

0

?
?

0
0

o
ROI. (Po,'tlon)

Fig. 1. Purely local representation of strings.

?

0

0

0

0

0

0

0

0

0

0

0

0

?
?
?

o o

Rol. (Po,lIIon)

Fig. 2. Semi-local representation of strings.

If the patterns representing the value and variable being bound together are not as simple as those
used in Fig. 3, the tensor product pattern representing the binding will not of course be particularly
visually infonnative. Such would be the case if the patterns for the fIllers and roles in a structure were
defmed with respect to a set of filler and role features: such distributed bindings have been used
effectively by McClelland and Kawamoto 18 and by Derthick 19 ,20. The extreme mathematical
simplicity of the tensor product operation makes feasible an analysis of the general, fully distributed
case.
Each binding unit in the tensor product representation corresponds to a pair of imaginary role and
filler units. A binding unit can be readily interpreted semantically if its corresponding fIller and role
units can. The activity of the binding unit indicates that in the structure being represented an element
is present which possesses the feature indicated by the corresponding filler unit and which occupies a
role in the structure which possesses the feature indicated by the corresponding role unit. The binding
unit thus detects a conjunction of a pair of fIller and role features. (Higher-order conjunctions will
arise later.)
A structure consists of multiple fIller/role bindings. So far we have only discussed the
representation of a single binding. In the purely local and semi-local cases, there are separate pools for
different roles, and it is obvious how to combine bindings: simultaneously represent them in the
separate pools. In the case of a fully distributed tensor product binding (eg., Fig. 3), each single
binding is a pattern of activity that extends across the entire set of binding units. The simplest
possibility for combining these patterns is simply to add them up; that is, to superimpose all the
bindings on top of each other. In the special cases of purely local and semi-local representations, this
procedure reduces trivially to simultaneously representing the individual fillers in the separate pools.

734

QB
~V~>?

.

Filler

,

0

0

0

0

0

..
()

0

0

o

~

0

@
:

:>-~

.:

,:,,~.~~:?;t' ??

0
""i:'
~
.

""~.}.

(Energy)

~
:. jot ';,
~-}

Role (Time)

Fig. 3. A visually transparent fully distributed tensor product representation.
The process of superimposing the separate bindings produces a representation of structures with
the usual connectionist properties. If the patterns representing the roles are not too similar, the
separate bindings can all be kept straight. It is not necessary for the role patterns to be nonoverlapping, as they are in the purely local and semi-local cases; it is sufficient that the patterns be
linearly independent. Then there is a simple operation that will correctly extract the filler for any role
from the representation of the structure as a whole. If the patterns are not just linearly independent,
but are also orthogonal, this operation becomes quite direct; we will get to it shortly. For now, the
point is that simply superimposing the separate bindings is sufficient. If the role patterns are not too
similar, the separate bindings do not interfere. The representation gracefully saturates if more and
more roles are filled, since the role patterns being used lose their distincmess once their number
approaches that of the role units.
Thus problem (2) listed above, shared by purely local and semi-local representations, is at last
removed in fully distributed tensor product representations: they do not accomodate structures only up
to a certain rigid limit, beyond which they are completely saturated; rather, they saturate gracefully.
The third problem is also fully addressed, as similar roles can be represented by similar patterns in the
tensor product representation and then generalizations both across similar fillers and across similar
roles can be learned and exploited.
The defmition of the tensor product representation of structured data can be summed up as follows:
(a)

(b)
(c)

Let a set S of structured objects be given a role decomposition: a set of fillers, F, a set of
roles R , and for each object s a corresponding set of bindings
P(s) = {f Ir : f fills role r in s }.
Let a connectionist representation of the fillers F be given; f is represented by the activity
vector r.
Let a connectionist representation of the roles R be given; r is represented by the activity

735

(d)

vector r.
Then the corresponding tensor product representation of s is

Y

feB> r (where eB>

!Irtl(s)

denotes the tensor product operation).
In the next section I will discuss a model using a fully distributed tensor product representation,
which will require a brief consideration of role decompositions. I will then go on to summarize general
properties of the tensor product representation.

Role decompositions
The most obvious role decompositions are positional decompositions that involve fixed position
slots within a structure of pre-detennined fonn. In the case of a string, such a role would be the it""
position in the string; this was the decomposition used in the examples of Figs. 1 through 3. Another
example comes from McClelland and Kawamoto's modeI18 for learning to assign case roles. They
considered sentences of the form The N 1 V the N 2 with the N 3; the four roles were the slots for the
three nouns and the verb.
A less obvious but sometimes quite powerful role decomposition involves not fixed positions of
elements but rather their local context. As an example, in the case of strings of letters, such roles
might be r""y = is preceded by x andfollowed by y, for various letters x and y.
Such a local context decomposition was used to considerable advantage by Rumelhart and
McClelland in their model of learning the morphophonology of the English past tense2l ? Their
structures were strings of phonetic segments, and the context decomposition was well-suited for the
task because the generalizations the model needed to learn involved the transformations undergone by
phonemes occurring in different local contexts.
Rumelhart and McClelland's representation of phonetic strings is an example of a fully distributed
tensor product representation. The fillers were phonetic segments, which were represented by a
pattern of phonetic features, and the roles were nearest-neighbor phonetic contexts, which were also
represented as distributed patterns. The distributed representation of the roles was in fact itself a
tensor product representation: the roles themselves have a constituent structure which can be further
broken down through another role decomposition. The roles are indexed by a left and right neighbor;
in essence, a string of two phonetic segments. This string too can be decomposed by a context
decomposition; the filler can be taken to be the left neighbor, and the role can be indexed by the right
neighbor. Thus the vowel [i] in the word week is bound to the role rw kt and this role is in turn a
binding of the filler [w] in the sub-role r' 1. The pattern for [i] is a vectOr i of phonetic features; the
pattern for [w] is another such vector o(features w, and the pattern for the sub-role r'_l is a third
vector k consisting of the phonetic features of [k]. The binding for the [i] in week is thus i0 (weB> k).
Each unit in the representation represents a third-order conjunction of a phonetic feature for a central
segment together with two phonetic features for its left and right neighbors. [To get precisely the
representation used by Rumelhart and McClelland, we have to take this tensor product representation
of the roles (eg. rW_1) and throw out a number of the binding units generated in this further
decomposition; only certain combinations of features of the left and right neighbors were used. The
distributed representation of letter triples used by Touretzky and Hinton l can be viewed as a similar
third-order tensor product derived from nested context decompositions, with some binding units
thrown away-in fact, all binding units off the main diagonal were discarded.]
This example illustrates how role decompositions can be iterated, leading to iterated tensor product
representations. Whenever the fillers or roles of one decomposition are structured objects, they can
themselves be further reduced by another role decomposition.
It is often useful to consider recursive role decompositions in which the fiDers are the same type of
object as the original structure. It is clear from the above definition that such a decomposition cannot
be used to generate a tensor product representation. Nonetheless, recursive role decompositions can
be used to relate the tensor product representation of complex structures to the tensor product
representations of simpler structures. For example, consider Lisp binary tree structures built from a set
A of atoms. A non-recursive decomposition uses A as the set of fIllers, with each role being the

736

occupation of a certain position in the tree by an atom. From this decomposition a tensor product
representation can be constructed. Then it can be seen that the operations car, cdr, and cons
correspond to certain linear operators car, cdr, and cons in the vector space of activation vectors. Just
as complex S-expressions can be constructed from atoms using cons, so their connectionist
representations can be constructed from the simple representation of atoms by the application of cons.
(This serial ""construction"" of the complex representation from the simpler ones is done by the analyst,
not necessarily by the network; cons is a static, descriptive, mathematical operator-not necessarily a
transformation to be carried out by a network.)

Binding and unbinding in connectionist networks
So far, the operation of binding a value to a variable has been described mathematically and
pictured in Figs. 1-3 in terms of ""imagined"" filler units and role units. Of course, the binding
operation can actually be performed in a network if the filler and role units are really there. Fig. 4
shows one way this can be done. The triangular junctions are Hinton's multiplicative connections22:
the incoming activities from the role and filler units are multiplied at the junction and passed on to the
binding unit.
Binding Units

Fi lIer
Units

Role Units

Fig. 4. A network for tensor product binding and unbinding.
""Unbinding"" can also be performed by the network of Fig. 4. Suppose the tensor product
representation of a structure is present in the binding units, and we want to extract the filler for a
particular role. As mentioned above, this can be done accurately if the role patterns are linearly
independent (and if each role is bound to only one filler). It can be shown that in this case, for each
role there is a pattern of activity which, if set up on the role units, will lead to a pattern on the filler
units that represents the corresponding filler. (If the role vectors are orthogonal, this pattern is the
same as the role pattern.) As in Hinton's model 20, it is assumed here that the triangular junctions work
in all directions, so that now they take the product of activity coming in from the binding and role units
and pass it on to the filler units, which sum all incoming activity.

737

The network of Fig. 4 can bind one value/variable pair at a time. In order to build up the
representation of an entire structure, the binding units would have to accumulate activity over an
extended period of time during which all the individual bindings would be performed serially.
Multiple bindings could occur in parallel if part of the apparatus of Fig. 4 were duplicated: this
requires several copies of the sets of filler and role units, paired up with triangular junctions, all
feeding into a single set of binding units.
Notice that in this scheme there are two independent capacities for parallel binding: the capacity to
generate bindings in parallel, and the capacity to maintain bindings simultaneously. The former is
determined by the degree of duplication of the ftller/role unit sets (in Fig. 4, for example, the parallel
generation capacity is 1). The parallel maintenance capacity is determined by the number of possible
linearly independent role patterns, i.e. the number of role units in each set It is logical that these two
capacities should be independent, and in the case of the human visual and linguistic systems it seems
that our maintenance capacity far exceeds our generation capacity21. Note that in purely local and
semi-local representations, there is a separate pool of units dedicated to the representation of each role,
so there is a tendency to suppose that the two capacities are equal. As long as a connectionist model
deals with structures (like four-letter words) that are so small that the number of bindings involved is
within the human parallel generation capacity, there is no harm done. But when connectionist models
address the human representation of large structures (like entire scenes or discourses), it will be
important to be able to maintain a large number of bindings even though the number that can be
generated in parallel is much smaller.

Further properties and extensions
Continuous structures. It can be argued that underlying the connectionist approach is a
fundamentally continuous formalization of computation 13. This would suggest that a natural
connectionist representation of structure would apply at least as well to continuous structures as to
discrete ones. It is therefore of some interest that the tensor product representation applies equally
well to structures characterized by a continuum of roles: a ""string"" extending through continuous time,
for example, as in continuous speech. In place of a sum over a discrete set of bindings, l:Ji 0ri we
have an integral over a continuum of bindings: J,r(t)0r(t) dt This goes over exactly to the discrete
case if the fillers are discrete step-functions of time.
Continuous patterns. There is a second sense in which the tensor product representation
extends naturally to the continuum. If the patterns representing fillers and/or roles are continuous
curves rather than discrete sets of activities, the tensor product operation is still well-defmed. (Imagine
Fig. 3 with the filler and role patterns being continuous peaked curves instead of discrete
approximations; the binding pattern is then a continuous peaked two-dimensional surface.) In this case,
the vectors rand/or r are members of infmite-dimensional function spaces; regarding them as patterns
of activity over a set of processors would require an infmite number of processors. While this might
pose some problems for computer simulation, the case where rand/of r are functions rather than
finite-dimensional vectors is not particularly problematic analytically. And if a problem with a
continuum of roles is being considered, it may be desirable to assume a continuum of linearly
independent role vectors: this requires considering infinite-dimensional representations.
Values as variables. Treating both values and variables symmetrically as done in the tensor
product representation makes it possible for the same entity to simultaneously serve both as a value
and as a variable. In symbolic computation it often happens that the value bound to one variable is
itself a variable which in tum has a value bound to it In a semi-local representation, where variables
are localized pools of units and values are patterns of activity in these pools, it is difficult to see how
the same entity can simultaneously serve as both value and variable. In the tensor product
representation, both values and variables are patterns of activity, and whether a pattern is serving as a
""variable"" or ""value""-Qr both-might be merely a matter of descriptive preference.

738

Symbolic structures in associative memories. The mathematical simplicity of the tensor
product representation makes it possible to characterize conditions under which a set of symbolic
structures can be stored in an associative memory without interference. These conditions involve an
interesting mixture of the numerical character of the associative memory and the discrete character of
the stored data.
Learning optimal role patterns by recirculation. While the use of distributed patterns to
represent constituents in structures is well-known, the use of such patterns to represent roles in
structures poses some new challenges. In some domains, features for roles are familiar or easy to
imagine; eg.. features of semantic roles in a case-frame semantics. But it is worth considering the
problem of distributed role representations in domain-independent terms as well. The patterns used to
represent roles determine how information about a structure's fillers will be coded, and these role
patterns have an effect on how much information can subsequently be extracted from the
representation by connectionist processing. The challenge of making the most information available
for such future extraction can be posed as follows. Assume enough apparatus has been provided to do
all the variable binding in parallel in a network like that of Fig. 4. Then we can dedicate a set of role
units to each role; the pattern for each role can be set up once and for all in one set of role units. Since
the activity of the role units provide multipliers for filler values at the triangular junctions, we can treat
these fixed role patterns as weights on the lines from the filler units to the binding units. The problem
of finding good role patterns now becomes the problem of finding good weights for encoding the
fillers into the binding units.
Now suppose that a second set of connections is used to try to extract all the fillers from the
representation of the structure in the binding units. Let the weights on this second set of connections
be chosen to minimize the mean-squared differences between the extracted ftller patterns and the
actual original filler patterns. Let a set of role vectors be called optimal if this mean-squared error is as
small as possible.
It turns out that optimal role vectors can be characterized fairly simply both algebraically and
geometrically (with the help of results from Williams24). Furthermore, having imbedded the role
vectors as weights in a connectionist net, it is possible for the network to learn optimal role vectors by
a fairly simple learning algorithm. The algorithm is derived as a gradient descent in the mean-squared
error, and is what G. E. Hinton and J. L. McClelland (unpublished communication) have called a
recirculation algorithm: it works by circulating activity around a closed network loop and training on
the difference between the activities at a given node on successive passes.

Acknowledgements
This research has been supported by NSF grants 00-8609599 and ECE-8617947, by the Sloan
Foundation's computational neuroscience program, and by the Department of Computer Science and
Institute of Cognitive Science at the University of Colorado at Boulder.

739

References
1. D. S. Touretzky & G. E. Hinton. Proceedings of the International Joint Conference on Artificial
Intelligence, 238-243 (1985).
2. D. S. Touretzky. Proceedings of the 8th Conference of the Cognitive Science Society, 522-530
(1986).
3. P. Smolensky. Technical Report CU-CS-355-87, Department of Computer Science, University
of Colorado at Boulder (1987).
4. J. L. McClelland & D. E. Rumelhart. Psychological Review 88, 375-407 (1981).
5. D. E. Rumelhart & J. L. McClelland. Psychological Review 89, 60-94 (1982).
6. M. Fanty. Technical Report 174, Department of Computer Science, University of Rochester
(1985).
7. J. A. Feldman. The Behavioral and Brain Sciences 8,265-289 (1985).
8. J. L. McClelland & J. L. Elman. In J. L. McClelland, D. E. Rumelhart, & the PDP Research
Group, Parallel distributed processing: Explorations in the microstructure of cognition. Vol. 2:
Psychological and biological models. Cambridge, MA: MIT Press/Bradford Books, 58-121
(1986).
9. T. J. Sejnowski & C. R. Rosenberg. Complex Systems 1,145-168 (1987).
10. J. A. Feldman. Technical Report 189, Department of Computer Science, University of Rochester
(1986).
11. J. A. Anderson & G. E. Hinton. In G. E. Hinton and J. A. Anderson, Eds., Parallel models of
associative memory. Hillsdale, NJ: Erlbaum, 9-48 (1981).
12. G. E. Hinton, J. L. McClelland, & D. E. Rumelhart. In D. E. Rumelhart, J. L. McClelland, & the
PDP Research Group, Parallel distributed processing: Explorations in the microstructure of
cognition. Vol. 1: Foundations. Cambridge, MA: MIT Press/Bradford Books, 77-109 (1986).
13. P. Smolensky. The Behavioral and Brain Sciences 11(1) (in press).
14. P. Smolensky. In J. L. McClelland, D. E. Rumelhart, & the PDP Research Group, Parallel
distributed processing: Explorations in the microstructure of cognition. Vol. 2: Psychological and
biological models. Cambridge, MA: MIT Press/Bradford Books, 390-431 (1986).
15. G. E. Hinton. In Hinton, G.E. and Anderson, J.A., Eds., Parallel models of associative memory.
Hillsdale,NJ: Erlbaum, 161-188 (1981).
16. M. S. Riley & P. Smolensky. Proceedings of the Sixth Annual Conference of the Cognitive Science
Society, 286-292 (1984).
17. P. Smolensky. In D. E. Rumelhart, J. L. McOelland, & the PDP Research Group, Parallel
distributed processing: Explorations in the microstructure of cognition. Vol. 1: Foundations.
Cambridge, MA: MIT Press/Bradford Books, 194-281 (1986).
18. J. L. McClelland & A. H. Kawamoto. In J. L. McClelland, D. E. Rumelhart, & the PDP Research
Group, Parallel distributed processing: Explorations in the microstructure of cognition. Vol. 2:
Psychological and biological models. Cambridge, MA: MIT Press/Bradford Books, 272-326
(1986).
19. M. Derthick. Proceedings of the National Conference on Artificial Intelligence, 346-351 (1987).
20. M. Dertbick. Proceedings of the Annual Conference of the Cognitive Science Society, 131-142
(1987).
21. D. E. Rumelhart & J. L. McClelland. In J. L. McClelland, D. E. Rumelhart, & the PDP Research
Group, Parallel distributed processing: Explorations in the microstructure of cognition. Vol. 2:
Psychological and biological models. Cambridge, MA: MIT Press/Bradford Books, 216-271
(1986)
22. G. E. Hinton. Proceedings of the Seventh International Joint Conference on Artificial Intelligence,
683-685 (1981).
23. A. M. Treisman & H. Schmidt. Cognitive Psychology 14,107-141 (1982).
24. R. J. Williams. Technical Report 8501, Institute of Cognitive Science, University of California,
San Diego (1985).

"
59,1987,"How Neural Nets Work","",59-how-neural-nets-work.pdf,"Abstract Missing","442

How Neural Nets Work
Alan Lapedes
Robert Farber
Theoretical Division
Los Alamos National Laboratory
Los Alamos, NM 87545

Abstract:
There is presently great interest in the abilities of neural networks to mimic
""qualitative reasoning"" by manipulating neural incodings of symbols. Less work
has been performed on using neural networks to process floating point numbers
and it is sometimes stated that neural networks are somehow inherently inaccurate and therefore best suited for ""fuzzy"" qualitative reasoning. Nevertheless,
the potential speed of massively parallel operations make neural net ""number
crunching"" an interesting topic to explore. In this paper we discuss some of our
work in which we demonstrate that for certain applications neural networks can
achieve significantly higher numerical accuracy than more conventional techniques. In particular, prediction of future values of a chaotic time series can
be performed with exceptionally high accuracy. We analyze how a neural net
is able to do this , and in the process show that a large class of functions from
Rn. ~ Rffl may be accurately approximated by a backpropagation neural net
with just two ""hidden"" layers. The network uses this functional approximation
to perform either interpolation (signal processing applications) or extrapolation
(symbol processing applicationsJ. Neural nets therefore use quite familiar methods to perform. their tasks. The geometrical viewpoint advocated here seems to
be a useful approach to analyzing neural network operation and relates neural
networks to well studied topics in functional approximation.
1. Introduction
Although a great deal of interest has been displayed in neural network's
capabilities to perform a kind of qualitative reasoning, relatively little work has
been done on the ability of neural networks to process floating point numbers
in a massively parallel fashion. Clearly, this is an important ability. In this
paper we discuss some of our work in this area and show the relation between
numerical, and symbolic processing. We will concentrate on the the subject of
accurate prediction in a time series. Accurate prediction has applications in
many areas of signal processing. It is also a useful, and fascinating ability, when
dealing with natural, physical systems. Given some .data from the past history
of a system, can one accurately predict what it will do in the future?
Many conventional signal processing tests, such as correlation function analysis, cannot distinguish deterministic chaotic behavior from from stochastic
noise. Particularly difficult systems to predict are those that are nonlinear and
chaotic. Chaos has a technical definition based on nonlinear, dynamical systems
theory, but intuitivly means that the system is deterministic but ""random,"" in
a rather similar manner to deterministic, pseudo random number generators
used on conventional computers. Examples of chaotic systems in nature include
turbulence in fluids (D. Ruelle, 1971; H. Swinney, 1978), chemical reactions (K.
Tomita, 1979), lasers (H. Haken, 1975), plasma physics (D. Russel, 1980) to
name but a few. Typically, chaotic systems also display the full range of nonlinear behavior (fixed points, limit cycles etc.) when parameters are varied, and
therefore provide a good testbed in which to investigate techniques of nonlinear
signal processing. Clearly, if one can uncover the underlying, deterministic algorithm from a chaotic time series, then one may be able to predict the future
time series quite accurately,
? American Institute of Physics 1988

443

In this paper we review and extend our work (Lapedes and Farber ,1987)
on predicting the behavior of a particular dynamical system, the Glass-Mackey
equation. We feel that the method will be fairly general, and use the GlassMackey equation solely for illustrative purposes. The Glass-Mackey equation
has a strange attractor with fractal dimension controlled by a constant parameter appearing in the differential equation. We present results on a neural network's ability to predict this system at two values of this parameter, one value
corresponding to the onset of chaos, and the other value deeply in the chaotic
regime. We also present the results of more conventional predictive methods and
show that a neural net is able to achieve significantly better numerical accuracy.
This particular system was chosen because of D. Farmer's and J. Sidorowich's
(D. Farmer, J . Sidorowich, 1987) use of it in developing a new, non-neural net
method for predicting chaos. The accuracy of this non-neural net method, and
the neural net method, are roughly equivalent, with various advantages or disadvantages accruing to one method or the other depending on one's point of
view. We are happy to acknowledge many valuable discussions with Farmer and
Sidorowich that has led to further improvements in each method.
We also show that a neural net never needs more than two hidden layers to
solve most problems. This statement arises from a more general argument that
a neural net can approximate functions from Rn. -+ R m with only two hidden
layers, and that the accuracy of the approximation is controlled by the number
of neurons in each layer. The argument assumes that the global minimum to the
backpropagation minimization problem may be found, or that a local minima
very close in value to the global minimum may be found. This seems to be
the case in the examples we considered, and in many examples considered by
other researchers, but is never guaranteed. The conclusion of an upper bound
of two hidden layers is related to a similar conclusion of R. Lipman (R. Lipman,
1987) who has previously analyzed the number of hidden layers needed to form
arbitrary decision regions for symbolic processing problems. Related issues are
discussed by J. Denker (J. Denker et.al. 1987) It is easy to extend the argument
to draw similar conclusions about an upper bound of two hidden layers for
symbol processing and to place signal processing, and symbol processing in a
common theoretical framework.
2. Backpropagation
Backpropagation is a learning algorithm for neural networks that seeks to
find weights, T ij, such that given an input pattern from a training set of pairs
of Input/Output patterns, the network will produce the Output of the training
set given the Input. Having learned this mapping between I and 0 for the
training set, one then applies a new, previously unseen Input, and takes the
Output as the ""conclusion"" drawn by the neural net based on having learned
fundamental relationships between Input and Output from the training set. A
popular configuration for backpropagation is a totally feedforward net (Figure
1) where Input feeds up through ""hidden layers"" to an Output layer.

444

OUTPUT

Figure 1.
A feedforward neural
net. Arrows schematically indicate full
feedforward connectivity

Each neuron forms a weighted sum of the inputs from previous layers to
which it is connected, adds a threshold value, and produces a nonlinear function
of this sum as its output value. This output value serves as input to the future
layers to which the neuron is connected, and the process is repeated. Ultimately
a value is produced for the outputs of the neurons in the Output layer. Thus,
each neuron performs:

(1)
where Tii are continuous valued, positive or negative weights, 9. is a constant,
and g(x) is a nonlinear function that is often chosen to be of a sigmoidal form.
For example, one may choose

g(z)

= 2""1 (1 + tanhz)

(2)

where tanh is the hyperbolic tangent, although the exact formula of the sigmoid
is irrelevant to the results.
If t!"") are the target output values for the pth Input pattern then ones trains
the network by minimizing

E

=L
p

L (t~P) - o!P)) 2

(3)

i

where t~p) is the target output values (taken from the training set) and O~pl
is the output of the network when the pth Input pattern of the training set is
presented on the Input layer. i indexes the number of neurons in the Output
layer.
An iterative procedure is used to minimize S. For example, the commonly
used steepest descents procedure is implemented by changing Tii and S, by AT'i
and AS, where

445

~T...
'1

=

aE

--'E

(4a)

aT...
'1

(4b)

This implies that ~E < 0 and hence E will decrease to a local minimum.
Use o~ the chain .rule and definition of some intermediate quantities allows the
followmg expressIons for ~Tij to be obtained (Rumelhart, 1987):
~Tij =

L E6lp)o~.p)

(Sa)

p

(Sb)
where

(6)
if i is labeling a neuron in the Output layer; and

6Jp) = O!p) (1 - o~p?) LTi j 6;p)

(7)

j

if i labels a neuron in the hidden layers. Therefore one computes 6Jp) for the
Output layer first, then uses Eqn. (7) to computer p ) for the hidden layers,
and finally uses Eqn. (S) to make an adjustment to the weights. We remark that
the steepest descents procedure in common use is extremely slow in simulation,
and that a better minimization procedure, such as the classic conjugate gradient
procedure (W. Press, 1986), can offer quite significant speedups. Many applications use bit representations (0,1) for symbols, and attempt to have a neural
net learn fundamental relationships between the symbols. This procedure has
been successfully used in converting text to speech (T. Sejnowski, 1986) and in
determining whether a given fragment of DNA codes for a protein or not (A.
Lapedes, R. Farber, 1987).
There is no fundamental reason, however, to use integer's as values for Input
and Output. If the Inputs and Outputs are instead a collection of floating point
numbers, then the network, after training, yields a specific continuous function
in n variables (for n inputs) involving g(x) (Le. hyperbolic tanh's) that provides
a type of nonlinear, least mean square interpolant formula for the discrete set
of data points in the training set. Use of this formula a = 1(11, 1"", ... 1'1)
when given a new input not in the training set, is then either interpolation or
extrapolation.
Since the Output values, when assumed to be floating point numbers may
have a dynamic range great than 10,1\, one may modify the g(x) on the Output
layer to be a linear function, instead of sigmoidal, so as to encompass the larger
dynamic range. Dynamic range of the Input values is not so critical, however we
have found that numerical problems may be avoided by scaling the Inputs (and

6i

446

also the Outputs) to [0,1], training the network, and then rescaling the Ti;, (J,
to encompass the original dynamic range. The point is that scale changes in
I and 0 may, for feedforward networks, always be absorbed in the T ijJ (J, and
vice versa. We use this procedure (backpropagation, conjugate gradient, linear
outputs and scaling) in the following section to predict points in a chaotic time
series.
3. Prediction
Let us consider situations in Nature where a system is described by nonlinear differential equations. This is faily generic. We choose a particular nonlinear
equation that has an infinite dimensional phase space, so that it is similar to
other infinite dimensional systems such as partial differential equations. A differential equation with an infinite dimensional phase space (i.e. an infinite number
of values are necessary to describe the initial condition) is a delay, differential
equation. We choose to consider the time series generated by the Glass-Mackey
equation:
az(t - 1')
b t

X=

1 + Z 10 (t

_ 1') -

(8)

Z( )

This is a nonlinear differential, delay equation with an initial condition specified
by an initial function defined over a strip of width l' (hence the infinite dimensional phase space i.e. initial functions, not initial constants are required).
Choosing this function to be a constant function, and a = .2, b = .1, and l' = 17
yields a time series, x(t), (obtained by integrating Eqn. (8)), that is chaotic with
a fractal attractor of dimension 2.1. Increasing l' to 30 yields more complicated
evolution and a fractal dimension of 3.5. The time series for 500 time steps for
1'=30 (time in units of 1') is plotted in Figure 2. The nonlinear evolution of the
system collapses the infinite dimensional phase space down to a low (approximately 2 or 3 dimensional) fractal, attracting set. Similar chaotic systems are
not uncommon in Nature.

Figure 2. Example time series at tau

~

30.

447

The goal is to take a set of values of xO at discrete times in some time
window containing times less than t, and use the values to accurately predict
x(t + P), where P is some prediction time step into the future. One may fix
P, collect statistics on accuracy for many prediction times t (by sliding the
window along the time series), and then increase P and again collect statistics
on accuracy. This one may observe how an average index of accuracy changes as
P is increased. In terms of Figure 2 we will select various prediction time steps,
P, that correspond to attempting to predict within a ""bump,"" to predicting
a couple of ""bumps"" ahead. The fundamental nature of chaos dictates that
prediction accuracy will decrease as P is increased. This is due to inescapable
inaccuracies of finite precision in specifying the x( t) at discrete times in the past
that are used for predicting the future. Thus, all predictive methods will degrade
as P is increased - the question is ""How rapidly does the error increase with
P?"" We will demonstrate that the neural net method can be orders of magnitude
more accurate than conventional methods at large prediction time steps, P.
Our goal is to use backpropagation, and a neural net, to construct a function

O(t

+ P)

= f (1 1 (t), 12(t - A) ... lm(t - mA))

(9)

where O(t + P) is the output of a single neuron in the Output layer, and 11 ~ 1m
are input neurons that take on values z(t), z(t - A) ... z(t - rnA), where A is
a time delay. O(t + P) takes on the value x(t + P). We chose the network
configuation of Figure 1.
We construct a training set by selecting a set of input values:

(10)

1m = x(t p

-

rnA)

with associated output values 0 = x(tp + P), for a collection of discrete times
that are labelled by tp. Typically we used 500 I/O pairs in the training set
so that p ranged from 1~ 500. Thus we have a collection of 500 sets of
{lip), l~p), ... , 1::); O(p)} to use in training the neural net. This procedure of
using delayed sampled values of x{t) can be implemented by using tapped delay lines, just as is normally done in linear signal processing applications, (B.
Widrow, 1985). Our prediction procedure is a straightforward nonlinear extension of the linear Widrow Hoff algorithm. After training is completed, prediction
is performed on a new set of times, t p, not in the training set i.e. for p = 500.
We have not yet specified what m or A should be, nor given any indication
why a formula like Eqn. (9) should work at all. An important theorem of Takens
(Takens, 1981) states that for flows evolving to compact attracting manifolds of
dimension d.A"" that a functional relation like Eqn. (9) does exist, and that m
lies in the range d.A, < m + 1 < 2d.A, + 1. We therefore choose m 4, for T 30.
Takens provides no information on A and we chose A = 6 for both cases. We
found that a few different choices of m and A can affect accuracy by a factor of 2 a somewhat significant but not overwhelming sensitivity, in view of the fact that
neural nets tend to be orders of magnitude more accurate than other methods.
Takens theorem gives no information on the form of fO in Eqn. (9). It therefore

=

=

448

is necessary to show that neural nets provide a robust approximating procedure
for continuous fO, which we do in the following section. It is interesting to note
that attempts to predict future values of a time series using past values of x(t)
from a tapped delay line is a common procedUre in signal processing, and yet
there is little, if any, reference to results of nonlinear dynamical systems theory
showing why any such attempt is reasonable.
After trainin, the neural net as described above, we used it to predict 500
new values of x(tJ in the future and computed the average accuracy for these
points. The accuracy is defined to be the average root mean square error, divided
by a constant scale factor, which we took to be the standard deviation of the
data. It is necessary to remove the scale dependence of the data and dividing by
the standard deviation of the data provides a scale to use. Thus the resulting
""index of accuracy"" is insensitive to the dynamic range of x( t).
As just described, if one wanted to use a neural net to continuously predict
x(t) values at, say, 6 time steps past the last observed value (i.e. wanted to
construct a net predicting x( t + 6)) then one would train one network, at P
= 6, to do this. If one wanted to always predict 12 time steps past the last
observed x( t) then a separate, P = 12, net would have to be trained. We, in
fact, trained separate networks for P ranging between 6 and 100 in steps of 6.
The index of accuracy for these networks (as obtained by computing the index
of accuracy in the prediction phase) is plotted as curve D in Figure 3. There
is however an alternate way to predict. If one wished to predict, say, x(t + 12)
using a P = 6 net, then one can iterate the P = 6 net. That is, one uses the
P
6 net to predict the x(t +6) values, and then feeds x(t +6) back into the
input line to predict x(t + 12) using the predicted x(t + 6) value instead of
the observed x(t + 6) value. in fact, one can't use the observed x(t +6) value,
because it hasn't been observed yet - the rule of the game is to use only data
occurring at time t and before, to predict x( t + 12). This procedure corresponds
to iterating the map given by Eqn. (9) to perform prediction at multiples of P.
Of course, the delays, ~, must be chosen commensurate with P.
This iterative method of prediction has potential dangers. Because (in our
example of iterating the P = 6 map) the predicted x(t + 6) is always made
with some error, then this error is compounded in iteration, because predicted,
and not observed values, are used on the input lines. However, one may predict more accurately for smaller P, so it may be the case that choosing a very
accurate small P prediction, and iterating, can ultimately achieve higher accuracy at the larger P's of interest. This tUrns out to be true, and the iterated
net method is plotted as curve E in Figure 3. It is the best procedure to use.
Curves A,B,C are alternative methods (iterated polynomial, Widrow-Hoff, and
non-iterated polynomial respectively. More information on these conventional
methods is in (Lapedes and Farber, 1987) ).

=

449
C B

A

1

D

E

1
I,
/'

,:

~

!I:

.8
/
I

/ "" \f:J
:

/

I
I
I
I
I
I
I
I
I
I
I
I

I .. ,,:

.6

I
I

. .',

~
~

~

-=

,

.4

I

,

,
I

I

.2

o

o

P1-~~ictlon ~~.

P
Figure 3.

(T.U3~

30)

400

4. Why It Works
Consider writing out explicitly Eqn. (9) for a two hidden layer network
where the output is assumed to be a linear neuron. We consider Input connects
to Hidden Layer 1, Hidden Layer 1 to Hidden Layer 2, and Hidden Layer 2 to
Output, Therefore:

Recall that the output neurons a linear computing element so that only two gOs
occur in formula (11), due to the two nonlinear hidden layers. For ease in later
analysis, let us rewrite this formula as

Ot =

L TtJcg (SU Mle + Ole) + Ot

(12a)

Ie tH 2

where

(12b)

450

The T's and (Ps are specific numbers specified by the training algorithm,
so that after training is finished one has a relatively complicated formula (12a,
12b) that expresses the Output value as a specific, known, function of the Input
values:
Ot == 1(117 12,"" .lm).

A functional relation of this form, when there is only one output, may be
viewed as surface in m + 1 dimensional space, in exactly the same manner
one interprets the formula z == f(x,y) as a two dimensional surface in three
' dimensional space. The general structure of fO as determined by Eqn. (12a,
12b) is in fact quite simple. From Eqn. (12b) we see that one first forms a sum
of gO functions (where gO is s sigmoidal function) and then from Eqn. (12a)
one (orms yet another sum involving gO functions. It may at first be thought
that this special, simple form of fO restricts the type of surface that may be
represented by Ot = f(Ii)' This initial tl.ought is wrong - the special form of
Eqn. (12) is actually a general representation for quite arbitrary surfaces.
To prove that Eqn. (12) is a reasonable representation for surfaces we
first point out that surfaces may be approximated by adding up a series of
""bumps"" that are appropriately placed. An example of this occurs in familiar
Fourier analysis, where wave trains of suitable frequency and amplitude are
added together to approximate curves (or surfaces). Each half period of each
wave of fixed wavelength is a ""bump,"" and one adds all the bumps together to
form the approximant. Let us noW see how Eqn. (12) may be interpreted as
adding together bumps of specified heights and positions. First consider SUM k
which is a sum of g( ) functions. In Figure (4) we plot an example of such a gO
function for the case of two inputs.

Figure 4. A sigmoidal surface.

451

The orientation of this sigmoidal surface is determined by T sit the position by
8;'1 and height by T""'i. Now consider another gO function that occurs in SUM"",.
The 8;, of the second gO function is chosen to displace it from the first, the Tii
is chosen so that it has the same orientation as the first, and T ""'i is chosen to
have opposite sign to the first. These two g( ) functions occur in SUM"""" and
so to determine their contribution to SUM"", we sum them together and plot the
result in Fi ure 5. The result is a ridged surface.

Figure 5. A ridge.

Since our goal is to obtain localized bumps we select another pair of gO functions
in SUMk, add them together to get a ridged surface perpendicular to the first
ridged surface, and then add the two perpendicular ridged surfaces together to
see the contribution to SUMk. The result is plotted in Figure (6).

Figure 6. A pseudo-bump .

452

We see that this almost worked, in so much as one obtains a local maxima by
this procedure. However there are also saddle-like configurations at the corners
which corrupt the bump we were trying to obtain. Note that one way to fix
this is to take g(SUMk + Ok) which will, if Ole is chosen appropriately, depress
the local minima and saddles to zero while simultaneously sending the central
maximum
towards 1. The result is plotted in Figure (7) and is the sought___
after
____________________________________________
b~~

Figure 7. A bump.

Furthermore, note that the necessary gO function is supplied by Eqn. (12).
Therefore Eqn. (12) is a procedure to obtain localized bumps of arbitrary height
and position. For two inputs, the kth bump is obtained by using four gO functions from SUMk (two gO functions for each ridged surface and two ridged
surfaces per bump) and then taking gO of the result in Eqn. (12a). The height
of the kth bump is determined by T tJe in Eqn. (12a) and the k bumps are added
together by that equation as well. The general network architecture which corresponds to the above procedure of adding two gO functions together to form a
ridge, two perpendicular ridges together to form a pseudo-bump, and the final
gO to form the final bump is represented in Figure (8). To obtain any number
ot bumps one adds more neurons to the hidden layers by repeatedly using the
connectivity of Figure (8) as a template (Le. four neurons per bump in Hidden
Layer 1, and one neuron per bump in HiClden Layer 2).

453

Figure 8. Connectivity needed
to obtain one bump. Add four
more neurons to Hidden layer
1, and one more neuron to
Hidden Layer 2, for each
additional bump.

One never needs more than two layers, or any other type of connectivity
than that already schematically specified by Figure (8). The accuracy of the
approximation depends on the number of bumps, whIch in turn is specified,
by the number of neurons per layer. This result is easily generalized to higher
dimensions (more than two Inputs) where one needs 2m hiddens in the first
hidden layer, and one hidden neuron in the second layer for each bump.
The argument given above also extends to the situation where one is pro-cessing symbolic information with a neural net. In this situation, the Input
information is coded into bits (say Os and Is) and similarly for the Output. Or,
the Inputs may still be real valued numbers, in which case the binary output
is attempting to group the real valued Inputs into separate classes. To make
the Output values tend toward 0 and lone takes a third and final gO on the
output layer, i.e. each output neuron is represented by g(Ot) where Ot is given
in Eqn. (11) . Recall that up until now we have used hnear neurons on the
output layer. In typical backpropagation examples, one never actually achieves
a hard 0 or 1 on the output layers but achieves instead some value between 0.0
and 1.0. Then typically any value over 0.5 is called 1, and values under 0.5 are
called O. This ""postprocessing"" step is not really outside the framework of the
network formalism, because it may be performed by merely increasing the slope
of the sigmoidal function on the Output layer. Therefore the only effect of the
third and final gO function used on the Output layer in symbolic information
processing is to pass a hyperplane through the surface we have just been discussing. This plane cuts the surface, forming ""decision regions,"" in which high
values are called 1 and low values are called O. Thus we see that the heart of the
problem is to be able to form surfaces in a general manner, which is then cut
by a hyperplane into general decision regions. We are therefore able to conclude
that the network architecture consisting of just two hidden layers is sufficient for
learning any symbol processing training set. For Boolean symbol mappings one
need not use the second hidden layer to remove the saddles on the bump (c.f.
Fig. 6). The saddles are lower than the central maximum so one may choose
a threshold on the output layer to cut the bump at a point over the saddles to
yield the correct decision region. Whether this representation is a reasonable
one for subsequently achieving good prediction on a prediction set, as opposed
to ""memorizing"" a training set, is an issue that we address below.

454

We also note that use of Sigma IIi units (Rummelhart, 1986) or high order
correlation nets (Y.-C. Lee, 1987) is an attempt to construct a surface by a
general polynomial expansion, which is then cut by a hyperplane into decision
regions, as in the above. Therefore the essential element of all these neural net
learning algorithms are identical (Le. surface construction), only the particular
method of parameterizing the surface varies from one algorithm to another. This
geometrical viewpoint, which provides a unifying framework for many neural net
algorithms, may provide a useful framework in which to attempt construction
of new algorithms.
Adding together bumps to approximate surfaces is a reasonable procedure
to use when dealing with real valued inputs. It ties in to general approximation
theory (c.f. Fourier series, or better yet, B splines), and can be quite successful
as we have seen. Clearly some economy is gained by giving the neural net bumps
to start with, instead of having the neural net form its own bumps from sigmoids.
One way to do this would be to use multidimensional Gaussian functions with
adjustable parameters.
The situation is somewhat different when processing symbolic (binary valued) data. When input symbols are encoded into N bit bit-strings then one has
well defined input values in an N dimensional input space. As shown above, one
can learn the training set of input patterns by appropriately forming and placing
bump surfaces over this space. This is an effective method for memorizing the
training set, but a very poor method for obtaining correct predictions on new
input data. The point is that, in contrast to real valued inputs that come from,
say, a chaotic time series, the input points in symbolic processing problems are
widely separated and the bumps do not add together to form smooth surfaces.
Furthermore, each input bit string is a corner of an 2N vertex hypercube, and
there is no sense in which one corner of a hypercube is surrounded by the other
corners. Thus the commonly used input representation for symbolic processing
problems requires that the neural net extrapolate the surface to make a new
prediction for a new input pattern (i.e. new corner of the hypercube) and not
interpolate, as is commonly the case for real valued inputs. Extrapolation is
a farmore dangerous procedure than interpolation, and in view of the separated
bumps of the training set one might expect on the basis of this argument that
neural nets would fail dismally at symbol processing. This is not the case.
The solution to this apparent conundrum, of course, is that although it is
sufficient for a neural net to learn a symbol processing training set by forming
bumps it is not necessary for it to operate in this manner. The simplest example of this occurs in the XOR problem. One can implement the input/output
mapping for this problem by duplicating the hidden layer architecture of Figure
(8) appropiately for two bumps ( i.e. 8 hid dens in layer 1, 2 hid dens in layer 2).
As discussed above, for Boolean mappings, one can even eliminate the second
hidden layer. However the architecture of Figure (9) will also suffice.

OUTPUT

Figure 9. Connectivity for XOR

HIDDEN

INPUT

455

Plotting the output of this network, Figure(9), as a function of the two inputs
yields a ridge orientated to run between (0,1) and (1,0) Figure(lO). Thus a
neural net may learn a symbolic training set without using bumps, and a high
dimensional version of this process takes place in more complex symbol processing tasks.Ridge/ravine representations of the training data are considerably
more efficient than bumps (less hidden neurons and weights) and the extended
nature of the surface allows reasonable predictions i.e. extrapolations.

Figure 10
XOR surface

(1, 1)

5. Conclusion.
Neural nets, in contrast to popular misconception, are capable of quite
accurate number crunching, with an accuracy for the prediction problem we
considered that exceeds conventional methods by orders of magnitude. Neural
nets work by constructing surfaces in a high dimensional space, and their operation when performing signal processing tasks on real valued inputs, is closely
related to standard methods of functional ,,-pproximation. One does not need
more than two hidden layers for processing real valued input data, and the accuracy of the approximation is controlled by the number of neurons per layer,
and not the number of layers. We emphasize that although two layers of hidden
neurons are sufficient they may not be efficient. Multilayer architectures may
provide very efficient networks (in the sense of number of neurons and number
of weights) that can perform accurately and with minimal cost.
Effective prediction for symbolic input data is achieved by a slightly different method than that used for real value inputs. Instead of forming localized
bumps (which would accurately represent the training data but would not predict well on new inputs) the network can use ridge/ravine like surfaces (and
generalizations thereof) to efficiently represent the scattered input data. While
neural nets generally perform prediction by interpolation for real valued data,
they must perform extrapolation for symbolic data if the usual bit representations are used. An outstanding problem is why do tanh representations seem to
extrapolate well in symbol processing problema? How do other functional bases
do? How does the representation for symbolic inputs affect the ability to extra~
olate? This geometrical viewpoint provides a unifyimt framework for examimr:

456

many neural net algorithms, for suggesting questions about neural net operation,
and for relating current neural net approaches to conventional methods.
Acknowledgment.
We thank Y. C. Lee, J. D. Farmer, and J. Sidorovich for a number of
valuable discussions.

References
C. Barnes, C. Burks, R. Farber, A. Lapedes, K. Sirotkin, ""Pattern Recognition
by Neural Nets in Genetic Databases"", manuscript in preparation
J. Denker et. al.,"" Automatic Learning, Rule Extraction,and Generalization"",
ATT, Bell Laboratories preprint, 1987
D. Farmer, J.Sidorowich, Phys.Rev. Lett., 59(8), p. 845,1987
H. Haken, Phys. Lett. A53, p77 (1975)
A. Lapedes, R. Farber ""Nonlinear Signal Processing Using Neural Networks:
Prediction and System Modelling"", LA-UR87-2662,1987
Y.C. Lee, Physica 22D,(1986)
R. Lippman, IEEE ASAP magazine,p.4, 1987
D. Ruelle, F. Takens, Comm. Math. Phys. 20, p167 (1971)
D. Rummelhart, J. McClelland in ""Parallel Distributed Processing"" Vol. 1,
M.I.T. Press Cambridge, MA (1986)
D. Russel et al., Phys. Rev. Lett. 45, pU75 (1980)
T. Sejnowski et al., ""Net Talk: A Parallel Network that Learns to Read Aloud,""
Johns Hopkins Univ. preprint (1986)
H. Swinney et al., Physics Today 31 (8), p41 (1978)
F. Takens, ""Detecting Strange Attractor in Turbulence,"" Lecture Notes in Mathematics, D. Rand, L. Young (editors), Springer Berlin, p366 (1981)
K. Tomita et aI., J. Stat. Phys. 21, p65 (1979)

"
60,1987,"The Hopfield Model with Multi-Level Neurons","",60-the-hopfield-model-with-multi-level-neurons.pdf,"Abstract Missing","278

THE HOPFIELD MODEL WITH MULTI-LEVEL NEURONS

Michael Fleisher
Department of Electrical Engineering
Technion - Israel Institute of Technology
Haifa 32000, Israel

ABSTRACT
The Hopfield neural network. model for associative memory is generalized. The generalization

replaces two state neurons by neurons taking a richer set of values. Two classes of neuron input output
relations are developed guaranteeing convergence to stable states. The first is a class of ""continuous"" relations and the second is a class of allowed quantization rules for the neurons. The information capacity for
networks from the second class is fOWld to be of order N 3 bits for a network with N neurons.
A generalization of the sum of outer products learning rule is developed and investigated as well.

? American Institute of Physics 1988

279

I. INTRODUCTION
The ability to perfonn collective computation in a distributed system of flexible structure without
global synchronization is an important engineering objective. Hopfield's neural network [1] is such a
model of associative content addressable memory.
An important property of the Hopfield neural network is its guaranteed convergence to stable states

(interpreted as the stored memories). In this work we introduce a generalization of the Hopfield model by
allowing the outputs of the neurons to take a richer set of values than Hopfield's original binary neurons.
Sufficient conditions for preserving the convergence property are developed for the neuron input output
relations. Two classes of relations are obtained. The first introduces neurons which simulate multi threshold functions, networks with such neurons will be called quantized neural networks (Q.N.N.). The second
class introduces continuous neuron input output relations and networks with such neurons will be called
continuous neural networks (C.N.N.).
In Section II, we introduce Hopfield's neural network and show its convergence property. C.N.N.
are introduced in Section

m and a

sufficient condition for the neuron input output continuous relations is

developed for preserving convergence. In Section IV, Q.N.N. are introduced and their input output relations are analyzed in the same manner as in III. In Section IV we look further at Q.N.N. by using the
definition of information capacity for neural networks of [2] to obtain a tight asymptotic estimate of the
capacity for a Q.N.N. with N neurons. Section VI is a generalized sum of outer products learning for the
Q.N.N. and section VII is the discussion.

n. THE HOPFIELD NEURAL NETWORK
A neural network consists of N pairwise connected neurons. The
states: Xi

i 'th neuron can be in one of two

=-lor Xi =+1. The connections are fixed real numbers denoted by W ij (the connection

from neuron

i

to nelD'On

j ).

Defme the state vector X to be a binary vector whose

i 'th

component

corresponds to the state of the i 'th neuron. Randomly and asynchronously, each neuron examines its input
and decides its next output in the following manner. Let ti be the threshold voltage of the i 'th neuron . If

the weighted sum of the present other N -1 neuron outputs (which compose the

i 'th

neuron input) is

280

greater or equal to ti' the next Xi (xt) is+l. ifnot.Xt is -1. This action is given in (1).

X?+
I

=sgn

N

[ Li
~ W??X
?-t?I ]
IJ J
j=1

(1)

We give the following theorem
Theorem 1 (of (1))
The network described with symmetric (Wij=Wji ) zero diagonal (Wi;=<? connection matrix

W

has the convergence property.

Defme the quantity

1

N N

N

E(X)
~ Li
~ W??X?X?
+ Li
~ t?X?
- =- -2 Li
IJ I J
I
I
i j=1
i=1

(2)

We show that E (X) caD only decrease as a result of the action of the network. Suppose that X k changed

t =Xl +Mk ?the resulting change in E is given by

to X

N

1: WkjXj-tk)

tJ.E = -llXk (

(3)

j=1
(Eq. (3) is correct because of the restrictions on

W).

The term in brackets is exactly the argument of the

sgn function in (1) and therefore the signs of IlXk and the term in brackets is the same (or IlXk =<? and
we get!lE ~ O. Combining this with the fact that E (X) is bounded shows that eventually the network
will remain in a local minimum of E (X). TlUs cornpJetcs the proof.

The technique used in the proof of Theorem 1 is an important tool in analyzing neural networks. A
network with a particular underlying E (X) function can be used to solve optimization problems with

E (K) as the object of optimization.

Thus we see another use of neural networks.

281

m. THE C.N.N.
We ask ourselves the following question: How can we change the sgn function in (1) without affecling the convergence property? The new action rule for the i 'th neuron is
N

X?+=/?[
~ W??X?
,
1 kI
IJ J ]

(4)

j=l
Our attention is focused on possible choices for Ii ('). The following theorem gives a part of the answer.

Theorem 2
The network described by (4) (with symmetric zero diagonal

W)

has the convergence property if

Ii ( .) are strictly increasing and bounded.

Define

(5)

We show as before that E ex) can only decrease and since E is bounded (because of the boundedness of

Ii's) the theorem is proved.
Xj

Usinggi(Xi ) =

Jli-l(u)dU we have
o

(6)

Using the intel111ediate value theorem we gel

282

C

where

C

S;

is

Xk+LlXk

=> IlE SO.

a

point

between

Xk

and

X k +LlXk .

Now,

if

Mk > 0 we

have

= > Ik-I(C) S;fk-1(Xk +Mk ) and the term in brackets is greater or equal to zero

A similar argument holds for Mk

< 0 (of course Mk =0 => llE =0). This comp~etes

the proof.

Some remarks:

(a) Strictly increasing bounded neuron relations are not the whole class of relations conserving the convergence property. This is seen immediately from the fact that Hopfield's original model (1) is not in this
class.

(b) The

E (X) in the C.N.N. coincides with Hopfield's continuous neural network [3]. The difference

between the two networks lies in the updating scheme. In our C.N.N. the neurons update their outputs at
the moments they examine their inputs while in [3] the updating is in the form of a set of differential equations featuring the time evolution of the network outputs.
(c) The boundedness requirement of the neuron relations results from the boundedness of

E (K).

It is

possible to impose further restrictions on W resulting in unbounded neuron relations but keeping E (X)
bounded (from below). This was done in [4] where the neurons exhibit linear relations.

IV. THE Q.N.N.
We develop the class of quantization rules for the neurons, keeping the convergence property.
Denote the set of possible neuron outputs by

t 1 < t 2 < ... < tn

Yo < Y 1 < ... < Yn

and the set of threshold values by

the action of the neurons is given by

xt = Y/

N

if t/ <

L

W;jXj

~ tl+l I=O, ... ,n

j=1

The following theorem gives a class of quantization rules with the convergence property.

(8)

283

Theorem 3
An.y quantization rule for the neurons which is an increasing step functioo that is

Yo<Y 1 < . .. y n',t 1 < ... <tn
Yields a network with the convergence property (with a

(9)

W symmetric and zero diagonal).

We proceed to prove.

Define

(10)

where G (X) is a piecewise linear convex

U function defined by the relation
(11)

As before we show M

~ O. Suppose a change occurred in Xk such thatXk =Yi - 1.Xt=yi . We then

have

(12)

A similar argument follows when Xk =Yi ,Xk+=Yi - 1
with

< Xk .

Any bigger change in Xk (from

Yi

to Yj

I i - j I > 1) yields the same result since it can be viewed as a sequence of I i - j I changes from Yi

to Yj each resulting in M ~O. The proof is completed by noting that LlX'e=O=>M =0 and

bounded.

E (X) is

284

CorollaIy
Hopfield's original model is a special case of (9).

V. INFORMATION CAPACITY OF THE Q.N.N.
We use the definition of [2] for the information capacity of the Q.N.N.

Definition 1
The information capacity of the Q.N.N. (bits) is the

log (Base 2) of the number of distinguishable

networks of N neurons. Two networks are distinguishable if observing the state transitions of the neurons
yields different observations. For Hopfield's original model it was shown in [2] that the capacity
network of N neurons is bounded by

C ~ Q(N 3)b

C ~ log (2(N-l)2f = O(N 3)b.

C

of a

It was also shown that

and thus is exactly of the order N 3b. It is obvious that in our case (which contains the

original model) we must have

C ~ Q(N 3)b

as well (since the lower bound cannot decrease in this

richer case). It is shown in the Appendix that the number of multi threshold functions of N -1 variables
with

n+l

oUlput levels is at most (n+lf 2+N +1 since we have

( (n+lf2+N +1f

N

neurons there will be

distinguishablenetworlcs and thus

(14)
01

as before,

C

is exactly of O(N 3)b. In fact, the rise in

C

is probably a faclOr of O(log2n) as can be

seen from the upper bound.

VI. ""OUTER PRODUCT"" LEARNING RULE
For Hopfleld's origiDal network with two state neurons (taking the values
sively investigated

?1) a nalw-al and exten-

rl.t 1.? ] learning rule is the so called sum of outer products construction.

1 K 1 1
W1).. =N- ~
~ X?X?
(15)
1 )
1=1
where Xl, ... , X K are the desired stable states of the network. A well-known result for (15) is that the
asymplOtic capacity K of the network is

285

K= N-l +1

(16)

410gN

In this section we introduce a natural generalization of (15) and prove a similar result for the asymp-

totic capacity. We first limit the possible quantization rules to:

(17)

with

Yo < ... < Yn

t.=~(y.+y.
IJ
J
2
J
J-

j=l, ... n

with

(b)

n+l is even
V i Yi -:# 0

(c)

y.I =-yn-l.

(a)

i=O, ... ,n

NeAt we state that the desired stable vectors Xl, . . . X K are such that each component is picked
independently at random from ( Yo

' . . . YM

} with equal probability. Thus. the K

?N

components of

the X 's are zero mean i.i.D random variables. Our modified learning rule is

w.. = -L
~ X!. [_1
]
N ~
Xl
IJ

1=1

Note that for Xi E
Define

I

(+1, -I}

j

(18) is identical to (16).

(18)

286

;~~

IYi -Yjl

l?oJ

A

= max
iJ

IY.12
l

IYj I

We state that
PROPOsmON:

The asymptotic capacity of the above network is given by

N
K=----16A 2 logN

,..,

(19)

(6y)2
PROOF:

Def""me

P (K , N) = Pr

{

vectors chosen randomly as deSCribed}
are stable states with the W of ( )

K

(20)

where Aij is the event that the i th component of j th vector is in error. We concentrate on the event All
W.L.G.

The input u 1 when X' is presented is given by

(21)

The first term is mapped by (17) into itself and corresponds to the desired Signal.
The last term is a sum of (K -1 )(N -1) i.i.D zero mean random variables and corresponds to

noise.

287

The middle term

K-l
1
-N X 1

choice of W (using (18) with

Pr (A 11) =Pr

is disposed of by assuming

K-l
-N

~ O. (With a zero diagonal
N -+00

*'

i j) this term does not appear).

noise gets us out of range }
Denoting the noise by I we have
{

(22)

(K -1)(N-l)4A 2
where the first inequality is from the defmition of .1Yand the second uses the lemma of [6] p. 58. We thus
get

,..,
P (K , N)

~

1 - K ? N . 2exp -

substituting (19) and taking N ~

00

(,1Y)2N 2

-~---'---~

(23)

8(K -l)(N-l)A 2

we get P (K , N) ~

1 and this completes the proof.

Vll. DISCUSSION
Two classes of generalization of the Hopfield neural network model were presented. We give some
remarks:

(a) Any combination of neurons from the two classes will have the convergence property as well.
(b) Our defmition of the information capacity for the eN.N. is useless since a full observation of the pos?

sible state transitions of the netwock is impossible.

288

APPENDIX

We prove the following theorem.
Theorem
An upper bound on the num~ of multi threshold functions with N inputs and M points in the

domain (out of(n+l)N possible points)

et/ is the solution of the recurrence relation

eNM --

M - 1 + n ?C M - 1
CN
N-l

(A.I)

Let us look on the N dimensional weight space W. Each input point X divides the weight space
N

into n+l regions by n parallel hyperplanes

L

W;X;=tk k=l, ... ,n. We keep adding points in such

;=1
a way that the new n hypeq>1anes corresponding to each added point partition the W space into as many
regions as possible. Assume M -1 points have made
hyperplane (out of n) is divided into at most

et! -I regions and we add the M 'lh point. Each

Cf/_l1 region, (being itself an N -1

dimensional space

divided by (M -1)n hyperlines). We thus have after passing the n hyperplanes:

eNM -is

A1 - 1
CNM - I + n ?CN-I

N-l[ M-1]
etI = (n + 1).L
i
n i and the theorem is proved .
? =0

The solution of the recurrence in the case

M =(n + I f

the number of multi threshold functions of N variables equal to

and the result used is established.

(all possible points) we have a bound on

289

LIST OF REFERENCES

[1]

Hopfield J. J. t ""Neural networks and physical systems with emergent collective computational abilities"", Proc. Nat. Acad. Sci. USA, Vol. 79 (1982), pp. 2554-2558.

[2]

Abu-Mostafa Y.S. and Jacques J. St, ""lnfonnation capacity of the Hopfield model"", IEEE Trans. on
Info. Theory, Vol. IT-31 (1985. ppA61-464.

[3]

Hopfield J. J., ""Neurons with graded response have collective computational properties like those of
two state neurons"", Proc. Nat. Acad. Sci. USA, Vol. 81 (1984).

[4]

Fleisher M., ""Fast processing of autoregressive signals by a neural network"", to be presented at IEEE
Conference, Israel 1987.

[5]

Levin, E., Private communication.

[6]

Pettov, ""Sums of independent random variables"".

"
61,1987,"HOW THE CATFISH TRACKS ITS PREY: AN INTERACTIVE ""PIPELINED"" PROCESSING SYSTEM MAY DIRECT FORAGING VIA RETICULOSPINAL NEURONS","",61-how-the-catfish-tracks-its-prey-an-interactive-pipelined-processing-system-may-direct-foraging-via-reticulospinal-neurons.pdf,"Abstract Missing","402

HOW

THE

PROCESSING

CATFISH TRACKS ITS PREY: AN INTERACTIVE ""PIPELINED""
SYSTEM MAY DIRECT FORAGING VIA RETlCULOSPINAL NEURONS.

Jagmeet S. Kanwal
Dept. of Cellular & Structural Biology, Univ. of Colorado, Sch. of
Medicine, 4200 East, Ninth Ave., Denver, CO 80262.
ABSTRACT
Ictalurid catfish use a highly developed gustatory system to
localize, track and acquire food from their aquatic environment.
The neural organization of the gustatory system illustrates well
the
importance
of
the
four
fundamental
ingredients
(representation, architecture, search and knowledge) of an
""intelligent"" system.
In addition, the ""pipelined"" design of
architecture illustrates how a goal-directed system effectively
utilizes interactive feedback from its environment.
Anatomical
analysis
of
neural networks involved in
target-tracking
indicated that reticular neurons within the medullary region of
the
brainstem,
mediate connections between the gustatory
(sensory) inputs and the motor outputs of the spinal cord.
Electrophysiological
analysis suggested that these neurons
integrate selective spatio-temporal patterns of sensory input
transduced through a rapidly adapting-type peripheral filter
(responding tonically only to a continuously increasing stimulus
concentration).
The connectivity and response patterns of
reticular cells and the nature of the peripheral taste response
suggest a unique ""gustation-seeking"" fUnction of reticulospinal
cells, which may enable a catfish to continuously track a
stimulus source once its directionality has been computed.
INTRODUCTION
Food search is an example of a broad class of behaviors
generally classified as goal-directed behaviors.
Goal-directed
behavior is frequently exhibited by animals, humans and some
machines.
Although a preprogrammed, hard-wired machine may achieve
a particular goal in a relatively short time, the general and
heuristic nature of complex goal-directed tasks, however, is best
exhibited by animals and best studied in some of the less advanced
animal species,
such as fishes,
where anatomical,
electrophysiological and behavioral analyses can be performed relatively
accurately and easily.
Food search, which may lead to food acquisition and ingestion,
is critical for the survival of an organism and, therefore, only
highly successful systems are selected during the evolution of a
species. The act of food search may be classified into two distinct
phases, (i) orientation, and (ii) tracking (navigation and homing).
In the channel catfish (the animal model utilized for this study),
locomotion (swimming) is primarily controlled by the large forked
caudal fin, which also mediates turning and directional swimming.

@ American Institute of Physics 1988

403

Both these forms of movement, which constitute the essential
movements
of
target-tracking,
involve
control
of
the
hypaxial/epiaxial muscles of the flank.
The alternate contraction
of these muscles causes caudal fin undulations.
Each cycle of the
caudal
fin undulation provides either a symmetrical
or
an
asymmetrical bilateral thrust.
The former provides a net thrust
forward, along the longitudinal axis of the fish causing it to move
ahead, while the latter biases the direction of movement towards the
right or left side of the fish.

HRP injection site
1 /recording site

*A

................................... ........................... ......................... NEUROBIOLOGY ...... ....................................
fEEDING BEHAVIOR

MUSCLE SET

MOTOR POOLS PREMOTOR NEURONS

GUSTATORY INPUTS

....................................... ..............................................................................................................................
food Search

1

Pick Up

flank and
Tail Fi n
Muscles

Caudal
Reticular
Spinal
VCord > .....""...... f orma tl on

:

:.... u.

flank
Mu:sculature
Ja'W Muscles

I

facial lobe

> ......_..............
I

II .... UIlIl ..... "" _....................... , . , . .. UIl. U Il ........... _WI ......... 111111 ... ' .

Rostral
Spinal Cord

Reticular
f
t?
orma Ion

facial lobe

Vagal lobe
Intrl nsic
Interneurons

Vagal lobe

>.........
I .....

> ........_..............
facial and/or > ..........................................._..._J....._. . .__?

Trigeminal
Motor Nucleus
,~

Selective
Ingestion

Oral and
Pharyngeal
Musculature

Vagal Motor
Nuclei

Fig. 1.
Schematic representation of possible pathways
gustatory modulation of foraging in the catfish.

for

the

404

Ictalurid catfishes possess a well developed gustatory system
and
use it to locate and acquire food from their
aquatic
environmentl,2,~ Behavioral evidence also indicates that ictalurid
catfishes can
detect small intensity (stimulus
concentration)
differences
across
their
barbels
(interbarbel
intensity
differences), and may use this or other extraoral taste information
to compute the directionality in space and track a gustatory
stimulus source 1
In other words, based upon the analysis of
locomotion, it may be inferred that during food search, the
gustatory sense of the catfish influences the duration and degree of
asymmetrical or symmetrical undulations of the caudal fin, besides
controlling reflex turns of the head and flank.
Since directional
swimming is ultimately dependent upon movement of the large caudal
fin it may be postulated that, if the gustatory system is to
coordinate food tracking, gustato-spinal connections exist upto the
level of the caudal fin of the catfish (fig. 1).
The objectives of this study were (i) to reconsider the
functional
organization
of the gustatory system within
the
costraints of the four fundamental ingredients (representation,
architecture, search and knowledge) of a naturally or artificially
""intelligent"" agent,
(ii) to test the existence of the postulated
gustato-spinal connections, and (iii) to delineate as far as
possible, using neuroanatomical and electrophysiological techniques,
the neural mechanism/s involved in the control of goal-directed
(foraging) behavior.

ORGANIZATIONAL CONSIDERATIONS
I. REPRESENTATION
Representation refers to the translation of a particular task
into information structures and information processes and determines
to a great extent the efficiency and efficacy with which a solution
to the task can be generate<i4.
The elaborate and highly sensitive
taste system of an ictalurid catfish consists of an extensive array
of chemo- and mechanosensory receptors distributed over most of the
extraoral
as
well
as oral regions of
the
epithelium2, 5.
Peripherally, branches of the facial nerve (which innervates all
extraoral taste buds) re~ond to a wide range of stimulus (amino
acids) concentrationEP, 7 , l:Si..e. from 10-% to 10-3 M.
The taste
activity however, adapts rapidly (phasic response) to ongoing
stimulation of the same concentration (Fig.
2) and responds
tonically only to continuously increasing concentrations of stimuli,
such as L-arginine and L-alanine.
rp
ros

Fig.:t. Integrated, facial taste recordings to continuous application of amino acids to the palate and nasal barbel showing the
phasic nature of the taste responses of the ramus palatinus (rp)
and ramus ophthalmicus superficialis (ros), respectively .

405

Gustatory information from the extraoral and oral epithelium is
""pipelined""
into
two
separate
subsystems,
facial
and
glossopharyngeal-vagal, respectively.
Each sUbsystem processes a
subset
of the incoming information
(extraoral or oral) and
coordinates a different component of food acquisition.
Food search
is accomplished by the extraoral subsystem,
while
selective
2
ingestion is accomplished by the oral subsystem
(Fig. 3).
The
extraoral gustatory information terminates in the facial lobe where
it is represented as a well-defin~d topographic map 9,10 , while the
oral information terminates in the adjacent vagal lobe where it is
represented as a relatively diffuse map 11.
II. ARCHITECTURE
The
information represented in an information
structure
eventually requires an operating frame (architecture) within which
to select and carry out the various processes. In ictalurid catfish,
partially processed information from the primary gustatory centers
(facial and vagal lobes) in the medullary region of the brainstem
converges along ascending and descending pathways (Fig. 4). One of
the centers in the ascending pathways is the secondary gustatory
nucleus
in
the isthmic region which is connected
to
the
corresponding
nucleus
of
the opposite side
via
a
large
commissurel 2 ,13.
Facial and vagal gustatory information crosses
over to the opposite side via this commissure thus making it
possible for neurons to extract information about interbarbel or
interflank intensity differences.
Although neurons in this region
are known to have large receptive fields 14 , the exact function of
this large commissural nucleus is not yet clearly established.
It is quite clear, however, that gustatory information is at
first ""pipelined"" into separate regions where it is processed in
parallel 15 before converging onto neurons in the ascending (isthmic)
and descending (reticular) processors as well as other regions
within the medulla.
The ""pipelined"" architecture underscores the
need for differential processing of subsets of sensory inputs which
are consequently integrated to coordinate temporal transitions
between the various components of goal-directed behavior.
III. SEARCH
An important task underlying all ""intelligent"" goal directed
activity is that of search.
In artificial systems this involves
application of several general problem-solving methods such as
means-end analysis, generate and test methods and heuristic search
methods.
No attempt, as yet, has been made to fit any of these
models to the food-tracking behavior of the catfish.
However,
behavioral
observations
suggest
that the
catfish
uses
a
combinatorial approach resulting in a different yet optimal foraging
strategy each time ~
What is interesting about biological models is that the
intrinsic search strategy is expressed extrinsically by the behavior
of the animal which, with a few precautions, can be observed ~uite
easily. In addition, simple manipulations of either the animal or
its environment can provide interesting data about the search

406

SENSORY

BRA IN

INPUT

Ie xtra

5

t
e

-=-=b

(0 r a I)

-

..?: .-

~
~I'- ?

-.

t

-.

,

\

__

"",to

u
d
s

Jr

VII

~ ac l al

lobe

p

IX
X

vagal
lobe

~~~~~

~~v~ ?(!l](L~~
[pl~??~~~?(:l

? __

~!pa~Cil[1.
!p[3C!J(!J~~~C!J(3

Fig. 4.

OUT PUT

r--:r
a

I-ora I

Fig. 3.

BEHAVIORAL

F ISH

food

searc h
and
DIe k uO

selectIve
IngestIon

I

407

strategy/ies being used by the animal, which in turn can highlight
some of the computational (neuronal) search strategies adopted by
the brain e.g. the catfish seems to minimize the probability of
failure by continuously interacting with the environment so as to be
able to correct any computational or knowledge-based errors.
IV. KNOWLEDGE
If
an ""intelligent"" goal-directed system resets to zero
knowledge before each search trial, its success would depend
entirely upon the information obtained over the time period of a
search.
Such a system would also require a labile architecture to
process the varying sets of information generated during each
search. For such a system, the solution space can become very large
and given the constraints of time (generally an important cri te:don
in biological systems) this can lead to continuous failure.
For
these reasons, knowledge becomes an important ingredient of an
""intelligent"" agent since it can keep the search under control.
For the gustatory system of the catfish
too,
randomly
accessable knowledge, in combination with the immediately available
information about the target, may playa critical role in the
adoption of a successful search strategy.
Although a significant
portion of this knowledge is probably learned, it is not yet clear
where and how this knowledge is stored in the catfish brain.
The
reduction in the solution space for a catfish which has gradually
learned to find food in its environment may be attributed to the
increase in the amount of knowledge, which to some extent may
involve a restructuring of the neural networks during development.
EXPERIMENTAL METHODS
The methods employed for the present study are only briefly
introduced here.
Neuroanatomical tracing techniques exploit the
phenomenon of axonal transport. Crystals of the enzyme, horseradish
peroxidase (HRP) or some other substance, when injected at a small
locus in the brain, are taken up by the damaged neurons and
transported anterogradely and retrogradely from cell bodies and/or
axons at the injection site.
In the present study,
small
superficial injections of HRP (Sigma, Type VI) were made at various
loci in the facial lobe (FL) in separate animals.
After a survival
period of 3 to 5 days, the animals were sacrificed and the brains
sectioned and reacted for visualization of the neuronal tracer.
In
this manner, complex neural circuits can be gradually delineated.
Electrophysiological recordings from neurons in the central
nervous system were obtained using heat-pulled glass micropipettes.
These glass electrodes had a tip diameter of approximately 1 um and
an impedance of less than 1 megohm when filled with an electrolyte
(3M KCl or 3M Nacl).
Chemical stimulation of the receptive fields was accomplished
by injection of stimuli (amino acids, amino acid mixtures and liver
or bait-extract solutions) into a continuous flow of well-water over
the receptive epithelium.
Tactile stimulation was performed by
gentle strokes of a sable hair brush or a glass probe.

408

EXPERIMENTAL OBSERVATIONS
Injections of HRP into the spinal cord labelled two relevant
populations of cells, (i) in the ipsilateral reticular formation at
the level of the facial lobe (FL), and (ii) a few large scattered
cells within the ipsilateral, rostral portion OI the lateral lobule
of the FL (Fig. 5). Injection of HRP at several sites within the FL
resulted in the identification of a small region in the FL from
where anterogradely filled fibers project to the reticular formation
(Fig. 5).
Superimposition of these injection sites onto the
anatomical map OI the extraoral surface of the catfish indicated
that this small region, within the facial lobe, corresponds to the
snout region of the extraoral surface.
FACIO-RETICULAR PROJECTIONS

FACIO- & RETICULO -SPINAL PROJECTIONS

injection site

?r

1

aID
SpC

1

,

injection site

2

3

CB =cerebellum
LL =lateral line lobe
Fig. 5. Schematic chartings showing
labelled-cell bodies(squares) and fibers
transverse sections through the medulla.

4

-

(dots)

in

409

FL

facial lobe
RF = reticular formation
SpC= spinal cord
VL = vagal lobe

Fl

=

VL
\.
Qjg LlP~ ~PC
FLANK

RF

SNOUT

~---------~
Fig. 6A.

WATER SaUIRT -HEAD ?

+

GLIDING TOUCH -FLANK

!III1/1 III11I11 J11I11II
LIVER EXTRACT

-SNOUT

IIHI~I J+~ ,. 'I I I I ! II

r

1-,'1 1?1l(I
UJi!
-iJ,l"" ILL !~~ I I I I
'?n
ill'!Pll r~1""r MIl?l """", i II

I I , I? J.
I L
I~

if

I,II

1/' II""11'
I'//1I I,. II

AMINO ACID MIXTURE ?

(Receptive
fields)

(Sample unit responses)

LI.J 11111,ltll!,llllliltUII.I~I'III~UII AU) Jlldll,IIIl~lIijkml!II,1.
:

CONTROL

IJ,[ I!11111,11II1"".!L

?

til.llluI1Inlll.h!LIIIII,hll, 1,1/L . I LI ~ iLL.! L..IJ"" ,1.
AMINO ACID MIXTURE

J ./,

,I lJ

,1,1 \ L [1.. 1"" 1,1,1./ d ,II ""I..I1LLLlL/.i.LLU~LUt

"" ijl,ldqllljl,lJJ\lL,~Lld 1""ltH! I~d II~ 1,,1
TOUCH -SNOUT

I ... ? .

, 11,1"" I Lt J iJ,tt.i

? -SNOUT

LlLlII t LI

?

J
""

1 I

?.d.?' ,_J. L.._,I ... ,:!...,J. ..... 1...?.... 1, 1...... 1 UJ"""">1.-I"",,JrlHk', ,Llk.-I

t

Fig. 6B.

"" .+1.1.4.

d II I
Jl;!d.t4.l, .lui,

410

Multiunit
electrophysiological
recordings
from
various
anteroposterior levels of the reticular formation indicated that the
snout region (upper lip and proximal portion of the maxillary
barbels) of the catfish project to a disproportionately large region
of the reticular formation along with a mixed representation of the
flank (Fig. 6A).
Single
unit recordings indicated that some neurons have
receptive fields restricted to a bilateral portion of the snout
region, while others had large receptive fields extending over the
whole flank or over an anteroposterior half of the body (Fig. 6B).
DISCUSSION
The experimental results obtained here suggest that facial lobe
projections to the reticular formation form a functional connection.
The reticular neurons project to the spinal cord and, most likely,
influence
the general cycle of swimming-related activity
of
motoneurons within the spinal cord 16.
The disproportionately large representation of the snout region
within
the
medullary
reticular
formation,
as
determined
electrophysiologically,
is consistent with the anatomical data
indicating that most of the fibers projecting to the reticular
formatirnl originate from cells in that portion of the facial lobe
where the snout region is mapped.
The lateral lobule of the spinal
cord has a second pathway which projects directly into the spinal
cord upto the level of the anterior end of the caudal fin and may
coordinate reflexive turning.
The significance of the present results is best understood when
considered together with previously known information about the
anatomy and electrophysiology of the gustatory
system.
The
information presented above is used to propose a model (Fig. 7) for
a mechanism that may be involved during the homing phase of target
tracking by the catfish.
During homing, which refers to the last
phase of target-tracking during food search, it may be assumed that
the fish is rapidly approaching its target or moving through a steep
signal intensity (stimulus concentration) gradient.
The data
presented above suggest that a neuronal mechanism exists which helps
the catfish to lock on to the target during homing.
This proposal
is based upon the following considerations:
1. Owing to the rapidly adapting response of the peripheral filter,
a tonic level of activity in the facial lobe input can occur only
when the animal is moving through an increasing concentration
gradient of the gustatory stimUlUS.
2. Facial lobe neurons, which receive inputs from the snout region,
project to a group of cells in the reticular formation. Activity in
the facio-reticular pathway causes a suppression in the spontaneous
activity of the reticular neurons.
3. Direct and/or indirect spinal projections from the reticular
neurons are involved in the modulation of activity of those spinal
motoneurons which coordinate swimming. Thus, it may be hypothesized
that during complete suppression of activity in a specific reticulospinal pathway, the fish swims straight ahead, but during excitation

411

of certain reticulospinal neurons the fish
dictated by the pattern of activation.
Fig. 7.
The snout region of
the catfish has special significance
because
of
its
extensive
representation
in the
reticular
formation. In case the fish makes a
random or computational error, while
approaching its target, the snout is
the first region to move out of the
stimulus gradient.

as

.'.

: .:
~.

Thus, the spinal motoneurons, teleologically speaking, ""seek"" a
gustatory
stimulus in order to suppress activity of certain
reticulospinal neurons, which in turn reduce variations in the
pattern
of
activity of swimming-related spinal
motoneurons.
Accordingly, in a situation where the fish is rapidly approaching ~
target, ie. under the specific conditions of a continuously rising
stimulus concentration at the snout region and an absence of a
stimulus intensity difference across the barbels, there is a locking
of the movement of the body (of the fish) towards the stationary or
moving target (food or prey).
It should be pointed out, however, that the empirical data
available so far, only offers clues to the target-tracking mechanism
proposed here. Clearly, more research is needed to validate this
proposal
and to identify other mechanisms of target-tracking
utilized by this biological system.
This research
T.E. Finger.

was supported in part by NIH Grant

NS15258

to

REFERENCES
1.
2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.

P. B. Johnsen and J. H. Teeter, J. Compo Physiol. 140,95 (1981).
J. Atema, Brain Behav. and Evol. 4, 273-294, (1971).
J. E. Bardach, et a1., Science, 155,1276-1278, (1967).
A. Newell, Mc-Graw Hill Encyclopedia of Electronics and
Computers, (1984), p.71-74.
C. J. Herrick, Bull. US. Fish. Comm. 22, 237-272, (1904).
J. Caprio, Compo Biochem. Physiol. 52A, 247-251, (1975).
C. J. Davenport and J. Caprio, J. Compo Physiol. 147, 217 (1982).
J. S. Kanwal and J. Caprio, Brain Res. 406, 105-112, (1987).
T. E. Finger, J. Compo Neurol. 165, 513-526 (1976).
T. Marui and J. Caprio', Brain Res. 231,185-190 (1982).
J. S. Kanwal and J. Caprio, J. Neurobiol. in press, (1988).
C. J. Herrick, J. Compo Neurol. 15, 375-456 (1905).
C. J. Herrick, J. Compo Neurol. 16, 403-440 (1906).
C. F. Lamb and J. Caprio, ISOT, #P70, (1986).
T. E. Finger and Y. Morita, Science, 227, 776-778 (1985).
P. S. G. Stein, Handbook of the Spinal Cord, (Marcel Dekker
Inc., N.Y., 1984), p. 647.

"
62,1987,"Cycles: A Simulation Tool for Studying Cyclic Neural Networks","",62-cycles-a-simulation-tool-for-studying-cyclic-neural-networks.pdf,"Abstract Missing","290
CYCLES: A Simulation Tool for Studying
Cyclic Neural Networks
Michael T. Gately
Texas Instruments Incorporated, Dallas, TX 75265
ABSTRACT
A computer program has been designed and implemented to allow a researcher
to analyze the oscillatory behavior of simulated neural networks with cyclic connectivity. The computer program, implemented on the Texas Instruments Explorer / Odyssey system, and the results of numerous experiments are discussed.
The program, CYCLES, allows a user to construct, operate, and inspect neural
networks containing cyclic connection paths with the aid of a powerful graphicsbased interface. Numerous cycles have been studied, including cycles with one or
more activation points, non-interruptible cycles, cycles with variable path lengths,
and interacting cycles. The final class, interacting cycles, is important due to its
ability to implement time-dependent goal processing in neural networks.
INTRODUCTION
Neural networks are capable of many types of computation. However, the
majority of researchers are currently limiting their studies to various forms of
mapping systems; such as content addressable memories, expert system engines,
and artificial retinas. Typically, these systems have one layer of fully connected
neurons or several layers of neurons with limited (forward direction only) connectivity. I have defined a new neural network topology; a two-dimensional lattice of
neurons connected in such a way that circular paths are possible.
The neural networks defined can be viewed as a grid of neurons with one
edge containing input neurons and the opposite edge containing output neurons
[Figure 1]. Within the grid, any neuron can be connected to any other. Thus
from one point of view, this is a multi-layered system with full connectivity. I
view the weights of the connections as being the long term memory (LTM) of the
system and the propagation of information through the grid as being it's short
term memory (STM).
The topology of connectivity between neurons can take on any number of
patterns. Using the mammalian brain as a guide, I have limit~d the amount of
connectivity to something much less then total. In addition to making analysis
of such systems less complex, limiting the connectivity to some small percentage
of the total number of neurons reduces the amount of memory used in computer
simulations. In general, the connectivity can be purely random, or can form any
of a number of patterns that are repeated across the grid of neurons.
The program CYCLES allows the user to quickly describe the shape of the
neural network grid, the source of input data, the destination of the output data,
the pattern of connectivity. Once constructed, the network can be ""run."" during
which time the STM may be viewed graphically.
? American Institute of Physics 1988

input column

output column

~

~
-00000000000--00000000000--00000000000--

COMMAND WINDOW

..... vJI ...... '_,.lIr _"". .... ;""r ?? ,Ii

-

11.,61 ... ""

~

.??......
I'???????
.
......
? .. ......
? . .........

......'.,
..

~OOOOOOOOOOo--

Alt., GlobM VaN., . .

,. ,

,

~OOOOOOOOOOo--

'nllI./n

""., ,

?? ?.....
... ..
? ..........
?.....
'

'

~OOOOOOOOOOo--

o

000

~O
~O
~O
~O

-000

o

0 0 000-00000-00000-0
0 0 0 0-o 0 0 0 0 0-0 0 0 000--

sample connectivity
pattern -- replicated
across all neurons

t

output column

Figure 1. COMPONENTS OF A CYCLES NEURAL NETWORK

I .,,_

,

'

'

~OOOOOOOOOOo-~O

.,~~,~~
fI/II~"",*- ,~.

IIlIIZIII

u.rou.F_tII'Y

GRAPHICAL DISPLAY WINDOW
HM.
It_,~

......
w_I'
NYlI""

''''' ""

""'~ r .... "" ' _ 0'

"""" ... t_

~

fI'."" .... 11 ... 8' ,,,,,,""

of .... t ' . . ,t .... ,,'

,.._ IN,.,.... .. 0Jf

,..,_t,.,,,,,_01

y. . ,.

1

""J???? ~ , ..

'.Itt,,,,. ,,,_ . rt.,..?,.,
""""'tU.raf' .......

r ...
II,\IIM "" "" _ 1 W .... "", ..,,.. tVf'?""ltJ

w,~,,_

\

USER INTERACTION WINDOW

STI

rus WINDOW

Figure 2. NEURAL NETWORK WORKSTATION INTERFACE

tv

to

I-'

292

IMPLEMENTATION
CYCLES was implemented on a TI Explorer/Odyssey computer system with
8MB of RAM and 128MB of Virtual Memory. The program was written in Common LISP. The program was started in July of 1986, put aside for a while, and
finished in March of 1987. Since that time, numerous small enhancements have
been made - and the system has been used to test various theories of cyclic neural
networks.
The code was integrated into the Neural Network Workstation (NNW), an
interface to various neural network algorithms. The NNW utilizes the window
interface of the Explorer LISP machine to present a consistent command input
and graphical output to a variety of neural network algorithms [Figure 2].
The backpropagation-like neurons are collected together into a large threedimensional array. The implementation actually allows the use of multiple twodimensional grids; to date, however, I have studied only single-grid systems.
Each neuron in a CYCLES simulation consists of a list of information; the
value of the neuron, the time that the neuron last fired, a temporary value used
during the computation of the new value, and a list of the neurons connectivity.
The connectivity list stores the location of a related neuron and the strength of
the connection between the two neurons. Because the system is implemented in
arrays and lists, large systems tend to be very slow. However, most of my analysis
has taken place on very small systems ? 80 neurons) and for this size the speed
is acceptable.
To help gauge the speed of CYCLES, a single grid system containing 100
neurons takes 0.8 seconds and 1235 cons cells (memory cells) to complete one
update within the LISP machine. If the graphics interface is disabled, a test
requiring 100 updates takes a total of 10.56 seconds.
TYPES OF CYCLES
As mentioned above, several types of cycles have been observed. Each of these
can be used for different applications. Figure 3 shows some of these cycles.
1. SIMPLE cycles are those that have one or more points of activation traveling
across a set number of neurons in a particular order. The path length can be
any SIze.
2. NON-INTERRUPTABLE cycles are those that have sufficiently strong connectivity strengths that random flows of activation which interact with the
cycle will not upset or vary the original cycle.
3. VARIABLE PATH LENGTH cycles can, based upon external information,
change their path length. There must be one or more neurons that are always
a part of the path.
4. INTERACTING cycles typically have one neuron in common. Each cycle
must have at least one other neuron involved at the junction point in order to
keep the cycles separate. This type of cycle has been shown to implement a
complex form of a clock where the product of the two (or more) path lengths
are the fundamental frequency.

293

Figure 3. Types of Cycles [Simple and Interacting]

?
?
?
?
?

? ? ? ? ? ? ?
? ? ?
?
?
? ? ?
?
? ? ?
? ? ? ? ? ? ?

*

?
?
?
?
?
?
?

?
?
?
?
?
?
?

?????????
?
?
?
?
?
?
??
??
?????????

?
?
?
?
?
?

Figure 4. Types of Connectivity [Nearest Neighbor and Gaussian]

INPUT

OUTPUT

Intent

Completed

Joint 3 Extended

Move Joint 3

Joint 2 Centered

Move Joint 2

Joint 1 Extended

Move Joint 1

Chuck Opened

Open Chuck

Chuck Closed

Close Chuck

Figure 5. Robot Arm used in Example

294

CONNECTIVITY
Several types of connectivity have been investigated. These are shown in
Figure 4.
1. In TOTAL connectivity, every neuron is connected to every other neuron.
This particular pattern produces very complex interactions with no apparent
stability.
2. With RANDOM connectivity, each neuron is connected to a random number
of other neurons. These other neurons can be anywhere in the grid.
3. A very useful type of connectivity is to have a PATTERN. The patterns can
be of any shape, typically having one neuron feed its nearest neighbors.
4. Finally, the GAUSSIAN pattern has been used with the most success. In this
pattern, each neuron is connected to a set number of nodes - but the selection
is random. Further, the distribution of nodes is in a Gaussian shape, centered
around a point ""forward"" of itself. Thus the flow of information, in general,
moves forward, but the connectivity allows cycles to be formed.
\

ALGORITHM
The algorithm currently being used in the system is a standard inner product
equation with a sigmoidal threshold function. Each time a neuron's weight is to
be calculated, the value of each contributing neuron on the connectivity list is
multiplied by the strength of the connection and summed. This sum is passed
through a sigmoidal thresholding function. The value of the neuron is changed
to be the result of this threshold function. As you can see, the system updates
neurons in an ordered fashion, thus certain interactions will not be observed. Since
timing information is saved in the neurons, asynchron:' could be simulated.
Initially, the weights of the connections are set randomly. A number of interesting cycles have been observed as a result of this randomness. However, several
experiments have required specific weights. To accommodate this, an interface to
the weight matrix is used. The user can create any set of connection strengths
desired.
I have experimented with several learning algorithms-that is, algorithms that
change the connection weights. The first mechanism was a simple Hebbian rule
that states that if two neurons both fire, and there is a connection between them,
then strengthen the strength of that connection. A second algorithm I experimented with used a pain/pleasure indicator to strengthen or weaken weights.
An algorithm that is currently under development actually presets the weights
from a grammar of activity required of the network. Thus, the user can describe
a process that must be controlled by a network using a simple grammar. This
description is then ""compiled"" into a set of weights that contain cycles to indicate
time-independent components of the activity.

295

USAGE
Even without a biological background, it is easy to see that the processing
power of the human brain is far more than present associative memories. Our
repertoire of capabilities includes, among other things: memory of a time line,
creativity, numerous types of biological clocks, and the ability to create and execute complex plans. The CYCLES algorithm has been shown to be capable of
executing complex, time-variable plans.
A plan can be defined as a sequence of actions that must be performed in
some preset order. Under this definition, the execution of a plan would be very
straightforward. However, when individual actions within the plan take an indeterminate length of time, it is necessary to construct an execution engine capable
of dealing with unexpected time delays. Such a system must also be able to abort
the processing of a plan based on new data.
With careful programming of connection weights, I have been able to use
CYCLES to execute time-variable plans. The particular example I have chosen
is for a robot arm to change its tool. In this activity, once the controller receives
the signal that the motion required, a series of actions take place that result in
the tool being changed.
As input to this system I have used a number of sensors that may be found
in a robot; extension sensors in 2-D joints and pressure sensors in articulators.
The outputs of this network are pulses that I have defined to activate motors on
the robot arm. Figure 5 shows how this system could be implemented. Figure
6 indicates the steps required to perform the task. Simple time delays, such as
found with binding motors and misplaced objects are accommodated with the
built in time-independence.
The small cycles that occur within the neural network can be thought of as
short term memory. The cycle acts as a place holder - keeping track of the system's
current place in a series of tasks. This type of pausing is necessary in many ""real""
activities such as simple process control or the analysis of time varying data.
IMPLICATIONS
The success of CYCLES to simple process control activities such as robot arm
control implies that there is a whole new area of applications for neural networks
beyond present associative memories. The exploitation of the flow of activation as
a form of short term memory provides us with a technique for dealing with many
of the ""other"" type of computations which humans perform.
The future of the CYCLES algorithm will take two directions. First, the
completion of a grammar and compiler for encoding process control tasks into a
network. Second, other learning algorithms will be investigated which are capable
of adding and removing connections and altering the strengths of connections
based upon an abstract pain/pleasure indicator.

296

The robot gets a signal
to begin the tool change
process. A cycle is started
that outputs a signal to
the chuck motor.

~.-.-.

-~

? ? ? ? ? ?

....

? ? ? ? ? ?

?

? ? ? ? ? ?

.

? ? ? ? ? ?

~

: : : ;}'\.:-.
...
? ?
? ? ?

.~

? ?:.J. ? ? ?
? .p..~

_. ?

? ? ? ?
? ? ? ? ? ?

Next, the chuck is closed
around the new tool bit.

When the joint indicator
indicates that the joint is
centered, it changes the
flow of activation to cause
a cycle that activates the
third joint.

..?

? ? ? ? ? ?
~.~

~~.

-..~

?

D

?

-.(.:/.: :? ? ? ? ? ?
? ? U
? ? ? ?

The last signal ends the
sequence of cycles and
sends the completed
signal.

? ? ? ? ?

.-

? ? ? ? ? ?

?

? ? ? ? ? ?

? .? . ..-

? ? ? ? ? ?
? ? ? ? ? ?

? / ....

?

? ? ? ? ? ?
. .........
.
-""'.

?

D

When the first joint is
fully extended, the joint
sensor sends a signal
that stops that cycle, and
begins one that outputs
a signal to the second
joint.

? ? ? ? ? ?

? ? ?

? ? ? ? ?
? ? ? ? ? ?

When sensor indicates
that the chuck is open.
the first cycle is stopped
and a second begins
activ<lting the motor
in the first joint.

? ? ? ? ? ?
? ? ? ? ? ?
-.~. ? ?

D

Figure 6. Example use of CYCLES to control a Robot Arm

"
63,1987,"Connectivity Versus Entropy","",63-connectivity-versus-entropy.pdf,"Abstract Missing","1

CONNECTIVITY VERSUS ENTROPY
Yaser S. Abu-Mostafa
California Institute of Technology
Pasadena, CA 91125

ABSTRACT
How does the connectivity of a neural network (number of synapses per
neuron) relate to the complexity of the problems it can handle (measured by
the entropy)? Switching theory would suggest no relation at all, since all Boolean
functions can be implemented using a circuit with very low connectivity (e.g.,
using two-input NAND gates). However, for a network that learns a problem
from examples using a local learning rule, we prove that the entropy of the
problem becomes a lower bound for the connectivity of the network.

INTRODUCTION
The most distinguishing feature of neural networks is their ability to spontaneously learn the desired function from 'training' samples, i.e., their ability
to program themselves. Clearly, a given neural network cannot just learn any
function, there must be some restrictions on which networks can learn which
functions. One obvious restriction, which is independent of the learning aspect,
is that the network must be big enough to accommodate the circuit complexity of the function it will eventually simulate. Are there restrictions that arise
merely from the fact that the network is expected to learn the function, rather
than being purposely designed for the function? This paper reports a restriction
of this kind.
The result imposes a lower bound on the connectivity of the network (number of synapses per neuron). This lower bound can only be a consequence of
the learning aspect, since switching theory provides purposely designed circuits
of low connectivity (e.g., using only two-input NAND gates) capable of implementing any Boolean function [1,2] . It also follows that the learning mechanism
must be restricted for this lower bound to hold; a powerful mechanism can be
? American Institute of Physics 1988

2

designed that will find one of the low-connectivity circuits (perhaps byexhaustive search), and hence the lower bound on connectivity cannot hold in general.
Indeed, we restrict the learning mechanism to be local; when a training sample
is loaded into the network, each neuron has access only to those bits carried by
itself and the neurons it is directly connected to. This is a strong assumption
that excludes sophisticated learning mechanisms used in neural-network models,
but may be more plausible from a biological point of view.
The lower bound on the connectivity of the network is given in terms of
the entropy of the environment that provides the training samples. Entropy is a
quantitative measure of the disorder or randomness in an environment or, equivalently, the amount of information needed to specify the environment. There
are many different ways to define entropy, and many technical variations of this
concept [3]. In the next section, we shall introduce the formal definitions and
results, but we start here with an informal exposition of the ideas involved.
The environment in our model produces patterns represented by N bits
x = Xl ??? X N (pixels in the picture of a visual scene if you will). Only h different
patterns can be generated by a given environment, where h < 2N (the entropy
is essentially log2 h). No knowledge is assumed about which patterns the environment is likely to generate, only that there are h of them. In the learning
process, a huge number of sample patterns are generated at random from the
environment and input to the network, one bit per neuron. The network uses
this information to set its internal parameters and gradually tune itself to this
particular environment. Because of the network architecture, each neuron knows
only its own bit and (at best) the bits of the neurons it is directly connected to
by a synapse. Hence, the learning rules are local: a neuron does not have the
benefit of the entire global pattern that is being learned.
After the learning process has taken place, each neuron is ready to perform
a function defined by what it has learned. The collective interaction of the
functions of the neurons is what defines the overall function of the network. The
main result of this paper is that (roughly speaking) if the connectivity of the
network is less than the entropy of the environment, the network cannot learn
about the environment. The idea of the proof is to show that if the connectivity
is small, the final function of each neuron is independent of the environment,
and hence to conclude that the overall network has accumulated no information
about the environment it is supposed to learn about.

FORMAL RESULT
A neural network is an undirected graph (the vertices are the neurons and the
edges are the synapses). Label the neurons 1"""", N and define Kn C {I"""", N}
to be the set of neurons connected by a synapse to neuron n, together with
neuron n itself. An environment is a subset e C {O,I}N (each x E e is a sample

3

from the environment). During learning, Xl,""', xN (the bits of x) are loaded
into the neurons 1"""", N, respectively. Consider an arbitrary neuron nand
relabel everything to make Kn become {I"""", K}. Thus the neuron sees the
first K coordinates of each x.
Since our result is asymptotic in N, we will specify K as a function of N;
K = a.N where a. = a.(N) satifies limN-+oo a.(N) = 0.0 (0 < 0.0 < 1). Since the
result is also statistical, we will consider the ensemble of environments

e

e=e(N)={eC{O,I}N

I lel=h}

where h = 2~N and /3 = /3(N) satifies limN-+oo /3(N) = /30 (0 < /30 < 1). The
probability distribution on e is uniform; any environment e E e is as likely to
occur as any other.
The neuron sees only the first K coordinates of each x generated by the
environment e. For each e, we define the function n : {O,I}K -+ {O, 1,2,??.}
where
n(al"" .aK) = I{x Eel Xle = ale for k = 1,'"" ,K}I
and the normalized version

The function v describes the relative frequency of occurrence for each of the 2K
binary vectors Xl'"" XK as x = Xl ??? XN runs through all h vectors in e. In other
words, v specifies the projection of e as seen by the neuron. Clearly, veal > 0
for all a E {O,l}K and LaE{O,l}K veal = 1.
Corresponding to two environments el and e2, we will have two functions VI
and V2. IT VI is not distinguishable from V2, the neuron cannot tell the difference
between el and e2' The distinguishability between VI and V2 can be measured
by
1
d(Vl,V2) = - 2: IV1(a) - V2(a) I
2 aE{O,l}K
The range of d(Vb V2) is 0 < d(Vl' V2) < 1, where '0' corresponds to complete
indistinguishability while '1' corresponds to maximum distinguishability. We
are now in a position to state the main result.
Let el and e2 be independently selected environments from according to the
uniform probability distribution. d(Vl' V2) is now a random variable, and we are
interested in the expected value E(d(Vl' V2))' The case where E(d(Vb V2)) = 0
corresponds to the neuron getting no information about the environment, while
the case where E(d(Vb V2)) = 1 corresponds to the neuron getting maximum
information. The theorem predicts, in the limit, one of these extremes depending
on how the connectivity (0. 0) compares to the entropy (/30)'

e

4

Theorem.
1. H Q o > Po
2.

, then limN..... co E (d(VI, V2))
H Q o < Po , then limN..... co E (d(v}, V2))

= 1.
= O.

The proof is given in the appendix, but the idea is easy to illustrate informally. Suppose h = 2 K + 10 (corresponding to part 2 of the theorem). For most
environments e E
the first K bits of x E e go through all 2K possible val10
ues approximately 2 times each as x goes through all h possible values once.
Therefore, the patterns seen by the neuron are drawn from the fixed ensemble of
all binary vectors of length K with essentially uniform probability distribution,
i.e., v is the same for most environments. This means that, statistically, the
neuron will end up doing the same function regardless of the environment at
hand.
What about the opposite case, where h = 2K - 10 (corresponding to part lof
the theorem)? Now, with only 2K - 10 patterns available from the environment,
the first K bits of x can assume at most 2K - 10 values out of the possible 2K
values a binary vector of length K can assume in principle. Furthermore, which
values can be assumed depends on the particular environment at hand, i.e.,
v does depend on the environment. Therefore, although the neuron still does
not have the global picture, the information it has says something about the
environment.

e,

ACKNOWLEDGEMENT
This work was supported by the Air Force Office of Scientific Research under
Grant AFOSR-86-0296.

APPENDIX

In this appendix we prove the main theorem. We start by discussing some

e.

basic properties about the ensemble of environments
Since the probability
we have
distribution on e is uniform and since Ie I =

e:),

2N)-1

Pr(e) = ( h

which is equivalent to generating e by choosing h elements x E {O,l}N with
uniform probability (without replacement). It follows that
Pr(x E e)

h

= 2N

5

Pr(Xl E e , X2 E e)

h

= 2N

h-l
X 2N _

1

and so on.
The functions n and v are defined on K-bit vectors. The statistics of n(a)
(a random variable for fixed a) is independent of a
Pr(n(at}

= m) = Pr(n(a2) = m)

which follows from the symmetry with respect to each bit of a. The same holds
for the statistics of v(a). The expected value E(n(a)) = h2- K (h objects going
into 2K cells), hence E(v(a)) = 2- K . We now restate and prove the theorem.

Theorem.
1. If a o > Po , then limN_oo E (d(vt, V2))
2. If a o < Po , then limN_oo E (d(vt, V2))

= 1.
= 0.

Proof.
We expand E (d(vt, V2)) as follows

where nl and n2 denote nl(O. ??0) and n2(0?? ?0), respectively, and the last step
follows from the fact that the statistics of nl(a) and n2(a) is independent of a.
Therefore, to prove the theorem, we evaluate E(lnl - n21) for large N.
1. Assume a o > Po. Let n denote n(O??? 0), and consider Pr(n = 0). For n to
be zero, all 2N - K strings x of N bits starting with K O's must not be in the
environment e. Hence

Pr(n

h
= 0) = (1 - ) (1 2N

h
2N - 1

) ... (1 -

where the first term is the probability that 0? . ?00

h
2N - 2N - K

f/. e,

+ 1)

the second term is the

6

probability that O? .. 01

~ f

given that

o? .. 00 ~ f,

and so on.

>

(1-

=

(1- h2- N(1- 2- K)-1) 2

2N

_h2N _ K

)'N-K
N- K

> (1 - 2h2- N)2N - K

> 1- 2h2- N 2N - K
= 1- 2h2- K

Hence, Pr(nl = 0) = Pr(n2
E( n2) = h2- K . Therefore,
E(lnl - n2\)

= 0) = Pr(n = 0) > 1 -

"" ""
= LLPr(nl

2h2- K

?

However, E(nl) =

= i,n2 = j)li - jl

i=O;=O

= L""

L"" Pr(nl = i)Pr(n2 = j) Ii -

jl

i=O;=O

> L"" Pr(nl
;=0

= 0)Pr(n2 =

j)j

+ L"" Pr(nl = i)Pr(n2 = O)i
i=O

which follows by throwing away all the terms where neither i nor j is zero (the
term where both i an j are zero appears twice for convenience, but this term is
zero anyway).
= Pr(nl = 0)E(n2) + Pr(n2 = O)E(nl)
> 2(1 - 2h2- K )h2- K
Substituting this estimate in the expression for E(d(Vb V2)), we get

E(d(vl, V2))

=

2K
2h E(lnl - n21)

2K
x 2(1 - 2h2- K )h2- K
- 2h
= 1- 2h2- K

>-

=1-

2

X 2(,8-a)N

Since a o > 130 by assumption, this lower bound goes to 1 as N goes to infinity.
Since 1 is also an upper bound for d( VI, V2) (and hence an upper bound for the
expected value E(d(vl, V2))) , limN_oo E(d(vl, V2)) must be 1.

7

2. Assume a o <

Po.

Consider

E(lnl - n21)

(I(nl - h2- K ) - (n2 - h2- K )I)
E(\nl - h2- K \ + In2 - h2- K I)

=E
<

= E(\nl = 2E(ln -

h2- K I) + E(ln2 - h2- K I)
h2- K I)

To evaluate E(ln - h2- K I), we estimate the variance of n and use the fact
that E(ln - h2- K I) < ..jvar(n) (recall that h2- K = E(n?). Since var(n) =
E(n 2) - (E(n))2, we need an estimate for E(n 2). We write n = E.E{O,l}N-K 6.,
where
6 - { 1 , if 0 .. ?Oa E e?,
? 0, otherwise.
In this notation, E(n 2 ) can be written as

E(n 2)

=E

(I:

I:

.E{O,l}N-K bE{O,l}N-K

I:

L

6.6t,)

E(6.6t,)

.E{O,l}N-K bE{O,l}N-K
For the 'diagonal' terms (a = b),

E(6.6.)

= Pr(6. = 1)

= h2- N
There are 2 N - K such diagonal terms, hence a total contribution of 2 N h2- N = h2- K to the sum. For the 'off-diagonal' terms (a '# b),

E(6.6b )

K

x

= Pr( 6. = 1,6b = 1)
= Pr(6. = 1)Pr(6b = 116. = 1)
h

h-l

=-x--::-:::-2N
2N_1

There are 2 N - K (2 N - K -1) such off-diagonal terms, hence a total contribution of
2N - K (2 N - K -1) x 2;~:N~1) < (h2-K)2 2~~1 to the sum. Putting the contributions

8

from the diagonal and off-diagonal terms together, we get
2N
E(n 2) < h2- K + (h2-K)2 2N _ 1
var(n)

= E(n 2) -

(E(n))2

< (h2- K + (h2- K )'

2:: 1) - (h2-

K )'

1
= h2- K + (h2 - K )2----:-:-_
2N -1

h2- K )
= h2- K ( 1 + ---:-:-2N -1
< 2h2- K

The last step follows since h2- K is much smaller than 2N -1. Therefore, E(ln1
h2- K I) < vvar(n) < (2h2- K )?i. Substituting this estimate in the expression for
E( d( Vb V2)), we get
2K
E(d(vb V2)) = 2h E(lnl - n21)
2K
< 2h x 2E(ln - h2- K I)
2K
1
< 2h x 2 x (2h2-K)?i
-_ ( 22K)
- ~
h
= v'2 X 2~(Q-~)N

Since a o < Po by assumption, this upper bound goes to 0 as N goes to infinity.
Since 0 is also a lower bound for d(vb V2) (and hence a lower bound for the
expected value E(d(vb V2))), limN_oo E(d(vb V2)) must be O. ?

REFERENCES
[1] Y. Abu-Mostafa, ""Neural networks for computing?,"" AlP Conference Proceedings # 151, Neural Networks for Computing, J. Denker (ed.), pp. 1-6, 1986.
[2] Z. Kohavi, Switching and Finite Automata Theory, McGraw-Hill, 1978.
[3] Y. Abu-Mostafa, ""The complexity of information extraction,"" IEEE Trans.
on Information Theory, vol. IT-32, pp. 513-525, July 1986.
[4] Y. Abu-Mostafa, ""Complexity in neural systems,"" in Analog VLSI and Neural
Systems by C. Mead, Addison-Wesley, 1988.

"
64,1987,"A Trellis-Structured Neural Network","",64-a-trellis-structured-neural-network.pdf,"Abstract Missing","592

A Trellis-Structured Neural Network*
Thomas Petsche t and Bradley W. Dickinson
Princeton University, Department of Electrical Engineering
Princeton, N J 08544

Abstract
We have developed a neural network which consists of cooperatively interconnected Grossberg on-center off-surround subnets and which can be used to
optimize a function related to the log likelihood function for decoding convolutional codes or more general FIR signal deconvolution problems. Connections in
the network are confined to neighboring subnets, and it is representative of the
types of networks which lend themselves to VLSI implementation. Analytical and
experimental results for convergence and stability of the network have been found.
The structure of the network can be used for distributed representation of data
items while allowing for fault tolerance and replacement of faulty units.

1

Introd uction

In order to study the behavior of locally interconnected networks, we have focused
on a class of ""trellis-structured"" networks which are similar in structure to multilayer
networks [5] but use symmetric connections and allow every neuron to be an output.
We are studying such? locally interconnected neural networks because they have the
potential to be of great practical interest. Globally interconnected networks, e.g.,
Hopfield networks [3], are difficult to implement in VLSI because they require many
long wires. Locally connected networks, however, can be designed to use fewer and
shorter wires.
In this paper, we will describe a subclass of trellis-structured networks which optimize a function that, near the global minimum, has the form of the log likelihood
function for decoding convolutional codes or more general finite impulse response signals. Convolutional codes, defined in section 2, provide an alternative representation
scheme which can avoid the need for global connections. Our network, described in
section 3, can perform maximum likelihood sequence estimation of convolutional coded
sequences in the presence of noise. The performance of the system is optimal for low
error rates.
The specific application for this network was inspired by a signal decomposition
network described by Hopfield and Tank [6]. However, in our network, there is an
emphasis on local interconnections and a more complex neural model, the Grossberg
on-center off-surround network [2], is used. A modified form of the Gorssberg model
is defined in section 4. Section 5 presents the main theoretical results of this paper.
Although the deconvolution network is simply a set of cooperatively interconnected
?Supported by the Office of N ava.l Research through grant N00014-83-K-0577 and by the National
Science Foundation through grant ECS84-05460.
tpermanent address: Siemens Corporate Research and Support, Inc., 105 College Road East,
Princeton, N J 08540.

@

American Institute of Physics 1988

593

on-center off-surround subnetworks, and absolute stability for the individual subnetworks has been proven [1], the cooperative interconnections between these subnets
make a similar proof difficult and unlikely. We have been able, however, to prove
equiasymptotic stability in the Lyapunov sense for this network given that the gain
of the nonlinearity in each neuron is large. Section 6 will describe simulations of the
network that were done to confirm the stability results.

2

Convolutional Codes and MLSE

In an error correcting code, an input sequence is transformed from a b-dimensional
input space to an M -dimensional output space, where M ~ b for error correction
and/ or detection. In general, for the b-bit input vector U = (U1, . ?? ,Ub) and the Mbit output vector V = (VI, ... , VM), we can write V = F( U1, . . . ,Ub). A convolutional
code, however, is designed so that relatively short subsequences of the input vector
are used to determine subsequences of the output vector. For example, for a rate 1/3
convolutional code (where M ~ 3b), with input subsequences oflength 3, we can write
the output, V = (VI, ... , Vb) for Vi = (Vi,I, Vi,2, Vi,3), of the encoder as a convolution
of the input vector U = (UI, ... , Ub, 0, 0) and three generator sequences
go = (11 1)

gi = (1 1 0)

g2 = (0 1 1).

This convolution can be written, using modulo-2 addition, as

(1)

Vi=
k=max{I,i-2)

In this example, each 3-bit output subsequence, Vi, of V depends only on three
bits of the input vector, i.e., Vi = I( Ui-2, Ui-I, Ui). In general, for a rate l/n code, the
constraint length, K, is the number of bits of the input vector that uniquely determine
each n-bit output subsequence. In the absence of noise, any subsequences in the
input vector separated by more than K bits (i.e., that do not overlap) will produce
subsequences in the output vector that are independent of each other.
If we view a convolutional code as a special case of block coding, this rate 1/3,
K = 3 code converts a b-bit input word into a codeword of length 3(b + 2) where
the 2 is added by introducing two zeros at the end of every input to ""zero-out"" the
code. Equivalently, the coder can be viewed as embedding 2b memories into a 23{b+2L
dimensional space. The minimum distance between valid memories or codewords in
this space is the free distance of the code, which in this example is 7. This implies
that the code is able to correct a minimum of three errors in the received signal.
For a convolutional code with constraint length K, the encoder can be viewed as
a finite state machine whose state at time i is determined by the K - 1 input bits,
Ui-k, ... , Ui-I. The encoder can also be represented as a trellis graph such as the one
shown in figure 1 for a K = 3, rate 1/3 code. In this example, since the constraint
length is three, the two bits Ui-2 and Ui-I determine which of four possible states the
encoder is in at time i . In the trellis graph, there is a set of four nodes arranged in a
vertical column, which we call a stage, for each time step i. Each node is labeled with
the associated values of Ui-2 and Ui-1. In general, for a rate l/n code, each stage of
the trellis graph contains 2K -1 nodes, representing an equal number of possible states.
A trellis graph which contains S stages therefore fully describes the operation of the
encoder for time steps 1 through S. The graph is read from left to right and the upper
edge leaving the right side of a node in stage i is followed if Ui is a zero; the lower edge

594

stage i-1

stage i-2

stage i

stage i+1

stage i+2
state 1

&000
111

state 2

state 3

101
state 4

&-010

Figure 1: Part of the trellis-code representation for a rate 1/3, K = 3 convolutional
code.
if Ui is a one. The label on the edge determined by Ui is Vi, the output of the encoder
given by equation 1 for the subsequence Ui-2, Ui-I, Ui.
Decoding a noisy sequence that is the output of a convolutional coder plus noise
is typically done using a maximum likelihood sequence estimation (MLSE) decoder
which is designed to accept as input a possibly noisy convolutional coded sequence, R,
and produce as output the maximum likelihood estimate, V, of the original sequence,
V. If the set of possible n(b+2)-bit encoder output vectors is {Xm : m = 1, ... , 2n(b+2)}
and Xm,i is the ith n-bit subsequence of Xm and ri is the ith n-bit subsequence of R
then
b

V = argmax II P(ri I Xm,i)
Xm

(2)

i=l

That is, the decoder chooses the Xm that maximizes the conditional probability, given .
X m , of the received sequence.
A binary symmetric channel (BSC) is an often used transmission channel model in
which the decoder produces output sequences formed from an alphabet containing two
symbols and it is assumed that the probability of either of the symbols being affected
by noise so that the other symbol is received is the same for both symbols. In the
case of a BSC, the log of the conditional probability, P( ri I Xm,i), is a linear function
of the Hamming distance between ri and Xm,i so that maximizing the right side of
equation 2 is equivalent to choosing the Xm that has the most bits in common with
R. Therefore, equation 2 can be rewritten as
(3)
where Xm,i,l is the lth bit of the ith subsequence of Xm and fa (b) is the indicator
function: fa(b) = 1 if and only if a equals b.
For the general case, maximum likelihood sequence estimation is very expensive
since the number of possible input sequences is exponential in b. The Viterbi algorithm [7], fortunately, is able to take advantage of the structure of convolutional codes
and their trellis graph representations to reduce the complexity of the decoder so that

595

it is only exponential in I( (in general K ~ b). An optimum version of the Viterbi algorithm examines all b stages in the trellis graph, but a more practical and very nearly
optimum version typically examines approximately 5K stages, beginning at stage i,
before making a decision about Ui.

3

A Network for MLSE Decoding

The structure of the network that we have defined strongly reflects the structure of a
trellis graph. The network usually consists of 5]( subnetworks, each containing 2 K - 1
neurons. Each subnetwork corresponds to a stage in the trellis graph and each neuron
to a state. Each stage is implemented as an ""on-center off-surround"" competitive
network [2], described in more detail in the next section, which produces as output a
contrast enhanced version of the input. This contrast enhancement creates a ""winner
take all"" situation in which, under normal circumstances, only one neuron in each
stage -the neuron receiving the input with greatest magnitude - will be on. The
activation pattern of the network after it reaches equilibrium indicates the decoded
sequence as a sequence of ""on"" neurons in the network. If the j-th neuron in subnet i,
Ni,i is on, then the node representing state j in stage i lies on the network's estimate
of the most likely path.
For a rate lin code, there is a symmetric cooperative connection between neurons
Ni,j and Ni+1 ,k if there is an edge between the corresponding nodes in the trellis
graph. If (xi,i,k,l, . .. , Xi,j,k,n) are the encoder output bits for the transition between
these two nodes and (ri,!, ... , ri,n) are the received bits, then the connection weight
for the symmetric cooperative connection between Ni,i and Ni+1,k is
1 n
m ',J,
"""" k-- - ""
I .ri I (X ',J""
"""" k/)
L.J

n

1=1

(4)

'

If there is no edge between the nodes, then mi,i,k = o.
Intuitively, it is easiest to understand the action of the entire network by examining one stage. Consider the nodes in stage i of the trellis graph and assume that
the conditional probabilities of the nodes in stages i - 1 and i + 1 are known. (All
probabilities are conditional on the received sequence.) Then the conditional probability of each node in stage i is simply the sum of the probabilities of each node in
stages i - 1 and i + 1 weighted by the conditional transition probabilities. If we look
at stage i in the network, and let the outputs of the neighboring stages i - 1 and
i + 1 be fixed with the output of each neuron corresponding to the ""likelihood"" of
the corresponding state at that stage, then the final outputs of the neurons M,i will
correspond to the ""likelihood"" of each of the corresponding states. At equilibrium, the
neuron corresponding to the most likely state will have the largest output.

4

The Neural Model

The ""on-center off-surround"" network[2] is used to model each stage in our network.
This model allows the output of each neuron to take on a range of values, in this
case between zero and one, and is designed to support contrast enhancement and
competition between neurons. The model also guarantees that the final output of
each neuron is a function of the relative intensity of its input as a fraction of the total
input provided to the network.

596

Using the ""on-center off-surround"" model for each stage and the interconnection
weights, mi,j,k, defined in equation 4, the differential equation that governs the instantaneous activity of the neurons in our deconvolution network with S stages and
N states in each stage can be written as
N

Ui,j = -Aui,j

-

+ I)mi-I,k,jf(Ui-I,k) + mi,j,kf(Ui+1,k)])
N
klJ
(C + Ui,j) L (f( Ui,k) + L[mi-I,k,t!( Ui-I,k) + mi,l,kf( Ui+1,k)])
+ (B -

Ui ,j) (f(Ui,j)

k""lj

(5)

1=1

where f(x) = (1 + e-'\X)-I, oX is the gain of the nonlinearity, and A, B, and Care
constants
For the analysis to be presented in section 5, we note that equation 5 can be
rewritten more compactly in a notation that is similar to the equation for additive
analog neurons given in [4]:
S

U'&,}. --

-

Au""&,}

-

N

'""'
' ?S?&,},. k, 1!(Uk,
I) - 1'.&,3""
.. k 1!(Uk, I))
L..J '""'Cu
L..J &,}

(6)

k=I/=I

where, for 1

~

I

~

N,

1'.&,},&,}
. . .. -- B
1'.&,},&,
.. . I = -C V I r~ J'
Ti j i-I I = Bmi_l I j - C

S?&,},&,
"" 11
S&,},&-,
? "" 11 = l.J
~m&-I""q
'
I
q

S &,},&+
.. ? 1, /- - ~m'
l.J
&,q, I

'""

q

Si,j,k,1 = 0 V k ? {i - 1, i, i

+ 1}

, ,

1'.&,3,&+
... II,

Bm""1
I,),

--

-

C

E mi-l ""I q

q?j

~
l.J

q""lj

(7)

m'&,q, I

To eliminate the need for global interconnections within a stage, we can add two
summing elements to calculate
N

N

Xi

=L

f(Xi,j)

and

N

Ji = L L

j=1

[mi-l,k,j!( Ui-l,k)

+ mi,j,kf( Ui+1,k)]

(8)

j=I k=I

Using these two sums allows us to rewrite equation 5 as

U?&,}. = -Au'&,}. + (B

+ C)(f(u? .) + L
&,)

.) - U?&,}?(X&? + J.)
&

(9)

&,)

This form provides a more compact design for the network that is particularly suited
to implementation as a digital filter or for use in simulations since it greatly reduces
the calculations required,

5

Stability of the Network

The end of section 3 described the desired operation of a single stage, given that the
outputs of the neighboring stages are fixed. It is possible to show that in this situation
a single stage is stable. To do this, fix f( Uk,/) for k E {i - 1, i + 1} so that equation 6
can be written in the form originally proposed by Grossberg [2]:

Ui,j = -Auj,j

+ (B -

Uj,j) (Ii,j

+ f(Ui,j)) -

(Ui,j

N

N

k=1

k=1

+ C)(L Ii,k + L

!(Ui,k))

(10)

597
where Ii,; = 2:1'=1 [mi-l,k,jf( Ui-l,k) + mi,j,kf( Ui+I,k)].
Equation 10 is a special case of the more general nonlinear system

t

Xi = ai(xi) (bi(Xi) -

(11)

Ci,kdk(Xk))

k=1

where: (1) ai(xi) is continuous and ai(xd > 0 for Xi 2: OJ (2) bi(Xi) is continuous
for Xi ~ OJ (3) Ci,k = Ck,ij and (4) di(Xi) ~ 0 for all Xi E (-00,00). Cohen and
Grossberg [1] showed that such a system has a global Lyapunov function:

(12)
and that, therefore, such a system is equiasymptotically stable for all constants and
functions satisfying the four constraints above. In our case, this means that a single
stage has the desired behavior when the neighboring stages are fixed. IT we take the
output of each neuron to correspond to the likelihood of the corresponding state then,
if the two neighboring stages are fixed, stage i will converge to an equilibrium point
where the neuron receiving the largest input will be on and the others will be off, just
as it should according to section 2.
It does not seem possible to use the Cohen-Grossberg stability proof for the entire
system in equation 5. In fact, Cohen and Grossberg note that networks which allow
cooperative interactions define systems for which no stability proof exists [1].
Since an exact stability proof seems unlikely, we have instead shown that in the
limit as the gain, A, of the nonlinearity gets large the system is asymptotically stable.
Using the notation in [4], define Vi = f(Ui) and a normalized nonlinearity J(.) such
that J-l(Vi) = AUi. Then we can define an energy function for the deconvolution
network to be
1
E -- -2

L

T:.
1,.1,k,l V.?1,.1?Vik,l -

i,j,k,l

L

1 ( -A -A

i,j

- 1
S 1,.1,k,l
?? Vik,l ) ~VIc'1
1
f - (() d(

L

k,l

(13)

2

The time derivative of E is

.

E -- -

- ' ( -Au?? L -dVii
dt
I,)

i,i

U?1,.1.

? ? Vik,l + L T?1,.1,k,l
? Vik,l
L S1,.1,k,l

k,l

k,l

-

1~
(VIc ,1 - 1
)
""X L.i Si,j,k,l } l. f- (()d(

k,l

(14)

2

It is difficult to prove that E is nonpositive because of the last term in the parentheses.
However, for large gain, this term can be shown to have a negligible effect on the
derivative.
It can be shown that for f(u) = (1 + C>'U)-I,
l-I(()d( is bounded above

Ii'2

by log(2). In this deconvolution network, there are no connections between neurons
unless they are in the same or neighboring stages, i.e., Si,i,k,l = 0 for Ii - kl > 1 and
1 is restricted so that 0 ~ 1 ~ S, so there are no more than 3S non-zero terms in the
problematical summation. Therefore, we can write that
1

lim - ,
>'-00

L

A k,l

Si,j,k,l

~VIc'1

t

_

f-l(() d( = 0

598

Then, in the limit as ). -- 00, the terms in parentheses in equation 14 converge to Ui
. equatIOn
. 6, so t h at li m E? = ~
dVi- j'Ui.
.
U?
III
L..J smg th e ch?
am ruI e, we can reWrl?te thOIS
.\-+00
..
dt
t,)
as

E.n~J = - t= (d~J )'( d~/-l (V;J?)

It can also be shown that that, if 1(?) is a monotonically increasing function then
~ I-I (Vi) > 0 for all Vi. This implies that for all u = (Ui,b . .? ,UN,S), lim>.-+oo E S; 0,
and, therefore, for large gains, E as defined in equation 13 is a Lyapunov function for
the system described by equation 5 and the network is equiasymtotically stable.
If we apply a similar asymptotic argument to the energy function, equation 13
reduces to
1
E -- - '2 ~
(15)
L..J T:',3"". k IV.?1,3.Vik , I
i,j,k,1

which is the Lyapunov function for a network of discontinuous on-off neurons with
interconnection matrix T. For the binary neuron case, it is fairly straight forward to
show that the energy function has minima at the desired decoder outputs if we assume
that only one neuron in each stage may be on and that Band C are appropriately
chosen to favor this. However, since there are 0(5 2 N) terms in the disturbance
summation in equation 15, convergence in this case is not as fast as for the derivative
of the energy function in equation 13, which has only 0(5) terms in the summation.

6

Simulation Results

The simulations presented in this section are for the rate 1/3, K = 3 convolutional code
illustrated in figure 1. Since this code has a constraint length of 3, there are 4 possible
states in each stage and an MLSE decoder would normally examine a minimum of
5K subsequences before making a decision, we will use a total of 16 stages. In these
simulations, the first and last stage are fixed since we assume that we have prior
knowledge or a decision about the first stage and zero knowledge about the last stage.
The transmitted codeword is assumed to be all zeros.
The simulation program reads the received sequence from standard input and uses
it to define the interconnection matrix W according to equation 4. A relaxation
subroutine is then called to simulate the performance of the network according to an
Euler discretization of equation 5. Unit time is then defined as one RC time constant of
the unforced system. All variables were defined to be single precision (32 bit) floating
point numbers.
Figure 2a shows the evolution of the network over two unit time intervals with the
sampling time T = 0.02 when the received codeword contains no noise. To interpret
the figure, recall that there are 16 stages of 4 neurons each. The output of each stage
is a vertical set of 4 curves. The upper-left set is the output of the first stage; the
upper-most curve is the output of the first neuron in the stage. For the first stage,
the first neuron has a fixed output of 1 and the other neurons have a fixed output of
o. The outputs of the neurons in the last stages are fixed at an intermediate value to
represent zero a priori knowledge about these states. Notice that the network reaches
an equilibrium point in which only the top neurons in each state (representing the ""00""
node in figure 1) are on and all others are off. This case illustrates that the network
can correctly decode an unerrored input and that it does so rapidly, i.e., in about one
time constant. In this case, with no errors in the input, the network performs the

599

o

2 0

2 0

( a)

2 0

2

o

10 0

10 0

10 0

10

(b)

Figure 2: Evolution of the trellis network for (a) unerrored input, (b) input with burst
errors: R is 000 000 000 000 000 000 000 000 111 000 000 000 000 000 000. A = 10.,
A = 1.0, B = 1.0, C = 0.75, T = 0.02. The initial conditions are XI,1 = 1., xI,.i = 0.0,
X16,j = 0.2, all other Xi,j = 0.0.
same function as Hopfield and Tank's network and does so quite well. Although we
have not been able to prove it analytically, all our simulations support the conjecture
that if xi,AO) = ~ for all i and j then the network will always converge to the global
minimum.
One of the more difficult decoding problems for this network is the correction of
a burst of errors in a transition subsequence. Figure 2b shows the evolution of the
network when three errors occur in the transition between stages 9 and 10. Note that
10 unit time intervals are shown since complete convergence takes much longer than
in the first example. However, the network has correctly decoded many of the stages
far from the burst error in a much shorter time.
If the received codeword contains scattered errors, the convolutional decoder should
be able to correct more than 3 errors. Such a case is shown in figure 3a in which the
received codeword contains 7 errors. The system takes longest to converge around two
transitions, 5-6 and 11-12. The first is in the midst of consecutive subsequences which
each have one bit errors and the second transition contains two errors.
To illustrate that the energy function shown in equation 13 is a good candidate
for a Lyapunov function for this network, it is plotted in figure 3b for the three cases
described above. The nonlinearity used in these simulations has a gain of ten, and, as
predicted by the large gain limit, the energy decreases monotonically.
To more thoroughly explore the behavior of the network, the simulation program
was modified to test many possible error patterns. For one and two errors, the program
exhaustively tested each possible error pattern. For three or more errors, the errors
were generated randomly. For four or more errors, only those errored sequences for
which the MLS estimate was the sequence of all zeros were tested. The results of
this simulation are summarized in the column labeled ""two-nearest"" in figure 4. The
performance of the network is optimum if no more than 3 errors are present in the
received sequence, however for four or more errors, the network fails to correctly decode
some sequences that the MLSE decoder can correctly decode.

600

~~~~
~~~~
~~~~
~~~E
0

2 0

2 0

2 0

80

60

40
E

20

errors
0

-20
0. 0

0.5

1.0

1.5

2.0

time

2

(b)

(a)

Figure 3: (a) Evolution of the trellis network for input with distributed errors. The
input, R, is 000 010 010 010 100 001 000 000 000 000 110 000 000 000 000. The
constants and initial conditions are the same as in figure 2. (b) The energy function
defined in equation 13 evaulated for the three simulations discussed.

errored
bits

number of
test vectors

0
1
2
3
4
5

1
39
500
500
500
500
500
500
2500

6

7

Total

number of errors
tvo-nearest four-nearest
0
0
0
0
7
33
72
132
244

0
0
0
0
0
20
68

103
191

Figure 4: Simulation results for a deconvolution network for a K = 3, rate 1/3 code.
The network parameters were: .x = 15, A = 6, B = 1, C = 0.45, and T = 0.025.
For locally interconnected networks, the major concern is the flow of information
through the network. In the simulations presented until now, the neurons in each stage
are connected only to neurons in neighboring stages. A modified form of the network
was also simulated in which the neurons in each stage are connected to the neurons
in the four nearest neighboring stages. To implement this network, the subroutine to
initialize the connection weights was modified to assign a non-zero value to Wi,j ,i+2,k.
This is straight-forward since, for a code with a constraint length of three, there is a
single path connecting two nodes a distance two apart.
The results of this simulation are shown in the column labeled ""four-nearest"" in
figure 4. It is easy to see that the network with the extra connections performs better

601

than the previous network. Most of the errors made by the nearest neighbor network
occur for inputs in which the received subsequences ri and ri+1 or ri+2 contain a total
of four or more errors. It appears that the network with the additional connections
is, in effect, able to communicate around subsequences containing errors that block
communications for the two-nearest neighbor network.

7

Summary and Conclusions

We have presented a locally interconnected network which minimizes a function that
is analogous to the log likelihood function near the global minimum. The results of
simulations demonstrate that the network can successfully decode input sequences
containing no noise at least as well as the globally connected Hopfield-Tank [6] decomposition network. Simulations also strongly support the conjecture that in the
noiseless case, the network can be guaranteed to converge to the global minimum. In
addition, for low error rates, the network can also decode noisy received sequences.
We have been able to apply the Cohen-Grossberg proof of the stability of ""oncenter off-surround"" networks to show that each stage will maximize the desired local
""likelihood"" for noisy received sequences. We have also shown that, in the large gain
limit, the network as a whole is stable and that the equilibrium points correspond to
the MLSE decoder output. Simulations have verified this proof of stability even for relatively small gains. Unfortunately, a proof of strict Lyapunov stability is very difficult,
and may not be possible, because of the cooperative connections in the network.
This network demonstrates that it is possible to perform interesting functions even
if only localized connections are allowed, although there may be some loss of performance. If we view the network as an associative memory, a trellis structured network
that contains N S neurons can correctly recall 28 memories. Simulations of trellis networks strongly suggest that it is possible to guarantee a non-zero minimum radius of
attraction for all memories. We are currently investigating the use of trellis structured
layers in multilayer networks to explicitly provide the networks with the ability to
tolerate errors and replace faulty neurons.

References
[1] M. Cohen and S. Grossberg, ""Absolute stability of global pattern formation and parallel
memory storage by competitive neural networks,"" IEEE Trans. Sys., Man, and Cyber.,
vol. 13, pp. 815-826, Sep.-Oct. 1983.
[2] S. Grossberg, ""How does a brain build a cognitive code,"" in Studies of Mind and Brain,
pp. 1-52, D. Reidel Pub. Co., 1982.
[3] J. Hopfield, ""Neural networks and physical systems with emergent collective computational
abilities,"" Proceedings of the National Academy of Sciences USA, vol. 79, pp. 2554-2558,
1982.

[4] J. Hopfield, ""Neurons with graded response have collective computational properties like
those of two-state neurons,"" Proceeedings of the National Academy of Science, USA, vol. 81,
pp. 3088-3092, May 1984.
[5] J. McClelland and D. Rumelhart, Parallel Distributed Processing, Vol. 1. The MIT Press,
1986.

[6] D. Tank and J. Hopfield, ""Simple 'neural' optimization networks: an AID converter, signal
decision circuit and a linear progra.mming circuit,"" IEEE Trans. on Circuits and Systems,
vol. 33, pp. 533-541, May 1986.
[7] A. Viterbi and J. Omura, Principles of Digital Communications and Coding. McGra.w-Hill,
1979.

"
65,1987,"Minkowski-r Back-Propagation: Learning in Connectionist Models with Non-Euclidian Error Signals","",65-minkowski-r-back-propagation-learning-in-connectionist-models-with-non-euclidian-error-signals.pdf,"Abstract Missing","348

Minkowski-r Back-Propaaation: Learnine in Connectionist
Models with Non-Euclidian Error Silllais
Stephen Jose Hanson and David J. Burr
Bell Communications Research
Morristown, New Jersey 07960
Abstract
Many connectionist learning models are implemented using a gradient descent
in a least squares error function of the output and teacher signal. The present model
Fneralizes. in particular. back-propagation [1] by using Minkowski-r power metrics.
For small r's a ""city-block"" error metric is approximated and for large r's the
""maximum"" or ""supremum"" metric is approached. while for r=2 the standard backpropagation model results. An implementation of Minkowski-r back-propagation is
described. and several experiments are done which show that different values of r
may be desirable for various purposes. Different r values may be appropriate for the
reduction of the effects of outliers (noise). modeling the input space with more
compact clusters. or modeling the statistics of a particular domain more naturally or
in a way that may be more perceptually or psychologically meaningful (e.g. speech or
vision).

1. Introduction
The recent resurgence of connectionist models can be traced to their ability to
do complex modeling of an input domain. It can be shown that neural-like networks
containing a single hidden layer of non-linear activation units can learn to do a
piece-wise linear partitioning of a feature space [2]. One result of such a partitioning
is a complex gradient surface on which decisions about new input stimuli will be
made. The generalization, categorization and clustering propenies of the network are
therefore detennined by this mapping of input stimuli to this gradient swface in the
output space. This gradient swface is a function of the conditional probability
distributions of the output vectors given the input feature vectors as well as a function
of the error relating the teacher signal and output.
f'F'I

an"" c.,-i,. ....

T.. ............

.. .,

~.r

01.

349

Presently many of the models have been implemented using least squares error.
In this paper we describe a new model of gradient descent back-propagation [I] using
Minkowski-r power error metrics. For small r's a ""city-block"" error measure (r=I) is
approximated and for larger r's a ""maximum"" or supremum error measure is
approached, while the standard case of Euclidian back-propagation is a special case
with 1'*2. Fll""St we derive the general case and then discuss some of the implications
of varying the power in the general metric.
2. Derivation of Minkowski-r Back-propagation
The standard back-propagation is derived by minimizing least squares error as
a function of connection weights within a completely connected layered network.
The error for the Euclidian case is (for a single input-output pair),

E

.. 2
=-21 L. O'j-Yj)
,

(1)

J

where Y is the activation of a unit and y represents an independent teacher signal.
The activation of a unit 0') is typically computed by nonnalizing the input from other
units (x) over the interval (0,1) while compressing the high and low end of this range.
A common function used for this normalization is the logistic,
1
Yj=--1 + e-Xt

(2)

The input to a unit (x) is found by summing products of the weights and
corresponding activations from other units,
(3)

where Yle represents units in the fan in of unit i and
connection between unit i and unit h.

Whi

represents the strength of the

A gradient for the Euclidian or standard back-propagation case could be found
by finding the partial of the error with respect to each weight, and can be expressed in
this three tenn differential,

350

dE
dE dyi dX;
.
--dw/ti
dyi ax; aw.,

(4)

which from the equations before turns out to be,

(5)

Generalizing the error for Minkowski-r power metrics (see Figure 1 for the
family of curves),

E

=-r1 L.

. . I )'
I (Yi - Yi

(6)

?

..

~

~

:
I:
C'f

0

?

.eo

?

?20

0

ao

...

10

NfIII

Figure 1: Minkowski-r Family
Using equations 24 above with equation 6 we can easily find an expression for the
gradient in the general Minkowski-r case,

dE = ( IYi - Yi)
. . I ,-1 1 )
(y
. .. )
Yi( -Yi "",.sgn i - Yi

~
aw,.;

(7)

This gradient is used in the weight update rule proposed by Rumelhart, Hinton and
Williams [1],

351

whi(n+l)

=

dE

(X-

dWAi

+ wAi(n)

(8)

Since the gradient computed for the hidden layer is a function of the gradient for the
output, the hidden layer weight updating proceeds in the same way as in the
Euclidian case [1], simply substituting this new Minkowski-r gradient.
It is also possible to define a gradient over r such that a minimum in error
would be sought. Such a gradient was suggested by White [3, see also 4] for
maximum likelihood estimation of r, and can be shown to be,

dIO?E) = (1-1Ir)(1Ir) + (llr)2/og (r) + (lIr) 2"",(1lr) + (1/r) 21Yi-Yi 1
-(1/r)(IYi -Yil)'/og(IYi -Yi I)

(9)

An approximation of this gradient (using the last term of equation 9) has been
implemented and investigated for simple problems and shown to be fairly robust in
recovering similar r values. However, it is important that the r update rule changes
slower than the weight update rule. In the simulations we ran r was changed once for
every 10 times the weight values were changed. This rate might be expected to vary
with the problem and rate of convergence. Local minima may be expected in larger
problems while seeking an optimal r. It may be more infonnative for the moment to
examine different classes of problems with fixed r and consider the specific rationale
for those classes of problems.
3. Variations in r
Various r values may be useful for various aspects of representing infonnation
in the feature domain. Changing r basically results in a reweighting of errors from
output bits l . Small r's give less weight for large deviations and tend to reduce the
influence of outlier points in the feature space during learning. In fact, it can be
shown that if the distributions of feature vectors are non-gaussian, then the r=2 case
1. It is possible to entcltain r values that are negative, which would give largest weight to small errors
close to zero and smallest weight to very large emn. Values of r lea than 1 generally are non-metric.
i.e. they viola1e 81ieast one of the meuic axioms. For example. r<O violates the triangle inequality.
Fa' aome problems this may make sense and the need for a metric em:r weighting may be unnecessary.
These issues are not explored in this paper.

352

will not be a maximum likelihood estimator of the weights [5]. The city block case,
r=1, in fact, arises if the underlying conditional probability distributions are Laplace
[5]. More generally. r's less than two will tend to model non~gaussian distributions
where the tails of the distributions are more pronounced than in the gaussian. Better
estimators can be shown to exist for general noise reduction and have been studied in
the area of robust estimation procedures [5] of which the Minkowski-r metric is only
one possible case to consider.

r<2. It is generally recommended that 1'=1.5 may be optimal for many noise
reduction problems [6]. However, noise reduction may also be expected to vary with
the problem and nature of the noise. One example we have looked at involves the
recovery of an arbitrary 3 dimensional smooth surface as shown in Figure 2a, after
the addition of random noise. This surface was generated from a gaussian curve in the
2 dimensions. Uniform random noise equal to the width (standard deviation) of the
surface shape was added point-wise to the surface producing the noise plus surface
shape shown in Figure 2b.

b

Figure 2: Shape surface (2a), Shape plus noise surface (2b) and recovered Shape
sUrface (2c)
The shape in Figure 2a was used as target points for Minkowski-r back~propagation2
and recovered with some distortion of the slope of the shape near the peak of the
2. All simulation runs, unless otherwise stated, used the same learning rate (.05) and smoothing value (.9)
and stopping critmon defined in tenns of absolute mean deviation. The number of iterations to meet
the stopping criterion varied considerably as r was changed (see below).

353

surface (see Fiaure 2c). Next the noise plus shape surface was used as target points
for the learning procedure with r=2. The shape shown in Figure 3a was recovered,
however. with considerable distortion iaround the base and peak. The value of r was
reduced to 1.5 (Figure 3b) and then finally to 1.2 (Figure 3c) before shape distortions
were eliminated. Although, the major properties of the shape of the surface were
recovered. the scale seems distorted (however, easily restored with renormalization
into the 0.1 range).

Figure 3: Shape surface recovered with r=2 (3a), r=1.5 (3b) and r=1.2 (3c)

r>2. Large r's tend to weight large deviations. When noise is not possible in
the feature space (as in an arbitrary boolean problem) or where the token clusters are
compact and isolated tllen simpler (in the sense of the number and placement of
partition planes) genenuization surfaces may be created with larger r values. For
example, in the simple XOR problem, the main effect of increasing r is to pull the
decision boundaries closer into the non-zero targets (compare high activation regions
in Figure 4a and 4b).
In this particular problem clearly such compression of the target regions does not
constitute simpler decision surfaces. However, if more hidden units are used than are
needed for pattern class separation, then increasing r during training will tend to
reduce the number of cuts in the space to the minimum needed. This seems to be
primarily due to the sensitivity of the hyper-plane placement in the feature space to
the geometry of the targets.
A more complex case illustrating the same idea comes from an example
suggested by Minsky & Papen [7] called ""the mesh"". This type of pattern
recognition problem is also. like XOR, a non-linearly separable problem. An optimal

354

Figure 4: XOR solved with r=2 (4a) and r=4 (4b)

solution involves only three cuts in feature space
cluSten (see Figure Sa).

to

separate the two ""meshed""

f14W'"" 1

b

Figure 5: Mesh problem with minimwn cut solution (5a) and Performance Surface(5b)

Typical solutions for r=2 in this case tend to use a large number of hidden units to
separate the two sets of exemplars (see Figure 5b for a perfonnance surface). For
example t in Figure 6a notice that a typical (based on several runs) Euclidian backprop starting with 16 hidden units has found a solution involving five decision
boundaries (lines shown in the plane also representing hidden units) while the r=3
case used primarily three decision boundaries and placed a number of other

355

boundaries redundantly near the center of the meshed region (see Figure 6b) where
there is maximum uncertainty about the cluster identification.

-

-

~

~

ID

~
0

0

..

ID

0

0

?

?0

C'lI

0

0

0

~
0

0

C'lI

0

0.0

0.2

G.4

0.8

0.8

1.0

b

0.0

0.2

0.4

0.8

0.8

1.0

Figure 6: Mesh solved with r=2 (6a) and r=3 (6b)

Speech Recognition. A final case in which large r's may be appropriate is data
that has been previously processed with a transformation that produced compact
regions requiring separation in the feature space. One example we have looked at
involves spoken digit recognition. The first 10 cepstral coefficients of spoken digits
(""one"" through ""ten"") were used for input to a network. In this case an advantage is
shown for larger r's with smaller training set sizes. Shown in Figure 7 are transfer
data for 50 spoken digits replicated in ten different runs per point (bars show standard
error of the mean). Transfer shows a training set size effect for both r=2 and r=3,
however for the larger r value at smaller training set sizes (10 and 20) note that
transfer is enhanced.
We speculate that this may be due to the larger r backprop creating discrimination
regions that are better able to capture the compactness of the clusters inherent in a
small number of training points.
4. Conver&ence Properties

It should be generally noted that as r increases. convergence time tends to grow
roughly linearly (although this may be problem dependent). Consequently,
decreasing r can significantly improve convergence, without much change to the
nature of solution. Further, if noise is present decreasing r may reduce it
dramatically. Note finally that the gradient for the Minkowski-r back-propagation is
nonlinear and therefore more complex for implementing learning procedures.

356

...---... ....... ----.-- -..-- - -- - 1..-

8
0

~c

co

~
?c

co

...!

0

:J

~

0

u
0~

t------l--:::~+-?/'-

!:

:

/

0

C\I

0

t?

R=2 ,.-

Q

"". .

i1

!

I

0

~
~

~ .-

i
1

0

~

I

~ '~- '. ~

:'

! ! T.:' 10 replications of 50 transfer POints
: i' I :
I /... .?.C/
L____U.____
----..
o

10

20

30

40

50

TRAINING SET SIZE

Figure 7: Digit Recognition Set Size Effect
5. Summary and Conclusion
A new procedure which is a variation on the Back-propagation algorithm is
derived and simulated in a number of different problem domains. Noise in the target
domain may be reduced by using power values less than 2 and the sensitivity of
partition planes to the geometry of the problem may be increased with increasing
power values. Other types of objective functions should be explored for their
potential consequences on network resources and ensuing pattern recognition
capabilities.

References
1. Rumelhart D. E., Hinton G. E., Williams R., Learning Internal Representations by
error propagation. Nature. 1986.

2. Burr D. I. and Hanson S. I .? Knowledge Representation in Connectionist Networks.
Bellcore. Technical Report,

3. White. H. Personal Communication. 1987.
4. White, H. Some Asymptotic Results for Learning in Single Hidden Layer
Feedforward Network Models. Unpublished Manuscript. 1987.

357

S. Mosteller, F. & Tukey, 1. Robust Estimation Procedures, Addison Wesley, 1980.
6. Tukey, 1. Personal Communication, 1987.
7. Minsky, M. & Papert, S., Perceptrons: An Introduction to Computational
Geometry, MIT Press, 1969.

"
66,1987,"On Properties of Networks of Neuron-Like Elements","",66-on-properties-of-networks-of-neuron-like-elements.pdf,"Abstract Missing","41

ON PROPERTIES OF NETWORKS
OF NEURON-LIKE ELEMENTS
Pierre Baldi? and Santosh S. Venkatesh t
15 December 1987

Abstract
The complexity and computational capacity of multi-layered, feedforward
neural networks is examined. Neural networks for special purpose (structured)
functions are examined from the perspective of circuit complexity. Known results in complexity theory are applied to the special instance of neural network
circuits, and in particular, classes of functions that can be implemented in
shallow circuits characterised. Some conclusions are also drawn about learning
complexity, and some open problems raised. The dual problem of determining
the computational capacity of a class of multi-layered networks with dynamics
regulated by an algebraic Hamiltonian is considered. Formal results are presented on the storage capacities of programmed higher-order structures, and
a tradeoff between ease of programming and capacity is shown. A precise determination is made of the static fixed point structure of random higher-order
constructs, and phase-transitions (0-1 laws) are shown.

1

INTRODUCTION

In this article we consider two aspects of computation with neural networks. Firstly
we consider the problem of the complexity of the network required to compute classes
of specified (structured) functions. We give a brief overview of basic known complexity theorems for readers familiar with neural network models but less familiar
with circuit complexity theories. We argue that there is considerable computational
and physiological justification for the thesis that shallow circuits (Le., networks with
relatively few layers) are computationally more efficient. We hence concentrate on
structured (as opposed to random) problems that can be computed in shallow (constant depth) circuits with a relatively few number (polynomial) of elements, and
demonstrate classes of structured problems that are amenable to such low cost solutions. We discuss an allied problem-the complexity of learning-and close with
some open problems and a discussion of the observed limitations of the theoretical
approach.
We next turn to a rigourous classification of how much a network of given
structure can do; i.e., the computational capacity of a given construct. (This is, in
?Department of Mathematics, University of California (San Diego), La Jolla, CA 92093
tMoore School of Electrical Engineering, University of Pennsylvania, Philadelphia, PA 19104

? American Institute of Physics 1988

42

a sense, the mirror image of the problem considered above, where we were seeking
to design a minimal structure to perform a given task.) In this article we restrict
ourselves to the analysis of higher-order neural structures obtained from polynomial
threshold rules. We demonstrate that these higher-order networks are a special class
of layered neural network, and present formal results on storage capacities for these
constructs. Specifically, for the case of programmed interactions we demonstrate
that the storage capacity is of the order of n d where d is the interaction order.
For the case of random interactions, a type of phase transition is observed in the
distribution of fixed points as a function of attraction depth.

2

COMPLEXITY

There exist two broad classes of constraints on compl,ltations.
1. Physical constraints: These are related to the hardware in which the computa-

tion is embedded, and include among others time constants, energy limitations,
volumes and geometrical relations in 3D space, and bandwidth capacities.

2. Logical constraints: These can be further subdivided into
? Computability constraints-for instance, there exist unsolvable problems,
i.e., functions such as the halting problem which are not computable in
an absolute sense .
? Complexity constraints-usually giving upper and/or lower bounds on
the amount of resources such as the time, or the number of gates required to compute a given function. As an instance, the assertion ""There
exists an exponential time algorithm for the Traveling Salesman Problem,"" provides a computational upper bound.
If we view brains as computational devices, it is not unreasonable to think
that in the course of the evolutionary process, nature may have been faced several
times by problems related to physical and perhaps to a minor degree logical constraints on computations. If this is the case, then complexity theory in a broad
sense could contribute in the future to our understanding of parallel computations
and architectural issues both in natural and synthetic neural systems.
A simple theory of parallel processing at the macro level (where the elements
are processors) can be developed based on the ratio of the time spent on communications between processors [7] for different classes of problems and different
processor architecture and interconnections. However, this approach does not seem
to work for parallel processing at the level of circuits, especially if calculations and
communications are intricately entangled.
Recent neural or connectionist models are based on a common structure, that
of highly interconnected networks of linear (or polynomial) threshold (or with sigmoid input-output function) units with adjustable interconnection weights. We shall
therefore review the complexity theory of such circuits. In doing so, it will be sometimes helpful to contrast it with the similar theory based on Boolean (AND, OR,
NOT) gates. The presentation will be rather informal and technical complements
can easily be found in the references.

43

Consider a circuit as being on a cyclic oriented graph connecting n Boolean
inputs to one Boolean output. The nodes of the graph correspond to the gates
(the n input units, the ""hidden"" units, and the output unit) of the circuit. The
size of the circuit is the total number of gates and the depth is the length of the
longest path connecting one input to the output. For a layered, feed-forward circuit,
the width is the average number of computational units in the hidden (or interior)
layers of elements. The first obvious thing when comparing Boolean and threshold
logic is that they are equivalent in the sense that any Boolean function can be
implemented using either logic. In fact, any such function can be computed in a
circuit of depth two and exponential size. Simple counting arguments show that
the fraction of functions requiring a circuit of exponential size approaches one as
n -+ 00 in both cases, i.e., a random function will in general require an exponential
size circuit. (Paradoxically, it is very difficult to construct a family of functions
for which we can prove that an exponential circuit is necessary.) Yet, threshold
logic is more powerful than Boolean logic. A Boolean gate can compute only one
function whereas a threshold gate can compute to the order of 2on2 functions by
varying the weights with 1/2 ~ a ~ 1 (see [19] for the lower bound; the upper
bound is a classical hyperplane counting argument, see for instance [20,30)). It
would hence appear plausible that there exist wide classes of problems which can be
computed by threshold logic with circuits substantially smaller than those required
by Boolean logic. An important result which separates threshold and Boolean logic
from this point of view has been demonstrated by Yao [31] (see [10,24] for an elegant
proof). The result is that in order to compute a function such as parity in a circuit
of constant depth k, at least exp(cnl/2k) Boolean gates with unbounded fanin are
required. As we shall demonstrate shortly, a circuit of depth two and linear size is
sufficient for the computation of such functions using threshold logic.
It is not unusual to hear discussions about the tradeoffs between the depth
and the width of a circuit. We believe that one of the main constributions of
complexity analysis is to show that this tradeoff is in some sense minimal and that
in fact there exists a very strong bias in favor of shallow (Le., constant depth)
circuits. There are multiple reasons for this. In general, for a fixed size, the number
of different functions computable by a circuit of small depth exceeds the number
of those computable by a deeper circuit. That is, if one had no a priori knowledge
regarding the function to be computed and was given hidden units, then the optimal
strategy would be to choose a circuit of depth two with the m units in a single
layer. In addition, if we view computations as propagating in a feedforward mode
from the inputs to the output unit, then shallow circuits compute faster. And the
deeper a circuit, the more difficult become the issues of time delays, synchronisation,
and precision on the computations. Finally, it should be noticed that given overall
responses of a few hundred milliseconds and given the known time scales for synaptic
integration, biological circuitry must be shallow, at least within a ""module"" and
this is corroborated by anatomical data. The relative slowness of neurons and their
shallow circuit architecture are to be taken together with the ""analog factor"" and
""entropy factor"" [1] to understand the necessary high-connectivity requirements of
neural systems.

44

From the previous analysis emerges an important class of circuits in threshold
logic characterised by polynomial size and shallow depth. We have seen that, in
general, a random function cannot be computed by such circuits. However, many
interesting functions-the structured problems--are far from random, and it is then
natural to ask what is the class of functions computable by such circuits? While
a complete characterisation is probably difficult, there are several sub-classes of
structural functions which are known to be computable in shallow poly-size circuits.
The symmetric functions, i.e., functions which are invariant under any permutation of the n input variables, are an important class of structured problems
that can be implemented in shallow polynomial size circuits. In fact, any symmetric function can be computed by a threshold circuit of depth two and linear size;
(n hidden units and one output unit are always sufficient). We demonstrate the
validity of this assertion by the following instructive construction. We consider n
binary inputs, each taking on values -1 and 1 only, and threshold gates as units.
Now array the 2n possible inputs in n + 1 rows with the elements in each row being
permuted versions of each other (i.e., n-tuples in a row all have the same number
of +1's) and with the rows going monotonically from zero +1's to n +l's. Any
given symmetric Boolean function clearly assumes the same value for all elements
(Boolean n-tuples) in a row, so that contiguous rows where the function assumes
the value +1 form bands. (There are at most n/2 bands-the worst case occuring
for the parity function.) The symmetric function can now be computed with 2B
threshold gates in a single hidden layer with the topmost ""neuron"" being activated
only if the number of +1's in the input exceeds the number of +1's in the lower
edge of the lowest band, and proceeding systematically, the lowest ""neuron"" being
activated only if the number of +1's in the input exceeds the number of +1's in the
upper edge of the highest band. An input string will be within a band if and only if
an odd number of hidden neurons are activated startbg contiguously from the top
of the hidden layer, and conversely. Hence, a single output unit can compute the
given symmetric function.
It is easy to see that arithmetic operations on binary strings can be performed
with polysize small depth circuits. Reif [23] has shown that for a fixed degree of precision, any analytic function such as polynomials, exponentials, and trigonometric
functions can be approximated with small and shallow threshold circuits. Finally,
in many situations one is interested in the value of a function only for a vanishingly
small (Le., polynomial) fraction of the total number of possible inputs 2n. These
functions can be implemented by polysize shallow circuits and one can relate the
size and depths of the circuit to the cardinal of the interesting inputs.
So far we only have been concerned with the complexity of threshold circuits.
We now turn to the complexity of learning, i.e., the problem of finding the weights
required to implement a given function. Consider the problem of repeating m points
in 1Rl coloured in two colours, using k hyperplanes so that any region contains only
monochromatic points. If i and k are fixed the problem can be solved in polynomial
time. If either i or k goes to infinity, the problem becomes NP-complete [1]. As
a result, it is not difficult to see that the general learning problem is NP-complete
(see also [12] for a different proof and [21] for a proof of the fact it is already
NP-complete in the case of one single threshold gate).

45

Some remarks on the limitations of the complexity approach are a
this juncture:

pro]XJs

at

1. While a variety of structured Boolean functions can be implemented at relatively low cost with networks of linear threshold gates (McCulloch-Pitts neurons), the extension to different input-output functions and the continuous
domain is not always straightforward.

2. Even restricting ourselves to networks of relatively simple Boolean devices such
as the linear threshold gate, in many instances, only relatively weak bounds
are available for computational cost and complexity.
3. Time is probably the single most important ingredient which is completely
absent from these threshold units and their interconnections [17,14]; there
are, in addition, non-biological aspects of connectionist models [8].
4. Finally, complexity results (where available) are often asymptotic in nature
and may not be meaningful in the range corresponding to a particular application.
We shall end this section with a few open questions and speculations. One
problem has to do with the time it takes to learn. Learning is often seen as a
very slow process both in artificial models (cf. back propagation, for instance) and
biological systems (cf. human acquisition of complex skills). However, if we follow
the standards of complexity theory, in order to be effective over a wide variety of
scales, a single learning algorithm should be polynomial time. We can therefore
ask what is learnable by examples in polynomial time by polynomial size shallow
threshold circuits? The status of back propagation type of algorithms with respect
to this question is not very clear.
The existence of many tasks which are easily executed by biological organisms
and for which no satisfactory computer program has been found so far leads to the
question of the specificity of learning algorithms, i.e., whether there exists a complexity class of problems or functions for which a ""program"" can be found only by
learning from examples as opposed to by traditional programming. There is some
circumstantial evidence against such conjecture. As pointed out by Valiant [25],
cryptography can be seen in some sense as the opposite of learning. The conjectures
existence of one way function, i.e., functions which can be constructed in polynomial time but cannot be invested (from examples) in polynomial time suggests that
learning algorithms may have strict limitations. In addition, for most of the artificial
applications seen so far, the programs obtained through learning do not outperform
the best already known software, though there may be many other reasons for that.
However, even if such a complexity class does not exist, learning algorithm may
still be very important because of their inexpensiveness and generality. The work of
Valiant [26,13] on polynomial time learning of Boolean formulas in his ""distribution
free model"" explores some additional limitations of what can be learned by examples
without including any additional knowledge.
Learning may therefore turn out to be a powerful, inexpensive but limited
family of algorithms that need to be incorporated as ""sub-routines"" of more global

46

programs, the structure of which may be -harder to find. Should evolution be regarded as an ""exponential"" time learning process complemented by the ""polynomial""
time type of learning occurring in the lifetime of organisms?

3

CAPACITY

In the previous section the focus of our investigation was on the structure and cost of
minimal networks that would compute specified Boolean functions. We now consider
the dual question: What is the computational capacity of a threshold network of
given structure? As with the issues on complexity, it turns out that for fairly general
networks, the capacity results favour shallow (but perhaps broad) circuits [29]. In
this discourse, however, we shall restrict ourselves to a specified class of higher-order
networks, and to problems of associative memory. We will just quote the principal
rigourous results here, and present the involved proofs elsewhere [4].
We consider systems of n densely interacting threshold units each of which
yields an instantaneous state -1 or +1. (This corresponds in the literature to a
system of n Ising spins, or alternatively, a system of n neural states.) The state
space is hence the set of vertices of the hypercube. We will in this discussion
also restrict our attention throughout to symmetric interaction systems wherein the
interconnections between threshold elements is bidirectional.
Let Id be the family of all subsets of cardinality d + 1 of the set {1, 2, ... , n}.
n
Clearly IIdl = ( d + 1)? For any subset I of {1, 2, ... , n}, and for every state
U

= {Ul,U2, ... ,un }E lB n deC
= {-1,l}n, set UI = fIiEIui.

Definition 1 A homogeneous algebraic threshold network of degree d is a network of

n threshold elements with interactions specified by a set of (
WI

indexed by I in I

d,

d:

1 ) real coefficients

and the evolution rule

ut = sgn ( IeIdL:ieI WIUI\{i})

(1)

These systems can be readily seen to be natural generalisations to higherorder of the familiar case d = 1 of linear threshold networks. The added degrees of
freedom in the interaction coefficients can potentially result in enhanced flexibility
and programming capability over the linear case as has been noted independently
by several authors recently [2,3,4,5,22,27]. Note that each d-wise product uI\i is just
the parity of the corresponding d inputs, and by our earlier discussion, this can be
computed with d hidden units in one layer followed by a single threshold unit. Thus
the higher-order network can be realised by a network of depth three, where the first
hidden layer has d( ~ ) units, the second hidden layer has ( ~ ) units, and there are
n output units which feedback into the n input units. Note that the weights from
the input to the first hidden layer, and the first hidden layer to the second are fixed

47

(computing the various d-wise products), and the weights from the second hidden
layer to the output are the coefficients WI which are free parameters.
These systems can be identified either with long range interactions for higherorder spin glasses at zero temperature, or higher-order neural networks. Starting
from an arbitrary configuration or state, the system evolves asynchronously by a
sequence of single ""spin"" flips involving spins which are misaligned with the instantaneous ""molecular field."" The dynamics of these symmetric higher-order systems
are regulated analogous to the linear system by higher-order extensions of the classical quadratic Hamiltonian. We define the homogeneous algebraic Hamiltonian of
degree d by

Hd(u)

=- E

WI'UI?

(2)

IeId

The algebraic Hamiltonians are functionals akin in behaviour to the classical
quadratic Hamiltonian as has been previously demonstrated [5].
Proposition 1 The functional H d is non-increasing under the evolution rule 1.
In the terminology of spin glasses, the state trajectories of these higher-order
networks can be seen to be following essentially a zero-temperature Monte Carlo
(or Glauber) dynamics. Because of the monotonicity of the algebraic Hamiltonians
given by equation 2 under the asynchronous evolution rule 1, the system always
reaches a stable state (fixed point) where the relation 1 is satisfied for each of the n
spins or neural states. The fixed points are hence the arbiters of system dynamics,
and determine the computational capacity of the system.
System behaviour and applications are somewhat different depending on
whether the interactions are random or programmed. The case of random interactions lends itself to natural extensions of spin glass formulations, while programmed
interactions yield applications of higher-order extensions of neural network models.
We consider the two cases in turn.

3.1

PROGRAMMED INTERACTIONS

Here we query whether given sets of binary n-vectors can be stored as fixed points
by a suitable selection of interaction coefficients. If such sets of prescribed vectors
can be stored as stable states for some suitable choice of interaction coefficients,
then proposition 1 will ensure that the chosen vectors are at the bottom of ""energy
wells"" in the state space with each vector exercising a region of attraction around
it-all characterestics of a physical associative memory. In such a situation the
dynamical evolution of the network can be interpreted in terms of computations:
error-correction, nearest neighbour search and associative memory. Of importance
here is the maximum number of states that can be stored as fixed points for an
appropriate choice of algebraic threshold network. This represents the maximal
information storage capacity of such higher-order neural networks.
Let d represent the degree ofthe algebraic threshold network. Let u(l), ... , u(m)
be the m-set of vectors which we require to store as fixed points in a suitable algebraic threshold network. We will henceforth refer to these prescribed vectors as

48

memories. We define the storage capacity of an algebraic threshold network of degree d to be the maximal number m of arbitrarily chosen memories which can be
stored with high probability for appropriate choices of coefficients in the network.
Theorem 1 The maximal (algorithm independent) storage capacity of a homoge-

neous algebraic threshold network of degree d is less than or equal to 2 ( ~ ).
Generalised Sum of Outer-Products Rule: The classical Reb bian rule for the
linear case d = 1 (cf. [11] and quoted references) can be naturally extended to
networks of higher-order. The coefficients WI, IE Id are constructed as the sum of
generalised Kronecker outer-products,
m

WI

=L

u~a).

a=l

Theorem 2 The storage capacity of the outer-product algorithm applied to a homogeneous algebraic threshold network of degree d is less than or equal to n d /2(d +
l)logn (also cf. [15,27]).

Generalised Spectral Rule: For d = 1 the spectral rule amounts to iteratively
projecting states orthogonally onto the linear space generated by u(1), ... , u(m), and
then taking the closest point on the hypercube to this projection (cf. [27,28]). This
approach can be extended to higher-orders as we now describe.
Let W denote the n X N(n,d) matrix of coefficients WI arranged lexicographically; i.e.,

W=

Wl,l,2, ... ,d-l,d

Wl,2,3, ... ,d,d+l

Wl,n-d+l,n-d+2, ... ,n-l,n

W2,l,2, ... ,d-l,d

W2,2,3, ... ,d,d+l

W2,n-d+l,n-d+2, ... ,n-l,n

W n ,l,2, ... ,d-l,d

W n ,2,3, ... ,d,d+l

W n ,n-d+l,n-d+2, ... ,n-l,n

Note that the symmetry and the ""zero-diagonal"" nature of the interactions have
been relaxed to increase capacity. Let U be the n X m matrix of memories. Form
the extended N(n,d) X m binary matrix 1 U = [lu(l) ... lu(m)], where
u(a)
l,2,. .. ,d-l,d

(a)

u 1,2, ... ,d-l,d+l

(a)
u n _ d+ l,n- d+2, ... ,n-l,n

Let A = dgP'<l) ... ),(m)] be a m X m diagonal matrix with positive diagonal terms.
A generalisation of the spectral algorithm for choosing coefficients yields
W
where

1

= UA1Ut

ut is the pseudo-inverse of 1 U.

49

Theorem 3 The storage capacity of the generalised spectral algorithm is at best
n
( d ).

3.2

RANDOM INTERACTIONS

We consider homogeneous algebraic threshold networks whose weights WI are Li.d.,
N(O, 1) random variables. This is a natural generalisation to higher-order of Ising
spin glasses with Gaussian interactions. We will show an asymptotic estimate for
the number of fixed points of the structure. Asymptotic results for the usual case
d = 1 of linear threshold networks with Gaussian interactions have been reported
in the literature [6,9,16].
For i = 1, ... , n set

s~

L:

= Ui

WIUI\i .

IeId:ieI

For each n the random variables S~, i

= 1, ... , n are identically distributed, jointly

Gaussian variables with zero mean, and variance
Definition 2 For any given f3 ~ 0, a state u E
for each i = 1, ... , n.

O'~ = ( n ~ 1

).

run is f3-strongly stable iff S~ ~ f3O'n,

The case f3 = 0 reverts to the usual case of fixed points. The parameter f3 is
essentially a measure of how deep the well of attraction surrounding the fixed point
is. The following proposition asserts that a 0-1 law (""phase transition"") governs
the expected number of fixed points which have wells of attraction above a certain
depth. Let Fd(f3) be the expected number of f3-strongly stable states.
Theorem 4 Corresponding to each fixed interaction order d there exists a positive
constant f3 d such that as n --+ 00,

if f3 < f3 d
if f3 = f3d
if f3 > f3 d ,
where kd(f3) > 0, and 0 ~ Cd(f3)
interaction order d.

4

< 1 are parameters depending solely on f3 and the

CONCLUSION

In fine, it appears possible to design shallow, polynomial size threshold circuits
to compute a wide class of structured problems. The thesis that shallow circuits
compute more efficiently than deep circuits is borne out. For the particular case of

50

higher-order networks, all the garnered results appear to point in the same direction:
For neural networks of fixed degree d, the maximal number of programmable states is
essentially of the order of n d ? The total number of fixed points, however, appear to
be exponential in number (at least for the random interaction case) though almost
all of them have constant attraction depths.

References
[1] Y. S. Abu-Mostafa, ""Number of synapses per neuron,"" in Analog VLSI and
Neural Systems, ed. C. Mead, Addison Wesley, 1987.

[2] P. Baldi, II. Some Contributions to the Theory of Neural Networks. Ph.D. Thesis, California Insitute of Technology, June 1986.

[3] P. Baldi and S. S. Venkatesh, ""Number of stable points for spin glasses and
neural networks of higher orders,"" Phys. Rev. Lett., vol. 58, pp. 913-916, 1987.

[4] P. Baldi and S. S. Venkatesh, ""Fixed points of algebraic threshold networks,""
in preparation.

[5] H. H. Chen, et al, ""Higher order correlation model of associative memory,"" in
Neural Networks for Computing. New York: AlP Conf. Proc., vol. 151, 1986.

[6] S. F. Edwards and F. Tanaka, ""Analytical theory of the ground state properties
of a spin glass: I. ising spin glass,"" Jnl. Phys. F, vol. 10, pp. 2769-2778, 1980.

[7] G. C. Fox and S. W. Otto, ""Concurrent Computations and the Theory of
Complex Systems,"" Caltech Concurrent Computation Program, March 1986.

[8] F. H. Grick and C. Asanuma, ~'Certain aspects of the anatomy and physiology
of the cerebral cortex,"" in Parallel Distributed Processing, vol. 2, eds. D. E.
Rumelhart and J. L. McCelland, pp. 333-371, MIT Press, 1986.

[9] D. J. Gross and M. Mezard, ""The simplest spin glass,"" Nucl. Phys., vol. B240,
pp. 431-452, 1984.
[10] J. Hasted, ""Almost optimal lower bounds for small depth circuits,"" Proc. 18-th
ACM STOC, pp. 6-20, 1986.

[11] J. J. Hopfield, ""Neural networks and physical sytems with emergent collective
computational abilities,"" Proc. Natl. Acad. Sci. USA, vol. 79, pp. 25.54-2558,
1982.
[12] J. S. Judd, ""Complexity of connectionist learning with various node functions,""
Dept. of Computer and Information Science Technical Report, vol. 87-60, Univ.
of Massachussetts, Amherst, 1987.
[13] M. Kearns, M. Li, 1. Pitt, and L. Valiant, ""On the learnability of Boolean
formulae,"" Proc. 19-th ACM STOC, 1987.
[14] C. Koch, T. Poggio, and V. Torre, ""Retinal ganglion cells: A functional interpretation of dendritic morphology,"" Phil. Trans. R. Soc. London, vol. B 288,
pp. 227-264, 1982.

51
[15] R. J. McEliece, E. C. Posner, E. R. Rodemich, and S. S. Venkatesh, ""The
capacity of the Hopfield associative memory,"" IEEE Trans. Inform. Theory,
vol. IT-33, pp. 461-482, 1987.
[16] R. J. McEliece and E. C. Posner, ""The number of stable points of an infiniterange spin glass memory,"" JPL Telecomm. and Data Acquisition Progress Report, vol. 42-83, pp. 209-215, 1985.
[17] C. A. Mead (ed.), Analog VLSI and Neural Systems, Addison Wesley, 1987.
[18] N. Megiddo, ""On the complexity of polyhedral separability,"" to appear in Jnl.
Discrete and Computational Geometry, 1987.
[19] S. Muroga, ""Lower bounds on the number of threshold functions,"" IEEE Trans.
Elec. Comp., vol. 15, pp. 805-806, 1966.
[20] S. Muroga, Threshold Logic and its Applications, Wiley Interscience, 1971.
[21] V. N. Peled and B. Simeone, ""Polynomial-time algorithms for regular setcovering and threshold synthesis,"" Discr. Appl. Math., vol. 12, pp. 57-69, 1985.
[22] D. Psaltis and C. H. Park, ""Nonlinear discriminant functions and associative
memories,"" in Neural Networks for Computing. New York: AlP Conf. Proc.,
vol. 151, 1986.
[23] J. Reif, ""On threshold circuits and polynomial computation,"" preprint.
[24] R. Smolenski, ""Algebraic methods in the theory of lower bounds for Boolean
circuit complexity,"" Proc. J9-th ACM STOC, 1987.
[25] L. G. Valiant, ""A theory of the learnable,"" Comm. ACM, vol. 27, pp. 1134-1142,
1984.
[26] L. G. Valiant, ""Deductive learning,"" Phil. Trans. R. Soc. London, vol. A 312,
pp. 441-446, 1984.
[27] S. S. Venkatesh, Linear Maps with Point Rules: Applications to Pattern Classification and Associativ~ Memory. Ph.D. Thesis, California Institute of Technology, Aug. 1986.
[28] S. S. Venkatesh and D. Psaltis, ""Linear and logarithmic capacities in associative
neural networks,"" to appear IEEE Trans. Inform. Theory.
[29] S. S. Venkatesh, D. Psaltis, and J. Yu, private communication.
[30] R. O. Winder, ""Bounds on threshold gate realisability,"" IRE Trans. Elec.
Comp., vol. EC-12, pp. 561-564, 1963.
[31] A. C. C. Yaa, ""Separating the poly-time hierarchy by oracles,"" Proc. 26-th
IEEE FOCS, pp. 1-10, 1985.

"
67,1987,"Generalization of Back propagation to Recurrent and Higher Order Neural Networks","",67-generalization-of-back-propagation-to-recurrent-and-higher-order-neural-networks.pdf,"Abstract Missing","602

GENERALIZATION OF BACKPROPAGATION
TO
RECURRENT AND HIGHER ORDER NEURAL NETWORKS
Fernando J. Pineda

Applied Physics Laboratory, Johns Hopkins University
Johns Hopkins Rd., Laurel MD 20707
Abstract
A general method for deriving backpropagation algorithms for networks
with recurrent and higher order networks is introduced. The propagation of activation
in these networks is determined by dissipative differential equations. The error signal
is backpropagated by integrating an associated differential equation. The method is
introduced by applying it to the recurrent generalization of the feedforward
backpropagation network. The method is extended to the case of higher order
networks and to a constrained dynamical system for training a content addressable
memory. The essential feature of the adaptive algorithms is that adaptive equation has
a simple outer product form.
Preliminary experiments suggest that learning can occur very rapidly in
networks with recurrent connections. The continuous formalism makes the new
approach more suitable for implementation in VLSI.

Introduction
One interesting class of neural networks, typified by the Hopfield neural
networks (1,2) or the networks studied by Amari(3,4) are dynamical systems with three
salient properties. First, they posses very many degrees of freedom, second their
dynamics are nonlinear and third, their dynamics are dissipative. Systems with these
properties can have complicated attractor structures and can exhibit computational
abilities.
The identification of attractors with computational objects, e.g. memories at d
rules, is one of the foundations of the neural network paradigm. In this paradigl n,
programming becomes an excercise in manipulating attractors. A learning algorithm is
a rule or dynamical equation which changes the locations of fixed points to encode
information. One way of doing this is to minimize, by gradient descent, some
function of the system parameters. This general approach is reviewed by Amari(4)
and forms the basis of many learning algorithms. The formalism described here is a
specific case of this general approach.
The purpose of this paper is to introduce a fonnalism for obtaining adaptive
dynamical systems which are based on backpropagation(5,6,7). These dynamical
systems are expressed as systems of coupled first order differential equations. The
formalism will be illustrated by deriving adaptive equations for a recurrent network
with first order neurons, a recurrent network with higher order neurons and finally a
recurrent first order associative memory.

Example 1: Recurrent backpropagation with first order units
Consider a dynamical system whose state vector x evolves according to the
following set of coupled differential equations

? American Institute ofPhvsics 1988

603

dx?/dt
= -x'1 + g'(LW""X')
I
1. IJ J + I?I

(1)

J

where i=l, ... ,N. The functions g' are assumed to be differentiable and may have
different forms for various populations of neurons. In this paper we shall make no
other requirements on gi' In the neural network literature it is common to take these
functions to be Sigmoid shaped functions. A commonly used form is the logistic
function,
(2)

This form is biologically motivated since it attempts to account for the refractory phase
of real neurons. However, it is important to stress that there is nothing in the
mathematical content of this paper which requires this form -- any differentiable
function will suffice in the formalism presented in this paper. For example, a choice
which may be of use in signal processing is sin(~).
A necessary condition for the learning algorithms discussed here to exist is that the
system posesses stable isolated attractors, i.e. fixed points. The attractor structure of
(1) is the same as the more commonly used equation
du/dt = -ui +~Wijg(Uj) + Ki'

(3)

J

Because (1) and (3) are related by a simple linear transformation. Therefore results
concerning the stability of (3) are applicable to (1). Amari(3) studied the dynamics of
equation (3) in networks with random conections. He found that collective variables
corresponding to the mean activation and its second moment must exhibit either stable
or bistable behaviour. More recently, Hopfield(2) has shown how to construct content
addressable memories from symmetrically connected networks with this same
dynamical equation. The symmetric connections in the network gaurantee global
stability. The solution of equation (1) is also globally asymptotically stable if w can be
transformed into a lower triangular matrix by row and column exchange operations.
This is because in such a case the network is a simply a feedforward network and the
output can be expressed as an explicit function of the input. No Liapunov function
exists for arbitrary weights as can be demonstrated by constructing a set of weights
which leads to oscillation. In practice, it is found that oscillations are not a problem
and that the system converges to fixed points unless special weights are chosen.
Therefore it shall be assumed, for the purposes of deriving the backpropagation
equations, that the system ultimately settles down to a fixed point.
Consider a system of N neurons, or units, whose dynamics is determined by
equation (1). Of all the units in the network we will arbitrarily define some subset of
them (A) as input units and some other subset of them (0) as output units. Units
which are neither members of A nor 0 are denoted hidden units. A unit may be
simultaneously an input unit and an output unit. The external environment influences
the system through the source term, I. If a unit is an input unit, the corresponding
component of I is nonzero. To make this more precise it is useful to introduce a
notational convention. Suppose that <I> represent some subset of units in the network
then the function 8i<I> is defined by
8'm= {
1'V

1

if i-th unit is a member of <I>

0

o therwise

(4)

In terms of this function, the components of the I vector are given by
(5)

604

where ~i is detennined by the external environment.
Our goal will be to fmd a local algorithm which adjusts the weight matrix w so that
a given initial state XO = x(to)' and a given input I result in a fixed point, xoo= x(too ),
whose components have a desired set of values Ti along the output units. This will be
accomplished by minimizing a function E which tneasures the distance between the
desired fixed point and the actual fixed point i.e.,
1 N
E = - :E Ji2
(6)

2 i=l
where

J.I -- (T.I - xoo.I ) e'n
I.u.

(7)

E depends on the weight matrix w through the fixed point Xoo(w). A learning
algorithm drives the fixed points towards the manifolds which satisfy xi00 = Ti on the
output units. One way of accomplishing this with dynamics is to let the system evolve
in the weight space along trajectories which are antiparallel to the gradient of E. In
. other words,
dE
(8)
dWi/dt = - T\ -

dw ..
IJ

where T\ is a numerical constant which defines the (slow) time scale on which w
changes. T\ must be small so that x is always essentially at steady state, i.e.
x(t) == xoo. It is important to stress that the choice of gradient descent for the learning
dynamics is by no means unique, nor is it necessarily the best choice. Other learning
dynamics which employ second order time derivatives (e.g. the momentum
method(5? or which employ second order space derivatives (e.g. second order
backpropagation(8? may be more useful in particular applications. However, equation
(8) does have the virtue of being the simplest dynamics which minimizes E.
On performing the differentiations in equation (8), one immediately obtains

dwrs/dt = T\ 1: Jk
k

dx ook

awrs

(9)

The derivative of xook with respect to wrs is obtained by first noting that the fixed
points of equation (1) satisfy the nonlinear algebraic equation
oo .) + J.
Xoo.I = g?(:Ewoox
I . IJ
J
I'

(10)

J

differentiating both sides of this equation with respect to Wrs and finally solving for
dxooId dW rs ' The result is
dXook
= (L- 1)kr gr'(Ur)xoo s
(11)
dWrs
where gr' is the derivative of gr and where the matrix L is given by
(12)
Bii is the Kroneker Bfunction ( BU= 1 if i=j, otherwise Bij = 0). On substituting (11)
into (9) one obtains the remarkablY simple form

605

where

dWrsldt

=11 YrXoo s

(13)

(14)
Yr = gr'(u r ) LJk(L -1)kr
k=
Equations (13) and (14) specify a fonnallearning rule. Unfortunately, equation
(14) requires a matrix inversion to calculate the error signals Yk' Direct matrix
inversions are necessarily nonlocal calculations and therefore this learning algorithm is
not suitable for implementation as a neural network. Fortunately, a local method for
calculating Yr can be obtained by the introduction of an associated dynamical system.
To obtain this dynamical system fIrst rewrite equation (14) as
LLrk (Yr / gr'(ur )} = Jk .
(15)
r
Then multiply both sides by fk'(uk)' substitute the explicit form for L and finally sum
over r. The result is
o= - Yk + gk'(uk){ LWrkYr + Jk} .
(16)
r
One now makes the observation that the solutions of this linear equation are the fIxed
points of the dynamical system given by
dYk/dt = - Yk +gk'(uk){LWrkYr + Jk} .
(17)
r
This last step is not unique, equation (16) could be transformed in various ways
leading to related differential equations, cf. Pineda(9). It is not difficult to show that
the frrst order fInite difference approximation (with a time step ~t = 1) of equations
(1), (13) and (17) has the same form as the conventional backpropagation algorithm.
Equations (1), (13) and (17) completely specify the dynamics for an adaptive
neural network, provided that (1) and (17) converge to stable fixed points and
provided that both quantities on the right hand side of equation (13) are the steady
state solutions of (1) and (17).
It was pointed out by Almeida(10) that the local stability of (1) is a sufficient
condition for the local stability of (17). To prove this it suffices to linearize equation
(1) about a stable fixed point. The resulting linearized equation depends on the same
matrix L whose transpose appears in the derivation of equation (17), cf. equation
(15). But Land LT have the same eigenValues, hence it follows that the fIXed points
of (17) must also be locally stable if the fIxed points of (1) are locally stable.

Learning multiple associations
It is important to stress that up to this point the entire discussionhas assumed that I
and T are constant in time, thus no mechanism has been obtained for learning multiple
input/output associations. Two methods for training the network to learn multiple
associations are now discussed. These methods lead to qualitatively different learning
behaviour.
Suppose that each input/output pair is labeled by a pattern label n, i.e. {In ,Tn}.
Then the energy function which is minimized in the above discussion must also
depend on this label since it is an implicit function of the In ,Tn pairs. In order to
learn multiple input/output associations it is necessary to minimize all the E[n]
simultaniously. In otherwords the function to minimize is
(18)

606

where the sum is over all input/output associations. From (18) it follows that the
gradient for Etotal is simply the sum of the gradients for each association, hence the
corresponding gradient descent equation has the form,

= 11 L yOOi[a] xOOia] .
(19)
a
In numerical simulations, each time step of (19) requires relaxing (1) and (17) for each
pattern and accumulating the gradient over all the patterns. This fonn of the algorithm
is deterministic and is guaranteed to converge because, by construction, Etotal is a
Liapunov function for equation (19). However, the system may get stuck m a local
minimum. This method is similar to the master/slave approach of Lapedes and
Farber(1l). Their adaptive equation, which plays the same role as equation (19), also
has a gradient form, although it is not strictly descent along the gradient. For a
randomly or fully connected network it can be shown that tbe number of oper~tions
required per weight update in the master/slave fonnalis~ is proportional to N where
N is the number of units. This is because there are O(N ) update equations and each
equation requires O(N) operations (assuming some precomputation). On the other
hand, in the backpropagation formalism each update equation re~uires only 0(1)
operations because of their trivial outer product form. Also O(N ) operations are
required t~ precompute XOO and yoo. The result is that each weight update requires
only O(N ) operations. It is not possible to conclude from this argument that one or
the other approach will be more efficient in a particular application because there are
other factors to consider such as the number of patterns and the number of time steps
required for x and y to converge. A detailed comparison of the two methods is in
preparation.
A second approach to learning multiple patterns is to use (13) and to change the
patterns randomly on each time step. The system therefore receives a sequence of
random impulses each of which attempts to minimize E[ex] for a single pattern. One
can then defme L(w) to be the mean E[a] (averaged over the distribution of patterns).
dWijldt

L(w) = <E [w, la,Ta ]>

(20)

Amari(4) has pointed out that if the sequence of random patterns is stationary and if
L(w) has a unique minimum then the theory of stochastic approximation guarantees
that the solution of (13) wet) will converge to the minimum point '!min of L(w) to
within a small fluctuating tenn which vanishes as 11 tends to zero. hVlaently 11 is
analogous to the temperature parameter in simulated annealing. This second approach
generally converges more slowly than the first, but it will ultimately converge (in a
statistical sense) to the global minimum.
In principle the fixed points, to which the solutions of (1) and (17) eventually
converge, depend on the initial states. Indeed, Amari's(3) results imply that equation
(1) is bistable for certain choices of weights. Therefore the presentation of multiple
patterns might seem problematical since in both approaches the final state of the
previous pattern becomes the initial state of the new pattern. The safest approach is to
reinitialize the network to the same initial state each time a new pattern is presented.
e.g. xi(t~ = 0.5 for all i. In practice the system learns robustly even if the initial
conditIons are chosen randomly.

Example 2: Recurrent higher order networks
It is straightforward to apply the technique of the previous section to a dynamical
system with higher order units. Higher order systems have been studied by
Sejnowski (12) and Lee et al.(13). Higher order networks may have definite advantages

607

over networks with first order units alone A detailed discussion of the
backpropagation fonnalism applied to higher order networks is beyond the scope of
this paper. Instead, the adaptive equations for a network with purely n-th order units
will be presented as an example of the fonnalism. To this end consider a dynamical
system of the fonn
dx?/dt
-- -x'1 + g'(lI!)
I
1-:1 + I?1

(21)

where
(22)

and where there are n+ 1 indices and the summations are over all indices except i. The
superscript on the weight tensor indicates the order of the correlation. Note that an
additional nonlinear function f has been added to illustrate a further generalization.
Both f and g must be differentiable and may be chosen to be sigmoids. It is not
difficult, although somewhat tedious, to repeat the steps of the previous example to
derive the adaptive equations for this system. The objective function in this case is the
same as was used in the fIrst example, i.e. equation (6). The n-th order gradient
descent equation has the fonn
(23)

Equation (23) illustrates the major feature of backpropagation which distinguishes it
from other gradient descent algorithms or similar algorithms which make use of a
gradient. Namely, that the gradient of the objective function has a very trivial outer
product fonn. y (n)oo is the steady state solution of
dy(n)k/dt = - y(n)k + gk'(uk) {fk'(xk)Ly(n)rkY (n)r + Jk }.
(24)
r
The matrix v(n) plays the role of w in the previous example, however v(n) now
depends on the state of the network according to
y(n)ij

= L'""

L s<n)ijk""'l ( f(xk) ... f(xI)}

(25)

k I
where is s(n) a tensor which is symmetric with respect to the exchange of the second
index and all the indices to the right, i.e.
S(n)..IJk""1 --

w(n)

ijk""'l

+ w(n)

ikj""'l

+ ... + w(n)

ijl""'k .

(26)

Finally, it should be noted that: 1) If the polynomial ui is not homogenous, the
adaptive equations are more complicated and involve cross tenns between the various
orders and that: 2) The local stability of the n-th order backpropagation equations now
depends on the eigenvalues of the matrix

L .. = 0"" - g.'(u?) f.'(x?) y(n) ..
IJ

IJ

1

1

1

1

IJ'

(27)

As before, if the forward propagation converges so will the backward propagation.

Example 3: Adaptive content addressable memory
In this section the adaptive equations for a content addressable memory
(CAM) are derived as a fmal illustration of the generality of the formalism. Perhaps

608

the best known (and best studied) examples of dYnamical systems which exhibit CAM
behaviour are the systems discussed by Hopfield(l). Hopfield used a nonadaptive
method for programming the symmetric weight matrix. More recently Lapedes and
Farber<ll) have demonstrated how to contruct a master dynamical system which can be
used to train the weights of a slave system which has the Hopfield fonn. This slave
system then performs the CAM operation. The resulting weights are not symmetric.
The learning proceedure presented in this section is most closely related to the
method of Lapedes and Farber in that a master network is used to adjust the weights of
a slave network. In constrast to the afforementioned formalism, which requires a
very large associated weight matrix for the master network, both the master and slave
networks of the following approach make use of the same weight matrix. The CAM
under consideration is based on equation (1). However, the interpretation of the
dynamics will be somewhat different from the first section. The main difference is that
the dynamics in the learning phase is constrained. The constrained dynamical system
is denoted the master network. The unconstrained system is denoted the slave
network. The units in the network are divided into only two sets: the set of visible
units (V) and the set of internal or hidden units (H). There will be no distinction made
between input and output units. Thus, I will generally be zero unless an input bias is
needed in some application.
The dynamical system will be used as an autoassociative memory, thus the
memory recall is performed by starting the network at a particular initial state which
represents partial information about a stored memory. More precisely, suppose that
there exists a subset K of the visible units whose states are known to have values Ti'
Then the initial state of the network is
(28)

where the bi are arbitrary. The CAM relaxes to the previously stored memory whose
basin of attraction contains this partial state.
Memories are stored by a master network whose topology is exactly the same
as the slave network, but whose dynamics is somewhat modified. The state vector z
of the master network evolves according to the equation
N
d~/dt = -~

+ gi(LwikZk) + Ii

(29)

k=l

where Z is defmed by
Z,1 = T?1 E)?V
+ z?1 E)'H
1
1

?

(30)

The components of Z along the visible units are just the target value specified by T.
This equation is useful as a master equation because if the weights can be chosen so
that the zi of the visible units relax to the target values Ti,: then a fixed point of (29) is
also a fixed point of (1). It can be concluded therefore, that by training the weights of
the master network one is also training the weights of the slave network. Note that the
form of Z implies that equation (29) can be rewritten as
(31)
where
9 i = - LWikTk .

(32)

keY

From equations (31) and (32) it is clear that the dynamics of the master system is
driven by the thresholds which depend on the targets.

609

To derive the adaptive equations consider the objective function
1 N
2
E master =2"" 1: Ii

(33)

i=l

where
(34)
It is straightforward to apply the steps discussed in previous sections to EJ1Iaster' This
results in adaptive equations for the weights. The mathematical details Will be omitted
since they are essentially the same as before, the gradient descent equation is
dWi/dt = 11yooiZOOj

(35)

where yOO is the steady state solution of

where

dyk""dt = - Yk +g'k(vkHeiHLwrkYr + Ik}
r
vi i ~ikZook .

(36)
(37)

Equations (31), and (35)-37) define the dynamics of the master network. To train the
slave network to be an autoassociative memory it is necessary to use the stored
memories as the initial states of the master network, i.e.
z?(t
1 0 ) = T?1 e?1V + b?1 eiH

(39)

where bi is an arbitrary value as before. The previous discussions concerning the
stability of the three equations (1), (13) and (17) apply to equations (31) (35) and (36)
as well. It is also possible to derive the adaptive equations for a higher order
associative network, but this will not be done here.
Only preliminary computer simulations have been performed with this
algorithm to verify their validity, but more extensive experiments are in progress. The
fIrst simulation was with a fully connected network with 10 visible units and 5 hidden
units. The training set consisted of four random binary vectors with the magnitudes of
the vectors adjusted so that 0.1 ~ Ti S; 0.9. The equations were approximated by first
order fmite difference equations with ~t = 1 and 11 = 1. The training was performed
with the detenninistic method for learning multiple associations. Figure 1. shows
Etotal as a function of the number of updates for both the master and slave networks.
Etota! for the slave exhibits discontinous behaviour because the trajectory through the
weight space causes x(to ) to cut across the basins of attraction for the fixed points of
equation (1).
The number of updates required for the network to learn the patterns is
relatively modest and can be reduced further by increasing 11. This suggests that
learning can occur very rapidly in this type of network.

Discussion
The algorithms presented here by no means exhaust the class of possible
adaptive algorithms which can be obtained with this formalism. Nor is the choice of
gradient descent a crucial feature in this formalism. The key idea is that it is possible
to express the gradient of an objective function as the outer product of vectors which
can be calculated by dynamical systems. This outer produc2,form is also responsible
for the fact that the gradient can be calculated with only O(N ) operations in a fully
connected or randomly connected network. In fact the number of operations per

610

weight update is proportional to the number of connections in the network. The
methods used here will generalize to calculate higher order derivatives of the objective
function as well.
The fact that the algorithms are expressed as differential equations suggests
that they may be implemented in analog electronic or optical hardware.

2.00 . . . . . - - - - - - - - - - - - - - ,

~

Master
-.- Slave

1.00 --"""",.. ~

20

40
60
Updates

80

100

figure 1. Etota! as a function of the the number of updates.
References
(1)
(2)
(3)
(4)

(5)
(6)

(7)
(8)

I. J. HopfieJd. Neural Networks as Physical Systems with Emergent Collective
Computational Abilities. Proc. Nat. Acad. Sci. USA. Bio.79. 2554-2558.
(1982)
1. I. Hopfield. Neurons with graded response have collective computational
properties like those of two-state neurons. Proc. Nat. Acad. Sci. USA. Bio. .8l,
3088-3092. (1984)
Shun-Ichi Amari. IEEE Trans. on Systems Man and Cybernetics. 2.643-657.
(1972)
Shun-Ichi Amari. in Systems Neuroscience. ed. Jacqueline Metzler.
Academic press. (1977)
D. E. Rumelhart. G. E. Hinton and R.I. Williams. in Parallel Distributed
Processing. edited by D. E. Rumelhart and 1. L. McClelland.
M.LT. press. (1986)
David B. Parker. Learning-Logic, Invention Report. S81-64. File 1.
Office of Technology Licensing. Stanford University. October. 1982
Y. LeChun. Proceedings of Cognitiva. 85. p. 599. (1985)
David B. Parker. Second Order Backpropagation: Implementing an Optimal

O(n) Approximation to Newton's Method as an Artificial Neural Network.
submitted to Computer. (1987)
Fernando J. Pineda. Generalization ofbackpropagation to recurrent neural
networks, Phys. Rev. Lett.? l.8. 2229-2232. (1987)
(10) Luis B. Almeida. in the Proceedings of the IEEE First Annual International
Conference on Neural Networks. San Diego. California. June 1987. edited by

(9)

611

M. Caudil and C. Butler (to be published This is a discrete version of the
algorithm presented as the fIrst example
(11) Alan Lapedes and Robert Farber, A self-optimizing, nonsymmetrical neural net
for content addressable memory and pattern recognition, Physica, D22,
247-259, (1986), see also, Programming a Massively Parallel, Computation
Universal System: Static Behaviour, in Neural Networks for Computing
Snowbird, UT 1986, AIP Conference Proceedings, 151, (1986),
edited by John S. Denker
(12) Terrence J. Sejnowski, Higher-order Boltzmann Machines, Draft preprint
obtained from author
(13) Y.C. Lee, Gary Doolen, H.H. Chen, G.Z. Sun, Tom Maxwell, H.Y. Lee and
C. Lee Giles, Machine Learning using a higher order correlation network,
Physica D22, 276-306, (1986)

"
68,1987,"Schema for Motor Control Utilizing a Network Model of the Cerebellum","",68-schema-for-motor-control-utilizing-a-network-model-of-the-cerebellum.pdf,"Abstract Missing","367

SCHEMA
OT ILl ZING

A

I'OR

NETWORK

MOTOR
MODEL

CONTROL
01'

THE

CEREBELLUM

James C. Houk, Ph.D.
Northwestern University Medical School, Chicago, Illinois
60201
ABSTRACT

This paper outlines a schema for movement control
based on two stages of signal processing. The higher stage
is a neural network model that treats the cerebellum as an
array of adjustable motor pattern generators. This network
uses sensory input to preset and to trigger elemental
pattern generators and to evaluate their performance. The
actual patterned outputs, however, are produced by intrinsic circuitry that includes recurrent loops and is thus
capable of self-sustained activity. These patterned
outputs are sent as motor commands to local feedback
systems called motor servos. The latter control the forces
and lengths of individual muscles. Overall control is thus
achieved in two stages:
(1) an adaptive cerebellar network
generates an array of feedforward motor commands and (2) a
set of local feedback systems translates these commands
into actual movements.
INTRODUCTION

There is considerable evidence that the cerebellum is
involved in the adaptive control of movement 1 , although the
manner in which this control is achieved is not well understood. As a means of probing these cerebellar mechanisms,
my colleagues and I have been conducting microelectrode
studies of the neural messages that flow through the intermediate division of the cerebellum and onward to limb
muscles via the rubrospinal tract. We regard this cerebellorubrospinal pathway as a useful model system for studying
general problems of sensorimotor integration and adaptive
brain function. A summary of our findings has been published as a book chapter 2 .
On the basis of these and other neurophysiological
results, I recently hypothesized that the cerebellum functions as an array of adjustable motor pattern generators 3 .
The outputs from these pattern generators are assumed to
function as motor commands, i.e., as neural control signals
that are sent to lower-level motor systems where they
produce movements. According to this hypothesis, the
cerebellum uses its extensive sensory input to preset the
? American Institute of Physics 1988

368

pattern generators, to trigger them to initiate the
production of patterned outputs and to evaluate the success
or failure of the patterns in controlling a motor behavior.
However, sensory input appears not to playa major role in
shaping the waveforms of the patterned outputs. Instead,
these waveforms seem to be produced by intrinsic circuity.
The initial purpose of the present paper is to provide
some ideas for a neural network model of the cerebellum
that might be capable of accounting for adjustable motor
pattern generation. Several previous authors have
described network models of the cerebellum that, like the
present model, are based on the neuroanatomical organization of this brain structure 4 ,5,6. While the present model
borrows heavily from these previous models, it has some
additional features that may explain the unique manner in
which the cerebellum processes sensory input to produce
motor commands. A second purpose of this paper is to
outline how this network model fits within a broader schema
for motor control that I have been developing over the past
several years 3,7. Before presenting these ideas, let me
first review some basic physiology and anatomy of the
cerebelluml .
SIGNALS

AND

CIRCUITS

IN

TRB

CBRBBBLLUM

There are three main categories of input fibers to the
cerebellum, called mossy fibers, climbing fibers and
noradrenergic fibers. As illustrated in Fig. 1, the mossy
fiber input shows considerable fan-out via granule cells
and parallel fibers. The parallel fibers in turn are
arranged to provide a high degree of fan-in to individual
Purkinje cells (P). These P cells are the sole output
elements of the cortical portion of the cerebellum. Via
the parallel fiber input, each P cell is exposed to
approximately 200,000 potential messages. In marked
contrast, the climbing fiber input to P cells is highly
focused. Each climbing fiber branches to only 10 P cells,
and each cell receives input from only one climbing fiber.
Although less is known about input via noradrenergic
fibers, it appears to be diffuse and even more divergent
than the mossy fiber input.
Mossy fibers originate from several brain sites transmitting a diversity of information about the external world
and the internal state of the body. Some mossy fiber
inputs are clearly sensory. They come fairly directly from
cutaneous, muscle or vestibular receptors. Others are
routed via the cerebral cortex where they represent highly
processed visual, auditory or somatosensory information.
Yet another category of mossy fiber transmits information
about central motor commands (Fig. 1 shows one such pathway, from collaterals of the rubrospinal tract relayed

369

through the lateral reticular nucleus (L?. The discharge
rates of mossy fibers are modulated over a wide dynamic
range which permits them to transmit detailed parametric
information about the state of the body and its external
environment.

noradrenergic

fibers

Sensory
Inputs

sensorimotor
cortex

--o~Ll

Motor
______________________________~)--~C~o~m~m=M~d=s~
rubrospinal tract

Figure 1: Pathways through the cerebellum. This diagram,
which highlights the cerebellorubrospinal system, also
constitutes a circuit diagram for the model of an
elemental pattern generator.
The sole source of climbing fibers is from cells
located in the inferior olivary nucleus. Olivary neurons
are selectively sensitive to sensory events. These cells
have atypical electrical properties which limit their
discharge to rates less than 10 impulses/sec, and usual
rates are closer to 1 impulse/sec. As a consequence,

370

individual climbing fibers transmit very little parametric
information about the intensity and duration of a stimulus;
instead, they appear to be specialized to detect simply the
occurrences of sensory events. There are also motor inputs
to this pathway, but they appear to be strictly inhibitory.
The motor inputs gate off responsiveness to self-induced
(or expected) stimuli, thus converting olivary neurons into
detectors of unexpected sensory events.
Given the abundance of sensory input to P cells via
mossy and climbing fibers, it is remarkable that these
cells respond so weakly to sensory stimulation. Instead,
they discharge vigorously during active movements. P cells
send abundant collaterals to their neighbors, while their
main axons project to the cerebellar nuclei and then onward
to several brain sites that in turn relay motor commands to
the spinal cord.
Fig. 1 shows P cell projections to the intermediate
cerebellar nucleus (I), also called the interpositus
nucleus. The red nucleus (R) receives its main input from
the interpositus nucleus, and it then transmits motor
commands to the spinal cord via the rubrospinal tract.
Other premotor nuclei that are alternative sources of motor
commands receive input from alternative cerebellar output
circuits. Fig. 1 thus specifically illustrates the
cerebellorubrospinal system, the portion of the cerebellum
that has been emphasized in my laboratory.
Microelectrode recordings from the red nucleus have
demonstrated signals that appear to represent detailed
velocity commands for distal limb movements.
Bursts of
discharge precede each movement, the frequency of discharge
within the burst corresponds to the velocity of movement,
and the duration of the burst corresponds to the duration
of movement. These velocity signals are not shaped by
continuous feedback from peripheral receptors; instead,
they appear to be produced centrally. An important goal of
the modelling effort outlined here is to explain how these
velocity commands might be produced by cerebellar circuits
that function as elemental pattern generators. I will then
discuss how an array of these pattern generators might
serve well in an overall schema of motor control.
ELEMENTAL

PATTBRN

GBNERATORS

The motivation for proposing pattern generators rather
than more conventional network designs derives from the
experimental observation that motor commands, once initiated, are not affected, or are only minimally affected, by
alterations in sensory input. This observation indicates
that the temporal features of these motor commands are
produced by self-sustained activity within the neural
network rather than by the time courses of network inputs.

371
Two features of the intrinsic circuitry of the cerebellum may be particularly instrumental in explaining selfsustained activity. One is a recurrent pathway from cerebellar nuclei that returns back to cerebellar nuclei. In
the case of the cerebellorubrospinal system in Fig. 1, the
recurrent pathway is from the interpositus nucleus to red
nucleus to lateral reticular nucleus and back to interpositus, what I will call the IRL loop. The other feature of
intrinsic cerebellar circuitry that may be of critical
importance in pattern generation is mutual inhibition
between P cells. Fig. 1 shows how mutual inhibition
results from the recurrent collaterals of P-cell axons.
Inhibitory interneurons called basket and stellate cells
(not shown in Fig. 1) provide additional pathways for
mutual inhibition. Both the IRL loop and mutual inhibition
between P cells constitute positive feedback circuits and,
as such, are capable of self-sustained activity.
Self-sustained activity in the form of high-frequency
spontaneous discharge has been observed in the IRL loop
under conditions in which the inhibitory P-cell input to I
cells is blocked 3. Trace A in Fig. 2 shows this unrestrained discharge schematically, and the other traces
illustrate how a motor command might be sculpted out of
this tendency toward high-frequency, repetitive discharge.
Trace B shows a brief burst of input presumed to be
sent from the sensorimotor cortex to the R cell in Fig. 1.
This burst serves as a trigger that initiates repetitive
discharge in an IRL loop, and trace D illustrates the
discharge of an I cell in the active loop. The intraburst
discharge frequency of this cell is presumed to be
determined by the summed magnitude of inhibitory input
(shown in trace C) from the set of P cells that project to
it (Fig. 1 shows only a few P cells from this set). Since
the inhibitory input to I was reduced to an appropriate
magnitude for controlling this intraburst frequency some
time prior to the arrival of the trigger event, this
example illustrates a mechanism for presetting the pattern
generator. Note that the same reduction of inhibition that
presets the intraburst frequency would bring the loop
closer to the threshold for repetitive firing, thus serving
to enable the triggering operation. The I-cell burst,
after continuing for a duration appropriate for the desired
motor behavior, is assumed to be terminated by an abrupt
increase in inhibitory input from the set of P cells that
project to I (trace C).
The time course of bursting discharge illustrated in
Fig. 2D would be expected to propagate throughout the IRL
loop and be transmitted via the rubrospinal tract to the
spinal cord where it could serve as a motor command.
Bursts of R-cell discharge similar to this are observed to
precede movements in trained monkey subjects2.

372

A.
111111111111111111111111111111111111111111111111111111111111111111111111

B.
1111

c.

D.

111111111111111
time -

Figure 2: Signals Contributing to Pattern Generation. A.
Repetitive discharge of I cell in the absence of Pcell inhibition. B. Trigger burst sent to the IRL
loop from sensorimotor cortex. C. Summed inhibition
produced by the set of P cells projecting to the I
cell. D. Resultant motor pattern in I cell.
The sculpting of a motor command out of a repetitive
firing tendency in the IRL loop clearly requires timed
transitions in the discharge rates of specific P cells.
The present model postulates that the latter result from
state transitions in the network of P cells. Bell and
Grimm8 described spontaneous transitions in P-cell firing
that occur intermittently, and I have frequently observed
them as well. These transitions appear to be produced by
intrinsic mechanisms and are difficult to influence with
sensory stimulation. The mutual recurrent inhibition
between P cells might explain this tendency toward state
transitions.
Recurrent inhibition between P cells is mediated by
synapses near the cell bodies and primary dendrites of the
P cells whereas parallel fiber input extends far out on the
dendritic tree. This arrangement may explain why sensory
input via parallel fibers does not have a strong, continuous effect on P cell discharge. This sensory input may
serve mainly to promote state transitions in the network of
P cells, perhaps by modulating the likelihood that a given
P cell would participate in a state transition. Once the

373

transition starts, the activity of the P cell may be dominated by the recurrent inhibition close to the cell body.
The mechanism responsible for the adaptive adjustment
of these elemental pattern generators may be a change in
the synaptic strengths of parallel fiber input to P cells 9 .
Such alterations in the efficacy of sensory input would
influence the state transitions discussed in the previous
paragraph, thus mediating adaptive adjustments in the
amplitude and timing of patterned output. Elsewhere I have
suggested that this learning process is analogous to operant conditioning and includes both positive and negative
reinforcement 3 . Noradrenergic fibers might mediate positive reinforcement, whereas climbing fibers might mediate
negative reinforcement. For example, if the network were
controlling a limb movement, negative reinforcement might
occur when the limb bumps into an object in the work space
(climbing fibers fire in response to unexpected somatic
events such as this), whereas positive reinforcement might
occur whenever the limb successfully acquires the desired
target (the noradrenergic fibers to the cerebellum are
thought to receive input from reward centers in the brain) .
Positive reinforcement may be analogous to the associative
reward-punishment algorithm described by BartolO which
would fit with the diffuse projections of noradrenergic
fibers. Negative reinforcement might be capable of a
higher degree of credit assignment in view of the more
focused projections of climbing fibers.
In summary, the previous paragraphs outline some ideas
that may be useful in developing a network model of the
cerebellum. This particular set of ideas was motivated by
a desire to explain the unique manner in which the cerebellum uses sensory input to control patterned output. The
model deals explicitly with small circuits within a much
larger network. The small circuits are considered elemental pattern generators, whereas the larger network can be
considered an array of these pattern generators. The
assembly of many elements into an array may give rise to
some emergent properties of the network, due to
interactions between the elements. However, the highly
compartmentalized anatomical structure of the cerebellum
fosters the notion of relatively independent elemental
pattern generators as hypothesized in the schema for
movement control presented in the next section.
SCHEMA

I'OR MOTOR

CONTROL

A major aim in developing the elemental pattern
generator model described in the previous section was to
explain the intriguing manner in which the cerebellum uses
sensory input. Stated succinctly, sensory input is used to
preset and to trigger each elemental pattern generator and

374

to evaluate the success of previous output patterns in
controlling motor behavior. However, sensory input is not
used to shape the waveform of an ongoing output pattern.
This means that continuous feedback is not available, at
the level of the cerebellum, for any immediate adjustments
of motor commands.
Is this kind of behavior actually advantageous in the
control of movement? I would propose the affirmative,
particularly on the grounds that this strategy seems to
have withstood the test of evolution. Elsewhere I have
reviewed the global strategies that are used to control
several different types of body function 11 ?
A common
theme in each of these physiological control systems is the
use of negative feedback only as a low-level strategy, and
this coupled with a high-level stage of adaptive
feedforward control. It was argued that this particular
two-stage control strategy is well suited for utilizing the
advantageous features of feedback, feedforward and adaptive
control in combination.
The adjustable pattern generator model of the cerebellum outlined in the previous section is a prime example of
an adaptive, feedforward controller. In the subsequent
paragraphs I will outline how this high-level feedforward
controller communicates with low-level feedback systems
called motor servos to produce limb movements (Fig. 3).
The array of adjustable pattern generators (PGn) in
the first column of .Fig. 3 produce an array of elemental
commands that are transmitted via descending fibers to the
spinal cord. The connectivity matrix for descending fibers
represents the consequences of their branching patterns.
Any given fiber is likely to branch to innervate several
motor servos. Similarly, each member of the array of motor
servos (MS m) receives convergent input from a large number
of pattern generators, and the summed total of this input
constitutes its overall motor command.
A motor servo consists of a muscle, its stretch receptors and the spinal reflex pathways back to the same muscle 12 ? These reflex pathways constitute negative feedback
loops that interact with the motor command to control the
discharge of the motor neuron pool innervating the
particular muscle. Negative feedback from the muscle
receptors functions to maintain the stiffness of the muscle
relatively constant, thus providing a spring-like interface
between the body and its mechanical environment 13 ? The
motor command acts to set the slack length of this
equivalent spring and, in this way, influences motion of
the limb. Feedback also gives rise to an unusual type of
damping proportional to a low fractional power of
velocit y 14. The individual motor servos interact with each
other and with external loads via the trigonometric
relations of the musculoskeletal matrix to produce
resultant joint positions.

375

Cerebellar
Network
elemental
commands

PG 1

r----

Motor
Servos

......... --

PG 2
...... -- ......

PG 3
.. -- .......

...

(II

forces,
lengths

motor
commands

CD

MS 1

u:

._.. -------

..c

joint
positions

shoulder

CI

c

'6
c

CD

&lCD

MS2

..........
)(

0

...0

?C

u.

~

)(

""ii

a;

-

?C

a;

CD
G)

~

~
a
""3

f

~C
C

8

elbow

wrist

&l

:J

...........

~

finger

MSM

....... -...

PG N

---

External
Load

-----

Figure 3: Schema for Motor Control Utilizing Pattern Generator Model of Cerebellum. An array of elemental
pattern generators (PGn ) operate in an adaptive, feedforward manner to produce motor commands. These outputs of the high-level stage are sent to the spinal
cord where they serve as inputs to a low-level array
of negative feedback systems called motor servos
(MS m). The latter regulate the forces and lengths of
individual muscles to control joint angles.
While the schema for motor control presented here is
based on a considerable body of experimental data, and it
also seems plausible as a strategy for motor control, it
will be important to explore its capabilities for human
limb control with simulation studies. It may also be
fruitful to apply this schema to problems in robotics.
Since I am mainly an experimentalist, my authorship of this
paper is meant as an entre for collaborative work with
neural network modelers that may be interested in these
problems.

376

RJ:I'J:RJ:HCJ:S

1. M. Ito, The Cerebellum and Neural Control (Raven
Press, N. Y., 1984).
2. J. C. Houk & A. R. Gibson, In: J. S. King, New
Concepts in Cerebellar Neurobiology (Alan R. Liss,
Inc., N. Y., 1987), p. 387.
3. J. C. Houk, In: M. Glickstein & C. Yeo, Cerebellum and
Neuronal Plasticity (Plenum Press, N. Y., 1988), in
press.
4. D. Marr, J. Physiol. (London) 2D2, 437 (1969).
5. J. S. Albus, Math. Biosci. lQ, 25 (1971).
6. C. C. Boylls, A Theory of Cerebellar Function with
Applications to Locomotion (COINS Tech. Rep., U. Mass.
Amherst), 76-1.
7. J. C. Houk, In: J. E. Desmedt, Cerebral Motor Control
in Man: Long Loop Mechanisms (Karger, Basel, 1978), p.
193.
8. C. C. Bell & R. J. Grimm, J. Neurophysiol., J2, 1044
(1969) .
9 C.-F. Ekerot & M. Kano, Brain Res., ~, 357 (1985).
10. A. G. Barto, Human Neurobiol., ~, 229 (1985).
11. J. C. Houk, FASEB J., Z, 97-107 (1988).
12. J. C. Houk & W. Z. Rymer, In: V. B. Brooks, Handbook
of Physiology, Vol. 1 of Sect. 1 (American Physiological Society, Bethesda, 1981), p.257.
13. J. C. Houk, Annu. Rev. Physiol., ~, 99 (1979).
14. C. C. A. M. Gielen & J. C. Houk, BioI. Cybern., 52,
217 (1987).

"
69,1987,"Spatial Organization of Neural Networks: A Probabilistic Modeling Approach","",69-spatial-organization-of-neural-networks-a-probabilistic-modeling-approach.pdf,"Abstract Missing","740

SPATIAL ORGANIZATION OF NEURAL NEn~ORKS:
A PROBABILISTIC MODELING APPROACH
A. Stafylopatis
M. Dikaiakos
D. Kontoravdis
National Technical University of Athens, Department of Electrical Engineering, Computer Science Division, 15773 Zographos,
Athens, Greece.
ABSTRACT
The aim of this paper is to explore the spatial organization of
neural networks under Markovian assumptions, in what concerns the behaviour of individual cells and the interconnection mechanism. Spaceorganizational properties of neural nets are very relevant in image
modeling and pattern analysis, where spatial computations on stochastic two-dimensional image fields are involved. As a first approach
we develop a random neural network model, based upon simple probabilistic assumptions, whose organization is studied by means of discrete-event simulation. We then investigate the possibility of approXimating the random network's behaviour by using an analytical approach originating from the theory of general product-form queueing
networks. The neural network is described by an open network of nodes, in which customers moving from node to node represent stimulations and connections between nodes are expressed in terms of suitably selected routing probabilities. We obtain the solution of the
model under different disciplines affecting the time spent by a stimulation at each node visited. Results concerning the distribution
of excitation in the network as a function of network topology and
external stimulation arrival pattern are compared with measures obtained from the simulation and validate the approach followed.
INTRODUCTION
Neural net models have been studied for many years in an attempt
to achieve brain-like performance in computing systems. These models
are composed of a large number of interconnected computational elements and their structure reflects our present understanding of the
organizing principles of biological nervous systems. In the begining, neural nets, or other equivalent models, were rather intended
to represent the logic arising in certain situations than to provide
an accurate description in a realistic context. However, in the last
decade or so the knowledge of what goes on in the brain has increased
tremendously. New discoveries in natural systems, make it now reasonable to examine the possibilities of using modern technology in
order to synthesige systems that have some of the properties of real
neural systems 8,9,10,11.
In the original neural net model developed in 1943 by McCulloch
and Pitts 1,2 the network is made of many interacting components,
known as the ""McCulloch-Pitts cells"" or ""formal neurons which are
simple logical units with two possible states changing state accordII ,

? American Institute of Physics 1988

741

ing to a threshold function of their inputs. Related automata models
have been used later for gene control systems (genetic networks) 3,
in which genes are represented as binary automata changing state according to boolean functions of their inputs. Boolean networks constitute a more general model, whose dynamical behaviour has been studied extensively. Due to the large number of elements, the exact
structure of the connections and the functions of individual components are generally unknown and assumed to be distributed at random.
Several studies on these random boolean networks 5,6 have shown that
they exhibit a surprisingly stable behaviour in what concerns their
temporal and spatial organization. However, very few formal analytical results are available, since most studies concern statistical
descriptions and computer simulations.
The temporal and spatial organization of random boolean networks
is of particular interest in the attempt of understanding the properties of such systems, and models originating from the theory of stochastic processes 13 seem to be very useful. Spatial properties of
neural nets are most important in the field of image recognition 12.
In the biological eye, a level-normalization computation is performed
by the layer of horizontal cells, which are fed by the immediately
preceding layer of photoreceptors. The horizontal cells take the
outputs of the receptors and average them spatially, this average
being weighted on a nearest-neighbor basis. This procedure corresponds to a mechanism for determining the brightness level of pixels
in an image field by using an array of processing elements. The
principle of local computation is usually adopted in models used for
representing and generating textured images. Among the stochastic
models applied to analyzing the parameters of image fields, the random Markov field model 7,14 seems to give a suitably structured representation, which is mainly due to the application of the markovian property in space. This type of modeling constitutes a promising alternative in the study of spatial organization phenomena in
neura 1 nets.
The approach taken in this paper aims to investigate some aspects of spatial organization under simple stochastic assumptions.
In the next section we develop a model for random neural networks
assuming boolean operation of individual cells. The behaviour of
this model, obtained through simulation experiments, is then approximated by using techniques from the theory of queueing networks.
The approximation yields quite interesting results as illustrated by
various examples.
THE RANDOM NETWORK MODEL
We define a random neural network as a set of elements or cells,
each one of which can be in one of two different states: firing or
quiet. Cells are interconnected to form an NxN grid, where each grid
point is occupied by a cell. We shall consider only connections between neighbors, so that each cell is connected to 4 among the other
cells: two input and two output cells (the output of a cell is equal
'to its internal state and it is sent to its output cells which use
;it as one of their inputs). The network topology is thus specified

742

by its incidence matrix A of dimension MxM, where M=N2. This matrix
takes a simple form in the case of neighbor-connection considered
here. We further assume a periodic structure of connections in what
concerns inputs and outputs; we will be interested in the following
two types of networks depending upon the period of reproduction for
elementary square modules 5, as shown in Fig.l:
- Propagative nets (Period 1)
- Looping nets
(Period 2)

-

....

\
I

""'

""';>

,
(b)

(a)

--

- '""'

-

Fig.1. (a) Propagative connections, (b) Looping connections
At the edges of the grid, circular connections are established (modulo N), so that the network can be viewed as supported by a torus.
The operation of tile network is non-autonomous: changes of state are determined by both the interaction among cells and the influence of external stimulations. We assume that stimulations arrive
from the outside world according to a Poisson process with parameter
A. Each arriving stimulation is associated with exactly one cell of
the network; the cell concerned is determined by means of a given
discrete probability distribution qi (l~i~M), considering an one-dimensional labeling of the Mcells.
The operation of each individual cell is asynchronous and can be
described in terms of the following rules:
- A quiet cell moves to the firing state if it receives an arriving
stimulation or if a boolean function of its inputs becomes true.
- A firing cell moves to the quiet state if a boolean function of its
inputs becomes false.
- Changes of state imply a reaction delay of the cell concerned; these delays are independent identically distributed random variables
following a negative exponential distribution with parameter y.
According to these rules, the operation of a cell can be viewed as illustrated by Fig.2, where the horizontal axis represents time and the
numbers 0,1,2 and 3 represent phases of an operation cycle. Phases 1
and 3, as indicated in Fig.2, correspond to reaction delays. In this
sense, the qui et and fi ri ng s ta tes, as defi ned in the begi ni ng of thi s
section, represent the aggregates of phases 0,1 and 2,3 respectively.
External stimulations affect the receiving cell only when it is in phase 0; otherwise we consider that the stimulation is lost. In the same way, we assume tha t changes of the value of the input boo 1ean function do not affect the operation of the cell during phases land 3. The
conditions are checked only at the end of the respective reaction delay.

743

quiet
state

~

I

/r

firing state
2

~

/

0
0
Fig.2. Changes of state for individual cells
The above defi ned model i ncl udes some fea tures of the ori gi na 1
McCulloch-Pitts cells 1,2. In fact, it represents an asynchronous
counterpart of the latter, in which boolean functions are considered
instead of threshold functions. However, it can be shown that any
McCulloch and Pitts' neural network can be implemented by a boolean
network designed in an appropriate fashion 5. In what follows, we will
consider that the firing condition for each individual cell is determined by an ""or"" function of its inputs.
Under the assumptions adopted, the evolution of the network in
time can be described by a conti nuous-parameter Markov process. However, the size of the state-space and the complexity of the system
are such that no analytical solution is tractable. The spatial organization of the network could be expressed in terms of the steadystate probability distribution for the Markov process. A more useful
representation is provided by the marginal probability distributions
for all cells in the network, or equivalently by the probability of
being in the firing state for each cell. This measure expresses the
level of excitation for each point in the grid.
We have studied the behaviour of the above model by means of simulation experiments for various cases depending upon the network size, the connection type, the distribution of external stimulation arrivals on the grid and the parameters A and V. Some examples are illustrated in the last section, in comparison with results obtained
using the approach discussed in the next section. The estimations obta i ned concern the probabil i ty of bei ng in the fi ri ng s ta te for all
cells in the network. The simulation was implemented according to
the ""batched means"" method; each run was carried out unti 1 the width
of the 95% confidence interval was less that 10% of the estimated
mean value for each cell, or until a maximum number of events had
been simulated depending upon the size of the network.
THE ANALYTICAL APPROACH
The neural network model considered in the previous section exhibited the markovian property in both time and space. Markovianity in
space, expressed by the principle of ""neighbor-connections"", is the
basic feature of Markov random fields 7,14, as already discussed. Our
idea is to attempt an approximation of the random neural network model by usi ng a well-known model, wlli ch is markovi an in time, and applying the constraint of markovianity in space. The model considered
is an open queueing network, which belongs to the general class of
queueing networks admitting a product-form solution 4. In fact, one
could distinguish several common features in the two network models.

744

A neural network, in general, receives information in the form of external stimulation signals and performs some computation on this information, which is represented by changes of its state. The operation of the network can be viewed as a flow of excitement among the
cells and the spatial distribution of this excitement represents the
response of the network to the information received. This kind of operation is particularly relevant in the processing of image fields. On
the other hand, in queueing networks, composed of a number of service
station nodes, customers arrive from the outside world and spend some
time in the network, during which they more from node to node, waiting and receiving service at each node visited. Following the external arrival pattern, the interconnection of nodes and the other network parameters, the operation of the network is characterized by a
distribution of activity among the nodes.
Let us now consider a queueing network, where nodes represent
cells and customers represent stimulations moving from cell to cell
following the topology of the network. Our aim is to define the network's characteristics in a way to match those of the neural net model as much as possible. Our queueing network model is completely
specified by the following assumptions:
- The network is composed of M=N2 nodes arranged on an NxN rectangular grid, as in the previous case. Interconnections are expressed by
means of a matrix R of routing probabilities: rij (l~i,j~) represents the probability that a stimulation (customer) leaving node i
will next visit node j. Since it is an open network, after visiting an
arbitrary number of cells, stimulations may eventually leave the network. Let riO denote the probability of leaving the network upon leaving node i. In what follows, we will assume that riO=s for all node's.
In what concerns the routing probauilities rij, they are determined
by the two interconnection schemata considered in the previous section (propagative and looping connections): each node i has two output nodes j, for which the routing probabilities are equally distributed. Thus, rij=(1-s)/2 for the two output nodes of i and equal to
zero for a11 0 ther nodes in the network.
- External stimulation arrivals follow a Poisson process with parameter A and are routed to the nodes according to the probability distribution qi (l~i<M) as in the previous section.
- Stimulations receive a ""service time"" at each node visited. Service
times are independent identically distributed random variables, which
are exponentially distributed with parameter V. The time spent by a
stimulation at a node depends also upon the ""service discipline""
adopted. We shall consider two types of service disciplines according
to the general queuei n9 network model 4: the fi rs t-come-fi rs t-served
(FCFS) discipline, where customers are served in the order of their
arrival to the node, and the infinite-server (IS) discipline, where
a customer's service is immediately assumed upon arrival to the node,
as if there were always a server available for each arriving customer (the second type includes no waiting delay). We will refer to the
above two types of nodes as type 1 and type 2 respectively. In either
case, all nodes of the network will be of the same type.
The steady-state solution of the above network is a straightforwa rd app 1i ca ti on of the general BCMP theorem 4 according to the

745

Isimple assumptions considered. The state of the system is described
,by the vector (kl,k2, ... ,kM), where ki is the number of customers
present at node i. We first define the traffic intensity Pi for each
node i as
(1)
i = 1,2, ... ,M
Pi = Aei/V
where the quantities {ei} are the solution of the following set of
linear equations:
M

ei

=

qi +

I

j=1

e?r ..

i =

J Jl

1,2, ... ,M

(2)

It can be easily seen that, in fact, ei represents the average number of visits a customer makes to node, i during his sojourn in the
network. The existence of a steady-state distribution for the system
depends on the sol uti on of the above set. Fo 11 owi ng the general theorem 4, the joint steady-state distribution takes the form of a product of independent distributions for the nodes:
p(k1,k2, ... ,kM} = ~1(k1)P2(k2} ?.? Pr~(kM)
(3)
where
ki
(I-P.}P.
(Type 1)
1
1
p.(k.)
(4)
k?
1
1 =
_p. p. 1
ell
(Type 2)

1

kiT

provided that the stabtlity condition Pi<1 is satisfied for type 1
nodes.
The product form solution of this type of network expresses the
idea of global and local balance which is characteristic of ergodic
Ivlarkov processes. We can then proceed to deri vi ng the des i red measure
for each node in the network; we are interested in the probability of
being active for each node, which can be interpreted as the probability that at least one customer is present at the node:
(Type 1)
Pi
(5 )
P(k .>O}=1-p.(O) =
_po
1
1
1-e 1
(Type 2)

1

The variation in space of the above quantity will be studied with respect to the corresponding measure obtained from simulation experiments for the neural network model.
.
NUMERICAL AND SIMULATION EXAMPLES
Simulations and numerical solutions of the queueing network motiel were run for different values of the parameters. The network sizes considered are relatively small but can provide useful information on the spatial organization of the networks. For both types of
service discipline discussed in the previous section, the approach
followed yields a very good approximation of the network's organization in most regions of the rectangular grid. The choice of the probability s of leaving the network plays a critical role in the beha-

746

(a)

(b)

Fig.3. A 10xiO network with A=l, V=l and propagative connections.
External stimulations are uniformly distributed over a 3x3 square
on the upper left corner of the grid. (a) simulation (b) Queueing
network approach with s=0.05 and type 2 nodes.

(a)

(b)

Fig.4. The network of Fig.3 with A=2 (a) Simulation (b) Queueing
network approach with s=0.08 and type 2 nodes.
viour of the queueing model,and must have a non-zero value in order
for the network to be stable. Good results are obtained for very
small values of s; in fact, this parameter represents the phenomenon
of excitation being ""lost"" somewhere in the network. Graphical representations for various cases are shown in Figures 3-7. We have
used a coloring of five ""grey levels"", defined by dividing into five
segments the interval between the smallest and the largest value of
the probability on the grid; the normalization is performed with respect to simulation results. This type of representation is less accurate than directly providing numerical values, but is more clear
for describing the organization of the system. In each case, the
results shown for the queueing model concern only one type of nodes,
the one that best fits the simulation results, which is type 2 in
the majority of cases examined. The graphical representation illustrates the structuring of the distribution of excitation on the
grid in terms of functionally connected regions of high and low

747

(a)

(b)

Fig.5. A 10xl0 network with A=l, V=l and looping connections.
External stimulations are uniformly distributed over a 4x4
square on the center of the grid. (a) Simulation (b) Queueing
network approach wi th s= 0.07 and type 2 nodes.

(a)

(b)

Fig.6. The network of Fig.5 with A=0.5 (a) Simulation (b) Queuei ng network approach wi th s= 0.03 and type 2 nodes.
excitation. We notice that clustering of nodes mainly follows the
spatial distribution of external stimulations and is more sharply
structured in the case of looping connections.
CONCLUSION
We have developed in this paper a simple continuous-time probabilistic model of neural nets in an attempt to investigate their
spatial organization. The model incorporates some of the main features of the McCulloch-Pitts ""formal neurons"" model and assumes boolean operation of the elementary cells. The steady-state behaviour
of the model was approximated by means of a queueing network model
with suitably chosen parameters. Results obtained from the solution
of the above approximation were compared with simulation results of
the initial model, which validate the approximation. This simplified approach is a first step in an attempt to study the organiza-

748

(a)

(b)

Fig.7. A 16x16 network with A=1, V=1 and looping connections.
External stimulations are uniformly distributed over two 4x4
squares on the upper left and lower right corners of the grid.
(a) Simulation (b) Queueing network approach with s=0.05 and
type 1 nodes.

tional properties of neural nets by means of markovian modeling techn; ques.
REFERENCES
1. W. S. McCulloch, W. Pitts, ""A Logical Calculus of the Ideas Im-

2.
3.
4.
5.
6.
7.
8.
9.
10.
11.
12.
13.
14.

manent in Nervous Activity"", Bull. of Math. Biophysics 5, 115133 (1943).
M. L. Minsky, Computation: Finite and Infinite Machines (Prentice Hall, 1967).
S. Kauffman, ""Behaviour of Randomly Constructed Genetic Nets"",
in Towards a Theoretical Biology, Ed. C. H. Waddington (Edinburgh University Press, 1970).
F. Baskett, K. M. Chandy, R. R. Muntz, F. G. Palacios, ""Open,
Closed and Mixed Networks of Queues with Different Classes of
Customers"", J. ACM, 22 (1975).
H. Atlan, F. Fogelman-Soulie, J. Salomon, G. Weisbuch, ""Random
Boolean Networks"", Cyb. and Syst. 12 (1981).
F. Folgeman-Soulie, E. Goles-Chacc, G. Weisbuch, ""Specific Roles
of the Different Boolean Mappings in Random Networks"", Bull. of
Math. Biology, Vol.44, No 5 (1982).
G. R. Cross, A. K. Jain, ""Markov Random Field Texture Models"",
IEEE Trans. on PAMI, Vol. PAMI-5, No 1 (1983).
E. R. Kandel, J. H. Schwartz, Principles of Neural Science,
(Elsevier, N.Y., 1985).
J. J. Hopfield, D. W. Tank, ""Computing with Neural Circuits:
A Model"", Sc i ence, Vol. 233, 625-633 (1986).
Y. S. Abu-Mostafa, D. Psaltis, ""Optical Neural Computers"",
Scient. Amer., 256, 88-95 (1987).
R. P. Lippmann, ""An Introduction to Computing with Neural Nets"",
IEEE ASSP Mag. (Apr. 1987).
C. A. Mead, ""Neural Hardware for Vision"", Eng. and Scie. (June
1987) .
E. Gelenbe, A. Stafylopatis, ""Temporal Behaviour of Neural Networks"", IEEE First Intern. Conf. on Neural Networks, San Diego,
CA (June 1987).
L. Onural, ""A Systematic Procedure to Generate Connected Binary
Fractal Patterns with Resolution-varying Texture"", Sec. Intern.
Sympt. on Compo and Inform. Sciences, Istanbul, Turkey (Oct.
1987) .

"
70,1987,"On the Power of Neural Networks for Solving Hard Problems","",70-on-the-power-of-neural-networks-for-solving-hard-problems.pdf,"Abstract Missing","137

On the Power of Neural Networks for
Solving Hard Problems
J ehoshua Bruck
Joseph W. Goodman
Information Systems Laboratory
Departmen t of Electrical Engineering
Stanford University
Stanford, CA 94305
Abstract
This paper deals with a neural network model in which each neuron
performs a threshold logic function. An important property of the model
is that it always converges to a stable state when operating in a serial
mode [2,5]. This property is the basis of the potential applications of the
model such as associative memory devices and combinatorial optimization

[3,6].
One of the motivations for use of the model for solving hard combinatorial
problems is the fact that it can be implemented by optical devices and
thus operate at a higher speed than conventional electronics.
The main theme in this work is to investigate the power of the model for
solving NP-hard problems [4,8], and to understand the relation between
speed of operation and the size of a neural network. In particular, it will
be shown that for any NP-hard problem the existence of a polynomial
size network that solves it implies that NP=co-NP. Also, for Traveling
Salesman Problem (TSP), even a polynomial size network that gets an
?-approximate solution does not exist unless P=NP.
The above results are of great practical interest, because right now it is
possible to build neural networks which will operate fast but are limited
in the number of neurons.

1

Background

The neural network model is a discrete time system that can be represented by
a weighted and undirected graph. There is a weight attached to each edge of
the graph and a threshold value attached to each node (neuron) of the graph.

? American Institute of Physics 1988

138

The order of the network is the number of nodes in the corresponding graph.
Let N be a neural network of order n; then N is uniquely defined by (W, T)
where:

? W is an n X n symmetric matrix, Wii is equal to the weight attached to
edge (i, j) .
? T is a vector of dimension n, Ti denotes the threshold attached to node i.
Every node (neuron) can be in one of two possible states, either 1 or -1. The
state of node i at time t is denoted by Vi(t). The state of the neural network at
time t is the vector V(t).
The next state of a node is computed by:

Vi(t + 1) = sgn(H,(t)) = {
where

~1 ~t~;2i~ 0

(1)

n

Hi(t) =

L

WiiVj(t) - Ti

i=l

The next state of the network, i.e. V(t + 1), is computed from the current
state by performing the evaluation (1) at a subset of the nodes of the network,
to be denoted by S. The modes of operation are determined by the method
by which the set S is selected in each time interval. If the computation is
performed at a single node in any time interval, i.e. 1S 1= 1, then we will say
that the network is operating in a serial mode; if 1S 1= n then we will say that
that the network is operating in a fully parallel mode. All the other cases, i.e.
1 <I S 1< n will be called parallel modes of operation. The set S can be chosen
at random or according to some deterministic rule.
A state V(t) is called stable iff V(t) = sgn(WV(t) - T), i.e. there is no
change in the state of the network no matter what the mode of operation is.
One of the most important properties of the model is the fact that it always
converges to a stable state while operating in a serial mode. The main idea in
the proof of the convergence property is to define a so called energy function
and to show that this energy function is nondecreasing when the state of the
network changes. The energy function is:

(2)
An important note is that originally the energy function was defined such that
it is nonincreasing [5]; we changed it such that it will comply with some known
graph problems (e.g. Min Cut).
A neural network will always get to a stable state which corresponds to a
local maximum in the energy function. This suggests the use of the network as a

139

device for performing a local search algorithm for finding a maximal value of the
energy function [6]. Thus, the network will perform a local search by operating
in a random and serial mode. It is also known [2,9] that maximization of E
associated with a given network N in which T = 0 is equivalent to finding
the Minimum Cut in N. Actually, many hard problems can be formulated as
maximization of a quadratic form (e.g. TSP [6)) and thus can be mapped to a
neural network.
.

2

The Main Results

The set of stable states is the set of possible final solutions that one will get
using the above approach. These final solutions correspond to local maxima of
the energy function but do not necessarily correspond to global optima of the
corresponding problem. The main question is: suppose we allow the network to
operate for a very long time until it converges; can we do better than just getting
some local optimum? i.e., is it possible to design a network which will always
find the exact solution (or some guaranteed approximation) of the problem?
Definition: Let X be an instance of problem. Then 1 X 1 denotes the size of
X, that is, the number of bits required to represent X. For example, for X
being an instance of TSP, 1 X I is the number of bits needed to represent the
matrix of the distances between cities.
Definition: Let N be a neural network. Then 1 N 1 denotes the size of the
network N. Namely, the number of bits needed to represent Wand T.
Let us start by defining the desired setup for using the neural network as a
model for solving hard problems.
Consider an optimization problem L, we would like to have for every instance
X of L a neural network N x with the following properties:
? Every local maximum of the energy function associated with N x corresponds to a global optimum of X .
? The network N x is small, that is,
in 1X I.

I

Nx

1

is bounded by some polynomial

Moreover, we would like to have an algorithm, to be denoted by A L , which given
an instance X E L, generates the description for N x in polynomial (in I X I)
time.
Now, we will define the desired setup for using the neural network as a model
for finding approximate solutions for hard problems.
Definition: Let

Eglo

be the global maximum of the energy function. Let

Eloc

140

be a local maximum of the energy function. We will say that a local maximum
is an f-approximate of the global iff:
Eglo - Eloc
--:;.--<
Eglo

f

-

The setup for finding approximate solutions is similar to the one for finding
exact solutions. For fo> 0 being some fixed number. We would like to have a
network N x~ in which every local maximum is an f-approximate of the global
and that the global corresponds to an optimum of X. The network N x? should
be small, namely, 1 N x~ 1 should be bounded by a polynomial in 1 X I. Also,
we would like to have an algorithm AL~, such that, given an instance X E L, it
generates the description for N x? in polynomial (in 1 X I) time.
Note that in both the exact case and the approximate case we do not put any
restriction on the time it takes the network to converge to a solution (it can be
exponential) .
A t this point the reader should convince himself that the above description is
what he imagined as the setup for using the neural network model for solving
hard problems, because that is what the following definition is about.
Definition: We will say that a neural network for solving (or finding an fapproximation of) a problem L exists if the algorithm AL (or ALJ which generates the description of N x (or Nx~) exists.
The main results in the paper are summarized by the following two propositions. The first one deals with exact solutions of NP-hard problems while the
second deals with approximate solutions to TSP.
Proposition 1 Let L be an NP-hard problem. Then the existence of a neural
network for solving L implies that NP = co-NP.
Proposition 2 Let f > 0 be some fixed number. The existence of a neural
network for finding an f-approximate solution to TSP implies that P=NP.
Both (P=NP) and (NP=co-NP) are believed to be false statements, hence,
we can not use the model in the way we imagine.

The key observation for proving the above propositions is the fact that a
single iteration in a neural network takes time which is bounded by a polynomial
in the size of the instance of the corresponding problem. The proofs of the above
two propositions follow directly from known results in complexity theory and
should not be considered as new results in complexity theory.

141

3

The Proofs

Proof of Proposition 1: The proof follows from the definition of the classes
NP and co-NP, and Lemma 1. The definitions and the lemma appear in Chapters 15 and 16 in [8] and also in Chapters 2 and 7 in [4].

Lemma 1 If the complement of an NP-complete problem is in NP,
then NP=co-NP.
Let L be an NP-hard problem. Suppose there exists a neural network that solves
L. Let 1 be an NP-complete problem. By definition, 1 can be polynomialy
reduced to L. Thus, for every instance X E 1, we have a neural network such
that from any of its global maxima we can efficiently recognize whether X is a
'yes' or a 'no' instance of 1.
We claim that we have a nondeterministic polynomial time algorithm to decide
that a given instance X E 1 is a 'no' instance. Here is how we do it: for X E 1
we construct the neural network that solves it by using the reduction to L. We
then check every state of the network to see if it is a local maximum (that is
done in polynomial time). In case it is a local maximum, we check if the instance
is a 'yes' or a 'no' instance (this is also done in polynomial time).
Thus, we have a nondeterministic polynomial time algorithm to recognize any
'no' instance of 1. Thus, the complement of the problem 1 is in NP. But 1 is
an NP-complete problem, hence, from Lemma 1 it follows that NP=co-NP. 0

Proof of Proposition 2: The result is a corollary of the results in [7], the
reader can refer to it for a more complete presentation.
The proof uses the fact that the Restricted Hamiltonian Circuit (RHC) is an
NP-complete problem.
Definiton of RHC: Given a graph G = (V, E) and a Hamiltonian path in G.
The question is whether there is a Hamiltonian circuit in G?
It is proven in [7] that RHC is NP-complete.
Suppose there exists a polynomial size neural network for finding an
f-approximate solution to TSP. Then it can be shown that an instance X E
RHC can be reduced to an instance X E TSP, such that in the network N x
the following holds: if the Hamiltonian path that is given in X corresponds to a
local maximum in N x? then X is a 'no' instance; else, if it does not correspond
to a local maximum in N x? then X is a 'yes' instance. Note that we can check
for locality in polynomial time.
Hence, the existence of N xe for all X E TSP implies that we have a polynomial
time algorithm for RHC. 0
?

142

4

Concluding Remarks
1. In Proposition 1 we let I W I and I T I be arbitrary but bounded by a
polynomial in the size of a given instance of a problem. If we assume
that I W I and I T I are fixed for all instances then a similar result to
Proposition 1 can be proved without using complexity theory; this result
appears in [1].
2. The network which corresponds to TSP, as suggested in [6], can not solve
the TSP with guaranteed quality. However, one should note that all the
analysis in this paper is a worst case type of analysis. So, it might be that
there exist networks that have good behavior on the average.
3. Proposition 1 is general to all NP-hard problems while Proposition 2 is
specific to TSP. Both propositions hold for any type of networks in which
an iteration takes polynomial time.
4. Clearly, every network has an algorithm which is equivalent to it, but an
algorithm does not necessarily have a corresponding network. Thus, if we
do not know of an algorithmic solution to a problem we also will not be able
to find a network which solves the problem. If one believes that the neural
network model is a good model (e.g. it is amenable to implementation with
optics), one should develop techniques to program the network to perform
an algorithm that is known to have some guaranteed good behavior.

Acknowledgement: Support of the U.S. Air Force Office of Scientific Research
is gratefully acknowledged.

References
[1] Y. Abu Mostafa, Neural Networks for Computing? in Neural Networks
for Computing, edited by J. Denker (AlP Conference Proceedings no. 151,
1986).
[2] J. Bruck and J. Sanz, A Study on Neural Networks, IBM Tech Rep, RJ
5403, 1986. To appear in International Journal of Intelligent Systems, 1988.
[3] J. Bruck and J. W. Goodman, A Generalized Convergence Theorem for
Neural Networks and its Applications in Combinatorial Optimization, IEEE
First ICNN, San-Diego, June 1987.
[4] M. R. Garey and D. S. Johnson, Computers and Intractability: A Guide to
the Theory of NP-Completeness, W. H. Freeman and Company, 1979.

143

[5] J. J. Hopfield, Neural Networks and Physical Systems with Emergent Collective Computational Abilities, Proc. Nat. Acad. Sci .. USA, Vol. 79, pp.
2554-2558, 1982.
[6] J. J. Hopfield and D. W. Tank, Neural Computations of Decisions in Optimization Problems, BioI. Cybern. 52, pp. 141-152, 1985.
[7] C. H. Papadimitriou and K. Steiglitz, On the Complexity of Local Search
for the Traveling Salesman Problem, SIAM J. on Comp., Vol. 6, No.1, pp.
76-83, 1977.
[8] C. H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Algo:rithms and Complexity, Prentice-Hall, Inc., 1982.
[9] J. C. Picard and H. D. Ratliff, Minimum Cuts and Related Problems, Networks, Vol 5, pp. 357-370, 1974.

"
71,1987,"Centric Models of the Orientation Map in Primary Visual Cortex","",71-centric-models-of-the-orientation-map-in-primary-visual-cortex.pdf,"Abstract Missing","62

Centric Models of the Orientation Map in Primary Visual Cortex
William Baxter
Department of Computer Science, S.U.N.Y. at Buffalo, NY 14620
Bruce Dow
Department of Physiology, S.U.N.Y. at Buffalo, NY 14620
Abstract
In the visual cortex of the monkey the horizontal organization of the preferred
orientations of orientation-selective cells follows two opposing rules: 1) neighbors tend
to have similar orientation preferences, and 2) many different orientations are observed
in a local region. Several orientation models which satisfy these constraints are found
to differ in the spacing and the topological index of their singularities. Using the rate
of orientation change as a measure, the models are compared to published experimental
results.
Introduction
It has been known for some years that there exist orientation-sensitive neurons in
the visual cortex of cats and mOnkeysl,2. These cells react to highly specific patterns of
light occurring in narrowly circumscribed regiOns of the visual field, i.e., the cell's
receptive field. The best patterns for such cells are typically not diffuse levels of
illumination, but elongated bars or edges oriented at specific angles. An individual cell
responds maximally to a bar at a particular orientation, called the preferred orientation. Its response declines as the bar or edge is rotated away from this preferred orientation.

Orientation-sensitive cells have a highly regular organization in primary cortex 3?
Vertically, as an electrode proceeds into the depth of the cortex, the column of tissue
contains cells that tend to have the same preferred orientation, at least in the upper
layers. Horizontally, as an electrode progresses across the cortical surface, the preferred
orientations change in a smooth, regular manner, so that the recorded orientations
appear to rotate with distance. It is this horizontal structure we are concerned with,
hereafter referred to as the orientation map. An orientation map is defined as a twodimensional surface in which every point has associated with it a preferred orientation
ranging from 00 ... 1800. In discrete versions, such as the array of cells in the cortex or
the discrete simulations in this paper, the orientation map will be considered to be a
sampled version of the underlying continuous surface. The investigations of this paper
are confined to the upper layers of macaque striate cortex.
Detailed knowledge of the two-dimensional layout of the orientation map has
implications for the architecture, development, and function of the visual cortex. The
organization of orientation-sensitive cells reflects, to some degree, the organization of
intracortical connections in striate cortex. Plausible orientation maps can be generated
by models with lateral connections that are uniformly exhibited by all cells in the
layer4,5, or by models which presume no specific intracortical connections, only
appropriate patterns of afferent input6? In this paper, we examine models in which
intracortical connections produce the orientation map but the orientation-controlling
circuitry is not displayed by all cells. Rather, it derives from localized ""centers"" which
are distributed across the cortical surface with uniform spacing7,8,9.

? American Institute of Physics 1988

63

The orientation map also represents a deformation in the retinotopy of primary
visual cortex. Since the early sixties it has been known that V1 refiects a topographic
map of the retina and hence the visual field 10. There is some global distortion of this
mapping 11 ,t2,13, but generally spatial relations between points in the visual field are
maintained on the cortical surface. This well-known phenomenon is only accurate for
a medium-grain description of V1, however. At a finer cellular level there is considerable scattering of receptive fields at a given cortical location 14. The notion of the hypercolumn 3 proposes that such scattering permits each region of the visual field to be
analyzed by a population of cells consisting of all the necessary orientations and with
inputs from both eyes. A quantitative description of the orientation map will allow
prediction of the distances between iso-orientation zones of a particular orientation,
and suggest how much cortical machinery is being brought to bear on the analysis of a
given feature at a given location in the visual field.
Models of the Orientation Map

Hubel and Wiesel's Parallel Stripe Model
The classic model of the orientation map is the parallel stripe model first published by Hubel and Wiesel in 1972 15? This model has been reproduced several times in
their publications3,16,17 and appears in many textbooks. The model consists of a series of
parallel slabs, one slab for each orientation, which are postulated to be orthogonal to
the ocular dominance stripes. The model predicts that a microelectrode advancing
tangentially (i.e., horizontally) through the tissue should encounter steadily changing
orientations. The rate of change, which is also called the orientation drift rate 18, is
determined by the angle of the electrode with respect to the array of orientation
stripes.
The parallel stripe model does not account for several phenomena reported in
long tangential penetrations through striate cortex in macaque monkeys I7.19. First, as
pointed out by Swindale 20 , the model predicts that some penetrations will have fiat or
very low orientation drift rates over lateral distances of hundreds of micrometers.
This is because an electrode advancing horizontally and perpendicular to the ocular
dominance stripes (and therefore parallel to the orientation stripes) would be expected
to remain within a single orientation column over a considerable distance with its
orientation drift rate equal to zero. Such results have never been observed. Second,
reversals in the direction of the orientation drift, from clockwise to counterclockwise
or vice versa, are commonly seen, yet this phenomenon is not addressed by the parallel
stripe model. Wavy stripes in the ocular dominace system 21 do not by themselves
introduce reversals. Third, there should be a negative correlation between the orientation drift rate and the ocularity ""drift rate"". That is, when orientation is changing
rapidly, the electrode should be confined to a single ocular dominance stripe (low ocularity drift rate), whereas when ocularity is changing rapidly the electrode should be
confined to a single orientation stripe (low orientation drift rate). This is clearly not
evident in the recent studies of Uvingstone and Hubel 17 (see especially their figs. 3b,
21 & 23), where both orientation and ocularity often have high drift rates in the same
electrode track, i.e., they show a positive correlation. Anatomical studies with 2deoxyglucose also fail to show that the orientation and ocular dominance column systems are orthogonal 22 ?

64

Centric Models and the Topological Index
Another model, proposed by Braitenberg and Braitenberg in 1979 7, has the orientations arrayed radially around centers like spokes in a wheel The centers are spaced at
distances of about O.5mm. This model produces reversals and also the sinusoidal progressions frequently encountered in horizontal penetrations. However this approach
suggests other possibilities, in fact an entire class of centric models. The organizing
centers form discontinuities in the otherwise smooth field of orientations. Different
topological types of discontinuity are possible, characterized by their topological
index 23 ? The topological index is a parameter computed by taking a path around a
discontinuity and recording the rotation of the field elements (figure 1). The value of
the index indicates the amount of rotation; the sign indicates the direction of rotation.
An index of 1 signifies that the orientations rotate through 3600; an index of 112
signifies a 1800 rotation. A positive index indicates that the orientations rotate in the
same sense as a path taken around the singularity; a negative index indicates the
reverse rotation.
Topological singularities are stable under orthogonal transformations, so that if
the field elements are each rotated 900 the index of the singUlarity remains unchanged.
Thus a +1 singularity may have orientations radiating out from it like spokes from a
wheel, or it may be at the center of a series of concentric circles. Only four types of
discontinuities are considered here, +1, -1, +1/2, -1/2, since these are the most stable, i.e ..
their neighborhoods are characterized by smooth change.
\
""

\

,

?

\

I

I

,

:

\

I

,

I

,

""

......... ',\!,',',
..........',\1'. . '_ ......

- - - - : : ~/~\,E : : - - - -

... ... ""'1\',
, ,\ , ...... _

/

...... '
,
I

:\
I

I

'""
\
\

~

J
~

J
I

,,

I

I

\

_/

I

\

... , ,"" ""' -"" '--

-------+------- ........ ,
: - .... , ' ,
..... ,

'
\

I
\

\

I

+1

I
I

I I
, ""/ ,

I

,

I
I

?

I

I

I

I

I

,,
I

I

I

---

,

',.I

I

I

-1

figure 1. Topological singularities. A positive index indicates that the orientations rotate
in the same direction as a path taken around the singularity; a negative index indicates
the reverse rotation. Orientations rotate through 3600 around ?1 centers, 1800 around
?l12 centers.

Cytochrome Oxidase Puffs
At topological singularities the change in orientation is discontinuous, which
violates the structure of a smoothly changing orientation map; modellers try to
minimize discontinuities in their models in order to satisfy the smoothness constraint.
Interestingly, in the upper layers of striate cortex of monkeys, zones with little or no
orientation selectivity have been discovered. These zones are notable for their high
cytochrome oxidase reactivity 24 and have been referred to as cytochrome oxidase puffs,
dots, spots, patches or blobs17,25,26,27. We will refer to them as puffs. If the organizing
centers of centric models are located in the cytochrome oxidase puffs then the discontinuities in the orientation map are effectively eliminated (but see below). Braitenberg
has indicated 28 that the +1 centers of his model should correspond to the puffs. Dow
and Bauer proposed a model 8 with +1 and -1 centers in alternating puffs. Gotz proposed
a similar model 9 with alternating +1f2 and -1f2 centers in the puffs. The last two
models manage to eliminate all discontinuities from the interpuff zones, but they

65

assume a perfect rectangular lattice of cytochrome oxidase puffs.

A Set of Centric Models
There are two parameters for the models considered here. (1) Whether the positive singularities are placed in every puff or in alternate puffs; and (2) whether the
singularities are ?1's or ?'-h's. This gives four centric models (figure 2):
El
Al
Elh
Alh

+1 centers in puffs. -1 centers in the interpuff zones.
ooth +1 and -1 centers in the puffs, interdigitated in a checkerboard fashion.
+112 centers in the puffs, -112 centers in the interpuff zones.
ooth +lj2 and -lj2 centers in the puffs, as in At.

The El model corresponds to the Braitenberg model transposed to a rectangular array
rather than an hexagonal one, in accordance with the observed organization of the
cytochrome oxidase regions 27 . In fact, the rectangular version of the Braitenberg model
is pictured in figure 49 of27. The Al model was originally proposed by Dow and
Bauer 8 and is also pictured in an article by Mitchison29. The A1f2 model was proposed
by Gotz 9. It should be noted that the El and Al models are the same model rotated
and scaled a bit; the Ph and A 1h have the same relationship.

E1

At

A 1h

figure 2. The four centric models. Dark ellipses represent cytochrome oxidase puffs.
Dots in interpuff zones of El & E1/2 indicate singularities at those points.

66

Simulations
Simulated horizontal electrode recordings were made in the four models to compare their orientation drift rates with those of published recordings. In the computer
simulations (figure 2) the interpuff distances were chosen to correspond to histological
measurements 27 ? Puff centers are separated by 500JL along their long axes, 350JL along
the short axes. The density of the arrays was chosen to approximate the sampling frequency observed in Hubel and Wiesel's horizontal electrode recording experiments 19,
about 20 cells per millimeter. Therefore the cell density of the simulation arrays was
about six times that shown in the figure.
All of the models produce simulated electrode data that qualitatively resemble
the published recording resUlts, e.g., they contain reversals, and runs of constantly
changing orientations. The orientation drift rate and number of reversals vary in the
different models.
The models of figure 2 are shown in perfectly rectangular arrays. Some important characteristics of the models, such as the absence of discontinuites in interpuff
zones, are dependent on this regularity. However, the real arrangement of cytochrome
oxidase puffs is somewhat irregular, as in Horton's figure 3 27 ? A small set of puffs from
the parafoveal region of Horton's figure was enlarged and each of the centric models
was embedded in this irregular array. The E1 model and a typical simulated electrode
track are shown in figure 3. Several problems are encountered when models developed
in a regular lattice are implemented in the irregular lattice of the real system; the
models have appreciably different properties. The -1 singularities in E1's interpuff
zones have been reduced to _1/2's; the A1 and A1f2 models now have some interpuff
discontinuities where before they had none.
Quantitative Comparisons

Measurement of the Orientation Drift Rate
There are two sets of centric models in the computer simulations: a set in the perfectly rectangular array (figure 2) and a set in the irregular puff array (as in figure 3).
At this point we can generate as many tracks in the simulation arrays as we wish.
How can this information be compared to the published records? The orientation drift
rate, or slope, is one basis for distinguishing between models. In real electrode tracks
however, the data are rather noisy, perhaps from the measuring process or from
inherent unevenness of the orientation map. The typical approach is to fit a straight
line and use the slope of this line. Reversals in the tracks require that lines be fit piecewise, the approach used by Hubel and Wiese1 19? Because of the unevenness of the data
it is not always clear what constitutes a reversal. Livingstone and Hubel 17 report that
the track in their figure 5 has only two reversals in 5 millimeters. Yet there seem to be
numerous microreversals between the 1st and 3rd mj11jmeter of their track. At what
point is a change in slope considered a true reversal rather than just noise?
The approach used here was to use a local slope measure and ignore the problem
of reversals - this permitted the fast calculation of slope by computer. A single electrode track, usually several millimeters long, was assigned a single slope, the average
of the derivative taken at each point of the track. Since these are discrete samples, the
local derivative must be approximated by taking measurements over a small neighborhood. How large should this neighborhood be? If too small it will be susceptible to
noise in the orientation measures, if too large it will ""flatten out"" true reversals. Slope

67

EI

..

913

+

..

+

1

2

MM

figure 3. A centric model in a realistic puff array (from 27 ). A simulated electrode track
and resulting data are shown. Only the El model is shown here, but other models
were similarly embedded in this array.

68

measures using neighborhoods of several sizes were applied to six published horizontal
electrode tracks from the foveal and parafoveal upper layers of macaque striate cortex:
figures 5,6,7 from 17, figure 16 from3, figure 1 from 3o. A neighborhood of O.lmm,
which attempts to fit a line between virtually every pair of points, gave abnormally
high slopes. Larger neighborhoods tended to give lower slopes, especially to those
tracks which contained reversals. The smallest window that gave consistent measures
for all six tracks was O.2mm; therefore this window was chosen for comparisons
between published data and the centric models. This measure gave an average slope of
285 degrees per millimeter in the six published samples of track data, compared to
Hubel & Wiesel's measure of 281 deg/mm for the penetrations in their 1974 paper19.

Slope measures of the centric models
The slope measure was applied to several thousand tracks at random locations
and angles in the simulation arrays, and a slope was computed for each simulated electrode track. Average slopes of the models are shown in Table 1. Generally, models
with ?1 centers have higher slopes than those with ?lh centers; models with centers
in every puff have higher slopes than the alternate puff models. Thus EI showed the
highest orientation drift rate, Al/2 the lowest, with A1 and E1f2 having intermediate
rates. The E1 model, in both the rectangular and irregular arrays, produced the most
realistic slope values.
TABLE I

EI
Al
Ph
Alh

Average slopes of the centric models
RectangUlar
array
312
216
198
117

Irregular
array
289
216
202
144

Numbers are in degrees/mm. Slope measure (window = O.2mm) applied
to 6 published records yielded an average slope of 285 degrees/mm.
Discussion

Constraints on the Orientation Map
Our original definition of the orientation map permits each cell to have an orientation preference whose angle is completely independent of its neighbors. But this is
much too general. Looking at the results of tangential electrode penetrations, there are
two striking constraints in the data. The first of these is reflected in the smoothness of
the graphs. Orientation changes in a regular manner as the electrode moves horizontally through the upper layers: neighboring cells have similar orientation preferences.
Discontinuities do occur but are rare. The other constraint is the fact that the orientation is always changing with distance, although the rate of change may vary.
Sequences of constant orientation are very rare and when they do occur they never
carryon for any appreciable distance. This is one of the major reasons why the parallel stripe model is untenable. The two major constraints on the orientation map may
be put informally as follows:

69

1. The smoothness constraint: neighboring points have similar orientation

preferences.
2. The heterogeneity constraint: all orientations should be represented
within a small region of the cortical surface.

This second constraint is a bit stronger than the data imply. The experimental results
only show that the orientations change regularly with distance, not that all orientations must be present within a region. But this constraint is important with respect to
visual processing and the notion of hypercolumns 3?
These are opposing constraints: the first tends to minimize the slope, or orientation drift rate, while the second tends to maximize this rate. Thus the organization of
the orientation map is analogous to physical systems that exhibit ""frustration"", that is,
the elements must satisfy conflicting constraints31 ? One of the properties of such systems is that there are many near-optimal solutions, no one of which is significantly
better than the others. As a result, there are many plausible orientation maps: any map
that satisfies these two constraints will generate qualitatively plausible simulated electrode tracks. This points out the need for quantitative comparisons between models
and experimental results.

Centric models and the two constraints
What are some possible mechanisms of the constraints that generate the orientation map? Smoothness is a local property and could be attributed to the workings of
individual cells. It seems to be a fundamental property of cortex that adjacent cells
respond to similar stimuli. The heterogeneity requirement operates at a slightly larger
scale, that of a hypercolumn rather than a minicolumn. While the first constraint may
be modeled as a property of individual cells, the second constraint is distributed over a
region of cells. How can such a collection of cells insure that its members cycle
through all the required orientations? The topological singularities discussed earlier, by
definition, include all orientations within a restricted region. By distributing these
centers across the surface of the cortex, the heterogeneity constraint may be satisfied. In
fact, the amount of orientation drift rate is a function of the density of this distribution (i.e., more centers per unit area give higher drift rates).
It has been noted that the El and the Al organizations are the same topological
model, but on different scales; the low drift rates of the At model may be increased by
increasing the density of the + 1 centers to that of the El model. The same relationship
holds for the E1I2 and A1f2 models. It is also possible to obtain realistic orientation drift
rates by increasing the density of +1f2 centers, or by mixing +1's and +Ws. However,
these alternatives increase the number of interpuff singularities. And given the possible
combinations of centers, it may be more than coincidental that a set of + t centers at
just the spacing of the cytochrome oxidase regions results in realistic orientation drift
rates.
Cortical Architecture and Types o/Circuitry
Thus far, we have not addressed the issue of how the preferred orientations are
generated. The mechanism is presently unknown, but attempts to depict it have traditionally been of a geometric nature, alluding to the dendritic morphology l.8.28.32. More
recently, computer simulations have shown that orientation-sensitive units may be
obtained from asymmetries in the receptive fields of afferents6, or developed using

70

simple Hebbian rules for altering synaptic weights5? That is, given appropriate network parameters, orientation tuning arises an as inherent property of some neural networks. Centric models propose a quite different approach in which an originally
untuned cell is ""programmed"" by a center located at some distance to respond to a
specific orientation. So, for an individual cell, does orientation develop locally, or is it
""imposed from without""? Both of these mechanisms may be in effect, acting synergistically to produce the final orientation map. The map may spontaneously form on the
embryonic cortex, but with cells that are nonspecific and broadly tuned. The organization imposed by the centers could have two effects on this incipient map. First, the
additional inft.uence from centers could ""tighten up"" the tuning curves, making the
cells more specific. Second, the spacing of the centers specifies a distinct and uniform
scale for the heterogeneity of the map. An unsupervised developing orientation map
could have broad expanses of iso-orientation zones mixed with regions of rapidly
changing orientations. The spacing of the puffs, hence the architecture of the cortex,
insures that there is an appropriate variety of feature sensitive cells at each location.
This has implications for cortical functioning: given the distances of lateral connectivity, for a cell of a given orientation, we can estimate how many other isoorientation zones of that same orientation the cell may be communicating with. For a
given orientation, the E1 model has twice as many iso-orientation zones per unit area
as At.
Ever since the discovery of orientation-specific cells in visual cortex there have
been attempts to relate the distribution of cell selectivities to architectural features of
the cortex. Hubel and Wiesel originally suggested that the orientation slabs followed
the organization of the ocular dominance slabs15? The Braitenbergs suggested in their
original mode1 7 that the centers might be identified with the giant cells of Meynert.
Later centric models have identified the centers with the cytochrome oxidase regiOns,
again relating the orientation map to the ocular dominance array, since the puffs themselves are closely related to this array.
While biologists have habitually related form to function, workers in machine
vision have traditionally relied on general-purpose architectures to implement a
variety of algorithms related to the processing of visual information33 ? More recently,
many computer scientists designing artificial vision systems have turned their attention towards connectionist systems and neural networks. There is great interest in
how the sensitivities to different features and how the selectivities to different values
of those features may be embedded in the system architecture 34 .3S.36. Linsker has proposed (this volume) that the development of feature spaces is a natural concomitance
of layered networks. providing a generic organizing principle for networks. Our work
deals with more specific cortical architectonics, but we are convinced that the study of
the cortical layout of feature maps will provide important insights for the design of
artificial systems.
References
1. D. Hubel & T. Wiesel. J. Physiol. (Lond.) 160, 106 (1962).
D. Hubel & T. Wiesel, J. Physiol. (Lond.) 195,225 (1968).
D. Hubel & T. Wiesel, Pmc. Roy. Soc. Lond. B 198, 1 (1977).
N. Swindale, Proc. Roy. Soc. Lond. B 215,211 (1982).

2.
3.
4.
5.
6.

R.Linsker, Proc. Natl. Acad. Sci. USA 83, 8779 (1986).
R. Soodak. Proc. Natl. Acad. Sci. USA 84, 3936 (1987).

71
7. V. Braitenberg & c. Braitenberg, Biol. Cyber. 33, 179 (1979).
8. B. Dow & R. Bauer, Biol. Cyber. 49, 189 (1984).
9. K. Gotz, Biol. Cyber. 56, 107 (1987).
10. P. Daniel & D. Whitteridge, J. Physiol. (Lond.) 159,302 (1961).
11. B. Dow, R. Vautin & R. Bauer, J. Neurosci. 5, 890 (1985).
12. R.B. Tootell, M.S. Silverman, E. Switkes & R. DeValois, Science 218,902 (1982).
13. D.C. Van Essen, W.T. Newsome & J.H. Maunsell, Vision Research 24,429 (1984).
14. D. Hubel & T. Wiesel, J. Compo Neurol. 158, 295 (1974).
15. D. Hubel & T. Wiesel, J. Compo Neurol. 146,421 (1972).
16. D. Hubel, Nature 299. 515 (1982).
17. M. Livingstone & D. Hubel, J. Neurosci. 4,309 (1984).
18. R. Bauer, B. Dow, A. Snyder & R. Vautin, Exp. Brain Res. SO, 133 (1983).
19. D. Hubel & T. Wiesel, J. Compo Neurol. 158,267 (1974).
20. N. Swindale, in Models of the Visual Cortex, D. Rose & V. Dobson, eds.,
(W iley, 1985), p. 452.
21. S. LeVay, D. Hubel, & T. Wiesel, J. Compo Neurol. 159,559 (1975).
22. D. Hubel, T. Wiesel & M. Stryker, J. Compo Neurol. 177,361 (1978).
23. T. Elsdale & F. Wasoff, Wilhelm Roux's Archives 180, 121 (1976).
24. M.T. Wong-Riley, Brain Res. 162,201 (1979).
25. A. Humphrey & A. Hendrickson. J. Neurosci. 3,345 (1983).
26. E. Carroll & M. Wong-Riley, J. Compo Neurol. 222,1(1984).
27. J. Horton, Proc. Roy. Soc. Lond. B 304, 199 (1984).
28. V. Braitenberg. in Models of the Visual Cortex, p.479.
29. G. Mitchison, in Models of the Visual Cortex, p. 443.
30. C. Michael, Vision Research 25 415 (1985).
31. S. Kirkpatrick, M. Gelatt & M. Vecchio Science 220, 671 (1983).
32. S. Tieman & H. Hirsch, in Models of the Visual Cortex, p. 432.
33. D. Ballard & C. Brown Computer Vision (Prentice-Hall, NJ., 1982).
34. D. Ballard, G. Hinton, & T. Sejnowski, Nature 306, 21 (1983).
35. D. Ballard, Behav. and Brain Sci. 9, 67 (1986).
36. D. Walters, Proc. First Int. Conf. on Neural Networks (June 1987).

"
72,1987,"Ensemble' Boltzmann Units have Collective Computational Properties like those of Hopfield and Tank Neurons","",72-ensemble-boltzmann-units-have-collective-computational-properties-like-those-of-hopfield-and-tank-neurons.pdf,"Abstract Missing","223

'Ensemble' Boltzmann Units
have Collective Computational Properties
like those of Hopfield and Tank Neurons
Mark Derthick and Joe Tebelskis
Department of Computer Science
Carnegie-Mellon University

1 Introduction
There are three existing connection::;t models in which network states are assigned
a computational energy. These models-Hopfield nets, Hopfield and Tank nets, and
Boltzmann Machines-search for states with minimal energy. Every link in the network can be thought of as imposing a constraint on acceptable states, and each violation adds to the total energy. This is convenient for the designer because constraint
satisfaction problems can be mapped easily onto a network. Multiple constraints can
be superposed, and those states satisfying the most constraints will have the lowest
energy.
Of course there is no free lunch. Constraint satisfaction problems are generally
combinatorial and remain so even with a parallel implementation. Indeed, Merrick
Furst (personal communication) has shown that an NP-complete problem, graph coloring, can be reduced to deciding whether a connectionist network has a state with
an energy of zero (or below). Therefore designing a practical network for solving a
problem requires more than simply putting the energy minima in the right places. The
topography of the energy space affects the ease with which a network can find good
solutions. If the problem has highly interacting constraints, there will be many local
minima separated by energy barriers. There are two principal approaches to searching these spaces: monotonic gradient descent, introduced by Hopfield [1] and refined
by Hopfield and Tank [2]; and stochastic gradient descent, used by the Boltzmann
Machine [3]. While the monotonic methods are not guaranteed to find the optimal
solution, they generally find good solutions much faster than the Boltzmann Machine.
This paper adds a refinement to the Boltzmann Machine search algorithm analogous
to the Hopfield and Tank technique, allowing the user to trade off the speed of search
for the quality of the solution.
? American Institute of Physics 1988

224

2 Hopfield nets
A Hopfield net [1] consists of binary-valued units connected by symmetric weighted
links. The global energy of the network is defined to be

E =

1

-2 ~ ~ WijSjSj I

Jr'

~ljsj
I

where Sj is the state of unit i, and Wjj is the weight on the link between units i and j.
The search algorithm is: randomly select a unit and probe it until quiescence.
During a probe, a unit decides whether to be on or off, detennined by the states of
its neighbors. When a unit is probed, there are two possible resulting global states.
The difference in energy between these states is called the unit's energy gap:

The decision rule is

oiL1i < 0
s, = { 1 otherwise

This rule chooses the state with lower energy. With time, the global energy of the
network monotonically decreases. Since there are only a finite number of states, the
network must eventually reach quiescence.

3

Boltzmann Machines

A Boltzmann Machine [3] also has binary units and weighted links, and the same
energy function is used. Boltzmann Machines also have a learning rule for updating
weights, but it is not used in this paper. Here the important difference is in the
decision rule, which is stochastic. As in probing a Hopfield unit, the energy gap is
detennined. It is used to detennine a probability of adopting the on state:
P(Sj

1
= 1) = 1 + e-tl;jT

where T is the computational temperature. With this rule, energy does not decrease
monotonically. The network is more likely to adopt low energy states, but it sometimes goes uphill. The idea is that it can search a number of minima, but spends
more time in deeper ones. At low temperatures, the ratio of time spent in the deepest
minima is so large that the chances of not being in the global minimum are negligible.
It has been proven [4] that after searching long enough, the probabilities of the states
are given by the Boltzmann distribution, which is strictly a function of energy and
temperature, and is independent of topography:

-Pex -_ e-CEa-E,,)jT
.P{3

(1)

225

The approach to equilibrium, where equation 1 holds, is speeded by initially
searching at a high temperature and gradually decreasing it. Unfortunately, reaching
equilibrium stills takes exponential time. While the Hopfield net settles quickly and
is not guaranteed to find the best solution, a Boltzmann Machine can theoretically be
run long enough to guarantee that the global optimum is found Most of the time the
_ uphill moves which allow the network to escape local minima are a waste of time,
however. It is a direct consequence of the guaranteed ability to find the best solution
that makes finding even approximate solutions slow.

4

Hopfield and Tank networks

In Hopfield and Tank nets [2], the units take on continuous values between zero and
one, so the search takes place in the interior of a hypercube rather than only on its
vertices. The search algorithm is deterministic gradient descent. By beginning near
the center of the space and searching in the direction of steepest descent, it seems
likely that the deepest minimum will be found. There is still no guarantee, but good
results have been reported for many problems.
The modified energy equation is

E =

~ 1 r;
I
-21 ~~
~ ~ WjjSjSj + ~ R j 10 g- (s)ds I

l '

~
~ [jSj

(2)

I

Rj is'the input resistance to unit i, and g(u) is the sigmoidal unit transfer function
1+~2X.. The second term is zero for extreme values of Sj, and is minimized at Sj =

t.

The Hopfield and Tank model is continuous in time as well as value. Instead of
proceeding by discrete probes, the system is described by simultaneous differential
equations, one for each unit. Hopfield and Tank show that the following equation of
m<?tion results in a monotonic decrease in the value of the energy function:
duo
_ I = -u./r + ~ Woos' + [.
dt
I
~ IlJ
I
J

where r = RC, C is a constant determining the speed of convergence, Uj = g-I(Sj),
and the gain, .A, is analgous to (the inverse of) temperature in a Boltzmann Machine .
.A determines how important it is to satisfy the constraints imposed by the links to
other units. When .A is low, these constraints are largely ignored and the second term
dominates, tending to keep the system near the center of the search space, where
there is a single global minimum. At high gains, the minima lie at the corners of
the search space, in the same locations as for the Hopfield model and the Boltzmann
model. If the system is run at high gain, but the initial state is near the center of the
space, the search gradually moves out towards the corners, on the way encountering
""continental divides"" between watersheds leading to all the various local minima. The
initial steepness of the watersheds serves as a heuristic for choosing which minima is

226

likely to be lower. This search heuristic emerges automatically from the architecture,
making network design simple. For many problems this single automatic heuristic
results in a system comparable to the best knowledge intensive algorithms in which
many domain specific heuristics are laboriously hand programmed.
For many problems, Hopfield and Tank nets seem quite sufficient [5,6]. However
for one network we have been using [7] the Hopfield and Tank model invariably settles
into poor local minima. The solution has been to use a new model combining the
advantages of Boltzmann Machines and Hopfield and Tank networks.

5

'Ensemble' Boltzmann Machines

It seems the Hopfield and Tank model gets its advantage by measuring the actual
gradient, giving the steepest direction to move. This is much more informative than
picking a random direction and deciding which of the two corners of the space to try,
as models using binary units must do. Peter Brown (personal communication) has
investigated continuous Boltzmann Machines, in which units stochastically adopt a
state between zero and one. The scheme presented here has a similar effect, but the
units actually take on discrete states between zero and one. Each ensemble unit can
be thought of as an ensemble of identically connected conventional Boltzmann units.
To probe the ensemble unit, each of its constituents is probed, and the state of the
ensemble unit is the average of its constituents' states. Because this average is over
a number of identical independent binary random variables, the ensemble unit's state
is binomially distributed.
Figure 1 shows an ensemble unit with three constituents. At infinite temperature,
and at zero temperature the states go to zero or one
all unit states tend toward
unless the energy gap is exactly zero. This is similar to the behavior of a Hopfield and
Tank network at low and high gain, respectively. In Ensemble Boltzmann Machines
(EBMs) the tendency towards! in the absence of constraints from other units results
from the shape of the binomial distribution. In contrast, the second term in the energy
equation is responsible for this effect in the Hopfield and Tank model.
Although an EBM proceeds in discrete time using probes, over a large number of
probes the search tends to proceed in the direction of the gradient. Every time a unit
is probed, a move is made along one axis whose length depends on the magnitude of
the gradient in that direction. Because probing still contains a degree of stochasticity,
EBMs can escape from local minima, and if run long enough are guaranteed to find
the global minimum. By varying n, the number of components of each ensemble
unit, the system can exhibit any intermediate behavior in the tradeoff between the
speed of convergence of Hopfield and Tank networks, and the ability to escape local
minima of Boltzmann Machines.
Clearly when n = 1 the performance is identical to a conventional Boltzmann
Machine, because each unit consists of a single Boltzmann unit. As n -+ 00 the

-t,

227

?

s=1/3

s=2/3

Figure 1: The heavy lines depict an 'Ensemble' Boltzmann Machine with two units. With
an ensemble size of three, this network behaves like a conventional Boltzmann Machine
consisting of six units (light lines). The state of the ensemble units is the average of the states
of its components.

value a unit takes on after probing becomes deterministic. The stable points of the
system are then identical to the ones of the Hopfield and Tank model.
To prove this, it suffices to show that at each probe the ensemble Boltzmann
unit takes on the state which gives rise to the lowest (Hopfield and Tank) energy.
Therefore the energy must monotonically decrease. Further, if the system is not at a
global (Hopfield and Tank) energy minimum, there is some unit which can be probed
so as to lower the energy.
To show that the state resulting from a probe is the minimum possible, we show
first that the derivative of the energy with resepect to the unit's state is zero at the
resulting state, and second that the second derivative is positive over the entire range
of possible states, zero to one.
Taking the derivative of equation 2 gives

Now
so

1
g(u) = 1 + e-2>'w

lIs
= -1n-2,\
1- s

g- (u)

Let T = 2lR' The EBM update rule is
1

Sk=---=
ilk / T
1

+ e-

228

Therefore

dEl

dslc

SI;

1

= - Ll Ic + Tin

[l+e

lLltl T
e-Llt/T

1

1+e- at1t

1+. Lll;/T

= -Lllc + Tin eLlI;/T

= - Lllc + T(LlIc/D
=

0

and
=

=

_1_. 1 - Sic ? [(1 - Sic) - (-Sic)]
2>""R
Sic
(I - SIc)2
1
2>..Rs lc (l - Sic)

> 0 on 0 < Sic < 1
In writing a program to simulate an EBM t it would be wasteful to explicitly
represent the components of each ensemble unit. Since each component has an
identical energy gapt the average of their values is given by the binomial distribution
b(ntp) where n is the ensemble size t and p is l+e 1LlIT. There are numerical methods
for sampling from this distribution in time independent of n [8]. When n is infinite t
there is no need to bother with the distribution because the result is just p.
Hopfield and Tank suggest [2] that the Hopfield and Tank. model is a mean field
approximation to the original Hopfield model. In a mean field approximation t the
average value of a variable is used to calculate its effect on other variables t rather
than calculating all the individual interactions. Consider a large ensemble of Hopfield
nets with two units t A and B. To find the distribution of final states exactlYt each B
unit must be updated based on the A unit in the same network. The calculation must
be repeated for every network in the ensemble. Using a mean field approximation t
the average value of all the B units is calculated based on the average value of all
the A units. This calculation is no harder than that of the state of a single Hopfield
network, yet is potentially more informative since it approximates an average property
of a whole ensemble of Hopfield networks. The states of Hopfield and Tank. units
can be viewed as representing the ensemble average of the states of Hopfield units
in this way. Peterson and Anderson [9] demonstrate rigorously that the behavior is a
mean field approximation.
In the EBM, it is intuitively clear that a mean field approximation is being made.
The network can be thought of as a real ensemble of Boltzmann networks t except with
additional connections between the networks so that each Boltzmann unit sees not
only its neighbors in the same nett but also sees the average state of the neighboring
units in all the nets (see figure 1).

229

6 Traveling Salesman Problem
The traveling salesman problem illustrates the use of energy-based connectionist networks, and the ease with which they may be designed. Given a list of city locations,
the task is to find a tour of minimum length through all the cities and returning to
the starting city. To represent a solution to an n city problem in a network, it is
convenient to use n columns of n rows of units [2]. If a unit at coordinates (i, J) is
on, it indicates that the ith city is the jth to be visited. A valid solution will have n
units on, one in every column and one in every row. The requirements can be divided
into four constraints: there can be no more than one unit on in a row, no more that
one unit on in a column, there must be n units on, and the distances between cities
must be minimized. Hopfield and Tank use the following energy function to effect
these constraints:

X

B/2

i

Hi

L L L SXiSYi +
i

x Y:IX

C/2

(;;~>Xi -

D/2

LLL
x Y:IX

nr

+

dxrsXi(sY,i+l

+ SY,i-l)

(3)

i

Here units are given two subscripts to indicate their row and column, and the subscripts ""wrap around"" when outside the range 1 < i < n. The first tenn is imple-mented with inhibitory links between every pair of units in a row, and is zero only
if no two are on. The second term is inhibition within columns. In the third term, n
is the number of cities in the tour. When the system reaches a vertex of the search
space, this term is zero only if exactly n units are on. This constraint is implemented
with inhibitory links between all n4 pairs of units plus an excitatory input current to
all units. In the last term dxr is the distance between cities X and Y. At points in
the search space representing valid tours, the summation is numerically equal to the
length of the tour.
As long as the constraints ensuring that the solution is a valid tour are stronger
than those minimizing distance, the global energy minimum will represent the shortest
tour. However every valid tour will be a local energy minimum. Which tour is chosen
will depend on the random initial starting state, and on the random probing order.
I

7 Empirical Results
The evidence that convinced me EBMs offer improved performance over Hopfield
and Tank networks was the ease of tuning them for the Ted Turner problem reported

230

in [7]. However this evidence is entirely subjective; it is impossible to show that
no set of parameters exist which would make the Hopfield and Tank model perform
well. Instead we have chosen to repeat the traveling salesman problem experiments
reported by Hopfield and Tank [2], using the same cities and the same values for the
constants in equation 3. The tour involves 10 cities, and the shortest tour is of length
2.72. An average tour has length 4.55. Hopfield and Tank report finding a valid tour
in 16 of 20 settlings, and that half of these are one of the two shortest tours.
One advantage of Hopfield and Tank nets over Boltzmann Machines is that they
move continuously in the direction of the gradient. EBMs move in discrete jumps
whose size is the value of the gradient along a given axis. When the system is
far from equilibrium these jumps can be quite large, and the search is inefficient.
Although Hopfield and Tank nets can do a whole search at high gain, Boltzmann
Machines usually vary the temperature so the system can remain close to equilibrium
as the low temperature eqUilibrium is approached. For this reason our model was
more sensitive to the gain parameter than the Hopfield and Tank model, and we used
temperatures much higher than
As expected, when n is infinite, an EBM produces results similar to those reported
by Hopfield and Tank. 85 out of 100 settlings resulted in valid tours, and the average
length was 2.73. Table 1 shows how n affects the number of valid tours and the
average tour length. As n decreases from infinity, both the average tour length and
the number of valid tours increases. (We have no explanation for the anomalously
low number of valid tours for n = 40.) Both of these effects result from the increased
sampling noise in determining the ensemble unit states for lower n. With more
noise, the system has an easier time escaping local minima which do not represent
valid tours. Yet at the same time the discriminability between the very best tours
and moderately good tours decreases, because these smaller energy differences are
swamped by the noise.
Rather than stop trials when the network was observed to converge, a constant
number of probes, 200 per unit, was made. However we noted that convergence was
generally faster for larger values of n. Thus for the traveling salesman problem, large
n give faster and better solutions, but a smaller values gives the highest reliability.
Depending on the application, a value of either infinity or 50 seems best.

2lR'

8

Conclusion

'Ensemble' Boltzmann Machines are completely upward compatible with conventional Boltzmann Machines. The above experiment can be taken to show that they
perform better at the traveling salesman problem. In addition, at the limit of infinite
ensemble size they perform similarly to Hopfield and Tank nets. For TSP and perhaps
many other problems, the latter model seems an equally good choice. Perhaps due to
the extreme regularity of the architecture, the energy space must be nicely behaved

231

Ensemble Size
I

40
50
100
1000
infinity

Percent Valid Average Tour Length
93
84
95
89
90
85

3.32
2.92
2.79
2.79
2.80
2.73

Table 1: Number of valid tours out of 100 trials and average tour length, as a function
of ensemble size. An ensemble size of one corresponds to a Boltzmann Machine. Infinity
loosely corresponds to a Hopfield and Tank network.

in that the ravine steepness near the center of the space is a good indication of its
eventual depth. In this case the ability to escape local minima is not required for
good perfonnance.
For the Ted Turner problem, which has a very irregular architecture and many
more constraint types, the ability to escape local minima seems essential. Conventional Boltzmann Machines are too noisy, both for efficient search and for debugging.
EBMs allow the designer the flexibility to add only as much noise as is necessary. In
addition, lower noise can be used for debugging. Even though this may give poorer
perfonnance, a more detenninistic search is easier for the debugger to understand,
allowing the proper fix to be made.

Acknowledgements
We appreciate receiving data and explanations from David Tank, Paul Smolensky,
and Erik Sobel. This research has been supported by an ONR Graduate Fellowship,
by NSF grant EET-8716324, and by the Defense Advanced Research Projects Agency
(DOD), ARPA Order No. 4976 under contract F33615-87-C-1499 and monitored by
the:
Avionics Laboratory
Air Force Wright Aeronautical Laboratories
Aeronautical Systems Division (AFSC)
Wright-Patterson AFB, OB 45433-6543
This research was also sponsored by the same agency under contract N00039-87C-0251 and monitored by the Space and Naval Warfare Systems Command.

232

References
[1] J. J. Hopfield, ""Neural networks and physical systems with emergent collective
computational abilities,"" Proceedings of the National Academy of Sciences U.SA.,
vol. 79, pp. 2554-2558, April 1982.
[2] J. Hopfield and D. Tank, '''Neural' computation of decisions in optimization
problems,?' Biological Cybernetics, vol. 52, pp. 141-152, 1985.
[3] G. E. Hinton and T. J. Sejnowski, ""Learning and relearning in Boltzmann Machines,"" in Parallel distributed processing: Explorations in the microstructure of
cognition, Cambridge, MA: Bradford Books, 1986.
[4] S. Geman and D. Geman, ""Stochastic relaxation, Gibbs distributions, and the
Bayesian restoration of images,"" IEEE Transactions on Pattern Analysis and
Machine Intelligence, vol. PAMI-6, pp. 721-741, 1984.
[5] J. L. Marroquin, Probabilistic Solution of Inverse Problems. PhD thesis, MIT,
September 1985.
[6] J. Hopfield and D. Tank, ""Simple 'Neural' optimization networks: an aid converter, signal decision circuit and a linear programming circuit,"" IEEE Transactions on Circuits and Systems, vol. 33, pp. 533--541, 1986.
[7] M. Derthick, ""Counterfactual reasoning with direct models,"" in AAA/-87, Morgan
Kaufmann, July 1987.
[8] D. E. Knuth, The Art of Computer Programming. Second Edition. Vol. 2,
Addison-Wesley, 1981.
[9] C. Peterson and J. R. Anderson, ""A mean field theory learning algorithm for
neural networks,"" Tech. Rep. EI-259-87, MCC, August 1987.

"
73,1987,"HIGH DENSITY ASSOCIATIVE MEMORIES","",73-high-density-associative-memories.pdf,"Abstract Missing","211

HIGH DENSITY ASSOCIATIVE MEMORIES!

A""'ir Dembo
Information Systems Laboratory, Stanford University
Stanford, CA 94305
Ofer Zeitouni
Laboratory for Information and Decision Systems
MIT, Cambridge, MA 02139
ABSTRACT
A class of high dens ity assoc iat ive memories is constructed,
starting from a description of desired properties those should
exhib it. These propert ies include high capac ity, controllable bas ins
of attraction and fast speed of convergence. Fortunately enough, the
resulting memory is implementable by an artificial Neural Net.
I NfRODUCTION
Most of the work on assoc iat ive memories has been structure
oriented, i.e.. given a Neural architecture, efforts were directed
towards the analysis of the resulting network. Issues like capacity,
basins of attractions, etc. were the main objects to be analyzed cf.,
e.g. [1], [2], [3], [4] and references there, among others.
In this paper, we take a different approach, we start by
explicitly stating the desired properties of the network, in terms of
capacity, etc. Those requirements are given in terms of axioms (c.f.
below). Then, we bring a synthesis method which enables one to design
an
architecture
which will
yield
the
desired
performance.
Surprisingly enough, it turns out that one gets rather easily the
following properties:
(a) High capacity (unlimited in the continuous state-space case,
bounded only by sphere-packing bounds in the discrete state
case).
(b) Guaranteed basins of attractions in terms of the natural
metric of the state space.
(c) High speed of convergence in the guaranteed basins of
attraction.
Moreover, it turns out that the architecture suggested below is the
only one which satisfies all our axioms (-desired properties-)I
Our approach is based on defining a potential and following a
descent algorithm (e.g., a gradient algorithm). The main design task
is to construct such a potential (and, to a lesser extent, an
implementat ion of the descent algorithm via a Neural network).
In
doing so, it turns out that, for reasons described below, it is useful
to regard each des ired memory locat ion as a -part icle- in the state
space. It is natural to require now the following requirement from a
IAn expanded version of this work has been submitted to Phys. Rev. A.
This work was carried out at the Center for Neural Sc ience, Brown
University.
? American Institute of Physics 1988

212

.eJlOry:
(Pl) The potential should be linear w.r.t. adding partic les in
the sense that the potential of two particles should be the sum of the
potentials induced by the individual particles (i.e ?? we do not allow
interparticles interaction).
(P2) Part icle locat ions are the only poss ible sites of stable
.emory locations.
(P3)
The system should be invariant to translations and
rotations of the coordinates.
We note that the last requirement is made only for the sake of
simplicity. It is not essential and may be dropped without affecting
the results.
In the sequel. we construct a potential which satisfies the above
requirements. We refer the reader to [5] for details of the proofs.
etc.
Acknowledgements. We would like to thank Prof. L.N. Cooper and C.M.
Bachmann for many fruitful discussions. In particular. section 2 is
part of a joint work with them ([6]).
2.

HIGH DENSIlY STORAGE MODEL

In what follows we present a particular case of a method for the
construct ion of a high storage dens ity neural memory. We define a
function with an arbitrary number of minima that lie at preassigned
points and define an appropriate relaxat ion procedure. The general
case in presented in [5].
Let i 1 ..... i m be a set of m arb itrary d ist inct memories in RN.
The ?energy? function we will use is:
m

~ =-

i2

Qi

Iii -

ii

I-L

(1)

i=l
where we assume throughout that N ~ 3. L ~ (N - 2). and Qi > 0 and use
1??? 1 to denote the Euclidean distance. Note that for L = 1. NF3. ~
is the electrostat ic potent ial induced by negat ive fixed part ic les
with charges -Qi. This ?energy? funct ion possesses global minima at
i 1 ????? i m (where ~(ii) .. - ) and has no local minima except at these
points.
A rigorous proof is presented in [5] together with the
complete characterization of functions having this property.
As a relaxation procedure. we can choose any dynamical system for
which ~ is strictly decreasing. uniformly in compacts. In this
instance. the theory of dynamical systems guarantees that for almost
any initial data. the trajectory of the system converges to one of the
desired points i 1 ????? i m? However. to give concrete results and to
further exploit the resemblance to electrostatic. consider the
relaxation:

213

.

.. -=
II

E- -= Il

(2)

i=1
where for N=3. L=1. equation (2) describes the motion of a positive
t~st particle in the electrost!tic f~eld ~ generated by the negative
f1xed charges -Q1 ???? L -~ at xl ????? x m?
Since the field E;i is just minus the gradient of e. it is clear
that along trajectories of (2). de/dt ~ O. with equality only at the
fbed points of (2). which are exactly the stat ionary po ints of e.
Therefore. using (2) as the relaxation procedure. we can conclude
that entering at any ~(O). the system converges to a stationary point
of e.
The space of inputs is partitioned into m domains of
attraction. each one corresponding to a different memory. and the
boundaries (a set of measure zero). on which p(O) will converge to a
saddle point of e.
We can now explain why e~ has no spurious local minima. at least
for L=1. N=3. using elementary physical arguments.
Suppose e has a
spurious local minima at y ~ xl ????? x m? then in a s!!all neighborhood
of y which does not include any of the xi. the field ~ points towards
y. Thus. on any closed surface in that neighborhood. the integral of
the normal inward component of ~ is positive. However. this integral
is just the total charge included inside the surface. which is zero.
Thus we arrive at a contradiction. so y can not be a local minimum.
We now have a relaxation procedure. such that almost any ~(O) is
attracted by one of the xi. but we have not yet spec ified the shapes
of the basins of attraction.
By varying the charges Qi. we can
enlarge one basin of attraction at the expense of the others (and vice
versa).
Even when all of the Qi are eqmal. the position of the xi might
cause ~(O) not to converge to the closest memory. as emphasized in the
example in fig. 1.
However. let r = min1~i~j~mlxi - i j 1 be the
minimal distance between any two memoriesJ then if I~(O) - ii I~
it can be shown that

~(O)

,[? .,lIk)
L +!
N+i

will converge to xi. (provided that k = - -

11). Thus. i f thamemories are densely packed in a hypersphere. by
choosing k large enough (i.e. enlarging the parameter L). convergence
to the closest memory for any -interesting- input. that is an input
i;:(O) with a distinct closest memory. is guaranteed.
The detailed
proof of the above property is given in [5]. It is based on bound ing
the number of x j ? j~i. in a hypersphere of radius R(Rlr) around xi. by
[2R/r + 1]N. tlien bounding the magnitude of the field induced
any
Xj. j~i. on the boundar, of such a hypersphere by (R-li;:(O)-xiP- +1).

'I.

and finally integrat ing to show that for

I~(O)-ii 15. (i~~I/~ ,with

e<1.

the convergence of ~(O) to xi is within finite time T. which behaves
like e L+2 for L
1 and e < 1 and fixed. Intuitively the reason for

?

214

this behaviour is the short-range nature of the fields used in
Because of this. we also expect extremely low
equat ion (2) ?
convergence rate for inputs ~(O) far away from all of the xi.
The radial nature of these fields suggests a
way to overcome this difficulty. that is to
increase the convergence rate from points very far
away. without disturbing all of the aforementioned
desirable properties of the model. Assume that we
'.
know in advance that all of the xi lie inside some
large hypersphere S around the origin. Then. at
any point ~ outside S. the field ~ has a positive
projection radially into S.
By adding a longrange force to B-. effective only outside of S. we
can hasten the mgvement towards S. from points far
away, without creating additional minima inside of
S. As an example the force (-~ for ji , S, 0 for
ji 8
S) will pull any test input ji(O) to
the boundary of S within the small finite time T ~
I
1/1SI. and from then on the system wil} behave
""
inside S according to the original field
Up to this point. our derivations have been
for
a
continuous system. but from it we can deduce
Figure 1
a discrete system. We shall do this mainly for a
R ? I and 0 ? 1
clearer comparison between our high density memory
model and the discrete version of Hopfield's
model. Before continuing in that direction. note
that our continuous system has unl imited storage
capacity unlike Hopfield's continuous system.
which like his discrete model,
has limited
capac ity.
For the discrete system, assume that the Xi are composed of
elements ?1 and replace the Euclid\an dJstance in (1) with the
normal ized Hamming 4 istance lii1 - ~21 = 1; I '=1111~ - 11~ I. This places
the vec tors :i i on the un it hypersphere.
J
J
J
The relaxation process for the discrete system will be of the
type defined in Hopfield's model in [11
Choose at random a
component to be updated (that is, a neighbor ~' of ii such that
Iii' - iii = 2/N). calculate the ""energy"" difference. r.e = ~(ii~-~(ii).
and only if r.e < O. change this component, that is:
,I

Bu.

11?1 ~f.l.1 sign(~(~~ - ~(ji?,

(3)

where e(ii) is the potent ial energN in (1). Since there is a finite
number of possible ~ vectors (2), convergence in finite time is
guaranteed.
This relaxation procedure is rigid since the movement is limited
to points with components +1. Therefore. although the local minima of
~(ii) defined in (2) are only at the desired points Xi' the relaxation
may get stuck at some ii which is not a stationary point of ~(ii).
However, the short range behaviour of the potential e(~), unlike the
long-range behavior of the quadratic potential used by Hopfield, gives

215

rise to results similar to those we have quoted for the continuous
ll10del (equation (1?.
Specifically. let the stored me~ories i 1 ????? i m be separated from
one another by having at least pN different components (0 < p i 1/2
and p fixed), and let ~(O) agree up to at least one ii with at most
epN errors between them (0 i e < 1/2. with e fixed), then jHO)
converges monotonically to i i by the relaxat ion procedure given in
equat ion (3).
This result holds independently of m. provided that N is large
enough (typically. Np In(1~e)

L 1)

and L is chosen so that

fi

In(!~e)

The proof is constructed by bounding the cummulative effect of terms

-

Se

I~
ii rL. j;&i. to t~e energy difference
and showing that it is
dominafed by I~
ii 1 L. For details. we refer the reader again to
[5].

-

Note the importance of this property: unlike the Hopfield model
which is limited to miN. the suggested system is optimal in the
sense of Information Theory. since for every set of memories i 1 ????? i m
separated from each other by a Hamming distance pN. up to 1/2 pN
errors in the input can be corrected. provided that N is large and L
properly chosen.
As for the complexity of the system. we note that the nonlinear
operat ion a -L. for a}O and L integer (which is at (the heart of our
system computationally)' is equivalent to e-Lln a)
and can be
implemented. therefore. by a simple electrical circuit composed of
diodes. which have exponential input-output characteristics. and
resistors. which can carry out the necessary multiplications (cf. the
implementation of section 3).
Further. since both liil and I~I are held fixed in the discrete
system. where all states are on the unit hypersphere. I~
ii 12 is
equivalent to the inner product of ~ and ii' up to a constant.
To
conclude.
the
suggested
model
involves
about
m'N
multiplications. followed by m nonlinear operations. and then m'N
additions. The original model of Hopfield involves
multiplications
and additions. and then N nonlinear operations. but is limited to
miN.
Therefore. whenever the Hopfield model is applicable the
complexity of both ll10dels is comparable.

-

Nf

3.

IMPLEMENI'ATION

We propose below one possible network which implements the
discrete time and space version of the model described above.
An
implementation for the ocntinuous time case. which is even simpler. is
also hinted. We point out that the implementation described below is
by no means unique. (and maybe even not the simplest one). Moreover.
the -neurons? used are artificial neurons which perform various tasks.
as follows:
There are (N+1) neurons which are delay elements. and
pOintwise non-linear functions (which may be interpreted as delayless. intermediate neurons).
There are ~N
synaptic connections
between those two layers of neurons. In addition. as in the Hopfield

\'l'\.

216

model, we have at each iteration to specify (either deterministically
or stochastically) which coordinate are we updating. To do that, we
use an N dimensional ?control register? whose content is always a unit
vector of {O, l}N (and the location of the '1' will denote the next
coordiante to be changed). This vector may be varied from instant n
to n + 1 either by shift (?sequential coordinate update?) or at
random.
Let Ai' UUN be the i-th output of the ?co1!,trol? register, xi'
l~UN and V be the (N+1) I!eurons inputs and xi = xi (l-2A i ) the
corresponding outputs (where xi' xi8{+1,-1), Ai 8{0,1}, but V is a real
number), _j' l~j~ be the input of the j-th inte;medi~te neuron
(-1~_ ~1), ~j = -(1-_ )-L be its output, and
'ji = ui j IN be the
synaptiC weight of thJ ij - th synapsis, where u~j) refers here to the
i-th element of the j-th memory.
The system's equations are:

<i

~ N

(4a)

1 ~ j

<m

(4b)

1

~

"""" -(1 __ )-L
j

(4c)

j

(4d)

S

1
- - V?
= i""(l-sign(V

(4e)

1
V ~V +

SV

<

i ~ N

(4f)
(4g)

The system is initialized by xi = xi (0) (the probe vector), and
V = + CD. A block diagram of this sytem appears in Fig. 2.
Note that
we made use of N + m + 1 neurons and O(Nm) connections.
As for the continuous time case (with memories on the unit
sphere) we will get the equations:

217
m

-

2

1 ~ i ~ N

(Sa)

x21.?

1 ~ j ~ m

(Sb)

?

1

Xi + 2m VX i = LN
""jil1 j.
j=l

N
-j

=N

2

N
6

"" J. i X1.?

=

2

i .. l

i=l

_(L + 1)
l1j

=

(1 + 6 - 2_ j)

-= 2

'I""

<j

~ m

(Sc)

~

V

(Sd)

l1j

j=l

with similar interpretation (here there is no
all components are updated continuously).

'control' register as

s

Legend

@]

i
Deloy Unit (Neuron)
,
Synoptic Switch ( 0= { ..

'2

Figure 2

c=O)
C =I

_~o
fc

Synoptic Switch (0 =Zi,

t

c =0)

c=I

Computation UnIt (0= 1/2(1-sign(i2-i, Il)

Neural Network Implementotion

218

REFERENCES
1.
2.
3.
4.
5"".
6.

Bopfield. -Neural Networks and Physical Systems with
Emergent Collective Computational Abilities-. Proc. Nat. Acad.
Sci. U.S.A ?? Vol. 79 (1982). pp. 2554-2558.
R.I. McEliece. et al ?? -The Capacity of the Hopfield Associative
Memory-. IEEE"" Trans. on Inf. Theory. Vol. IT-33 (1987). pp. 461482.
A. Dembo. -On the Capac ity of the Hopfield Memory-. submitted.
IEEE Trans. on Inf. Theory.
Kohonen. T ?? Self Organization and Associative Memory. Springer.
Berlin. 1984.
Dembo. A. and Ze itouni. 0 ?? General Potent ial Surfaces and Neural
Networks. submitted. Phys. Rev. A.
Bachmann. C.M.. Cooper. L.N., Dembo. A. and Zeitouni. 0.. A
relazation Model for Memory with high storage density. to appear.
Proc. Natl. Ac. Science.

1.1.

"
74,1987,"A Novel Net that Learns Sequential Decision Process","",74-a-novel-net-that-learns-sequential-decision-process.pdf,"Abstract Missing","760

A NOVEL NET THAT LEARNS
SEQUENTIAL DECISION PROCESS
G.Z. SUN, Y.C. LEE and H.H. CHEN
Department of PhYJicJ and AJtronomy
and
InJtitute for Advanced Computer StudieJ

UNIVERSITY OF MARYLAND,COLLEGE PARK,MD 20742

ABSTRACT
We propose a new scheme to construct neural networks to classify patterns. The new scheme has several novel features :
1. We focus attention on the important attributes of patterns in ranking
order. Extract the most important ones first and the less important
ones later.
2. In training we use the information as a measure instead of the error
function.
3. A multi-percept ron-like architecture is formed auomatically. Decision
is made according to the tree structure of learned attributes.
This new scheme is expected to self-organize and perform well in large scale
problems.

? American Institute of Physics 1988

761

1

INTRODUCTION

It is well known that two-layered percept ron with binary connections but no
hidden units is unsuitable as a classifier due to its limited power [1]. It cannot
solve even the simple exclusive-or problem. Two extensions have been prop'osed to remedy this problem. The first is to use higher order connections
l2]. It has been demonstrated that high order connections could in many
cases solve the problem with speed and high accuracy [3], [4]. The representations in general are more local than distributive. The main drawback
is however the combinatorial explosion of the number of high-order terms.
Some kind of heuristic judgement has to be made in the choice of these terms
to be represented in the network.
A second proposal is the multi-layered binary network with hidden units
r5]. These hidden units function as features extracted from the bottom input
layer to facilitate the classification of patterns by the output units. In order
to train the weights, learning algorithms have been proposed that backpropagate the errors from the visible output layer to the hidden layers for
eventual adaptation to the desired values. The multi-layered networks enjoy
great popularity in their flexibility.
However, there are also problems in implementing the multi-layered nets.
Firstly, there is the problem of allocating the resources. Namely, how many
hidden units would be optimal for a particular problem. If we allocate too
many, it is not only wasteful but also could negatively affect the performance
of the network. Since too many hidden units implies too many free parameters to fit specifically the training patterns. Their ability to generalize to
noval test patterns would be adversely affected. On the other hand, if too
few hidden units were allocated then the network would not have the power
even to represent the trainig set. How could one judge beforehand how many
are needed in solving a problem? This is similar to the problem encountered
in the high order net in its choice of high order terms to be represented.
Secondly, there is also the problem of scaling up the network. Since the
network represents a parallel or coorperative process of the whole system,
each added unit would interact with every other units. This would become
a serious problem when the size of our patterns becomes large.
Thirdly, there is no sequential communication among the patterns in the
conventional network. To accomplish a cognitive function we would need
the patterns to interact and communicate with each other as the human
reasoning does. It is difficult to envision such an interacton in current systems
which are basically input-output mappings.

2

THE NEW SCHEME

In this paper, we would like to propose a scheme that constructs a network
taking advantages of both the parallel and the sequential processes.
We note that in order to classify patterns, one has to extract the intrinsic
features, which we call attributes. For a complex pattern set, there may
be a large number of attributes. But differnt attributes may have different

762

ranking of importance. Instead of ext racing them all simultaneously it may
be wiser to extract them sequentially in order of its importance [6], [7]. Here
the importance of an attribute is determined by its ability to partition the
pattern set into sub-categories. A measure of this ability of a processing unit
should be based on the extracted information. For simplicity, let us assume
that there are only two categories so that the units have only binary output
values 1 and
but the input patterns may have analog representations). We
call these units, including their connection weights to the input layer, nodes.
For given connection weights, the patterns that are classified by a node as
in category 1 may have their true classifications either 1 or 0. Similarly, the
patterns that are classified by a node as in category 0 may also have their
true classifications either 1 or o. As a result, four groups of patterns are
formed: (1,1), (0,0), (1,0), (0,1). We then need to judge on the efficiency of
the node by its ability to split these patterns optimally. To do this we shall
construct the impurity fuctions for the node. Before splitting, the impurity
of the input patterns reaching the node is given by

?(

(1)

where pt = Nf / N is the probability of being truely classified as in category
1, and P~ = N~/N is the probability of being truely classified as in category
o. After splitting, the patterns are channelled into two branches, the impurity
becomes

1(1 = -Pt

L
j=O,1

P(j, 1) logP(j, 1) - P;

L

P(j, O)logP(j, 0)

(2)

j=O,1

where Pi = Ni / N is the probability of being classified by the node as in
category 1, P; = N8/N is the probability of being classified by the node as
in category 0, and P(j, i) is the probability of a pattern, which should be in
category j, but is classified by the node as in category i. The difference

(3)
represents the decrease of the impurity at the node after splitting. It is the
quantity that we seek to optimize at each node. The logarithm in the impurity function come from the information entropy of Shannon and Weaver.
For all practical purI?ose, we found the. optimization of (3) the same as maximizing the entropy l6]

where Ni is the number of training patterns classified by the node as in
category i, N ij is the number of training patterns with true classification in
category i but classified by the node as in category j. Later we shall call the
terms in the first bracket SI and the second S2. Obviously, we have
i = 0,1

763

After we trained the first unit, the training patterns were split into two
branches by the unit. If the classificaton in either one of these two branches
is pure enough, or equivalently either one of Sl and S2 is fairly close to 1,
then we would terminate that branch ( or branches) as a leaf of the decision
tree, and classify the patterns as such. On the other hand, if either branch is
not pure enough, we add additional node to split the pattern set further. The
subsequent unit is trained with only those patterns channeled through this
branch. These operations are repeated until all the branches are terminated
as leaves.

3

LEARNING ALGORITHM

We used the stochastic gradient descent method to learn the weights of each
node. The training set for each node are those patterns being channeled to
this node. As stated in the previous section, we seek to maximize the entropy
function S. The learning of the weights is therefore conducted through

oS
1:::. Wj = 11 ow-

(5)

J

Where 11 is the learning rate. The gradient of S can be calculated from the
following equation

oS = ~ [(1 _ 2NJ1) oNn
oWj
N
Nl oW;

(1 _ 2NJo) ONIO
NJ oWj

+ (1 _ 2 Nil ) oNOl +
Nl oWj

+ (1 _ 2N'fO) ONoo]
NJ oWj

(6)

Using analog units

or =

1 + exp( -

we have

oor =

ow-

1

Lj WjII)

orC1 _ or)!';
J

J

Furthermore, let Ar
then

N;;

=

t.

= 1 or 0 being the

[iA'

+ (1 -

(7)

(8)

true answer for the input pattern r ,

i)(1 - A')

1[i O' + (1 - j)(1 - 0') 1

(9)

Substituting these into equation (5), we get

1:::.Wj = 2T} :L[2Ar(NU - NlO)
r
Nl
No

+ Ni~ -

Ni;]or(l - or)IJ
(10)
No
Nl
In applying the formula (10),instead of calculating the whole summation at
once, we update the weights for each pattern individually. Meanwhile we
update N ij in accord with equation (9).

764

Figure 1: The given classification tree, where 01 , O'l and 03 are chosen to be
all zeros in the numerical example.

4

AN EXAMPLE

To illustrate our method, we construct an example which is itself a decision
tree. Assuming there are three hidden variables ai, a'l, a3, a pattern is given
by a ten-dimensional vector II, I'l, ... , 110 , constructed from the three hidden
variables as follows

+ a3

II

-

al

1'l

-

2al - a'l

16 17 -

a3 - 2a'l

18

-

2al

19

-

4a3 - 3a l

13
I""
Is

+ 2a'l + 3a3

-

al

-

5al - 4a""

110

2a3

a3 - al

2al

+ 3a3
+ 2a'l + 2 a 3?

A given pattern is classified as either 1 (yes) or 0 (no) according to the
corresponding values of the hidden variables ai, a'l, a3. The actual decision
is derived from the decision tree in Fig.1.
In order to learn this classification tree, we construct a training set of 5000
patterns generated by randomly chosen values ai, a'l, a3 in the interval -1 to
+1. We randomly choose the initial weights for each node, and terminate

765

5=0.79

G

51 =0.60/

~=0.87

""

G
G

51 =0.65/

VI

51 = 0.85/
(SS/S)W i

(fIg (2519/35)

,S2= 0.88

~OCE:S] (16171114)

~= 0.73

5. =0.90/
(92/S)rul

52=0.96
ffQ](548/12)

Figure 2: The learned classification tree structure
a branch as a leaf whenever the branch entropy is greater than 0.80. The
entropy is started at S = 0.65, and terminated at its maximum value S =
0.79 for the first node. The two branches of this node have the entropy
fuction valued at SI = 0.61, S2 = 0.87 respectively. This corrosponds to
2446 patterns channeled to the first branch and 2554 to the second. Since
S2 > 0.80 we terminate the second branch. Among 2554 patterns channeled
to the second branch there are 2519 patterns with true classification as no and
35 yes which are considered as errors. After completing the whole training
process, there are totally four nodes automatically introduced. The final
result is shown in a tree structure in Fig.2.
The total errors classified by the learned tree are 3.4 % of the 5000 trainig
patterns. After trainig we have tested the result using 10000 novel patterns,
the error among which is 3.2 %.

5

SUMMARY

We propose here a new scheme to construct neural network that can automatically learn the attributes sequentially to facilitate the classification
of patterns according to the ranking importance of each attribute. This
scheme uses information as a measure of the performance of each unit. It is

766

self-organized into a presumably optimal structure for a specific task. The
sequential learning procedure focuses attention of the network to the most
important attribute first and then branches out' to the less important attributes. This strategy of searching for attributes would alleviate the scale
up problem forced by the overall parallel back-propagation scheme. It also
avoids the problem of resource allocation encountered in the high-order net
and the multi-layered net. In the example we showed the performance of the
new method is satisfactory. We expect much better performance in problems
that demand large size of units.

6

acknowledgement

This work is partially supported by AFOSR under the grant 87-0388.

References
[1] M. Minsky and S. Papert, Perceptron, MIT Press Cambridge, Ma(1969).
[2] Y.C. Lee, G. Doolen, H.H. Chen, G.Z. Sun, T. Maxwell, H.Y. Lee and
C.L. Giles, Machine Learning Using A High Order Connection Netweork, Physica D22,776-306 (1986).
[3] H.H. Chen, Y.C. Lee, G.Z. Sun, H.Y. Lee, T. Maxwell and C.L. Giles,
High Order Connection Model For Associate Memory, AlP Proceedings
Vol.151,p.86, Ed. John Denker (1986).
[4] T. Maxwell, C.L. Giles, Y.C. Lee and H.H. Chen, Nonlinear Dynamics
of Artificial Neural System, AlP Proceedings Vol.151,p.299, Ed. John
Denker(1986).
[5] D. Rummenlhart and J. McClelland, Parallel Distributit'e Processing,
MIT Press(1986).
[6] L. Breiman, J. Friedman, R. Olshen, C.J. Stone, Classification and Regression Trees,Wadsworth Belmont, California(1984).
[7] J.R. Quinlan, Machine Learning, Vol.1 No.1(1986).

"
75,1987,"Probabilistic Characterization of Neural Model Computations","",75-probabilistic-characterization-of-neural-model-computations.pdf,"Abstract Missing","310

PROBABILISTIC CHARACTERIZATION OF
NEURAL MODEL COMPUTATIONS
Richard M. Golden t
University of Pittsburgh, Pittsburgh, Pa. 15260
ABSTRACT
Information retrieval in a neural network is viewed as a procedure in
which the network computes a ""most probable"" or MAP estimate of the unknown information. This viewpoint allows the class of probability distributions,
P, the neural network can acquire to be explicitly specified. Learning algorithms
for the neural network which search for the ""most probable"" member of P can
then be designed. Statistical tests which decide if the ""true"" or environmental
probability distribution is in P can also be developed. Example applications of
the theory to the highly nonlinear back-propagation learning algorithm, and the
networks of Hopfield and Anderson are discussed.
INTRODUCTION
A connectionist system is a network of simple neuron-like computing
elements which can store and retrieve information, and most importantly make
generalizations. Using terminology suggested by Rumelhart & McClelland 1,
the computing elements of a connectionist system are called units, and each unit
is associated with a real number indicating its activity level. The activity level
of a given unit in the system can also influence the activity level of another unit.
The degree of influence between two such units is often characterized by a
parameter of the system known as a connection strength. During the information retrieval process some subset of the units in the system are activated, and
these units in turn activate neighboring units via the inter-unit connection
strengths. The activation levels of the neighboring units are then interpreted as

t

Correspondence should be addressed to the author at the Department
of Psychology, Stanford University, Stanford, California, 94305, USA.
? American Institute of Physics 1988

311

the retrieved information. During the learning process, the values of the interunit connection strengths in the system are slightly modified each time the units
in the system become activated by incoming information.
DERIV ATION OF TIIE SUBJECITVE PF
Smolensky 2 demonstrated how the class of possible probability distributions that could be represented by a Hannony theory neural network model
can be derived from basic principles. Using a simple variation of the arguments
made by Smolen sky , a procedure for deriving the class of probability distributions associated with any connectionist system whose information retrieval
dynamics can be summarized by an additive energy function is briefly sketched.
A rigorous presentation of this proof may be found in Golden 3.
Let a sample space, Sp, be a subset of the activation pattern state space,
Sd, for a particular neural network model. For notational convenience, define the
term probability function (pf) to indicate a function that assigns numbers
between zero and one to the elements of Sp. For discrete random variables, the
pf is a probability mass function. For continuous random variables, the pf is a
probability density function. Let a particular stationary stochastic environment
be represented by the scalar-valued pf, Pe(X)' where X is a particular activation
pattern. The pf, Pe(X), indicates the relative frequency of occurrence of activation pattern X in the network model's environment. A second pf defined with
respect to sample space Sp also must be introduced. This probability function,
ps(X), is called the network's subjective pf. The pf Ps(X) is interpreted as the
network's belief that X will occur in the network's environment.
The subjective pf may be derived by making the assumption that the
information retrieval dynamical system, Ds' is optimal. That is, it is assumed
that D s is an algorithm designed to transform a less probable state X into a more
probable state X* where the probability of a state is defined by the subjective pf
ps(X;A), and where the elements of A are the connection strengths among the
units. Or in traditional engineering terminology, it is assumed that D s is a MAP
(maximum a posteriori) estimation algorithm. The second assumption is that an
energy function, V(X), that is minimized by the system during the information
retrieval process can be found with an additivity property. The additivity property says that if the neural network were partitioned into two physically

312

unconnected subnetworks, then Vex) can be rewritten as VI (Xl) + V2(X2 )
where VIis the energy function minimized by the first subnetwork and V2 is
the energy function minimized by the second subnetwork. The third assumption
is that Vex) provides a sufficient amount of information to specify the probability of activation pattern X. That is, p (X) = G(V(X? where G is some continuous function. And the final assumpti;n (following Smolen sky 2) is that statistical and physical independence are equivalent.
To derive ps(X), it is necessary to characterize G more specifically. Note
that if probabilities are assigned to activation patterns such that physically
independent substates of the system are also statistically independent, then the
additivity property of V(X) forces G to be an exponential function since the
continuous function that maps addition into multiplication is the exponential .
After normalization and the assignment of unity to an irrelevant free parameter
2, the unique subjective pf for a network model that minimizes V(X) during the
information retrieval process is:

onz

p s(X;A)

Z

=Z -1 exp [ -

=Jexp[ -

V (X;A)]

V (X;A)]dX

(1)

(2)

provided that Z < C < 00. Note that the integral in (2) is taken over sp. Also note
that the pf, Ps' and samfle space, Sp, specify a Markov Random Field since (1)
is a Gibbs distribution .

Example 1: Subjective pfs for associative back-propagation networks
The information retrieval equation for an associative back-propagation 6
network can be written in the form ~[I;A] where the elements of the vector 0
are the activity levels for the output units and the elements of the vector I are the
activity levels for the input units. The parameter vector A specifies the values

313

of the ""connection strengths"" among the units in the system. The function cl>
specifies the architecture of the network.
A natural additive energy function for the information retrieval dynamics of the least squares associative back-propagation algorithm is:

V(O)

= I()-.4>(I;A) 12,

(3)

If Sp is defined to be a real vector space such that 0 esp, then direct substitution of V(O) for ViX;A) into (1) and (2) yields a multivariate Gaussian density
function with mean cl>(I;A) and covariance matrix equal to the identity matrix
multiplied by 1!2. This multivariate Gaussian density function is ps(OII;A).
That is, with respect to ps(OII;A), information retrieval in an associative backpropagation network involves retrieving the ""most probable"" output vector, 0,
for a given input vector, I.

Example 2: Subjective pis/or Hopfield and BSB networks.

The Hopfield 7 and BSB model 8,9 neural network models minimize the
following energy function during information retrieval:

T

Vex) =-X MX

(4)

where the elements of X are the activation levels of the units in the system. and
the elements of M are the connection strengths among the units. Thus, the subjective pf for these networks is:

314

-l
T
P s< X)= Z exp [X M X]

where Z

=l:exp [XTM X]

(5)

where the summation is taken over Sp.
APPLICATIONS OF TIlE TIIEORY
If the subjective pf for a given connectionist system is known, then tradi-

tional analyses from the theory of statistical inference are immediately applicable. In this section some examples of how these analyses can aid in the design
and analysis of neural networks are provided.
Evaluating Learning Algorithms

Learning in a neural network model involves searching for a set of connection strengths or parameters that obtain a global minimum of a learning
energy function. The theory proposed here explicitly shows how an optimal
learning energy function can be constructed using the model's subjective pf and
the environmental pf. In particular, optimal learning is defined as searching for
the most probable connection strengths, given some set of observations (samples) drawn from the environmental pf. Given some mild restrictions upon the
fonn of the a priori pf associated with the connection strengths, and for a
sufficiently large set of observations, estimating the most probable connection
strengths (MAP estimation) is equivalent to maximum likelihood estimation 10
A well-known result 11 is that if the parameters of the subjective pf are
represented by the parameter vector A, then the maximum likelihood estimate of
A is obtained by finding the A * that minimizes the function :

315

E(A) =- <.LOG [p s(X;A)]>

(6)

where < > is the expectation operator taken with respect to the environmental pf.
Also note that (6) is the Kullback-Leibler 12 distance measure plus an irrelevant
constant. Asymptotically, E(A) is the logarithm of the probability of A given
some set of observations drawn from the environmental pf.
Equation (6) is an important equation since it can aid in the evaluation
and design of optimal learning algorithms. Substitution of the multivariate
Gaussian associated with (3) into (6) shows that the back-propagation algorithm
is doing gradient descent upon the function in (6). On the other hand, substitution of (5) into (6) shows that the Hebbian and Widrow-Hoff learning rules proposed for the Hopfield and BSB model networks are not doing gradient descent
upon (6).
Evaluating Network Architectures

The global minimum of ~6) occurs if and only if the subjective and
environmental pfs are equivalent 2. Thus, one crucial issue is whether any set
of connection strengths exists such that the neural network's subjective pf can
be made equivalent to a given environmental pf. If no such set of connection
strengths exists, the subjective pf, p s' is defined to be misspecified. White 11
and Lancaster 13 have introduced a statistical test designed to re~ct the null
hypothesis that the subjective pf, Ps' is not misspecified. Golden suggests a
version of this test that is suitable for subjective pfs with many parameters.
REFERENCES
1. D. E. Rumelhart, J. L. McClelland, and the PDP Research Group, Parallel
distributed processing: Explorations in the microstructure of cognition, 1,
(MIT Press, Cambridge, 1986).
2. P. Smolensky, In D. E. Rumelhart, J. L. McClelland and the PDP Research
Group (Eds.), Parallel distributed processing: Explorations in the microstructure of cognition, 1, (MIT Press, Cambridge, 1986), pp. 194-281.

316

3. R. M. Golden, A unified framework for connectionist systems. Unpublished
manuscript.
4. C. Goffman, Introduction to real analysis. (Harper and Row, N. Y., 1966), p.
65.
5. J. L. Marroquin, Probabilistic solution of inverse problems. A.I. Memo 860,
MIT Press (1985).
6. D. E. Rumelhart, G. E. Hinton, & R. J. Williams, In D. E. Rumelhart, 1. L.
McClelland, and the PDP Research Group (Eds.), Parallel distributed processing: Explorations in the microstructure of cognition, 1, (MIT Press,
Cambridge, 1986), pp. 318-362.
7. J. 1. Hopfield, Proceedings of the National Academy of Sciences, USA, 79,
2554-2558 (1982).
8. J. A. Anderson, R. M. Golden, & G. L. Murphy, In H. Szu (Ed.), Optical and
Hybrid Computing, SPIE, 634,260-276 (1986).
9. R. M. Golden, Journal of Mathematical Psychology, 30,73-80 (1986).
10. H. L. Van Trees, Detection, estimation, and modulation theory. (Wiley, N.
Y.,1968).
11. H. White, Econometrica, 50, 1-25 (1982).
12. S. Kullback & R. A. Leibler, Annals of Mathematical Statistics, 22, 79-86
(1951).
13. T. Lancaster, Econometrica, 52, 1051-1053 (1984).
ACKNOWLEDGEMENTS
This research was supported in part by the Mellon foundation while the
author was an Andrew Mellon Fellow in the Psychology Department at the
University of Pittsburgh, and partly by the Office of Naval Research under Contract No. N-OOI4-86-K-OI07 to Walter Schneider. This manuscript was revised
while the author was an NIH postdoctoral scholar at Stanford University. This
research was also supported in part by grants from the Office of Naval Research
(Contract No. NOOOI4-87-K-0671), and the System Development Foundation to
David Rumelhart. I am very grateful to Dean C. Mumme for comments, criticisms, and helpful discussions concerning an earlier version of this manuscript.
I would also like to thank David B. Cooper of Brown University for his suggestion that many neural network models might be viewed within a unified statistical framework.

"
76,1987,"A Dynamical Approach to Temporal Pattern Processing","",76-a-dynamical-approach-to-temporal-pattern-processing.pdf,"Abstract Missing","750

A DYNAMICAL APPROACH TO TEMPORAL PATTERN
PROCESSING
W. Scott Stornetta
Stanford University, Physics Department, Stanford, Ca., 94305
Tad Hogg and B. A. Huberman
Xerox Palo Alto Research Center, Palo Alto, Ca. 94304
ABSTRACT
Recognizing patterns with temporal context is important for
such tasks as speech recognition, motion detection and signature
verification. We propose an architecture in which time serves as its
own representation, and temporal context is encoded in the state of the
nodes. We contrast this with the approach of replicating portions of the
architecture to represent time.
As one example of these ideas, we demonstrate an architecture
with capacitive inputs serving as temporal feature detectors in an
otherwise standard back propagation model. Experiments involving
motion detection and word discrimination serve to illustrate novel
features of the system. Finally, we discuss possible extensions of the
architecture.
INTRODUCTION
Recent interest in connectionist, or ""neural"" networks has emphasized their
ability to store, retrieve and process patterns1,2. For most applications, the patterns to
be processed are static in the sense that they lack temporal context.
Another important class consists of those problems that require the processing
of temporal patterns. In these the information to be learned or processed is not a
particular pattern but a sequence of patterns. Such problems include speech
processing, signature verification, motion detection, and predictive signal
processin,r-8.
More precisely, temporal pattern processing means that the desired output
depends not only on the current input but also on those preceding or following it as
well. This implies that two identical inputs at different time steps might yield
different desired outputs depending on what patterns precede or follow them.
There is another feature characteristic of much temporal pattern processing.
Here an entire sequence of patterns is recognized as a single distinct category,

? American Institute of Physics 1988

751

generating a single output. A typical example of this would be the need to recognize
words from a rapidly sampled acoustic signal. One should respond only once to the
appearance of each word, even though the word consists of many samples. Thus, each
input may not produce an output.
With these features in mind, there are at least three additional issues which
networks that process temporal patterns must address, above and beyond those that
work with static patterns. The first is how to represent temporal context in the state of
the network. The second is how to train at intermediate time steps before a temporal
pattern is complete. The third issue is how to interpret the outputs during recognition,
that is, how to tell when the sequence has been completed. Solutions to each of these
issues require the construction of appropriate input and output representations. This
paper is an attempt to address these issues, particularly the issue of representing
temporal context in the state of the machine . We note in passing that the recognition
of temporal sequences is distinct from the related problem of generating a sequence,
given its first few members 9 .l O?11 .

TEMPORAL CLASSIFICATION
With some exceptions 10.12 , in most previous work on temporal problems the
systems record the temporal pattern by replicating part of the architecture for each
time step. In some instances input nodes and their associated links are replicated 3,4. In
other cases only the weights or links are replicated, once for each of several time
delays 7,8. In either case, this amounts to mapping the temporal pattern into a spatial
one of much higher dimension before processing.
These systems have generated significant and encouraging results. However,
these approaches also have inherent drawbacks. First, by replicating portions of the
architecture for each time step the amount of redundant computation is significantly
increased. This problem becomes extreme when the signal is sampled very
frequently4. :-.l' ext, by re lying on replications of the architecture for each time step, the
system is quite inflexible to variations in the rate at which the data is presented or size
of the temporal window. Any variability in the rate of the input signal can generate an
input pattern which bears little or no resemblance to the trained pattern. Such
variability is an important issue, for example, in speech recognition . Moreover, having
a temporal window of any fixed length makes it manifestly impossible to detect
contextual effects on time scales longer than the window size. An additional difficulty
is that a misaligned signal, in its spatial representation, may have very little
resemblance to the correctly aligned training signal. That is, these systems typically
suffer from not being translationally invariant in time.
~etworks based on relaxation to equilibrium 11,13,14 also have difficulties for

use with temporal problems. Such an approach removes any dependence on initial

752

conditions and hence is difficult to reconcile directly with temporal problems, which by
their nature depend on inputs from earlier times. Also, if a temporal problem is to be
handled in terms of relaxation to equilibrium, the equilibrium points themselves must
be changing in time.
A NON?REPLICATED, DYNAMIC ARCHITECTURE
We believe that many of the difficulties mentioned above are tied to the
attempt to map an inherently dynamical problem into a static problem of higher
dimension. As an alternative, we propose to represent the history of the inputs in the
state of the nodes of a system, rather than by adding additional units. Such an
approach to capturing temporal context shows some very immediate advantages over
the systems mentioned above . F'irst, it requires no replication of units for each distinct
time step. Second, it does not fix in the architecture itself the window for temporal
context or the presentation rate. These advantages are a direct result of the decision to
let time serve as its own representation for temporal sequences, rather than creating
additional spatial dimensions to represent time.
In addition to providing a solution to the above problems, this system lends
itself naturally to interpretation as an evolving dynamical system. Our approach
allows one to think of the process of mapping an evolving input into a discrete
sequence of outputs (such as mapping continuous speech input into a sequence of
words) as a dynamical system moving from one attractor to another 15 .
As a preliminary example of the application of these ideas, we introduce a
system that captures the temporal context of input patterns without replicating units
for each time step. We modify the conventional back propagation algorithm by making
the input units capacitive. In contrast to the conventional architecture in which the
input nodes are used simply to distribute the signal to the next layer, our system
performs an additional computation. Specifically, let Xi be the value computed by an
input node at time ti ' and Ii be the input signal to this node at the same time. Then the
node computes successive values according to
(1)

where a is an input amplitude and d is a decay rate. Thus, the result computed by an
input unit is the sum of the current input value multiplied by a, plus a fractional part,
d, of the previously computed value of the input unit. In the absence of further input,
this produces an exponential decay in the activation of the input nodes. The value for d
is chosen so that this decay reaches lie of its original value in a time t characteristic of
the time scale for the particular problem, i.e., d=e'tr, where r is the presentation rate.
The value for a is chosen to produce a specified maximum value for X, given by

753

al ma /(1-d) . We note that Eq. (1) is equivalent to having a non-modifiable recurrent
link with weight d on the input nodes, as illustrated in Fig. l.

o

0

Fig. 1: Schematic architecture with capacitive inputs. The input nodes
compute values according to Eq. (1). Hidden and output units are
identical to standard back propagation nets.
The processing which takes place at the input node can also be thought of in
terms of an infinite impulse response (IIR) digital filter. The infinite impulse response
of the filter allows input from the arbitrarily distant past to influence the current
output of the filter, in contrast to methods which employ fixed windows, which can be
viewed in terms of finite impulse response (FIR) filters. The capacitive node of Fig. 1 is
equivalent to pre-processing the signal with a filter with transfer function a/(1-dz? 1) .
This system has the unique feature that a simple transformation of the
parameters a and d allows it to respond in a near-optimal way to a signal which differs
from the training signal in its rate. Consider a system initially trained at rate r with
decay rate d and amplitude a. To make use of these weights for a different presentation
rate, r~ one simply adjusts the values a 'and d'according to
d' = d r/r '

(2)

1 - d'
a' = a """"[:""d

(3)

754

These equations can be derived by the following argument. The general idea is
that the values computed by the input nodes at the new rate should be as close as
possible to those computed at the original rate. Specifically, suppose one wishes to
change the sampling rate from r to nr, where n is an integer. Suppose that at a time to
the computed value of the input node is Xo ' If this node receives no additional input,
then after m time steps, the computed value of the input node will be Xod m . For the
more rapid sampling rate, Xod m should be the value obtained after nm time steps.
Thus we require

(4)
which leads to Eq. (2) because n= r7r. Now suppose that an input I is presented m
times in succession to an input node that is initially zero. After the
the computed value of the input node is

mth

presentation,

(5)
Requiring this value to be equal to the corresponding value for the faster presentation
rate after nm time steps leads to Eq. (3). These equations, then, make the computed
values of the input nodes identical, independent of the presentation rate . Of course,
this statement only holds exactly in the limit that the computed values of the input
nodes change only infinitesimally from one time step to the next. Thus, in practice, one
must insure that the signal is sampled frequently enough that the computed value of
the input nodes is slowly changing.
The point in weight space obtained after initial training at the rate r has two
desirable properties. First, it can be trained on a signal at one sampling rate and then
the values of the weights arrived at can be used as a near-optimal starting point to
further train the system on the same signal but at a different sampling rate.
Alternatively, the system can respond to temporal patterns which differ in rate from
the training signal, without any retraining of the weights. These factors are a result of
the choice of input representation, which essentially present the same pattern to the
hidden unit and other layers, independent of sampling rate. These features highlight
the fact that in this system the weights to some degree represent the temporal pattern
independent of the rate of presentation. In contrast, in systems which use temporal
windows, the weights obtained after training on a signal at one sampling rate would
have little or no relation to the desired values of the weights for a differen.t sampling
rate or window size.

755

EXPERIMENTS
As an illustration of this architecture and related algorithm, a three-layer,
15-30-2 system was trained to detect the leftward or rightward motion of a gaussian
pulse moving across the field of input units with sudden changes in direction. The
values of d and a were 0.7788 and 0.4424, respectively. These values were chosen to
give a characteristic decay time of 4 time steps with a maximum value computed by
the input nodes of 2.0 . The pulse was of unit height with a half-width, 0, of 1.3. Figure
2 shows the input pulse as well as the values computed by the input nodes for leftward
or rightward motion. Once trained at a velocity of 0.1 unit per sampling time, the
velocity was varied over a wide range, from a factor of2 slower to a factor of2 faster as
shown in Fig. 3. For small variations in velocity the system continued to correctly
identify the type of motion. More impressive was its performance when the scaling
relations given in Eqs. (2) and (3) were used to modify the amplitude and decay rate . In
this case, acceptable performance was achieved over the entire range of velocities
tested. This was without any additional retraining at the new rates. The difference in
performance between the two curves also demonstrates that the excellent performance
of the system is not an anomaly of the particular problem chosen, but characteristic of
rescaling a and d according to Eqs. (2) and (3). We thus see that a simple use of
capacitive links to store temporal context allows for motion detection at variable
velocities.
A second experiment involving speech data was performed to compare the
system's performance to the time-delay-neural-network of Watrous and Shastri 8 . In
their work, they trained a system to discriminate between suitably processed acoustic
signals of the words ""no"" and ""go."" Once trained on a single utterance, the system was
able to correctly identify other samples of these words from the same speaker. One
drawback of their approach was that the weights did not converge to a fixed point. We
were therefore particularly interested in whether our system could converge smoothly
and rapidly to a stable solution, using the same data, and yet generalize as well as
theirs did. This experiment also provided an opportunity to test a solution to the
intermediate step training problem.
The architecture was a 16-30-2 network. Each of the input nodes received an
input signal corresponding to the energy (sampled every 2.5 milliseconds) as a
function of time in one of 16 frequency channels. The input values were normalized to
lie in the range 0.0 to 1.0. The values of d and a were 0.9944 and 0.022, respectively.
These values were chosen to give a characteristic decay time comparable to the length
of each word (they were nearly the same length), and a maximum value computed by
the input nodes of 4.0. For an input signal that was part of the word ""no"", the training
signal was (t.O, 0.0), while for the word ""go"" it was (0.0, 1.0). Thus the outputs that
were compared to the training signal can be interpreted as evidence for one word or the
other at each time step. The error shown in Fig. 4 is the sum of the squares of the

756

difference between the desired outputs and the computed outputs for each time step,
for both words, after training up to the number ofiterations indicated along the x-axis.

a) input wavepacket

2

3

4

5

6

7

B

9

10

5

6

7

B

9

10

5

6

7

B

9

10

b) rightward
motion

2

3

4

c) leftward
motion

2

3

4

Fig. 2: a) Packet presented to input nodes. The x-axis represents the
input nodes. b) Computed values from input nodes during rightward
motion. c) Computed values during leftward motion .

757

100~______________~~~~__~~~::::~

%

80 __ .

:
' ""':w
-

-

-

~I!""'.::..:/,j/.:).

-. . . . . . . . . . . . . . . . . .

. 'i

-

;~

c
o
r

?

60 _

I)

?

?

I~

?

40 +-

r

e
c
t

'0

20

-I-

o

I
I

I
I

I
I

I

.5

1.0

1.5

2.0

I

v'lv
Fig. 3: Performance of motion detection experiment for various
velocities. Dashed curve is performance without scaling and solid
curve is with the scaling given in Eqs. (2) and (3).
125.0
100.0

e
r
r

75.0
50.0

0

r

25.0
0.0
0

500

1000

1500

2000

2500

iterations
Fig. 4: Error in no/go discrimination as a function of the number of
training iterations.
Evidence for each word was obtained by summing the values of the respective
nodes over time. This suggests a mechanism for signaling the completion of a
sequence: when this sum crosses a certain threshold value, the sequence (in this case,
the word) is considered recognized. Moreover, it may be possible to extend this
mechanism to apply to the case of connected speech: after a word is recognized, the
sums could be reset to zero, and the input nodes reinitialized.
Once we had trained the system on a single utterance, we tested the
perfor~ance of the resulting weights on additional utterances of the same speaker.

758

Preliminary results indicate an ability to correctly discriminate between ""no"" and
""go."" This suggests that the system has at least a limited ability to generalize in this
task domain.

DISCUSSION
At a more general level, this paper raises and addresses some issues of
representation. By choosing input and output representations in a particular way, we
are able to make a static optimizer work on a temporal problem while still allowing
time to serve as its own representation. In this broader context, one realizes that the
choice of capacitive inputs for the input nodes was only one among many possible
temporal feature detectors.
Other possibilities include refractory units, derivative units and delayed spike
units. Refractory units would compute a value which was some fraction of the current
input. The fraction would decrease the more frequently and recently the node had been
""on"" in the recent past. A derivative unit would have a larger output the more rapidly
a signal changed from one time step to the next. A delayed spike unit might have a
transfer function of the form Itne- at , where t is the time since the presentation of the
signal. This is similar to the function used by Tank and Hopfield7 , but here it could
serve a different purpose. The maximum value that a given input generated would be
delayed by a certain amount of time . By similarly delaying the training signal, the
system could be trained to recognize a given input in the context of signals not only
preceding but also following it. An important point to note is that the transfer
functions of each of these proposed temporal feature detectors could be rescaled in a
manner similar to the capacitive nodes. This would preserve the property of the system
that the weights contain information about the temporal sequence to some degree
independent of the sampling rate.
An even more ambitious possibility would be to have the system train the
parameters, such as d in the capacitive node case. It may be feasible to do this in the
same way that weights are trained, namely by taking the partial of the computed error
with respect to the parameter in question. Such a system may be able to determine the
relevant time scales of a temporal signal and adapt accordingly.

ACKNOWLEDGEMENTS
We are grateful for fruitful discllssions with Jeff Kephart and the help of
Raymond Watrous in providing data from his own experiments. This work was
partially supported by DARPA ISTO Contract # N00140-86-C-8996 and ONR
Contract # N00014-82-0699_

759

1.

D. Rumelhart, ed., Parallel Distributed Processing, (:\'lIT Press, Cambridge,
1986).

2.

J. Denker, ed., Neural Networks for Computing, AlP Conf. Proc.,151 (1986).

3.

T. J. Sejnowski and C. R. Rosenberg, NETtalk: A Parallel Network that Learns to
Read Aloud, Johns Hopkins Univ. Report No . JHU/EECS-86101 (1986).

4.

J.L. McClelland and J.L. Elman, in Parallel Distributed Processing, vol. II, p. 58.

5.

W. Keirstead and B.A. Huberman, Phys . Rev. Lett. 56,1094 (1986).

6.

A. Lapedes and R. Farber, Nonlinear Signal Processing Using Neural Networks,
Los Alamos preprint LA-uR-87-2662 (1987).

7.

D. Tank and J. Hopfield, Proc. Nat. Acad. Sci., 84, 1896 (1987).

8.

R. Watrous and L. Shastri, Proc. 9th Ann. Conf Cog. Sci. Soc., (Lawrence

Erlbaum, Hillsdale, 1987), p. 518.
9.

P. Kanerva, Self-Propagating Search: A Unified Theory of Memory, Stanford
Univ. Report No. CSLI-84-7 (1984).

10.

M.1. Jordan, Proc. 8th Ann. Conf. Cog. Sci. Soc., (Lawrence Erlbaum, Hillsdale,
1986), p. 531.

11.

J. Hopfield,Proc. Nat. Acad. SCi., 79, 2554 (1982).

12.

S. Grossberg, The Adaptive Brain, vol. II, ch. 6, (North-Holland, Amsterdam,
1987).

13.

G. Hinton and T. J. Sejnowski, in Parallel Distributed Processing, vol. I, p. 282.

14.

B. Gold, in Neural Networks for Computing, p. 158.

15.

T. Hogg and B.A. Huberman, Phys. Rev. A32, 2338 (1985).

"
77,1987,"The Performance of Convex Set Projection Based Neural Networks","",77-the-performance-of-convex-set-projection-based-neural-networks.pdf,"Abstract Missing","534

The Performance of Convex Set projection Based Neural Networks

Robert J. Marks II, Les E. Atlas, Seho Oh and James A. Ritcey
Interactive Systems Design Lab, FT-IO
University of Washington, Seattle, Wa 98195.
ABSTRACT

We donsider a class of neural networks whose performance can be
analyzed
and
geometrically
visualized
in
a
signal
space
environment.
Alternating
projection
neural
networks
(APNN' s)
perform by alternately projecting between two or more constraint
sets. Criteria for desired and unique convergence are easily
established. The network can be configured in either a homogeneous
or layered form. The number of patterns that can be stored in the
network is on the order of the number of input and hidden neurons.
If the output neurons can take on only one of two states, then the
trained layered APNN can be easily configured to converge in one
iteration. More generally, convergence is at an exponential rate.
Convergence
can
be
improved by
the
use
of
sigmoid
type
nonlinearities, network relaxation and/or increasing the number of
neurons in the hidden layer. The manner in which the network
responds to data for which it was not specifically trained (i.e.
how it generalizes) can be directly evaluated analytically.
1. INTRODUCTION

In this paper,
we depart from the performance analysis
techniques normally applied to neural networks. Instead, a signal
space approach is used to gain new insights via ease of analysis
and geometrical interpretation. Building on a foundation laid
elsewhere l - 3 , we demonstrate that alternating projecting neural
network's
(APNN's)
formulated from such a viewpoint can be
configured in layered form or homogeneously.
Significiantly,
APNN's have advantages over other neural
network architectures . For example,
(a) APNN's perform by alternatingly projecting between two or more
constraint sets. Criteria can be established for proper
iterative convergence for both synchronous and asynchronous
operation. This is in contrast to the more conventional
technique of formulation of an energy metric for the neural
networks, establishing a lower energy bound and showing that
the energy reduces each iteration 4 - 7 ? Such procedures generally
do not address the accuracy of the final solution. In order to
assure that such networks arrive at the desired globally
minimum energy, computationaly lengthly procedures such as
simulated annealing are used B - 10 ? For synchronous networks,
steady state oscillation can occur between two states of the
same energyll
(b) Homogeneous neural networks such as Hopfield's content
addressable memory4,12-14 do not scale well, i.e. the capacity

? American Institute of Physics 1988

535

of Hopfield's neural networks less than doubles when the number
of neurons is doubled 15-16. Also, the capacity of previously
proposed layered neural networks 17 ,18 is not well understood.
The capacity of the layered APNN'S, on the other hand, is
roughly equal to the number of input and hidden neurons 19 ?
(c) The speed of backward error propagation learning 17-18 can be
painfully slow. Layered APNN's, on the other hand, can be
trained on only one pass through the training data 2 ? If the
network memory does not saturate, new data can easily be
learned without repeating previous data. Neither is the
effectiveness of recall of previous data diminished. Unlike
layered back propagation neural networks, the APNN recalls by
iteration. Under certain important applications, however, the
APNN will recall in one iteration.
(d) The manner in which layered APNN's generalizes to data for
which it was not trained can be analyzed straightforwardly.
The outline of this paper is as follows. After establishing the
dynamics of the APNN in the next section, sufficient criteria for
proper convergence are given. The convergence dynamics of the APNN
are explored. Wise use of nonlinearities, e.g. the sigmoidal type
nonlinearities 2 , improve the network's performance. Establishing a
hidden layer of neurons whose states are a nonlinear function of
the input neurons' states is shown to increase the network's
capacity and the network's convergence rate as well. The manner in
which the networks respond to data outside of the training set is
also addressed.
2. THE ALTERNATING PROJECTION NEURAL NETWORK

In this section, we established the notation for the APNN.
Nonlinear modificiations to the network made to impose certain
performance attributes are considered later.
Consider a set of N continuous level linearly independent
library vectors (or patterns) of length L> N: {?n I OSnSN}. We form
the library matrix !:. = [?1 1?2 I ... I?N ] and the neural network
interconnect matrix a T = F (!:.T !:. )-1 FT where the superscript T
denotes transposition. We divide the L neurons into two sets: one
in which the states are known and the remainder in which the states
are
unknown.
This partition may change from application to
application. Let Sk (M) be the state of the kth node at time M. If
the kth node falls into the known catego~, its state is clamped to
the known value (i.e. Sk (M) = Ik where I is some library vector).
The states of the remaining floating neurons are equal to the sum
of the inputs into the node. That is, Sk (M) = i k , where
L

i

k

=
p

a

r1

tp k

sp

(1)

=

The interconnect matrix is better trained iteratively2. To include
a new library vector ?, the interconnects are updated as
~T
~T~
~
~
! + (EE ) / (E E) where E = (.!. - !) f .

536

If all neurons change state simultaneously (i.e. sp = sp (M-l) ), then
the net is said to operate synchronously. If only one neuron changes
state at a time, the network is operating asynchronously.
Let P be the number of clamped neurons. We have proven l that the
neural states converge strongly to the extrapolated library vector
if the first P rows of ! (denoted KP) form a matrix of full column
rank. That is, no column of ~ can be expressed as a linear
combination of those remainin.,v. 2 By strong convergence b , we mean
lim II 1 (M) II == 0 where II x II ==

t

iTi.

M~OO

Lastly, note that subsumed in the criterion that ~ be full
rank is the condition that the number of library vectors not exceed
the number of known neural states (P ~ N). Techniques to bypass this
restriction by using hidden neurons are discussed in section 5.
Without loss of generality, we will assume
Partition Notation:
that neurons 1 through P are clamped and the remaining neurons are
floating. We adopt the vectOr partitioning notation
71

Ip

=

IIp]
~

io

10

where
is the P-tuple of the first P elements of 1. and
is a
vector of the remaining Q = L-P. We can thus write, for example, ~
[ f~ If~ I ... If: ]. Using this partition notation, we can define
the neural clamping operator by: 7 _

!l ~ -

IL]
7

10

l

Thus, the first P elements of I are clamped to P ? The remaining Q
nodes ""float"".
Partition notation for the interconnect matrix will also prove
useful. Define

T r!2 I !lJ
L~

where

~2

is a P by P and !4 a Q by Q matrix.
3. STEADY STATE CONVERGENCE PROOFS

For purposes of later reference, we address convergence of the
network
for
synchronous
operation.
Asynchronous
operation
is
addressed in reference 2. For proper convergence, both cases
require that ~ be full rank. For synchronous operation, the
network iteration in (1) followed by clamping can be written as:
~

~

s(M+l) =!l ~ sCM)
(2)
As is illustrated in l - 3, this operation can easily be visualized
in an L dimensional signal space.
b

The referenced convergence proofs prove strong convergence in an
infinite dimensional Hilbert space. In a discrete finite
dimensional space, both strong and weak convergence imply
uniform convergence l9 ? 2D , i.e. 1(M)~t as M~oo.

537
For a given partition with
written in partitioned form as

[;'(M+J

!l

clamped

P

l*J[
!3!4

neurons,

(2)

can

J

~oI'(M)

be

(3)

The states of the P clamped neurons are not affected by their input
sum.
Thus, there is no contribution to the iteration by ~1 and ~2.
We can equivalently write (3) as
-+0

s

(M+ 1)

-;tp-+o

= !3 f

+!4 s

(M)

(4 )

We show in that if fp is full rank, then the spectral radius
(magnitude of the maximum eigenvalue) of ~4 is strictly less than
one 19 ? It follows that the steady state solution of (4) is:
(5 )

where, since fp is full rank, we have made use of our claim that
-+0
S (00)

=

-;to

f

(6)

4. CONVERGENCE DYNAMICS

In this section, we explore different convergence dynamics of
the APNN when fp is full column rank. If the library matrix
displays certain orthogonality characteristics, or if there is a
single output (floating) neuron, convergence can be achieved in a
single iteration. More generally, convergence is at an exponential
rate. Two techniques are presented to improve convergence. The
first is standard relaxation. Use of nonlinear convex constraint at
each neuron is discussed elsewhere 2 ,19.
One Step Convergence: There are at least two important cases where
the APNN converges other than uniformly in one iteration. Both
require that the output be bipolar (?1).
Convergence is in one
step in the sense that
-;to
?
-+0
f
= Slgn
s (1)
(7)
where the vector operation sign takes the sign of each element of
the vector on which it operates.

,0 .

CASE 1: If there is a single output neuron, then, from (4), (5) and
(6), sO (1)
(1 t LL )
Since the eigenvalue of the (scalar)
matrix, !4 = tL L lies between zero and one 1 9, we conclude that 1t LL > O. Thus, if ,0 is restricted to ?1, (7) follows immediately. A
technique to extend this result to an arbitrary number of output
neurons in a layered network is discussed in section 7.
CASE 2: For certain library matrices, the APNN can also display one
step convergence. We showed that if the columns of K are orthogonal
and the columns of fp are also orthogonal, then one synchronous
iteration results in floating states proportional to the steady

538

state values 19

?

Specifically, for the floating neurons,

~o

II

(1)

t

P

2

II

1

0

(8)

111112
An important special case of (8) is when the elements of Fare
all ?1 and orthogonal. If each element were chosen by a 50-50 coin
flip, for example, we would expect (in the statistical sense) that
this would be the case.
Exponential Convergence: More generally, the convergence rate of
the APNN is exponential and is a function of the eigenstructure of
.!4. Let {~r I 1 ~ r ~ Q } denote the eigenvectors of .!4 and {A r } the
corresponding eigenvalues. Define ~ = [ ~l 1~2 I ... I~o] and the
diagonal matrix A4 such that diag ~ = [AI A2 ... Ao] T ? Then we can
.
A
T ?
-+
T-+
-.
T
?
1
f
Wrl.te :!.4.=~ _4 ~. Defl.ne x (M) =~ s (M). S.;nce ~ ~ = I, \t...,. fol ows T ro~
the--+differe-ace equatJ-on i~ ('Up that x(M+l)=~:!.4 ~ ~ sCM) + ~ .!3
=~4 x (M) + g where g = ~.!3
The solution to this difference
equation is

1

t.

M

""r
/\ok

't'
1J
r

=

gk =

[

1 _

""kM + 1 ]

/\0

(

,- 1
1 - ,
/\ok)
gk

(9)

0

Since the spectral radius of !4 is less than one 19 , ~: ~ 0 as M ~
Our steady state result is thus x k (~) = (1 - Ak )
gk. Equation
.
[
""
M
+
l
]
(9)
can therefore be wrl.tten as x k (M) =
1 - /\ok
x k (~). The
eCflivalent of a ""time constant"" in this exponential convergence is
1/ tn (111 Ak I). The speed of convergence is thus dictated by the
spectral radius of .!4. As we have shown 19 later, adding neurons in
a hidden layer in an APNN can significiantly reduce this spectral
radius and thus improve the convergence rate.

~.

Relaxation: Both the projection and clamping operations can be
relaxed to alter the network's convergence without affecting its
steady state 20 - 21 ? For the interconnects, we choose an appropriate
value of the relaxation parameter a in the interval (0,2) and
9
redefine the interconnect matrix as T
aT + (1
a)I or
equivalently,
=

{a(t nn -l)+1

; n =m

a tnrn
TO see the effect of such relaxation on convergence, we need
simply exam\ne the resulting ::dgenvalues. If .!4 has eigenvalues
{A r I, then .!4 has eigenvalues Ar = 1 + a (Ar - 1). A Wl.se choice of a
reduces the spectral radius of .!~ with respect to that of .!4' and
thus decreases the time constant of the network's convergence.
Any of the operators projecting onto convex sets can be relaxed
without affecting steady state convergence 19 - 20 ? These include the
~ operator 2 and the sigmoid-type neural operator that projects onto
a box. Choice of stationary relaxation parameters without numerical
andlor empirical study of each specific case, however, generally
remains more of an art than a science.

539

5. LAYERED APNN' S

The networks thus far considered are homogeneous in the sense
that any neuron can be clamped or floating. If the partition is
such that the same set of neurons always provides the network
stimulus and the remainder respond, then the networks can be
simplified. Clamped neurons, for example, ignore the states of the
other neurons. The corresponding interconnects can then be deleted
from the neural network architecture. When the neurons are so
partitioned, we will refer the APNN as layered.
In this section, we explore various aspects of the layered APNN
and in particular, the use of a so called hidden layer of neurons
to increase the storage capacity of the network. An alternate
architecture for a homogeneous APNN that require only Q neurons has
been reported by Marks 2 ?
Hidden Layers: In its generic form, the APNN cannot perform a
simple exclusive or (XOR).
Indeed, failure to perform this same
operation was a nail in the coffin of the perceptron 22 . Rumelhart
et. al.1 7 -18 revived the percept ron by adding additional layers of
neurons. Although doing so allowed nonlinear discrimination, the
iterative training of such networks can be painfully slow. With the
addition of a hidden layer, the APNN likewise generalizes. In
contrast, the APNN can be trained by looking at each data vector
only once 1 ?
Although neural networks will not likely be used for performing
XOR's, their use in explaining the role of hidden neurons is quite
instructive. The library matrix for the XOR is

f-

[~ ~ ~ ~ 1

The first two rOwS of F do not form a matrix of full column rank.
Our approach is to augment fp with two more rows such that the
resulting matrix is full rank.
Most any nonlinear combination of
the first two rowS will in general increase the matrix rank.
Such
a procedure, for example, is used in ~-classifiers23 . possible
nonlinear operations include multiplication, a logical ""AND"" and
running a weighted sum of the clamped neural states through a
memoryless nonlinearity such as a sigmoid. This latter alteration
is particularly well suited to neural architectures.
To illustrate with the exclusive or (XOR) , a new hidden neural
state is set equal to the exponentiation of the sum of the first
two rows. A second hidden neurons will be assigned a value equal to
the cosine of the sum of the first two neural states multiplied by
Tt/2.
(The choice of nonlinearities here is arbitrary. )
The
augmented library matrix is

!:.+

0
0
1
1
0

0

1

1

0

1
1

e

e

e2

0

0
1

-1

1

0

540

In either the training or look-up mode, the states of the hidden
neurons are clamped indirectly as a result of clamping the input
neurons.
The playback architecture for this network is shown in Fig .1.
The interconnect values for the dashed lines are unity. The remaining interconnects are from the projection matrix formed from !+.
Geometrical Interpretation
In lower dimensions, the effects of
hidden neurons can be nicely illustrated geometrically. Consider
the library matrix
F =

1

1/2

]

Clearly IP = (1/2 1) . Let the neurons in the hidden layer be
determined by the nonlineariy x 2 where x denotes the elements in
the first row of f. Then

!+ =

[t: I t; ] =

[ 1/2
1i4

1;2

J

The corresponding geometry is shown in Fig. 2 for x the input
neuron, y the output and h the hidden neuron. The augmented library
vectors are shown and a portion of the generated subspace is shown
lightly shaded. The surface of h = x 2 resembles a cylindrical lens in
three dimensions. Note that the linear variety corresponding to f =
1/2 intersects the cylindrical lens and subspace only at
Similarly, the x = 1 plane intersects the lens and subspace at
2 ?
Thus, in both cases, clamping the input corresponding to the first
element of one of the two library vectors uniquely determines the
library vector.

1+.
1

Convergence Improvement: Use of additional neurons in the hidden
layer will improve the convergence rate of the APNN 19 ? Specifically,
the spectral radius of the .!4 matrix is decreased as additional
neurons
are
added.
The
dominant
time
constant
controlling
convergence is thus decreased.
Capacity: Under the assumption that nonlinearities are chosen such
that the augmented fp matrix is of full rank, the number of vectors
which can be stored in the layered APNN is equal to the sum of the
number of neurons in the input and hidden layers. Note, then, that
interconnects between the input and output neurons are not needed
if there are a sufficiently large number of neurons in the hidden
layer.
6. GENERALIZATION
We are assured that the APNN will converge to the desired
result if a portion of a training vector is used to stimulate the
network. What, however, will be the response if an initialization
is used that is not in the training set or, in other words, how
does the network generalize from the training set?
To illustrate generalization, we return to the XOR problem. Let
S5 (M) denote the state of the output neuron at the Mth (synchronous)

541

loyer :

,
"""" ""
/

input

-

hidden

, , ""- ""/

/

/

X

3 exp

Figure 1. Illustration of a
layered APNN fori performing
an XOR.

Figure 3. Response of the
elementary XOR APNN using an
exponential and trignometric
nonlinearity in the hidden
layer. Note that, at the
corners, the function is
equal to the XOR of the

y

l(

Figure 2. A geometrical
illustration of the use of an
x 2 nonlinearity to determine
the states of hidden neurons.

Figure 4. The generalization
of the XOR networks formed by
thresholding the function in
Fig . 3 at 3/4. Different
hidden layer nonlinearities
result in different
generalizations.

542

iteration. If S1 and S2 denote the input clamped value, then
S5 (m+1) =t1 5 Sl + t 25 S2 + t35 S3 + t4 5 S4 + t5 5 S5 (m) where S3 =exp (Sl +S2 )
and S4 =cos [1t (S1 + S2) /2] To reach steady state, we let m tend to
infinity and solve for S5 (~) :
1

A plot of S5 (~) versus (S1,S2) is shown in Figure 3. The
plot goes through 1 and zero according to the XOR of the corner
coordinates.
Thresholding
Figure
3
at
3/4
results
in
the
generalization perspective plot shown in Figure 4.
To analyze the network's generalization when there are more
than one output neuron, we use (5) of which (10) is a special case.
If conditions are such that there is one step convergence, then
generalization plots of the type in Figure 4 can be computed from
one network iteration using (7).
7. NOTES

(a) There clearly exists a great amount of freedom in the choice of
the nonlinearities in the hidden layer. Their effect on the
network performance is currently not well understood. One can
envision, however, choosing nonlinearities to enhance some
network attribute such as interconnect reduction, classification
region shaping (generalization) or convergence acceleration.
(b) There is a possibility that for a given set of hidden neuron
nonlinearities, augmentation of the fp matrix coincidentally
will result in a matrix of deficent column rank, proper
convergence is then not assured. It may also result in a poorly
conditioned matrix, convergence will then be quite slow. A
practical solution to these problems is to pad the hidden layer
with additional neurons. As we have noted, this will improve
the convergence rate.
(c) We have shown in section 4 that if an APNN has a single
bipolar output neuron, the network converges in one step in
the sense of (7). Visualize a layered APNN with a single
output neuron.
If there are a sufficiently large number of
neurons in the hidden layer, then the input layer does not
need to be connected to the output layer. Consider a second
neural network identical to the first in the input and hidden
layers except the hidden to output interconnects are
different. Since the two networks are different only in the
output interconnects, the two networks can be combined into a
singlee network with two output neurons. The interconnects
from the hidden layer to the output neurons are identical to
those used in the single output neurons architectures. The new
network will also converge in one step. This process can
clearly be extended to an arbitrary number of output neurons.
REFERENCES
1.

R.J. Marks II, ""A Class of Continuous Level Associative Memory
Neural Nets,"" ~. Opt., vo1.26, no.10, p.200S, 1987.

543

2.

3.

4.

5.
6.

7.

8.

9.
10.
11.
12.
13.
14.
15.
16.
17.
18.
19.
20.

21.

22.
23.

K.F. Cheung et. al., ""Neural Net Associative Memories Based on
Convex Set Projections,"" Proc. IEEE 1st International Conf. on
Neural Networks, San Diego, 1987.
R.J. Marks II et. al., ""A Class of Continuous Level Neural
Nets,"" Proc. 14th Congress of International Commission for
Optics Conf., Quebec, Canada, 1987.
J.J. Hopfield, ""Neural Networks and Physical Systems with
Emergent Collective Computational Abilities,"" Proceedings
Nat. Acad. of Sciences, USA, vol.79, p.2554, 1982.
J.J. Hopfield et. al., ""Neural Computation of Decisions in
Optimization Problem,"" BioI. Cyber., vol. 52, p.141, 1985.
?D. W. Tank et. al., ""Simple Neurel Optimization Networks: an AID
Converter, Signal Decision Circuit and a Linear Programming
Circuit,"" IEEE Trans. Cir. ~., vol. CAS-33, p.533, 1986.
M. Takeda et. ai, ""Neural Networks for Computation: Number
Representation and Programming Complexity,"" ~. Opt., vol.
25, no. 18, p.3033, 1986.
S. Geman et. al., ""Stochastic Relaxation, Gibb's Distributions,
and the Bayesian Restoration of Images,"" IEEE Trans. Pattern
Recog. & Machine Intelligence., vol. PAMI-6, p.721, 1984.
S. Kirkpatrick et. al. ,""Optimization by Simulated Annealing,""
Science, vol. 220, no. 4598, p.671, 1983.
D.H. Ackley et. al., ""A Learning Algorithm for Boltzmann
Machines,"" Cognitive Science, vol. 9, p.147, 1985.
K.F. Cheung et. al., ""Synchronous vs. Asynchronous Behaviour
of Hopfield's CAM Neural Net,"" to appear in Applied Optics.
R.P. Lippmann, ""An Introduction to Computing With Neural nets,""
IEEE ASSP Magazine, p.7, Apr 1987.
N. Farhat et. al .. , ""Optical Implementation of the Hopfield
Model,"" ~. Opt., vol. 24, pp.1469, 1985.
L.E. Atlas, ""Auditory Coding in Higher Centers of the CNS,""
IEEE Eng. in Medicine and Biology Magazine, p.29, Jun 1987.
Y.S. Abu-Mostafa et. al., ""Information Capacity of the Hopfield
Model, "" IEEE Trans. Inf. Theory, vol. IT-31, p.461, 1985.
R.J. McEliece et. al.,""The Capacity of the Hopfield Associative
Memory, "" IEEE Trans.
Inf. Theory (submitted), 1986.
D.E. Rumelhart et. al., Parallel Distributed Prooessing, vol. I
& II, Bradford Books, Cambridge, MA, 1986.
D.E. Rumelhart et. al., ""Learning Representations by Back-Propagation Errors,"" Nature. vol. 323, no. 6088, p.533, 1986.
R.J. Marks II et. al.,""Alternating Projection Neural Networks,""
ISDL report *11587, Nov. 1987 (Submitted for publication) .
D.C. Youla et. al, ""Image Restoration by the Method of Convex
Projections: Part I-Theory,"" IEEE Trans. Med. Imaging, vol.
MI-1, p.81, 1982.
M. I. Sezan and H. Stark. ""Image Restoration by the Method of
Convex Projections: Part II-Applications and Numerical Results,""
IEEE Trans. Med. Imaging, vol. MI-1, p.95, 1985.
M. Minsky et. al., Perceptrons, MIT Press, Cambridge, MA, 1969.
J. Sklansky et. al., Pattern Classifiers and Trainable
Machines, Springer-Verlag, New York, 1981.

"
78,1987,"Learning Representations by Recirculation","",78-learning-representations-by-recirculation.pdf,"Abstract Missing","358

LEARNING REPRESENTATIONS BY RECIRCULATION
Geoffrey E. Hinton
Computer Science and Psychology Departments, University of Toronto,
Toronto M5S lA4, Canada
James L. McClelland
Psychology and Computer Science Departments, Carnegie-Mellon University,
Pittsburgh, PA 15213
ABSTRACT
We describe a new learning procedure for networks that contain groups of nonlinear units arranged in a closed loop. The aim of the learning is to discover codes
that allow the activity vectors in a ""visible"" group to be represented by activity
vectors in a ""hidden"" group. One way to test whether a code is an accurate
representation is to try to reconstruct the visible vector from the hidden vector. The
difference between the original and the reconstructed visible vectors is called the
reconstruction error, and the learning procedure aims to minimize this error. The
learning procedure has two passes. On the fust pass, the original visible vector is
passed around the loop, and on the second pass an average of the original vector and
the reconstructed vector is passed around the loop. The learning procedure changes
each weight by an amount proportional to the product of the ""presynaptic"" activity
and the difference in the post-synaptic activity on the two passes. This procedure is
much simpler to implement than methods like back-propagation. Simulations in
simple networks show that it usually converges rapidly on a good set of codes, and
analysis shows that in certain restricted cases it performs gradient descent in the
squared reconstruction error.
INTRODUCTION
Supervised gradient-descent learning procedures such as back-propagation 1
have been shown to construct interesting internal representations in ""hidden"" units
that are not part of the input or output of a connectionist network. One criticism of
back-propagation is that it requires a teacher to specify the desired output vectors. It
is possible to dispense with the teacher in the case of ""encoder"" networks 2 in which
the desired output vector is identical with the input vector (see Fig. 1). The purpose
of an encoder network is to learn good ""codes"" in the intermediate, hidden units. If
for, example, there are less hidden units than input units, an encoder network will
perform data-compression 3 . It is also possible to introduce other kinds of constraints
on the hidden units, so we can view an encoder network as a way of ensuring that the
input can be reconstructed from the activity in the hidden units whilst also making

nus research was supported by contract NOOOl4-86-K-00167 from the Office of Naval Research
and a grant from the Canadian National Science and Engineering Research Council. Geoffrey Hinton
is a fellow of the Canadian Institute for Advanced Research. We thank: Mike Franzini, Conrad
Galland and Geoffrey Goodhill for helpful discussions and help with the simulations.

? American Institute of Physics 1988

359

the hidden units satisfy some other constraint.
A second criticism of back-propagation is that it is neurally implausible (and
hard to implement in hardware) because it requires all the connections to be used
backwards and it requires the units to use different input-output functions for the
forward and backward passes. Recirculation is designed to overcome this second
criticism in the special case of encoder networks.

output units
I \

hidden units
/

r-.

input units

Fig. 1. A diagram of a three layer encoder network that learns good codes using
back-propagation. On the forward pass, activity flows from the input units in the
bottom layer to the output units in the top layer. On the backward pass, errorderivatives flow from the top layer to the bottom layer.
Instead of using a separate group of units for the input and output we use the
very same group of ""visible"" units, so the input vector is the initial state of this group
and the output vector is the state after information has passed around the loop. The
difference between the activity of a visible unit before and after sending activity
around the loop is the derivative of the squared reconstruction error. So, if the
visible units are linear, we can perfonn gradient descent in the squared error by
changing each of a visible unit's incoming weights by an amount proportional to the
product of this difference and the activity of the hidden unit from which the
connection emanates. So learning the weights from the hidden units to the output
units is simple. The harder problem is to learn the weights on connections coming
into hidden units because there is no direct specification of the desired states of these
units. Back-propagation solves this problem by back-propagating error-derivatives
from the output units to generate error-derivatives for the hidden units.
Recirculation solves the problem in a quite different way that is easier to implement
but much harder to analyse.

360

THE RECIRCULATION PROCEDURE
We introduce the recirculation procedure by considering a very simple
architecture in which there is just one group of hidden units. Each visible unit has a
directed connection to every hidden unit, and each hidden unit has a directed
connection to every visible unit. The total input received by a unit is
Xj = LYiWji - 9j

(1)

i

where Yi is the state of the i th unit, K'ji is the weight on the connection from the i th to
the Jib unit and 9j is the threshold of the Jh unit. The threshold tenn can be
eliminated by giving every unit an extra input connection whose activity level is
fIXed at 1. The weight on this special connection is the negative of the threshold, and
it can be learned in just the same way as the other weights. This method of
implementing thresholds will be assumed throughout the paper.
The functions relating inputs to outputs of visible and hidden units are smooth
monotonic functions with bounded derivatives. For hidden units we use the logistic
function:
y. = <1(x.) =
J

J

I
I +e-Xj

(2)

Other smooth monotonic functions would serve as well. For visible units, our
mathematical analysis focuses on the linear case in which the output equals the total
input, though in simulations we use the logistic function.
We have already given a verbal description of the learning rule for the hiddento-visible connections. The weight, Wij , from the Ih hidden unit to the itlr visible
unit is changed as follows:
f:t.wij = ?y/I) [Yi(O)-Yi(2)]

(3)

where Yi(O) is the state of the i th visible unit at time 0 and Yi(2) is its state at time 2
after activity has passed around the loop once. The rule for the visible-to-hidden
connections is identical:
(4)

where y/I) is the state of the lh hidden unit at time I (on the frrst pass around the
loop) and y/3) is its state at time 3 (on the second pass around the loop). Fig. 2
shows the network exploded in time.
In general, this rule for changing the visible-to-hidden connections does not
perfonn steepest descent in the squared reconstruction error, so it behaves differently
from back-propagation. This raises two issues: Under what conditions does it work,
and under what conditions does it approximate steepest descent?

361

time =3

time = 1

time =2

time =0

Fig. 2. A diagram showing the states of the visible and hidden units exploded in
time. The visible units are at the bottom and the hidden units are at the top. Time
goes from left to right.

CONDITIONS UNDER WHICH RECIRCULATION
APPROXIMATES GRADIENT DESCENT
For the simple architecture shown in Fig. 2, the recirculation learning procedure
changes the visible-to-hidden weights in the direction of steepest descent in the
squared reconstruction error provided the following conditions hold:
1. The visible units are linear.
2. The weights are symmetrical (i.e. wji=wij for all i,j).
3. The visible units have high regression.
""Regression"" means that, after one pass around the loop, instead of setting the
activity of a visible unit, i, to be equal to its current total input, x i (2), as determined
by Eq 1, we set its activity to be
y;(2)

= AY;(O) + (I-A)x;(2)

(5)

where the regression, A, is close to 1. Using high regression ensures that the visible
units only change state slightly so that when the new visible vector is sent around the
loop again on the second pass, it has very similar effects to the first pass. In order to
make the learning rule for the hidden units as similar as possible to the rule for the
visible units, we also use regression in computing the activity of the hidden units on
the second pass
(6)

For a given input vector, the squared reconstruction error, E, is

For a hidden unit, j,

362

where

For a visible-to...hidden weight wj ;
dE,
dE
= Yj(1)Yi(O)-dwj ;
dYj(l)

So, using Eq 7 and the assumption that Wkj=wjk for all k,j
dE

dw??}l

=y/(l) y;(O) [LYk(2) Yk'(2) Wjk k

LYk(O) Yk'(2) Wjk]
k

The assumption that the visible units are linear (with a gradient of 1) means that
for all k, Yk'(2) = 1. So using Eq 1 we have
dE = y.'(l) y.(O)[x.(3)-x~1)]

dw ..

}

I

)

}

(8)

}l

Now, with sufficiently high regression, we can assume that the states of units
only change slightly with time so that

and

Yt(O) ::::: y;(2)

So by substituting in Eq 8 we get
dE
1
-aw::::: (1 _ A) y;(2) [y/3) ji

y/l)]

(9)

An interesting property of Eq 9 is that it does not contain a tenn for the gradient
of the input-output function of unit } so recirculation learning can be applied even
when unit} uses an unknown non-linearity. To do back-propagation it is necessary to
know the gradient of the non-linearity, but recirculation measures the gradient by
measuring the effect of a small difference in input, so the tenn y/3)-y/l) implicitly
contains the gradient.

363

A SIMULATION OF RECIRCULATION
From a biological standpoint, the synunetry requirement that wij=Wji is
unrealistic unless it can be shown that this synunetry of the weights can be learned.
To investigate what would happen if synunetry was not enforced (and if the visible
units used the same non-linearity as the hidden units), we applied the recirculation
learning procedure to a network with 4 visible units and 2 hidden units. The visible
vectors were 1000, 0100, 0010 and 0001, so the 2 hidden units had to learn 4
different codes to represent these four visible vectors. All the weights and biases in
the network were started at small random values uniformly distributed in the range
-0.5 to +0.5. We used regression in the hidden units, even though this is not strictly
necessary, but we ignored the teon 1/ (1 - A) in Eq 9.
Using an E of 20 and a A. of 0.75 for both the visible and the hidden units, the
network learned to produce a reconstruction error of less than 0.1 on every unit in an
average of 48 weight updates (with a maximum of 202 in 100 simulations). Each
weight update was perfonned after trying all four training cases and the change was
the sum of the four changes prescribed by Eq 3 or 4 as appropriate. The final
reconstruction error was measured using a regression of 0, even though high
regression was used during the learning. The learning speed is comparable with
back-propagation, though a precise comparison is hard because the optimal values of
E are different in the two cases. Also, the fact that we ignored the tenn 1/ (1- A.)
when modifying the visible-to-hidden weights means that recirculation tends to
change the visible-to-hidden weights more slowly than the hidden-to-visible weights,
and this would also help back -propagation.
It is not inunediately obvious why the recirculation learning procedure works
when the weights are not constrained to be synunetrical, so we compared the weight
changes prescribed by the recirculation procedure with the weight changes that
would cause steepest descent in the sum squared reconstruction error (i.e. the weight
changes prescribed by back-propagation). As expected, recirculation and backpropagation agree on the weight changes for the hidden-to-visible connections, even
though the gradient of the logistic function is not taken into account in weight
adjustments under recirculation. (Conrad Galland has observed that this agreement
is only slightly affected by using visible units that have the non-linear input-output
function shown in Eq 2 because at any stage of the learning, all the visible units tend
to have similar slopes for their input-output functions, so the non-linearity scales all
the weight changes by approximately the same amount.)
For the visible-to-hidden connections, recirculation initially prescribes weight
changes that are only randomly related to the direction of steepest descent, so these
changes do not help to improve the perfonnance of the system. As the learning
proceeds, however, these changes come to agree with the direction of steepest
descent. The crucial observation is that this agreement occurs after the hidden-tovisible weights have changed in such a way that they are approximately aligned
(symmetrical up to a constant factor) with the visible-to-hidden weights. So it
appears that changing the hidden-to-visible weights in the direction of steepest
descent creates the conditions that are necessary for the recirculation procedure to
cause changes in the visible-to-hidden weights that follow the direction of steepest
descent.
It is not hard to see why this happens if we start with random, zero-mean

364

visible-to-hidden weights. If the visible-to-hidden weight wji is positive, hidden unit
j will tend to have a higher than average activity level when the ith visible unit has a
higher than average activity. So Yj will tend to be higher than average when the
reconstructed value of Yi should be higher than average -- i.e. when the tenn
[Yi(O)-Yi(2)] in Eq 3 is positive. It will also be lower than average when this tenn is
negative. These relationships will be reversed if w ji is negative, so w ij will grow
faster when wJi is positive than it will when wji is negative. Smolensky4 presents a
mathematical analysis that shows why a similar learning procedure creates
symmetrical weights in a purely linear system. Williams 5 also analyses a related
learning rule for linear systems which he calls the ""symmetric error correction""
procedure and he shows that it perfonns principle components analysis. In our
simulations of recirculation, the visible-to-hidden weights become aligned with the
corresponding hidden-to-visible weights, though the hidden-to-visible weights are
generally of larger magnitude.

A PICTURE OF RECIRCULATION
To gain more insight into the conditions under which recirculation learning
produces the appropriate changes in the visible-to-hidden weights, we introduce the
pictorial representation shown in Fig. 3. The initial visible vector, A, is mapped into
the reconstructed vector, C, so the error vector is AC. Using high regression, the
visible vector that is sent around the loop on the second pass is P, where the
difference vector AP is a small fraction of the error vector AC. If the regression is
sufficiently high and all the non-linearities in the system have bounded derivatives
and the weights have bounded magnitudes, the difference vectors AP, BQ, and CR
will be very small and we can assume that, to first order, the system behaves linearly
in these difference vectors. If, for example, we moved P so as to double the length
of AP we would also double the length of BQ and CR.

Fig. 3. A diagram showing some vectors (A, P) over the visible units, their
""hidden"" images (B, Q) over the hidden units, and their ""visible"" images (C, R)
over the visible lUlits. The vectors B' and C' are the hidden and visible images of
A after the visible-to-hidden weights have been changed by the learning procedure.

365

Suppose we change the visible-to-hidden weights in the manner prescribed by
Eq 4, using a very smaIl value of ?. Let Q' be the hidden image of P (i.e. the image
of P in the hidden units) after the weight changes. To first order, Q' will lie between
B and Q on the line BQ. This follows from the observation that Eq 4 has the effect
of moving each y/3) towards y/l) by an amount proportional to their difference.
Since B is close to Q, a weight change that moves the hidden image of P from Q to
Q' will move the hidden image of A from B to B', where B' lies on the extension of
the line BQ as shown in Fig. 3. If the hidden-to-visible weights are not changed, the
visible image of A will move from C to C', where C' lies on the extension of the line
CR as shown in Fig. 3. So the visible-to-hidden weight changes will reduce the
squared reconstruction error provided the vector CR is approximately parallel to the
vector AP.
But why should we expect the vector CR to be aligned with the vector AP? In
general we should not, except when the visible-to-hidden and hidden-to-visible
weights are approximately aligned.
The learning in the hidden-to-visible
connections has a tendency to cause this alignment. In addition, it is easy to modify
the recirculation learning procedure so as to increase the tendency for the learning in
the hidden-to-visible connections to cause alignment. Eq 3 has the effect of moving
the visible image of A closer to A by an amount proportional to the magnitude of the
error vector AC. If we apply the same rule on the next pass around the loop, we
move the visible image of P closer to P by an amount proportional to the magnitude
of PRo If the vector CR is anti-aligned with the vector AP, the magnitude of AC will
exceed the magnitude of PR, so the result of these two movements will be to
improve the alignment between AP and CR. We have not yet tested this modified
procedure through simulations, however.
This is only an infonnal argument and much work remains to be done in
establishing the precise conditions under which the recirculation learning procedure
approximates steepest descent. The infonnal argument applies equally well to
systems that contain longer loops which have several groups of hidden units
arranged in series. At each stage in the loop, the same learning procedure can be
applied, and the weight changes will approximate gradient descent provided the
difference of the two visible vectors that are sent around the loop aligns with the
difference of their images. We have not yet done enough simulations to develop a
clear picture of the conditions under which the changes in the hidden-to-visible
weights produce the required alignment.
USING A HIERARCHY OF CLOSED LOOPS
Instead of using a single loop that contains many hidden layers in series, it is
possible to use a more modular system. Each module consists of one ""visible"" group
and one ""hidden"" group connected in a closed loop, but the visible group for one
module is actually composed of the hidden groups of several lower level modules, as
shown in Fig. 4. Since the same learning rule is used for both visible and hidden
units, there is no problem in applying it to systems in which some units are the
visible units of one module and the hidden units of another. Ballard6 has
experimented with back-propagation in this kind of system, and we have run some
simulations of recirculation using the architecture shown in Fig. 4. The network

366

learned to encode a set of vectors specified over the bottom layer. After learning,
each of the vectors became an attractor and the network was capable of completing a
partial vector, even though this involved passing information through several layers.

00

00

00

0000

0000

Fig 4. A network in which the hidden units of the bottom two modules are the
visible units of the top module.

CONCLUSION
We have described a simple learning procedure that is capable of fonning
representations in non-linear hidden units whose input-output functions have
bounded derivatives. The procedure is easy to implement in hardware, even if the
non-linearity is unknown. Given some strong assumptions, the procedure petforms
gradient descent in the reconstruction error. If the synunetry assumption is violated,
the learning procedure still works because the changes in the hidden-to-visible
weights produce symmetry. H the assumption about the linearity of the visible units
is violated, the procedure still works in the cases we have simulated. For the general
case of a loop with many non-linear stages, we have an informal picture of a
condition that must hold for the procedure to approximate gradient descent, but we
do not have a fonnal analysis, and we do not have sufficient experience with
simulations to give an empirical description of the general conditions under which
the learning procedure works.
REFERENCES
1. D. E. Rumelhart, G. E. Hinton and R.I. Williams, Nature 323, 533-536 (1986).
2. D. H. Ackley, G. E. Hinton and T. 1. Sejnowski, Cognitive Science 9,147-169
(1985).
3. G. Cottrell, 1. L. Elman and D. Zipser, Proc. Cognitive Science Society, Seattle,
WA (1987).
4. P. Smolensky, Technical Report CU-CS-355-87, University of Colorado at
Boulder (1986).
5. R.I. Williams, Technical Report 8501, Institute of Cognitive Science, University
ofCalifomia, San Diego (1985).
6. D. H. Ballard, Proc. American Association for Artificial Intelligence, Seattle, W A
(1987).

"
79,1987,"Learning in Networks of Nondeterministic Adaptive Logic Elements","",79-learning-in-networks-of-nondeterministic-adaptive-logic-elements.pdf,"Abstract Missing","840

LEARNING IN NETWORKS OF
NONDETERMINISTIC ADAPTIVE LOGIC ELEMENTS
Richard C. Windecker*
AT&T Bell Laboratories, Middletown, NJ 07748
ABSTRACT
This paper presents a model of nondeterministic adaptive automata that are
constructed from simpler nondeterministic adaptive information processing
elements. The first half of the paper describes the model. The second half discusses
some of its significant adaptive properties using computer simulation examples.
Chief among these properties is that network aggregates of the model elements can
adapt appropriately when a single reinforcement channel provides the same positive
or negative reinforcement signal to all adaptive elements of the network at the same
This holds for multiple-input, multiple-output, multiple-layered,
time.
combinational and sequential networks. It also holds when some network elements
are ""hidden"" in that their outputs are not directly seen by the external
environment.
INTRODUCTION
There are two primary motivations for studying models of adaptive automata
constructed from simple parts. First, they let us learn things about real biological
systems whose properties are difficult to study directly: We form a hypothesis
about such systems, embody it in a model, and then see if the model has reasonable
learning and behavioral properties. In the present work, the hypothesis being tested
is: that much of an animal's behavior as determined by its nervous system is
intrinsically nondeterministic; that learning consists of incremental changes in the
probabilities governing the animal's behavior; and that this is a consequence of the
animal's nervous system consisting of an aggregate of information processing
elements some of which are individually nondeterministic and adaptive. The second
motivation for studying models of this type is to find ways of building machines
that can learn to do (artificially) intelligent and practical things. This approach has
the potential of complementing the currently more developed approach of
programming intelligence into machines.
We do not assert that there is necessarily a one-to-one correspondence
between real physiological neurons and the postulated model information processing
elements. Thus, the model may be loosely termed a ""neural network model,"" but is
more accurately described as a model of adaptive automata constructed from simple
adaptive parts.

* The main ideas in this paper were conceived and initially developed while the
author was at the University of Chiang Mai, Thailand (1972-73). The ideas were
developed further and put in a form consistent with existing switching and
automata theory during the next four years. For two of those years, the author
was at the University of Guelph, Ontario, supported of National Research
Council of Canada Grant #A6983.

? American Institute of Physics 1988

841

It almost certainly has to be a property of any acceptable model of animal
learning that a single reinforcement channel providing reinforcement to all the
adaptive elements in a network (or subnetwork) can effectively cause that network
to adapt appropriately. Otherwise, methods of providing separate, specific
reinforcement to all adaptive elements in the network must be postulated. Clearly,
the environment reinforces an animal as a whole and the same reinforcement
mechanism can cause the animal to adapt to many types of situation. Thus, the
reinforcement system is non-specific to particular adaptive elements and particular
behaviors. The model presented here has this property.
The model described here is a close cousin to the family of models recently
described by Barto and coworkers 1-4. The most significant difference are: 1) In
the present model, we define the timing discipline for networks of elements more
explicitly and completely. This particular timing discipline makes the present
model consistent with a nondeterministic extension of switching and automata
theory previously described 0. 2) In the present model, the reinforcement algorithm
that adjusts the weights is kept very simple. With this algorithm, positive and
negative reinforcement have symmetric and opposite effects on the weights. This
ensures that the logical signals are symmetric opposites of each other. (Even small
differences in the reinforcement algorithm can make both subtle as well as profound
differences in the behavior of the model.) We also allow, null, or zero,
reinforcemen t.
As in the family of models described by Barto, networks constructed within
the present model can get ""stuck"" at a sUboptimal behavior during learning and
therefore not arrive at the optimal adapted state. The complexity of the Barto
reinforcement algorithm is designed partly to overcome this tendency. In the
present work, we emphasize the use of training strategies when we wish to ensure
that the network arrives at an optimal state. (In nature, it seems likely that getting
""stuck"" at suboptimal behavior is common.) In all networks studied so far, it has
been easy to find strategies that prevent the network from getting stuck.
The chief contributions of the present work are: 1) The establishment of a
close connection between these types of models and ordinary, nonadaptive,
switching and automata theory 0. This makes the wealth of knowledge in this area,
especially network synthesis and analysis methods, readily applicable to the study
of adaptive networks. 2) The experimental demonstration that sequential
(""recurrent"") nondeterministic adaptive networks can adapt appropriately. Such
networks can learn to produce outputs that depend on the recent sequence of past
inputs, not just the current inputs. 3) The demonstration that the use of training
strategies can not only prevent a network from getting stuck, but may also result in
more rapid learning. Thus, such strategies may be able to compensate, or even
more than compensate, for reduced complexity in the model itself.
References 2-4 and 6 provide a comprehensive background and guide to the
literature on both deterministic and nondeterministic adaptive automata including
those constructed from simple parts and those not.
THE MODEL ADAPTIVE ELEMENT
The model adaptive element postulated in this work is a nondeterministic,
adaptive generalization of threshold logic 7. Thus, we call these elements
Nondeterministic Adaptive Threshold-logic gates (NATs). The output chosen by a
NAT at any given time is not a function of its inputs. Rather, it is chosen by a
stochastic process according to certain probabilities. It is these probabilities that
are a function of the inputs.
A NAT is like an ordinary logic gate in that it accepts logical inputs that are
two-valued and produces a logical output that is two-valued. We let these values be

842

+ 1 and -1. A NAT also has a timing input channel and a reinforcement input
channel. The NAT operates on a three-part cycle: 1) Logical input signals are
changed and remain constant. 2) A timing signal is received and the NAT selects a
new output based on the inputs at that moment. The new output remains
constant. 3) A reinforcement signal is received and the weights are incremented
according to certain rules.
Let N be the number of logical input channels, let Xi represent the ith input
signal, and let z be the output. The NAT has within it N+ 1 ""weights,""
wo, WI! ... , WN. The weights are confined to integer values. For a given set of
inputs, the gate calculates the quantity W:

Then the probability that output z =

+ 1 is chosen is:

w _--=-=-

P(z = +1) -

Je

1

.j2;u

-

00

2q2

W/v2q
dx = _1_
..;;

J

e-(l d~

(2)

- 00

where ~ = xjV2u. (An equivalent formulation is to let the NAT generate a
random number, Wq, according to the normal distribution with mean zero and
variance u 2 . Then if W > - Wq, the gate selects the output z = + 1. If
W < - Wq, the gate selects output z = -1. If W = - Wq, the gate selects output
-1 or + 1 with equal probability.)
Reinforcement signals, R, may have one of three values: + 1, -1, and 0
representing positive, negative, and no reinforcement, respectively. If + 1
reinforcement is received, each weight is incremented by one in the direction that
makes the current output, z, more likely to occur in the future when the same
inputs are applied; if -1 reinforcement is received, each weight is incremented in
the direction that makes the current output less likely; if 0 reinforcement is
received, the weights are not changed. These rules may be summarized: ~wo = zR
and ~Wj = xjzR for i > o.
NATs operate in discrete time because if the NAT can choose output + 1 or
-1, depending on a stochastic process, it has to be told when to select a new
output. It cannot ""run freely,"" or it could be constantly changing output. Nor can
it change output only when its inputs change because it may need to select a new
output even when they do not change.
The normal distribution is used for heuristic reasons. If a real neuron (or an
aggregate of neurons) uses a stochastic process to produce nondeterministic
behavior, it is likely that process can be described by the normal distribution. In
any case, the exact relationship between P{z = + 1) and W is not critical. What is
important is that P(z = + 1) be monotonically increasing in W, go to 0 and 1
asymptotically as W goes to - 00 and + 00, respectively, and equal 0.5 at W = O.
The parameter u is adjustable. We use 10 in the computer simulation
experiments described below. Experimentally, values near 10 work reasonably well
for networks of NATs having few inputs. Note that as u goes to zero, the behavior
of a NAT approximates that of an ordinary deterministic ada pt,ive threshold logic
gate with the difference that the output for the case W = 0 is not arbitrary: The
NAT will select output +1 or -1 with equal probability.
Note that for all values of W, the probabilit,ies are greater than zero that
either + 1 or -1 will be chosen, although for large values of W (relative to u) for all

843

practical purposes, the behavior is deterministic. There are many values of the
weights that cause the NAT to approximate the behavior of a deterministic
threshold logic gate. ~or the same reasons that deterministic threshold logic gates
cannot realize all 22 functions of N variables 7, so a NAT cannot learn to
approximate any deterministic function; only the threshold logic functions.
Note also that when the weights are near zero, a NAT adapts most rapidly
when both positive and negative reinforcement are used in approximately equal
amounts. As the NAT becomes more likely to produce the appropriate behavior,
the opportunity to use negative reinforcement decreases while the opportunity to
use positive reinforcement increases. This means that a NAT cannot learn to
(nearly) always select a certain output if negative reinforcement alone is used.
Thus, positive reinforcement has an important role in this model. (In most
deterministic models, positive reinforcement is not useful.)
Note further that there is no hysteresis in NAT learning. For a given
configuration of inputs, a + 1 output followed by a + 1 reinforcement has exactly the
same effect on all the weights as a -1 output followed by a -1 reinforcement. So
the order of such events has no effect on the final values of the weights.
Finally, if only negative reinforcement is applied to a NAT, independent of
output, for a particular combination of inputs, the weights will change in the
direction that makes W tend toward zero and once there, follow a random walk
centered on zero. (The further W is from zero, the more likely its next step will be
toward zero.) If all possible input combinations are applied with more or less equal
probability, all the weights will tend toward zero and then follow random walks
centered on zero. In this case, the NAT will select + 1 or -1 with more or less
equal probability without regard to its inputs.
NETWORKS
NATs may be connected together in networks (NAT-nets). The inputs to a
NAT in such a network can be selected from among: 1) the set of inputs to the
entire network, 2) the set of outputs from other NATs in the network, and 3) its
own output. The outputs of the network may be chosen from among: 1) the inputs
to the network as a whole, and 2) the outputs of the various NATs in the network .
Following Ref. 5, we impose a timing discipline on a NAT-net. The network is
organized into layers such that each NAT belongs to one layer. Letting L be the
number of layers, the network operates as follows: 1) All NATs in a given layer
receive timing signals at the same time and select a new output at the same time.
2) Timing signals are received by the different layers, in sequence, from 1 to L. 3)
Inputs to the network as a whole are levels that may change only before Layer 1
receives its timing signal. Similarly, outputs from the network as a whole are
available to the environment only after Layer L has received its timing signal.
Reinforcement to the network as a whole is accepted only after outputs are made
available to the environment. The same reinforcement signal is distributed to all
NATs in the network at the same time.
With these rules, NAT-nets operate through a sequence of timing cycles. In
each cycle: 1) Network inputs are changed. 2) Layers 1 through L select new
outputs, in sequence. 3) Network outputs are made available to the environment.
4) Reinforcement is received from the environment. We call each such cycle a
""trial"" and a sequence of such trials is a ""session.""
This model is very general. If, for each gate, inputs are selected only from
among the inputs to the network as a whole and from the outputs of gates in layers
preceding it in the timing cycle, then the network is combinational. In this case, the
probability of the network producing a given output configuration is a function of
the inputs at the start of the timing cycle. If at least one NAT has one input from a

844

NAT in the same layer or from a subsequent layer in the timing cycle, then the
network is sequential. In this case, the network may have ""internal states"" that
allow it to remember information from one cycle to the next. Thus, the
probabilities governing its choice of outputs may depend on inputs in previous
cycles. So sequential NAT-nets may have short-term memory embodied in internal
states and long-term memory embodied in the weights. In Ref. 5, we showed that
sequential networks can be constructed by adding feedback paths to combinational
networks and any sequential network can be put in this standard form.
In information-theoretic terms: 1) A NAT-net with no inputs and some
outputs is an ""information source."" 2) A NAT-net with both inputs and outputs is
an information ""channel."" 3) A combinational NAT-net is ""memory-less"" while a
sequential NAT-net has memory. In this context, note that a NAT-net may operate
in an environment that is either deterministic or nondeterministic. Both the logical
and the reinforcement inputs can be selected by stochastic processes. Note also
that nondeterministic and deterministic elements as well as adaptive and
nonadaptive elements can be combined in one network. (It may be that the
decision-making parts of an animal's nervous system are nondeterministic and
adaptive while the information transmitting parts (sensory data-gathering and the
motor output parts) are deterministic and nonadaptive.)
One capability that combinational NAT-nets possess is that of ""pattern
recognizers."" A network having many inputs and one or a few outputs can
""recognize"" a small subset of the potential input patterns by producing a particular
output pattern with high probability when a member of the recognized subset
appears and a different output pattern otherwise. In practice, the number of
possible input patterns may be so large that we cannot present them all for training
purposes and must be content to train the network to recognize one subset by
distinguishing it (with different output pattern) from another subset. In this case,
if a pattern is subsequently presented to the network that has not been in one of
the training sets, the probabilities governing its output may approach one or zero,
but may well be closer to 0.5. The exact values will depend on the details of the
training period. If the new pattern is similar to those in one of the training sets, the
NAT-net will often have a high probability of producing the same output as for that
set. This associative property is the analog of the well known associative property
in deterministic models. If the network lacks sufficient complexity for the
separation we wish to make, then it cannot be trained. For example, a single Ninput NAT cannot be trained to recognize any arbitrary set of input patterns by
selecting the + 1 output when one of them is presented and -1 otherwise. It can
only be trained to make separations that correspond to threshold functions.
A combinational NAT-net can also produce patterns. By analogy with a
pattern recognizer, a NAT-net with none or a few inputs and a larger number of
outputs can learn for each input pattern to produce a particular subset of the
possible output patterns. Since the mapping may be few-to-many, instead of
many-to-few, the goal of training in this case mayor may not be to have the
network approximate deterministic behavior. Clearly, the distinction between
pattern recognizers and pattern prod ucers is somewhat arbitrary: in general, NATnets are pattern transducers that map subsets of input patterns into subsets of
output patterns. A sequential network can ""recognize"" patterns in the timesequence of network inputs and produce patterns in the time-sequence of outputs.
SIMULATION EXPERIMENTS
In this Section, we discuss computer simulation results for three types of
multiple-element networks. For two of these types, certain strategies are used to
train the networks. In general, these strategies have two parts that alternate, as

845

needed. The first part is a general scheme for providing network inputs and
reinforcement that tends to train all elements in the network in the desired
direction. The second part is substituted temporarily when it becomes apparent
that the network is getting stuck in some suboptimal behavior. It is focussed on
getting the network unstuck. The strategies used here are intuitive. In general,
there appear to be many strategies that will lead the network to the desired
behavior. While we have made some attempt to find strategies that are reasonably
efficient, it is very unlikely that the ones used are optimal. Finally, these strategies
have been tested in hundreds of training sessions. Although they worked in all such
sessions, there may be some (depending on the sequence of random numbers
generated) in which they would not work .
In describing the networks simulated, Figs. 1-3, we use the diagramatic
conventions defined in Ref. 5: We put all NATs in the same layer in a vertical line,
with the various layers arranged from left to right in their order in the timing cycle.
Inputs to the entire network corne in from the left; outputs go out to the right.
Because the timing cycle is fixed, we omit the timing inputs in these figures. For
similar reasons, we also omit the reinforcement inputs.
In the simulations described here, the weights in the NATs start at zero
making the network outputs completely random in the sense that on any given
trial, all outputs are equally likely to occur, independent of past or present inputs.
As learning proceeds, some or all the weights become large, so that the NAT-net's
selection of outputs is strongly influenced by some or all of its inputs and internal
connections. (Note that if the weights do not start at zero, they can be driven close
to zero by using negative reinforcement.) In general, the optimum behavior toward
which the network adapts is deterministic. However, because the probabilities are
never identically equal to zero or one, we apply an arbitrary criterion and say that a
NAT-net has learned the appropriate behavior when that criterion is satisfied. In
real biological systems, we cannot know the weights or the exact probabilities
governing the behavior of the individual adaptive elements. Therefore, it is
appropriate to use a criterion based on observable behavior. For example, the
criterion might be that the network selects the correct response (and continues to
receive appropriate reinforcement) 25 times in a row .
Note that NAT-nets can adapt appropriately when the environment is not
deliberately trying to make the them behave in a particular way. For example, the
environment may provide inputs according to some (not necessarily deterministic)
pattern and there may be some independent mechanism that determines whether
the NAT-net is responding appropriately or not and provides the reinforcement
accordingly. One paradigm for this situation is a game in which the NAT-net and
the environment are players. The reinforcement scheme is simple: if, according to
the rules of the game, the NAT-net wins a play (= trial) of the game, reinforcement
is + 1 , if it loses, -1.
For a NAT-net to adapt appropriately in this situation, the game must consist
of a series of similar plays. If the game is competitive, the best strategy a given
player has depends on how much information he has about the opponent and vice
versa. If a player assumes that his opponent is all-knowing, then his best strategy is
to minimize his maximum loss and this often means playing at random, or a least
according to certain probabilities. If a player knows a lot about how his opponent
plays, his best strategy may be to maximize gain. This often means playing
according to some deterministic strategy.
The example networks described here are special cases of three types: pattern
producing (combinational multiple-output) networks, pattern recogmzmg
(combinational multiple-input, multiple-layered, few-output) networks, and game
playing (sequential) networks. The associative properties of NATs and NAT-nets

846

are not emphasized here because they are analogous to the well known associative
properties of other related models.
A Class of Simple Pattern Producing Networks
A simple class of pattern producing
networks consists of the single-layer type
shown in Fig. 1. Each of M NATs in such a
o~- z,
network has no inputs, only an output. As a
consequence, each has only one weight, Woo
Z2
The network is a simple, adaptive, information
source.
O~- ~3
Consider first the case in which the
??
network contains only one NAT and we wish to
train it to always produce a simple ""pattern,""
???
+ 1. We give positive reinforcement when it
selects + 1 and negative reinforcement
Z18
otherwise. If Wo starts at 0, it will quickly
gr.ow large making the probability of selecting
+ 1 approach unity. The criterion we use for
Fig. 1. A Simple Pattern
deciding that the network is trained is that it
Producing Network
produce a string of 25 correct outputs. Table I
shows that in 100 sessions, this one-NAT network selected + 1 output for the next
25 trials starting, on average, at trial 13.
Next consider a network with two NATs. They can produce four different
output patterns. If both weights are 0, they will produce each of the patterns with
equal probability. But they can be trained to produce one pattern (nearly) all the
time. If we wish to train this subnetwork to produce the pattern (in vector
notation) [+1 +1], one strategy is to give no
reinforcement if it produces patterns [-1 +1] or
M Min Ave Max
[+1 -1), give it positive reinforcement if it
1
1
13
26
produces [+1 +1] and negative reinforcement if
2
8
25
43
it produces [-1 -1]. Table I shows that in 100
4
18
35
60
sessions, this network learned to produce the
8
44
70
109
desired pattern (by producing a string of 25
16
215
49
115
correct outputs) in about 25 trials. Because we
initially gave reinforcement only about 50% of
the time, it took longer to train two NATS Table I. Training Times For
than one.
Networks Per Fig. 1.
Next, consider the 16-NAT network in
Fig. 1. Now there are 216 possible patterns the network can produce. When all the
weights are zero, each has probability 2- 16 of being produced. An ineffective
strategy for training this network is to provide positive reinforcement when the
desired pattern is produced, negative reinforcement when its opposite is produced,
and zero reinforcement otherwise. A better strategy is to focus on one output of the
network at a time, training each NAT separately (as above) to have a high
probability of producing the desired output. Once all are trained to a relatively
high level, the network as a whole has a reasonable chance of producing exactly the
correct output. Now we can provide positive reinforcement when it does and no
reinforcement otherwise. With this two-stage hybrid strategy, the network will
soon meet the training criterion. The time it takes to train a network of M
elements with a strategy of this type is roughly proportional to M, not 2(M - 1), as
for the first strategy.

...

0--.'
...
???
?

0--..

?
?

847

A still more efficient strategy is to alternate between a general substrategy
and a substrategy focussed on keeping the network from getting ""stuck ."" One
effective general substrategy is to give positive reinforcement when more than half
of the NATs select the desired output, negative reinforcement when less than half
select the desired output, and no reinforcement when exactly half select the desired
output. This substrategy starts out with approximately equal amounts of positive
and negative reinforcement being applied. Soon, the network selects more than half
of the outputs correctly more and more of the time. Unfortunately, there will tend
to be a minority subset with low probability of selecting the correct output. At this
stage, we must recognize this subset and switch to a substrategy that focuses on the
elements of this subset following the strategy for one or two elements, above. When
all NATs have a sufficiently high probability of selecting the desired output,
training can conclude with the first substrategy.
The strategies used to obtain the results for M = 4,8, and 16 in Table I were
slightly more complicated variants of this two-part strategy. In all of them, a
running average was kept of the number of right responses given by each NAT.
Letting OJ be the ""correct"" output for Zj, the running average after the tt"" trial,
Aj( t), is:
Aj(t) = BAj(t - 1)

+

(3)

CjZj(t)

where B is a fraction generally in the range 0.75 to 0.9. If Aj(t) for a particular i
gets too far below the combined average for all i, then training focuses on the it""
element until its average improves. The significance of the results given in Table I
is not the details of the strategies used, nor how close the training times may be to
the optimum. Rather, it is the demonstration that training strategies exist such
that the training time grows significantly more slowly than in proportion to M.
A Simple Pattern Recognizing Network
As mentioned above, there are fewer
threshold logic functions of N variables (for
N > 1) than the total possible functions.
x, -~))~---......p)oo-- Z
For N = 2, there are 14. The remining two
X2 _-0lil_1:;,._ ___
are the ""exclusive or"" (XOR) and its
complement. Multi-layered networks are
needed to realize these functions, and an Fig. 2. A Two-Element Network
important test of any adaptive network
That Learns XOR
model is its ability to learn XOR. The
network in Fig. 2 is one of the simplest networks capable of learning this function.
Table II gives the results of 100 training sessions with this network. The strategy
used to obtain these
Ave
Max
Min
Function
Network
results again had two
106
57
18
parts. The general part
OR
Fig. 2
1992
681
218
XOR
Fig. 2
consisted of supplying
-700
-3500
-14,300
each of the four possible
XOR
Ref. 2
2232
input patterns to the
XOR
Ref. 8
network
in
rotation,
Table II. Training Times For The
glvmg
appropriate
Network In Fig. 2.
reinforcement each trial.
The second part involved
keeping a running average (similar to Eq. (3)) of the responses of the network by
input combination. When the average for one combination fell significantly behind

?.

848

the average for all, training was focused on just that combination until performance
improved. The criterion used for deciding when training was complete was a
sequence of 50 correct responses (for all input patterns together).
For comparison, Table II shows results for the same network trained to realize
the normal OR function. Also shown for comparison are numbers taken from Refs.
2 and 8 for the equivalent network in those different models. These are
nondeterministic and deterministic models, respectively. The numbers from Ref. 2
are not exactly comparable with the present results for several reasons. These
include: 1) The criterion for judging when the task was learned was not the same;
2) In Ref. 2, the ""wrong"" reinforcement was deliberately applied 10% of the time to
test learning in this situation; 3) Neither model was optimized for the particular
task at hand. Nonetheless, if these (and other) differences were taken into account,
it is likely that the NAT-net would have learned the XOR function significantly
faster.
The significance of the present results is that they suggest that the use of a
training strategy can not only prevent a network from getting stuck, but may also
facilitate more rapid learning. Thus, such strategies can compensate, or more than
compensate, for reduced complexity in the reinforcement algorithm.
A Simple Game-Playing Network
Here, we consider NAT-nets in the context of the game of ""matching
pennies."" In this game, each player has a stack of pennies. At each play of the
game, each player places one of his pennies, heads up or heads down, but covered, in
front of him. Each player uncovers his penny at the same time. If they match,
player A adds both to his stack, otherwise, player B takes both.
Game theory says that the strategy of each player that minimizes his
maximum loss is to play heads and tails at random. Then A cannot predict B's
behavior and at best can win 50% of the time and likewise for B with respect to A.
This is a conservative strategy on the part of each player because each assumes that
the other has (or can derive through a sequence of plays), and can use, information
about the other player's strategy. Here, we make the different assumption that: 1)
Player B does not play at random, 2) Player B has no information about A's
strategy, and 3) Player B is incapable of inferring any information about A through
a sequence of plays and in any event is incapable of changing its strategy. Then, if
A has no information about B's pattern of playing at the start of the game, A's best
course of action is to try to infer a non-random pattern in B's playing through a
sequence of plays and subsequently take advantage of that knowledge to win more
often than 50% of the time. An adaptive NAT-net, as A, can adapt appropriately
in situations of this type. For example, suppose a single NAT of the type in Fig. 1
plays A, where + 1 output means heads, -1 output means tails. A third agent
supplies reinforcement + 1 if the NAT wins a play, -1 otherwise. Suppose B plays
heads with 0.55 probability and tails with 0.45 probability. Then A will learn over
time to play heads 100% of the time and thereby maximize its total winnings by
winning 55% of the time.
A more complicated situation is the following. Suppose B repeats its own
move two plays ago 80% of the time, and plays the opposite 20% of the time. A
NAT-net with the potential to adapt to this strategy and win 80% of the time is
shown in Fig. 3. This is a sequential network shown in the standard form of a
combinational network (in the dotted rectangle) plus a feedback path. The input to
the network at time tis B's play at t - 1. The output is A's move. The top NAT
selects its output at time t based partly on the bottom NAT's output at time
t - 1. The bottom NAT selects its output at t - 1 based on its input at that time
which is B's output at t - 2. Thus, the network as a whole can learn to select its

849

output based on B's play two time increments past. Simulation of 100 sessions
resulted in the network learning to do this
98 times. On average, it took 468 plays
(Min 20, max 4137) to reach the point at
which the network repeated B's move two
H i - - - -.... Z
x----~
times past on the next 50 plays. For two
sessions the network got stuck (for an
unknown number of plays greater than
25,000) playing the opposite of B's last
move or always playing tails. {The first
two-part strategy found that trains the
network to repeat B's output two time
increments past without getting stuck (not
Fig. 3. A Sequential Gamein the game-playing context) took an
Playing Network
average of 260 trials (Min 25, Max 1943) to
meet the training criterion.)
The significance of these results is that a sequential NAT-net can learn to
produce appropriate behavior. Note that hidden NATs contributed to appropriate
behavior for both this network and the one that learned XOR, above.
CONCLUDING REMARKS
The examples above have been kept simple in order to make them readily
understandable. They are not exhaustive in the sense of covering all possible types
of situations in which NAT-nets can adapt appropriately. Nor are they definitive in
the sense of proving generally and in what situations NAT-nets can adapt
appropriately. Rather, they are illustrative in the sense of demonstrating a variety
of significant adaptive abilities. They provide an existence proof that NAT-nets can
adapt appropriately and relatively easily in a wide variety of situations.
The fact that nondeterministic models can learn when the same reinforcement
is applied to all adaptive elements, while deterministic models generally cannot,
supports the hypothesis that animal nervous systems may be (partly)
nondeterministic. Experimental characterization of how animal learning does, or
does not get ""stuck,"" as a function of learning environment or training strategy,
would be a useful test of the ideas presented here.
REFERENCES
1.
2.
3.
4.
5.
6.
7.
8.

Barto, A. G., ""Game-Theoretic Cooperativity in Networks of Self-Interested
Units,"" pp. 41-46 in Neural Networks for Computing, J. S. Denker, Ed., AlP
Conference Proceedings 151, American Institute of Physics, New York, 1986.
Barto, A. G., Human Neurobiology, 4, 229-256, 1985.
Barto, A. G., R. S. Sutton, and C. W. Anderson, IEEE Transactions on
Systems, Man, and Cybernetics, SMC-13, No.5, 834-846, 1983.
Barto, A. G., and P. Anandan, IEEE Transactions on Systems, Man, and
Cybernetics, SMC-15, No.3, 360-375, 1985.
Windecker, R. C., Information Sciences, 16, 185-234 (1978).
Rumelhart, D. E., and J. L. McClelland, Parallel Distributed Processing, MIT
Press, Cambridge, 1986.
Muroga, S., Threshold Logic And Its Applications, Wiley-Interscience, New
York, 1971.
Rumelhart, D. E., G. E. Hinton, and R. J. Williams, Chapter 8 in Ref. 6.

"
80,1987,"Stochastic Learning Networks and their Electronic Implementation","",80-stochastic-learning-networks-and-their-electronic-implementation.pdf,"Abstract Missing","9

Stochastic Learning Networks and their Electronic Implementation
Joshua Alspector*. Robert B. Allen. Victor Hut. and Srinagesh Satyanarayanat
Bell Communications Research. Morristown. NJ 01960
We describe a family of learning algorithms that operate on a recurrent, symmetrically
connected. neuromorphic network that. like the Boltzmann machine, settles in the
presence of noise. These networks learn by modifying synaptic connection strengths on
the basis of correlations seen locally by each synapse. We describe a version of the
supervised learning algorithm for a network with analog activation functions. We also
demonstrate unsupervised competitive learning with this approach. where weight
saturation and decay play an important role. and describe preliminary experiments in
reinforcement learning. where noise is used in the search procedure. We identify the
above described phenomena as elements that can unify learning techniques at a physical
microscopic level.
These algorithms were chosen for ease of implementation in vlsi. We have designed a
CMOS test chip in 2 micron rules that can speed up the learning about a millionfold
over an equivalent simulation on a VAX lln80. The speedup is due to parallel analog
computation for snmming and multiplying weights and activations. and the use of
physical processes for generating random noise. The components of the test chip are a
noise amplifier. a neuron amplifier. and a 300 transistor adaptive synapse. each of which
is separately testable. These components are also integrated into a 6 neuron and 15
synapse network. Finally. we point out techniques for reducing the area of the
electronic correlational synapse both in technology and design and show how the
algorithms we study can be implemented naturally in electronic systems.
1. INTRODUCTION

Ibere has been significant progress. in recent years. in modeling brain function as the collective
behavior of highly interconnected networks of simple model neurons. This paper focuses on the
issue of learning in these networks especially with regard to their implementation in an electronic
system. Learning phenomena that have been studied include associative memoryllJ. supervised
leaming by error correction(2) and by stochastic search(3). competitive learning(4 ) lS) reinforcement
leamingI6 ). and other forms of unsupervised leaming(7). From the point of view of neural
plausibility as well as electronic implementation. we particularly like learning algorithms that
change synaptic connection strengths asynchronously and are based only on information
available locally at the synapse. This is illustrated in Fig. 1. where a model synapse uses only the
correlations of the neurons it connects and perhaps some weak global evaluation signal not
specific to individual neurons to decide how to adjust its conductance.

?

t

Address for correspondence: J. Alspector, BeU Communications ReselllCh, 2E-378, 435 South St., Morristown, Nl
07960 / (201) 8294342/ josh@beUcore.com
Pennanent address: University of California, Belkeley, EE Department, Cory HaU, Belkeley, CA 94720

* PennllDeDt address: Columbia University, EE Department, S.W. Mudd Bldg., New Yolk, NY 10027
@ American Institute of Physics 1988

10

S,
I

C.=<s
'1

i

's

j

>

S,

J

<r>

Hebb-type learning rule:
If

global scalar
evaluation
signal

C ij Increases,
(perhaps in the presence of r )
Increment W ij

Fig. 1. A local correlational synapse.
We believe that a stochastic search procedure is most compatible with this viewpoint. Statistical
procedures based on noise form the communication pathways by which global optimization can
take place based only on the interaction of neurons. Search is a necessary part of any learning
procedure as the network attempts to find a connection strength matrix that solves a particular
problem. Some learning procedures attack the search directly by gradient following through error
(orrection[8J (9J but electronic implementation requires specifying which neurons are input,
tudden and output in advanC'e and nece!;sitates global control of the error correction[2J procedure
m a way that requires specific connectivity and ~ynch!'Ony at the neural Jevel. There is also the
question of how such procedures would work with unsupervised methods and whether they might
get stuck in local minima. Stochastic processes can also do gradient foUowing but they are better
at avoiding minima, are compatible with asynchronous updates and local weight adjustments,
and, as we show in this paper, can generalize well to less supervifM!d learning.
The phenomena we studied are 1) analog activation, 2) noise, 3) semi-local Hebbian synaptic
modification, and 4) weight decay and saturation. These techniques were applied to problems in
supervised, unsupervised, and reinforcement learning. The goal of the study was to see if these
diverse learning styles can be unified at the microscopic level with a small set of physically
plausible and electronically implementable phenomena. The hope is to point the way for
powerful electronic learning systems in the future by elucidating the conditions and the types of
circuits that may be necessary. It may also be true that the conditions for electronic learning may

11

have some bearing on the general principles of biologicalleaming.
2. WCAL LEAltNlNG AND STOCHASl'IC SEARCH
2.1 Supervised Learning in Recurrent Networks with Analog Activations

We have previously shown! 10] how the supervised learning procedure of the Boltzmann
machine(3) can be implemented in an electronic system. This system works on a recurrent,
symmetrically connected network which can be characterized as settling to a minimum in its
Liapunov function(l]!II). While this architecture may stretch our criterion of neural plausibility, it
does provide for stability and analyzability. The feedback connectivity provides a way for a
supervised learning procedure to propagate information back through the network as the
stochastic search proceeds. More plausible would be a randomly connected network where
symmetry is a statistical approximation and inhibition damps oscillations, but symmetry is more
efficient and weD matched to our choice of learning rule and search procedure.
We have extended our electronic model of the Boltzmann machine to include analog activations.
Fig. 2 shows the model of the neuron we used and its tanh or sigmoid transfer function. The net
input consists of the usual weighted sum of activations from other neurons but, in the case of
Boltzmann machine learning, these are added to a noise signal chosen from a variety of
distributions so that the neuron performs the physical computation:
activation =1 (neti FI (EwijSj+noise ):::tanh(gain*neti)

Instead of counting the number of on-on and off-off cooccurrences of neurons which a synapse
connects, the correlation rule now defines the value of a cooccurrence as:
Cij=/i*/i

where Ii is the activation of neuron i which is a real value from -1 to 1. Note that this rule
effectively counts both on-on and off-off cooccurrences in the high gain limit. In this limit, for
Gaussian noise, the cumulative probability distribution for the neuron to have activation +1 (on)
is close to sigmoidal. The effect of noise ""jitter"" is illustrated at the bottom of the figure. The
weight change rule is still:
if Cij+ > Cij- then increment Wij .... else decrement

where the plus phase clamps the output neurons in their desired states while the minus phase
allows them to run free.
As? mentioned, we have studied a variety of noise distributions other than those based on the
Boltzmann distribution. The 2-2-1 XOR problem was selected as a test case since it has been
shown! 10] to be easily caught in local minima. The gain was manipulated in conditions with no
noise or with noise sampled from one of three distributions. The Gaussian distribution is closest
to true electronic thermal noise such as used in our implementation, but we also considered a
cut-off uniform distribution and a Cauchy distribution with long noise tails for comparison. The
inset to Fig. 3 shows a histogram of samples from the noise distributions used. The noise was
multiplied by the temperature to 'jitter' the transfer function. Hence. the jitter decreased as the
annealing schedule proceeded.

12

1;.

Vnol se
1;.

f.(r.

J

I

W II

II

vout or
+ noise)

1;.

Vln+

or r.

1;.

Vnol sl

WIJI J

+ noise = ne~

high IIIln
tr8nl'.. function
wUh noll. 'line""

Fig. 2. Electronic analog neuron.
Fig. 3 shows average performance across 100 runs for the last 100 patterns of 2000 training
pattern presentations. It can be seen that reducing the gain from a sharp step can improve
learning in a small region of gain, even without noise. There seems to be an optimal gain level.
However, the addition of noise for any distribution can substantially improve learning at all levels
of gain.
1
~

-----

-

~

0.9

Gaussian
Unifona
Cauchy
HO Hoise

tlCLI
~

u~
c

0.8

0

......-, .'.' ....u __. . . , ..

.,.j

~
~

8.0

0.7

&:
0.6-

...

0.5

10

-3

.,
10

-2

-1

10
Inverse Gain

Fig. 3. Proportion correct vs. inverse gain.

1

10

1

13

2.2 Stochastic Competitive Learning

We have studied how competitive leaming(4J[~) can be accomplished with stochastic local units.
Mter the presentation of the input pattern. the network is annealed and the weight is increased
between the winning cluster unit and the input units which are on. As shown in Fig. 4 this
approach was applied to the dipole problem of Rumelhart and Zipser. A 4x4 pixel array input
layer connects to a 2 unit competitive layer with recurrent inhibitory connections that are not
adjusted. The inhibitory connections provide the competition by means of a winner-lake-all
process as the network settles. The input patterns are dipoles - only two input units are turned
OIl at each pattern presentatiOll and they must be physically adjacent. either vertically or
horizontally. In this way, the network learns about the connectedness of the space and eventually
divides it into two equal spatial regions with each of the cluster units responding only to dipoles
from one of the halves. Rumelhart and Zipser renormalized the weights after each pattern and
picked the winning unit as the one with the highest activation. Instead of explicit nonnalization
of the weights. we include a decay term proportional to the weight. The weights between the
input layer and cluster layer are incremented for on-on correlations, but here there are no
alternating phases so that even this gross synchrony is not necessary. Indeed. if small time
constants are introduced to the weight updates. no external timing should be needed.

winner-lake-all
cluster layer

input/ayer

Pig. 4. Competitive learning network for the dipole problem.
Fig. S shows the results of several runs. A 1 at the po~ition of an input unit means that unit 1 of
the cluster layer has the larger weight leading to it from that position. A + between two units
means the dipole from these two units excites unit 1. A 0 and - means that unit 0 is the winner in
the complementary case. Note that adjacent l's should always have a + between them since both
weights to unit 1 are stronger. H, however, there is a 1 next to a 0, then there is a tension in the
dipole and a competition for dominance in the cluster layer. We define a figure of merit called
""surface tension"" which is the number of such dipoles in dispute. The smaller the number, the

14

better. Note in Runs A and B, the number is reduced to 4, the minimum possible value, after
2000 pattern presentations. The space is divided vertically and horizontally, respectively. Run C
bas adopted a less favorable diagonal division with a surface tension of 6.

Number of dipole pattern presentations
2000

1400

0

200

800

0-0-0-0

1+0-0+1
+ + + +
1+1+1+1
+ +
1+1-0-0
+
0-0-0-0

1+1+1+1
+ + +
1+1+1-0
+ +
1-0-0-0

1+1+1+1
+ + + +
1+1+1+1
+ - + 0-0-0-0

1+1+1+1
+ + + +
1+1+1+1
- +
0-0-0-0

0-0-0-0

0-0-0-0

0-0-0-0

0-0-0+1
+ +
0-0-1+1
- + +
0-0-1+1
- + +
0-0+1+1

-0-0-1+1
-- +
- + +
-0-0-1+1

0-0-0-1

-++
-0-0-1+1
- + +
-0-0-1+1
--++
0-0+1+1

0-0-0-0

RUn A
0-0-0-0
0-0-0-0
0-0-0-0

---

0-0-0-0

0-0-0-0

-0-0-0+1
--+
-1-0-1+1
--+

0-0-0-0

+ - + +
1+0+1+1

0-0-0-0

Run B

0-0-0-0
0-0-0-0

Run C
0-0-0-0
0- 0-0-0

-

--

-

-

-

- -

+ +
0-0+1+1

-+++
0-1+1+1
-++ +

0+1+1+1
+ + +
0+1+1+1
+ + +
0-0-0-0

-

1+1+1+1
+ + + +
0+1+1+1
+ +
0-0-0-0

0-0-0-0

0-0-0-0

0-0-0-0

0+1+1+1

0-1+1+1

-

--

-

-

0-0-1+1

1+1+1+1
+ + +
0-0+1+1
+ +
0-0-0-1
- - +
0-0-0-1

-

--

Fig. 5. Results of competitive learning runs on the dipole problem.
Table 1 sbows the result of several competitive algorithms compared when averaged over 100
such runs. The deterministic algorithm of Rumelhart and Zipser gives an average surface tension
of 4.6 while the stochastic procedure is almost as good. Note that noise is essential in belping the
competitive layer settle. Without noise the surface tension is 9.8, sbowing that the winner-takeall procedure is not working properly.

Competitive learning algorithm

""surface tension""

Stochastic net with decay
- anneal: T=3H T=1.0
- no anneal: 70 @ T=1.0

4.8

Stochastic net with renonnallzation

5.6

Deterministic, winner-take-all
(Rumelhart & Zipser)

4.6

9.8

Table 1. Performance of competitive learning algorithms across 1()() runs.
We also tried a procedure where, instead of decay, weights were renormalized. The model is that
each neuron can support a maximum amount of weight leading into it. Biologically, this might
be the area that other neurons can form synapses on, so that one synapse cannot increase its
strength except at the expense of some of the others. Electronically, this can be implemented as

15

current emanating from a fixed clUTent source per neuron. As shown in Table 1, this works
nearly as well as decay. Moreover, preliminary results show that renormalization is especiaUy
effective when more then two cluster units are employed.
Both of the stochastic algorithms, which can be implemented in an electronic synapse in nearly
the same way as the supervised learning algorithm, divide the space just as the deterministic
normalization procedure14J does. This suggests that our chip can do both styles of learning,
supervised if one includes both phases and unsupervised if only the procedure of the minus phase
is used.
1.3 Reiolorcelfteot Learning

We have tried several approaches to reinforcement learning using the synaptic model of Fig. 1
where the evaluation signal is a scalar value available globally that represents how well the
system performed on each trial. We applied this model to an xor problem with only one output
unit. The reinforcement was r = 1 for the correct output and r = -1 otherwise. To the network,
this was similar to supervised learning since for a single unit, the output state is fully specified by
a scalar value. A major difference, however, is that we do not clamp the output unit in the
desired state in order to compare plus and minus phases. This feature of supervised learning has
the effect of adjusting weights to follow a gradient to the desired state. In the reinforcement
learning described here, there is no plus phase. This has a satisfying aspect in that no overall
synchrony is necessary to compare phases, but is also much slower at converging to a solution
because the network has to search the solution space without the guidance of a teacher clamping
the output units. This situation becomes much worse when there is more than one output unit. In
that case, the probability of reinforcement goes down exponentially with the number of outputs.
To test multiple outputs, we chose the simple replication problem whereby the output simply has
to replicate the input. We chose the number of bidden units equal to the input (or output).
10 the absence of a teacher to clamp the outputs, the network has to find the answer by chance,
guided only by a ""critic"" which rates its effort as ""better"" or ""worse"". This means the units must
somehow search the space. We use the same stochastic units as in the supervised or unsupervised
techniques, but now it is important to have the noise or the annealing temperature set to a proper
level. If it is too high, the reinforcement received is random rather than directed by the weights
in the network. If it is too low, the available states searched become too smaU and the probability
of finding the right solution decreases. We tuned our annealing schedule by looking at a
volatility measure defined at each neuron which is simply the fraction of the time the neuron
activation is above zero. We then adjust the final anneal temperature so that this number is
neither 0 or 1 (noise too low) nor 0.5 (noise too high). We used both a fixed annealing schedule
for all neurons and a unit-specific schedule where the noise was proportional to the sum of weight
magnitudes into the unit. A characteristic of reinforcement learning is that the percent correct
initially increases but then decreases and often oscillates widely. To avoid this, we added a factor
of (I - <r ? multiplying the final temperature. This helped to stabilize the learning.

In keeping with our simple model of the synapse, we chose a weight adjustment technique that
consisted of correlating the states of the connected neurons with the global reinforcement signal.
Each synapse measured the quantity R =rs;sj for each pattern presented. If R >0, then ~';j is
incremented and it is decremented if R <0. We later refined this procedure by insisting that the
reinforcement be greater than a recent average so that R =(r-<,. > hi Sj. This type of procedure

16

appears in previous work in a number of fonns.(12] (13) For r =?l only, this ""excess
reinforcement"" is the same as our previous algorithm but differs if we make a comparison
between short term and long tenn averages or use a graded reinforcement such as the negative of
the sum squared error. Following a suggestion by G. Hinton, we also investigated a more
complex technique whereby each synapse must store a time average of three quantities: <r>,
<SiSj>, and <rsiSj>. The definition now is R =<rsiSj>-<r><SjSj> and the rule is the same as
before. Statistically, this is the same as ""excess reinforcement"" if the latter is averaged over
trials. For the results reported below the values were collected across 10 pattern presentations. A
variation. which employed a continuous moving average, gave similar results.
Table 2 summarizes the perfonnance on the xor and the replication task of these reinforcement
learning techniques. As the table shows a variety of increasingly sophisticated weight adjustment
rules were explored; nevertheless we were unable to obtain good results with the techniques
described for more than S output units. In the third column, a small threshold had to be exceeded
prior to weight adjustment. In the fourth column, unit-specific temperatures dependent on the
sum of weights, were employed. The last column in the table refers to frequency dependent
learning where we trained on a single pattern until the network produced a correct answer and
then moved on to another pattern. This final procedure is one of several possible techniques
related to 'shaping' in operant learning theory in which difficult patterns are presented more often
to the network.
network
xor
24-1
2-2-1

-

eplication
2-2-2
3-3-3
444

S-S-S
6-6-6

t=1

time-averaged

+?=0.1

+T-I:W

+freq

(0.60) 0.64
(0.58) 0.57

(0.70) 0.88
(0.69) 0.74

(0.76) 0.88
(0.96) 1.00

(0.92)0.99
(0.85) 1.00

(0.98) 1.00
(0.78) 0.88

(0.94)0.94
(0.15) 0.21

(0.46) 0.46
(0.31) 0.33

(0.91) 0.97
(0.31) 0.62

(0.87) 0.99
(0.37)0.37

(0.97) 1.00
(0.97) 1.00
(0.75) 1.00
(0.13) 0.87
(0.02) 0.03

-

-

-

-

-

-

-

Table 2. Proportion correct performance of reinforcement learning
after (2K) and 10K patterns.
Our experiments. while incomplete, hint that reinforcement learning can also be implemented by
the same type of local-global synapse that characterize the other learning paradigms. Noise is
also necessary here for the random search procedure.

2... Sanunary of Study of hDdameatai Learning Par...eters
In summary, we see that the use of noise and our model of a local correlational synapse with a
DOn-specific global evaluation signal are two important features in all the learning paradigms.
Graded activation is somewhat less important. Weight decay seems to be quite important
although saturation can substitute for it in unsupervised learning. Most interesting from our point
of view is that all these phenomena are electronically implementable and therefore physically

17

plausible. Hopefully this means they are also related to true neural phenomena and therefore
provide a basis for unifying the various approaches of learning at a microscopic level.
3. ELECTRONIC IMPLEMENTATION
3.1 The Supervised LearDiog Chip
We have completed the design of the chip previously proposed.(IO] Its physical style of
computation speeds up learning a millionfold over a computer simulation. Fig. 6 shows a block
diagram of the neuron. It is a double differential amplifier. One branch forms a sum of the inputs
from the differential outputs of aU other neurons with connections to it. The other adds noise
from the noise amplifier. This first stage has low gain to preserve dynamic range at the summing
nodes. The second stage has high gain and converts to a single ended output. This is fed to a
switching arrangement whereby either this output state or some externally applied desired state is
fed into the final set of inverter stages which provide for more gain and guaranteed digital
complementarity .

Sdlslrld

Fig. 6. Block diagram of neuron.
The noise amplifier is shown schematically in Fig. 7. Thermal noise, with an nns level of tens of
microvolts, from the channel of an FET is fed into a 3 stage amplifier. Each stage provides a
potential gain of 100 over the noise bandwidth. Low pass feedback in each stage stabilizes the
DC output as well as controls gain and bandwidth by means of an externally controlled variable
resistance for tuning the annealing cycle.
Fig. 8 shows a block diagram of the synapse. The weight is stored in 5 flip-flops as a sign and
magnitude binary number. These flip-flops control the conductance from the outputs of neuron i
to the inputs of neuron j and vice-versa as shown in the figure. The conductance of the FETs are
in the ratio 1:2:4:8 to correspond to the value of the binary number while the sign bit determines
whether the true or complementary lines connect. The flip-flops are arranged in a counter which
is controUed by the correlation logic. If the plus phase correlations are greater than the minus
phase, then the counter is incremented by a single unit If less, it is decremented.

18

Vcontrol

I

I

l

I
>--.._V._.nOISI

Fig. 7. Block diagram of noise amplifier.

Sj

or

I

Sj

or

I

nior~
"" T---~'-~__~--~
up.

.r----...
correlation

""ncrement

logic

sgn

down.
o
& set
i------lhnl
logic

WI)

or

JI

2
phase

3

Fig. 8. Block diagram of synapse.
Fig. 9 sbows the layout of a test chip. A 6 neuron, 15 synapse network may be seen in the lower
left comer. Eacb neuron bas attacbed to it a noise amplifier to assure that the noise is
uncorrelated. The network occupies an area about 2.5 mm on a side in 2 micron design rules.
Eacb 300 transistor synapse occupies 400 by 600 microns. In contrast, a biological synapse
occupies only about one square micron. The real miracle of biological learning is in the synapse
wbere plasticity operates on a molecular level, not in the neuron. We can't bope to compete using
transistors, bowevc:r small, especially in the digital domain. Aside from this small network, the
rest of the chip is occupied with test structures of the various components.
3.1 Analog Synapse

Analog circuit tecbni~ues can reduce the size of the synapse and increase its functionality.
Several recent papers( 4] II~I have shown how to make a voltage controlled resistor in MOS
technology. The voltage controlling the conductance representing the synaptic weight can be
obtained by an analog charge integrator from the correlated activation of the neurons which the
synapse in question connects. A charge integrator with a ""leaky capacitor"" bas a time constant

19

which can be used to make comparisons as a continuous time average over the last several trials.
thereby' adding temporal information. One can envision this time constant as being adaptive as
well. The charge integrator directly implements the analog Hebb-typel 16] correlation rules of
section 2.

~.~ ~,~~~' ~ .. ~i~ 'i~ ~ ~~ilf'~~
.'
?

~.,

??
' /., ~ ""'"" )A , ..?'<""""~
:~"";"" ..
? ./ . '
. \ ' :"": :"" . _ .

??????????
*??
:i .
c?.. ..?

~.*

If. ., ? iii ? -

I I .?

~ii.:' ...

??.???? ???????????

., ? ? ? ?

'

~

.

_ ?

??

. .. . . .

~.~

It ill ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?

~.I ':;;::dU:;.;;;.UEEi
......... .
? 1!~'.'

-Jot- :

~ II.

~ ~"" ,

i nr-':,~""?"""";??;.

:i ii r. ? . '. ,:
:-""fO.,a'l.~""~;""

.......
..?.?.....
...?',......
.....
. . . . ..
.? ??"".?
? . ' ;~-.

...:t~""1I ?

???

,;.:""

1IIi1.

~.... ...... ,? ?~I'

! : '.

.. ,.... "" ~
.
:i ..................

JjI!

II~.~

'

' :"" :::'.l-

,.;,:,...

s ?Ii,?iI'. .
?

?
.. .......
:::, ':.

Fig. 9. Chip layout.
3.3 Tecbnologicalbnprovemeots for Flectronic Neural Networks
It is still necessary to store the voltage which controls the analog conductance and we propose the
EPROMll7] or EEPROM device for this. Such a device can hold the value of the weight in the
same way that flip-flops do in the digital implementation of the synapse(lOJ. The process which

creates this device has two polysilicon layers which are useful for making high valued
capacitances in analog circuitry. In addition. the second polysilicon layer could be used to make
CCD devices for charge storage and transport. Coupled with the charge storage on a floating
gate(l8], this forms a compact. low power representation for weight values that apyroach
biological values. Another useful addition would be a high valued stable resistive layerl l9 . One

20

could thereby avoid space-wasting long-channel MOSFETs which are currently the only
rea~ble way to achieve high resistance in MOS technology. Lastly, the addition of a diffusion
step or two creates a Bi-CMOS process which adds high quality bipolar transistors useful in
analog design. Furthermore, one gets the logarithmic dependence of voltage on current in bipolar
technology in a natural, robust way, that is not subject to the variations inherent in using
MOSFETs in the subthreshold region. This is especially useful in compressing the dynamic
range in sensory processing[20J?
4. CONCLUSION

We have shown how a simple adaptive synapse which measures correlations can account for a
variety of learning styles in stochastic networks. By embellishing the standard CMOS process
and using analog design techniques. a technology suitable for implementing such a synapse
electronically can be developed. Noise is an important element in our formulation of learning. It
can help a network settle, interpolate between discrete values of conductance during learning. and
search a large solution space. Weight decay (""forgetting"") and saturation are also important for
stability. These phenomena not only unify diverse learning styles but are electronically
implementabfe.

ACKNOWLEDGMENT:

This work has been influenced by many researchers. We would especially like to thank Andy
Barto and Geoffrey Hinton for valuable discussions on reinforcement learning, Yannis Tsividis
for contributing many ideas in analog circuit design, and Joel Gannett for timely releases of his
vlsi verification software.

21

References
1. JJ. Hopfield, ""Neural netwolks and physical systems with emergent coUective computational abilities"", Proc. Natl.
Acad. Sci. USA 79,2554-2558 (1982).

2. D.E. Rumelhart, G.E. Hinton, and RJ. Williams, ""Learning internal representations by error propagation"", in
Paralld Distribuled Processing: Explorations in th~ Microstructur~ of Cognition. Vol. 1: Foundations. edited by
D.E. Rumelhart and J.L. McClelland, (MrT Press, Cambridge, MA, 1986), p. 318.

3. D.H. Ackley, G.E. Hinton, and T J. Sejnowski, ""A learning algorithm for Boltzmann machines"", Cognitive Science
9, 147-169 (1985).

4. D.E. Rumelhart and D. apser, ''Feature dillCovery by competitive learning"", Cognitive Science 9, 75-112 (1985).
5. s. Grossberg, ""Adaptive pattern classification and universal recoding: Part L Parallel development and coding of
neural feature detectors."", Biological Cybernetics 23, 121-134 (1976).

6. A.G. Barto, R.S. Sutton, and C.W. Anderson, ""Neuronlike adaptive elements that can solve difficult learning
control problems"",1EEE Trans. Sys. Man Cyber. 13,835 (1983).

7. B.A. Pearlmutter and G.E. Hinton, ""G-Maximization: An unsupervised learning procedure for discovering
regularities"", in N~ural Networks for Computing. edited by J.S. Denker, AIP Conference Proceedings 151,
American Inst. of Physics, New Yolk (1986), p.333.

8. F. Rosenblatt, Principirs of Neurodyrramics:

Perc~ptrons

and the Th~ory of Brain Mechanisms (Spartan Books,

Washington, D.C., 1961).

9. G. Widrowand M.E. Hoff, ""Adaptive switching cirt:uits"", Inst. of Radio Engineers, Western Electric Show and
Convention. COftycntion Record, Part 4, ~104 (1960).

10. J. Alspeaor and R.B. Allen, ""A neuromorphic vlsi learning system"". in M~'aN:rd Rrs~arch in VLSl: Procudings
ofth~

1987 StQ1lfordConf~rtnu. edited by P. Losleben (MIT Press, Cambridge, MA.1987), pp. 313-349.

11. M.A. Cohen and S. Grossberg, ""Absolute stability of global pattern formation and parallel memory storage by
competitive neural networks"", Trans. IEEE 13,815, (1983).

12. B. Widrow. N.K. Gupta, and S. Maitra, ""Punish,IReward: Learning with a critic in adaptive threshold systems"",
IEEE Trans. on Sys. Man & Cyber., SMC-3, 455 (1973).

13. R.S. Sutton, ""Temporal credit assignment in reinforcement learning"", unpublished doctoral dissertation, U. Mass.
Amherst, technical report COINS 84-02 (1984).

]4. Z. Czamul,

""Design of voltage-controlled linear ttansconductance elements with a muched pair of FET
transistors"", IEEE Trans. Cire. Sys. 33, 1012, (1986).

15. M. Banu and Y. Tsividis, ""Flouing voltage-controUed resistors in CMOS technology"", Electron. Lett. 18,678-679
(1982).

16. D.O. Hebb, Th~ OrganizotiOlf ofBtMV;oT (Wiley, NY, 19(9).

17. D. Frohman-Bentchkowsky. HFAMOS - ?

new semiconductor charge storage device"", Solid-State Electronics 17,

517 (1974).

18. J.P. Sage, K.. Thompson, and R.S. Withers, ""An artificial neural network integrued circuit based on MNOS/CCD
principles"", in Nrural Networks for Computing. edited by J.S. Denker. AIP Conference Proceedings 151,
American lost. of Physics, New York (1986), p.38 1.

19. A.P. ThaJcoor, J.L. Lamb. A. Moopenn, and J. Lambe, ""Binary synaptic connections ba!ICd on memory switching
in a-Si:H"". in Neural N~""""""orks for Computing. edited by J.S. Denker, AIP Conference Proceedings 151. American

Inst. of Physics, New York (1986), p.426.

20. M.A. Sivilotti, M.A. Mahowald, and C.A. Mead, ~ReaJ-Time visual computations using analog CMOS processing
arrays"", in Advanud R~S('arch in VLSl: Prou~dings of thr 1987 Stanford
(MIT Press, Cambridge, MA, 1987), pp. 295-312.

Corrf~r~nu.

edited by P. Losleben

"
81,1987,"Invariant Object Recognition Using a Distributed Associative Memory","",81-invariant-object-recognition-using-a-distributed-associative-memory.pdf,"Abstract Missing","830

Invariant Object Recognition Using a Distributed Associative Memory
Harry Wechsler and George Lee Zimmerman
Department or Electrical Engineering
University or Minnesota
Minneapolis, MN 55455

Abstract
This paper describes an approach to 2-dimensional object recognition. Complex-log conformal mapping is combined with a distributed associative memory to create a system
which recognizes objects regardless of changes in rotation or scale. Recalled information
from the memorized database is used to classify an object, reconstruct the memorized version of the object, and estimate the magnitude of changes in scale or rotation. The system
response is resistant to moderate amounts of noise and occlusion. Several experiments, using real, gray scale images, are presented to show the feasibility of our approach.
Introduction
The challenge of the visual recognition problem stems from the fact that the projection of an object onto an image can be confounded by several dimensions of variability
such as uncertain perspective, changing orientation and scale, sensor noise, occlusion, and
non-uniform illumination. A vision system must not only be able to sense the identity of an
object despite this variability, but must also be able to characterize such variability -- because the variability inherently carries much of the valuable information about the world.
Our goal is to derive the functional characteristics of image representations suitable for invariant recognition using a distributed associative memory. The main question is that of
finding appropriate transformations such that interactions between the internal structure
of the resulting representations and the distributed associative memory yield invariant
recognition. As Simon [1] points out, all mathematical derivation can be viewed simply as
a change of representation, making evident what was previously true but obscure. This
view can be extended to all problem solving. Solving a problem then means transforming it
so as to make the solution transparent .
We approach the problem of object recognition with three requirements:
classification, reconstruction, and characterization. Classification implies the ability to distinguish objects that were previously encountered. Reconstruction is the process by which
memorized images can be drawn from memory given a distorted version exists at the input. Characterization involves extracting information about how the object has changed
from the way in which it was memorized. Our goal in this paper is to discuss a system
which is able to recognize memorized 2-dimensional objects regardless of geometric distortions like changes in scale and orientation, and can characterize those transformations.
The system also allows for noise and occlusion and is tolerant of memory faults.
The following sections, Invariant Representation and Distributed Associative
Memory, respectively, describe the various components of the system in detail. The Experiments section presents the results from several experiments we have performed on real
data. The paper concludes with a discussion of our results and their implications for future
research.

? American Institute of Physics 1988

831

1. Invariant Representation

The goal of this section is to examine the various components used to produce the
vectors which are associated in the distributed associative memory. The block diagram
which describes the various functional units involved in obtaining an invariant image
representation is shown in Figure 1. The image is complex-log conformally mapped so that
rotation and scale changes become translation in the transform domain . Along with the
conformal mapping, the image is also filtered by a space variant filter to reduce the effects
of aliasing. The conformally mapped image is then processed through a Laplacian in order
to solve some problems associated with the conformal mapping. The Fourier transform of
both the conformally mapped image and the Laplacian processed image produce the four
output vectors. The magnitude output vector I-II is invariant to linear transformations of
the object in the input image. The phase output vector <1>2 contains information concerning the spatial properties of the object in the input image.

1.1 Complex-Log Mapping and Space Variant Filtering
The first box of the block diagram given in Figure 1 consists of two components:
Complex-log mapping and space variant filtering. Complex-log mapping transforms an
image from rectangular coordinates to polar exponential coordinates. This transformation
changes rotation and scale into translation. If the image is mapped onto a complex plane
then each pixel (x,y) on the Cartesian plane can be described mathematically by z = x +
jy. The complex-log mapped points ware described by
w =In{z) =In(lzl} +jiJ z

(1)

Our system sampled 256x256 pixel images to construct 64x64 complex-log mapped
images. Samples were taken along radial lines spaced 5.6 degrees apart. Along each radial
line the step size between samples increased by powers of 1.08. These numbers are derived
from the number of pixels in the original image and the number of samples in the
complex-log mapped image. An excellent examination of the different conditions involved
in selecting the appropriate number of samples for a complex-log mapped image is given in
[2J. The non-linear sampling can be split into two distinct parts along each radial line. Toward the center of the image the samples are dense enough that no anti-aliasing filter is
needed. Samples taken at the edge of the image are large and an anti-aliasing filter is
necessary. The image filtered in this manner has a circular region around the center which
corresponds to an area of highest resolution. The size of this region is a function of the
number of angular samples and radial samples. The filtering is done, at the same time as
the sampling, by convolving truncated Bessel functions with the image in the space
domain. The width of the Bessel functions main lobe is inversely proportional to the eccentricity of the sample point.
A problem associated with the complex-log mapping is sensitivity to center
misalignment of the sampled image. Small shifts from the center causes dramatic distortions in the complex-log mapped image. Our system assumes that the object is centered in
the image frame. Slight misalignments are considered noise. Large misalignments are considered as translations and could be accounted for by changing the gaze in such a way as
to bring the object into the center of the frame. The decision about what to bring into the
center of the frame is an active function and should be determined by the task. An example of a system which could be used to guide the translation process was developed by
Anderson and Burt [3J. Their pyramid system analyzes the input image at different tem-

00

c..:>

~

Inverse
Processing
and
Reconstruction

.

Image

~

I

Compl"".lo,
Mapping
and
Space Variant
Filtering

I
I
I

~-?-FO"",i""

II

'

1ransform

I

2

-1-1

I

I

-~

Laplacian

Fourier
Transform

2

_~I

Distributed
Associative
Memory

~

Rotation
and
Scale
Estimation

I-II
Classification

Figure 1. Block Diagram of the System.

833

poral and spatial resolution levels. Their smart sensor was then able to shift its fixation
such that interesting parts of the image (ie . something large and moving) was brought into
the central part of the frame for recognition .

1.2 Fourier Transform
The second box in the block diagram of Figure 1 is the Fourier transform. The
Fourier transform of a 2-dimensional image f(x,y) is given by
F(u,v) =

j j

f(x,y)e-i(ux+vy) dx dy

(2)

-00 -00

and can be described by two 2-dimensional functions corresponding to the magnitude
IF(u,v)1 and phase <l>F(u,v). The magnitude component of the Fourier trans~rm which is
invariant to translatIOn, carries much of the contrast information of the image . The phase
component of the Fourier transform carries information about how things ar} placed in an
image. Translation of f(x,y) corresponds to the addition of a linear phase cpmponent. The
complex-log mapping transforms rotation and scale into translation and tije magnitude of
the Fourier transform is invariant to those translations so that I-II ivill not change
significantly with rotation and scale of the object in the image .

1.3 Laplacian
The Laplacian that we use is a difference-of-Gaussians (DOG) approximation to the
function as given by Marr [4).
'V 2G

2

2

=h [1 - r2/2oo 2) e{ -r /200 }

(3)

'1rtT

The result of convolving the Laplacian with an image can be viewed as a two step process.
The image is blurred by a Gaussian kernel of a specified width oo. Then the isotropic
second derivative of the blurred image is computed. The width of the Gaussian kernel is
chosen such that the conformally mapped image is visible -- approximately 2 pixels in our
experiments. The Laplacian sharpens the edges of the object in the image and sets any region that did not change much to zero. Below we describe the benefits from using the Laplacian.
The Laplacian eliminates the stretching problem encountered by the complex-log
mapping due to changes in object size. When an object is expanded the complex-log
mapped image will translate . The pixels vacated by this translation will be filled with
more pixels sampled from the center of the scaled object. These new pixels will not be
significantly different than the displaced pixels so the result looks like a stretching in the
complex-log mapped image . The Laplacian of the complex-log mapped image will set the
new pixels to zero because they do not significantly change from their surrounding pixels.
The Laplacian eliminates high frequency spreading due to the finite structure of the
discrete Fourier transform and enhances the differences between memorized objects by accentuating edges and de-emphasizing areas of little change.

2. Distributed Associative Memory (DAM)
The particular form of distributed associative memory that we deal with in this paper is a memory matrix which modifies the flow of information. Stimulus vectors are associated with response vectors and the result of this association is spread over the entire
memory space . Distributing in this manner means that information about a small portion
of the association can be found in a large area of the memory. New associations are placed

834

over the older ones and are allowed to interact. This means that the size of the memory
matrix stays the same regardless of the number of associations that have been memorized.
Because the associations are allowed to interact with each other an implicit representation
of structural relationships and contextual information can develop, and as a consequence a
very rich level of interactions can be captured. There are few restrictions on what vectors
can be associated there can exist extensive indexing and cross-referencing in the memory.
Distributed associative memory captures a distributed representation which is context
dependent. This is quite different from the simplistic behavioral model [5].
The construction stage assumes that there are n pairs of m-dimensional vectors that
are to be associated by the distributed associative memory. This can be written as
""l.K:::+.
IV~

1

= -r.
1

~or 1?
I'

= 1 , ... ,n

(4)

-d
h ?th stlmu
. I us vector an d -d
h .th correspon d?mg response Vech
were
s. enotes tel
r. enotes tel
tor. W~ want to construct a memory matrix M such that when the kth stimulus vector S;
is projected onto the space defined by M the resulting projection will be the corresponding
More specifically we want to solve the following equation:
response vector

r;.

(5)

MS=R

- 11 s2
11 ? ??11 ?
?
~
S = [ s1
h
were
S ] an d R = [ -r 1 11 -r 2 11 ???11 r]. A
umque
soIutlOn
lor
t h?IS equation does not necessarily n exist for any arbitrary gr~up of associations that might be
chosen. Usually, the number of associations n is smaller than m, the length of the vector to
be associated, so the system of equations is underconstrained. The constraint used to solve
for a unique matrix M is that of minimizing the square error, IIMS - RJ1 2, which results in
the solution

(6)
where S+ is known as the Moore-Penrose generalized inverse of S [6J.
The recall operation projects an unknown stimulus vector
M. The resulting projection yields the response vector r

r =Ms

s onto

the memory space

(7)

If the memorized stimulus vectors are independent and the unknown stimulus vector s is
one of the memorized vectors
then the recalled vector will be the associated response
If the memorized stimulus vectors are dependent, then the vector recalled by
vector
one of the memorized stimulus vectors will contain the associated response vector and
some crosstalk from the other stored response vectors.

r;.

S;,

The recall can be viewed as the weighted sum of the response vectors. The recall
begins by assigning weights according to how well the unknown stimulus vector matches
with the memorized stimulus vector using a linear least squares classifier. The response
vectors are multiplied by the weights and summed together to build the recalled response
vector. The recalled response vector is usually dominated by the memorized response vector that is closest to the unknown stimulus vector.
Assume that there are n associations in the memory and each of the associated
stimulus and response vectors have m elements. This means that the memory matrix has
m 2 elements. Also assume that the noise that. is added to each element of a memorized

835

stimulus vector
memory is then

IS

independent, Zero mean, with a variance of O'~ The recall from the
1

(8)
where tt is the input noise vector and t1 is the output noise vector. The ratio of the average output noise variance to the averagg input noise variance is

0'2o/0'.12

1
[MMT]
= -Tr
m

(9)

For the autoassociative case this simplifies to

(10)
This says that when a noisy version of a memorized input vector is applied to the memory
the recall is improved by a factor corresponding to the ratio of the number of memorized
vectors to the number of elements in the vectors. For the heteroassociative memory matrix a similar formula holds as long as n is less than m [7].

(11)
Fault tolerance is a byproduct of the distributed nature and error correcting capabilities of the distributed associative memory. By distributing the information, no single
memory cell carries a significant portion of the information critical to the overall performance of the memory.
3. Experiments

In this section we discuss the result of computer simulations of our system. Images
of objects are first preprocessed through the sUbsystem outlined in section 2. The output of
such a subsystem is four vectors: I-I , <1>1' 1-1 2, and <1>2' We construct the memory by associating the stimulus vector I-II with ?he response vector <1>2 for each object in the database.
To perform a recall from the meJIlory the.. unknown image is preprocessed by the same_subsystem to produce the vectors I-II' <1>1' 1-12, and <1>2' The resulting stimulus vector I-I is
projected onto the m~mory matrix to produce a respOJlse vector which is an ~stimatel of
the memorized phase <1>2' The estimated phase vector cI> 2 and the magnitude I-II ate used
to reconstruct the memorized object. The difference between the estimated phase <1>2 and
the unknown phase <1>2 is used to estimate the amount of rotation and scale experienced by
the object.
The database of images consists of twelve objects: four keys, four mechanical parts,
and four leaves. The objects were chosen for their essentially two-dimensional structure.
Each object was photographed using a digitizing video camera against a black background. We emphasize that all of the images used in creating and testing the recognition
system were taken at different times using various camera rotations and distances. The images are digitized to 256x256, eight bit quantized pixels, and each object covers an area of
about 40x40 pixels. This small object size relative to the background is necessary due to
the non-linear sampling of the complex-log mapping. The objects were centered within the
frame by hand. This is the source of much of the noise and could have been done automatically using the object's center of mass or some other criteria determined by the task. The
orientation of each memorized object was arbitrarily chosen such that their major axis

836

was vertical. The 2-dimensional images that are the output from the invariant representation subsystem are scanned horizontally to form the vectors for memorization. The database used for these experiments is shown in Figure 2.

Figure 2. The Database of Objects Used in the Experiments

a) Original

b) Unknown

c) Recall: rotated 135?

d) Memory:6
SNR: -3.37 Db

Figure 3. :Recall Using a Rotated and scaled key
The first example of the operation of our system is shown in Figure 3. Figure 3a) is
the image of one of the keys as it was memorized. Figure 3b) is the unknown object
presented to our system. The unknown object in this caSe is the same key that has been
rotated by 180 degrees and scaled. Figure 3c) is the recalled, reconstructed image. The

837

rounded edges of the recalled image are artifacts of the complex-log mapping. Notice that
the reconstructed recall is the unrotated memorized key with some noise caused by errors
in the recalled phase. Figure 3d) is a histogram which graphically displays the
classification vector which corresponds to S+S. The histogram shows the interplay between
the memorized images and the unknown image. The"" 6"" on the bargraph indicates which
of the twelve classes the unknown object belongs. The histogram gives a value which is
the best linear estimate of the image relative to the memorized objects. Another measure,
the signal-to-noise ratio (SNR), is given at the bottom of the recalled image. SNR compares the variance of the ideal recall after processing with the variance of the difference
between the ideal and actual recall. This is a measure of the amount of noise in the recall.
The SNR does not carry rr.uch information about the q""Jality of the recall image because
the noise measured by the SNP.. is jue to many factors such as misalignment of the center,
changing reflections, and dependence between other memorized objects -- each affecting.
quality in a variety of ways. Rotation and scale estimate~ are made using a vector_ D
corresponding to the dlll'erence between the unknown vector <1>2 and the recalled vector <I> 2'
In an ideal situation D will be a plane whose E;radient indicates the exact amount of r:.otation and scale the recalled object has experienced. In our system the recalled vector <I> 2 is
corrupted with noise which means rotation...and scale have to be estim:ned. The estimate is
made by letting the first order difference D at each point in the plane vote for a specified
range of rotation or scale.

a) Original

b) Unknown

c) Recall

d) Memory:4

Figure 4 Recall Using Scaled and Rotated"" S"" with Occlusion
Figure 4 is an example of occlusion. The unknown object in this case is an ""s""
curve which is larger and slightly tilted from the memorized ""s"" curve. A portion of the
bottom curve was occluded. The resulting reconstruction is very noisy but has filled in the
missing part of the bottom curve. The noisy recall is reflected in both the SNR and the interplay betw~en the memories shown by the hi~togram.

a) Ideal recall

b) 30% removed

c) 50% removed

d) 75% removed

Figure 5. Recall for Memory Matrix Randomly Set to Zero
Figure 5 is the result of randomly setting the elements of the memory matrix to

838

zero. Figure 5a) shows is the ideal recall. Figure 5b) is the recall after 30 percent of the
memory matrix has been set to zero. Figure 5c) is the recall for 50 percent and Figure 5d)
is the recall for 75 percent. Even when 90 percent of the memory matrix has been set to
zero a faint outline of the pin could still be seen in the recall. This result is important in
two ways. First, it shows that the distributed associative memory is robust in the presence
of noise. Second, it shows that a completely connected network is not necessary and as a
consequence a scheme for data compression of the memory matrix could be found.

4. Conclusion
In this paper we demonstrate a computer vIsIon system which recognIzes 2dimensional objects invariant to rotation or scale. The system combines an invariant
representation of the input images with a distributed associative memory such that objects
can be classified, reconstructed, and characterized. The distributed associative memory is
resistant to moderate amounts of noise and occlusion. Several experiments, demonstrating
the ability of our computer vision system to operate on real, grey scale images, were
presented.
Neural network models, of which the di~tributed associative memory is one example,
were originally developed to simulate biological memory. They are characterized by a
large number of highly interconnected simple processors which operate in p2..rallel. An excellent review of the many neural network models is given in [8J. The distrib-uted associative memory we use is linear, and as a result there are certain desirable properties which
will not be exhibited by our computer vision system. For example, feedback through our
system will not improve recall from the memory. Recall could be improved if a non-linear
element, such as a sigmoid function, is introduced into the feedback loop. Non-linear neural networks, such as those proposed by Hopfield [9] or Anderson et. al. [10J, can achieve
this type of improvement because each memorized pattern js associated with sta~le points
in an energy space. The price to be paid for the introduction of non-linearities into a
memory system is that the system will be difficult to analyze and can be unstable. Implementing our computer vision system using non-linear distributed associative memory is a
goal of our future research.
We are presently extending our work toward 3-dimensional object recognition. Much
of the present research in 3-dimensional object recognition is limited to polyhedral, nonoccluded objects' in a clean, highly controlled environment. Most systems are edge based
and use a generate-and-test paradigm to estimate the position and orientation of recognized objects. We propose to use an approach based on characteristic views [llJ or aspects
[12J which suggests that the infinite 2-dimensional projections of a 3-dimensional object
can be grouped into a finite number of topological equivalence classes. An efficie:.t 3dimensional recognition system would require a parallel indexing method to search for object models in the presence of geometric distortions, noise, and occlusion. Our object recognition system using distributed associative memory can fulfill those requirements with
respect to characteristic views.

Referenees
[lJ Simon, H. A., (1984), The Seienee of the Artifldal (2nd ed.), MIT Press.
[2J Massone, L., G. Sandini, and V. Tagliasco (1985), ""Form-invariant"" topological mapping strategy for 2D shape recognition, CVGIP, 30, 169-188.
[3J Anderson, C. H., P. J. Burt, and G. S. Van Der Wal (1985), Change detection and
tracking using pyramid transform techniques, Proe. of the SPIE Conferenee on
Intelligenee, Robots, and Computer Vision, Vol. 579, 72-78.

839

Marr, D. (1982), Vision, W. H. Freeman, 1982.
Hebb, O. D. (1949), The Organization of Behavior, New York: Wiley.
Kohonen, T. (1984), Self-Organization and Associative-Memories, Springer-Verlag.
Stiles, G. S. and D. L. Denq (1985), On the effect of noise on the Moore-Penrose generalized inverse associative memory, IEEE Trans. on PAMI, 7, 3,358-360.
[8J MCClelland, J. L., and D . E. Rumelhart, and the PDP Research Group (Eds.) (1986),
Parallel Distributed, Processing, Vol. 1, 2, MIT Press.
[9] Hopfield, J. J. (1982), Neural networks and physical systems with emergent collective
computational abilities, Proc. Natl. Acad. Sci. USA, 79, April 1982.
[10J Anderson, J. A., J. W. Silversteir., S. A. Ritz, and R. S. Jones (1977), Distinctive
features, categorical perception, and probability learning: some applications of a
neural model, Psychol. Rev., 84,413-451.
[11] Chakravarty, I., and H. Freeman (1982), Characteristic views as a basis for 3-D object
recognition, Proc. SPIE on Robot Vision, 336,37-45.
[12] Koenderink, J. J., and A . J . Van Doorn (1979), Internal representation of solid shape
with respect to vision, Bioi. Cybern., 32,4,211-216.

[4]
[5]
[6J
[7]

"
82,1987,"Simulations Suggest Information Processing Roles for the Diverse Currents in Hippocampal Neurons","",82-simulations-suggest-information-processing-roles-for-the-diverse-currents-in-hippocampal-neurons.pdf,"Abstract Missing","82

SIMULATIONS SUGGEST
INFORMATION PROCESSING ROLES
FOR THE DIVERSE CURRENTS IN
HIPPOCAMPAL NEURONS
Lyle J. Borg-Graham
Harvard-MIT Division of Health Sciences and Technology and
Center for Biological Information Processing,
Massachusetts Institute of Technology, Cambridge, Massachusetts 02139
ABSTRACT
A computer model of the hippocampal pyramidal cell (HPC) is described
which integrates data from a variety of sources in order to develop a consistent description for this cell type. The model presently includes descriptions of eleven non-linear somatic currents of the HPC, and the electrotonic
structure of the neuron is modelled with a soma/short-cable approximation.
Model simulations qualitatively or quantitatively reproduce a wide range of
somatic electrical behavior i~ HPCs, and demonstrate possible roles for the
various currents in information processing.

1

The Computational Properties of Neurons

There are several substrates for neuronal computation, including connectivity, synapses, morphometries of dendritic trees, linear parameters of cell
membrane, as well as non-linear, time-varying membrane conductances, also
referred to as currents or channels. In the classical description of neuronal
function, the contribution of membrane channels is constrained to that of
generating the action potential, setting firing threshold, and establishing the
relationship between (steady-state) stimulus intensity and firing frequency.
However, it is becoming clear that the role of these channels may be much
more complex, resulting in a variety of novel ""computational operators"" that
reflect the information processing occurring in the biological neural net.

? American Institute of Physics 1988

83

2

Modelling Hippocampal Neurons

Over the past decade a wide variety of non-linear ion channels, have been
described for many excitable cells, in particular several kinds of neurons.
One such neuron is the hippocampal pyramidal cell (HPC). HPC channels are marked by their wide range of temporal, voltage-dependent, and
chemical-dependent characteristics, which results in very complex behavior
or responses of these stereotypical cortical integrating cells. For example,
some HPC channels are activated (opened) transiently and quickly, thus primarily affecting the action potential shape. Other channels have longer kinetics, modulating the response of HPCs over hundreds of milliseconds. The
measurement these channels is hampered by various technical constraints,
including the small size and extended electrotonic structure of HPCs and the
diverse preparations used in experiments. Modelling the electrical behavior
of HPCs with computer simulations is one method of integrating data from
a variety of sources in order to develop a consistent description for this cell
type.
In the model referred to here putative mechanisms for voltage-dependent
and calcium-dependent channel gating have been used to generate simulations of the somatic electrical behavior of HPCs, and to suggest mechanisms
for information processing at the single cell level. The model has also been
used to suggest experimental protocols designed to test the validity of simulation results. Model simulations qualitatively or quantitatively reproduce
a wide range of somatic electrical behavior in HPCs, and explicitly demonstrate possible functional roles for the various currents [1].
The model presently includes descriptions of eleven non-linear somatic
currents, including three putative N a+ currents - INa-trig, INa-rep, and
INa-tail; six K+ currents that have been reported in the literature - IDR
(Delayed Rectifier), lA, Ie, IAHP (After-hyperpolarization), 1M, and IQ;
and two Ca 2+ currents, also reported previously - lea and leas.
The electrotonic structure of the HPC is modelled with a soma/shortcable approximation, and the dendrites are assumed to be linear. While the
conditions for reducing the dendritic tree to a single cable are not met for
HPC (the so-called Rall conditions [3]), the Zin of the cable is close to that
of the tree. In addition, although HPC dendrites have non-linear membrane,
it assumed that as a first approximation the contribution of currents from
this membrane may be ignored in the somatic response to somatic stimulus.
Likewise, the model structure assumes that axon-soma current under these
conditions can be lumped into the soma circuit.

84

In part this paper will address the following question: if neural nets
are realizable using elements that have simple integrative all-or-nothing responses, connected to each other with regenerative conductors, then what
is the function for all the channels observed experimentally in real neurons?
The results of this HPC model study suggest some purpose for these complexities, and in this paper we shall investigate some of the possible roles of
non-linear channels in neuronal information processing. However, given the
speculative nature of many of the currents that we have presented in the
model, it is important to view results based on the interaction of the many
model elements as preliminary.

3

Defining Neural Information Coding is the First
Step in Describing Biological Computations

Determination of computational properties of neurons requires a priori assumptions as to how information is encoded in neuronal output. The classical description assumes that information is encoded as spike frequency.
However, a single output variable, proportional to firing frequency, ignores
other potentially information-rich degrees of freedom, including:
? Relative phase of concurrent inputs.
? Frequency modulation during single bursts.
? Cessation of firing due to intrinsic mechanisms.
? Spike shape.
Note that these variables apply to patterns of repetitive firingl. The
relative phase of different inputs to a single cell is very important at low
firing rates, but becomes less so as firing frequency approaches the time
constant of the postsynaptic membrane or some other rate-limiting process
in the synaptic transduction (e.g. neurotransmitter release or post synaptic channel activation/deactivation kinetics). Frequency modulation during
bursts/spike trains may be important in the interaction of a given axon's
output with other inputs at the target neuron. Cessation of firing due to
mechanisms intrinsic to the cell (as opposed to the end of input) may be
lSingle spikes may be considered as degenerate cases of repetitive firing responses.

85

important, for example, in that cell's transmission function. Finally, modulation of spike shape may have several consequences, which will be discussed
later.

4

Physiological Modulation of HPC Currents

In order for modulation of HPC currents to be considered as potential information processing mechanisms in vivo, it is necessary to identify physiological modulators. For several of the currents described here such factors
have been identified. For example, there is evidence that 1M is inhibited
by muscarinic (physiologically, cholinergic) agonists [2], that 1A is inhibited by acetylcholine [6], and that 1AHP is inhibited by noradrenaline [5].
In fact, the list of neurotransmitters which are active non-synaptically is
growing rapidly. It remains to be seen whether there are as yet undiscovered mechanisms for modulating other HPC currents, for example the three
N a+ currents proposed in the present model. Some possible consequences
of such mechanisms will be discussed later.

5

HPC Currents and Information Processing

The role of a given channel on the HPC electrical response depends on its
temporal characteristics as a function of voltage, intracellular messengers,
and other variables. This is complicated by the fact that the opening and
closing of channels is equivalent to varying conductances, allowing both linear and non-linear operations (e.g. [4] and [7]). In particular, a current
which is activated/deactivated over a period of hundreds of milliseconds
will, to a first approximation, act by slowly changing the time constant of
the membrane. At the other extreme, currents which activate/deactivate
with sub-millisecond time constants act by changing the trajectory of the
membrane voltage in complicated ways. The classic example of this is the
role of N a+ currents underlying the action potential.
To investigate how the different HPC currents may contribute to the
information processing of this neuron, we have looked at how each current
shapes the HPC response to a simple repertoire of inputs. At this stage
in our research the inputs have been very basic - short somatic current
steps that evoke single spikes, long lasting somatic current steps that evoke
spike trains, and current steps at the distal end of the dendritic cable. By
examining the response to these inputs the functional roles of the HPC

86

I Current"" Spike Shape I Spike Threshold I Tm/Frequency-Intensity I
+++
++
-(+)
+
++

Ic

+
+
- (++)
++
+
+

IAHP

-

1M

-

++
+

INa-trig
INa-rep
ICa
IDR
IA

-

-

+++
+ (+++)
++
++
+++
+++
+

Table 1: Putative functional roles of HPC somatic currents. Entries in
parentheses indicate secondary role, e.g. Ca 2 + activation of J(+ current.
currents can be tentatively grouped into three (non-exclusive) categories:
? Modulation of spike shape.
? Modulation of firing threshold, both for single and repetitive spikes.
? Modulation of semi-steady-state membrane time constant.
? Modulation of repetitive firing, specifically the relationship between
strength of tonic input and frequency of initial burst and later ""steady
state"" spike train.
Table 1 summarizes speculative roles for some of the HPC currents as
suggested by the simulations. Note that while all four of the listed characteristics are interrelated, the last two are particularly so and are lumped
together in Table 1.

5.1

Possible Roles for Modulation of FI Characteristic

Again, it has been traditionally assumed that neural information is encoded
by (steady-state) frequency modulation, e.g. the number of spikes per second
over some time period encodes the output information of a neuron. For
example, muscle fiber contraction is approximately proportional to the spike
frequency of its motor neuron 2. If the physiological inhibition of a specific
2In fact, where action potential propagation is a stereotyped phenomena, such as in
long axons, then the timing of spikes is the only parameter that may be modulated.

87

. ..

-- -~

.........

'--;,

\

,
,
,
,
,
,
,
,
,
,

\
\
\
\

Stimulus Intensity (Constant Current)
Figure 1: Classical relation between total neuronal input (typically tonic
current stimulus) and spike firing frequency [solid line] and (qualitative)
biological relationships [dashed and dotted lines]. The dotted line applies
when INa-rep is blocked.
current changes the FI characteristic, this allows one way to modulate that
neuron's information processing by various agents.
Figure 1 contrasts the classical input-output relation of a neuron and
more biological input-output relations. The relationships have several features which can be potentially modulated either physiologically or pathologically, including saturation, threshold, and shape of the curves. Note in
particular the cessation of output with increased stimulation, as the depolarizing stimulus prevents the resetting of the transient inward currents.
For the HPC, simulations show (Figure 2 and Figure 3) that blocking the
putative INa-rep has the effect of causing the cell to ""latch-up"" in response
to tonic stimulus that would otherwise elicit stable spike trains. Both depolarizing currents and repolarizing currents playa role here. First, spike
upstroke is mediated by both INa-rep and the lower threshold INa-trig; at
high stimuli repolarization between spikes does not get low enough to reset
INa-trig' Second, spikes due to only one of these N a+ currents are weaker
and as a result do not activate the repolarizing [(+ currents as much as
normal because a) reduced time at depolarized levels activates the voltagedependent [(+ currents less and b) less Ca2+ influx with smaller spikes
reduces the Ca2+ -dependent activation of some [(+ currents. The net result is that repolarization between spikes is weaker and, again, does not reset
INa-trig.

Although the current being modulated here

(INa-rep)

is theoretical, the

88

Voltage (nV)
,~

;299.9

699.9

499.9

--

~~VL-,299.9

499.9

,899.9

2 nA Stinulus, Nornal

Vo leage (nV)
b~

Tine (sec) (x 1.ge-3)

699.9

'---

Tine (sec) (x 1.ge-3)
,899.9

I!J(~VVVVVVL.--'L.--V--V--~~N~
Voltage (P'lV)
h~

,299.9

499.9

699.9

Tine

(se~

(x 1.ge-3)

99.9

I

I

~VVl/VvI/\/VV\/\/VVVVV1.,/VVVVV-~~
6 nA StiP'lulus, Nornal

Figure 2: Simulation of repetitive firing in response to constant current
injection into the soma. In this series, with the ""normal"" cell, a stimulus
of about 8 nA (not shown) will cause to cell to fire a short burst and then
cease firing.
possibility of selective blocking of INa-rep allows a mechanism for shifting
the saturation of the neuron's response to the left and, as can be seen by
comparing Figures 2 and 3, making the FI curve steeper over the response
range.

5.2

Possible Roles for Modulation of Spike Threshold

The somatic firing threshold determines the minimal input for eliciting a
spike, and in effect change the sensitivity of a cell. As a simple example,
blocking INa-trig in the HPe model raises threshold by about 10 millivolts.
This could cause the cell to ignore input patterns that would otherwise
generate action potentials.
There are two aspects of the firing ""threshold"" for a cell - static and
dynamic. Thus, the rate at which the soma membrane approaches threshold is important along with the magnitude of that threshold. In general
the threshold level rises with a slower depolarization for several reasons, including partial inactivation of inward currents (e.g. INa-trig) and partial
activation of outward currents (e.g. IA [8]) at subthreshold levels.

89

Tine (sec) (x 1.ge-3)
499.9

99.9

899.9

2 nA Stinulus,

4 nA Stinulus,

u~o

I-Na-Rep

u~o

I-Na-Rep

Tine (sec)
499 . 9

99.9

ex

1.ge-3}

899.9

-89.9

6 nA Stinulus,

u~o

I-Na-Rep

Figure 3: Blocking one of the putative N a+ currents (INa-rep) causes the
HPC repetitive firing response to fail at lower stimulus than ""normal"". This
corresponds to the leftward shift in the saturation of the response curve
shown in Figure 1.
Thus it is possible, for example, that IA helps to distinguish tonic dendritic distal synaptic input from proximal input. For input that eventually
will supply the same depolarizing current at the soma, dendritic input will
have a slower onset due to the cable properties of the dendrites. This slow
onset could allow IA to delay the onset of the spike or spikes. A similar depolarizing current applied more proximally would have a faster onset.
Sub-threshold activation of IA on the depolarizing phase would then be insufficient to delay the spike.

5.3

Possible Roles for Modulation of Somatic Spike Shape

How important is the shape of an individual spike generated at the soma?
First, we can assume that spike shape, in particular spike width, is unimportant at the soma spike-generating membrane - once the soma fires, it fires.
However, the effect of the spike beyond the soma mayor may not depend
on the spike shape, and this is dependent on both the degree which spike
propagation is linear and on the properties of the pre-synaptic membrane.
Axon transmission is both a linear and non-linear phenomena, and the
shorter the axon's electrotonic length, the more the shape of the somatic

90

action potential will be preserved at the distal pre-synaptic terminal. At
one extreme, an axon could transmit the spike a purely non-linear fashion
- once threshold was reached, the classic ""all-or-nothing"" response would
transmit a stereotyped action potential whose shape would be independent
of the post-threshold soma response. At the other extreme, i.e. if the axonal
membrane were purely linear, the propagation of the somatic event at any
point down the axon would be a linear convolution of the somatic signal
and the axon cable properties. It is likely that the situation in the brain lies
somewhere between these limits, and will depend on the wavelength of the
spike, the axon non-linearities and the axon length.
What role could be served by the somatic action potential shape modulating the pre-synaptic terminal signal? There are at least three possibilities.
First, it has been demonstrated that the release of transmitter at some presynaptic terminals is not an ""all-or-nothing"" event, and in fact is a function
of the pre-synaptic membrane voltage waveform. Thus, modulation of the
somatic spike width may determine how much transmitter is released down
the line, providing a mechanism for changing the effective strength of the
spike as seen by the target neuron. Modulation of somatic spike width could
be equivalent to a modulation ofthe ""loudness"" of a given neuron's message.
Second, pyramidal cell axons often project collateral branches back to the
originating soma, forming axo-somatic synapses which result in a feedback
loop. In this case, modulation of the somatic spike could affect this feedback
in complicated ways, particularly since the collaterals are typically short.
Finally, somatic spike shape may also playa role in the transmission of
spikes at axonal branch points. For example, consider a axonal branch point
with an impedance mismatch and two daughter branches, one thin and one
thick. Here a spike that is too narrow may not be able to depolarize the
thick branch sufficiently for transmission of the spike down that branch, with
the spike propagating only down the thin branch. Conversely, a wider spike
may be passed by both branches. Modulation of the somatic spike shape
could then be used to direct how a cell's output is broadcast, some times
allowing transmission to all the destinations of an HPC , and at other times
inhibiting transmission to a limited set of the target neurons.
For HPCs much evidence has been obtained which implicate the roles
of various HPC currents on modulating somatic spike shape, for example
the Ca 2 +-dependent K+ current Ie [9]. Simulations which demonstrate
the effect of Ie on the shape of individual action potentials are shown in
Figure 4.

91

Volt""9"" (!'IV)
Tin"" (~""c) (x 1.9,,-3)
Il 3.1l 4 . 9 S.1l

Volts"" (nU)
Tin"" (~""c) (x 1.9,,-3)
.9
Il 3.1l 4.1l 5.9

-81l.1l

-81l.9

""
,:""
1'\

, :
I""

\

Curr""nt (nA)""

..

1l.1l

....

-11l.1l

?.9

""

..

(x.1.1l,,-3)
3.'8- .'\.?.il""_"".5.1l

Ti~,, : (~ec)

.Il

""
I

... ...

I-Na-Tris

-_. I-DR
"" .. "" I-C

Figure 4: Role of Ie during repolarization of spike. In the simulation on the
left, Ie is the largest repolarizing current. In the simulation on the right,
blocking Ie results in an wider spike.

6

The Assumption of Somatic Vs. Non-Somatic
Currents

In this research the somatic response of the HPC has been modelled under
the assumption that the data on HPC currents reflect activity of channels
localized at the soma. However, it must be considered that all channel proteins, regardless of their final functional destination, are manufactured at
the soma. Some of the so-called somatic channels may therefore be vestiges of channels intended for dendritic, axonal, or pre-synaptic membrane.
For example, if the spike-shaping channels are intended to be expressed for
pre-synaptic membrane, then modulation of these channels by endogenous
factors (e.g. ACh) takes place at target neuron. This may seem disadvantageous if a factor is to act selectively on some afferent tract. On the other
hand, in the dendritic field of a given neuron it is possible only some afferents have certain channels, thus allowing selective response to modulating
agents. These possibilities further expand the potential roles of membrane
channels for computation.

92

7

Other Possible Roles of Currents for Modulating HPC Response

There are many other potential ways that HPC currents may modulate the
HPC response. For example, the relationship between intracellular Ca2+
and the Ca2 +-dependent K+ currents, Ic and IAHP, may indicate possible
information processing mechanisms.
Intracellular Ca 2+ is an important second messenger for several intracellular processes, for example muscular contraction, but excessive [Ca 2+]in is
noxious. There are at least three negative feedback mechanisms for limiting
the flow of Ca2+ : voltage-dependent inactivation of Ca2+ currents; reduction of ECa (and thus the Ca2+ driving force) with Ca2+ influx; and the just
mentioned Ca2+ -mediation of repolarizing currents. A possible information
processing mechanism could be by modulation of IAHP, which plays an important role in limiting repetitive firing;. Simulations suggest that blocking
this current causes Ic to step in and eventually limit further repetitive firing, though after many more spikes in a train. Blocking both these currents
may allow other mechanisms to control repetitive firing, perhaps ones that
operate independently of [Ca 2+]in. Conceivably, this could put the neuron
into quite a differen t operating region.

8

Populations of Neurons V s. Single Cells: Implications for Graded Modulation of HPC Currents

In this paper we have considered the all-or-nothing contribution of the various channels, Le. the entire population of a given channel type is either
activated normally or all the channels are disabled/blocked. This description may be oversimplified in two ways. First, it is possible that a blocking
mechanism for a given channel may have a graded effect. For example, it is
possible that cholinergic input is not homogeneous over the soma membrane,
or that at a given time only a portion of these afferents are activated. In
either case it is possible that only a portion of the cholinergic receptors are
bound, thus inhibiting a portion of channels. Second, the result of channel
inhibition by neuromodulatory projections must consider both single cell
3The slowing down of the spike trains in Figure 2 and Figure 3 is mainly due to the
buildup of [Ca 2+];n, which progressively activates more IAHP.

93

response and population response, the size of the population depending on
the neuro-architecture of a cortical region and the afferents. For example,
activation of a cholinergic tract which terminates in a localized hippocampal
region may effect thousands of HPCs. Assuming that the 1M of individual
HPCs in the region may be either turned on or off completely with some
probability, the behavior of the population will be that of a graded response
of 1M inhibition. This graded response will in turn depend on the strength
of the cholinergic tract activity.
The key point is that the information processing properties of isolated
neurons may be reflected in the behavior of a population, and vica-versa.
While it is likely that removal of a single pyramidal cell from the hippocampus will have zero functional effect, no neuron is an island. Understanding the central nervous system begins with the spectrum of behavior in its
functional units, which may range from single channels, to specific areas of
a dendritic tree, to the single cell, to cortical or nuclear subfields, on up
through the main subsystems of CNS.

References
[1] L. Borg-Graham. Modelling the Somatic Electrical Behavior of Hippocampal Pyramidal Neurons. Master's thesis, Massachusetts Institute
of Technology, 1987.
[2] J. Halliwell and P. Adams. Voltage clamp analysis of muscarinic excitation in hippocampal neurons. Brain Research, 250:71-92, 1982.
[3] J. J. B. Jack, D. Noble, and R. W. Tsien. Electric Current Flow In
Excitable Cells. Clarendon Press, Oxford, 1983.
[4] C. Koch and T. Poggio. Biophysics of computation: neurons, synapses
and membranes. G. B.!. P. Paper, (008), 1984. Center for Biological
Information Processing, MIT.
[5] D. Madison and R. Nicoll. Noradrenaline blocks accommodation ofpyramidal cell discharge in the hippocampus. Nature, 299:, Oct 1982.
[6] Y. Nakajuma, S. Nakajima, R. Leonard, and K. Yamaguchi. Actetylcholine inhibits a-current in dissociated cultured hippocampal neurons.
Biophysical Journal, 49:575a, 1986.

94

[7] T. Poggio and V. Torre. Theoretical Approaches to Complex Systems,
Lecture Notes in Biomathematics, pages 28- 38. Volume 21, Springer
Verlag, Berlin, 1978. A New Approach to Synaptic Interaction.
[8] J. Storm. A-current and ca-dependent transient outward current control
the initial repetitive firing in hippocampal neurons. Biophysical Journal,
49:369a, 1986.
[9] J. Storm. Mechanisms of action potential repolarization and a fast afterhyperpolarization in rat hippocampal pyramidal cells. Journal of Physiology, 1986.

"
83,1987,"Analysis and Comparison of Different Learning Algorithms for Pattern Association Problems","",83-analysis-and-comparison-of-different-learning-algorithms-for-pattern-association-problems.pdf,"Abstract Missing","72

ANALYSIS AND COMPARISON OF DIFFERENT LEARNING
ALGORITHMS FOR PATTERN ASSOCIATION PROBLEMS

J. Bernasconi
Brown Boveri Research Center
CH-S40S Baden, Switzerland
ABSTRACT
We investigate the behavior of different learning algorithms
for networks of neuron-like units. As test cases we use simple pattern association problems, such as the XOR-problem and symmetry detection problems. The algorithms considered are either versions of
the Boltzmann machine learning rule or based on the backpropagation
of errors. We also propose and analyze a generalized delta rule for
linear threshold units. We find that the performance of a given
learning algorithm depends strongly on the type of units used. In
particular, we observe that networks with ?1 units quite generally
exhibit a significantly better learning behavior than the corresponding 0,1 versions. We also demonstrate that an adaption of the
weight-structure to the symmetries of the problem can lead to a
drastic increase in learning speed.
INTRODUCTION
In the past few years, a number of learning procedures for
neural network models with hidden units have been proposed 1 ,2. They
can all be considered as strategies to minimize a suitably chosen
error measure. Most of these strategies represent local optimization
procedures (e.g. gradient descent) and therefore suffer from all the
problems with local m1n1ma or cycles. The corresponding learning
rates, moreover, are usually very slow.
The performance of a given learning scheme may depend criticallyon a number of parameters and implementation details. General
analytical results concerning these dependences, however, are practically non-existent. As a first step, we have therefore attempted
to study empirically the influence of some factors that could have a
significant effect on the learning behavior of neural network systems.
Our preliminary investigations are restricted to very small
networks and to a few simple examples. Nevertheless, we have made
some interesting observations which appear to be rather general and
which can thus be expected to remain valid also for much larger and
more complex systems.
NEURAL NETWORK MODELS FOR PATTERN ASSOCIATION
An artificial neural network consists of a set of interconnected units (formal neurons). The state of the i-th unit is described
by a variable S. which can be discrete (e.g. S. = 0,1 or S. = ?1) or
continuous (e.l. 0 < S. < 1 or -1 < S. < +ll, and each ~onnection
j-7i carries a weight- W.1. which can be 1positive, zero, or negative.
1J

? American Institute of Physics 1988

73

The dynamics of the network is determined by a local update
rule,
S.(t+l)
1

= HIj

W. . S . (t))
1J

(1)

J

where f is a nonlinear activation function, specifically a threshold
function in the case of discrete units and a sigmoid-type function,
e.g.
(2)

or
(3)

respectively, in the case of continuous units. The individual units
can be given different thresholds by introducing an extra unit which
always has a value of 1.
If the network is supposed to perform a pattern association
task, it is convenient to divide its units into input units, output
units, and hidden units. Learning then consists in adjusting the
weights in such a way that, for a given input pattern, the network
relaxes (under the prescribed dynamics) to a state in which the
output units represent the desired output pattern.
Neural networks learn from examples (input/output pairs) which
are presented many times, and a typical learning procedure can be
viewed as a strategy to minimize a suitably defined error function
F. In most cases, this strategy is a (stochastic) gradient descent
method: To a clamped input pattern, randomly chosen from the learning examples, the network produces an output pattern {O . }. This is
compared with the desired output, say {T . }, and the erfor F( {O. },
{T . }) is calculated . Subsequently, each 1weight is changed by ~an
am~unt proportional to the respective gradient of F,
b.W ..
~J

of
= -r} oW ..

(4)

~J

and the procedure is repeated for a new learning example until F is
minimized to a satisfactory level.
In our investigations, we shall consider two different types of
learning schemes. The first is a deterministic version of the Boltzmann machine learning rule! and has been proposed by Yann Le Cun 2 ?
It applies to networks with symmetric weights, W.. = W.. , so that an
~J
J~
energy
E(~) == - I

W.. S. S .
(i ,j) ~J
~
J

(5)

can be associated with each state S = {S.}. If X refers to the net1
work state when only the input units are clamped and Y to the state
when both the input and output units are clamped, the error function

74

is defined as

= E c:~)

F

- E QO

(6)

and the gradients are simply given by

of- = Y.
-oW. .
1
1J

Y.J

x. X.
1

J

(7)

The second scheme, called backpropagation or generalized delta
rule 1 ,3, probably represents the most widely used learning algorithm.
In its original form, it applies to networks with feedforward connections only, and it uses gradient descent to minimize the mean squared
error of the output signal,

F

= -21 L. (T1
. -1
0.)2

(8)

1

For a weight W.. from an (input or hidden) unit j to an output
unit i, we simply ha~
(9 )

where f' is the derivative of the nonlinear activation function
introduced in Eq. (1), and for weights which do not connect to an
output unit, the gradients can successively be determined by applying the chain rule of differentiation.
In the case of discrete units, f is a threshold function, so
that the backpropagation algorithm described above cannot be applied.
We remark, however, that the perceptron learning rUle 4 ,
~W ..

1J

= ?(T.1

- O.)S.
1

J

(10)

is nothing else than Eq. (9) with f' replaced by a constant ?.
Therefore, we propose that a generalized delta rule for linear
threshold units can be obtained if f' is replaced by a constant ? in
all the backpropagation expressions for of/oW ... This generalization
of the perceptron rule is, of course, not u1dque. In layered networks, e.g., the value of the constant which replaces f' need not be
the same for the different layers.

ANALYSIS OF LEARNING ALGORITHMS
The proposed learning algorithms suffer from all the problems
of gradient descent on a complicated landscape. If we use small
weight changes, learning becomes prohibitively slow, while large
weight changes inevitably lead to oscillations which prevent the
algorithm from converging to a good solution. The error surface,
moreover, may contain many local minima, so that gradient descent is
not guaranteed to find a global minimum.

75

There are several ways to improve a stochastic gradient descent
procedure. The weight changes may, e.g., be accumulated over a
number of learning examples before the weights are actually changed.
Another often used method consists in smoothing the weight changes
by overrelaxation,

of

~W ..

(k+1) = -~ ~W + a ~W .. (k)
a ..
1J
1J
1J

(11)

where ~W .. (k) refers to the weight change after the presentation of
the k-th 1 1earning example (or group of learning examples, respectively). The use of a weight decay term,
~W ..

1J

of
= -11 a~W
..
1J

- BW ..
1J

(12)

prevents the algorithm from generating very large weights which may
create such high barriers that a solution cannot be found in reasonable time.
Such smoothing methods suppress the occurrence of oscillations,
at least to a certain extent, and thus allow us to use higher learning rates. They cannot prevent, however, that the algorithm may
become trapped in bad local minimum. An obvious way to deal with the
problem of local minima is to restart the algorithm with different
initial weights or, equivalently, to randomize the weights with a
certain probability p during the learning procedure. More sophisticated approaches involve, e.g., the use of hill-climbing methods.
The properties of the error-surface over the weight space not
only depend on the choice of the error function F, but also on the
network architecture, on the type of units used, and on possible
restrictions concerning the values which the weights are allowed to
assume.
The performance of a learning algorithm thus depends on many
factors and parameters. These dependences are conveniently analyzed
in terms of the behavior of an appropriately defined learning curve.
For our small examples, where the learning set always consists of
all input/output cases, we have chosen to represent the performance
of a learning procedure by the fraction of networks that are
""perfect"" after the presentation of N input patterns. (Perfect networks are networks which for every input pattern produce the correct
output). Such learning curves give us much more detailed information
about the behavior of the system than, e. g., averaged quantities
like the mean learning time.
RESULTS
In the following, we shall present and discuss some representative results of our empirical study. All learning curves refer to
a set of 100 networks that have been exposed to the same learning
procedure, where we have varied the initial weights, or the sequence

76

of learning examples, or both. With one exception (Figure 4), the
sequences of learning examples are always random.
A prototype pattern association problem is the exclusive-or
(XOR) problem. Corresponding networks have two input units and one
output unit. Let us first consider an XOR-network with only one
hidden unit, but in which the input units also have direct connections to the output unit. The weights are symmetric, and we use the
deterministic version of the Boltzmann learning rule (see Eqs. (5)
to (7)). Figure 1 shows results for the case of tabula rasa initial
conditions, i.e. the initial weights are all set equal to zero. If
the weights are changed after every learning example, about 2/3 of
the networks learn the problem with less than 25 presentations per
pattern (which corresponds to a total number of 4 x 25 = 100 presentations). The remaining networks (about 1/3), however, never learn
to solve the XOR-problem, no matter how many input/output cases are
presented. This can be understood by analyzing the corresponding
evolution-tree in weight-space which contains an attractor consisting of 14 ""non-perfect"" weight-configurations. The probability to
become trapped by this attractor is exactly 1/3. If the weight
changes are accumulated over 4 learning examples, no such attractor

100
en
~

a::

80

I

.-w
z
.-u

60

??? ? ?000?
I-

-

?
??
?
?

-

w
a::

40

Q.

20 .....

lL.

i

ij

0

0

0

0

0

0

0

0

0

? ? ? ? ? ? ? ? ?

0

-

00
0
00

-

00

0

W

~

I

I

-

0

~

I

0

0

-

?0
0

~

0

.o.~.

0

I

I

I

I

20

40

60

80

100

#: PRESENTATIONS /PATTERN

Fig. 1. Learning curves for an XOR-network with one hidden unit
(deterministic Boltzmann learning, discrete ?I units, initial
weights zero). Full circles: weights changed after every learning
example; open circles: weight changes accumulated over 4 learning
examples.

77

seems to exist (see Fig. 1), but for some networks learning at least
takes an extremely long time . The same saturation effect is observed
with random initial weights (uniformly distributed between -1 and
+1), see Fig. 2.
Figure 2 also exhibits the difference in learning behavior
between networks with ?1 units and such with 0,1 units. In both
cases, weight randomization leads to a considerably improved learning behavior. A weight decay term, by the way, has the same effect.
The most striking observation, however, is that ?1 networks learn
much faster than 0,1 networks (the respective average learning times
differ by about a factor of 5). In this connection, we should mention
that ~ = 0.1 is about optimal for 0,1 units and that for ?1 networks
the learning behavior is practically independent of the value of ~.
It therefore seems that ?1 units lead to a much more well-behaved
error-surface than 0,1 units. One can argue, of course, that a
discrete 0,1 model can always be translated into a ?1 model, but
this would lead to an energy function which has a considerably more
complicated weight dependence than Eq. (5).

100

en
~
a:::

80

0

3:

....w
z

60

....

u

w

lL.

40

a:::

w
a..

~
0

20
0

2

5
#

10 20

50 100 200

1000

PRESENTATIONS / PATTERN

Fig. 2. Learning curves for an XOR-network with one hidden unit
(deterministic Boltzmann learning, initial weights random, weight
changes accumulated over 5 learning examples). Circles: discrete ?1
units, ~ = 1; triangles: discrete 0,1 units, ~ = 0.1; broken curves:
without weight randomization; solid curves: with weight randomization (p
0.025).

=

78

Figures 3 and 4 refer to a feedforward XOR-network with 3
hidden units, and to backpropagation or generalized delta rule
learning. In all cases we have included an overrelaxation (or momentum) term with a
0.9 (see Eq. (11?. For the networks with continuous units we have used the activation functions given by Eqs. (2)
and (3), respectively, and a network was considered ""perfect"" if for
all input/output cases the error was smaller than 0.1 in the 0,1
case, or smaller than 0.2 in the ?1 case, respectively.
In Figure 3, the weights have been changed after every learning
example, and all curves refer to an optimal choice of the only
remaining parameter, ?. or "", respectively. For discrete as well as
for continuous units, the ?1 networks again perform much better than
their 0,1 counterparts. In the continuous case, the average learning
times differ by about a factor of 7, and in the discrete case the
discrepancy is even more pronounced. In addition, we observe that in
?1 networks learning with the generalized delta rule for discrete
units is about twice as fast as with the backpropagation algorithm
for continuous units.

=

100~--~--~----~----~~~~--~--~

en

~

a::

80

0

~

I-

w

60

Z

I0

w
a::
w
a.

lL.

~

40
20

0

O~----~--~------~----~----~~~~--~

10

5

20

50

100

200

500 1000

:# PRESENTATIONS / PATTERN

Fig. 3. Learning curves for an XOR-network with three hidden units
(backpropagation/generalized delta rule, initial weights random,
weights changed after every learning example). Open circles: discrete ?1 units, ?. = 0.05; open triangles: discrete 0,1 units, ?. = 0.025;
full circles: continuous ?1 units, ""
0.125; full triangles; continuous 0,1 units, ""
0.25.

=

=

79

In Figure 4, the weight changes are accumulated over all 4
input/output cases, and only networks with continuous units are
considered. Also in this case, the ?1 units lead to an improved
learning behavior (the optimal Il-values are about 2.5 and 5.0,
respectively). They not only lead to significantly smaller learning
times, but ?1 networks also appear to be less sensitive with respect
to a variation of 11 than the corresponding 0,1 versions.
The better performance of the ?1 models with continuous units
can partly be attributed to the steeper slope of the chosen activation function, Eq. (3). A comparison with activation functions that
have the same slope, however, shows that the networks with ?1 units
still perform significantly better than those with 0,1 units. If the
weights are updated after every learning example, e.g., the reduction in learning time remains as large as a factor of 5. In the case
of backpropagation learning, the main reason for the better performance of ?1 units thus seems to be related to the fact that the
algorithm does not modify weights which emerge from a unit with
value zero. Similar observations have been made by Stornetta and
Huberman,s who further find that the discrepancies become even more
pronounced if the network size is increased.

100
""1
CI)
~

a:

=5.0

80

0

~

I-

w

z

60

I-

u
w

lL.

40

a:

w

a..

~
0

20
0
0

50
#

100

150

200

250

PRESENTATIONS I PATTERN

Fig. 4. Learning curves for an XOR-network with three hidden units
(backpropagation, initial weights random, weight changes accumulated
over all 4 input/output cases). Circles: continuous ?1 units;
triangles: continuous 0,1 units.

80

In Figure 5, finally, we present results for a network that
learns to detect mirror symmetry in the input pattern. The network
consists of one output, one hidden, and four input units which are '
also directly connected to the output unit. We use the deterministic
version of Boltzmann learning and change the weights after every
presentation of a learning pattern . If the weights are allowed to
assume arbitrary values, learning is rather slow and on average
requires almost 700 presentations per pattern. We have observed,
however, that the algorithm preferably seems to converge to solutions in which geometrically symmetric weights are opposite in sign
and almost equal in magnitude (see also Ref. 3). This means that the
symmetric input patterns are automatically treated as equivalent, as
their net input to the hidden as well as to the output unit is zero.
We have therefore investigated what happens if the weights are
forced to be antisymmetric from the beginning. (The learning procedure, of course, has to be adjusted such that it preserves this
antisymmetry). Figure 5 shows that such a problem-adapted weightstructure leads to a dramatic decrease in learning time.

100

en
~

?
??
?
?
??
?

80

a::
0

3:

I-

w
z

60

(,)

w

a::

0
0

0
0
0
0

?
?
???
?

lLL.

0

0

40

lLI

0
0

0
0

a..

~
0

20

0

2

0

?
??
10 20

5
#

0
0
0

0

50 100 200

500

2000

PRESENTATIONS I PATTERN

Fig. 5. Learning curves for a symmetry detection network with 4
input units and one hidden unit (deterministic Boltzmann learning,
11
1, discrete ?1 units, initial weights random, weights changed
after every learning example).
Full circles: symmetry-adapted
weights; open circles: arbitrary weights, weight randomization
(p
0.015).

=

=

81

CONCLUSIONS
The main results of our empirical study can be summarized as
follows:
- Networks with ?1 units quite generally exhibit a significantly
faster learning than the corresponding 0,1 versions.
- In addition, ?1 networks are often less sensitive to parameter variations than 0,1 networks.
- An adaptation of the weight-structure to the symmetries of the
problem can lead to a drastic improvement of the learning behavior.
Our qualitative interpretations seem to indicate that the observed effects should not be restricted to the small examples considered in this paper. It would be very valuable, however, to have
corresponding analytical results.
REFERENCES
1. ""Parallel Distributed Processing: Explorations in the Microstructure of Cognition"", vol. 1: ""Foundations"", ed. by D.E. Rumelhart
and J.L. McClelland (MIT Press, Cambridge), 1986, Chapters 7 & 8.
2. Y. Ie Cun, in ""Disordered Systems and Biological Organization"",
ed . by E. Bienenstock, F. Fogelman Soulie, and G. Weisbuch (Springer, Berlin), 1986, pp. 233-240.
3. D.E. Rumelhart, G.E. Hinton, and R.J. Williams, Nature 323, 533
(1986).
4. M.L. Minsky and S. Papert, ""Perceptrons"" (MIT Press, Cambridge),
1969.
5. W.S. Stornetta and B.A. Huberman, IEEE Conference on ""Neural Networks"", San Diego, California, 21-24 June 1987.

"
84,1987,"Presynaptic Neural Information Processing","",84-presynaptic-neural-information-processing.pdf,"Abstract Missing","154

PRESYNApnC NEURAL INFORMAnON PROCESSING
L. R. Carley
Department of Electrical and Computer Engineering
Carnegie Mellon University, Pittsburgh PA 15213

ABSTRACT
The potential for presynaptic information processing within the arbor
of a single axon will be discussed in this paper. Current knowledge about
the activity dependence of the firing threshold, the conditions required for
conduction failure, and the similarity of nodes along a single axon will be
reviewed. An electronic circuit model for a site of low conduction safety in
an axon will be presented. In response to single frequency stimulation the
electronic circuit acts as a lowpass filter.
I. INTRODUCTION
The axon is often modeled as a wire which imposes a fixed delay on a
propagating signal. Using this model, neural information processing is
performed by synaptically sum m ing weighted contributions of the outputs
from other neurons. However, substantial information processing may be
performed in by the axon itself. Numerous researchers have observed
periodic conruction failures at norma! physiological impulse activity rates
(e.g., in cat, in frog 2 , and in man ). The oscillatory nature of these
conduction failures is a result of the dependence of the firing threshold on
past impulse conduction activity.
The simplest view of axonal (presynaptic) information processing is
as a switch: the axon will either conduct an im pulse or not. The state of
the switch depends on how past impulse activity modulates the firing
threshold, which will result in conduction failure if firing threshold is bigger
than the incoming impulse strength. In this way, the connectivity of a
synaptic neural network could be modulated by past impulse activity at
sites of conduction failure within the network. More sophisticated
presynaptic neural information processing is possible when the axon has
more than one terminus, implying the existence of branch points within the
axon. Section II will present a general description of potential for
presynaptic information processing.
The after-effects of previous activity are able to vary the connectivity
of the axonal arbor at sites of low conduction safety according to the
temporal pattern of the impulse train at each site (Raymond and LeUvin,
1978; Raymond, 1979). In order to understand the inform ation processing
potential of presynaptic networks it is necessary to study the after- effects
of activity on the firing threshold. Each impulse is normally followed by a
brief refractory period (about 10m s in frog sciatic nerve) of increased

? American Institute of Phvl'if:<' 1qR~

155

threshold and a longer superexcitable period (about 1 s in frog sciatic
nerve) during which the threshold is actually below its resting level.
During prolonged periods of activity, there is a gradual increase in firing
threshold which can persist long (> 1 hour in frog nerve) after cessation
of im pulse activity (Raymond and Lettvin, 1978). In section III, the
methods used to measure the firing threshold and the after-effects of
activity will be presented.
In addition to understanding how impulse activity modulates sites of
low conduction safety, it is important to explore possible constraints on
the distribution of sites of low conduction safety within the axon's arbor.
Section IV presents results from a study of the distribution of the aftereffects of activity along an axon.
Section V presents an electronic circuit model for a region of low
conduction safety within an axonal arbor. It has been designed to have a
firing threshold that depends on the past activity in a manner similar to the
activity dependence measured for frog sciatic nerve.
II. PRESYNAPTIC SIGNAL PROCESSING
Conduction failure has been observed in many diffe~e~t organisms,
including man, at normal physiological activity rates. 1 , , The aftereffects of activity can ""modulate"" conduction failures at a site of low
conduction safety. One common place where the conduction safety is low
is at branch points where an impedance mismatch occurs in the axon.
In order to clarify the meaning of presynaptic information processing,
a simple example is in order. Parnas reported that in crayfish a single
axon separately activates the medial (DEA~~ and lateral (DEAL) branches
of the deep abdominal extensor muscles.' At low stimulus frequencies
(below 40-50 Hz) impulses travel down both branches; however, each
impulse evokes much smaller contractions in DEAL than in DEAM resulting
in contraction of DEAM without significant contraction of DEAL. At higher
stim ulus frequencies conduction in the branch leading to D EAM fails and
DEAL contracts without DEAM contracting. Both DEAL and DEAM can be
stim ulated separately by stim ulus patterns more com plicated than a single
frequency.
The theory of ""fallible trees"", which has been discussed by Lettvin,
McCulloch and Pitts, Raymond, and Waxman and Grossman among
others, suggests that one axon which branches many times forms an
information processing element with one input and many outputs. Thus,
the after-effects of previous activity are able to vary the connectivity of
the axonal arbor at regions of low conduction safety according to the
temporal pattern of the impulse train in each branch. The transfer function
of the fallible tree is determined by the distribution of sites of low
conduction safety and the distribution of superexcitability and depressibility
at those sites. Thus, a single axon with 1000 terminals can potentially be
in 2 1000 different states as a function of the locations of sites of conduction
failure within the axonal arbor. And, each site of low conduction safety is

156

modulated by the past impulse activity at that site.
Fallible trees have a number of interesting properties. They can be
used to cause different input frequencies to excite different axonal
terminals. Also, fallible trees, starting at rest, will preserve timing
information in the input signal; Le., starting from rest, all branches will
respond to the first impulse.
III. AFTER- EFFECTS OF ACTIVITY
In this section, the firing threshold will be defined and an experimental
method for its measurem ent will be described. In addition, the aftereffects of activity will be characterized and typical results of the
characterization process will be given.
The following method was used to measure the firing threshold.
Whole nerves were placed in the experimental setup (shown in figure 1).
The whole nerve fiber was stim ulated with a gross electrode. The
response from a single axon was recorded using a suction microelectrode.
Firing threshold was measured by applying test stimuli through the gross
stimulating electrode and looking for a response in the suction
m icroelectrode.

F ixed-duration
variable-amplitude
current stimulator

.

??
,

Ag-AgCI

Motordriven
vernier
micrometer

electrode
0?4 mm diameter
f--MOVES~

A

~;

Suction electrOdep'.
Single axon
\
Whole nerve

t'.
t.

lh

Refer~nce

~ suctIon

electrode

Figure 1. Drawing of the experimental recording chamber.

Threshold Hunting, a
was used to characterize
test stimulus which fails
increase the strength of

process forschoosin g the test stimulus strength,
the axons. It uses the following paradigm. A
to elicit a conducting impulse causes a small
subsequent test stimuli. A test stim ulus which

157

elicits an im pulse causes a small decrease in the strength of subsequent
test stimuli. Conditioning Stimuli, ones large enough to guarantee firing an
impulse, can be interspersed between test stimuli in order to achieve a
controlled overall activity rate. Rapid variations in threshold following one
or more conditioning impulses can be measured by slowly increasing the
time delay between the conditioning stimuli and the test stimulus. Several
phases follow each impulse. First, there is a refractory period of short
duration (about 10ms in frog nerve) during which another impulse cannot
be initiated. Following the refractory period the axon actually becomes
more excitable than at rest for a period (ranging from 200ms to 1 s in frog
nerve, see figure 2). The superexcitable period is measured by applying a
conditioning stimulus and then delaying by a gradually increasing time
delay and applying a test stimulus (see figure 3). There is only a slight
increase in the peak of the superexcitable period following multiple
im pulses? The superexcitability of an axon was characterized by the %
decrease of the threshold from its resting level at the peak of the
superexcitable period.
5'(1) fo, P, 0.50

?

5

+

:......-TO~

:_TO'Ald-~

1

1

CONO I TlONING

o~!_ _ _ _~~~I----~~~I~--17~~'---IOc~~Td
INTERVAL 'm.. c)

Figure 2. Typical superexcitable
period in axon from frog sciatic
nerve.

T[ST 5t IMULU5

.

T [5T 5T IMULUS

co NOI T 10NING

:_FRAMC 1 - ; - r R A M C

?-:-

Figure 3. Stim ulus pattern used
for measuring superexcitability.

During a period of repetitive impulse conduction, the firing threshold may
gradually increase. After the period of increased im pulse activity ends, the
threshold gradually recovers from its maximum over the course of several
minutes or more with complete return of the threshold to its resting level
taking as long as an hour or two (in frog nerve) depending on the extent of
the preceding im pulse activity. The depressibility of an axon can be
characterized by the initial upward slope of the depression and the time

158

constant of the recovery phase (see figure 4). The pattern of conditioning
and test stimuli used to generate the curve in figure 4 is shown in figure 5.
Depression may be correlated with microanatomical changes which
occur ira the glial cells in the nodal region during periods of increased
activity. During periods of repetitive stim ulation the size and num ber of
extracellular paranodal intramyelinic vacuoles increases causing changes
in the paranodal geom etry.
Cond.t.on.,,!!
burst

Test

Threshold \percenl.gt of rHling level)
200

120

40

?o+-'--5~-tO--15--2-0--2+-5--:'30
Time (min)

l'

r--

On

Figure 4. Typical depression in an
axon from frog sciatic nerve. The
average activity rate was 4
impulses/sec between the 5 min
mark and the 10 min mark.

5 min

>""

T

Time

~

Off

Figure 5. Stim ulus pattern used
for measuring depression.

IV. CONSTRAINTS ON FALLIBLE TREES
The basic fallible tree theo ry places no constraints on the distribution
of sites of conduction failure among the branches of a single axon. In this
section one possible constraint on the distribution of sites of conduction
failure will be presented. Experiments have been performed in an attempt
to determine if the extremely wide variations in superexcitability anS
depressibility found between nodes from different axons in a single nerve
(particularly for depressibility) also occur between nodes from the same
axon.
A study of the distribution of the after-effects of activity along an
unbranching length of frog sciatic nerve isund only sm all variations in the
after- effects along a single axon.
Both superexcitability and
depressibility were extremely consistent for nodes from along a single
unbranching length of axon (see figures 6 and 7). This suggests that there
may be a cell-wide regulatory system that maintains the depressibility and

159

superexcitability at com parable levels throug hout the extent of the axon.
Thus, portions of a fallible tree which have the same axon diameter would
be expected to have the same superexcitability and depressibility.

3.()

30

95
Superexcitability (%1

Figure 6. PDF of SuperexcitabiliThe upper trace represents
the PDF of the entire population
of nodes studied and the two
lower
traces
represent
the
separate populations of nodes
from two different axons.

ty.

0 -8

8 -0

2-5

25

80

Upward slope (""'/minl

Figure 7. PDF of Depressibility.
The upper trace represents the
PDF of the entire population of
nodes studied and the two lower
traces represent the separate
populations of nodes from two
different axons.

This study did not examine axons which branched, therefore it cannot be
concluded that superexcitability and depressibility must remain constant
throughout a fallible tree. For example, it is quite likely that the cell
actually regulates quantities like pump- site density, not depressibility. In
that case, daughter branches of smaller diameter might be expected to
show consistently higher depressibility. Further research is needed to
determine how the activity dependence of the threshold scales with axon
diameter along a single axon before the consistency of the after-effects
along an unbranching axon can be used as a constraint on presynaptic
information processing networks.
V. ELECTRICAL AXON CIRCUIT
This section presents a simple electronic circuit which has been
designed to have a firing threshold that depends on the past states of the
output in a manner similar to the activity dependence measured for frog
sciatic nerve. In response to constant frequency stimuli, the circuit acts as

160

a low pass filter whose corner frequency depends on the coefficients which
determine the after-effects of activity.
Figure B shows the circuit diagram for a switched capacitor circuit
which approximates the after- effects of activity found in the frog sciatic
nerve. The circuit employs a two phase nonoverlapping clock, e for the
even clock and 0 for the odd clock, typical of switched capacitor circuits.
It incorporates a basic model for superexcitability and depressibility. VTH
represents the resting threshold of the axon. On each clock cycle the V'N
is com pared with VTH+ Vo- Vs.
The two capacitors and three switches at the bottom of figure B model
the change in threshold caused by superexcitability. Note that each
impulse resets the comparator's minus input to (1-cx.)VTH, which decays
back to VTH on subsequent clock cycles with a time constant inversely
proportional to Ps. This is a slight deviation from the actual physiological
situation in which multiple conditioning im pulses will generate slightly more
superexcitability than a single impulse?
The two capacitors and two switches at the upper left of figure B
model the depressibility of the axon. The current source represents a
fixed increment in the firing threshold with every past impulse. The
depression voltage decays back to 0 on subsequent clock cycles with a
time constant inversely proportional to PO.

Figure B. Circuit diagram for electrical circuit analog of nerve threshold.

The electrical circuit exhibits response patterns similar to those of
neurons that are conducting intermittently (see figure 9). During bursts of
conduction, the depression voltage increases linearly until the comparator

161

fails to fire. The electrical axon then fails to fire until the depression
voltage decays back to (1 +aOV)VTH' The connectivity between the input
and output of the axon is defined to be the average fraction of impulses
which are conducted. In terms of connectivity, the electrical axon model
acts as a lowpass filter (see figure 10).

riftiNG
VD '
YES

tll4 Vs

,

??

NO

..

.

rlUINC ""'I1ACTI(lN

??

~

\

o :

vS
,00

10

300

T,,.a: ?Sl:CONUS I

Figure 9. Typical waveform s for
intermittent
conduction.
The
upper trace indicates whether
impulses are conducted or not.
VD and Vs are the depression
voltage and the superexcitable
voltage respectively.

o. :.I--~~----;-t-----;2r-------.c.
INruT

rR(: QVE~'

Figure 10. Frequency response of
electrical
axon
model.
The
connectivity is reflected by the
fraction of impulses which are
conducted out of a seq uence of
100.000
stimuli
where
the
frequency is in stim uli/second.

For a fixed stim ulus frequency. the average fraction of im pulses
which are conducted by the electrical model can be predicted analytically.
The expressions can be greatly simplified by making the assumption that
VD increases and decreases in a linear fashion. Under that assumption. in
terms of the variables indicated on the schematic diagram,

where M is the number of clock cycles between input stimuli. which is
inversely proportional to the input frequency. The frequency at which only
half of the impulses are conducted is defined as the corner frequency of
the low pass filter. The corner frequency is

162

f(P == 0.5)

_...!.
M

==

log(1-~D)
aD

log(1--)
aOV

Using the above equations, lowpass filters with any desired cutoff
frequency can be designed.
The analysis indicates that the corner frequency of the lowpass filter
can be varied by changing the degree of conduction safety (aov) without
changing either depressibility or superexcitability. This suggests that the
existence of a cell- wide regulatory system maintaining the depressibility
and superexcitability at comparable levels throughout the extent of the
axon would not prevent the construction of a bank of low pass filters since
their corner frequencies could still be varied by varying the degree of
conduction safety (aov).
VI. CONCLUSIONS
Recent studies report that the primary effect of several common
anesthetics is to abolish the activity dependence of the firing threshold
without interfering with impulse conduction. 11 This suggests that
presynaptic processing may play an important role in human
consciousness. This paper has explored some of the basic ideas of
presynaptic information processing, especially the after- effects of activity
and their modulation of impulse conduction at sites of low conduction
safety. A switched capacitor circuit which sim ulates the activity dependent
conduction block that occurs in axons has been designed and simulated.
Simulation results are very similar to the intermittent conduction patterns
measured experimentally in frog axons. One potential information
processing possibility for the arbor of a single axon, suggested by the
analysis of the electronic circuit, is to act as a filterbank; every terminal
could act as a lowpass filter with a different corner frequency.

BIBLIOGRAPHY

[1] Barron D. H. and B. H. C. Matthews, Intermittent conduction in the
spinal chord. J. Physiol. 85, p. 73-103 (1935).

163

[2]

Fuortes M. G. F., Action of strychnine on the ""intermittent
conduction"" of impulses along dorsal columns of the spinal chord of
frogs. J. Physiol. 112, p.42 (1950).

[3] Culp W. and J. Ochoa, Nerves and Muscles as Abnormal Impulse
Generators. (Oxford University Press, London, 1980).
[4] Grossman V., I. Parnas, and M. E. Spira, Ionic mechanisms involved
in differential conduction of action potentials at high frequency in a
branching axon. J. Physiol. 295, p.307 - 322 (1978).
[5] Parnas I., Differential block at high frequency of branches of a
single axon innervating two muscles. J. Physiol. 35, p. 903-914,
1972.
[6]

Carley, L.R. and S.A. Raymond, Threshold Measurement:
Applications to Excitable Membranes of Nerve and Muscle. J.
Neurosci. Meth. 9, p. 309 - 333 (1983).

[7] Raymond S. A. and J. V. Lettvin, After-effects of activity in
peripheral axons as a clue to nervous coding. In Physiology and
Pathobiology of Axons, S. G. Waxman (ed.), (Raven Press, New York,
1978), p. 203 - 225.
[8] Wurtz C. C. and M. H. Ellisman, Alternations in the ultrastructure of
peripheral nodes of Ranvier associated with repetitive action
potential propagation. J. Neurosci. 6(11), 3133- 3143 (1986).
[9] Raym ond S. A., Effects of nerve im pulses on threshold of frog
sciatic nerve fibers. J. Physiol. 290,273- 303 (1979).
[10] Carley, L.R. and S.A. Raymond, Com parison of the after- effects of
impulse conduction on threshold at nodes of Ranvier along single
frog Sciatic axons. J. Physiol. 386, p. 503 - 527 (1987).
[11] Raymond S. A. and J. G. Thalhammer, Endogenous activitydependent mechanisms for reducing hyperexcitability ofaxons:
Effects of anesthetics and CO 2 , In Inactivation of Hypersensistive
Neurons, N. Chalazonitis and M. Gola, (eds.), (Alan R. Liss Inc., New
Vork, 1987), p. 331-343.

"
85,1987,"Strategies for Teaching Layered Networks Classification Tasks","",85-strategies-for-teaching-layered-networks-classification-tasks.pdf,"Abstract Missing","850

Strategies for Teaching Layered Networks
Classification Tasks
Ben S. Wittner 1 and John S. Denker
AT&T Bell Laboratories
Holmdel, New Jersey 07733

Abstract
There is a widespread misconception that the delta-rule is in some sense guaranteed to
work on networks without hidden units. As previous authors have mentioned, there is
no such guarantee for classification tasks. We will begin by presenting explicit counterexamples illustrating two different interesting ways in which the delta rule can fail. We
go on to provide conditions which do guarantee that gradient descent will successfully
train networks without hidden units to perform two-category classification tasks. We
discuss the generalization of our ideas to networks with hidden units and to multicategory classification tasks.

The Classification Task
Consider networks of the form indicated in figure 1. We discuss various methods for
training such a network, that is for adjusting its weight vector, w. If we call the input
v, the output is g(w? v), where 9 is some function.
The classification task we wish to train the network to perform is the following. Given
two finite sets of vectors, Fl and F2, output a number greater than zero when a vector in
Fl is input, and output a number less than zero when a vector in F2 is input. Without
significant loss of generality, we assume that 9 is odd (Le. g( -s) == -g( s?. In that case,
the task can be reformulated as follows. Define 2

F :== Fl U {-v such that v E F2}

(1)

and output a number greater than zero when a vector in F is input. The former
formulation is more natural in some sense, but the later formulation is somewhat more
convenient for analysis and is the one we use. We call vectors in F, training vectors.

A Class of Gradient Descent Algorithms
We denote the solution set by
W :== {w such that g(w? v) > 0 for all v E F},
lCurrently at NYNEX Science and Technology, 500 Westchester Ave., White Plains, NY 10604
2 We use both A := Band B =: A to denote ""A is by definition B"".

@

American Institute of Physics 1988

(2)

851

output

inputs
Figure 1: a simple network
and we are interested in rules for finding some weight vector in W. We restrict our
attention to rules based upon gradient'descent down error functions E(w) of the form

E(w) =

L h(w . v).

(3)

VEF

The delta-rule is of this form with
1
h(w . v) = h6(W . v) := -(b - g(w . v))2
2

(4)

for some positive number b called the target (Rumelhart, McClelland, et al.). We call
the delta rule error function E 6 .

Failure of Delta-rule Using Obtainable Targets
Let 9 be any function that is odd and differentiable with g'(s) > 0 for all s. In this
section we assume that the target b is in the range of g. We construct a set F of
training vectors such that even though M' is not empty, there is a local minimum of E6
not located in W. In order to facilitate visualization, we begin by assuming that 9 is
linear. We will then indicate why the construction works for the nonlinear case as well.
We guess that this is the type of counter-example alluded to by Duda and Hart (p. 151)
and by Minsky and Papert (p. 15).
The input vectors are two dimensional. The arrows in figure 2 represent the training
vectors in F and the shaded region is W. There is one training vector, vI, in the second
quadrant, and all the rest are in the first quadrant. The training vectors in the first
quadrant are arranged in pairs symmetric about the ray R and ending on the line L.
The line L is perpendicular to R, and intersects R at unit distance from the origin.
Figure 2 only shows three of those symmetric pairs, but to make this construction work
we might need many. The point p lies on R at a distance of g-l(b) from the origin .
We first consider the contribution to E6 due to any single training vector, v. The
contribution is
(5)
(1/2)(b - g(w? v))2,
and is represented in figure 3 in the z-direction. Since 9 is linear and since b is in the

\

p,

,""

.....

\

\

,

,'c""

\

, ,.

, R

,
, L
\

X-axis

853

x-axis

Figure 3: Error surface
We now remove the assumption that 9 is linear. The key observation is that
dh6/ds == h/(s) = (b - g(s?( -g'(s?

(6)

still only has a single zero at g-l(b) and so h(s) still has a single minimum at g-l(b).
The contribution to E6 due to the training vectors in the first quadrant therefore still
has a global minimum on the xy-plane at the point p. So, as in the linear case, if there
are enough symmetric pairs of training vectors in the first quadrant, the value of Eo
at p can be made arbitrarily lower than the value along some circle in the xy-plane
centered around p, and E5 = Eo + El will have a local minimum arbitrarily near p.

Q.E.D.

Failure of Delta-rule Using Unobtainable Targets
We now consider the case where the target b is greater than any number in the range
of g. The kind of counter-example presented in the previous section no longer exists,
but we will show that for some choices of g, including the traditional choices, the delta
rule can still fail. Specifically, we construct a set F of training vectors such that even
though W is not empty, for some choices of initial weights, the path traced out by going
down the gradient of E5 never enters W.

854
y-axis

,

,

"",.,-P

4
J'=----~----~--~
L
q , __ ....

:,

,

,
,
,

,:~

x-axis

Figure 4: Counter-example for unobtainable targets
We suppose that 9 has the following property. There exists a number r > 0 such that

. hs'( -rs)
hm h 5'()
=
S

_-00

(7)

o.

An example of such a 9 is

9(S)

2

= tanh(s) = 1 + e- 2., -

1,

(8)

for which any r greater than 1 will do.
The solid arrows in figure 4 represent the training vectors in F and the more darkly
shaded region is W. The set F has two elements,
and

v2

The dotted ray, R lies on the diagonal {y

= x}.

=mm[n

(9)

Since

(10)

855

the gradient descent algorithm follows the vector field

-v E(w) =

-h/(w?

h/(w. V 2 )V 2 .

V1)V 1 -

(11)

The reader can easily verify that for all won R,

(12)
So by equation (7), if we constrain w to move along R,
.
-h/(w. vI)
hm
,
2 = O.
w ...... oo -h o (w . v )

(13)

Combining equations (11) and (13) we see that there is a point q somewhere on R such
that beyond q, - V E( w) points into the region to the right of R, as indicated by the
dotted arrows in figure 4.
Let L be the horizontal ray extending to the right from q. Since for all s,

g'(s) > 0

and

b> g(s),

(14)

o.

(15)

we get that
- h/(s) = (b - g(s?g'(s) >

So since both vI and v 2 have a positive y-component, -V E(w) also has a positive
y-component for all w. So once the algorithm following -V E enters the region above
L and to the right of R (indicated by light shading in figure 4), it never leaves. Q.E.D.

Properties to Guarantee Gradient Descent Learning
In this section we present three properties of an error function which guarantee that
gradient descent will not fail to enter a non-empty W.
We call an error function of the form presented in equation (3) well formed if h is
differentiable and has the following three properties.

1. For all s, -h'( s) ~ 0 (i.e. h does not push in the wrong direction).

2. There exists some f > 0 such that -h'(s)
if there is a misclassification).

~ f

for all s

~

0 (i.e. h keeps pushing

3. h is bounded below.

Proposition 1 If the error junction is well formed, then gradient descent is guaranteed
to enter W, provided W is not empty.

856

The proof proceeds by contradiction. Suppose for some starting weight vector the path
traced out by gradient descent never enters W. Since W is not empty, there is some
non-zero w* in W. Since F is finite,
A := min{w*. v such that v E F} -:> O.

(16)

Let wet) be the path traced out by the gradient descent algorithm. So

w'(t) = -VE(w(t? =

I:: -h'(w(t) ?v)v

for all t.

(17)

vEF

Since we are assuming that at least one training vector is misclassified at all times, by
properties 1 and 2 and equation (17),
w* . w'(t) 2: fA
So
Iw'(t)1 2: fA/lw*1 =:

for all t.

e> 0

(18)

for all t.

(19)

By equations (17) and (19),

dE(w(t?/dt = V E? w'(t)

= -w'(t) . w'(t) ~ -e < 0

for all t.

(20)

This means that

E(w(t?

--+ -00

as

t

--+ 00.

(21)

But property 3 and the fact that F is finite guarantee that E is bounded below. This
contradicts equation (21) and finishes the proof.

Consensus and Compromise
So far we have been concerned with the case in which F is separable (i.e. W is not
empty). What kind of behavior do we desire in the non-separable case? One might
hope that the algorithm will choose weights which produce correct results for as many
of the training vectors as possible. We suggest that this is what gradient descent using
a well formed error function does.
From investigations of many well formed error functions, we suspect the following well
formed error function is representative. Let g( s) = s, and for some b > 0, let

h(S)={ (b-s)2

o

ifs~~;

otherwIse.

(22)

In all four frames of figure 5 there are three training vectors. Training vectors 1 and 2
are held fixed while 3 is rotated to become increasingly inconsistent with the others. In
frames (i) and (ii) F is separable. The training set in frame (iii) lies just on the border
between separability and non-separability, and the one in frame (iv) is in the interior of

857

i)

3

ii )

3

2

1

iv)

iii)

2

3

...

L.1

2

1

3

Figure 5: The transition between seperability and non-seperability
the non-separable regime. Regardless of the position of vector 3, the global minimum
of the error function is the only minimum.
In frames (i) and (ii), the error function is zero on the shaded region and the shaded
region is contained in W. As we move training vector number 3 towards its position in
frame (iii), the situation remains the same except the shaded region moves arbitrarily
far from the origin. At frame (iii) there is a discontinuity; the region on which the
error function is at its global minimum is now the one-dimensional ray indicated by
the shading. Once training vector 3 has moved into the interior of the non-separable
regime, the region on which the error function has its global minimum is a point closer
to training vectors 1 and 2 than to 3 (as indicated by the ""x"" in frame (iv?.
If all the training vectors can be satisfied, the algorithm does so; otherwise, it tries to
satisfy as many as possible, and there is a discontinuity between the two regimes. We
summarize this by saying that it finds a consensus if possible, otherwise it devises a
compromise.

Hidden Layers
For networks with hidden units, it is probably impossible to prove anything like proposition 1. The reason is that even though property 2 assures that the top layer of weights

858

gets a non-vanishing error signal for misclassified inputs, the lower layers might still get
a vanishingly weak signal if the units above them are operating in the saturated regime.
We believe it is nevertheless a good idea to use a well formed error function when
training such networks. Based upon a probabilistic interpretation of the output of the
network, Baum and Wilczek have suggested using an entropy error function (we thank
J.J. Hopfield and D.W. Tank for bringing this to our attention). Their error function
is well formed. Levin, Solla, and Fleisher report simulations in which switching to the
entropy error function from the delta-rule introduced an order of magnitude speed-up
of learning for a network with hidden units.

Multiple Categories
Often one wants to classify a given input vector into one of many categories. One popular
way of implementing multiple categories in a feed-forward network is the following. Let
the network have one output unit for each category. Denote by oj(w) the output of
the j-th output unit when input v is presented to the network having weights w. The
network is considered to have classified v as being in the k-th category if

or(w) > oj(w) for all j ~ k.

(23)

The way such a network is usually trained is the generalized delta-rule (Rumelhart,
McClelland, et al.). Specifically, denote by c(v) the desired classification of v and let

b""! .= {b
1

?

if j = c(v);
-b otherwise,

(24)

for some target b > O. One then uses the error function

E(w):=

EE
(bj - oj (w?)
v
.

2

?

(25)

3

This formulation has several bothersome aspects. For one, the error function is not will
formed. Secondly, the error function is trying to adjust the outputs, but what we really
care about is the differences between the outputs. A symptom of this is the fact that
the change made to the weights of the connections to any output unit does not depend
on any of the weights of the connections to any of the other output units.
To remedy this and also the other defects of the delta rule we have been discussing, we
suggest the following. For each v and j, define the relative coordinate
(26)

859

What we really want is all the

13 to be positive, so use the error function

E(w):=

E E

h (f3j(w))

(27)

v #c(v)

for some well formed h. In the simulations we have run, this does not always help, but
sometimes it helps quite a bit.
We have one further suggestion. Property 2 of a well formed error function (and the
fact that derivatives are continuous) means that the algorithm will not be completely
satisfied with positive 13; it will try to make them greater than zero by some non-zero
margin. That is a good thing, because the training vectors are only representatives of
the vectors one wants the network to correctly classify. Margins are critically important
for obtaining robust performance on input vectors not in the training set. The problem
is that the margin is expressed in meaningless units; it makes no sense to use the same
numerical margin for an output unit which varies a lot as is used for an output unit
which varies only a little. We suggest, therefore, that for each j and v, keep a running
estimate of uj(w), the variance of f3J(w), and replace f3J(w) in equation (27) by

f3J (w)/uj (w).

(28)

Of course, when beginning the gradient descent, it is difficult to have a meaningful
estimate of uj(w) because w is changing so much, but as the algorithm begins to
converge, your estimate can become increasingly meaningful.

References
1. David Rumelhart, James McClelland, and the PDP Research Group, Parallel Dis-

tributed Processing, MIT Press, 1986
2. Richard Duda and Peter Hart, Pattern Classification and Scene Analysis, John
Wiley & Sons, 1973.
3. Marvin Minsky and Seymour Papert, ""On Perceptrons"", Draft, 1987.
4. Eric Baum and Frank Wilczek, these proceedings.
5. Esther Levin, Sara A. Solla, and Michael Fleisher, private communications.

"
86,1987,"SPONTANEOUS AND  INFORMATION-TRIGGERED SEGMENTS OF SERIES OF HUMAN BRAIN ELECTRIC FIELD MAPS","",86-spontaneous-and-information-triggered-segments-of-series-of-human-brain-electric-field-maps.pdf,"Abstract Missing","467

SPONTANEOUS AND INFORMATION-TRIGGERED SEGMENTS OF SERIES
OF HUMAN BRAIN ELECTRIC FIELD MAPS
D. lehmann, D. Brandeis*, A. Horst, H. Ozaki* and I. Pal*
Neurol09Y Department, University Hospital, 8091 Zurich, Switzerland
ABSTRACT
The brain works in a state-dependent manner: processin9
strate9ies and access to stored information depends on the momentary
functional state which is continuously re-adjusted. The state is
manifest as spatial confi9uration of the brain electric field.
Spontaneous and information-tri9gered brain electric activity is a
series of momentary field maps. Adaptive segmentation of spontaneous
series into spatially stable epochs (states) exhibited 210 msec mean
segments, discontinuous changes. Different maps imply different
active neural populations, hence expectedly different effects on
information processing: Reaction time differred between map classes
at stimulus arrival. Segments might be units of brain information
processin9 (content/mode/step), possibly operationalizin9
consciousness time. Related units (e.9. tri9gered by stimuli durin9
fi9ure perception and voluntary attention) mi9ht specify brain submechanisms of information treatment.
BRAIN FUNCTIONAL STATES AND THEIR CHANGES
The momentary functional state of the brain is reflected by the
confi9uration of the brain's electro-ma9netic field. The state
manifests the strate9Y, mode, step and content of brain information
processing, and the state constrains the choice of strate9ies and
modes and the access to memory material available for processin9 of
incoming information (1). The constraints include the available
range of changes of state in PAVLOV's classical ?orienting reaction""
as response to new or important informations. Different states mi9ht
be viewed as different functional connectivities between the neural
elements.
The orienting reaction (see 1,2) is the result of the first
(Mpre-attentiveM) stage of information processing. This stage
operates automatically (no involvement of consciousness) and in a
parallel mode, and quickly determines whether (a) the information is
important or unknown and hence requires increased attention and
alertness, i.e. an orienting reaction which means a re-adjustment of
functional state in order to deal adequately with the information
invokin9 consciousness for further processing, or whether (b) the
information is known or unimportant and hence requires no readjustment of state, i.e. that it can be treated further with well* Present addresses: D.B. at Psychiat. Dept., V.A. Med. Center, San
Francisco CA 94121; H.O. at lab. Physiol. for the Developmentally
Handicapped, Ibaraki Univ., Mito, Japan 310; I.P. at Biol09ic
Systems Corp., Mundelein Il 60060.
? American Institute of Physics 1988

468

established (?automatic?) strategies. Conscious strategies are slow
but flexible (offer wide choice), automatic strategies are fast but
rigid.
Examples for functional states on a gross scale are wakefulness,
drowsin.ss and sleep in adults, or developmental stages as infancy,
childhood and adolesc.nce, or drug states induced by alcohol or
other psychoactive agent ?? The different states are associated with
distinctly different ways of information processing. For example, in
normal adults, reality-close, abstracting strategies based on causal
relationships predominate during wakefulness, whereas in drowsiness
and sleep (dreams), reality-remote, visualizing, associative
concatenations of contents are used. Other well-known examples are
drug states.
HUMAN BRAIN ELECTRIC FIELD DATA AND STATES
While alive, the brain produces an ever-changing el.ctromagnetic
fi.ld, which very sensitively reflects global and local states as
effected by spontaneous activity, incoming information, metabolism,
drugs, and diseases. The .lectric component of the brain~s electromagnetic field as non-invasively measured from the intact human
scalp shows voltages between 0.1 and 250 microVolts, temporal
fr.quencies between 0.1 and 30, 100 or 3000 Hz depending on the
examined function, and spatial frequencies up to 0.2 cycles/em.
Brain electric field data are traditionally viewed as time series
of potential differences betwe.n two scalp locations (the
electroencephalogram or EE6). Time series analysis has offered an
effective way to class different gross brain functional states,
typically using EE6 power spectral values. Differences between power
spectra during different gross states typically are greater than
between different locations. States of lesser functional complexity
such as childhood vs adult states, sleep vs wakefulness, and many
drug-state. vs non-drug states tend to increased power in slower
frequencies (e.g. 1,4).
Time series analyses of epochs of intermediate durations between
30 and 10 seconds have demonstrated (e.g. 1,5,6) that there are
significant and reliable relations between spectral power or
coh.rency values of EE6 and characteristics of human mentation
(reality-close thoughts vs free associations, visual vs non-visual
thoughts, po.itive vs negative ~otions).
Viewing brain electric field data as series of momentary field
maps (7,8) opens the possibility to investigate the temporal
microstructure of brain functional states in the sub-second range.
The rationale is that the momentary configuration of activated
neural elements represents a given brain functional state, and that
the spatial pattern of activation is reflected by the momentary
brain electric field which is recordable on the scalp as a momentary
field map. Different configurations of activation (different field
maps) are expected to be associated with different modes,
strategies, steps and contents of information processing.

469

SE(J1ENTATI~

OF BRAIN ELECTRIC HAP SERIES INTO STABLE SE(J1ENTS

When Viewing brain electric activity as series of maps of
momentary potential distributions, changes of functional state are
recognizable as changes of the ?electric landscapes? of these maps.
Typically, several successive maps show similar landscapes, then
quickly change to a new configuration which again tends to persist
for a number of successive maps, suggestive of stable states
concatenated by non-linear transitions (9,10). Stable map landscapes
might be hypothesized to indicate the basic building blocks of
information processing in the brain, the -atoms of thoughts?. Thus,
the task at hand is the recognition of the landscape configurations;
this leads to the adaptive segmentation of time series of momentary
maps into segments of stable landscapes during varying durations.
We have proposed and used a method which describes the
configuration of a momentary map by the locations of its maximal and
minimal potential values, thus invoking a dipole model. The goal
here is the phenomenological recognition of different momentary
functional states using a very limited number of major map features
as classifiers, and we suggest conservative interpretion of the data
as to real brain locations of the generating processes which always
involve millions of neural elements.
We have studied (11) map series recorded from 16 scalp locations
over posterior skull areas from normal subjects during relaxation
with closed eyes. For adaptive segmentation, the maps at the times
of maximal map relief were selected for optimal signal/nOise
conditions. The locations of the maximal and minimal (extrema)
potentials were extracted in each map as descriptors of the
landscape; taking into account the basically periodic nature of
spontaneous brain electric activity (Fig. 1), extrema locations were
treated disregarding polarity information. If over time an extreme
left its pre-set spatial window (say, one electrode distance), the
segment was terminated. The map series showed stable map
configurations for varying durations (Fig. 2), and discontinuous,
step-wise changes. Over 6 subjects, resting alpha-type EEG showed
210 msec mean segment duration; segments longer than 323 msec
covered 50% of total time; the most prominent segment class (1.5% of
all classes) covered 20% of total time (prominence varied strongly
over classes; not all possible classes occurred). Spectral power and
phase of averages of adaptive and pre-determined segments
demonstrated the adequacy of the strategy and the homogeneity of
adaptive segment classes by their reduced within-class variance.
Segmentation using global map dissimilarity (sum of Euklidian
difference vs average reference at all measured points) emulates the
results of the extracted-characteristics-strategy.
FUNCTIONAL SIGNIFICANCE OF MOMENTARY MICRO STATES
Since different maps of momentary EEG fields imply activity of
different neural populations, different segment classes must
manifest different brain functional states with expectedly different

470

189 to 189

117 to 117

125 to 125

132 to 132

WItS

148 to 148

148 to 148

156 to 156

164 to 164

WItS

171 to 171
179 to 179
RECORD=1 FILE=A:VP3EC2A

187 to 187
195 to 195 WItS
NORMAL SUBJECT, EYES CLOSED

Fig. 1. Series of momentary potential distribution maps of the brain
field recorded from the scalp of a normal human during relaxation
with closed eyes. Recording with 21 electrodes (one 5-electrode row
added to the 16-electrode array in Fig. 2) using 128 samples/sec/
channel. Head seen from above, left ear left; white positive, dark
negative, 8 levels from +32 to -32 microVolts. Note the periodic
reversal of field polarity within the about 100 msec (one cycle of
the 8-12Hz so-called ?EEG alpha- activity) while the field configuration remains largely constant. - This recording and display was
done with a BRAIN ATLAS system (Biologic Systems, Mundelein, Il).
effects on ongoing information processing. This was supported by
measurements of selective reaction time to acoustic stimuli which
were randomly presented to eight subjects during different classes
of EEG segments (323 responses for each subject). We found
significant reaction time differences over segment classes (ANOVA p
smaller than .02), but similar characteristics over subjects. This
indicates that the momentary sub-second state as manifest in the
potential distribution map significantly influences the behavioral
consequence of information reaching the brain.
Presentation of information is followed by a sequence of
potential distribution maps (Nevent-related potentials? or ERP's,
averaged over say, 100 presentations of the same stimulus, see 12).
The different spatial configurations of these maps (12) are thought
to reflect the sequential stages of information processing
associated with Mcomponents? of event-related brain activity (see
e.g. 13) which are traditionally defined as times of maximal
voltages after information input (maximal response strength).

471

45

'-X_ - - L . ..-7

2

""

l
/

~~' ~,~.4
:

:

~'

3

5

4

,5

\' .~

,.,.

55

56

'

3

'

,

59

'X-_

.l..LU..L/

Fig. 2. Sequence of spatially stable segments durin9 a spontaneous
series of momentary EEG maps of 3.1 sec duration in a normal
volunteer. Each map shows the occurrence of the extreme potential
values durin9 one adaptively determined segment: the momentary maps
were searched for the locations of the two extreme potentials; these
locations were accumulated, and linearly interpolated between
electrodes to construct the present maps. (The number of isofrequency-of-occurrence lines therefore is related to the number of
searched maps). - Head seen from above, left ear left, electrode
locations indicated by crosses, most forward electrode at vertex.
Data FIR filtered to 8-12Hz (alpha EEG). The fi9ure to the left
below each map is a running segment number. The figure to the ri9ht
above each map multiplied by 50 indicates the segment duration in
msec.
Application of the adaptive segmentation procedure described above
for identification of functional components of event-related brain
electric map sequences requires the inclusion of polarity
information (14); such adaptive segmentation permits to separate
different brain functional states without resortin9 to the strength
concept of processing stages.
An example (12) might illustrate the type of results obtained
with this analysis: Given segments of brain activity which were
triggered by visual information showed different map configurations
when subjects paid attention vs when they paid no attention to the
stimulus, and when they viewed figures vs meanin9less shapes as

472

LVF

RVF

Fig. 3. Four difference maps, computed as differences between maps
obtained during (upper row) perception of a visual -illusionarytriangle figure (left picture) minus a visual non-figure (right)
shown to the left and right visual hemi-fields (LVF, RVF) , and
obtained during (lower row) attending minus during ignoring the
presented display. The analysed segment covered the time from 168 to
200 msec after stimulus presentations. - Mean of 12 subjects. Head
seen from above, left ear left, 16 electrodes as in Fig. 2,
isopotential contour lines at 0.1 microVolt steps, dotted negative
referred to mean of all values. The -illusionary- figure stimulus
wa. studied by Kanisza (16); see also (12). - Note that the mirror
symmetric configuration of the difference maps for LVF and RVF is
found for the -figure- effect only, not for the -attention- effect,
but that the anterior-posterior difference is similar for both cases.
stimuli. Fig. 3 illustrates such differences in map configuration.
The -attention--induced and -figureR-induced changes in map
configuration showed certain similarities e.g. in the illustrated
segment 168-200 msec after information arrival, supporting the
hypothesis that brain mechanisms for figure perception draw on brain
resources which in other circumstances are utilized in volontary
attention.
The spatially homogeneous temporal segments might be basic
building blocks of brain information processing, possibly
operationalizing consciousness time (15), and offering a common
concept for analysis of brain spontaneous activity and event related
brain potentials. The functional significance of the segments might
be types/ modes/ steps of brain information processing or
performance. Identification of related building blocks during
different brain functions accordingly could specify brain submechanisms of information treatment.

473

Acknowledgement: Financial support by the Swiss National Science
Foundation (including Fellowships to H.O. and I.P.) and by the 8HDO,
the Hartmann Muller and the SANDOZ Foundation is gratefully
acknowledged.

REFERENCES
1.
2.
3.

4.
5.

6.

7.
8.

9.
10.
11.
12.
13.
14.
15.
16.

M. Koukkou and D. Lehmann, Brit. J. Psychiat. 142, 221-231
(1983).
A. Ohman, In: H.D. Kimmel, E.H. von Olst and J.F. Orlebeke
(Eds.), Drug-Discrimination and State Dependent Learning
(Academic Press, New York, 1979), pp. 283-318.
A. Katada, H. Ozaki, H. Suzuki and K. Suhara, Electroenceph.
Clin. Neurophysiol. 52, 192-201 (1981).
M. Koukkou and D. Lehmann, BioI. Psychiat. 11, 663-677 (1976).
J. Berkhout, D.O. Walter and W.R. Adey, Electroenceph. clin.
Neurophysiol. 27, 457-469 (1969).
P. Grass, D. Lehmann, B. Meier, C.A. Meier and I. Pal, Sleep
Res. 16, 231 (1987).
D. Lehmann, Electroenceph. Clin. Neurophysiol. 31, 439-449
{1971).
D. Lehmann, In: H.H. Petsche and M.A.B. Brazier (eds.),
Synchronization of EEG Activity in Epilepsies (Springer, Wien,
1972), pp. 307-326.
H. Haken, Advanced Synergetics (Springer, Heidelberg, 1983).
J.J. Wright, R.R. Kydd and G.L. Lees, BioI. Cybern., 1985, 53,
11-17.
D. Lehmann, H. Ozaki and I. Pal, Electroenceph. Clin.
Neurophysiol. 67, 271-288 (1987).
D. Brandeis and D. Lehmann, Neuropsychologia 24, 151-168 (1986).
A.S. Gevins, N.H. Morgan, S.L. Bressler, B.A. Cutillo, R.M.
White, J. Illes, D.S. Greer, J.C.Doyle and M. Zeitlin, Science
235,580-585 (1987).
D. Lehmann and W. Skrandies, Progr. Neurobiol. 23, 227-250
(1984).
B. Libet, Human Neurobiol. 1, 235-242 (1982).
G. Kanisza, Organization of Vision (Praeger, New York, 1979).

"
87,1987,"High Order Neural Networks for Efficient Associative Memory Design","",87-high-order-neural-networks-for-efficient-associative-memory-design.pdf,"Abstract Missing","233

HIGH ORDER NEURAL NETWORKS FOR EFFICIENT
ASSOCIATIVE MEMORY DESIGN

I. GUYON?, L. PERSONNAZ?, J. P. NADAL?? and G. DREYFUS?
? Ecole Superieure de Physique et de Chimie Industrielles de la Ville de Paris
Laboratoire d'Electronique
10, rue Vauquelin
75005 Paris (France)
?? Ecole Normale Superieure
Groupe de Physique des Solides
24, rue Lhomond
75005 Paris (France)

ABSTRACT

We propose learning rules for recurrent neural networks with high-order
interactions between some or all neurons. The designed networks exhibit the
desired associative memory function: perfect storage and retrieval of pieces
of information and/or sequences of information of any complexity.
INTRODUCTION

In the field of information processing, an important class of potential
applications of neural networks arises from their ability to perform as
associative memories. Since the publication of J. Hopfield's seminal paper 1,
investigations of the storage and retrieval properties of recurrent networks
have led to a deep understanding of their properties. The basic limitations of
these networks are the following:
- their storage capacity is of the order of the number of neurons;
- they are unable to handle structured problems;
- they are unable to classify non-linearly separable data.
? American Institute of Physics 1988

234

In order to circumvent these limitations, one has to introduce additional
non-linearities. This can be done either by using ""hidden"", non-linear units, or
by considering multi-neuron interactions2 . This paper presents learning rules
for networks with multiple interactions, allowing the storage and retrieval,
either of static pieces of information (autoassociative memory), or of temporal
sequences (associative memory), while preventing an explosive growth of the
number of synaptic coefficients.
AUTOASSOCIATIVE MEMORY

The problem that will be addressed in this paragraph is how to design an
autoassociative memory with a recurrent (or feedback) neural network when
the number p of prototypes is large as compared to the number n of neurons.
We consider a network of n binary neurons, operating in a synchronous
mode, with period t. The state of neuron i at time t is denoted by (Ji(t), and the
state of the network at time t is represented by a vector ~(t) whose
components are the (Ji(t). The dynamics of each neuron is governed by the
following relation:
(Ji(t+t) = sgn vi(t).
(1 )
In networks with two-neuron interactions only, the potential vi(t) is a linear
function of the state of the network:

For autoassociative memory design, it has been shown 3 that any set of
correlated patterns, up to a number of patterns p equal to 2 n, can be made the
stable states of the system, provided the synaptic matrix is computed as the
orthogonal projection matrix onto the subspace spanned by the stored
vectors. However, as p increases, the rank of the family of prototype vectors
will increase, and finally reach the value of n. In such a case, the synaptic
matrix reduces to the identity matrix, so that all 2 n states are stable and the
energy landscape becomes flat. Even if such an extreme case is avoided, the
attractivity of the stored states decreases with increasing p, or, in other terms,

235

the number of fixed points which are not the stored patterns increases; this
problem can be alleviated to a large extent by making a useful use of these
""spurious"" fixed points4. Another possible solution consists in ""gardening"" the
state space in order to enlarge the basins of attraction of the fixed points5.
Anyway, no dramatic improvements are provided by all these solutions since
the storage capacity is always O(n).
We now show that the introduction of high-order interactions between
neurons, increases the storage capacity proportionally to the number of
connections per neuron. The dynamical behaviour of neuron i is still governed
by (1). We consider two and three-neuron interactions, extension to higher
order are straightforward.
The potential vi (t) is now defi ned as

It is more convenient, for the derivation of learning rules, to write the potential
in the matrix form:
~(t) =

C ;t(t),

where :?(t) is an m dimensional vector whose components are taken among
the set of the (n 2+n)/2 values: a1 , ... , an' a1 a2 , ... , aj al ' ... , a n-1 an.
As in the case of the two-neuron interactions model, we want to compute the
interaction coefficients so that the prototypes are stable and attractor states.
A condition to store a set of states Q:k (k=1 to p) is that y'k= Q:k for all k. Among
the solutions, the most convenient solution is given by the (n,m) matrix
c=I,r l

(2)

where I, is the (n,p) matrix whose columns are the Q:k and rl is the (p,m)
pseudoinverse of the (m,p) matrix r whose columns are the { . This solution
satisfies the above requirements, up to a storage capacity which is related to
the dimension m of vectors :?. Thus, in a network with three-neuron

236

interactions, the number of patterns that can be stored is O(n 2). Details on
these derivations are published in Ref.6.
By using only a subset of the products {aj all. the increase in the number of
synaptic coefficients can remain within acceptable limits, while the attractivity
of the stored patterns is enhanced, even though their number exceeds the
number of neurons ; this will be examplified in the simulations presented
below.
Finally, it can be noticed that, if vector ~contains all the {ai aj}' i=1, ... n, j=1, ... n,
only, the computation of the vector potential ~=C~can be performed after the
following expression:

where ~ stands for the operation which consists in squaring all the matrix
coefficients. Hence, the computation of the synaptic coefficients is avoided,
memory and computing time are saved if the simulations are performed on a
conventional computer. This formulation is also meaningful for optical
implementations, the function ell being easily performed in optics 7.
In order to illustrate the capabilities of the learning rule, we have performed
numerical simulations which show the increase of the size of the basins of
attraction when second-order interactions, in addition to the first-order ones,
are used. The simulations were carried out as follows. The number of neurons
n being fixed, the amount of second-order interactions was chosen ; p
prototype patterns were picked randomly, their components being ?1 with
probability 0.5 ; the second-order interactions were chosen randomly. The
synaptic matrix was computed from relation (2). The neural network was
forced into an initial state lying at an initial Hamming distance Hi from one of
the prototypes {!k ; it was subsequently left to evolve until it reached a stable
state at a distance Hf from {!k. This procedure was repeated many times for
each prototype and the Hf were averaged over all the tests and all the
prototypes.
Figures 1a. and 1b. are charts of the mean values of Hf as a function of the
number of prototypes, for n = 30 and for various values of m (the dimension of

237

vector ':/.). These curves allowed us to determine the maximum number of
prototype states which can be stored for a given quality of recall. Perfect recall
implies Hf =0 ; when the number of prototypes increases, the error in recall
may reach Hf =H i : the associative memory is degenerate. The results
obtained for Hi In =10% are plotted on Figure 1a. When no high-order
interactions were used, Hf reached Hi for pIn = 1, as expected; conversely,
virtually no error in recall occured up to pIn = 2 when all second-order
interactions were taken into account (m=465). Figure 1b shows the same
quantities for Hi=20 0/0 ; since the initial states were more distant from the
prototypes, the errors in recall were more severe.
1.2

1.2

1.0

1.0

0.8

0.8

0.6

:f
A 0.6

:f

A

f

f

v

(8)

0.4

v

0.2

0.2

0.0

0.0
2

0

3

(b)

0.4

2

0

3

pIn

pIn

Fig. 1. Improvement of the attractivity by addition of three-neuron interactions
to the two-neuron interactions. All prototypes are always stored exactly (all
curves go through the origin). Each point corresponds to an average over
min(p,10) prototypes and 30 tests for each prototype.
[] Projection: m = n = 30; ?
1 a: Hi I n =10 %

;

m = 120 ; ?

m = 180;

0

m = 465 (all interactions)

1 b : Hi In =20%.

TEMPORAL SEQUENCES (ASSOCIATIVE MEMORY)

The previous section was devoted to the storage and retrieval of items of
information considered as fixed points of the dynamics of the network
(autoassociative memory design). However, since fully connected neural
networks are basically dynamical systems, they are natural candidates for

238

storing and retrieving information which is dynamical in nature, i.e., temporal
sequences of patterns8: In this section, we propose a general solution to the
problem of storing and retrieving sequences of arbitrary complexity, in
recurrent networks with parallel dynamics.
Sequences consist in sets of transitions between states {lk_> Q:k+ 1, k=1, ... , p.
A sufficient condition to store these sets of transitions is that y..~ Q:k+ 1 for all k.
In the case of a linear potential y""=C Q:, the storage prescription proposed in
ref.3 can be used:
C=r,+r,I,
where r, is a matrix whose columns are the Q:k and r,+ is the matrix whose
columns are the successors Q:k+ 1 of Q:k. If P is larger than n, one can use
high-order interactions, which leads to introduce a non-linear potential Y..=C ';f. ,
with ';f. as previously defined. We proposed in ref. 10 the following storage
prescription :
(3)

The two above prescriptions are only valid for storing simple sequences,
where no patterns occur twice (or more). Suppose that one pattern occurs
twice; when the network reaches this bifurcation point, it is unable to make a
decision according the deterministic dynamics described in (1), since the
knowledge of the present state is not sufficient. Thus, complex sequences
require to keep, at each time step of the dynamics, a non-zero memory span.
The vector potential Y..=C':J. must involve the states at time t and t-t, which
leads to define the vector ';f. as a concatenation of vectors Q:(t), ~(t-t), Q:(t)?Q:(t),
Q:(t)?Q:(t-t), or a suitable subset thereof. The subsequent vector Q:(t+t) is still
determined by relation (1). In this form, the problem is a generalization of the
storage of patterns with high order interactions, as described above. The
storage of sequences can be still processed by relation (3).
The solution presented above has the following features:
i) Sequences with bifurcation points can be stored and retrieved.
ii) The dimension of the synaptic matrix is at most (n,2(n 2+n)), and at least
(n,2n) in the linear case, so that at most 2n(n2+n) and at least 2n2 synapses
are required.

239

iii) The storage capacity is O(m), where m is the dimension of the vector ';t .
iv) Retrieval of a sequence requires initializing the network with two states in
succession.
The example of Figure 2 illustrates the retrieval performances of the latter
learning rule. We have limited vector ';t to Q:(t}?Q:(t-t). In a network of n=48
neurons, a large number of poems have been stored, with a total of p=424
elementary transitions. Each state is consists in the 6 bit codes of 8 letters.

ALOUETTE
JETE
PLUMERAI
ALOUETTE
GENTILLE
ALOUETTE
ALOUETTE
JETE
PLUMERAI

JE NE
OLVMERAI
AQFUETTE
JEHKILLE
SLOUETTE
ALOUETTE
JETE
PLUMERAI

Fig. 2. One of the stored poems is shown in the first column. The network is
initialized with two states (the first two lines of the second column). After a few
steps, the network reaches the nearest stored sequence.
LOCAL LEARNING

Finally, it should be mentioned that all the synaptic matrices introduced in this
paper can be computed by iterative, local learning rules.
For autoassociative memory, it has been shown analytically9 that the
procedure:
with Cij(O) = 0,
which is a Widrow-Hoff type learning rule, yields the projection matrix, when

240
the number of presentations of the prototypes {~k} goes to infinity, if the latter
are linearly independent.
A derivation along the same lines shows that, by repeated presentations of
the prototype transitions, the learning rules:

lead to the exact solutions (relations (2) and (3) respectively), if the vectors }<
are Ii nearly independent.
GENERALIZATION TASKS

Apart from storing and retrieving static pieces of information or sequences,
neural networks can be used to solve problems in which there exists a
structure or regularity in the sample patterns (for example presence of clumps,
parity, symmetry ... ) that the network must discover. Feed-forward networks
with multiple layers of first-order neurons can be trained with
back-propagation algorithms for these purposes; however, one-layer
feed-forward networks with mUlti-neuron interactions provide an interesting
alternative. For instance, a proper choice of vector ':I. (second-order terms only)
with the above learning rule yields a perfectly straightforward solution to the
exclusive-OR problem. Maxwell et al. have shown that a suitable high-order
neuron is able to exhibit the ""ad hoc network solution"" for the contiguity
problem 11.
CONCLUSION

The use of neural networks with high-order interactions has long been
advocated as a natural way to overcome the various limitations of the Hopfield
model. However, no procedure guaranteed to store any set of information as
fixed points or as temporal sequences had been proposed. The purpose of
the present paper is to present briefly such storage prescriptions and show

241

some illustrations of the use of these methods. Full derivations and extensions
will be published in more detailed papers.

REFERENCES
1.
2.

J. J. Hopfield, Proc. Natl. Acad. Sci. (USA) la, 2554 (1982).
P. Peretto and J. J. Niez, BioI. Cybern. M, 53 (1986).
P. Baldi and S. S. Venkatesh, Phys. Rev. Lett . .5.6 , 913 (1987).
For more references see ref.6.

3.

L. Personnaz, I. Guyon, G. Dreyfus,

J. Phys. Lett. ~ , 359 (1985).

L. Personnaz, I. Guyon, G. Dreyfus, Phys. Rev. A ~ , 4217 (1986).
4.

I. Guyon, L. Personnaz, G. Dreyfus, in ""Neural Computers"", R. Eckmiller
and C. von der Malsburg eds (Springer, 1988).

5.

E. Gardner, Europhys. Lett . .1, 481 (1987).
G. Poppel and U.Krey, Europhys. Lett.,.1, 979 (1987).

6.

L. Personnaz, I. Guyon, G. Dreyfus, Europhys. Lett. .1,863 (1987).

7.

D. Psaltis and C. H. Park, in ""Neural Networks for Computing"", J. S. Denker
ed., (A.I.P. Conference Proceedings 151, 1986).

8.

P. Peretto,

J. J. Niez, in ""Disordered Systems and Biological Organization"",

E. Bienenstock, F. Fogelman, G. Weisbush eds (Springer, Berlin 1986).
S. Dehaene, J. P. Changeux,

J. P. Nadal, PNAS

(USA)~, 2727 (1987).

D. Kleinfeld, H. Sompolinsky, preprint 1987.
J. Keeler, to appear in

J. Cog. Sci.

For more references see ref. 9.
9.

I. Guyon, L. Personnaz, J.P. Nadal and G. Dreyfus, submitted for
publication.

10. S. Diederich, M. Opper, Phys. Rev. Lett . .5.6, 949 (1987).
11. T. Maxwell, C. Lee Giles, Y. C. Lee, Proceedings of ICNN-87, San Diego,
1987.

"
88,1987,"Speech Recognition Experiments with Perceptrons","",88-speech-recognition-experiments-with-perceptrons.pdf,"Abstract Missing","144

SPEECH RECOGNITION EXPERIMENTS
WITH PERCEPTRONS

D. J. Burr
Bell Communications Research
Morristown, NJ 07960

ABSTRACT
Artificial neural networks (ANNs) are capable of accurate recognition of
simple speech vocabularies such as isolated digits [1]. This paper looks at two
more difficult vocabularies, the alphabetic E-set and a set of polysyllabic
words. The E-set is difficult because it contains weak discriminants and
polysyllables are difficult because of timing variation. Polysyllabic word
recognition is aided by a time pre-alignment technique based on dynamic programming and E-set recognition is improved by focusing attention. Recognition accuracies are better than 98% for both vocabularies when implemented
with a single layer perceptron.
INTRODUCTION
Artificial neural networks perform well on simple pattern recognition
tasks. On speaker trained spoken digits a layered network performs as accurately as a conventional nearest neighbor classifier trained on the same tokens
[1]. Spoken digits are easy to recognize since they are for the most part
monosyllabic and are distinguished by strong vowels.
It is reasonable to ask whether artificial neural networks can also solve
more difficult speech recognition problems. Polysyllabic recognition is difficult
because multi-syllable words exhibit large timing variation. Another difficult
vocabulary, the alphabetic E-set, consists of the words B, C, D, E, G, P, T, V,
and Z. This vocabulary is hard since the distinguishing sounds are short in
duration and low in energy.
We show that a simple one-layer perceptron [7] can solve both problems
very well if a good input representation is used and sufficient examples are
given. We examine two spectral representations - a smoothed FFT (fast
Fourier transform) and an LPC (linear prediction coefficient) spectrum. A
time stabilization technique is described which pre-aligns speech templates
based on peaks in the energy contour. Finally, by focusing attention of the
artificial neural network to the beginning of the word, recognition accuracy of
the E-set can be consistently increased.
A layered neural network, a relative of the earlier percept ron [7], can be
trained by a simple gradient descent process [8]. Layered networks have been
? American Institute of Physics 1988

145

applied successflJ.lly to speech recognition [1], handwriting recognition [2], and
to speech synthesis [11]. A variation of a layered network [3] uses feedback to
model causal constraints, which can be useful in learning speech and language.
Hidden neurons within a layered network are the building blocks that are used
to form solutions to specific problems. The number of hidden units required is
related to the problem [1,2]. Though a single hidden layer can form any mapping [12], no more than two layers are needed for disjunctive normal form [4].
The second layer may be useful in providing more stable learning and
representation in the presence of noise. Though neural nets have been shown
to perform as well as conventional techniques[I,5], neural nets may do better
when classes have outliers [5].
PERCEPTRONS
A simple perceptron contains one input layer and one output layer of
neurons directly connected to each other (no hidden neurons). This is often
called a one-layer system, referring to the single layer of weights connecting
input to output. Figure 1. shows a one-layer perceptron configured to sense
speech patterns on a two-dimensional grid. The input consists of a 64-point
spectrum at each of twenty time slices. Each of the 1280 inputs is connected
to each of the output neurons, though only a sampling of connections are
shown. There is one output neuron corresponding to each pattern class. Neurons have standard linear-weighted inputs with logistic activation.
C(1)

C(2)

C(N-1)

C(N)

FR:<lBC'V ....
64 units

Figure 1. A single layer perceptron sensing a time-frequency array of sample
data. Each output neuron CU) (1 <i<N) corresponds to a pattern class and
is full connected to the input array (for clarity only a few connections are
shown).
An input word is fit to the grid region by applying an automatic endpoint
detection algorithm. The algorithm is a variation of one proposed by Rabiner
and Sambur [9] which employs a double threshold successive approximation

146

method. Endpoints are determined by first detecting threshold crossings of
energy and then of zero crossing rate. In practice a level crossing other than
zero is used to prevent endpoints from being triggered by background sounds.
INPUT REPRESENTATIONS
Two different input representations were used in this study. The first is a
Fourier representation smoothed in both time and frequency. Speech is sampled at 10 KHz ap.d Hamming windowed at a number of sample points. A
128-point FFT spectrum is computed to produce a template of 64 spectral
samples at each of twenty time frames. The template is smoothed twice with a
time window of length three and a frequency window of length eight.
For comparison purposes an LPC spectrum is computed using a tenth
order model on 300-sample Hamming windows. Analysis is performed using
the autocorrelation method with Durbin recursion [6]. The resulting spectrum
is smoothed over three time frames.
Sample spectra for the utterance ""neural-nets"" is shown in Figure 2.
Notice the relative smoothness of the LPC spectrum which directly models
spectral peaks.
FFT

LPC

Figure 2. FFT and LPC time-frequency plots for the utterance ""neural nets"".
Time is toward the left, and frequency, toward the right.
DYNAMIC TIME ALIGMv1ENT
Conventional speech recognition systems often employ a time normalization technique based on dynamic programming [10]. It is used to warp the
time scales of two utterances to obtain optimal alignment between their spectral frames. We employ a variation of dynamic programming which aligns
energy contours rather than spectra. A reference energy template is chosen
for each pattern class, and incoming patterns are warped onto it. Figure 3
shows five utterances of ""neural-nets"" both before and after time alignment.
Notice the improved alignment of energy peaks.

147

?

I

?

?

?

I

~

II

~

~

!I

!

>-

\b

~

III

z

W

.. ..
(a. )

10

10

...
TIME

(b)

Figure 3. (a) Superimposed energy plots of five different utterances of ""neural
nets"". (b). Same utterances after dynamic time alignment.

POLYSYLLABLE RECOGNITION
Twenty polysyllabic words containing three to five syllables were chosen,
and five tokens of each were recorded by a single male speaker. A variable
number of tokens were used to train a simple perceptron to study the effect of
training set size on performance. Two performance measures were used:
classification accuracy, and an RMS error measure. Training tokens were permuted to obtain additional experimental data points.

Figure 4. Output responses of a perceptron trained with one token per class
(left) and four tokens per class (right).

148

Figure 4 shows two representative perspective plots of the output of a
perceptron trained on one and four tokens respectively per class. Plots show
network response (z-coordinate) as a function of output node (left axis) and
test word index (right axis). Note that more training tokens produce a more
ideal map - a map should have ones along the diagonal and zeroes everywhere
else.
Table 1 shows the results of these experiments for three different
representations: (1) FFT, (2) LPC and (3) time aligned LPC. This table lists
classification accuracy as a function of number of training tokens and input
representation. The perceptron learned to classify the unseen patterns perfectly for all cases except the FFT with a single training pattern.

Table 1. Polysyllabic
Number Training Tokens
FFT
LPC
Time Aligned LPC
Permuted Trials

Word Recognition
2
1
98.7%
100%
100%
100%
100%
100%
400
300

AccuraclT
3
100%
100%
100%
200

4

100%
100%
100%
100

A different performance measure, the RMS error, evaluates the degree to
which the trained network output responses Rjk approximate the ideal targets
T jk ? The measure ""is evaluated over the N non-trained tokens and M output
nodes of the network. Tik equals 1 for J=k and 0 for J=I=k.

Figure 5 shows plots of RMS error as a function of input representation
and training patterns. Note that the FFT representation produced the highest
error, LPC was about 40% less, and time-aligned LPC only marginally better
than non-aligned LPC. In a situation where many choices must be made (i.e.
vocabularies much larger than 20 words) LPC is the preferred choice, and
time alignment could be useful to disambiguate similar words. Increased
number of training tokens results in improved performance in all cases.

149

o

ci

,-----------------------------~

'""0

..

FFT

i
""!
l-

I-

ii

0

5

0

g

W
tJl
~

LPC

a:

'""0
0

o
o

TIme Aligned LPC

~--~----~--~----~__~____~

1.0

2.0

3.0

4.0

Number Traln'ng Tokens

Figure 5. RMS error versus number of training tokens for various input
representations.

E-SET VOCABULARY
The E-Set vocabulary consists of the nine E-words of the English alphabet - B, C, D, E, G, P, T, V, Z. Twenty tokens of each of the nine classes
were recorded by a single male speaker. To maximize the sizes of training and
test sets, half were used for training and the other half for testing. Ten permutations produced a total of 900 separate recognition trials.
Figure 6 shows typical LPC templates for the nine classes. Notice the
double formant ridge due to the ''E'' sound, which is common to all tokens.
Another characteristic feature is the FO ridge - the upward fold on the left of
all tokens which characterizes voicing or pitched sound.

150

Figure 6. LP C time-frequency plots for representative tokens of the E-set
words.

Figure 7. Time-frequency plots of weight values connected to each output
neuron ''E'' through ""z"" in a trained perceptron.

151

Figure 7 shows similar plots illustrating the weights learned by the network when trained on ten tokens of each class. These are plotted like spectra,
since one weight is associated with each spectral sample. Note that the patterns have some formant structure. A recognition accuracy of 91.4% included
perfect scores for classes C, E, and G.
Notice that weights along the FO contour are mostly small and some are
slightly negative. This is a response to the voiced ''E"" sound common to all
classes. The network has learned to discount ""voicing"" as a discriminator for
this vocabulary.
Notice also the strong ""hilly"" terrain near the beginning of most templates. This shows where the network has decided to focus much of its
discriminating power. Note in particular the hill-valley pair at the beginning
of ''p'' and ""T"". These are near to formants F2/F3 and could conceivably be
formant onset detectors. Note the complicated detector pattern for the ''V''
sound.
The classes that are easy to discriminate (C, E, G) produce relatively fiat
and uninter~sting weight spaces. A highly convoluted weight space must
therefore be correlated with difficulty in discrimination. It makes little sense
however that the network should be working hard in the late time C'E"" sound)
portion of the utterance. Perhaps additional training might reduce this
activity, since the network would eventually find little consistent difference
there.
A second experiment was conducted to help the network to focus attention. The first k frames of each input token were averaged to produce an average spectrum. These average spectra were then used in a simple nearest
neighbor recognizer scheme. Recognition accuracy was measured as a function
of k. The highest performance was for k=8, indicating that the first 40% of
the word contained most of the ""action"".

Figure 8.
word.

E

C

P

T

0

0

0

0

0

0

100 0

0

0

0

0

0

0

D

0

0

08

0

0

2

0

0

0

E

0

0

0

100 0

0

0

0

0

c

0

0

0

0

100 0

0

0

0

p

0

0

3

0

0

03

4

0

0

T

0

0

0

0

0

0

100 0

0

V

2

0

0

0

0

2

0

0

Z

0

0

0

0

0

0

0

B

C

B

08

c

D

V

Z

0

08

09

Confusion matrix of the E-set focused on the first 40% of each

152

All words were resampled to concentrate 20 time frames into the first
40% of the word. LPC spectra were recomputed using a 16th order model
and the network was trained on the new templates. Performance increased
from 91.4% to 98.2%. There were only 16 classification errors out of the 900
recognition tests. The confusion matrix is shown in Figure 8. Learning times
for all experiments consisted of about ten passes through the training set.
When weights were primed with average spectral values rather than random
values, learning time decreased slightly.
CONCLUSIONS
Artificial neural networks are capable of high performance in pattern
recognition applications, matching or exceeding that of conventional
classifiers. We have shown that for difficult speech problems such as time
alignment and weak discriminability, artificial neural networks perform at
high accuracy exceeding 98%. One-layer perceptrons learn these difficult tasks
almost effortlessly - not in spite of their simplicity, but because of it.
REFERENCES
1. D. J. Burr, ""A Neural Network Digit Recognizer"", Proceedings of IEEE
Conference on Systems, Man, and Cybernetics, Atlanta, GA, October, 1986,
pp. 1621-1625.

2. D. J. Burr, ""Experiments with a Connectionist Text Reader,"" IEEE International Conference on Neural Networks, San Diego, CA, June, 1987.
3. M. I. Jordan, ""Serial Order: A Parallel Distributed Processing Approach,""
ICS Report 8604, UCSD Institute for Cognitive Science, La Jolla, CA, May
1986.
4. S. J. Hanson, and D. J. Burr, 'What Connectionist Models Learn: Toward
a Theory of Representation in Multi-Layered Neural Networ.ks,"" submitted for
pu blication.
5. W. Y. Huang and R. P. Lippmann, ""Comparisons Between Neural Net and
Conventional Classifiers,"" IEEE International Conference on Neural Networks,
San Diego, CA, June 21-23, 1987.
6. J. D. Markel and A. H. Gray, Jr., Linear Prediction of Speech, SpringerVerlag, New York, 1976.
7. M. L. Minsky and S. Papert, Perceptrons, MIT Press, Cambridge, Mass.,
1969.

153

8. D. E. Rumelhart, G. E. Hinton, and R. J. Williams, ''Learning Internal
Representations by Error Propagation,"" in Parallel Distributed Processing,
Vol. 1, D. E. Rumelhart and J. L. McClelland, eds., MIT Press, 1986, pp. 318362.
9. L. R. Rabiner and M. R. Sambur, ""An Algorithm for Determining the Endpoints of Isolated Utterances,"" BSTJ, Vol. 54,297-315, Feb. 1975.
10. H. Sakoe and S. Chiba, ""Dynamic Programming Optimization for Spoken
Word Recognition,"" IEEE Trans. Acoust., Speech, Signal Processing, Vol.
ASSP-26, No.1, 43-49, Feb. 1978.
11. T. J. Sejnowski and C. R. Rosenberg, ""NETtalk: A Parallel Network that
Learns to Read Aloud,"" Technical Report JHU/EECS-86/01, Johns Hopkins
University Electrical Engineering and Computer Science, 1986.
12. A. Wieland and R. Leighton, ""Geometric Analysis of Neural Network
Capabilities,"" IEEE International Conference on Neural Networks, San Deigo,
CA, June 21-24, 1987.

"
89,1987,"Neural Network Implementation Approaches for the Connection Machine","",89-neural-network-implementation-approaches-for-the-connection-machine.pdf,"Abstract Missing","127

Neural Network Implementation Approaches
for the
Connection Machine
Nathan H. Brown, Jr.
MRJlPerkin Elmer, 10467 White Granite Dr. (Suite 304), Oakton, Va. 22124

ABSlRACf
The SIMD parallelism of the Connection Machine (eM) allows the construction of
neural network simulations by the use of simple data and control structures. Two
approaches are described which allow parallel computation of a model's nonlinear
functions, parallel modification of a model's weights, and parallel propagation of a
model's activation and error. Each approach also allows a model's interconnect
structure to be physically dynamic. A Hopfield model is implemented with each
approach at six sizes over the same number of CM processors to provide a performance
comparison.
INTRODUCflON
Simulations of neural network models on digital computers perform various
computations by applying linear or nonlinear functions, defined in a program, to
weighted sums of integer or real numbers retrieved and stored by array reference. The
numerical values are model dependent parameters like time averaged spiking frequency
(activation), synaptic efficacy (weight), the error in error back propagation models, and
computational temperature in thermodynamic models. The interconnect structure of a
particular model is implied by indexing relationships between arrays defined in a
program. On the Connection Machine (CM), these relationships are expressed in
hardware processors interconnected by a 16-dimensional hypercube communication
network. Mappings are constructed to defme higher dimensional interconnectivity
between processors on top of the fundamental geometry of the communication
network. Parallel transfers are defined over these mappings. These mappings may be
dynamic. CM parallel operations transform array indexing from a temporal succession
of references to memory to a single temporal reference to spatially distributed
processors.
Two alternative approaches to implementing neural network simulations on the CM
are described. Both approaches use ""data parallelism"" 1 provided by the *Lisp virtual
machine. Data and control structures associated with each approach and performance
data for a Hopfield model implemented with each approach are presented.
DATA STRUCTURES
The functional components of a neural network model implemented in *Lisp are
stored in a uniform parallel variable (pvar) data structure on the CM. The data structure
may be viewed as columns of pvars. Columns are given to all CM virtual processors.
Each CM physical processor may support 16 virtual processors. In the fust approach
described, CM processors are used to represent the edge set of a models graph
structure. In the second approach described, each processor can represent a unit, an
outgoing link, or an incoming link in a model's structure. Movement of activation (or
error) through a model's interconnect structure is simulated by moving numeric values

? American Institute of Physics 1988

128

over the eM's hypercube. Many such movements can result from the execution of a
single CM macroinstruction. The CM transparently handles message buffering and
collision resolution. However, some care is required on the part of the user to insure
that message traffic is distributed over enough processors so that messages don't stack
up at certain processors, forcing the CM to sequentially handle large numbers of
buffered messages. Each approach requires serial transfers of model parameters and
states over the communication channel between the host and the CM at certain times in a
simulation.
The first approach, ""the edge list approach,"" distributes the edge list of a network
graph to the eM, one edge per CM processor. Interconnect weights for each edge are
stored in the memory of the processors. An array on the host machine stores the
current activation for all units. This approach may be considered to represent abstract
synapses on the eM. The interconnect structure of a model is described by product
sets on an ordered pair of identification (id) numbers, rid and sid. The rid is the id of
units receiving activation and sid the id of units sending activation. Each id is a unique
integer. In a hierarchical network, the ids of input units are never in the set of rids and
the ids of output units are never in the set of sids. Various set relations (e.g. inverse,
reflexive, symmetric, etc.) defined over id ranges can be used as a high level
representation of a network's interconnect structure. These relations can be translated
into pvar columns. The limits to the interconnect complexity of a simulated model are
the virtual processor memory limits of the CM configuration used and the stack space
~uired by functions used to compute the weighted sums of activation. Fig. 1 shows a
R -> R2 -> R4 interconnect structure and its edge list representation on the CM.
6

7

8

:z
eM PROCESSOR

0 1 2 3 4

9

3

5 6 7 8 9 1 0111213

f if

:~ (~?,';)H f HHH ff
SAcr

( 8j ) 1 2 3 1 2 3 4 5 4 5 4 5 4 5

Fig. 1. Edge List Representation of a R3_> R2 -> R4 Interconnect Structure
This representation can use as few as six pvars for a model with Hebbian
adaptation: rid (i), sid (j), interconnect weight (wij), ract (ai), sact (aj), and learn rate
(11)? Error back propagation requires the addition of: error (ei), old interconnect
weight (wij(t-l?, and the momentum term (ex). The receiver and sender unit
identification pvars are described above. The interconnect weight pvar stores the
weight for the interconnect. The activation pvar, sact, stores the current activation, aj'
transfered to the unit specified by rid from the unit specified by sid. The activation
pvar, ract, stores the current weighted activation ajwij- The error pvar stores the error
for the unit specified by the sid. A variety of proclaims (e.g. integer, floating point,
boolean, and field) exist in *Lisp to define the type and size ofpvars. Proclaims
conserve memory and speed up execution. Using a small number of pvars limits the

129

amount of memory used in each CM processor so that maximum virtualization of the
hardware processors can be realized. Any neural model can be specified in this fashion.
Sigma-pi models require multiple input activation pvars be specified. Some edges may
have a different number of input activation pvars than others. To maintain the uniform
data structure of this approach a tag pvar has to be used to determine which input
activation pvars are in use on a particular edge.
The edge list approach allows the structure of a simulated model to ""physically""
change because edges may be added (up to the virtual processor limit), or deleted at any
time without affecting the operation of the control structure. Edges may also be placed
in any processor because the subselection (on rid or sid) operation performed before a
particular update operation insures that all processors (edges) with the desired units are
selected for the update.
The second simulation approach, ""the composite approach,"" uses a more
complicated data structure where units, incoming links, and outgoing links are
represented. Update routines for this approach use parallel segmented scans to form
the weighted sum of input activation. Parallel segmented scans allow a MIMD like
computation of the weighted sums for many units at once. Pvar columns have unique
values for unit, incoming link, and outgoing link representations. The data structures
for input units, hidden units, and output units are composed of sets of the three pvar
column types. Fig. 2 shows the representation for the same model as in Fig. 1
implemented with the composite approach.
2

o1

3

5

4

6

7

8

9

2 3 4 5 6 7 8 9 101112 1314151617181920212223242526272829303132333435

rr, f~ ~\'~~Ii~

c - -?.

c

o

c - -?.

+----+
lol

IO~ O.~~
~

~~+-t+*~
t -~. - ~
II I(

II I(

I

Fig. 2. Composite Representation of a R3 -> R2 -> R4 Interconnect Structure
In Fig. 2, CM processors acting as units, outgoing links, and incoming links are
represented respectively by circles, triangles, and squares. CM cube address pointers
used to direct the parallel transfer of activation are shown by arrows below the
structure. These pointers defme the model interconnect mapping. Multiple sets of
these pointers may be stored in seperate pvars. Segmented scans are represented by
operation-arrow icons above the structure. A basic composite approach pvar set for a
model with Hebbian adaptation is: forward B, forward A, forward transfer address,
interconnect weight (Wij), act-l (ai), act-2 (aj), threshold, learn rate (Tl), current unit id
(i), attached unit id U), level, and column type. Back progagation of error requires the
addition of: backward B, backward A, backward transfer address, error (ei), previous
interconnect weight (Wij(t-l?, and the momentum tenn (ex). The forward and
backward boolean pvars control the segmented scanning operations over unit
constructs. Pvar A of each type controls the plus scanning and pvar B of each type
controls the copy scanning. The forward transfer pvar stores cube addresses for

130

forward (ascending cube address) parallel transfer of activation. The backward transfer
pvar stores cube addresses for backward (descending cube address) parallel transfer of
error. The interconnect weight, activation, and error pvars have the same functions as
in the edge list approach. The current unit id stores the current unit's id number. The
attached unit id stores the id number of an attached unit. This is the edge list of the
network's graph. The contents of these pvars only have meaning in link pvar columns.
The level pvar stores the level of a unit in a hierarchical network. The type pvar stores
a unique arbitrary tag for the pvar column type. These last three pvars are used to
subselect processor ranges to reduce the number of processors involved in an
operation.
Again, edges and units can be added or deleted. Processor memories for deleted
units are zeroed out. A new structure can be placed in any unused processors. The
level, column type, current unit id, and attached unit id values must be consistent with
the desired model interconnectivity.
The number of CM virtual processors required to represent a given model on the
CM differs for each approach. Given N units and N(N-1) non-zero interconnects (e.g.
a symmetric model), the edge list approach simply distributes N(N-1) edges to N(N-1)
CM virtual processors. The composite approach requires two virtual processors for
each interconnect and one virtual processor for each unit or N +2 N (N-1) CM virtual
processors total. The difference between the number of processors required by the two
approaches is N2. Table I shows the processor and CM virtualization requirements for
each approach over a range of model sizes.
TABLE I Model Sizes and CM Processors Required
Run No. Grid Size Number of Units Edge List Quart CM Virt. Procs. Virt. LeveL
N(N-1)
1
2
3
4
5
6

82
92
112
13 2
162
192

64
81
121
169
256
361

4032
6480
14520
28392
65280
129960

8192
8192
16384
32768
65536
131072

0
0
0
2
4
8

Run No. Grid Size Number of Units Composite Quart CM Virt. Procs. Virt. LeveL
N+2N(N-1)
7
8
9
10
11
12

82
92
112
132
162
192

64
81
121
169
256
361

8128
13041
29161
56953
130816
260281

8192
16384
32768
65536
131072
262144

0
0
2
4
8
16

131

CONTROL STRUCTURES
The control code for neural network simulations (in *Lisp or C*) is stored and
executed sequentially on a host computer (e.g. Symbolics 36xx and V AX 86xx)
connected to the CM by a high speed communication line. Neural network simulations
executed in *Lisp use a small subset of the total instruction set: processor selection
reset (*all), processor selection (*when), parallel content assignment (*set), global
summation (*sum), parallel multiplication (*!! ), parallel summation (+! I), parallel
exponentiation (exp! I), the parallel global memory references (*pset) and (pref! I), and
the parallel segmented scans (copy!! and +!!). Selecting CM processors puts them in a
""list of active processors"" (loap) where their contents may be arithmetically manipulated
in parallel. Copies of the list of active processors may be made and used at any time. A
subset of the processors in the loap may be ""subselected"" at any time, reducing the loap
contents. The processor selection reset clears the current selected set by setting all
processors as selected. Parallel content assignment allows pvars in the currently
selected processor set to be assinged allowed values in one step. Global summation
executes a tree reduction sum across the CM processors by grid or cube address for
particular pvars. Parallel multiplications and additions multiply and add pvars for all
selected CM processors in one step. The parallel exponential applies the function, eX, to
the contents of a specified pvar, x, over all selected processors. Parallel segmented
scans apply two functions, copy!! and +!!, to subsets ofCM processors by scanning
across grid or cube addresses. Scanning may be forward or backward (Le. by
ascending or descending cube address order, respectively).
Figs. 3 and 4 show the edge list approach kernels required for Hebbian learning for
a R2 -> R2 model. The loop construct in Fig. 3 drives the activation update
(1)

operation. The usual loop to compute each weighted sum for a particular unit has been
replaced by four parallel operations: a selection reset (*all), a subselection of all the
processors for which the particular unit is a receiver of activation (*when (=!! rid (!!
(1+ u??, a parallel multiplication (*!! weight sact), and a tree reduction sum (*sum
... ). Activation is spread for a particular unit, to all others it is connected to, by:
storing the newly computed activation in an array on the host, then subselecting the
processors where the particular unit is a sender of activation (*when (=!! sid (!! (1 +
u??, and broadcasting the array value on the host to those processors.
(dotimes (u 4)
(*all (*when (=!! rid (!! (1+ u?)
(setf (aref activation u)
(some-nonlinearity (*sum (*!! weight sact??
(*set ract (!! (aref activation u?)
(*all (*when (=!! sid (!! (1+ u?)
(*set sact (!! (aref activation u???
Fig. 3. Activation Update Kernel for the Edge Lst Approach.
Fig. 4 shows the Hebbian weight update kernel

132

(2)

(*all
(*set weight
(*!! learn-rate ract sact??
Fig. 4. Hebbian Weight Modification Kernel for the Edge List Approach
The edge list activation update kernel is essentially serial because the steps involved can
only be applied to one unit at a time. The weight modification is parallel. For error
back propagation a seperate loop for computing the errors for the units on each layer of
a model is required. Activation update and error back propagation also require transfers
to and from arrays on the host on every iteration step incurring a concomitant overhead.
Other common computations used for neural networks can be computed in parallel
using the edge list approach. Fig. 5 shows the code kernel for parallel computation of
Lyapunov engergy equations

(3)
where i= 1 to number of units (N).
(+ (* -.5 (*sum (*!! weight ract sact?) (*sum (*!! input sact?)
Fig. 5. Kernel for Computation of the Lyapunov Energy Equation
Although an input pvar, input, is defined for all edges, it is only non-zero for those
edges associated with input units. Fig. 6 shows the pvar structure for parallel
computation of a Hopfield weight prescription, with segmented scanning to produce the
weights in one step,
IJ -l:S
r= I(2ar1?-I)(2arJ?-I)

W? ?

(4)

where wii=O, Wij=Wjh and r=I to the number of patterns, S, to be stored.
seg
t
n
ract
vII V2 1 ...
V I 2 v22' ..
sact
weight

n
t
n
n
VSI vII V2 I ... VSI .. .
VS2 v13 v23 ... VS3 .. .
wI2
w13

Fig. 6. Pvar Structure for Parallel Computation QfHopfield Weight Prescription
Fig. 7 shows the *Lisp kernel used on the pvar structure in Fig. 6.
(set weight
(scan '+!! (*!! (-!! (*!! ract (!! 2? (!! 1? (-!! (*!! sact (!! 2? (!! 1??
:segment-pvar seg :inc1ude-self t)
Fig. 7. Parallel Computation of Hopfield Weight Prescription

133

The inefficiencies of the edge list activation update are solved by the updating
method used in the composite approach. Fig. 8 shows the *Lisp kernel for activation
update using the composite approach. Fig. 9 shows the *Lisp kernel for the Hebbian
learning operation in the composite approach.

(*a1l
(*when (=!! level (!! 1?
(*set act (scan!! act-I 'copy!! :segment-pvar forwardb :include-self t?
(*set act (*!! act-l weight?
(*when (=!! type (!! 2? (*pset :overwrite act-l act-I ftransfer?)
(*when (=!! level (!! 2?
(*set act (scan!! act-l '+!! :segment-pvar forwarda :include-self t?
(*when (=!! type (!! 1? (some-nonlinearity!! act-I??
Fig. 8. Activation Update Kernel for the Composite Approach

(*all
(*set act-l (scan!! act-I 'copy!! :segment-pvar forwardb
:include-self t?
(*when (=!! type (!! 2?
(*set act-2 (pref!! act-I btransfer?)
(*set weight
(+!! weight
(*!! learn-rate act-l act-2??)
Fig. 9. Hebbian Weight Update Kernel for the Composite Approach
It is immediately obvious that no looping is invloved. Any number of interconnects
may be updated by the proper subselection. However, the more subselection is used
the less efficient the computation becomes because less processors are invloved.
COMPLEXITY ANALYSIS
The performance results presented in the next section can be largely anticipated
from an analysis of the space and time requirements of the CM implementation
approaches. For simplicity I use a Rn -> Rn model with Hebbian adaptation. The
oder of magnitude requirements for activation and weight updating are compared for
both CM implementation approaches and a basic serial matrix arithmetic approach.
F~r the given model the space requirements on a conventional serial machine are
2n+n locations or O(n 2). The growth of the space requirement is dominated by the
nxn weight matrix. defining the system interconnect structure. The edge list appro~ch
uses six pvars for each processor and uses nxn processors for the mapping, or 6n
locations or O(n2). The composite approach uses 11 pvars. There are 2n processors
for units and 2n2 proces~ors for interconnects in the given model. The composite
approach uses 11(2n+2n ) locations or O(n2 ). The CM implementations take up
roughly the same space as the serial implementation, but the space for the serial
implementation is composed of passive memory whereas the space for the CM
implementations is composed of interconnected processors with memory .

The time analysis for the approaches compares the time order of magnitudes to
compute the activation update (1) and the Hebbian weight update (2). On a serial

134

machine, the n weighted sums computed for the ac~vation update require n2
multiplicationsffd n(n-l) additions. There are 2n -n operations or time order of
magnitude O(n ~ The time order of magnitude for the weight matrix update is O(n2)
since there are n weight matrix elements.
The edge list approach forms n weighted sums by performing a parallel product of
all of the weights and activations in the model, (*!! weight sact), and then a tree
reduction sum, (*sum ... ), of the products for the n uni~ (see Fig. 4). There are
1+n(nlog2n) operations or time order of magnitude O(n ). This is the same order of
magnitude as obtained on a serial machine. Further, the performance of the activation
update is a function of the number of interconnects to be processed.
The composite approach forms n weighted sums in nine steps (see Fig. 8): five
.selection operations; the segmented copy scan before the parallel multiplication; the
parallel multiplication; the parallel transfer of the products; and the segmented plus
scan, which forms the n sums in one step. This gives the composite activation update a
time order of magnitude O( 1). Performance is independent of the number of
interconnects processed. The next section shows that this is not quite true.
The n2 weights in the model can be updated in three parallel steps using the edge
list approach (see Fig. 4). The n2 weights in the model can be updated in eight parallel
steps using the composite approach (see Fig. 9). In either case, the weight update
operation has a time order of magnitude 0(1).
The time complexity results obtained for the composite approach apply to
computation of the Lyaponov energy equation (3) and the Hopfield weighting
prescription (4), given that pvar structures which can be scanned (see Figs. 1 and 6) are
used. The same operations performed serially are time order of magnitude 0(n2).
The above operations all incur a one time overhead cost for generating the addresses
in the pointer pvars, used for parallel transfers, and arranging the values in segments
for scanning. What the above analysis shows is that time complexity is traded for
space complexity. The goal of CM programming is to use as many processors as
possible at every step.
PERFORMANCE COMPARISON
Simulations of a Hopfield spin-glass model2 were run for six different model sizes
over the same number (16,384) of physical CM processors to provide a performance
comparison between implementation approaches. The Hopfield network was chosen
for the performance comparison because of its simple and well known convergence
dynamics and because it uses a small set of pvars which allows a wide range of
network sizes (degrees of virtualization) to be run. Twelve treaments are run. Six with
the edge list approach and six with the composite approach. Table 3-1 shows the
model sizes run for each treatment. Each treatment was run at the virtualization level
just necessary to accomodate the number of processors required for each simulation.
Two exemplar patterns are stored. Five test patterns are matched against the two
exemplars. Two test patterns have their centers removed, two have a row and column
removed, and one is a random pattern. Each exemplar was hand picked and tested to
insure that it did not produce cross-talk. The number of rows and columns in the
exemplars and patterns increase as the size of the networks for the treatments increases.

135

Since the performance of the CM is at issue, rather than the performance of the network
model used, a simple model and a simple pattern set were chosen to minimize
consideration of the influence of model dynamics on performance.
Performance is presented by plotting execution speed versus model size. Size is
measured by the number of interconnects in a model. The execution speed metric is
interconnects updated per second, N*(N-l )/t, where N is the number of units in a
model and t is the time used to update the activations for all of the units in a model. All
of the units were updated three times for each pattern. Convergence was determined
by the output activation remaining stable over the fmal two updates. The value of t for
a treatment is the average of 15 samples of t. Fig. 10 shows the activation update cycle
time for both approaches. Fig. 11 shows the interconnect update speed plots for both
approaches. The edge list approach is plotted in black. The composite approach is
plotted in white. The performance shown excludes overhead for interpretation of the
*Lisp instructions. The model size categories for each plot correspond to the model
sizes and levels of eM virtualization shown in Table I.
Activation Update Cycle Time vs Model Size

1 .6
1 .4
1.2

?

sees O.B

0.6
0.4

?

?

o
0.2
?
OO___~~~__~O~__~O~__.O__~
1

2

3

4

5

6

Model Size

Fig. 10. Activation Update Cycle Times
Interconnect Update Speed Comparison
Edge Ust Approach vs. Composite Approach

2000000}
0

1500000

0
0

i.p.s. 1000000

0

0

0

500000t

o?1

?
2

?

?

3
4
Model Size

?

5

?
6

Fig. 11. Edge List Interconnect Update Speeds
Fig. 11 shows an order of magnitude performance difference between the
approaches and a roll off in performance for each approach as a function of the number
of virtual processors supported by each physical processor. The performance tum
around is at 4x virtualization for the edge list approach and 2x virtualization for the
composite approach.

136

CONCLUSIONS
Representing the interconnect structure of neural network models with mappings
defined over the set of fine grain processors provided by the CM architecture provides
good performance for a modest programming effort utilizing only a small subset of the
instructions provided by *Lisp. Further, the perfonnance will continue to scale up
linearly as long as not more than 2x virtualization is required. While the complexity
analysis of the composite activation update suggests that its performance should be
independent of the number of interconnects to be processed, the perfonnance results
show that the performance is indirectly dependent on the number of interconnects to be
processed because the level of virtualization required (after the physical processors are
exhausted) is dependent on the number of interconnects to be processed and
virtualization decreases performance linearly. The complexity analysis of the edge list
activation update shows that its perfonnance should be roughly the same as serial
implementations on comparable machines. The results suggest that the composite
approach is to be prefered over the edge list approach but not be used at a virtualization
level higher than 2x.
The mechanism of the composite activation update suggest that hierarchical
networks simulated in this fashion will compare in perfonnance to single layer
networks because the parallel transfers provide a type of pipeline for activation for
synchronously updated hierarchical networks while providing simultaneous activation
transfers for asynchronously updated single layer networks. Researchers at Thinking
Machines Corporation and the M.I.T. AI Laboratory in Cambridge Mass. use a similar
approach for an implementation of NETtalk. Their approach overlaps the weights of
connected units and simultaneously pipelines activation forward and error backward. 3
Perfonnance better than that presented can be gained by translation of the control
code from interpreted *Lisp to PARIS and use of the CM2. In addition to not being
interpreted, PARIS allows explicit control over important registers that aren't
accessable through *Lisp. The CM2 will offer a number of new features which will
enhance perfonnance of neural network simulations: a *Lisp compiler, larger
processor memory (64K), and floating point processors. The complier and floating
point processors will increase execution speeds while the larger processor memories
will provide a larger number of virtual processors at the performance tum around points
allowing higher perfonnance through higher CM utilization.
REFERENCES

1. ""Introduction to Data Level Parallelism,"" Thinking Machines Technical Report
86.14, (April 1986).
2. Hopfield, J. J., ""Neural networks and physical systems with emergent collective
computational abilities,"" Proc. Natl. Acad. Sci., Vol. 79, (April 1982), pp. 2554-2558.
3. Blelloch, G. and Rosenberg, C. Network Learning on the Connection Machine,
M.I.T. Technical Report, 1987.

"
90,1987,"Phasor Neural Networks","",90-phasor-neural-networks.pdf,"Abstract Missing","584

PHASOR NEURAL NETVORKS
Andr~

J. Noest, N.I.B.R., NL-ll0S AZ Amsterdam, The Netherlands.
ABSTRACT

A novel network type is introduced which uses unit-length 2-vectors
for local variables. As an example of its applications, associative
memory nets are defined and their performance analyzed. Real systems
corresponding to such 'phasor' models can be e.g. (neuro)biological
networks of limit-cycle oscillators or optical resonators that have
a hologram in their feedback path.
INTRODUCTION
Most neural network models use either binary local variables or
scalars combined with sigmoidal nonlinearities. Rather awkward coding
schemes have to be invoked if one wants to maintain linear relations
between the local signals being processed in e.g. associative memory
networks, since the nonlinearities necessary for any nontrivial
computation act directly on the range of values assumed by the local
variables. In addition, there is the problem of representing signals
that take values from a space with a different topology, e.g. that
of the circle, sphere, torus, etc. Practical examples of such a
signal are the orientations of edges or the directions of local optic
flow in images, or

~he

phase of a set of (sound or EM) waves as they

arrive on an array of detectors. Apart from the fact that 'circular'
signals occur in technical as well as biological systems, there are
indications that some parts of the brain (e.g. olfactory bulb, cf.
Dr.B.Baird's contribution to these proceedings) can use limit-cycle
oscillators formed by local feedback circuits as functional building
blocks, even for signals without circular symmetry. Vith respect to
technical implementations, I had speculated before the conference
whether it could be useful to code information in the phase of the
beams of optical neurocomputers, avoiding slow optical switching
elements and using only (saturating) optical amplification and a
? American Institute of Physics 1988

585

hologram encoding the (complex) 'synaptic' weight factors. At the
conference, I learnt that Prof. Dana Anderson had independently
developed an optical device (cf. these proceedings) that basically
works this way, at least in the slow-evolution limit of the dynamic
hologram. Hopefully, some of the theory that I present here can be
applied to his experiment. In turn, such implementations call for
interesting extensions of the present models.
BASIC ELEMENTS OF GENERAL PHASOR NETVORKS
Here I study the perhaps simplest non-scalar network by using unitlength 2-vectors (phasors) as continuous local variables. The signals
processed by the network are represented in the relative phaseangles.
Thus, the nonlinearities (unit-length 'clipping') act orthogonally to
the range of the variables coding the information. The behavior of
the network is invariant under any rigid rotation of the complete set
of phasors, representing an arbitrary choice of a global reference
I

phase. Statistical physicists will recognize the phasor model as a
generalization of 02-spin models to include vector-valued couplings.
All 2-vectors are treated algebraically as complex numbers, writing

x for

Ixl for the length, Ixl for the phase-angle, and

the complex

conjugate of a 2-vector x.
A phasor network then consists of N?l phasors s. , with Is.l=l,
1

interacting via couplings c .. , with
1J

C ..

11

1

= O. The c 1J
.. are allowed

to be complex-valued quantities. For optical implementations this
is clearly a natural choice, but it may seem less so for biological
systems. However, if the coupling between two limitcycle oscillators
with frequency f is mediated via a path having propagationdelay d,
then that coupling in fact acquires a phaseshift of

f.d.2~

radians.

Thus, complex couplings can represent such systems more faithfully
than the usual models which neglect propagationdelays altogether.
Only 2-point couplings are treated here, but multi-point couplings
c.1)'k' etc., can be treated similarly.
The dynamics of each phasor depends only on its local field
h.=
1

!z:4~ c 1J
.. s.
J
J

+ n.

1

where z is the number of inputs

586

c .. ~O per cell and n. is a local noise term (complex and Gaussian).
1J

1

Various dynamics are possible, and yield largely similar results:
Continuous-time, parallel evolution:

(""type A"")

d (/s./) = Ih. l.sin(/h.1 - Is./)

(IT

1

1

1

1

s.(t+dt)= h.1 Ih. I , either serially in

Discrete-time updating:

1 1 1

random i-sequence (""type B""), or in parallel for all i (""type C"").
The natural time scale for type-B dynamics is obtained by scaling
the discrete time-interval eft as ,.., liN ; type-C dynamics has cl't=l.
LYAPUNOV FUNCTION

(alias ""ENERGY"", or ""HAMILTONIAN"" )

If one limits the attention temporarily to purely deterministic
(n.=O) models, then the question suggests itself whether a class of
1

couplings exists for which one can easily find a Lyapunov function
i.e. a function of the network variables that is monotonic under the
dynamics. A well-known example

1

is the 'energy' of the binary and

scalar Hopfield models with symmetric interactions. It turns out that
a very similar function exists for phasor networks with type-A or B
dynamics and a Hermitian matrix of couplings.
-H =

L
?
1

Hermiticity (c ..

1J

5.1

h.

1

=

=c .. ) makes
J 1

(lIz)

L

5.1 c 1J
.. s.
J

? .
1,J

H real-valued and non-increasing in time.

This can be shown as follows, e.g. for the serial dynamics (type B).
Suppose, without loss of generality, that phasor i=l is updated.
Then

-z H

Ls. c ' l sl
1>1
+ sl' 2: c ' 1 5.
i>l

=

+

1

z 51 h1

+

1

1

I.I:
i ,j>l

-s.

1

c .. s.
1J

J

+ constant.

1

Vith Hermitian couplings, H becomes real-valued, and one also has

l:c 1 ?
i>l

I:c' 5.
i>1 1 l 1
Thus, - H - constant

1

s.
1

=

z h1

.

51 h1 + sl h1 = 2 Re(sl h 1 )
Clearly, H is minimized with respect to sl by sl(t+1) = hll Ih11 ?
Type-A dynamics has the same Lyapunovian, but type C is more complex.
=

The existence of Hermitian interactions and the corresponding energy
function simplifies greatly the understanding and design of phasor
networks, although non-Hermitian networks can still have a Lyapunov-

587

function, and even networks for which such a function is not readily
found can be useful, as will be illustrated later.
AN APPLICATION: ASSOCIATIVE MEMORY.
A large class of collective computations, such as optimisations
and content-addressable memory, can be realised with networks having
an energy function. The basic idea is to define the relevant penalty
function over the solution-space in the form of the generic 'energy'
of the net, and simply let the network relax to minima of this energy.
As a simple example, consider an associative memory built within the
framework of Hermitian phasor networks.
In order to store a set of patterns in the network, i.e. to make
a set of special states (at least approximatively) into attractive
fixed points of the dynamics, one needs to choose an appropriate
set of couplings. One particularly simple way of doing this is via
the phasor-analog of ""Hebb's rule"" (note the Hermiticity)
p s(.k). s-(.k), h
c .. =
were s.(k).IS phasor 1. .In I earne d pattern k .
IJ

rk

1

J

1

The rule is understood to apply only to the input-sets

'i

of each i.

Such couplings should be realisable as holograms in optical networks,
but they may seem unrealistic in the context of biological networks
of oscillators since the phase-shift (e.g. corresponding to a delay)
of a connection may not be changeable at will. However, the required
coupling can still be implemented naturally if e.g. a few paths with
different fixed delays exist between pairs of cells. The synaps in
each path then simply becomes the projection of the complex coupling
on the direction given by the phase of its path, i.e. it is just a
classical Hebb-synapse that computes the correlation of its pre- and
post-synaptic (imposed) signals, which now are phase-shifted versions
of the phasors s~~)The required complex c .. are then realised as the
1

IJ

vector sum over at least two signals arriving via distinct paths with
corresponding phase-shift and real-valued synaps. Two paths suffice
if they have orthogonal phase-shifts, but random phases will do as
well if there are a reasonable number of paths.
Ve need to have a concise way of expressing how 'near' any state
of the net is to one or more of the stored patterns. A natural way

588

of doing this is via a set of p order parameters called ""overlaps""
N

-(k)

1
s 1.. s.1
?
N 11:
1

I

; 1

Note the constraint on the p overlaps

P

I

< k -< p

-

?

2

Mk ~ 1 if all the patterns

k

are orthogonal, or merely random in the limit N-.QO. This will be
assumed from now on. Also, one sees at once that the whole behaviour
of the network does not depend on any rigid rotation of all phasors
over some angle since H, Mk , c .. and the dynamics are invariant under
1J
multiplication of all s.
by
a
fixed
phasor : s~
= S.s. with ISI=1.
I
I
I
Let us find the performance at low loading: N,p,z .. oo, with p/z.. O
and zero local noise. Also assume an initial overlap m)O with only
one pattern, say with k=1. Then the local field is
hi
1 s~1~
hP~
Z
1
1

and

h.*
1

f

s~k)
~s .. k s~k~
1
J
J
j' i

1
= -z

I: sP~s.

jl'i

=

J

J

(1)
= m1 . si ? S

~ fs~k). L: s~k~s.
z k=2

1

j(~i J

J

h(1)
i +
+ O(1//Z)

h71

,

with

O( ./( p-l) Iz')

where
S~f(i);ISI=1,

.

Thus, perfect recall (M 1=1) occurs in one 'pass' at loadings p/z ... O.
EXACTLY SOLVABLE CASE:

SPARSE and ASYMMETRIC couplings

Although it would be interesting to develop the full thermodynamics
of Hermitian phasor networks with p and z of order N (analogous to the
analysis of the finite-T Hopfield model by the teams of Amit 2 and van
Hemmen 3 ), I will analyse here instead a model with sparse, asymmetric
connectivity, which has the great advantages of being exactly solvable
with relative ease, and of being arguably more realistic biologically
and more easily scalable technologically. In neurobiological networks
a cell has up to z;10 4 asymmetric connections, whereas N;101~ This
probably has the same reason as applies to most VLSI chips, namely to
alleviate wiring problems. For my present purposes, the theoretical
advantage of getting some exact results is of primary interest 4
Suppose each cell has z incoming connections from randomly selected
other cells. The state of each cell at time t depends on at most zt
.
cells at time t=O. Thus, If
z t ?N 112 and N large, then the respective

589

4
trees of 'ancestors' of any pair cells have no cells in common. In
x

particular, if z_ (logN) , for any finite x, then there are no common
ancestors for any finite time t in the limit N-.OO. For fundamental
information-theoretic reasons, one can hope to be able to store p
patterns with p at most of order z for any sort of 2-point couplings.
Important questions to be settled are: Yhat are the accuracy and
speed of the recall process, and how large are the basins of the
attractors representing recalled patterns?
Take again initial conditions (t=O) with, say, m(t)= Hl > H>l = O.
Allowing again local random Gaussian (complex) noise n., the local
? ld s become, In
. now f amI'1'Iar notatIon,
.
h .= h(l)
1 n .?
f Ie
. + h*. +
1

1

1

1

As in the previous section, the h~l)term consists of the 'signal'
1

m(t).s. (modulo the rigid rotation S) and a random term of variance

*

1

at most liz. For p _ z, the h. term becomes important. Being sums of

*

1

z(p-1) phasors oriented randomly relative to the signal, the h. are
1

independent Gaussian zero-mean 2-vectors with variance (p-1)/z , as
p,z and N.. oo

. Finally, let the local noises n.1 have variance r2.

Then the distribution of the s.(t+l) phasors can be found in terms of
1
* .?
2
the signal met) and the total variance a=(p/z)+r of the random h.+n
1
1
After somewhat tedious algebraic manipulations (to be reported in
detail elsewhere) one obtains the dynamic behaviour of met)
m(t+1) = F(m(t),a)

for discrete parallel (type-C) dynamics,

and
d met) = F(m(t),a) - met)

for type-A or type-B dynamics ,

Tt

where the function
m

F(m,a) =

+""

2
Idx.(1+cos2x).expl-(m.sinx) la].(l+erfl(m.cosx)/~)
-1'C

The attractive fixed points H* (a)= F(H * ,a) represent the retrieval
accuracy when the loading-pIus-noise factor equals a. See figure 1.
For a?l one obtains the expansion 1-H* (a)

= a/4 + 3a 2 132 + O(a 3 ).

The recall solutions vanish continuously as H*_(a -a) 112 at a =tc/4.
c

c

One also obtains (at any t) the distribution of the phase scatter of
the phasors around the ideal values occurring in the stored pattern.

590

P(/u./)
1

= (1/2n).exp(-m 2 /a).(1+I1t.L.exp(L 2 ).(1+erf(L?
-(k)

, and
L = (m/la).cos(/u./)
1

where

u.=
s. s.
111

,

(modulo S).

Useful approximations for the high, respectively low M regimes are:
M ?ra: PUu./)
1

(MIl'a1l).exp[-(M./u./)2 /a ]
1

;

I/u./1 ?""XI2
1

M ? f i : PUu./)
= (1I21t).(1+L ?./;l)
1
Figure ~
RETRIEVAL-ERROR and BASIN OF ATTRACTION versus LOADING + NOISE.

Q
Q

Q

en

Q
Q

.,;
Q

"".,;
Q

I:

UI

..,)

Q

-C0

a.

1:)

CD

x

-

c-

Q

Q

.

Q

Q
Q

'""Q
0

Q

0

Q
0

c:
""'0.00

0.10

0.20

O. 30

0 ? 40

a

0 ? 50

= p/z

0 ? 60

+ r-r

O. 70

0 ? 80

0 ? 90

1. 00

591

DISCUSSION
It has been shown that the usual binary or scalar neural networks
can be generalized to phasor networks, and that the general structure
of the theoretical analysis for their use as associative memories can
be extended accordingly. This suggests that many of the other useful
applications of neural nets (back-prop, etcJ can also be generalized
to a phasor setting. This may be of interest both from the point of
view of solving problems naturally posed in such a setting, as well
as from that of enabling a wider range of physical implementations,
such as networks of limit-cycle oscillators, phase-encoded optics,
or maybe even Josephson-junctions.
The performance of phasor networks turns out to be roughly similar
to that of the scalar systems; the maximum capacity

p/z=~/4

for

phasor nets is slightly larger than its value 2/n for binary nets,
but there is a seemingly faster growth of the recall error 1-M at
small a (linear for phasors, against exp(-1/(2a?

for binary nets).

However, the latter measures cannot be compared directly since they
stem from quite different order parameters. If one reduces recalled
phasor patterns to binary information, performance is again similar.
Finally, the present methods and results suggest several roads to
further generalizations, some of which may be relevant with respect
to natural or technical implementations. The first class of these
involves local variables ranging over the k-sphere with k>l. The
other generalizations involve breaking the O(n) (here n=2) symmetry
of the system, either by forcing the variables to discrete positions
on the circle (k-sphere), and/or by taking the interactions between
two variables to be a more general function of the angular distance
between them. Such models are now under development.
REFERENCES
1. J.J.Hopfield, Proc.Nat.Acad.Sci.USA 79, 2554 (1982) and
idem, Proc.Nat.Acad.Sci.USA 81, 3088 (1984).
2. D.J.Amit, H.Gutfreund and H.Sompolinski, Ann.Phys. 173, 30 (1987).
3. D.Grensing, R.Kuhn and J.L. van Hemmen, J.Phys.A 20, 2935 (1987).
4. B.Derrida, E.Gardner and A.Zippelius, Europhys.Lett. 4, 167 (1987)

"
91,1987,"Scaling Properties of Coarse-Coded Symbol Memories","",91-scaling-properties-of-coarse-coded-symbol-memories.pdf,"Abstract Missing","652

Scaling Properties of Coarse-Coded Symbol Memories
Ronald Rosenfeld
David S. Touretzky
Computer Science Department
Carnegie Mellon University
Pittsburgh, Pennsylvania 15213

Abstract: Coarse-coded symbol memories have appeared in several neural network
symbol processing models. In order to determine how these models would scale, one
must first have some understanding of the mathematics of coarse-coded representations. We define the general structure of coarse-coded symbol memories and derive
mathematical relationships among their essential parameters: memory 8ize, 8ymbol-8et
size and capacity. The computed capacity of one of the schemes agrees well with actual
measurements oC tbe coarse-coded working memory of DCPS, Touretzky and Hinton's
distributed connectionist production system.
1

Introduction

A di8tributed repre8entation is a memory scheme in which each entity (concept, symbol)
is represented by a pattern of activity over many units [3]. If each unit participates
in the representation of many entities, it is said to be coar8ely tuned, and the memory
itself is called a coar8e-coded memory.
Coarse-coded memories have been used for storing symbols in several neural network
symbol processing models, such as Touretzky and Hinton's distributed connectionist
production system DCPS [8,9], Touretzky's distributed implementation of linked list
structures on a Boltzmann machine, BoltzCONS [10], and St. John and McClelland's
PDP model of case role defaults [6]. In all of these models, memory capacity was measured empirically and parameters were adjusted by trial and error to obtain the desired
behavior. We are now able to give a mathematical foundation to these experiments by
analyzing the relationships among the fundamental memory parameters.
There are several paradigms for coarse-coded memories. In a feature-based repre8entation, each unit stands for some semantic feature. Binary units can code features
with binary values, whereas more complicated units or groups of units are required to
code more complicated features, such as multi-valued properties or numerical values
from a continuous scale. The units that form the representation of a concept define
an intersection of features that constitutes that concept. Similarity between concepts
composed of binary Ceatures can be measured by the Hamming distance between their
representations. In a neural network implementation, relationships between concepts
are implemented via connections among the units forming their representations. Certain
types of generalization phenomena thereby emerge automatically.
A different paradigm is used when representing points in a multidimensional continuous space [2,3]. Each unit encodes values in some subset of the space. Typically the
@ American Institute of Physics 1988

653

subsets are hypercubes or hyperspheres, but they may be more coarsely tuned along
some dimensions than others [1]. The point to be represented is in the subspace formed
by the intersection of all active units. AB more units are turned on, the accuracy of the
representation improves. The density and degree of overlap of the units' receptive fields
determines the system's resolution [7].
Yet another paradigm for coarse-coded memories, and the one we will deal with
exclusively, does not involve features. Each concept, or symbol, is represented by an
arbitrary subset of the units, called its pattern. Unlike in feature-based representations,
the units in the pattern bear no relationship to the meaning of the symbol represented. A
symbol is stored in memory by turning on all the units in its pattern. A symbol is deemed
present if all the units in its pattern are active. l The receptive field of each unit is defined
as the set of all symbols in whose pattern it participates. We call such memories coarsecoded symbol memories (CCSMs). We use the term ""symbol"" instead of ""concept"" to
emphasize that the internal structure of the entity to be represented is not involved in
its representation. In CCSMs, a short Hamming distance between two symbols does
not imply semantic similarity, and is in general an undesirable phenomenon.
The efficiency with which CCSMs handle sparse memories is the major reason they
have been used in many connectionist systems, and hence the major reason for studying
them here. The unit-sharing strategy that gives rise to efficient encoding in CCSMs
is also the source of their major weakness. Symbols share units with other symbols.
AB more symbols are stored, more and more of the units are turned on. At some
point, some symbol may be deemed present in memory because all of its units are
turned on, even though it was not explicitly stored: a ""ghost"" is born. Ghosts are
an unwanted phenomenon arising out of the overlap among the representations of the
various symbols. The emergence of ghosts marks the limits of the system's capacity:
the number of symbols it can store simultaneously and reliably.

2

Definitions and Fundamental Parameters

A coarse coded symbol memory in its most general form consists of:
? A set of N binary state units.
? An alphabet of Q symbols to be represented. Symbols in this context are atomic
entities: they have no constituent structure.

? A memory scheme, which is a function that maps each symbol to a subset of
the units - its pattern. The receptive field of a unit is defined as the set of
all symbols to whose pattern it belongs (see Figure 1). The exact nature of the
lThis criterion can be generalized by introducing a visibility threshold: a fraction of
the pattern that should be on in order for a symbol to be considered present. Our analysis deals only with a visibility criterion of 100%, but can be generalized to accommodate
nOise.

654

I

I 81 I 82 I 88 I 8 I 85 I 86 I 87 I 88 I
4

Ul
U2
U8
U4
U5
U6

?

?
? ?
? ?
? ?
? ?
?
? ?
?
?
? ?
? ?
?

?
?

Figure 1: A memory scheme (N = 6, Q = 8) defined in terms of units Us and symbols
8;. The columns are the symbols' patterns. The rows are the units' receptive fieldB.

memory scheme mapping determines the properties of the memory, and is the
central target of our investigation.
As symbols are stored, the memory fills up and ghosts eventually appear. It is not
possible to detect a ghost simply by inspecting the contents of memory, since there is
no general way of distinguishing a symbol that was stored from one that emerged out of
overlaps with other symbols. (It is sometimes possible, however, to conclude that there
are no ghosts.) Furthermore, a symbol that emerged as a ghost at one time may not be
a ghost at a later time if it was subsequently stored into memory. Thus the definition
of a ghost depends not only on the state of the memory but also on its history.
Some memory schemes guarantee that no ghost will emerge as long as the number of
symbols stored does not exceed some specified limit. In other schemes, the emergence
of ghosts is an ever-present possibility, but its probability can be kept arbitrarily low
by adjusting other parameters. We analyze systems of both types. First, two more bits
of notation need to be introduced:
Pghost: Probability of a ghost. The probability that at least one ghost will appear
after some number of symbols have been stored.
k: Capacity. The maximum number of symbols that can be stored simultaneously
before the probability of a ghost exceeds a specified threshold. If the threshold is
0, we say that the capacity is guaranteed.
A localist representation, where every symbol is represented by a single unit and
every unit is dedicated to the representation of a single symbol, can now be viewed as
a special case of coarse-coded memory, where k = N = Q and Pghost = o. Localist
representations are well suited for memories that are not sparse. In these cases, coarsecoded memories are at a disadvantage. In designing coarse-coded symbol memories we
are interested in cases where k ? N ? Q. The permissible probability for a ghost in
these systems should be low enough so that its impact can be ignored.

655

3
3.1

Analysis of Four Memory Schemes
Bounded Overlap (guaranteed capacity)

If we want to construct the memory scheme with the largest possible a (given Nand
k) while guaranteeing Pghost = 0, the problem can be stated formally as:

Given a set of size N, find the largest collection of subsets of it such that no
union of k such subsets subsumes any other subset in the collection.
This is a well known problem in Coding Theory, in slight disguise. Unfortunately,
no complete analytical solution is known. We therefore simplify our task and consider
only systems in which all symbols are represented by the same number of units (i.e. all
patterns are of the same size). In mathematical terms, we restrict ourselves to constant
weight codes. The problem then becomes:
Given a set of size N, find the largest collection of subsets of size exactly
L such that no union of k such subsets subsumes any other subset in the
collection.
There are no known complete analytical solutions for the size of the largest collection
of patterns even when the patterns are of a fixed size. Nor is any efficient procedure
for constructing such a collection known. We therefore simplify the problem further.
We now restrict our consideration to patterns whose pairwise overlap is bounded by a
given number. For a given pattern size L and desired capacity k, we require that no
two patterns overlap in more than m units, where:

_lL -k 1J

m-

(1)

--

Memory schemes that obey this constraint are guaranteed a capacity of at least k
symbols, since any k symbols taken together can overlap at most L - 1 units in the
pattern of any other symbol - one unit short of making it a ghost. Based on this
constraint, our mathematical problem now becomes:
Given a set of size N, find the largest collection of subsets of size exactly L
such that the intersection of any two such subsets is of size ~ m (where m
is given by equation 1.)
Coding theory has yet to produce a complete solution to this problem, but several
methods of deriving upper bounds have been proposed (see for example [4]). The simple
formula we use here is a variant of the Johnson Bound. Let abo denote the maximum
number of symbols attainable in memory schemes that use bounded overlap. Then

(m~l)
(m~l)

(2)

656

The Johnson bound is known to be an exact solution asymptotically (that is, when
N, L, m -+ 00 and their ratios remain finite).
Since we are free to choose the pattern size, we optimize our memory scheme by
maximizing the above expression over all possible values of L. For the parameter subspace we are interested in here (N < 1000, k < 50) we use numerical approximation to
obtain:

<

max (

LeII,N]

N
L - m

)m+l <

(3)

(Recall that m is a function of Land k.) Thus the upper bound we derived depicts a
simple exponential relationship between Q and N/k. Next, we try to construct memory
schemes of this type. A Common Lisp program using a modified depth-first search
constructed memory schemes for various parameter values, whose Q'S came within 80%
to 90% of the upper bound. These results are far from conclusive, however, since only
a small portion of the parameter space was tested.
In evaluating the viability of this approach, its apparent optimality should be contrasted with two major weaknesses. First, this type of memory scheme is hard to
construct computationally. It took our program several minutes of CPU time on a
Symbolics 3600 to produce reasonable solutions for cases like N = 200, k = 5, m = 1,
with an exponential increase in computing time for larger values of m. Second, if CCSMs are used as models of memory in naturally evolving systems (such as the brain),
this approach places too great a burden on developmental mechanisms.
The importance of the bounded overlap approach lies mainly in its role as an upper
bound for all possible memory schemes, subject to the simplifications made earlier. All
schemes with guaranteed capacities can be measured relative to equation 3.

3.2

Random Fixed Size Patterns (a stochastic approach)

Randomly produced memory schemes are easy to implement and are attractive because
of their naturalness. However, if the patterns of two symbols coincide, the guaranteed
capacity will be zero (storing one of these symbols will render the other a ghost). We
therefore abandon the goal of guaranteeing a certain capacity, and instead establish a
tolerance level for ghosts, Pghost. For large enough memories, where stochastic behavior
is more robust, we may expect reasonable capacity even with very small Pghost.
In the first stochastic approach we analyze, patterns are randomly selected subsets
of a fixed size L. Unlike in the previous approach, choosing k does not bound Q. We
may define as many symbols as we wish, although at the cost of increased probability
of a ghost (or, alternatively, decreased capacity). The probability of a ghost appearing
after k symbols have been stored is given by Equation 4:

(4)

657

TN,L(k, e) is the probability that exactly e units will be active after k symbols have
been stored. It is defined recursively by Equation 5"":
TN,L(O,O) = 1
TN,L(k, e)
0 for either k 0 and e 1= 0, or k > 0 and e < L
TN,L(k, e) = E~=o T(k - 1, c - a) . (N-~-a)) . (~:~)/(~)

=

=

(5)

We have constructed various coarse-coded memories with random fixed-size receptive
fields and measured their capacities. The experimental results show good agreement
with the above equation.
The optimal pattern size for fixed values of N, k, and a can be determined by
binary search on Equation 4, since Pghost(L) has exactly one maximum in the interval
[1, N]. However, this may be expensive for large N. A computational shortcut can be
achieved by estimating the optimal L and searching in a small interval around it. A
good initial estimate is derived by replacing the summation in Equation 4 with a single
term involving E[e]: the expected value of the number of active units after k symbols
have been stored. The latter can be expressed as:

The estimated L is the one that maximizes the following expression:

An alternative formula, developed by Joseph Tebelskis, produces very good approximations to Eq. 4 and is much more efficient to compute. After storing k symbols in
memory, the probability Pz that a single arbitrary symbol x has become a ghost is given
by:

Pz(N,L,k,a)

.(L) (N L_i)k / (N)k
L

L i
= f.(-1)'

(6)

If we now assume that each symbol's Pz is independent of that of any other symbol,
we obtain:

(7)
This assumption of independence is not strictly true, but the relative error was less
than 0.1% for the parameter ranges we considered, when Pghost was no greater than
0.01.

We have constructed the two-dimensional table TN,L(k, c) for a wide range of (N, L)
values (70 ~ N ~ 1000, 7 ~ L ~ 43), and produced graphs of the relationships between
N, k, a, and Pghost for optimum pattern sizes, as determined by Equation 4. The

658

results show an approximately exponential relationship between a and N /k [5]. Thus,
for a fixed number of symbols, the capacity is proportional to the number of units. Let
arl p denote the maximum number of symbols attainable in memory schemes that use
random fixed-size patterns. Some typical relationships, derived from the data, are:

~ 0.0086. eO.46S f
arlp(Pghost = 0.001) ~ O.OOOS. eO. 47S f
arlP(Pghost

3.3

= 0.01)

(8)

Random Receptors (a stochastic approach)

A second stochastic approach is to have each unit assigned to each symbol with an
independent fixed probability s. This method lends itself to easy mathematical analysis,
resulting in a closed-form analytical solution.
After storing k symbols, the probability that a given unit is active is 1 - (1 - s)k
(independent of any other unit). For a given symbol to be a ghost, every unit must
either be active or else not belong to that symbol's pattern. That will happen with a
probability [1 - s . (1 - s)k] N, and thus the probability of a ghost is:

(9)

Pghost(a, N, k,s)
Assuming Pghost
simplified to:

?

1 and k

?

a (both hold in our case), the expression can be

Pghost(a,N,k,s)

a? [1- s. (1- s)k]N

from which a can be extracted:
arr(N, k, 8, Pghost)

(10)

We can now optimize by finding the value of s that maximizes a, given any desired
upper bound on the expected value of Pghost. This is done straightforwardly by solving
Ba/Bs = o. Note that 8? N corresponds to L in the previous approach. The solution is
s = l/(k + 1), which yields, after some algebraic manipulation:
(11)
A comparison of the results using the two stochastic approaches reveals an interesting
similarity. For large k, with Pghost = 0.01 the term 0.468/k of Equation 8 can be seen
as a numerical approximation to the log term in Equation 11, and the multiplicative
factor of 0.0086 in Equation 8 approximates Pghost in Equation 11. This is hardly
surprising, since the Law of Large Numbers implies that in the limit (N, k -+ 00, with
8 fixed) the two methods are equivalent.

659

Finally, it should be. noted that the stochastic approaches we analyzed generate
a family of memory schemes, with non-identical ghost-probabilities. Pghost in our
formulas is therefore better understood as an expected value, averaged over the entire
family.

3.4

Partitioned Binary Coding (a reference point)

The last memory scheme we analyze is not strictly distributed. Rather, it is somewhere
in between a distributed and a localist representation, and is presented for comparison
with the previous results. For a given number of units N and desired capacity k, the
units are partitioned into k equal-size ""slots,"" each consisting of N / k units (for simplicity
we assume that k divides N). Each slot is capable of storing exactly one symbol.
The most efficient representation for all possible symbols that may be stored into
a slot is to assign them binary codes, using the N / k units of each slot as bits. This
would allow 2N Jic symbols to be represented. Using binary coding, however, will not
give us the required capacity of 1 symbol, since binary patterns subsume one another.
For example, storing the code '10110' into one of the slots will cause the codes '10010',
'10100' and '00010' (as well as several other codes) to become ghosts.
A possible solution is to use only half of the bits in each slot for a binary code, and
set the other half to the binary complement of that code (we assume that N/k is even).
This way, the codes are guaranteed not to subsume one another. Let Qpbc denote the
number of symbols representable using a partitioned binary coding scheme. Then,
'""pbc -_
.....

2NJ2Ic

-- eO.847 !:!-..

(12)

Once again, Q is exponential in N /k. The form of the result closely resembles the
estimated upper bound on the Bounded Overlap method given in Equation 3. There is
also a strong resemblance to Equations 8 and 11, except that the fractional multiplier in
front of the exponential, corresponding to Pghost, is missing. Pghost is 0 for the Partitioned Binary Coding method, but this is enforced by dividing the memory into disjoint
sets of units rather than adjusting the patterns to reduce overlap among symbols.
As mentioned previously, this memory scheme is not really distributed in the sense
used in this paper, since there is no one pattern associated with a symbol. Instead, a
symbol is represented by anyone of a set of k patterns, each N /k bits long, corresponding
to its appearance in one of the k slots. To check whether a symbol is present, all k slots
must be examined. To store a new symbol in memory, one must scan the k slots until an
empty one is found. Equation 12 should therefore be used only as a point of reference.

4

Measurement of DCPS

The three distributed schemes we have studied all use unstructured patterns, the only
constraint being that patterns are at least roughly the same size. Imposing more complex structure on any of these schemes may is likely to reduce the capacity somewhat. In

660

Memory Scheme
Bounded Overlap
Random Fixed-size Patterns
Random Receptors
Partitioned Binary Coding

Qbo(N,

k)

<

Result
eO.367 t

r

Q,,!p(Pghost = 0.01) ~ 0.0086. e?.468
Q,,!p(Pghost = 0.001) ~ 0.0008 . e?.473f
Q _ P
. e N .1og (k+1)""'Tl/((k+l)""'Tl_k""')
,.,. - ghost
eO.347r
Qpbc --

Table 1 Summary of results for various memory schemes.

order to quantify this effect, we measured the memory capacity of DCPS (BoltzCONS
uses the same memory scheme) and compared the results with the theoretical models
analyzed above.
DCPS' memory scheme is a modified version of the Random Receptors method [5].
The symbol space is the set of all triples over a 25 letter alphabet. Units have fixed-size
receptive fields organized as 6 x 6 x 6 subspaces. Patterns are manipulated to minimize
the variance in pattern size across symbols. The parameters for DCPS are: N = 2000,
Q = 25 3 = 15625, and the mean pattern size is (6/25)3 x 2000 = 27.65 with a standard
deviation of 1.5. When Pghost = 0.01 the measured capacity was k = 48 symbols. By
substituting for N in Equation 11 we find that the highest k value for which Q,.,. ~ 15625
is 51. There does not appear to be a significant cost for maintaining structure in the
receptive fields.

5

Summary and Discussion

Table 1 summarizes the results obtained for the four methods analyzed. Some differences must be emphasiz'ed:
and Qpbc deal with guaranteed capacity, whereas Q,.!p and Q,.,. are meaningful
only for Pghost > O.

?

Qbo

?

Qbo

is only an upper bound.

? Q,.!p is based on numerical estimates.
? Qpbc is based on a scheme which is not strictly coarse-coded.
The similar functional form of all the results, although not surprising, is aesthetically
pleasing. Some of the functional dependencies among the various parameters_ can be
derived informally using qualitative arguments. Only a rigorous analysis, however, can
provide the definite answers that are needed for a better understanding of these systems
and their scaling properties.

661

Acknowledgments
We thank Geoffrey Hinton, Noga Alon and Victor Wei for helpful comments, and Joseph
Tebelskis for sharing with us his formula for approximating Pghost in the case of fixed
pattern sizes.
This work was supported by National Science Foundation grants IST-8516330 and
EET-8716324, and by the Office of Naval Research under contract number NOOO14-86K-0678. The first author was supported by a National Science Foundation graduate
fellowship.

References
[1] Ballard, D H. (1986) Cortical connections and parallel processing: structure and
function. Behavioral and Brain Sciences 9(1).
[2] Feldman, J. A., and Ballard, D. H. (1982) Connectionist models and their properties. Cognitive Science 6, pp. 205-254.
[3] Hinton, G. E., McClelland, J. L., and Rumelhart, D. E. (1986) Distributed representations. In D. E. Rumelhart and J. L. McClelland (eds.), Parallel Distributed
Processing: Explorations in the Microstructure of Cognition, volume 1. Cambridge,
MA: MIT Press.
[4] Macwilliams, F.J., and Sloane, N.J.A. (1978). The Theory of Error-Correcting
Codes, North-Holland.
[5] Rosenfeld, R. and Touretzky, D. S. (1987) Four capacity models for coarse-coded
symbol memories. Technical report CMU-CS-87-182, Carnegie Mellon University
Computer Science Department, Pittsburgh, PA.
[6] St. John, M. F. and McClelland, J. L. (1986) Reconstructive memory for sentences:
a PDP approach. Proceedings of the Ohio University Inference Conference.
[7] Sullins, J. (1985) Value cell encoding strategies. Technical report TR-165, Computer Science Department, University of Rochester, Rochester, NY.
[8] Touretzky, D. S., and Hinton, G. E. (1985) Symbols among the neurons: details of
a connectionist inference architecture. Proceedings of IJCAI-85, Los Angeles, CA,
pp. 238-243.
[9] Touretzky, D. S., and Hinton, G. E. (1986) A distributed connectionist production system. Technical report CMU-CS-86-172, Computer Science Department,
Carnegie Mellon University, Pittsburgh, PA.
[10] Touretzky, D. S. (1986) BoltzCONS: reconciling connectionism with the recursive
nature of stacks and trees. Proceedings of the Eighth A nnual Conference of the
Cognitive Science Society, Amherst, MA, pp. 522-530.

"
92,1987,"MURPHY: A Robot that Learns by Doing","",92-murphy-a-robot-that-learns-by-doing.pdf,"Abstract Missing","544

MURPHY: A Robot that Learns by Doing
Bartlett W. Mel
Center for Complex Systems Research
University of Illinois
508 South Sixth Street
Champaign, IL 61820
January 2, 1988

Abstract
MURPHY consists of a camera looking at a robot arm, with a connectionist network
architecture situated in between. By moving its arm through a small, representative
sample of the 1 billion possible joint configurations, MURPHY learns the relationships,
backwards and forwards, between the positions of its joints and the state of its visual field.
MURPHY can use its internal model in the forward direction to ""envision"" sequences
of actions for planning purposes, such as in grabbing a visually presented object, or in
the reverse direction to ""imitate"", with its arm, autonomous activity in its visual field.
Furthermore, by taking explicit advantage of continuity in the mappings between visual
space and joint space, MURPHY is able to learn non-linear mappings with only a single
layer of modifiable weights.

Background
Current Focus Of Learning Research
Most connectionist learning algorithms may be grouped into three general catagories,
commonly referred to as supenJised, unsupenJised, and reinforcement learning. Supervised
learning requires the explicit participation of an intelligent teacher, usually to provide the
learning system with task-relevant input-output pairs (for two recent examples, see [1,2]).
Unsupervised learning, exemplified by ""clustering"" algorithms, are generally concerned
with detecting structure in a stream of input patterns [3,4,5,6,7]. In its final state, an
unsupervised learning system will typically represent the discovered structure as a set of
categories representing regions of the input space, or, more generally, as a mapping from
the input space into a space of lower dimension that is somehow better suited to the task at
hand. In reinforcement learning, a ""critic"" rewards or penalizes the learning system, until
the system ultimately produces the correct output in response to a given input pattern

[8].
It has seemed an inevitable tradeoff that systems needing to rapidly learn specific,
behaviorally useful input-output mappings must necessarily do so under the auspices of
an intelligent teacher with a ready supply of task-relevant training examples. This state of
affairs has seemed somewhat paradoxical, since the processes of Rerceptual and cognitive
development in human infants, for example, do not depend on the moment by moment
intervention of a teacher of any sort.

Learning by Doing
The current work has been focused on a fourth type of learning algorithm, i.e. learning-bydoing, an approach that has been very little studied from either a connectionist perspective

? American Institute of Physics 1988

545

or in the context of more traditional work in machine learning. In its basic form, the
learning agent
? begins with a repertoire of actions and some form of perceptual input,
? exercises its repertoire of actions, learning to predict i) the detailed sensory consequences of its actions, and, in the other direction, ii) its actions that are associated
with incoming sensory patterns, and
? runs its internal model (in one or both directions) in a variety of behaviorally-relevant
tasks, e.g. to ""envision"" sequences of actions for planning purposes, or to internally
""imitate"" , via its internal action representation, an autonomously generated pattern
of perceptual activity.
In comparison to standard supenJised learning algorithms, the crucial property of
learning-by-doing is that no intelligent teacher is needed to provide input-output pairs
for learning. Laws of physics simply translate actions into their resulting percepts, both
of which are represented internally. The learning agent need only notice and record this
relationship for later use. In contrast to traditional unsupervised learning approaches,
learning-by-doing allows the acquisition of specific, task-relevant mappings, such as the
relationship between a simultaneously represented visual and joint state. Learning-bydoing differs as well from reinforcement paradigms in that it can operate in the absence of
a critic, i.e. in situations where reward or penalty for a particular training instance may
be inappropriate.
Learning by doing may therefore by described as an unsupeMJised associative algorithm,
capable of acquiring rich, task-relevant associations, but without an intelligent teacher or
critic.
Abridged History of the Approach

The general concept of leaning by doing may be attributed at least to Piaget from the
1940's (see [9] for review). Piaget, the founder of the ""constructivist"" school of cognitive
development, argued that knowledge is not given to a child as a passive observer, but
is rather discovered and constructed by the child, through active manipulation of the
environment. A handful of workers in artificial intelligence have addressed the issue of
learning-by-doing, though only in highly schematized, simulated domains, where actions
and sensory states are represented as logical predicates [10,11,12,13].
Barto & Sutton [14] discuss learning-by-doing in the context of system identification
and motor control. They demonstrated how a simple simulated automaton with two actions and three sensory states can build a model of its environment through exploration,
and subsequently use it to choose among behavioral alternatives. In a similar vein, Rumelhart [15] has suggested this same approach could be used to learn the behavior of a robot
arm or a set of speech articulators. Furthermore, the forward-going ""mental model"" , once
learned, could be used internally to train an inverse model using back-propagation.
In previous work, this author [16] described a connectionist model (VIPS) that learned
to perform 3-D visual transformations on simulated wire-frame objects. Since in complex
sensory-motor environments it is not possible, in general, to learn a direct relationship
between an outgoing command state and an incoming sensory state, VIPS was designed
to predict changes in the state of its visual field as a function of its outgoing motor command. VIPS could then use its generic knowledge of motor-driven visual transformations
to ""mentally rotate"" objects through a series of steps.

546

Recinolopic
Visual RepresemaDOII

-- -

Value-Coded
loint RepresenlatiOll

- --

I
Figure 1: MURPHY's Connectionist Architecture. 4096 coarsely-tuned visual
units are organized in a square, retinotopic grid. These units are bi-directionally
interconnected with a population of 273 joint units. The joint population is subdivided into 3 sUbpopulations, each one a value-coded representation of joint angle
for one of the three joints. During training, activity in the joint unit population
determines the physical arm configuration.

Inside MURPY
The current work has sought to further explore the process of learning-by-doing in a
complex sensory-motor domain, extending previous work in three ways. First, the learning
of mappings between sensory and command (e.g. motor) representations should be allowed
to proceed in both directions simultaneously during exploratory behavior, where each
mapping may ultimately subserve a very different behavioral goal. Secondly, MURPHY
has been implemented with a real camera and robot arm in order to insure representational
realism to the greatest degree possible. Third, while the specifics of MURPHY's internal
structures are not intended as a model of a specific neural system, a serious attempt has
been made to adhere to architectural components and operations that have either been
directly suggested by nervous system structures, or are at least compatible with what is
currently known. Detailed biological justification on this point awaits further work.

MURPHY's Body
MURPHY consists of a 512 x 512 JVC color video camera pointed at a Rhino XR-3 robotic
arm. Only the shoulder, elbow, and wrist joints are used, such that the arm can move
only in the image plane of the camera. (A fourth, waist joint is not used). White spots are
stuck to the arm in convenient places; when the image is thresholded, only the white spots
appear in the image. This arrangement allows continuous control over the complexity of
the visual image of the arm, which in turn affects time spent both in computing visual
features and processing weights during learning. A Datacube image processing system is
used for the thresholding operation and to ""blur"" the image in real time with a gaussian
mask. The degree of blur is variable and can be used to control the degree of coarse-coding
(i.e. receptive field overlap) in the camera-topic array of visual units. The arm is software
controllable, with a stepper motor for each joint. Arm dynamics are not considered in this
work.

547

MURPHY's Mind
MURPHY is currently based on two interconnected populations of neuron-like units. The
first is organized as a rectangular, visuotopically-mapped 64 x 64 grid of coarsely-tuned
visual units that each responds when a visual feature (such as a white spot on the arm)
falls into its receptive field (fig. 1). Coarse coding insures that a single visual feature will
activate a small population of units whose receptive fields overlap the center of stimulation.
The upper trace in figure 2 shows the unprocessed camera view, and the center trace depicts
the resulting pattern of activation over the grid of visual units.
The second population of 273 units consists of three subpopulations, representing the
angles of each of the three joints. The angle of each joint is value-coded in a line of
units dedicated to that joint (fig. 1). Each unit in the population is ""centered"" at a
some joint angle, and is maximally activated when the joint is to be sent to that angle.
Neighboring joint units within a joint sub population have overlapping ""projective fields""
and progressively increasing joint-angle centers.
It may be noticed that both populations of units are coarsely tuned, that is, the units
have overlapping receptive fields whose centers vary in an orderly fashion from unit to
neighboring unit. This style of representation is extremely common in biological sensory
systems [17,18,19]' and has been attributed a number ofrepresentational advantages (e.g.
fewer units needed to encode range of stimuli, increased immunity to noise and unit malfunction, and finer stimulus discriminations). A number of additional advantages of this
type of encoding scheme are discussed in section, in relation to ease of learning, speed of
learning, and efficacy of generalization.

MURPHY's Education
By moving its arm through a small, representative sample (approximately 4000) of the
1 billion possible joint configurations, MURPHY learns the relationships, backwards and
forwards, between the positions of its joints and the state of its visual field. During training, the physical environment to which MURPHY's visual and joint representations are
wired enforces a particular mapping between the states of these two representations. The
mapping comprises both the kinematics of the arm as well as the optical parameters and
global geometry of the camera/imaging system. It is incrementally learned as each unit in
population B comes to ""recognize"" , through a process of weight modification, the states of
population A in which it has been strongly activated. After sufficient training experience
therefore, the state of popUlation A is sufficient to generate a ""mental image"" on population B, that is, to predictively activate the units in B via the weighted interconnections
developed during training.
In its current configuration, MURPHY steps through its entire joint space in around
1 hour, developing a total of approximately 500,000 weights between the two popUlations .

The Learning Rule
Tradeoffs in Learning and Representation
It is well known in the folklore of connectionist network design that a tradeoff exists
between the choice of representation (i.e. the ""semantics"") at the single unit level and the
consequent ease or difficulty of learning within that representational scheme.
At one extreme, the single-unit representation might be completely decoded, calling for
a separate unit for each possible input pattern. While this scheme requires a combinatorially explosive number of units, and the system must ""see"" every possible input pattern
during training, the actual weight modification rule is rendered very simple. At another
extreme, the single unit representation might be chosen in a highly encoded fashion with
complex interactions among input units. In this case, the activation of an output unit

548

may be a highly non-linear or discontinuous function of the input pattern, and must be
learned and represented in mUltiple layers of weights.
Research in connectionism has often focused on Boolean functions [20,21,1,22,23], typified by the encoder problem [20], the shifter problem [21] and n-bit parity [22]. Since
Boolean functions are in general discontinuous, such that two input patterns that are close
in the sense of Hamming distance do not in general result in similar outputs, much effort
has been directed toward the development of sophisticated, multilayer weight-modification
rules (e.g. back-propagation) capable of learning arbitrary discontinuous functions. The
complexity of such learning procedures has raised troubling questions of scaling behavior
and biological plausibility.
The assumption of continuity in the mappings to be learned, however, can act to
significationly simplify the learning problem while still allowing for full generalization to
novel input patterns. Thus, by relying on the continuity assumption, MURPHY's is able
to learn continuous non-linear functions using a weight modification procedure that is
simple, locally computable, and confined to a single layer of modifiable weights.

How MURPHY learns
For sake of concrete illustration, MURPHY's representation and learning scheme will be
described in terms of the mapping learned from joint units to visual units during training.
The output activity of a given visual unit may be described as a function over the 3dimensional joint space, whose shape is determined by the kinematics of the arm, the
location of visual features (i.e. white spots) on the arm, the global properties of the
camera/imaging system, and the location of the visual unit's receptive field. In order for
the function to be learned, a visual unit must learn to ""recognize"" the regions of joint
space in which it has been visually activated during training. In effect, each visual unit
learns to recognize the global arm configurations that happen to put a white spot in its
receptive field.
It may be recalled that MURPHY's joint unit population is value-coded by dimension,
such that each unit is centered on a range of joint angles (overlapping with neighboring
units) for one of the 3 joints. In this representation, a global arm configuration can
be represented as the conjunctive activity of the k (where k 3) most active joint units.
MURPHY's visual units can therefore learn to recognize the regions of joint space in which
they are strongly activated by simply ''memorizing'' the relevant global joint configurations
as conjunctive clusters of input connections from the value-coded joint unit population.
To realize this conjunctive learning scheme, MURPHY's uses sigma-pi units (see [24]),
as described below. At training step S, the set of k most active joint units are first
identified. Some subset of visual units is also strongly activated in state S, each one
signalling the presence of a visual feature (such as a white spot) in its receptive fields.
At the input to each active visual unit, connections from the k most highly active joint
units are formed as a multiplicative k-tuple of synaptic weights. The weights Wi on these
connections are initially chosen to be of unit strength. The output Cj of a given synaptic
conjunction is computed by multiplying the k joint unit activation values Xi together with
their weights:

=

The output y of the entire unit is computed as a weighted sum of the outputs of each
conjunction and then applying a sigmoidal nonlinearity:

y

= u(L WjCj).
i

Sigma-pi units of this kind may be thought of as a generalization of a logical disjunction of
conjunctions (OR of AND's). The multiplicative nature of the conjunctive clusters insures

549

that every input to the conjunct is active in order for the conjunct to have an effect on
the unit as a whole. If only a single input to a conjunct is inactive, the effect of the
conjunction is nullified.
Specific-Instance Learning in Continuous Domains
MURPHY's learning scheme is directly reminiscent of specific-instance learning as discussed by Hampson &: Vol per [23] in their excellent review of Boolean learning and representational schemes. Specific-instance learning requires that each unit simply ''memorize""
all relevant input states, i.e. those states in which the unit is intended to fire. Unfortunately, simple specific-instance learning allows for no generalization to novel inputs,
implying that each desired system responses will have to have been explicitly seen during training. Such a state of affairs is clearly impractical in natural learning contexts.
Hampson &: Volper [23] have further shown that random Boolean functions will require
an exponential number of weights in this scheme.
For continous functions on the other hand, two kinds of generalization are possible
within this type of specific-instance learning scheme. We consider each in turn, once again
from the perspective of MURPHY's visual units learning to recognize the regions in joint
space in which they are activated.
Generalization by Coarse-Coding
When a visual unit is activated in a given joint configuration, and acquires an appropriate
conjunct of weights from the set of highly active units in the joint popUlation, by continuity the unit may assume that it should be at least partially activated in nearby joint
configurations as well. Since MURPHY's joint units are coarse-coded in joint angle, this
will happen automatically: as the joints are moved a small distance away from the specific
training configuration, the output of the conjunct encoding that training configuration
will decay smoothly from its maximum. Thus, a visual unit can ""fire"" predictively in joint
configurations that it has never specifically seen during training, by interpolating among
conjuncts that encode nearby joint configurations.
This scheme suggests that training must be sufficiently dense in joint space to have
seen configurations ''nearby'' to all points in the space by some criterion. In practice, the
training step size is related to the degree of coarse-coding in the joint population, which is
chosen in tUrn such that a joint pertubation equal to the radius of a joint unit's projective
field (i.e. the range of joint angles over which the unit is active) should on average push
a feature in the visual field a distance of about one visual receptive field radius. As a rule
of thumb, the visual receptive field radius is chosen small enough so as to contain only a
single feature on average.
Generalization by Extrapolation

The second type of generalization is based on a heuristic principle, again illustrated in
terms of learning in the visual population. If a visual unit has during training been
very often activated over a large, easy-to-specify region of joint space, such as a hyperrectangular region, then it may be assumed that the unit is activated over the entire region
of joint space, i.e. even at points not yet seen. At the synaptic level, ""large regions"" can be
represented as conjuncts with fewer terms. In its simplest form, this kind of generalization
amounts to simply throwing out one or more joints as irrelevant to the activation of a
given visual unit. What synaptic mechanism can achieve this effect? Competition among
joint unit afferents can be used to drive irrelevant variables from the sigma-pi conjuncts.
Thus, if a visual unit is activated repeatedly during training, and the elbow and shoulder
angle units are constantly active while the most active wrist unit varies from step to step,
then the weighted connections from the repeatedly activated elbow and shoulder units

550

--

.

? ?
?

--

?
,

??

?

?? ?

?

?

,..
til

I

.;

,

?.. ?

?

,.,
I

Figure 2: Three Visual Traces. The top trace shows the unprocessed camera view
of MURPHY's arm. White spots have been stuck to the arm at various places, such
that a thresholded image contains only the white spots. This allows continuous
control over the visual complexity of the image. The center trace represents the
resulting pattern of activation over the 64 x 64 grid of coarsely-tuned visual units.
The bottom trace depicts an internally-produced ""mental"" image of the arm in the
same configuration as driven by weighted connections from the joint population.
Note that the ""mental"" trace is a sloppy, but highly recognizable approximation
to the camera-driven trace.
will become progressively and mutually reinforced at the expense of the set of wrist unit
connections, each of which was only activated a single time.
This form of generalization is similar in function to a number of ""covering"" algorithms
designed to discover optimal hyper-rectangular decompositions (with possible overlap) of
a set of points in a multi-dimensional space (e.g. [25,26]). The competitive feature has
not yet been implemented explicitly at the synaptic level, rather, the full set of conjuncts
acquired during training are currently collapsed en masse into a more compact set of conjuncts, according to the above heuristics. In a typical run, MURPHY is able to eliminate
between 30% and 70% of its conjuncts in this way.

What MURPHY Does
Grabbing A Visually Presented Target
Once MURPHY has learned to image its arm in an arbitrary joint configuration, it can
use heuristic search to guide its arm ""mentally"" to a visually specified goal. Figure 3(a)
depicts a hand trajectory from an initial position to the location of a visually presented
target. Each step in the trajectory represents the position of the hand (large blob) at an
intermediate joint configuration. MURPHY can visually evaluate the remaining distance
to the goal at each position and use best-first search to reduce the distance. Once a
complete trajectory has been found, MURPHY can move its arm to the goal in a single
physical step, dispensing with all backtracking dead-ends, and other wasted operations (fig.
3(b? . It would also be possible to use the inverse model, i.e. the map from a desired visual
into an internal joint image, to send the arm directly to its final position. Unfortunately,
MURPHY has no means in its current early state of development to generate a full-blown

551

-

_... -

M1RPI!Y'. HInt&! Tra jeetory

Figure 3: Grabbing a.n Object. (a) Irregular trajectory represents sequence of
""mental"" steps taken by MURPHY in attempting to ""grab"" a visually-presented
target (shown in (b) as white cross). Mental image depicts MURPHY's arm in its
final goal configuration, i.e. with hand on top of object. Coarse-coded joint activity
is shown at right. (b) Having mentally searched a.nd found the target through a
series of steps, MURPHY moves its arm phY6ically in a single step to the target,
discarding the intermediate states of the trajectory that are not relevant in this
simple problem.

visual image of its arm in one of the final goal positions, of which there are many possible.
Sending the tip of a robot arm to a given point in space is a classic task in robotics.
The traditional approach involves first writing explicit kinematic equations for the arm
based on the specific geometric details of the given arm. These equations take joint angles
as inputs and produce manipUlator coordinates as outputs. In general, however, it is
most often useful to specify the coordinates of the manipulator tip (i.e. its desired final
position), and compute the joint angles necessary to achieve this goal. This involves the
solution of the kinematic equations to generate an inverse kinematic model. Deriving such
expressions has been called ""the most difficult problem we will encounter"" in vision-based
robotics [27]. For this reason, it is highly desirable for a mobile agent to learn a model
of its sensory-motor environment from scratch, in a way that depends little or not at all
on the specific parameters of the motor apparatus, the sensory apparatus, or their mutual
interactions. It is interesting to note that in this reaching task, MURPHY appears from
the outside to be driven by an inverse kinematic model of its arm, since its first official
act after training is to reach directly for a visually-presented object.
While it is clear that best-first search is a weak method whose utility is limited in complex problem solving domains, it may be speculated that given the ability to rapidly image
arm configurations, combined with a set of simple visual heuristics and various mechanism
for escaping local minima (e.g. send the arm home), a number of more interesting visual
planning problems may be within MURPHY's grasp, such as grabbing an object in the
presence of obstacles. Indeed, for problems that are either difficult to invert, or for which
the goal state is not fully known a priori, the technique of iterating a forward-going model
has a long history (e.g. Newton's Method).

552

Imitating Autonomous Arm Activity
A particularly interesting feature of ""learning-by-doing"" is that for every pair of unit
populations present in the learning system, a mapping can be learned between them both
backwards and forwards. Each such mapping may enable a unique and interesting kind of
behavior. In MURPHY's case, we have seen that the mapping from a joint state to a visual
image is useful for planning arm trajectories. The reverse mapping from a visual state to
ajoint image has an altogether different use, i.e. that of ""imitation"". Thus, if MURPHY's
arm is moved passively, the model can be used to ''follow'' the motion with an internal
command (i.e. joint) trace. Or, if a substitute arm is positioned in MURPHY's visual
field, MURPHY can ""assume the position"", i.e . imitate the model arm configuration by
mapping the afferent visual state into a joint image, and using the joint image to move the
arm. As of this writing, the implementation of this behavior is still somewhat unreliable.

Discussion and Future Work
In short, this work has been concerned with learning-by-doing in the domain of visionbased robotics. A number of features differentiate MURPHY from most other learning
systems, and from other approaches to vision-based robotics:
? No intelligent teacher is needed to provide input-ouput pairs. MURPHY learns by
exercising its repertoire of actions and learning the relationship between these actions
and the sensory images that result.
? Mappings between populations of units, regardless of modality, can be learned in
both directions simultaneously during exploratory behavior. Each mapping learned
can support a distinct class of behaviorally useful functions.
? MURPHY uses its internal models to first solve problems ""mentally"". Plans can
therefore be developed and refined before they are actually executed.
? By taking explicit advantage of continuity in the mappings between visual and joint
spaces, and by using a variant of specific-instance learning in such a way as to allow
generalization to novel inputs, MURHPY can learn ""difficult"" non-linear mappings
with only a single layer of modifiable weights.
Two future steps in this endeavor are as follows:
? Provide MURPHY with direction-selective visual and joint units both, so that it
may learn to predict relationships between rates of change in the visual and joint
domains. In this way, MURPHY can learn how to perturb its joints in order to send
its hand in a particular direction, greatly reducing the current need to search for
hand trajectories.
? Challenge MURPHY to grab actual objects, possibly in the presence of obstacles,
where path of approach is crucial. The ability to readily envision intermediate arm
configurations will become critical for such tasks.
.

Acknowledgements
Particular thanks are due to Stephen Omohundro for his unrelenting scientific and moral
support, and for suggesting vision and robotic kinematics as ideal domains for experimentation.

553

References
[1] T.J. Sejnowski & C.R. Roaenberg, Complex Systems, 1, 145, (1969).
[2] G.J. Tesauro & T.J. Sejnowski. A parallel network that leMIUI to play backgammon. Submitted for
publication.
[3] S. Grossberg, BioI. Cybern., f3, 187, (1976).
[4] T. Kohonen, Self organization and auociati""e memory., (Springer-Verlag, Berlin 1984).
[5] D.E. Rumelhart & D. Zipser. In Parallel diatri6uted proceuing: e:rplorationa in tA.e microatructure
oj cognition, ""01. 1, D.E. Rumelhart, J.L. McClelland, Eds., (Bradford: Cambridge, MA, 1986), p.
151.
[6] R. Linsker, Proc. Natl. Acad. Sci., 83, 8779, (1986).

[7] G.E. Hinton & J.L. McClelland. Learning representations by recirculation. Oral presentation, IEEE
conference on Neural Information Processing Systems, Denver, 1987.
[8] A.G. Barto, R.S. Sutton, & C.W. Anderson, IEEE Trans. on Sy ?. , Man, Cybern., amc-13, 834, (1983).
[9] H. Ginsburg & S. Opper, Piaget'a tA.eor, oj intellectual de""elopment., (Prentice Hall, New Jersey,
1969).
[10] J.D. Becker. In Computer modela Jor tA.ougA.t and language., R. Schank & K.M. Colby, Eds., (FreelllAIl, San Francisco, 1973).
[11] R.L. Rivest & R.E. Schapire. In Proc. of the 4th into workshop on ma.ch.ine learning, 364-375, (1987).
[12] J .G. Carbonell & Y. Gil. In Proc. of the 4th into workshop on machlne learning, 256-266, (1987).
[13] K. Chen, Tech Report, Dept. of Computer Science, University of illinois, 1987.
[14] A.G. Barto & R.S. Sutton, AFWAL-TR-81-1070, Avionics Laboratory, Air Force Wright Aeronautical
Laboratories, Wright-Patterson AFB, Ohio 45433, 1981.
[15] D.E. Rumelhart, ""On learning to do what you want"". Talk given at CMU Connectionist Summer
School,1986a.
[16] B.W. Melin Proc. of 8th Ann. Con!. of the Cognitive Science Soc., 562-571, (1986).
[17] D.H. Ballard, G.E. Hinton, & T.J Sejnowski, Nature, 306, 21, (1983).
[18] R.P. Erikson, American Scientist, May-June 1984, p. 233.
[19] G.E. Hinton, J.L. McClelland, & D.E. Rumelhart. In Parallel diatri6uted proceuing: e:rplorationa
in tA.e microatructure oj cognition, ""01. 1, D.E. Rumelhart, J .L. McClelland, Eds., (Bradford, Cambridge, 1986), p. 77.
[20] D.H. Ackley, G.E. Hinton, & T.J. Sejnowski, Cognitive Science, 9, 147, (1985).
[21] G.E. Hinton & T .J. Sejnowski. In Parallel diatri6uted proceuing: e:rplorationa in tA.e microatructure
oj cognition, ""01. 1, D.E. Rumelhart, J.L. McClelland, Eds., (Bradford, Cambridge, 1986), p. 282.
[22] G.J. Tes&llro, Complex Systems, 1,367, (1987).
[23] S.E. Hampson & D.J. Volper, Biological Cybernetics, 56, 121, (1987).
[24] D.E. Rumelhart, G.E. Hinton, & J.L. McClelland. In Parallel diatri6uted proceuing: e:rplorationa
in tA.e microatructure oj cognition, ""01. 1, D.E. Rumelhart, J.L. McClelland, Eds., (Bradford, Cambridge, 1986), p. 3.
[25] R.S. Michalski, J.G. Carbonell, & T.M. Mitchell, Eds., MacA.ine learning: an artificial intelligence
approacA., Vois. I and II, (Morgan KauflllAll, Los Altos, 1986).
[26] S. Omohundro, Complex Systems, 1, 273, (1987).
[27] Paul, R. R060t manipulatora: matA.ematica, programming, and control., (MIT Press, Cambridge,
1981).

"
93,1988,"A Computationally Robust Anatomical Model for Retinal Directional Selectivity","",93-a-computationally-robust-anatomical-model-for-retinal-directional-selectivity.pdf,"Abstract Missing","477

A COMPUTATIONA.LLY ROBUST
ANATOlVIICAL MODEL FOR RETIN.AL
DIRECTIONAL SELECTI\l ITY
Norberto M. Grzywacz
Center BioI. Inf. Processing
MIT, E25-201
Cambridge, MA 02139

Franklin R. Amthor
Dept. Psychol.
Univ. Alabama Birmingham
Birmingham, AL 35294

ABSTRACT
We analyze a mathematical model for retinal directionally selective
cells based on recent electrophysiological data, and show that its
computation of motion direction is robust against noise and speed.

INTROduCTION
Directionally selective retinal ganglion cells discriminate direction of visual motion
relatively independently of speed (Amthor and Grzywacz, 1988a) and with high
contrast sensitivity (Grzywacz, Amthor, and Mistler, 1989). These cells respond
well to motion in the ""preferred"" direction, but respond poorly to motion in the
opposite, null, direction.
There is an increasing amount of experimental work devoted to these cells.
Three findings are particularly relevant for this paper: 1- An inhibitory process
asymmetric to every point of the receptive field underlies the directional selectivity
of ON-OFF ganglion cells of the rabbit retina (Barlow and Levick, 1965). This
distributed inhibition allows small motions anywhere in the receptive field center
to elicit directionally selective responses. 2- The dendritic tree of directionally
selective ganglion cells is highly branched and most of its dendrites are very fine
(Amthor, Oyster and Takahashi, 1984; Amthor, Takahashi, and Oyster, 1988). 3The distributions of excitatory and inhibitory synapses along these cells' dendritic
tree appear to overlap. (Famiglietti, 1985).
Our own recent experiments elucidated some ofthe spatiotemporal properties of
these cells' receptive field. In contrast to excitation , which is transient with stimulus,
the inhibition is sustained and might arise from sustained amacrine cells (Amthor
and Grzywacz, 1988a). Its spatial distribution is wide, extending to the borders
of the receptive field center (Grzywacz and Amthor, 1988). Finally, the inhibition
seems to be mediated by a high-gain shunting, not hyperpolarizing, synapse, that
is, a synapse whose reversal potential is close to cell's resting potential (Amthor
and Grzywacz, 1989).

478

Grzywacz and Amthor

In spite of this large amount of experimental work, theoretical efforts to put
these pieces of evidence into a single framework have been virtually inexistent.
We propose a directional selectivity model based on our recent data on the
inhibition's spatiotemporal and nonlinear properties. This model, which is an elaboration of the model of Torre and Poggio (1978), seems to account for several
phenomena related to retinal directional <;eledivity.

THE ]\IIODEL
Figure 1 illustrates the new model for retinal directional selectivity. In this modd,
a stimulus moving in the null direction progressively activates receptive field regions
linked to synapses feeding progressively more distal dendrites Of the ganglion cells .
Every point in the receptive field center activates adjacent excitatory a~d inhibitory
synapses. The inhibitory synapses are assumed to cause shunting inhibition. (""'""e
also formulated a pre-ganglionic version of this model, which however, is outside
the scope of this paper) .

.--

NULL

FIGURE 1. The new model for retinal directional selectivity.
This model is different than that of Poggio and Koch (1987), where the motion axis is
represented as a sequence of activation of different dendrites. Furthermore, in their
model, the inhibitory synapses must be closer to the soma than the excitatory ones .
(However, our model is similar a model proposed, and argued against, elsewhere
(Koc,h, Poggio, and Torre, 1982).
An advantage of our model is that it accounts for the large inhibitory areas t.o
most points of the receptive field (Grzywacz and Amthor, 1988). Also, in the new
model, the distributions of the excitatory and inhibitory synapses overlap along the
dendritic tree, as suggested (Famiglietti, 1985). Finally, the dendritic tree of ONOFF directionally selective ganglion cells (inset- Amthor, Oyster, and Takahashi,

A Computationally Robust Anatomical Model

1984) is consistent with our model. The tree's fine dendrites favor the multiplicity
of directional selectivity and help to deal with noise (see below).
In this paper, we make calculations with an unidimensional version of the model
dealing with motions in the preferred and null directions. Its receptive field maps
into one dendrite of the cell. Set the origin of coordinates of the receptive field to be
the point where a dot moving in the null direction enters the receptive field. Let S
be the size of the receptive field. Next, set the origin of coordinates in the dendri te
to be the soma and let L be the length of the dendrite. The model postulates that
a point z in the receptive field activates excitatory and inhibitory synapses in pain t
z = zL/ S of the dendrite.
The voltages in the presynaptic sites are assumed to be linearly related to the
stimulus, [(z,t), that is, there are functions fe{t) and li(t) such that the excitatory,
{3e(t), and inhibitory, {3i(t), presynaptic voltages of the synapses to position ;r in
the dendrite are

.

J = e,

.
l,

where ""*"" stands for convolution. We assume that the integral of Ie is zero, (the
excitation is transient), and that the integral of Ii is positive. (In practice, gamma
distribution functions for Ii and the derivatives of such functions for Ie were used
in this paper's simulations.)
The model postulates that the excitatory, ge, and inhibitory, gi, postsynaptic
conductances are rectified functions of the presynaptic voltages. In some examples,
we use the hyperbolic tangent as the rectification function:

where Ij and T; are constants. In other examples, we use the rectification functions
described in Grzywacz and Koch (1987), and their model of ON-OFF rectifications.
For the postsynaptic site, we assume, without loss of generality, zero reversal
potential and neglect the effect of capacitors (justified by the slow time-courses of
excitation and inhibition).
Also, we assume that the inhibitory synapse leads to shunting inhibition, that
is, its conductance is not in series with a battery. Let Ee be the voltage of the
excitatory battery. In general, the voltage, V, in different positions of the dendrite
is described by the cable equation:

d2~~:, t)

= Ra (-Ee!}e (z, t) + V (z, t) (ge (z, t) + 9j (z, t) + 9,.)),

where Ra is the axoplasm resistance per unit length, g,. is the resting membrane
conductance, and the tilde indicates that in this equation the conductances are
given per unit length.

479

480

Grzywacz and Amthor

For the calculations illustrated in this paper, the stimuli are always delivered to
the receptive field through two narrow slits. Thus, these stimuli activate synapses
in two discrete positions of a dendrite. In this paper, we only show results for square
wave and sinusoidal modulations of light, however, we also performed calculations
for more general motions.
The synaptic sites are small so that their resting conductances are negligible,
and we assume that outside these sites the excitatory and inhibitory conductances
are zero. In this case, the equation for outside the synapses is:
d2U
dy2 = U,

=

where we defined A 1/(Ra y,,)1/2 (the length constant), U = V/Ee, and y
The boundary conditions used are

=

= Z/A.

=

where L L/ A, and where if R, is the soma's input resistance, then p
R, /(RaA)
(the dendritic-to-soma cond uctance ratio). The first condition means that currents
do not flow through the tips of the dendrites.
Finally, label by 1 the synapse proximal to the soma, and by 2 the distal one;
the boundary conditions at the synapses are

1I~lIj

= lim

II> 111

1I<lIj

lim U

1I~lIj

U,

j = 1,2,

j = 1,2,

(I )

where 7'e = geRa).. and 7'i = 9iRa)...
It can be shown that the relative inhibitory strength for motions in the preferred
direction decreases with L and increases with p. Thus, to favor conditions for
multiplicity of direction selectivity in the receptive field, we perform calculations
with L -+ 00 and p = 1. The strengths of the excitatory syna.pses are set such that
their contribution to somatic voltage in the absence of inhibition is in variant with
position. Finally, we ensure that the excitatory synapses never sat urate.
Under these conditions, one can show that the voltage in the soma is:

U (0) =

{27'e,2

+ (7'e,2 + 7'i,2 + 2) 7'e,d e2~y - (7'?,2 + 7'j,2) 7'e,1 ,
((7'i,l +2)7'i,2 + 27'j,1 +4)e 26Y - 7'i,17'i,2

(2)

where 6y is the distance between the synapses.
A fina.l quantity, which is used in this paper is the directional selectivity index
It. Let Up and Un be the total responses to the second slit in the apparent motion
in the preferred and null directions respectively. {Alternatively, for the sinusoidal

A Computationally Robust Anatomical Model

motion, these quantities are the respective average responses .) \Ve follow Grzywacz
and Koch (198i) and define
(3)

RESULTS
This section presents the results of calcuhtions ba.""ed on the modd. \Ve address:
the multiple computations of directional seir->divity in the {.?ells? receptive fields; the
robustness of these computations again~t noise: I h"" robustness of these computations against speed.
Figure 2 plots the degree of directional selectivity for apparent lIlotions activating two synapses as function of the synapses' distan,'e in a dendrite (computed
from Equations 2 and 3).
1.

~---------------------------

32

.""..

16

...c::

-....
-..,
...

B

>~

'""

..

.5

u

~

2

c:

a

'""
u

""-

0.5

c'""

.0
.00
l!~IG URE

1 .5
1.0
. 50
Dendritic Distance (>.1

2. Locality of lnkraction betwt't""'n

2.0

synap""'t'~ a(I1\-'(1l,'""

hv apparent mo-

tions.
It can be shown that the critical parameter controlling whether a certain synaptic distance produces a criterion directional selectivity is rj (Equation 1). As the
parameter rj increases, the criterion distance decreases , Thus , ""ince in retinal directionally selective cells the inhibition has high gain (Amthor and Grzywa<.""z, 1989)
and the dendrites are fine (Amthor, Oyster and Takahashi, 1984; Amthor, Takahashi, and Oyster, 1988), then rj is high, and motions anywhere in receptive field
should elicit directionally selective responses (Barlow and Levick, 1965). In other
words, the model's receptive field computes motion direction multiple times.
Next, we show that the high inhibitory gain and the cells' fine dendrites help to
deal with noise, and thus . may explain the high contrast sensitivity (0.5% contrast-

481

482

Grzywacz and Amthor

Grzywacz, Amthor, and Mistler, 1989) of the cells' directional selectivity. This
conclusion is illustrated in Figure 3's multiple plots.

..

- -Looo

..

~ 1.0

-

OUTPUT NOISE

J

~I

-""11

INIIIIT DAY 1IfI\/1 NOIS?

VCCJ1ATDA'f 1IfI\/1 NOI.

!.

~1

, "".., ......a

-NlgII

,

..
.50

..

N

,,

...

oo-===--e:;..........::.-....;::.,---==--..::..
00

10

? .0
Response

?. 00

.0

10

.00

Response

4.0

.

1.0
Aupan ..

FIGURE 3. The model's computatifm of direction is robust against additive noise
in the output, and in the excitatory and inhibitory inputs.
To generate this figure, we used Equation 2 assuming that a Gaussian noise is added
to the cell's output, excitatory input, or inhibitory input. {In the latter case, we
used an approximation that assumes small standard deviation for the inhibitory
input's noise.)
Once again the critical parameter is the ri defined in Equation 1. The larger
this parameter is, the better the model deals with noise. In the case of output noise,
an increase of the parameter separatt's the preferred and null mean responses. For
noise in the excitatory input, a parameter increase not only separates the means,
but also reduces the standard deviation: Shunting inhibition SHUnTS down the
noise. Finally, the most dramatic improvement occurs when the noise is in the
inhibitory input. (In all these plots, the parameter increase is always by a factor of
three.)
Since for retinal direc tionally selective ganglion cells, ri is high (high inhibitory
gain and fine dendrites), we conclude that the cells' mechanism are particularly well
suited to deal with noise.
For sinusoidal motions, the directional selectivity is robust for a large range
of temporal frequencies provided that the frequencies are sufficiently low (Figure
4). (Nevertheless, the cell's preferred direction responses may be sharply tuned to
either temporal frequency or speed- Amthor and Grzywacz, 1988).

A Computationally Robust Anatomical Model

I

-HI"", rl
- 'llHl rl
I

!

,

\

I
I

I
I

I

I

i

2.00

~

,

I

iis

::

""

I

--

20.0

200.

---------------

,i
i

i

is

2.00

20 .0
FrtQlltncy ~I

IE-roo

FIGURE 4. Directional selectivity is robust against speed modulation. To generate this curve, we subtracted the average respons~ to a isolated flickering slit from
the preferred and null average responses (from Equation 2).
This robustness is due to the invariance with speed for low speeds of the relative
temporal phase shift between inhibition and excitation. Since the excitation has
band-pass characteristics, it leads the stimulus by a constant phase. On the other
hand, the inhibition is delayed and advanced in the preferred and null directions
respectively, due to the asymmdric spatial integration. The phase shifts due to this
integration are also speed invariant.

CONCLUSIONS
We propose a new model for retinal directional selectivity. The shunting inhibition of ganglion cells (Torre and Poggio, 1978), which is temporally sustained, is
the main biophysical mechanism of the model. It postulates that for null direction motion, the stimulus activates regions of the receptive field that are linked to
excitatory and inhibitory synapses, which are progressively farther away from the
soma. This models accounts for: 1- the distribution of inhibition around points
of the receptive field (Grzywacz and Amthor, 1988); 2- the apparent full overlap
of the distribution of excitatory and inhibitory synapses along the dendritic trees
of directionally selective ganglion cells (Famiglietti, 1985); 3- the multiplicity of
directionally selective regions (Barlow and Levick, 1965); 4- the high contrast sensitivity of the cells' directional selectivity (Grzywacz, Amthor, and Mistler, 1989);
5- the relative in variance of directional selectivity on stimulus speed (Amthor and
Grzywacz, 1988).
Two lessons of our model to neural network modeling are: Threshold is not
the only neural mechanism, and the basic computational unit may not be a neuron

483

484

Grzywacz and Amthor

but a piece of membrane (Grzywacz and Poggio, 1989). In our model, nonlinear
interactions are relatively confined to specific dendritic tree branches (Torre and
Poggio, 1978). This allows local computations by which single cells might generate
receptive fields with multiple directionally selective regions, as observed by Barlow
and Levick (1965). Such local computations could not occur if the inhibition only
worked through a reduction in spike rate by somatic hyperpolarization.
Thus, most neural network models may be biologically irrelevant, since they
are built upon a too simple model of the neuron. The properties of a network
depend strongly on its basic elements. Therefore, to understand the computations
of biological networks. it may be essential to first understand the basic biophysical
mechanisms of information processing before developing complex networks.

ACKNOWLEDGMENTS
We thank Lyle Borg-Graham and Tomaso Poggio for helpful discussions. Also, we
thank Consuelita Correa for help with the figures. N .M.G. was supported by grant
BNS-8809528 from the National Science Foundation, by the Sloan Foundation, and
by a grant to Tomaso Poggio and Ellen Hildreth from the Office of Naval Research,
Cognitive and Neural Systems Division. F.R.A. was supported by grants from the
National Institute of Health (EY05070) and the Sloan Foundation.

REFERENCES
Amthor & Grzywacz (1988) Invest. Ophthalmol. Vi"". Sci. 29:225.
Amthor & Grzywacz (1989) Retinal Directional Selectivity Is Accounted for by
Shunting Inhibition. Submitted for Publication.
Amthor, Oyster & Takahashi (1984) Brain Res. 298:187.
Amthor, Takahashi & Oyster (1989) J. Compo Neurol. In Press.
Barlow & Levick (1965) J. Physiol. 178:477.
Famiglietti (1985) Neuro""ci. Abst. 11:337.
Grzywacz & Amthor (1988) Neurosci. Ab""t. 14:603.
Grzywacz, Amthor & Mistler (1989) Applicability of Quadratic and Threshold Models to Motion Discrimination in the Rabbit Retina. Submitted for Publication.
Grzywacz & Koch (1987) Synapse 1:417.
Grzywacz & Poggio (1989) In An Introduction to Neural and Electronic Networks.
Zornetzer, Davis & Lau, Eds. Academic Press, Orlando, USA. In Press.
Koch, Poggio & Torre (1982) Philos . Tran"". R. Soc. B 298:227.
Poggio & Koch (1987) Sci. Am. 256:46.
Torre & Poggio (1978) Proc. R. Soc. B 202:409.

"
94,1988,"Learning with Temporal Derivatives in Pulse-Coded Neuronal Systems","",94-learning-with-temporal-derivatives-in-pulse-coded-neuronal-systems.pdf,"Abstract Missing","195

LEARNING WITH TEMPORAL DERIVATIVES IN
PULSE-CODED NEURONAL SYSTEMS
Mark Gluck

David B. Parker

Eric S. Reifsnider

Department of Psychology
Stanford University
Stanford, CA 94305

Abstract
A number of learning models have recently been proposed which
involve calculations of temporal differences (or derivatives in
continuous-time models). These models. like most adaptive network
models. are formulated in tenns of frequency (or activation), a useful
abstraction of neuronal firing rates. To more precisely evaluate the
implications of a neuronal model. it may be preferable to develop a
model which transmits discrete pulse-coded information. We point out
that many functions and properties of neuronal processing and learning
may depend. in subtle ways. on the pulse-coded nature of the information coding and transmission properties of neuron systems. When compared to formulations in terms of activation. computing with temporal
derivatives (or differences) as proposed by Kosko (1986). Klopf
(1988). and Sutton (1988). is both more stable and easier when reformulated for a more neuronally realistic pulse-coded system. In reformulating these models in terms of pulse-coding. our motivation has
been to enable us to draw further parallels and connections between
real-time behavioral models of learning and biological circuit models
of the substrates underlying learning and memory.

INTRODUCTION
Learning algorithms are generally defined in terms of continuously-valued levels of input
and output activity. This is true of most training methods for adaptive networks. (e.g .?
Parker. 1987; Rumelhart. Hinton. & Williams, 1986; Werbos. 1974; Widrow & Hoff,
1960). and also for behavioral models of animal and hwnan learning. (e.g. Gluck &
Bower. 1988a, 1988b; Rescorla & Wagner. 1972). as well as more biologically oriented
models of neuronal function (e.g .? Bear & Cooper, in press; Hebb, 1949; Granger.
Abros-Ingerson, Staubli, & Lynch, in press; Gluck & Thompson, 1987; Gluck.
Reifsnider. & Thompson. in press; McNaughton & Nadel. in press; Gluck & Rumelhart.
in press). In spite of the attractive simplicity and utility of the ""activation"" construct

196

Parker, Gluck and Reifsnider

neurons use discrete trains of pulses for the transmission of information from cell to cell.
Frequency (or activation) is a useful abstraction of pulse trains. especially for bridging
the gap between whole-animal and single neuron behavior. To more precisely evaluate
the implications of a neuronal model. it may be preferable to develop a model which
transmits discrete pulse-coded information; it is possible that many functions and properties of neuronal processing and learning may depend. in subtle ways. on the pulse-coded
nature of the information coding and transmission properties of neuron systems.
In the last few years, a number of learning models have been proposed which involve
computations of temporal differences (or derivatives in continuous-time models). Klopf
(1988) presented a formal real-time model of classical conditioning that predicts the
magnitude of conditioned responses (CRs). given the temporal relationships between
conditioned stimuli (eSs) and an unconditional stimulus (US). Klopf's model incorporates a ""differential-Hebbian"" learning algorithm in which changes in presynaptic levels of activity are correlated with changes in postsynaptic levels of activity. Motivated
by the constraints and motives of engineering. rather than animal learning. Kosko (1986)
proposed the same basic rule and provided extensive analytic insights into its properties.
Sutton (1988) introduced a class of incremental learning procedures. called ""temporal
difference"" methods. which update associative (predictive) weights according to the
difference between temporally successive predictions. In addition to the applied potential
of this class of algorithms. Sutton & Barto (1987) show how their model. like Klopf's
(1988) model. provides a good fit to a wide range of behavioral data on classical conditioning.
These models. all of which depend on computations involving changes over time in
activation levels. have been successful both for predicting a wide range of behavioral
animal learning data (Klopf. 1988; Sutton & Barto. 1987) and for solving useful
engineering problems in adaptive prediction (Kosko. 1986; Sutton. 1988). The possibility
that these models might represent the computational properties of individual neurons.
seems, at first glance. highly unlikely. However. we show by reformulating these models
for pulse-coded communication (as in neuronal systems) rather than in terms of abstract
activation levels. the computational soundness as well as the biological relevance of the
models is improved. By avoiding the use of unstable differencing methods in computing
the time-derivative of activation levels. and by increasing the error-tolerance of the computations, pulse coding will be shown to improve the accuracy and reliability of these
models. The pulse coded models will also be shown to lend themselves to a closer comparison to the function of real neurons than do models that operate with activation levels.
As the ability of researchers to directly measure neuronal behavior grows. the value of
such close comparisons will increase. As an example. we describe here a pulse-coded
version of Klopf's differential-Hebbian model of classification learning. Further details
are contained in Gluck. Parker. & Reifsnider. 1988.

Learning with Temporal Derivatives

Pulse-Coding in Neuronal Systems
We begin by outlining the general theory and engineering advantages of pulse-coding
and then describe a pulse-coded refonnulation of differential-Hebbian learning. The key
idea is quite simple and can be summarized as follows: Frequency can be seen, loosely
speaking, as an integral of pulses; conversely, therefore, pulses can be thought of as carrying infonnation about the derivatives of frequency. Thus, computing with the ""derivatives of frequency"" is analogous to computing with pulses. As described below, our
basic conclusion is that differential-Hebbian learning (Klopf, 1988; Kosko, 1986) when
refonnulated for a pulse-coded system is both more stable and easier to compute than is
apparent when the rule is fonnulated in tenns of frequencies. These results have important implications for any learning model which is based on computing with timederivatives, such as Sutton's Temporal Difference model (Sutton, 1988; Sutton & Barto,
1987)
There are many ways to electrically transmit analog information from point to point.
Perhaps the most obvious way is to transmit the infonnation as a signal level. In electronic systems, for example, data that varies between 0 and 1 can be transmitted as a voltage level that varies between 0 volts and 1 volt This method can be unreliable, however, because the receiver of the information can't tell if a constant DC voltage offset has
been added to the information, or if crosstalk has occurred with a nearby signal path. To
the exact degree that the signal is interfered with, the data as read by the receiver will be
erroneously altered. The consequences of faults appearing in the signal are particularly
serious for systems that are based on derivatives of the signal. In such systems, even a
small, but sudden, unintended change in signal level can drastically alter its derivative,
creating large errors.
A more reliable way to transmit analog information is to encode it as the frequency of a
series of pulses. A receiver can reliably detennine if it has received a pulse, even in the
face of DC voltage offsets or moderate crosstalk. Most errors will not be large enough to
constitute a pulse, and thus will have no effect on the transmitted infonnation. The
receiver can count the number of pulses received in a given time window to detennine
the frequency of the pulses. Further infonnation on encoding analog infonnation as the
frequency of a series of pulses can be found in many electrical engineeri.ng textbooks
(e.g., Horowitz & Hill, 1980).
As noted by Parker (1987), another advantage of coding an analog signal as the frequency of a series of pulses is that the time derivative of the signal can be easily and
stably calculated: If x (t) represents a series of pulses (x equals 1 if a pulse is occuring at
time t; otherwise it equals 0) then we can estimate the frequency, f (t), of the series of
pulses using an exponentially weighted time average:

f

(t) =

Jllx

('t)e-Jl{t-'t) d't

197

198

Parker, Gluck and Reifsnider
where Jl is the decay constant. The well known formula for the derivative of 1 (t) is

AtJP- = Jl~(t)-/(t))
Thus. the time derivative of pulse-coded information can be calculated without using any
unstable differencing methods. it is simply a function of presence or absence of a pulse
relative to the current expectation (frequency) of pulses. As described earlier. calculation
of time derivatives is a critical component of the learning algorithms proposed by Klopf
(1988). Kosko (1986) and Sutton (Sutton. 1988; Sutton & Barto 1987). They are also an
important aspect of 2nd order (pseudo-newtonian) extensions of the backpropogation
learning rule for multi-layer adaptive ""connectionist"" networks (parker. 1987).

Summary 01 Klopf s Model
Klopf (1988) proposed a model of classical conditioning which incorporates the same
learning rule proposed by Kosko (1986) and which extends some of the ideas presented
in Sutton and Barto's (1981) real-time generalization of Rescorla and Wagner's (1972)
model of classical conditioning. The mathematical specification of Klopf s model consists of two equations: one which calculates output signals based on a weighted sum of
input signals (drives) and one which determines changes in synapse efficacy due to
changes in signal levels. The specification of signal output level is defined as

where: y (t ) is the measure of postsynaptic frequency of firing at time t; Wi (t) is the
efficacy (positive or negative) of the i th synapse; Xi (t) is the frequency of action potentials at the i th synapse; 9 is the threshold of firing; and n is the number of synapses on
the ""neuron"". This equation expresses the idea that the postsynaptic firing frequency
depends on the summation of the weighted presynaptic firing frequencies. Wi (t )Xi (t ).
relative to some threshold. 9. The learning mechanism is defined as

where: ~Wi (t) is the change in efficacy of the i th synapse at time t; ~y (t) is the change
in postsynaptic firing at time t; 't' is the longest interstimulus interval over which delayed
conditioning is effective. The Cj are empirically established learning rate constants -each corresponding to a different inter-stimulus interval.
In order to accurately simulate various behavioral phenomena observed in classical conditioning. Klopf adds three ancillary assumptions to his model. First. he places a lower
bound of 0 on the activation of the node. Second. he proposes that changes in synaptic

199

Learning with Temporal Derivatives

weight, ~w; (t), be calculated only when the change in presynaptic signal level is positive
-- that is, when Ax; (t-j) > O. Third, he proposes separate excitatory and inhibitory
weights in contrast to the single real-valued associative weights in other conditioning
models (e.g., Rescorla & Wagner, 1972; Sutton & Barto, 1981). It is intriguing to note
that all of these assumptions are not only sufficiently justified by constraints from
behavioral data but are also motivated by neuronal constraints. For a further examination
of the biological and behavioral factors supporting these assumptions see Gluck, Parker,
and Reifsnider (1988).
The strength of Klopf's model as a simple formal behavioral model of classical conditioning is evident. Although the model has not yielded any new behavioral predictions, it
has demonstrated an impressive ability to reproduce a wide, though not necessarily complete, range of Pavlovian behavioral phenomena with a minimum of assumptions.
Klopf (1988) specifies his learning algorithm in terms of activation or frequency levels.
Because neuronal systems communicate through the transmission of discrete pulses, it is
difficult to evaluate the biological plausibility of an algorithm when so formulated. For
this reason, we present and evaluate a pulse-coded reformulation of Klopf's model.

A Pulse-Coded Reformulation of Klopf s Model
We illustrate here a pulse-coded reformulation of Klopf's (1988) model of classical conditioning. The equations that make up the model are fairly simple. A neuron is said to
have fired an output pulse at time t if vet) > e, where e is a threshold value and vet) is
defined as follows:

vet) = (l-d)v(t-l) + !:Wi(t)Xi(t)

(1)

where v (t) an auxiliary variable, d is a small positive constant representing the leakage
or decay rate, Wi (t) is the efficacy of synapse i at time t, and Xi (t) is the frequency of
presynaptic pulses at time t at synapse i. The input to the decision of whether the neuron
will fire consists of the weights and efficacies of the synapses as well as information
about previous activation levels at the neuronal output Note that the leakage rate, d,
causes older information about activation levels to have less impact on current values of
v (t) than does recent information of the same type.
The output of the neuron, p (t), is:
v (t) > e then p (t) = 1 (pulse generated)
v (t ) ~ e then p (t) = 0 (no pulse generated)
It is important that once p (t) has been determined, v (t) will need to be adjusted if

200

Parker, Gluck and Reifsnider
To reflect the fact that the neuron has fired, (i.e., p (t) = 1) then v (t) = v (t) - 1.
This decrement occurs after p (t) has been determined for the current t. Frequencies of
pulses at the output node and at the synapses are calculated using the following equations:

p (t)

= 1.

/ (t)

=/ (t-l) + 11/(t)

where
11/ (t)

= m(p (t) - /

(t-l))

where / (t) is the frequency of outgoing pulses at time t; p (t) is the ouput (1 or 0) of the
neuron at time t ; and m is a small positive constant representing a leakage rate for the
frequency calculation.
Following Klopf (1988), changes in synapse efficacy occur according to

(2)

where
I1Wi(t) = Wi (t+l) - Wi(t)

and l1y (t) and ru:i (t) are calculated analogously to 11/ (t); 't is the longest interstimulus
interval (lSI) over which delay conditioning is effective; and Cj is an empirically established set of learning rates which govern the efficacy of conditioning at an lSI of j .
Changes in Wi (t) are governed by the learning rule in Equation 2 which alters v (t) via
Equation 1.
Figure 1 shows the results of a computer simulation of a pulse-coded version of Klopf's
conditioning model. The first graph shows the excitatory weight (dotted line) and inhibitory weight (dashed line) of the CS ""synapse"". Also on the same graph is the net synaptic
weight (solid line), the sum of the excitatory and inhibitory weights. The subsequent
graphs show CS input pulses, US input pulses, and the output (CR) pulses. The simulation consists of three acquisition trials followed by three extinction trials.

201

Learning with Temporal Derivatives

en

l! 0.4
.~ 02
.

;

~

(...............................J

0.6

0.0
?0.2

.................................. (.................................,

.........

~

?V1???????????U ..............................

------------------------------------------~-----~-----------

o

50

100

150

200

250

cycle

Figure 1. Simulation of pulse.coded version of Klopf's conditioning model.
Top panel shows excitatory and inhibitory weights as dashed lines and the net
synaptic weight of the CS as a solid line. Lower panels show the CS and US
inputs and the CR output.

As expected, excitatory weight increases in magnitude over the three ~quisition trials,
while inhibitory weight is stable. During the first two extinction trials, the excitatory and
the net synaptic weights decrease in magnitude, while the inhibitory weight increases.
Thus, the CS produces a decreasing amount of output pulses (the CR). During the third
extinction trial the net synaptic weight is so low that the CS cannot produce output
pulses, and so the CR is extinct. However, as net weight and excitatory weight remain
positive, there are residual effects of the acquisition which will accelerate reacquisition.
Because a threshold must be reached before a neuronal output pulse can be emitted, and
because output must occur for weight changes to occur, pulse coding adds to the
accelerated reacquisition effect that is evident in the original Klopf model; extinction is
halted before net weight is zero, when pulses can no longer be produced.

300

202

Parker, Gluck and Reifsnider

Discussion
To facilitate comparison between learning algorithms involving temporal derivative computations and actual neuronal capabilities. we formulated a pulse-coded variation of
Klopfs classical conditioning model. Our basic conclusion is that computing with temporal derivatives (or differences) as proposed by Kosko (1986). Klopf (1988). and Sutton
(1988). is more stable and easier when reformulated for a more neuronally realistic.
pulse-coded system. than when the rules are fonnulated in terms of frequencies or activation.
It is our hope that further examination of the characteristics of pulse-coded systems may
reveal facts that bear on the characteristics of neuronal function. In refonnulating these
algorithms in terms of pulse-coding. our motivation has been to enable us to draw further
parallels and connections between real-time behavioral models of learning and biological
circuit models of the substrates underlying classical conditioning. (e.g .? Thompson. 1986;
Gluck & Thompson. 1987; Donegan. Gluck. & Thompson. in press). More generally.
noting the similarities and differences between algorithmic/behavioral theories and biological capabilities is one way of laying the groundwork for developing more complete
integrated theories of the biological bases of associative learning (Donegan. Gluck. &
Thompson. in press).

Acknowledgments
Correspondence should be addressed to: Mark A. Gluck. Dept of Psychology. Jordan
Hall; Bldg. 420. Stanford. CA 94305. For their commentary and critique on earlier drafts
of this and related papers. we are indebted to Harry Klopf. Bart Kosko. Richard Sutton.
and Richard Thompson. This research was supported by an Office of Naval Research
Grant to R. F. Thompson and M. A. Gluck.

References
Bear. M. F., & Cooper, L. N. (in press). Molecular mechanisms for synaptic modification in the
visual cortex: Interaction between theory and experiment. In M. A. Gluck, & D. E.
Rumelhart (Eds.), Neuroscience and Connectionist Theory. Hillsdale, N.J.: Lawrence Erlbaum Associates ..
Donegan, N. H., Gluck, M. A., & Thompson, R. F. (1989). Integrating behavioral and biological
models of classical conditioning. In R. D. Hawkins, & G. H. Bower (Eds.), Computational
models of learning in simple neural systems (Volume 22 of the Psychology of Learning and
Motivation). New York: Academic Press.
Gluck, M. A., & Bower. G. H. (1988a). Evaluating an adaptive network model of human learning.
Journal of Memory and Language, 27, 166-195.
Gluck, M. A., & Bower, G. H. (1988b). From conditioning to category learning: An adaptive network model. Journal of Experimental Psychology: General, 117(3), 225-244.

Learning with Temporal Derivatives

Gluck, M. A., Parker, D. B., & Reifsnider, E. (1988). Some biological implications of a
differential-Hebbian learning rule. Psychobiology, 16(3), 298-302.
Gluck, M. A, Reifsnider, E. S., & Thompson, R. F. (in press). Adaptive signal processing and temporal coarse coding: Cerebellar models of classical conditioning and VOR Adaptation. In
M. A. Gluck, & D. E. Rumelhart (Eds.), Neuroscience and Connectionist Theory. Hillsdale,
N.1.: Lawrence Erlbaum Associates ..
Gluck, M. A, & Rumelhart, D. E. (in press). Neuroscience and Connectionist Theory. Hillsdale,
N.J.: Lawrence Erlbaum Associates ..
Gluck, M. A., & Thompson, R. F. (1987). Modeling the neural substrates of associative learning
and memory: A computational approach. Psychological Review, 94, 176-191.
Granger, R., Ambros-Ingerson, 1., Staubli, U., & Lynch, G. (in press). Memorial operation of multipIe, interacting simulated brain structures. In M. A. Gluck, & D. E. Rumelhart (Eds.), Neuroscience and Connectionist Theory. Hillsdale, N.J.: Lawrence Erlbaum Associates ..
Hebb, D. (1949). Organization of Behavior. New York: Wiley & Sons.
Horowitz, P., & Hill, W. (1980). The Art of Electronics. Cambridge, England: Cambridge University Press.
Klopf, A. H. (1988). A neuronal model of classical conditioning. Psychobiology, 16(2), 85-125.
Kosko, B. (1986). Differential hebbian learning. In 1. S. Denker (Ed.), Neural Networksfor Computing, AlP Conference Proceedings 151 (pp. 265-270). New York: American Institute of
Physics.
McNaughton, B. L., & Nadel, L. (in press). Hebb-Marr networks and the neurobiological representation of action in space. In M. A. Gluck, & D. E. Rumelhart (Eds.), Neuroscience and Connectionist Theory. Hillsdale, N.J.: Lawrence Erlbaum Associates ..
Parker, D. B. (1987). Optimal Algorithms for Adaptive Networks: Second Order Back Propagation, Second Order Direct Propagation, and Second Order Hebbian Learning. Proceedings
of the IEEE First Annual Conference on Neural Networks. San Diego, California:, .
Rescorla. R. A, & Wagner, A. R. (1972). A theory of Pavlovian conditioning: Variations in the
effectiveness of reinforcement and non-reinforcement. In A. H. Black, & W. F. Prokasy
(Eds.), Classical conditioning II: Current research and theory. New York: AppletonCentury-Crofts.
RumeIhart, D. E., Hinton, G. E., & Williams, R. J. (1986). Learning internal representations by
error propogation. In D. Rumelhart, & 1. McClelland (Eds.), Parallel distributed processing: Explorations in the microstructure of cognition (Vol. 1: Foundations). Cambridge,
M.A.: MIT Press.
Sutton, R. S. (1988). Learning to predict by the methods of temporal differences. Machine Learning, 3, 9-44.
Sutton, R. S., & Barto, A. G. (1981). Toward a modem theory of adaptive networks: Expectation
and prediction. Psychological Review, 88, 135-170.
Sutton, R. S., & Barto, A. G. (1987). A temporal-difference model of classical conditioning. In
Proceedings of the 9th Annual Conference of the Cognitive Science Society. Seattle, WA.
Thompson, R. F. (1986). The neurobiology ofleaming and memory. Science, 233, 941-947.
Werbos, P. (1974). Beyond regression: New tools for prediction and analysis in the behavioral sciences. Doctoral dissertation (Economics), Harvard University, Cambridge, Mass ..
Widrow, B., & Hoff, M. E. (1960). Adaptive switching circuits. Institute of Radio Engineers,
Western Electronic Show and Convention, Convention Record, 4,96-194.

203

Part II
Application

"
95,1988,"ALVINN: An Autonomous Land Vehicle in a Neural Network","",95-alvinn-an-autonomous-land-vehicle-in-a-neural-network.pdf,"Abstract Missing","305

ALVINN:
AN AUTONOMOUS LAND VEHICLE IN A
NEURAL NETWORK
Dean A. Pomerleau
Computer Science Department
Carnegie Mellon University
Pittsburgh, PA 15213

ABSTRACT
ALVINN (Autonomous Land Vehicle In a Neural Network) is a 3-layer
back-propagation network designed for the task of road following. Currently ALVINN takes images from a camera and a laser range finder as input
and produces as output the direction the vehicle should travel in order to
follow the road. Training has been conducted using simulated road images.
Successful tests on the Carnegie Mellon autonomous navigation test vehicle
indicate that the network can effectively follow real roads under certain field
conditions. The representation developed to perfOIm the task differs dramatically when the networlc is trained under various conditions, suggesting
the possibility of a novel adaptive autonomous navigation system capable of
tailoring its processing to the conditions at hand.

INTRODUCTION
Autonomous navigation has been a difficult problem for traditional vision and robotic
techniques, primarily because of the noise and variability associated with real world
scenes. Autonomous navigation systems based on traditional image processing and pattern recognition techniques often perform well under certain conditions but have problems
with others. Part of the difficulty stems from the fact that the processing performed by
these systems remains fixed across various driving situations.
Artificial neural networks have displayed promising performance and flexibility in other
domains characterized by high degrees of noise and variability, such as handwritten
character recognition [Jackel et al., 1988] [Pawlicki et al., 1988] and speech recognition
[Waibel et al., 1988]. ALVINN (Autonomous Land Vehicle In a Neural Network) is a
connectionist approach to the navigational task of road following. Specifically, ALVINN
is an artificial neural network designed to control the NAVLAB, the Carnegie Mellon
autonomous navigation test vehicle.

NETWORK ARCmTECTURE
ALVINN's current architecture consists of a single hidden layer back-propagation network

306

Pomerleau

Road Intensity
Feedback Unit

45 Direction
Output Units

8x32 Range Finder
Input Retina

30x32 Video
Input Retina
Figure 1: ALVINN Architecture
(See Figure 1). The input layer is divided into three sets of units: two ""retinas"" and a
single intensity feedback unit. The two retinas correspond to the two forms of sensory
input available on the NAVLAB vehicle; video and range information. The first retina,
consisting of 3002 units, receives video camera input from a road scene. The activation
level of each unit in this retina is proportional to the intensity in the blue color band of
the corresponding patch of the image. The blue band of the color image is used because
it provides the highest contrast between the road and the non-road. The second retina,
consisting of 8x32 units, receives input from a laser range finder. The activation level of
each unit in this retina is proportional to the proximity of the corresponding area in the
image. The road intensity feedback unit indicates whether the road is lighter or darker
than the non-road in the previous image. Each of these 1217 input units is fully connected
to the hidden layer of 29 units, which is in tum fully connected to the output layer.
The output layer consists of 46 units, divided into two groups. The first set of 45 units
is a linear representation of the tum curvature along which the vehicle should travel in
order to head towards the road center. The middle unit represents the ""travel straight
ahead"" condition while units to the left and right of the center represent successively
sharper left and right turns. The network is trained with a desired output vector of all
zeros except for a ""hill"" of activation centered on the unit representing the correct tum
curvature, which is the curvature which would bring the vehicle to the road center 7
meters ahead of its current position. More specifically, the desired activation levels for

ALVlNN: An Autonomous Land Vehicle in a Neural Network

Real Road Image

Simulated Road Image

Figure 2: Real and simulated road images
the nine units centered around the correct tum curvature unit are 0.10, 0.32, 0.61, 0.89,
1.00,0.89,0.61,0.32 and 0.10. During testing, the tum curvature dictated by the network
is taken to be the curvature represented by the output unit with the highest activation
level.
The final output unit is a road intensity feedback unit which indicates whether the road
is lighter or darker than the non-road in the current image. During testing, the activation
of the output road intensity feedback unit is recirculated to the input layer in the style
of Jordan [Jordan, 1988] to aid the network's processing by providing rudimentary infonnation concerning the relative intensities of the road and the non-road in the previous
image.

TRAINING AND PERFORMANCE
Training on actual road images is logistically difficult, because in order to develop a
general representation, the network must be presented with a large number of training
exemplaIS depicting roads under a wide variety of conditions. Collection of such a
data set would be difficult, and changes in parameters such as camera orientation would
require collecting an entirely new set of road images. To avoid these difficulties we
have developed a simulated road generator which creates road images to be used as
training exemplars for the network. Figure 2 depicts the video images of one real and
one artificial road. Although not shown in Figure 2, the road generator also creates
corresponding simulated range finder images. At the relatively low resolution being used
it is difficult to distinguish between real and simulated roads.
NetwoIk: training is performed using these artificial road ""snapshots"" and the Warp back-

307

? 308

Pomerleau

Figure 3: NAVLAB, the eMU autonomous navigation test vehicle.
propagation simulator described in [Pomerleau et al., 1988]. Training involves first creating a set of 1200 road snapshots depicting roads with a wide variety of retinal orientations and positions, under a variety of lighting conditions and with realistic noise levels.
Back-propagation is then conducted using this set of exemplars until only asymptotic
performance improvements appear likely. During the early stages of training, the input
road intensity unit is given a random activation level. This is done to prevent the network from merely learning to copy the activation level of the input road intensity unit
to the output road intensity unit, since their activation levels should almost always be
identical because the relative intensity of the road and the non-road does not often change
between two successive images. Once the network has developed a representation that
uses image characteristics to determine the activation level for the output road intensity
unit, the network is given as input whether the road would have been darker or lighter
than the non-road in the previous image. Using this extra information concerning the
relative brightness of the road and the non-road, the network is better able to determine
the correct direction for the vehicle to trave1.
After 40 epochs of training on the 1200 simulated road snapshots, the network correctly
dictates a tum curvature within two units of the correct answer approximately 90%
of the time on novel simulated road images. The primary testing of the ALVINN's
performance has been conducted on the NAVLAB (See Figure 3). The NAVLAB is
a modified Chevy van equipped with 3 Sun computers, a Warp, a video camera, and
a laser range finder, which serves as a testbed for the CMU autonomous land vehicle
project [Thorpe et al., 1987]. Performance of the network to date is comparable to that
achieved by the best traditional vision-based autonomous navigation algorithm at CMU
under the limited conditions tested. Specifically, the network can accurately drive the
NAVLAB at a speed of 1/2 meter per second along a 400 meter path through a wooded

ALVINN: An Autonomous Land Vehicle in a Neural Network
Weights to Direction Output Units
t~li'C

jjllil

Weight to Output
Feedback Unit
D

Weights from Video Camera Retina

Road 1
Edges

Weight from Input
Feedback Unit
n
Weight from
Bias Unit

?
Weights from
Range Finder Retina

Excitatory
Periphery Connections
Inhibitory
Central Connections

Figure 4: Diagram of weights projecting to and from a typical hidden unit in a network
trained on roads with a fixed width. The schematics on the right are aids for interpretation.
area of the CMU campus under sunny fall conditions. Under similar conditions on the
same course, the ALV group at CMU has recently achieved similar driving accuracy at
a speed of one meter per second by implementing their image processing autonomous
navigation algorithm on the Watp computer. In contrast, the ALVINN network is currently
simulated using only an on-boani Sun computer, and dramatic speedups are expected
when tests are perfonned using the Watp.

NETWORK REPRESENTATION
The representation developed by the network to perfonn the road following task depends
dramatically on the characteristics of the training set. When trained on examples of roads
with a fixed width, the network develops a representations consisting of overlapping road
filters. Figure 4 is a diagram of the weights projecting to and from a single hidden unit
.
in such a network.
As indicated by the weights to and from the feedback units, this hidden unit expects the
road to be lighter than the non-road in the previous image and supports the road being
lighter than the non-road in the current image. More specifically, the weights from the

309

310

Pomerleau
Weights to Direction Output Units
1::tllII:UIll t k?

Weight to Output
Feedback Unit

-

mDIRoad
~ N on-road
~

Weights from Video Camera Retina
.
' :

' .' :

..

Weight from Input
Feedback Unit

. : ' : .'

11111111

1111111

I[

Weight from
Bias Unit

111111111111

?

.:

.

Weights from
Range Finder Retina

Figure 5: Diagram of weights projecting to and from a typical hidden unit in a network
trained on roads with different widths.
video camera retina support the interpretation that this hidden unit is a filter for two light
roads, one slightly left and the other slightly right or center (See schematic to the right
of the weights from the video retina in Figure 4). This interpretation is also supported by
the weights from the range finder retina, which has a much wider field of view than the
video camera. This hidden unit is excited if there is high range activity (Le. obstacles) in
the periphery and inhibited if there is high range activity in the central region of the scene
where this hidden unit expects the road to be (See schematic to the right of the weights
from the range finder retina in Figure 4). Finally, the two road filter interpretation is
reflected in the weights from this hidden unit to the direction output units. Specifically,
this hidden unit has two groups of excitatory connections to the output units, one group
dictating a slight left turn and the other group dictating a slight right turn. Hidden units
which act as filters for 1 to 3 roads are the representation structures most commonly
developed when the network is trained on roads with a fixed width.
The network develops a very different representation when trained on snapshots with
widely varying road widths. A typical hidden unit from this type of representation is
depicted in figure 5. One important feature to notice from the feedback weights is that
this unit is filtering for a road which is darlcer than the non-road. More importantly, it
is evident from the video camera retina weights that this hidden unit is a filter solely for
the left edge of the road (See schematic to the right of the weights from the range finder

ALVINN: An Autonomous Land Vehicle in a Neural Network

retina in Figure 5). This hidden unit supports a rather wide range of travel directions.
This is to be expected, since the correct travel direction for a road with an edge at a
particular location varies substantially depending on the road's width. This hidden unit
would cooperate with hidden units that detect the right road edge to determine the correct
travel direction in any particular situation.

DISCUSSION AND EXTENSIONS
The distinct representations developed for different circumstances illustrate a key advantage provided by neural networks for autonomous navigation. Namely, in this paradigm
the data, not the programmer, determines the salient image features crucial to accurate
road navigation. From a practical standpoint, this data responsiveness has dramatically
sped ALVINN's development. Once a realistic artificial road generator was developed,
back-propagation producted in half an hour a relatively successful road following system.
It took many months of algorithm development and parameter tuning by the vision and
autonomous navigation groups at CMU to reach a similar level of performance using
traditional image processing and pattern recognition techniques.
More speculatively, the flexibility of neural network representations provides the possibility of a very different type of autonomous navigation system in which the salient
sensory features are determined for specific driving conditions. By interactively training
the network on real road images taken as a human drives the NAVLAB, we hope to
develop a system that adapts its processing to accommodate current circumstances. This
is in contrast with other autonomous navigation systems at CMU [Thorpe et al., 1987]
and elsewhere [Dunlay & Seida, 1988] [Dickmanns & Zapp, 1986] [Kuan et al., 1988].
Each of these implementations has relied on a fixed, highly structured and therefore relatively inflexible algorithm for finding and following the road, regardless of the conditions
at hand.
There are difficulties involved with training ""on-the-fly"" with real images. If the network
is not presented with sufficient variability in its training exemplars to cover the conditions
it is likely to encounter when it takes over driving from the human operator, it will not
develop a sufficiently robust representation and will perform poorly. In addition, the
network must not solely be shown examples of accurate driving, but also how to recover
(i.e. return to the road center) once a mistake has been made. Partial initial training on
a variety of simulated road images should help eliminate these difficulties and facilitate
better performance.
Another important advantage gained through the use of neural networks for autonomous
navigation is the ease with which they assimilate data from independent sensors. The
current ALVINN implementation processes data from two sources, the video camera and
the laser range finder. During training, the network discovers how information from
each source relates to the task, and weights each accordingly. As an example, range
data is in some sense less important for the task of road following than is the video
data. The range data contains information concerning the position of obstacles in the
scene, but nothing explicit about the location of the road. As a result, the range data
is given less significance in the representation, as is illustrated by the relatively small

311

312

Pomerleau

magnitude weights from the range finder retina in the weight diagrams. Figures 4 and
5 illustrate that the range finder connections do correlate with the connections from the
video camera, and do contribute to choosing the correct travel direction. Specifically, in
both figures, obstacles located outside the area in which the hidden unit expects the road
to be located increase the hidden unit's activation level while obstacles located within the
expected road boundaries inhibit the hidden unit. However the contributions from the
range finger connections aren't necessary for reasonable performance. When ALVINN
was tested with normal video input but an obstacle-free range finder image as constant
input, there was no noticeable degradation in driving performance. Obviously under
off-road driving conditions obstacle avoidance would become much more important and
hence one would expect the range finder retina to playa much more significant role in the
network's representation. We are currently working on an off-road version of ALVINN
to test this hypothesis.
Other current directions for this project include conducting more extensive tests of the
network's performance under a variety of weather and lighting conditions. These will
be crucial for making legitimate performance comparisons between ALVINN and other
autonomous navigation techniques. We are also working to increase driving speed by
implementing the network simulation on the on-board Warp computer.
Additional extensions involve exploring different network architectures for the road following task. These include 1) giving the network additional feedback information by using Elman's [Elman, 1988] technique of recirculating hidden activation levels, 2) adding
a second hidden layer to facilitate better internal representations, and 3) adding local
connectivity to give the network a priori knowledge of the two dimensional nature of the
input
In the area of planning, interesting extensions include stopping for, or planning a path
around, obstacles. One area of planning that clearly needs work is dealing sensibly with
road forks and intersections. Currently upon reaching a fork, the network may output two
widely discrepant travel directions, one for each choice. The result is often an oscillation
in the dictated travel direction and hence inaccurate road following. Beyond dealing with
individual intersections, we would eventually like to integrate a map into the system to
enable global point-to-point path planning.

CONCLUSION
More extensive testing must be performed before definitive conclusions can be drawn concerning the peiformance of ALVINN versus other road followers. We are optimistic concerning the eventual contributions neural networks will make to the area of autonomous
navigation. But perhaps just as interesting are the possibilities of contributions in the
other direction. We hope that exploring autonomous navigation, and in particular some of
the extensions outlined in this paper, will have a significant impact on the field of neural
networks. We certainly believe it is important to begin researching and evaluating neural
networks in real world situations, and we think autonomous navigation is an interesting
application for such an approach.

ALVINN: An Autonomous Land Vehicle in a Neural Network

Acknowledgements
This work would not have been possible without the input and support provided by Dave Touretzky,
Joseph Tebelskis, George Gusciora and the CMU Warp group, and particularly Charles Thorpe, Till
Crisman, Martial Hebert, David Simon, and rest of the CMU ALV group.
This research was supported by the Office of Naval Research under Contracts NOOOI4-87-K-0385,
NOOOI4-87-K-0533 and NOOOI4-86-K-0678, by National Science Foundation Grant EET-8716324,
by the Defense Advanced Research Projects Agency (DOD) monitored by the Space and Naval
Warfare Systems Command under Contract NOOO39-87-C-0251, and by the Strategic Computing
Initiative of DARPA, through ARPA Order 5351, and monitored by the U.S. Army Engineer
Topographic Laboratories under contract DACA76-85-C-0003 titled ""Road Following"".

References
[Dickmanns & Zapp, 1986] Dickmanns, E.D., Zapp, A. (1986) A curvature-based
scheme for improving road vehicle guidance by computer vision. ""Mobile Robots"",
SPIE-Proc. Vol. 727, Cambridge, MA.
[Elman, 1988] Elman, J.L, (1988) Finding structure in time. Technical report 8801. Center for Research in Language, University of California, San Diego.
[Dunlay & Seida, 1988] Dunlay, R.T., Seida, S. (1988) Parallel off-road perception processing on the ALV. Proc. SPIE Mobile Robot Conference, Cambridge MA.
[Jackel et al., 1988] Jackel, L.D., Graf, H.P., Hubbard, W., Denker, J.S., Henderson, D.,
Guyon, 1. (1988) An application of neural net chips: Handwritten digit recognition.
Proceedings of IEEE International Conference on Neural Networks, San Diego, CA.
[Jordan, 1988] Jordan, M.l. (1988) Supervised learning and systems with excess degrees
of freedom. COINS Tech. Report 88-27, Computer and Infolll1ation Science, University of Massachusetts, Amherst MA.
[Kuan et al., 1988] Kuan, D., Phipps, G. and Hsueh, A.-C. Autonomous Robotic Vehicle
Road Following. IEEE Trans. on Pattern Analysis and Machine Intelligence, Vol.
10, Sept. 1988.
[pawlicki et al., 1988] Pawlicki, T.E, Lee, D.S., Hull, J.J., Srihari, S.N. (1988) Neural
network models and their application to handwritten digit recognition. Proceedings
of IEEE International Conference on Neural Networks, San Diego, CA.
[pomerleau et al., 1988] Pomerleau, D.A., Gusciora, G.L., Touretzky, D.S., and Kung,
H.T. (1988) Neural network simulation at Waq> speed: How we got 17 million
connections per second. Proceedings of IEEE International Conference on Neural
Networks, San Diego, CA.
[Th0IJle et al., 1987] Thorpe, c., Herbert, M., Kanade, T., Shafer S. and the members of
the Strategic Computing Vision Lab (1987) Vision and navigation for the Carnegie
Mellon NAVLAB. Annual Revi~ of Computer Science Vol. 11, Ed. Joseph Traub,
Annual Reviews Inc., Palo Alto, CA.

[Waibel et al., 1988] Waibel, A, Hanazawa, T., Hinton, G., Shikano, K., Lang, K. (1988)
Phoneme recognition: Neural Networks vs. Hidden Markov Models. Proceedings
from Int. Conf. on Acoustics, Speech and Signal Processing, New York, New York.

313

"
97,1988,"Neural Analog Diffusion-Enhancement Layer and Spatio-Temporal Grouping in Early Vision","",97-neural-analog-diffusion-enhancement-layer-and-spatio-temporal-grouping-in-early-vision.pdf,"Abstract Missing","289

NEURAL ANALOG DIFFUSION-ENHANCEMENT
LAYER AND SPATIO-TEMPORAL GROUPING
IN EARLY VISION
Allen M. Waxman?,t, Michael Seibert?,t,RobertCunninghamt and I ian Wu?
? Laboratory for Sensory Robotics
Boston University
Boston, MA 02215

t Machine Intelligence Group
MIT Lincoln Laboratory
Lexington, MA 02173

ABSTRACT
A new class of neural network aimed at early visual processing is
described; we call it a Neural Analog Diffusion-Enhancement Layer or
""NADEL."" The network consists of two levels which are coupled
through feedfoward and shunted feedback connections. The lower level
is a two-dimensional diffusion map which accepts visual features as
input, and spreads activity over larger scales as a function of time. The
upper layer is periodically fed the activity from the diffusion layer and
locates local maxima in it (an extreme form of contrast enhancement)
using a network of local comparators. These local maxima are fed back
to the diffusion layer using an on-center/off-surround shunting
anatomy. The maxima are also available as output of the network. The
network dynamics serves to cluster features on multiple scales as a
function of time, and can be used in a variety of early visual processing
tasks such as: extraction of comers and high curvature points along
edge contours, line end detection, gap filling in contours, generation of
fixation points, perceptual grouping on multiple scales, correspondence
and path impletion in long-range apparent motion, and building 2-D
shape representations that are invariant to location, orientation, scale,
and small deformation on the visual field.

INTRODUCTION
Computer vision is often divided into two main stages, ""early vision"" and ""late vision"",
which correspond to image processing and knowledge-based recognition/interpretation,
respectively. Image processing for early vision involves algorithms for feature
enhancement and extraction (e.g. edges and comers), feature grouping (i.e., perceptual
We acknowledge support from the Machine Intelligence Group of MIT Lincoln
Laboratory. The views expressed are those of the authors and do not reflect the official
policy or position of the U.S. Government

290

Waxman, Seibert, Cunningham and Wu

organization), and the extraction of physical properties for object surfaces that comprise a
scene (e.g. reflectance, depth, surface slopes and curvatures, discontinuities). The
computer vision literature is characterized by a plethora of algorithms to achieve many of
these computations, though they are hardly robust in performance.
Biological neural network processing does, of course, achieve all of these early vision
tasks, as evidenced by psychological studies of the preattentive phase of human visual
processing. Often, such studies provide motivation for new algorithms in computer
vision. In contrast to this algorithmic approach, computational neural network processing
tries to glean organizational and functional insights from the biological realizations, in
order to emulate their information processing capabilities. This is desirable. mainly
because of the adaptive and real-time nature of the neural network architecture. Here, we
shall demonstrate that a single neural architecture based on dynamical diffusionenhancement networks can realize a large variety of early vision tasks that deal mainly
with perceptual grouping. The ability to group image features on multiple scales as a
function of time, follows from ""attractive forces"" that emerge from the network
dynamics. We have already implemented the NADEL (in 16-bit arithmetic) on a videorate parallel computer, the PIPE [Kent et al .? 1985], as well as a SUN-3 workstation.

THE NADEL
The Neural Analog Diffusion-Enhancement Layer was recently introduced by Seibert &
Waxman [1989]. and is illustrated in Figure 1; it consists primarily of two levels which
are coupled via feedforward and shunted feedback connections. Low-level features
extracted from the imagery provide input to the lower level (a 2-D map) which spreads
input activity over larger scales as time progresses via diffusion, allowing for passive
decay of activity. The diffused activity is periodically sampled and passed upward to a
contrast-enhancing level (another 2-D map) which locates local maxima in the terrain of
diffuse activity. However, this forward pathway is masked by receptive fields which pass
only regions of activity with positive Gaussian curvature and negative mean curvature;
that is these receptive fields play the role of inhibitory dendro-dendritic modulatory gates.
This masking fascilitates the local maxima detection in the upper level. These local
maxima detected by the upper level are fed back to the lower diffusion level using a
shunting dynamics with on-center/off-surround anatomy (cf. [Grossberg, 1973] on the
importance of shunting for automatic gain control, and the role of center/surround
anatomies in competitive networks). The local maxima are also available as outputs of the
network, and take on different interpretations as a function of the input. A number of
examples of spatio-temporal grouping will be illustrated in the next section.
The primary result of diffusion-enhancement network dynamics is to create a longrange attractive force between isolated featural inputs. This force manifests itself by
shifting the local maxima of activity toward one another. leading to a featural grouping
over mUltiple scales as a function of time. This is shown in Figure 1, where two featural
inputs spread their initial excitations over time. The individual activities superpose. with
the tail of one gaussian crossing the maximum of the other gaussian at an angle. This

Neural Analog Diffusion-Enhancement Layer

biases the superposition of activities, adding more activity to one side of a maximum than
another, causing a shift in the local maxima toward one another. Eventually, the local
maxima merge into a single maximum at the centroid of the individual inputs. If we keep
track of the local maxima as diffusion progresses (by connecting the output of the
enhancement layer to another layer which stores activity in short term memory), then the
two initial inputs will become connected by a line. In Figure 1 we also illustrate the
grouping of five features in two clusters, a configuration possessing two spatial scales.
After little diffusion the local maxima are located where the initial inputs were. Further
diffusion causes each cluster to form a single local maximum at the cluster centroid.
Eventually, both clusters merge into a single hump of activity with one maximum at the
centroid of the five initial inputs. Thus, multi scale grouping over time emerges. The
examples of Figure 1 use only diffusion without any feedback, yet they illustrate the
importance of localizing the local maxima through a kind of contrast-enhancement on
another layer. The local maxima of activity serve as ""place tokens"" representing grouped
features at a particular scale. The feedback pathway re-activates the diffusion layer,
thereby allowing the grouping process to proceed to still larger scales, even across
featureless areas of imagery.
The dynamical evolution of activity in the NADEL can be modeled using a modified
diffusion equation [Seibert & Waxman, 1989]. However, in our simulations of the
NADEL we don't actually solve this differential equation directly. Instead, each iteration
of the NADEL consists of a spreading of activity using gaussian convolution, allowing
for passive decay, then sampling the diffusion layer, masking out areas which are not
positive Gaussian curvature and negative mean curvature activity surfaces, detecting one
local maximum in each of these convex areas, and feeding this back to the diffusion layer
with a shunted on-center/off-surround excitation at the local maxima. In the biological
system, diffusion can be accomplished via a recurrent network of cells with offcenter/on-surround lateral connectivity, or more directly using electrotonic coupling
across gap junctions as in the horizontal cell layer of the retina [Dowling, 1987].
Curvature masking of the activity surface can be accomplished using oriented offcenter/on-surround receptive fields that modulate the connections between the two
primary layers of the NADEL.

SPATIO-TEMPORAL GROUPING
We give several examples of grouping phenomena in early vision, utilizing the NADEL.
In all cases its parameters correspond to gaussian spreading with 0'=3 and passive decay
of 1% per iteration, and on-center/off-surround feedback with 0'+=11'12 and 0'_=1.

Grouping of Two Points: The simple case of two instantaneous point stimuli input
simultaneously to the NADEL is summarized in Figure 2. We plot the time (N network
iterations) it takes to merge the two inputs, as a function of their initial separation (S
pixels). For S:S;6 the points merge in one iteration; for S>24 activity equilibrates and
shifting of local maxima never begins.

291

292

Waxman, Seibert, Cunningham and Wu

Grouping on Multiple Scales: Figure 3 illusttates the hierarchy of groupings generated
by a square outline (31 pixels on a side) with gaps (9 pixels wide). Comer and line-end
features are first enhanced using complementary center-surround receptive fields
(modeled as a rectified response to a difference-of-gaussians), and located at the local
maxima of activity. These features are shown superimposed on the shape in 3a; they
serve as input to the NADEL. Figure 3b shows the loci of local maxima determined up to
the second stable grouping, superimposed over the shape. Boundary completion fills the
gaps in the square. In Figure 3c we show the loci of local maxima on the image plane,
after the final grouping has occured (N=I00 iterations). The trajectory of local maxima
through space-time (x,y,t) is shown in Figure 3d after the fourth grouping. It reveals a
hierarchical organization similar to the ""scale-space diagrams"" of Witkin [1983].
It can be seen from Figure 3d that successive groupings form stable entities in that the
place tokens remain stationary for several iterations of the NADEL. It isn't until activity
has diffused farther out to the next representative scale that these local maxima start
moving once again, and eventually merge. This relates stable perceptual groupings to
place tokens (i.e., local maxima of activity) that are not in motion on the diffusion layer.
The motion of place tokens can be measured in the same fashion as feature point motion
across the visual field. Real-time receptive fields for measuring the motion of image edge
and point features have recently been developed by Waxman et ale [1988].
Grouping of Time-Varying Inputs: The simplest example in this case corresponds to the
grouping of two lights that are flashed at different locations at different times. When the
time interval between flashes (Stimulus Onset Asynchrony SOA) is set appropriately,
one perceives a smooth motion _or ""path impletion"" between the stimuli. This percept of
""long-range apparent motion"" is the cornerstone of the Gestalt Psychology moverment,
and has remained unexplained for one-hundred years now [Kolers, 1972]. We have
applied the NADEL to a variety of classical problems in apparent motion including the
""split motion"" percept and the mUlti-point Ternus configuration [Waxman et al., 1989].
Here we consider only the case of motion between two stimuli, where we interpret the
locus of local maxima as the impleted path in apparent motion. However, the direction
of perceived motion is not determined by the grouping process itself; only the path. We
make the additional assumption that grouping generates a motion percept only if the
second stimulus begins to shift immediately upon input to the NADEL. We suggest that
the motion percept occurs only after path impletion is complete. That is, while grouping
is active, its outputs are suppressed from our perception (a form of ""ttansient-onsustained inhibition"" analogous to saccadic suppression). By varying the separation
between the two stimuli, and the time (SOA) between their inputs, we can plot regimes
for which the NADEL predicts apparent motion. This is shown in Figure 4, which
compares favorably with the psychophysical results summarized in Figure 3.2 of [Kolers,
1972]. We find regimes in which complete paths are formed (""smooth motion""), partial
paths are formed (""jumpy motion""), and no immediate shifting occurs (""no motion""). The
maximum allowable SOA between stimuli (upper curves) is determined by the passive
decay rate. Increasing this decay from 1% to 3% will decrease the maximum SOA by a

Neural Analog Diffusion-Enhancement Layer

factor of five. The minimum allowable SOA (lower curves) increases with increasing
separation, since it takes longer for activity from the first stimulus to influence a more
distant second stimulus. The linearity of the lower boundary has been interpreted by
[Waxman et aI.? 1989] as suggestive of Korte's ""third law"" [Kolers, 1972], when taken in
combination with a logarithmic transformation of the visual field [Schwartz, 1980].
Attentional Cues and Invariant Representations: Place tokens which emerge as stable
groupings over time can also provide attentional cues to a vision system. They would
typically drive saccadic eye motions during scene inspection, with the relative activities
of these maxima and their order of emergence determining the sequence of rapid eye
motions. Such eye motions are known to play a key role in human visual perception
[Yarbus, 1967]; they are influenced by both bottom-up perceptual cues as well as topdown expectations. The neuromorphic vision system developed by Seibert & Waxman
[1989], shown in Figure 5, utilizes the NADEL to drive ""eye motions"", and thereby
achieve translational invariance in 2-D object learning and recognition. This is followed
by a log-polar transform (which emulates the geniculo-cortical connections [Schwartz,
1980]) and another NADEL to achieve rotation and scale in variance as well. Further
coding of the transformed feature points by overlapping receptive fields provides
invariance to small deformation. Pattern learning and recognition is then achieved using
an Adaptive Resonance Theory (ART-2) network [Carpenter & Grossberg, 1987].

REFERENCES
G. Carpenter & S. Grossberg (1987). ART-2: Self-organization of stable category
recognition codes for analog input patterns. Applied Optics 26, pp. 4919-4930.

I.E. Dowling (1987). The RETINA: An approachable part or the brain. Cambridge,
MA: Harvard University Press.
S. Grossberg (1973). Contour enhancement, short term memory, and constancies in
reverberating neural networks. Studies in Applied Mathematics 52. pp.217-257.
E.W. Kent, M.O. Shneier & R. Lumia (1985). PIPE: Pipelined Image Processing Engine.
Journal of Parallel and Distributed Computing 2, pp. 50-78.
P.A. Kolers (1972). Aspects or Motion Perception. New York: Pergamon Press.
E.L. Schwartz (1980). Computational anatomy and functional architecture of striate
cortex: A spatial mapping approach to perceptual coding. Vision Research 20, pp. 645669.
M. Seibert & A.M. Waxman (1989). Spreading activation layers, visual saccades and
invariant representations for neural pattern recognition systems. N~ural Networks 2, pp.
9-27.

293

294

Waxman, Seibert, Cunningham and Wu

A.M. Waxman, J. Wu & F. Bergholm (1988). Convected activation profiles and the
measurement of visual motion. Proceeds. 1988 IEEE Conference on Computer Vision
and Pattern Recognition. Ann Arbor, MI, pp. 717-723.
A.M. Waxman. J. Wu & M. Seibert (1989). Computing visual motion in the short and
the long: From receptive fields to neural networks. Proceeds. IEEE 1989 Workshop on
Visual Motion. Irvine, CA.
A.P. Witkin (1983). Scale space filtering. Proceeds. of the International Joint
Conference on Artificial Intelligence. Karlsruhe, pp. 1019-1021.

AL. Yarbus (1967). Eye Movements and Vision. New York: Plenum Press.

ON?CENTER!

o
o
o

OFF?SURROUND

OFF?CENTER!
a.l-SURAOUNQ

SHUNTNG
FEE08AO<

ON-CENTER!
OFF?SURAOUND

Figure 1 ? (left) The NADEL takes featural input and diffuses it over a 2-D map as a
function of time. Local maxima of activity are detected by the upper layer and fed back to
the diffusion layer using an on-center/off-surround shunting anatomy. (right. top)
Features spread their activities which superpose to generate an attractive force, causing
distant features to group. (right, bottom) Grouping progresses in time over multiple
scales. with small clusters emerging before extended clusters. Clusters are represented by
their local ~axima of activity, which serve as place tokens.

1ii~Ill'J!I!IIIl!lll!l1llllllm=
!,~

~l""

lmilllillUml:l ?

1_?

1000
600
.00

I;
200

/,

~

I

so

~

~~

..

I~~

Ii'
~,I
~

tt~i'><'!

k;'~
""~~~""'r..;.'(!S.1-:'~-'
~,~o.~_,

?

~7'~~':;'
~~~~ .

...

(b)

(a)

I
~o

/

.x

~

?

':'.~
~
~

/

60

.9

~

1

~h
t~5~

~~!:Ji.
.J\llt!
:??'!""Id

I

I

lOa

<!

1~~'l
F~

.'
;h~ '

800

z
~
e.
~
e.

/

/

20

I
/
10

I

I

6

I

t2

/

~

y

/

~

.---

.... ,-_ .....

r!3.

g

Separalion

~

5 (pIXelS)

g.

(e)

Cd)

I
g

Figure 2 _ The time (network iterations N) to merge
two points input simultaneously to the NADEL, as a
function of their initial separation (S pixels).

(""t-

~

Figure 3 - Perceptual grouping of a square outline with gaps.

~

~

~

'-0

c:.n

~

co

(J')

E_pectat Ions
Spatial relations

200

80

g

,/

40

Smooth Motion

<II

::s
e.::s

./

./'

c:

.2

~
a>

,;+

No Motion

60
~

./

I?.

./

20

a

./'

-l:

,/

0

~

iii

.s

10
8

C
C/)

6

Jumpy Motion

~~

./ , /
./

~

./
./

./

4

/
/

/

2

/

VIA NADEL

/
1

J
....g-~

100

FEATURE MAP

6

Separation S (pixels)

Figure 4 - Apparent motion between two flashed
lights: Stimulus Onset Asynchrony SOA (network
iterations N) vs. Separation S (pixels). Solid curves
indicate boundaries between which introduction of
the second light yields immediate shifting of local
maxima; dashed curves (above solid curves) indicate
when final merge occurs yielding the impleted path.

EYE MOTIONS

Figure 5 - The neuromorphic vision system for
invariant learning and recognition of 2-D object~
utilizes three NADEL networks.

"
98,1988,"Spreading Activation over Distributed Microfeatures","",98-spreading-activation-over-distributed-microfeatures.pdf,"Abstract Missing","553

SPREADING ACTIVATION OVER
DISTRIBUTED MICROFEATURES
James Hendler *
Depart.ment, of Computer Science
University of Maryland
College Park, MD 20742

ABSTRACT
One att?empt at explaining human inferencing is that of spreading activat,ion, particularly in the st.ructured connectionist paradigm. This has resulted in t.he building of systems with semantically nameable nodes which perform inferencing by examining
t.he pat,t.erns of activation spread. In this paper we demonst.rate
t.hat simple structured network infert'ncing can be p(>rformed by
passing art.iva.t.ion over the weights learned by a distributed algarit,hm. Thus , an account, is provided which explains a wellbehaved rela t ionship bet.ween structured and distri butt'd conn('ct.ionist. a.pproachrs.

INTRODUCTION
A primar~? difference brtween t,he nPllral net.works of 20 years ago and t.he
(""urrent genera Lion of connect,ionist models is t.he addit.ion of mechanisms whic h
permit t.he s),st,em to create all internal represent,ation. These subsymbolic,
semantica.lly unnameable, feat.urrs which a.re induced by connectionist. learning
algorithms havr been discussed as bt,ing of import. bot,h in structured and distribut.ed ronnl""ctionist nrtworks (cf. Feldman and Balla.rd , 1982; Rumelhart and
McClelland, 198(j). The fact that network learning algorit.hms can creatr these
rm?cro!eal'ure,s is not, however. enough in itself t.o aC('Qunt for how rognition
works. Most. of what, we call int.elligent thought. dt'rives from being able t,o rea:son about. t.he relatioll:::> I)t'tween object.s, to hypothesize about event.s a.nd things,
etc. If we are to do cognit.ive modeling we must. complet.e the story by rxplainiJlg
how networks can rea,-;oll in tht> wa.y that, humans (or other int,elligrnt beings) do.
aile attempt at (-'xplaining such rea.<;oning is that of spreading activat.ion ill the
structured cOllllect,ionist. and marker- passing (cf. Charniak, ]983; Hendler, 1987)

?

The aut.hor is also affiliatf' ci wit.h thp Instit.ut.e for Acivanced C'omputpr Studies a.nd t.he Systems Research Center a.t the Universit.y of Ma.ryland. Funding for this work was provided in part by
Offi ce of Naval Resf'arch Grallt N00014-88--K - 0,560 .

554

Hendler

approaches. In t,hese syst,em::i semantically nanwable nodes permit an energy
spread; and reasoning about tilt' world is accounted for by looking at, either
stahh' configurations of tJw activation (the st.ruet.ured connectionist. approach) or
at. t,he paths fOllnd by examining int.ersect,ions among t.he nodes (the markerpassing te('llnique) . In this paper we will demonst.rate t.hat. simple Rt,ruct.lJrednetwork- like infE'rencing ('an be performed by pa.ssing act.ivat.ion over t,he wt'ightR
lea.rned by a distribut.ed algorithm. Thus, an account. is provided which explains
a well-behaved relation~hip bet.ween st.ruct,ured and dist.ributed connt'ct.ionist
a pproa.ches .

THE SPREADING ACTIVATION MODEL
In this paper we will demonstrate that local connect.ionist.- Iike net.works can be
built by spreading activat.ion ovel' t.he microfeaturcs learned b.\' a dist.ribut.ed network. To show t.his, we st,art wit.h a simple example which c1f'Jl1onst.rat.es the
activation spreading mechanism used. ThE' part.icular net.work We will use ill this
example is a 6- 3-8 three-layer net.work t rained by t.he hack-propagation learning
algorithm. The training set used is shown in table 1. The \w?ights bet.ween the
out.put node::; and hidden units which are learned by the Iletwork (after h'arning
t.o tlw !)O% level for a typical rlln) are shown in figure 1 .

TABLE 1. Training Set. for Examph' 1.

Inpll t
Pattern

Output.
Pattern

000000
0000 J 1
001100
OOll}1
110000

10000000
01000000
00100000
00010000
00001000
00000100
00000010
00000001

lIOO]]
] I I 100

111111

Spreading Activation over Distributed Microfeatures

Weights

n1
n2
n3
n4
n5
n6
n7

nB

h1

h2

h3

-4.98
-6.99
-6.11
-6.37
4.36
4.38
0.89
3.88

4.40
-4.99
3.49
-4.68
3.73
-5.97
1.07
-6.95

-2.82
-2.23
0.30
2.53
-5.09
-3.67
3.32
1.88

Figure 1. Weights L~arnecl by Back Propagation

To underst.and how t,he act,ivat.ioll spreads, let. us examine what. occurs when
activation is started at node nl wit.h a weight of 1. This activation strength is
divided by the outbranching of the nodf' and then mult.iplied by t.he weight of
each link to t.he hidden units. Thus a.ctiva.tion flows from nl t.o hi with a
strength of 1/ 3 1"" Weighl(tl1 ,hl}. A similar computat.ion is made t.o each of t.he
other hidden units. This act.ivat.ion now spreads to each of the ot.her Ollt.pUt.
nodes in turn. Thus, n2 would gain act,ivat.ion of

Acti','ation(hl) I Wet""ght(n2,hl)/ 8 -1Activat-ion(h2) 1"" lYe'ight(n2)d)/ 8 +
Ad1'vation(h3) 1"" Weight(n2,h3)/ 8
or .80 from rli .
Table 2 shows a graph of t.he act.ivat,ioll spread between the output units. The
table, which is symmetric, can t.hus be read as showing t.he out,put at each of the
other units when an activation st.rength of 1 is placed at t,he named node . Looking at. the table we see t,hat. t.il(' hight:'st, activat.ion OCClJrs among nodes which
share t.he most feat,ures of tJlf' input (i .e. ~anlf' value and posit.ion) while t.he
lowest is se('n among tho::;t:' pat.tt'fIls shariug t.he fewest feat.ures.

555

556

Hendler

However, as well as having this property, t.able 2 can be seen as providing a
matrix which specifies t.he weights bet.ween t.he out.put nodes if viewed as a st.ruct,ured net.work. That. is. ,,1 is conned?ed to rtf! by a strength of + .80, to nB by a
st.rength of + 1.0:3, etc . Thus. by I\~ing this t.echniquE' distribut.ed r{'presentations
can be turned into connectivity weight.s for st.ructured lIet.works. When non-?
ort.hogonal wpights are lIsed. t he same act.ivat ion--spreading a.lgorithm produces a
struct.ured network whi('h can be used for more complex inferenciug than can the
dist.ributed net work alone .
We demonst.rat.e t.his b)' a simple . and aga.in contrin?d. example. This example is
mot.ivat.ed by Gary Cot.trell's st.ructured JI10dd for word sense disambiguation
(CoUrt'll, Hl85). Cottrell, using weights clerived by hand, demonstrat.ed that. a
struct.ured connect.ionis!. net.work could di:';t inguish both word- sense a.nd case- slot
assignm('nts for amhiguous lexical items. Pre~enkd wit.h the sent{'nce ""John
threw the fight."" f?he syst.em would ndivate a node for one meaning of ""throw/'
presented wit.h ""John t.hrew t.he ball"" it would come up wit.h another. The nodes
of Cottrell's network included worels (John. Threw , etc .). word RenseR (Johnl,
Propp\. etc .) :lnd cClI'P- sloLs (TAGT (lIgt'llt of tl1(-' throw) . PAGT (ag('nt of t,he
Propel). etc.).

TABLE 2. Adivat.jon Spn>ad in 6--:3?8 Network.
,,1

nl
n2
n.'J

n4
'115
116

n7

uB

?

.80
1.03
.17
.38
-1.57
- .38
- 2.3

II::!
.80

oj

?

1.03
1.02

-.14

.97
- .63
-2 .03
- .03
-l.f!7

1.02
2.60
-1.57
.31
-.79

?

114

?//5

.17
2.6
.97

?

-2.42
-.38
-.09
.52

.38
-1.57
- .0:3
- 2.42

?
.64

-.;38
- .77

uB
-1.57
.:31
- 2.03
-.:38
.04

?
- .f)

2.1 ?1

Tl7

- .:38
-.79
- .0:3
-.Of!
-.;38

-.6

?

.09

u8
- 2.3
.14
--1.97
.52

-.77
2 .14
.09

?

To duplicate Gary's network via training, we presented a 3-layer backprop net...
work wit.h a training set in which distribut.ed pat.t.erns, H'ry loosely corresponding
to a ""dictionary"" of word (-,Ileodings l were associa.ted wit,h a vector representing
each of the individual noell's which would he represented in Cottrt-ll's system, but.
wit.h no struct.ure . Thus, each elemPIlt. in t.he training set. is

}- Whieh in any realisti r sy stem would sornp. day be rpplaeed by aduaJ signal pro.;pssing outp""t.S Of Othpf rpprespnt.alinn s of ai'liial worn pfonuneiat.ioll forms.

Spreading Activation over Distributed Microfeatures

a 16 bit vretor (represent.ing a four word srnt.en('e. ea('h word as a. 4 bit. pattrrn),
associated wit.h allot.he)? 16 bit. ve('tor repr<'spnt.ing t.he nodes
Bobl Johnl propE'l t.hrfW IJght I ball J jlJgt pob) t agt. to bj bob John t.hrfw U1E'
fight ball
For t.his example, the system was t.rnineci on th(? E'1I('odings of t.he four srnt.encrs
John t.hrew the ball
John threw the fight.
Bob t.1Hfw t be hall
Bob t.hrfw Lllf 6ght
wit.h the output set. high foJ' tho:-;e objects
a.ppropriatf?\y a.<.;so('iaj,rd . (IS shown in Tabh? :3.

TABLE

;~.

the second vedor whi('h \v('/,e

Tr<lining S(?t fa)' Example Z.

Output.
Patt.el'n

Input.

Pattern
011 0
01 J 0
100/
J 00 J

/II

0001 0101
OOOJ 0101
OOOJ 010J
000 1 0101

OOlO
J010
00/0
10 10

JOO 11000 1J J 01 I 10
lOlOOlJI00101101
0/0/100011011110
01 JOOJ 1100011101

Upon complet.ion of t.he kaming , t.he aet.ivat.ioJl sprrading algorithm was used to
derive a table of COlll1f'ctivity weights betw('ell the out.put. unit.s as shown in table
4.
These weight.s W(')'e then t.ransferred into a local COllnect ionist simulat.or and a
very simple act.ivation spn'adiJlg modrl was llsed to examine t.he r esult?s . \Vhpn
Wt' run t.he simulator. u~ing tht' aeti\'atioIl spn?ading oY('r leaJ'lwd wpights.
exactly t.he f('sult.s prodllced by Cott.reJl's n{'twork lIr{' seen . Thus :
Act.ivation from tht, nodt's corresponding to john. tbroll', tllf-. alld fif/hl
cam,e a posit.ive activation at. the node for ('Throw"" and a negative a('t.ivat.ion at t.he node for ""Propr!.""
while
A('tivat.ion from joh"" throlt' the ball sprt'ad positiniy to "" Prope'"" ,lIlel
not. t.o 'I t IIrow . ,.
Furt.her, ot?her effrct.s which

cHP

also predict.ed by C'ou.rdl's model lire seeJl:

Act.iYat.ioJl at. TAGT and TOB.! spreads posit.i\'t' activation to TIr.,.o/l'
and not t.o Propel.
and
Activation at PAG?' and POB) causes a spread t.o Propel but. not to

Thro'W.

557

558

Hendler

TABLE 4. Connectivity Weights for Example 2.

*** -?0.12
- 0.12 ***
0.01 -OJ)}
-0 .01 0.01
-0.0] 0.01
0,01 -0,01
O.OJ -0.01
0 .01 ?-0.01
-0.01 0.01
-0.01 0.01
0 .12 -0.12
- 0.12 0.12
-0.0:3 0.03
??0.03 0 .0:3
??0.0] 0.01
0.00 O.OJ

0.01 -0.01
- 0.01 0.01
*u -0.04
?-0.04 ***
-0.04 0.04
0,04 -0.04
0.04 -0.04
0.05 -0.05
-0,05 0.05
-0.04 0.04
0 .01 -0.01
?-0,01 0 .01
-0.02 0 .02
??0.02 0 ,02
-?0.04 0.04
0.04 -0.04

-0.01 0.01
0.01 - 0.01
-0.04 0 .04
0.04 -0 .04
u* -0.04
-0,04 ***
-0,05 O.O!)
-0,05 0.05
0.05 -0.05
0.04 -0.04
- 0.01 0.01
0.01 -?0.01
0.02 -?0.02
0.02 -0 .02
0.04 - 0.04
?-0.04 0.04

0.01
-0.01
0 .04
- 0.04
-0.0,5
0.05
***
O.OS
-0.05
-0,05
0.01
-0.00
-?0.02
?-0.02
-?0.04
0.0,5

0.01 - 0.01 -0.01
-0.01 0.01 0.01
0.05 -0.05 - 0.04
-0.05 0.05 0.04
-0,05 0.05 0,04
0,05 -0.0.5 -? 0.04
0.05 -0 .05 -0.05
u* -?0.05 -O.O!)
- 0.05 *** 0.05
-0.05 0.05 u*
0 .01 -0.01 -0 .01
-0.01 0 .01 O.OJ
-0.02 0.02 0.02
-0.02 0 .0;3 0.02
- 0.04 O.O<J D.O?'
0,05 O.O!) O.OG

0.12 - 0 .12
-?0.12 0 .12
0.01 - 0.01
?_?0.01 0.01
-0,01 0 ,01
0.01 - 0.01
0.01 ??0.00
0.01 -O.OJ
-0.01 O.()]
-0.01 0.01
*** ?-O.l:.?
??0.12 ***
?-0.0:3 0.0:3
0.0:3 0.0:)
? 0.01 O.OJ
O.OJ ?0.00

???0.0:3
0.0:3
- 0 .02
0.02
0.02
- 0 .02
-0.02
-0'()2
0 .02
0.02
?-0.0:3
O.O:~

***
0.20
0.02
0 .02

-0.0:3 -0.01 0 .00
O.O~ 0.01 ?-0.01
- 0.02 - 0.04 0.04
0.02 0.04 - 0 .04
0.02 0.04 - 0.04
-0.02 - 0.04 0.04
-0.02 - 0 .04 0.05
-0,02 ??0.04 0.05
0.0:3 0 .04 - 0.05
0.02 0.04 -0.05
-0.0:3 ?-0.01 0.0]
0.0:3 0 .01 ??0.00
0 .20 0.02 -0.02
* ** 0.02 - 0.02
0.02 *** . ~.O .?
0.02 ?0.04 ***

We believe that results like this one ma.y argue t.hat. :-;tl'uetllrt'd IId?works are
int.pgrally linked to dist.ributed networks ill t,hat. distribllt.<?d Ilf'twork le:ullillg
t.echuiqut's may provide a fundamental ba~i:-; for ('xplaining the ('ogllit.in' df'VelOPment. of structured networks . III addition, Wt ' see that :,-imple illf{'J'f'llt ial rt'a~on?
ing ('an be produ('ed using purdy cOIlJledioni~t. mockl:,.

CONCLUDING REMARKS
Wt' have at.t.empt.ed t.o ;;;hO\.... that a model u;;;ing an activation spn'ading va.rinnt
ean be used t.o take learned connect.ionist models aJld lwrform SOllle limit ed forms
of inferencing upon t.helll. Furt.her, WP have argllt""d t.hat t.his tf'chniqlll' Illay pro""idr a comput.ational modd in which strllctured network;;; C;}l) Iw leal'llPd and
t.hat st,ruct.ured net.work::; provide the infeI't'ncing (?apnbilities missing in purely
dist.rihut.ed models. However. befort' w(' can t.ruly furtht'r thi~ claim. ~ignit1('ant
work remain;;; to be done . We must ext.end alld ('xplort' such models. particularly
t'xamining whether t.hese t?ypes of t.echniqups ('an be extt'llded t.o handle tlw complt'xitr t?hat can be found in real?- world prol)JpIll~ and sl'rioll~ ('ogllitin models .

In part ieula.r we are beginlling an examinat.ion of two cru('ial isslIP::;: First.,
will t.he technique described above work for realist.ic problem?;? In particular, can
t.hl' infen?ncing be designed t.o impact on t.1l(' ]'Pwgnition by t 11(> di.stribut.ed net.work? If so, one ('ould Sf'f', for l'xample, a speech recognit.ion program coupled to
a system like Cottrell's natural languagt' sy:.;\.eJll, providing a handle for a t.ext.
underst.anding system. Similarly such a t.e('hnique might. allow the int.('gration of
top - down and bott.OIll'-IIP pro('('ssing for vision a.nd ot.ht'r such signal Pl'ocf'ssing
tasks.

Spreading Activation over Distributed Microfeatures

Secondly. we wish to see jf more complex spreading activation models could be
hooked to this t.ype of model. Could networks such as t.hose proposed by Sha.st.ri
(1985), Diedt'rich (HI8!?). and Polla.ck and 'Valt.z (1982) which provide complex
inferencing bllt requirt' more ,structure than simply wt'ight.s bet.ween unit.s, be
ab.stract.t'cI out. of the learned weight.s? Two partieular areas current.ly being pur~llf'd by t.JH' author. for t'xampk foclls on act.i\'e inhibit.ioll modeb for dt't.ermining whetlwr port.jon~ of the nt'twork C(ln lw ~lIpPJ'f'ssed t.o provide mort' complex
inferencing and t.he learning of structures given temporally ordered information.

References
Charniak, E. Passing markt'rs: A t.heory of contt'xtual influence
comprehension Cognitive S6ence, 7(3), 198:~. 171-190.

lJl

language

Cottrell, G.W. A Connection-ist Approach to Word - Sense DiMlmb1'gllation, Doet.oral Disst'rta.t.ion, Comput.t'r Scienc(' Dt'pt.. l fllivl'rsit.y of Hochesler, 1985.
Diederich, J. Parallelverarbeil/l'flg in 1IetzlL'erk-ba.~ie1'fen Systemen PhD Disst'rtation, Dt'pt. of Linguistics, llni\'ersity of Rielt~f('ld. J985.
Feldman, J.A. and Ballard , D.H. (J 982). Connect.ionist models a.nd t.heir propt:'rt.ies. Cognit1've Science. 6. 205-?254-

JlItegrating Maf'l.?er -pali8illg aod Problem Solving: A .~p,.e(/dirtg
artivatiou approach to 1'ml)ro'l'cd choice ill ploflJlillg Lawrence Erlbaulll As~ociate~,
N .J., Novt'mbt'J', Hlg7.

Hendler, J.A.

Pollack, J.B. and 'Yalt.7., D.L Nat?u!'al Language Processing lIsiug spr?'ading
act.ivat.ion and lateral inhibit.ion Proceedings of the FO'llrth intema.i1'o'l1al Conference of Ihe Cognitive S'o'eure S'ociety, 1982, .50-58.
Rurnelhart . D.E. and McClelland. J.L. ((,ds.) Parallel D';strib'llfed Computing
Cambridge . ,Ma.: MJT Prel-is.
Shastri, L. El'ideul1'al RWMuing ?in SefJ/(llItic /\.retll'{)rk.~: A formal theor:1J ((tid //8
parallel implementatioTl Doct.oral DiS8t'l't at.jon, Computt'r Scit'nce Depart ment,
l Jnivefsit.y of Roc-hester, Sept .. J 985.

559

"
99,1988,"Analog Implementation of Shunting Neural Networks","",99-analog-implementation-of-shunting-neural-networks.pdf,"Abstract Missing","695

ANALOG IMPLEMENTATION OF SHUNTING
NEURAL NETWORKS
Bahram Nabet, Robert B. Darling, and Robert B. Pinter
Department of Electrical Engineering, FT-lO
University of Washington
Seattle, WA 98195

ABSTRACT
An extremely compact, all analog and fully parallel implementation of a class of shunting recurrent neural networks that is applicable to a wide variety of FET-based integration technologies is
proposed. While the contrast enhancement, data compression, and
adaptation to mean input intensity capabilities of the network are
well suited for processing of sensory information or feature extraction for a content addressable memory (CAM) system, the network
also admits a global Liapunov function and can thus achieve stable
CAM storage itself. In addition the model can readily function as
a front-end processor to an analog adaptive resonance circuit.

INTRODUCTION
Shunting neural networks are networks in which multiplicative, or shunting, terms
of the form Xi Lj f;(Xj) or Xi Lj Ij appear in the short term memory equations,
where Xi is activity of a cell or a cell population or an iso-potential portion of a
cell and Ii are external inputs arriving at each site. The first case shows recurrent
activity, while the second case is non-recurrent or feed forward. The polarity of
these terms signify excitatory or inhibitory interactions.
Shunting network equations can be derived from various sources such as the passive
membrane equation with synaptic interaction (Grossberg 1973, Pinter 1983), models
of dendritic interaction (RaIl 1977), or experiments on motoneurons (Ellias and
Grossberg 1975).
While the exact mechanisms of synaptic interactions are not known in every individual case, neurobiological evidence of shunting interactions appear in several

696

Nabet, Darling and Pinter

areas such as sensory systems, cerebellum, neocortex, and hippocampus (Grossberg
1973, Pinter 1987). In addition to neurobiology, these networks have been used to
successfully explain data from disciplines ranging from population biology (Lotka
1956) to psychophysics and behavioral psychology (Grossberg 1983).
Shunting nets have important advantages over additive models which lack the extra nonlinearity introduced by the multiplicative terms. For example, the total
activity of the network, shown by Li Xi, approaches a constant even as the input
strength grows without bound. This normalization in addition to being computationally desirable has interesting ramifications in visual psychophysics (Grossberg
1983). Introduction of multiplicative terms also provides a negative feedback loop
which automatically controls the gain of each cell, contributes to the stability of the
network, and allows for large dynamic range of the input to be processed by the
network. The automatic gain control property in conjunction with properly chosen
nonlinearities in the feedback loop makes the network sensitive to small input values
by suppressing noise while not saturating at high input values (Grossberg 1973).
Finally, shunting nets have been shown to account for short term adaptation to
input properties, such as adaptation level tuning and the shift of sensitivity with
background strength (Grossberg 1983), dependence of visual size preference and
latency of response on contrast and mean luminance, and dependence of temporal
and spatial frequency tuning on contrast and mean luminance (Pinter 1985).

IMPLEMENTATION
The advantages, generality, and applicability of shunting nets as cited in the previous section make their implementation very desirable, but digital implementation
of these networks is very inefficient due to the need for analog to digital conversion, multiplication and addition instructions, and implementation of iterative algorithms. A linear feedback class of these networks (Xi Lj !; (Xj)
Xi Li J{ijXj),
however, can be implemented very efficiently with simple, completely parallel and
all analog circuits.

=

FRAMEWORK
Figure 1 shows the design framework for analog implementation of a class of shunting nets. In this design addition (subtraction) is achieved, via Kirchoff's current
law by placing transistors in upper (lower) rails, and through the choice of depletion or enhancement mode devices. Multiplicative, or shunting, interconnections
are done by one transistor per interconnect, using a field-effect transistor (FET) in
the voltage-variable conductance region. Temporal properties are characterized by
cell membrane capacitance C, which can be removed, or in effect replaced by the
parasitic device capacitances, if higher speed is desired. A buffer stage is necessary
for correct polarity of interconnections and the large fan-out associated with high
connectivity of neural networks.

Analog Implementation of Shunting Neural Networks

Vdd

I.,

+
x.,

c

-t""
'.J

.

x?
J

Vss

Figure 1. Design framework for implementation of one cell in a
shunting network. Voltage output of other cells is connected to the
gate of transistors Qi,i'

Such a circuit is capable of implementing the general network equation:
(1)

Excitatory and inhibitory input current sources can also be shunted, with extra
circuitry, to implement non-recurrent shunting networks.
NMOS, CMOS and GALLIUM ARSENIDE

Since the basic cell of Fig. 1 is very similar to a standard logic gate inverter, but with
the transistors sized by gate width-to-Iength ratio to operate in the nonsaturated
current region, this design is applicable to a variety of FET technologies including
NMOS, CMOS, and gallium arsenide (GaAs).
A circuit made of all depletion-mode devices such as GaAs MESFET buffered FET
logic, can implement all the terms of Eq. (1) except shunting excitatory terms and
requires a level shifter in the buffer stage. A design with all enhancement mode
devices such as silicon NMOS can do the same but without a level shifter. With
the addition of p-channel devices, e.g. Si CMOS, all polarities and all terms of Eq.
(1) can be realized. As mentioned previously a buffer stage is necessary for correct
polarity of interconnections and fan out/fan in capacity.
Figure 2 shows a GaAs MESFET implementation with only depletion mode devices
which employs a level shifter as the buffer stage.

697

698

Nabet, Darling and Pinter
VDD-------------r------~--------------~--

INPUTS:
EXTERNAL OR FROM
PREVJOUS LAYER

EXCITATORY
CONNECTIONS

INHIBITORY
CONNECTIONS
GN~-L--~------~------~--

TUNABLE
SELF-RELAXATION
CONNECTION

OUTPUT TO
NEXT LAYER
VSS--~--....L....?

LEVEL SHIFT AND BUFFER STAGE

Figure 2. Gallium arsenide MESFET implementation with level
shifter and depletion mode devices. Lower rail transistors produce
shunting off-surround terms. Upper transistors can produce additive excitatory connections.

SPECIFIC IMPLEMENTATION
The simplest shunting network that can be implemented by the general framework
of Fig.1 is Fig. 2 with only inhibitory connections (lower rail transistors). This
circuit implements the network model
dX?
d/

= Ii -

a,X,

+ Xi(J(iXi) -

"" J(ijXj)
Xi(L....J
j#i

(2),

The simplicity of the implementation is notable; a linear array with nearest neighbor
interconnects consists of only 5 transistors, 1-3 diodes, and if required 1 capacitor
per cell.
A discrete element version of this implementation has been constructed and shows
good agreement with expected properties. Steady state output is proportional to
the square root of a uniform input thereby compressing the input data and showing
adaptation to mean input intensity (figure 3). The network exhibits contrast enhancement of spatial edges which increases with higher mean input strength (figure
4). A point source input elicits an on-center off-surround response, similar to the
difference-of-Gaussians receptive field of many excitable cells. This 'receptive field'
becomes more pronounced as the input intensity increases, showing the dependence
of spatial frequency tuning on mean input level (figure 5). The temporal response
of the network is also input dependent since the time constant of the exponential

Analog Implementation of Shunting Neural Networks

decay of the impulse response decreases with input intensity. Finally, the dependence of the above properties on mean input strength can be tuned by varying the
conductance of the central FET.
700.0

---

600.0

500.0 ?

>
E
11.1

II

400.0

!:i
~

5

300.0

~

o

200.0

100.0

0.1

0.3

0.5

0 .7

0.9

1. 1

1.3

1.5

1.7

1.11

2.1

INPUT CURRENT rnA

Figure 3. Response of network to uniform input. Output is proportional to the square root of the input.

DEPENDENCE OF ENHANCEMENT ON MEAN INPUT
1.5

1.4

~

:J
0

...

1.3

a

1.2

i

1.1

N

II:

0

z

5

~
0
a

1.0

0 .11

f

...::l

0.8

IL
~

0 .7

0.11

2

5

3

7

CELL NUMBER

Figure 4. Response of network to spatial edge patterns with the
same contrast but increasing mean input level.

699

700

Nabet, Darling and Pinter

Imox

~

2 .0J rnA, llmox - J75.74 mil

1.0

0 .11
~

g
:>

0.11

0

Q

~

0 .7

!5
II.
I

iii

0.11

II:

0.5

i
0
Z

0.4

O.J
2

J

4

II

5

7

cEll NUMBER
INPUT

-x-

OUTPUT

Figure 5. Response of network to a point source input. Inset
shows the receptive field of fly's lamina monopolar cells (LMC of
Lucilia sericata). Horizontal axis of inset in visual angle, vertical
a.xis relative voltage units of hyperpolarization. Inset from Pinter
et al. (in preparation)

CONTENT ADDRESSABILITY AND RELATION TO ART
Using a theorem by Cohen and Grossberg (1983), it can be shown that the network
equa.tion (2) a.dmits the global Liapunov function
n

V --

-

""'(l?ln(xi)
~
1
>. - a'x
1 1' + K'x~)
1 1

n

+.!2 '""

;=1

~

K??x
IJ J'XL
.. ,

(3)

j,k=l

=

where>. is a constant, under the constraints Kij
Kji and Xi > O. This shows that
in response to an arbitrary input the network always approaches an equilibrium
point. The equilibria represent stored patterns and this is Content Addressable
Memory (CAM) property.
In addition, Eq. (2) is a special case of the feature representation field of an analog
adaptive resonance theory ART-2 circuit, (Carpenter and Grossberg 1987), and
hence this design can operate as a module in a learning multilayer ART architecture.

Analog Implementation of Shunting Neural Networks

FUTURE PLANS
Due to the very small number of circuit components required to construct a cell,
this implementation is quite adaptable to very high integration densities. A solid
state implementation of the circuit of figure (2) on a gallium arsenide substrate,
chosen for its superiority for opto-electronics applications, is in progress. The chip
includes monolithically fabricated photosensors for processing of visual information.
All of the basic components of the circuit have been fabricated and tested. With
standard 2 micron GaAs BFL design rules, a chip could contain over 1000 cells per
cm 2 , assuming an average of 20 inputs per cell.

CONCLUSIONS
?
?

?

?
?
?

The present work has the following distinguishing features:
Implements a mathematically well described and stable model.
Proposes a framework for implementation of shunting nets which are biologically
feasible, explain variety of psychophysical and psychological data and have many
desirable computational properties.
Has self-sufficient computational capabilities; especially suited for processing of sensory information in general and visual information in particular (N abet and Darling
1988).
Produces a 'good representation' of the input data which is also compatible with
the self-organizing multilayer neural network architecture ART-2.
Is suitable for implementation in variety of technologies.
Is parallel, analog, and has very little overhead circuitry.

..

-.

701

702

Nabet, Darling and Pinter

REFERENCES
Carpenter, G.A. and Grossberg, S. (1987) ""ART 2: self organization of stable category recognition codes for analog input patterns,"". Applied Optics 26, pp. 49194930.
Cohen,M.A. and Grossberg, S. (1983) ""Absolute stability of global pattern formation and parallel memory storage by competitive neural networks"" , IEEE Transactions on Systems Man and Cybernetics SMC-13, pp. 815-826.
Ellias, S.A. and Grossberg, S. (1975) ""Pattern formation, contrast control, and
oscillations in the short term memory of shunting on-center off-surround networks""
Biological Cybernetics, 20, pp. 69-98.
Grossberg, S. (1973), ""Contour enhancement, Short term memory and constancies
in reverberating neural networks,"" Studies in Applied Mathematics, 52, pp. 217257.
Grossberg, S. (1983), ""The quantized geometry of visual space: the coherent computation of depth, form, and lightness."" The behavioral and brain sciences, 6, pp.
625-692.
Lotka, A.J. (1956). Elements of mathematical biology. New York: Dover.
Nabet, B. and Darling, R.B. (1988). ""Implementation of optical sensory neural networks with simple discrete and monolithic circuits,"" (Abstract) Neural Networks,
Vol.l, Suppl. 1, 1988, pp. 396.
Pinter, R.B., (1983). ""The electrophysiological bases for linear and nonlinear product term lateral inhibition and the consequences for wide-field textured stimuli""
J. Theor. Bioi. 105 pp. 233-243.
Pinter, R.B. (1985) "" Adaptation of spatial modulation transfer functions via nonlinear lateral inhibition"" Bioi. Cybernetics 51, pp. 285-291.
Pinter, R.B. (1987) ""Visual system neural networks: Feedback and feedforward lateral inhibition"" Systems and Control Encyclopedia (ed.M.G. Singh) Oxford: Pergamon Press. pp. 5060-5065.
Pinter, R.B., Osorio, D., and Srinivasan, M.V., (in preperation) ""Shift of edge
preference to scototaxis depends on mean luminance and is predicted by a matched
filter hypothesis in fly lamina cells""
RaIl, W. (1977). ""Core conductor theory and cable properties of neurons"" in Handbook of Physiology: The Nervous System vol. I, part I, Ed. E.R. Kandel pp. 39-97.
Bethesda, MD: American Physiological Society.

"
