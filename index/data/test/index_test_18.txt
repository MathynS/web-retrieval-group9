query sentence: Neural-network
<<------------------------------------------------------------------------------------------------------------------------------------------->>
title: 516-neural-network-routing-for-random-multistage-interconnection-networks.pdf

Neural Network Routing for Random Multistage
Interconnection Networks
Mark W. Goudreau
Princeton University
and
NEe Research Institute Inc.
Independence Way
Princeton NJ
Lee Giles
NEC Research Institute Inc.
Independence Way
Princeton NJ
Abstract
A routing scheme that uses a neural network has been developed that can
aid in establishing point-to-point communication routes through multistage interconnection networks MINs The neural network is a network
of the type that was examined by Hopfield Hopfield and
In this work the problem of establishing routes through random MINs
RMINs in a shared-memory distributed computing system is addressed
The performance of the neural network routing scheme is compared to two
more traditional approaches exhaustive search routing and greedy routing The results suggest that a neural network router may be competitive
for certain RMIN
INTRODUCTION
A neural network has been developed that can aid in establishing point-topoint communication routes through multistage interconnection networks MINs
Goudreau and Giles Such interconnection networks have been widely studied Huang Siegel The routing problem is of great interest due to
its broad applicability Although the neural network routing scheme can accommodate many types of communication systems this work concentrates on its use in a
shared-memory distributed computing system
Neural networks have sometimes been used to solve certain interconnection network
Neural Network Routing for Random Multistage Interconnection Networks
Input
Ports
Output
Ports
Interconnection
Network
Control Bits
Logic1
I
Neural
Network
Interconnection
Logic2
Network
I
Controller
I
Externa Control
Figure The communication system with a neural network router The input
ports processors are on the left while the output ports memory modules are on
the right
problems such as finding legal routes Brown Hakim and Meadows
and increasing the throughput of an interconnection network Brown and Liu
Marrakchi and Troudet The neural network router that is the subject of
this work however differs significantly from these other routers and is specially
designed to handle parallel processing systems that have MINs with random interstage connections Such random MINs are called RMINs RMINs tend to have
greater fault-tolerance than regular MINs
The problem is to allow a set of processors to access a set of memory modules
through the RMIN A picture of the communication system with the neural network
router is shown in Figure The are processors and memory modules The
system is assumed to be synchronous At the beginning of a message cycle some
set of processors may desire to access some set of memory modules It is the
job of the router to establish as many of these desired connections as possible in
a non-conflicting manner Obtaining the optimal solution is not critical Stymied
processors may attempt communication again during the subsequent message cycle
It is the combination of speed and the quality of the solution that is important
The object of this work was to discover if the neural network router could be competitive with other types of routers in terms of quality of solution speed and resource
Goudreau and Giles
RMIN2
RMINI
RMIN3
Figure Three random multistage interconnection networks The blocks that are
shown are crossbar switches for which each input may be connected to each output
utilization To this end the neural
other schemes for routing in RMINs
routing So far the results of this
router may indeed be a practicable
too large
network routing scheme was compared to two
namely exhaustive search routing and greedy
investigation suggest that the neural network
alternative for routing in RMINs that are not
EXHAUSTIVE SEARCH ROUTING
The exhaustive search routing method is optimal in terms of the ability of the router
to find the best solution There are many ways to implement such a router One
approach is described here
For a given interconnection network every route from each input to each output
was stored in a database The RMIN that were used as test cases in this paper
always had at least one route from each processor to each memory module When
a new message cycle began and a new message set was presented to the router
the router would search through the database for a combination of routes for the
message set that had no conflicts A conflict was said to occur if more than one
route in the set of routes used a single bus in the interconnection network In the
case where every combination of routes for the message set had a conflict the router
would find a combination of routes that could establish the largest possible number
of desired connections
If there are possible routes for each message this algorithm needs a memory of
size mnk and in the worst case takes exponential time with respect to the size
Neural Network Routing for Random Multistage Interconnection Networks
of the message set Consequently it is an impractical approach for most RMINs
but it provides a convenient upper bound for the performance of other routers
GREEDY ROUTING
When greedy routing is applied message connections are established one at a time
Once a route is established in a given message cycle it may not be removed Greedy
routing does not always provide the optimal routing solution
The greedy routing algorithm that was used required the same route database as
the exhaustive search router did However it selects a combination of routes in
the following manner When a new message set is present the router chooses one
desired message and looks at the first route on that message's list of routes The
router then establishes that route Next the router examines a second message
assuming a second desired message was requested and sees if one of the routes
in the second message's route list can be established without conflicting with the
already established first message If such a route does exist the router establishes
that route and moves on to the next desired message
In the worst case the speed of the greedy router is quadratic with respect to the
size of the message set
NEURAL NETWORK ROUTING
The focal point of the neural network router is a neural network of the type that
was examined by Hopfield Hopfield and The problem of establishing
a set of non-conflicting routes can be reduced to a constraint satisfaction problem
The structure of the neural network router is completely determined by the RMIN
When a new set of routes is desired only certain bias currents in the network change
The neural network routing scheme also has certain fault-tolerant properties that
will not be described here
The neural network calculates the routes by converging to a legal routing array A
legal routing array is 3-dimensional Therefore each element of the routing array
will have three indices If element ai,i,k is equal to then message is routed
through output port of stage We say and are in the same row if
I and They are in the same column if I and Finally they are
in the same rod if and
A legal routing array will satisfy the following three constraints
one and only one element in each column is equal to
the elements in successive columns that are equal to represent output ports
that can be connected in the interconnection network
no more than one element in each rod is equal to
The first restriction ensures that each message will be routed through one and
only one output port at each stage of the interconnection network The second
restriction ensures that each message will be routed through a legal path in the
Goudreau and Giles
interconnection network The third restriction ensures that any resource contention
in the interconnection network is resolved In other words only one message can
use a certain output port at a certain stage in the interconnection network When
all three of these constraints are met the routing array will provide a legal route
for each message in the message set
Like the routing array the neural network router will naturally have a 3-dimensional
structure Each ai,j,k of a routing array is represented by the output voltage of a
neuron At the beginning of a message cycle the neurons have a random
output voltage If the neural network settles in one of the global minima the
problem will have been solved
A continuous time mode network was chosen It was simulated digitally The neural
network has neurons The input to neuron is Ui its input bias current is Ii and
its output is Vi. The input Ui is converted to the output Vi by a sigmoid function
Neuron influences neuron by a connection represented by Similarly
neuron affects neuron through connection Iij. In order for the Liapunov function
Equation to be constructed Iij must equal7ji We further assume that Iii
For the synchronous updating model there is also a time constant denoted by T.
The equations which describe the output of a neuron are
duo
LN T...
dt
T=RC
g(Uj
e-X
The equations above force the neural net into stable states that are the local minima
of this approximate energy equation
iNN
2L
Iij Vi V'i Ii
i=l
For the neural network the weights Iii's are set as are the bias currents
It is the output voltages that vary to to minimize E.
Let be the number of messages in a message set let be the number of stages
in the RMIN and let be the number of ports per stage may be a function
of the stage number Below are the energy functions that implement the three
constraints discussed above
A
E1
E2
p=l
Vm,I,p
Neural Network Routing for Random Multistage Interconnection Networks
Ea
S-l
m=l
p=l
tt
i=l
Vm",i
JIm j)Vm,IJ Pm Vm,S IJ
A and are arbitrary positive constants El and Ea handle the first
constraint in the routing array E4 deals with the second constraint E2 ensures the
third From the equation for the function d(sl,pl,p2 represents the distance
between output port pI from stage sl and output port p2 from stage If pI
can connect to p2 through stage sl then this distance may be set to zero If pI
and p2 are not connected through stage sl then the distance may be set to one
Also am is the source address of message while f3m is the destination address
of message
The entire energy function is
Solving for the connection and bias current values as shown in Equation results
in the following equations
Oml,m2
1m am,p
is a Kronecker delta when and otherwise
Essentially this approach is promising because the neural network is acting as a
parallel computer The hope is that the neural network will generate solutions much
faster than conventional approaches for routing in RMINs
The neural network that is used here has the standard problem namely a global
minimum is not always reached But this is not a serious difficulty Typically
when the globally minimal energy is not reached by the neural network some of
the desired routes will have been calculated while others will not have Even a
locally minimal solution may partially solve the routing problem Consequently
this would seem to be a particularly encouraging type of application for this type
of neural network For this application the traditional problem of not reaching
the global minimum may not hurt the system's performance very much while the
expected speed of the neural network in calculating the solution will be a great
asset
IFor the simulations A
and were chosen empirically
and
These values for A
Goudreau and Giles
Table Routing results for the RMINs shown in Figure The
calculated due to their computational complexity
RMIN1
RMIN2
entries were not
RMIN3
Eel
Egr
Enn
Eel
Egr
Enn
Eel
Egr
Enn
The neural network router uses a large number of neurons If there are input
ports and output ports for each stage of the RMIN an upper bound on the
number of neurons needed is S. Often however the number of neurons actually
required is much smaller than this upper bound
It has been shown empirically that neural networks of the type used here can con
verge to a solution in essentially constant time For example this claim is made for
the neural network described in Takefuji and Lee which is a slight variation
of the model used here
SIMULATION RESULTS
Figure shows three RMINs that were examined The routing results for the three
routing schemes are shown in Table Eel represents the expected number of
messages to be routed using exhaustive search routing Egr is for greedy routing
while Enn is for neural network routing These values are functions of the size
of the message set M. Only message sets that did not have obvious conflicts
were examined For example no message set could have two processors trying to
communicate to the same memory module The table shows that for at least these
three RMINs the three routing schemes produce solutions that are of similar virtue
In some cases the neural network router appears to outperform the supposedly
optimal exhaustive search router That is because the Eel and Egr values were
calculated by testing every message set of size while Enn was calculated by
testing randomly generated message sets of size M. For the neural network
router to appear to perform best it must have gotten message sets that were easier
to route than average
In general the performance of the neural network router degenerates as the size of
the RMIN increases It is felt that the neural network router in its present form will
not scale well for large RMINs This is because other work has shown that large
neural networks of the type used here have difficulty converging to a valid solution
Hopfield
Neural Network Routing for Random Multistage Interconnection Networks
CONCLUSIONS
The results show that there is not much difference in terms of quality of solution for
the three routing methodologies working on these relatively small sample RMINs
The exhaustive search approach is clearly not a practical approach since it is too
time consuming But when considering the asymptotic analyses for these three
methodologies one should keep in mind the performance degradation of the greedy
router and the neural network router as the size of the RMIN increases
Greedy routing and neural network routing would appear to be valid approaches
for RMINs of moderate size But since asymptotic analysis has a very limited
significance here the best way to compare the speeds of these two routing schemes
would be to build actual implementations
Since the neural network router essentially calculates the routes in parallel it can
reasonably be hoped that a fast analog implementation for the neural network
router may find solutions faster than the exhaustive search router and even the
greedy router Thus the neural network router may be a viable alternative for
RMIN that are not too large

<<----------------------------------------------------------------------------------------------------------------------->>

title: 1162-experiments-with-neural-networks-for-real-time-implementation-of-control.pdf

Experiments with Neural Networks for Real
Time Implementation of Control
P. K. Campbell M. Dale H. L. Ferra and A. Kowalczyk
Telstra Research Laboratories
Blackburn Road Clayton Vic. Australia
p.campbell m.dale h.ferra a.kowalczyk}@trl.oz.au
Abstract
This paper describes a neural network based controller for allocating
capacity in a telecommunications network This system was proposed in
order to overcome a real time response constraint Two basic
architectures are evaluated a feedforward network-heuristic and a
feedforward network-recurrent network These architectures are
compared against a linear programming optimiser as a benchmark
This LP optimiser was also used as a teacher to label the data samples
for the feedforward neural network training algorithm It is found that
the systems are able to provide a traffic throughput of and
respectively of the throughput obtained by the linear programming
solution Once trained the neural network based solutions are found in a
fraction of the time required by the LP optimiser
Introduction
Among the many virtues of neural networks are their efficiency in terms of both execution
time and required memory for storing a structure and their practical ability to approximate
complex functions A typical drawback is the usually data hungry training algorithm
However if training data can be computer generated off line then this problem may be
overcome In many applications the algorithm used to generate the solution may be
impractical to implement in real time In such cases a neural network substitute can
become crucial for the feasibility of the project This paper presents preliminary results for
a non-linear optimization problem using a neural network The application in question is
that of capacity allocation in an optical communications network The work in this area is
continuing and so far we have only explored a few possibilities
Application Bandwidth Allocation in SDH Networks
Synchronous Digital Hierarchy SDH is a new standard for digital transmission over
optical fibres adopted for Australia and Europe equivalent to the SONET
Synchronous Optical NETwork standard in North America The architecture of the
particular SDH network researched in this paper is shown in Figure
Nodes at the periphery of the SDH network are switches that handle individual
calls
P. CAMPBELL M. DALE H. L. FERRA A. KOWALCZYK
Each switch concentrates traffic for another switch into a number of streams
Each stream is then transferred to a Digital Cross-Connect DXC for switching and
transmission to its destination by allocating to it one of several alternative virtual
paths
The task at hand is the dynamic allocation of capacities to these virtual paths in order to
maximize SDH network throughput
This is a non-linear optimization task since the virtual path capacities and the constraints
the physical limit on capacity of links between DXC's are quantized and the objective
function Erlang blocking depends in a highly non-linear fashion on the allocated
capacities and demands Such tasks can be solved optimally with the use of classical
linear programming techniques but such an approach is time-consuming for large
SDH networks the task could even require hours to complete
One of the major features of an SDH network is that it can be remotely reconfigured using
software controls Reconfiguration of the SDH network can become necessary when
traffic demands vary or when failures occur in the DXC's or the links connecting them
Reconfiguration in the case of failure must be extremely fast with a need for restoration
times under ms
output path
capacities
synaptic weights
hidden units
AND gates
thresholds
used
input
link
capacities
DXC Digital
Cross-Connect
offered
traffic
Switch
Figure
Example of an Inter-City SDH/SONET Network Topology used in experiments
Example of an architecture of the mask perceptron generated in experiments
In our particular case there are three virtual paths allocated between any pair of switches
each using a different set of links between DXC's of the SDH network Calls from one
switch to another can be sent along any of the virtual paths leading to paths in total
switches to other switches each with paths
The path capacities are normally set to give a predefined throughput This is known as the
steady state If links in the SDH network become partially damaged or completely cut
the operation of the SDH network moves away from the steady state and the path
capacities must be reconfigured to satisfy the traffic demands subject to the following
constraints
Capacities have integer values between and 64 with each unit corresponding to a
Mb/s stream or Erlangs
The total capacity of all virtual paths through anyone link of the SDH network
Experiments with Neural Networks for Real Time Implementation of Control
cannot exceed the physical capacity of that link
The neural network training data consisted of 13 link capacities and 42 traffic demand
values representing situations in which the operation of one or more links is degraded
completely or partially The output data consisted of integer values representing the
difference between the steady state path capacities and the final allocated path capacities
Previous Work
The problem of optimal SDH network reconfiguration has been researched already In
particular Gopal proposed a heuristic greedy search algorithm to solve this nonlinear integer programming problem Herzberg in reformulated this non-linear integer
optimization problem as a linear programming task Herzberg and Bye in
investigated application of a simplex algorithm to solve the LP problem whilst Bye
considered an application of a Hopfield neural network for this task and finally Leckie
used another set of AI inspired heuristics to solve the optimization task
All of these approaches have practical deficiencies the linear programming is slow while
the heuristic approaches are relatively inaccurate and the Hopfield neural network method
simulated on a serial computer suffers from both problems
In a previous paper Campbell investigated application of a mask perceptron to
the problem of reconfiguration for a toy SDH network The work presented here
expands on the work in that paper with the idea of using a second stage mask perceptron
in a recurrent mode to reduce link violationslunderutilizations
The Neural Controller Architecture
Instead of using the neural network to solve the optimization task as a substitute for
the simplex algorithm it is taught to replicate the optimal LP solution provided by it
We decided to use a two stage approach in our experiments For the first stage we
developed a feedforward network able to produce an approximate solution More
precisely we used a collection of random examples for which the linear
programming solution of capacity allocations had been pre-computed to develop a
feedforward neural network able to approximate these solutions
Then for a new example such an approximate neural network solution was rounded to
the nearest integer to satisfy constraint and used to seed the second stage providing
refinement and enforcement of constraint
For the second stage experiments we initially used a heuristic module based on the Gopal
approach The heuristic firstly reduces the capacities assigned to all paths which
cause a physical capacity violation on any links then subsequently increases the capacities
assigned to paths across links which are being under-utilized
We also investigated an approach for the second stage which uses another feedforward
neural network The teaching signal for the second stage neural network is the difference
between the outputs from the first stage neural network alone and the combined first stage
neural networkiheuristic solution This time the input data consisted of 13 link usage
values either a link violation or underutilization and 42 values representing the amount
of traffic lost per path for the current capacity allocations The second stage neural
network had outputs representing the correction to the first stage neural network's
outputs
The second stage neural network is run in a recurrent mode adjusting by small steps the
currently allocated link capacities thereby attempting to iteratively move closer to the
combined neural-heuristic solution by removing the link violations and under-utilizations
left behind by the first stage network
The setup used during simulation is shown in Figure For each particular instance tested
the network was initialised with the solution from the first stage neural network The
offered traffic demand and the available maximum link capacities were used to
determine the extent of any link violations or underutilizations as well as the amount of
lost traffic demand satisfaction This data formed the initial input to the second stage
network The outputs of the neural network were then used to check the quality of the
P. CAMPBELL M. DALE H. L. FERRA A. KOWALCZYK
solution and iteration continued until either no link violations occurred or a preset
maximum number of iterations had been performed
offered traffic
link capacities
computation of
constraint-demand
satisfaction
solution
solution
correction
I
initialization
solution
from stage
demand satisfaction
42 inputs
link capacities
violation!underutilization
13 inputs
Figure Recurrent Network used for second stage experiments
When computing the constraint satisfaction the outputs of the neural network where
combined and rounded to give integer link violations/under-utilizations This means that
in many cases small corrections made by the network are discarded and no further
improvement is possible In order to overcome this we introduced a scheme whereby
errors link violations/under-utilizations are occasionally amplified to allow the network a
chance of removing them This scheme works as follows
an instance is iterated until it has either no link violations or until iterations have
been performed
if any link violations are still present then the size of the errors are multiplied by an
amplification factor
a further maximum of iterations are performed
if subsequently link violations persist then the amplification factor is increased
the procedure repeats until either all link violations are removed or the amplification factor
reaches some fixed value
Description of Neural Networks Generated
The first stage feedforward neural network is a mask perceptron Figure Each
input is passed through a number of arbitrarily chosen binary threshold units There were a
total of thresholds for the 55 inputs The task for the mask perceptron training
algorithm is to select a set of useful thresholds and hidden units out of thousands of
possibilities and then to set weights to minimize the mean-square-error on the training set
The mask perceptron training algorithm automatically selected 67 of these units for direct
connection to the output units and a further hidden units gates whose
Experiments with Neural Networks for Real Time Implementation of Control
outputs are again connected to the neural network outputs giving connections in
all
Such neural networks are very rapid to simulate since the only operations required are
comparison and additions
For the recurrent network used in the second stage we also used a mask perceptron The
training algori thIn used for the recurrent network was the same as for the first stage in
particular note that no gradual adaptation was employed The inputs to the network are
passed through arbitrarily chosen binary threshold units Of these 35 were selected by
the training algorithm for direct connection to the output units via weighted links
Results
The results are presented in Table and Figure The values in the table represent the
traffic throughput of the SDH network for the respective methods as a percentage of the
throughput determined by the LP solution Both the neural networks were trained using
instances and tested against a different set of instances However for the
recurrent network approximately of these cases still had link violations after
simulation so the values in Table are for the of valid solutions obtained from either
the training or test set
Solution type
Feedforward Net/Heuristic
Feedforward Net/Recurrent Net
Gopal-S
Gopal-O
Training
Test
98
these numbers are for the training and test instances out of for which the
recurrent network achieved a solution with no link violations after simulation as described in
Section
Table Efficiency of solutions measured by average fraction of the optimal
throughput of the LP solution
As a comparison we implemented two solely heuristic algorithms We refer to these as
Gopal-S and Gopal-O Both employ the same scheme described earlier for the Gopal
heuristic The difference between the two is that Gopal-S uses the steady state solution as
an initial starting point to determine virtual path capacities for a degraded network
whereas Gopal-O starts from a point where all path capacities are initially set to zero
Referring to Figure link capacity ratio denotes the total link capacity of the degraded
SDH network relative to the total link capacity of the steady state SDH network A low
value of link capacity ratio indicates a heavily degraded network The traffic throughput
ratio denotes the ratio between the throughput obtained by the method in question and the
throughput of the steady state solution
Each dot in the graphs in Figure represents one of the test set cases It is clear from
the figure that the neural network/heuristic approach is able to find better solutions for
heavily degraded networks than each of the other approaches Overall the clustering of
dots for the neural network/heuristic combination is tighter the y-direction and closer
to than for any of the other methods The results for the recurrent network are very
encouraging being qUalitatively quite close to those for the Gopal-S algorithm
All experiments were run on a SPARCStation The neural network training took a few
minutes During simulation the neural network took an average of ms per test case with
a further ms for the heuristic for a total of ms On average the Gopal-S
algorithm required ms and the Gopal-O algorithm required ms per test case The
recurrent network solution required an average of ms per test case The optimal
solutions calculated using the linear programming algorithm took between and
seconds per case on a SPARCStation
P. CAMPBELL M. DALE H. L. FERRA A. KOWALCZYK
Neural Network/Heuristic
Recurrent Neural Network
is
85
link Capacity Ratio
ra
cr
95
90
95
cr
70
Link Capacity Ratio
Gopal-O
Gopal-S
75
90
link Capacity Ratio
75
90
Link Capacily Ratio
Figure Experimental results for the Inter-City SDH network on the
independent test set of random cases On the axis we have the ratio
between the total link capacity of the degraded SDH network and the steady state
SDH network On the axis we have the ratio between the throughput obtained
by the method in question and the throughput of the steady state solution
Fig shows results for the neural network combined with the heuristic
second stage Fig shows results for the recurrent neural network second
stage Fig shows results for the heuristic only initialised by the steady state
Gopal-S and Fig has the results for the heuristic initialised by zero
Gopal-O
Discussion and Conclusions
The combined neural network/heuristic approach performs very well across the whole
range of degrees of SDH network degradation tested The results obtained in this paper are
consistent with those found in The average accuracy of and fast solution
generation times ffJ ms highlight this approach as a possible candidate for
implementation in a real system especially when one considers the easily achievable
speed increase available from parallelizing the neural network The mask perceptron used
in these experiments is well suited for simulation on a DSP other hardware the
operations required are only comparisons calculation of logical AND and the
summation of synaptic weights no multiplications or any non-linear transfonnations are
required
The interesting thing to note is the relatively good perfonnance of the recurrent network
namely that it is able to handle over of cases achieving very good perfonnance when
compared against the neural network/heuristic solution of the quality of the teacher
One thing to bear in mind is that the heuristic approach is highly tuned to producing a
solution which satisfies the constraints changing the capacity of one link at a time until
the desired goal is achieved On the other hand the recurrent network is generic and does
not target the constraints in such a specific manner making quite crude global changes in
Experiments with Neural Networks for Real Time Implementation of Control
one hit and yet is still able to achieve a reasonable level of performance While the speed
for the recurrent network was lower on average than for the heuristic solution in our
experiments this is not a major problem since many improvements are still possible and
the results reported here are only preliminary but serve to show what is possible It is
planned to continue the SOH network experiment in the future with more investigation on
the recurrent network for the second stage and also more complex SDH architectures
Acknowledgments
The research and development reported here has the active support of various sections and
individuals within the Telstra Research Laboratories especially Dr. C. Leckie Mr.
P. Sember Dr. M. Herzberg Mr. A. Herschtal and Dr. L. Campbell The permission of the
Managing Director Research and Information Technology Telstra to publish this paper is
acknowledged
The research and development reported here has the active support of various sections and
individuals within the Telstra Research Laboratories especially Dr. C. Leckie and
Mr. P. Sember who were responsible for the creation and trialling of the programs
designed to produce the testing and training data
The SOH application was possible due to co-operation of a number of our colleagues in
TRL in particular Dr. L. Campbell who suggested this particular application Dr. M.
Herzberg and Mr. A. Herschtal
The permission of the Managing Director Research and Information Technology Telstra
to publish this paper is acknowledged

<<----------------------------------------------------------------------------------------------------------------------->>

title: 211-a-large-scale-neural-network-which-recognizes-handwritten-kanji-characters.pdf

A Large-Scale Neural Network
A LARGE-SCALE NEURAL NETWORK
WHICH RECOGNIZES HANDWRITTEN
KANJI CHARACTERS
Yoshihiro Mori
Kazuki Joe
ATR Auditory and Visual Perception Research Laboratories
Sanpeidani Inuidani Seika-cho Soraku-gun Kyoto Japan
ABSTRACT
We propose a new way to construct a large-scale neural network for
handwritten Kanji characters recognition This neural network
consists of parts a collection of small-scale networks which are
trained individually on a small number of Kanji characters a network
which integrates the output from the small-scale networks and a
process to facilitate the integration of these neworks The recognition
rate of the total system is comparable with those of the small-scale
networks Our results indicate that the proposed method is effective for
constructing a large-scale network without loss of recognition
performance
INTRODUCTION
Neural networks have been applied to recognition tasks in many fields with good results
Denker They have performed better than
conventional methods However these networks currently operate with only a few
categories about to The Japanese writing system at present is composed of about
characters For a network to recognize this many characters it must be given a
large number of categories while maintaining its level of performance
To train small-scale neural networks is not a difficult task Therefore exploring methods
for integrating these small-scale neural networks is important to construct a large-scale
network If such methods could integrate small-scale networks without loss of the
performance the scale of neural networks would be extended dramatically In this paper
we propose such a method for constructing a large-scale network whose object is to
recognize handwritten Kanji characters and report the result of a part of this
network This method is not limited to systems for character recognition and can be
applied to any system which recognizes many categories
STRATEGIES FOR A LARGE-SCALE NETWORK
Knowing the current recognition and generalization capacity of a neural network we
realized that constructing a large-scale monolithic network would not be efficient or
Mori and Joe
effective Instead from the start we decided on a building blocks approach
There are two strategies to mix many small-scale networks
Selective Neural Network SNN
In this strategy a large-scale neural network is made from many small-scale networks
which are trained individually on a small number of categories and a network SNN
which selects the appropriate small-scale network I). The advantage of this strategy
is that the information passed to a selected small-scale networks is always appropriate for
that network Therefore training these small-scale networks is very easy But on the
other hand increasing the number of categories will substantially increase the training
time of the SNN and may make it harder for the SNN to retain high perfonnance
Furthennore the error rate of the SNN will limit the perfonnance of the whole system
Integrative Neural Network INN
In this strategy a large-scale neural network is made from many small-scale networks
which are trained individually on a small number of categories and a network INN
which integrates the output from these small-scale networks(Fig The advantage of
this strategy is that every small-scale network gets information and contributes to finding
the right answer Therefore it is possible to use the knowledge distributed among each
small-scale network But in some respects various devices are needed to make the
integration easier
The common advantage with both strategies just mentioned is that the size of each neural
network is relatively small and it does not take a long time to train these networks Each
small-scale networks is considered an independent part of the whole system Therefore
retraining these networks to improve the performance of the whole system will not take
too long
O,utput
Sub
Net
Neural Network
Selection Type
Suspending
Network
SNN Strategy
A Large-Scale Neural Network
Output
Neural Network
Integration Type
INN Strategy
STRUCTURE OF LARGE-SCALE NETWORK
The whole system is constructed using three kinds of neural networks The ftrst one
called a SubNet is an ordinary three layered feed forward type neural network trained
using the Back Propagation learning algorithm The second kind of network is called a
SuperNet This neural network makes its decision by integrating the outputs from all the
SubNets This network is also a 3-layered feed-forward net but is larger than the Subnets
The last network which we call an OtherFilter is devised to improve the integration of
the uperNet This OtherFilter network was designed using the VQ algorithm
There are also some changes made in the BP learning algorithm
especially for pattern recognition
We decided that based on the time it takes for learning there should be categories in
each small-scale network The characters are separated into these small groups
through the K-means clustering method which allows similar characters to be grouped
together The separation occurs in two stages First groups of characters each are
formed then each group is separated into smaller units In this way groups of
characters each are obtained We choose the INN strategy to use distributed knowledge to
full advantage The 9-character units are SubNets which are integrated in stages First
SubNets are integrated by a higher level network SuperNet Altogether SuperNets
are needed to recognize all characters SuperNets are in turn integrated by a higher
level network the HyperNet More precisely the role and structure of these kinds of
networks are as follows
SubNet
A feature vector extracted from handwritten patterns is used as the input described in
Section The number of units in the output layer is the same as the number of
categories to be recognized by the SubNet In short the role of a SubNet is to output the
similarity between the input pattern and the categories allotted to the SubNet
SuperNet
The outputs from each SubNet fIltered by the OtherFilter network are used as the input to
Mori and Joe
the SuperNet The number of units in an output layer is the same as the number of
SubNets belonging to a SuperNet In shortt the role of SuperNet is to select the SubNet
which covers the category corresponding to the input patterns
Output
Horizontal
45?diagonal
Vertical
Original Pattern
ubNet
OtherFIIter

<<----------------------------------------------------------------------------------------------------------------------->>

title: 1193-a-new-approach-to-hybrid-hmmann-speech-recognition-using-mutual-information-neural-networks.pdf

A New Approach to Hybrid HMMJANN Speech
Recognition Using Mutual Information Neural
Networks
G. Rigoll
Neukirchen
Gerhard-Mercator-University Duisburg
Faculty of Electrical Engineering
Department of Computer Science
Bismarckstr 90 Duisburg Germany
ABSTRACT
This paper presents a new approach to speech recognition with hybrid
HMM/ANN technology While the standard approach to hybrid
HMMIANN systems is based on the use of neural networks as
posterior probability estimators the new approach is based on the use
of mutual information neural networks trained with a special learning
algorithm in order to maximize the mutual information between the
input classes of the network and its resulting sequence of firing output
neurons during training It is shown in this paper that such a neural
network is an optimal neural vector quantizer for a discrete hidden
Markov model system trained on Maximum Likelihood principles
One of the main advantages of this approach is the fact that such
neural networks can be easily combined with HMM's of any
complexity with context-dependent capabilities It is shown that the
resulting hybrid system achieves very high recognition rates which
are now already on the same level as the best conventional HMM
systems with continuous parameters and the capabilities of the
mutual information neural networks are not yet entirely exploited
INTRODUCTION
Hybrid HMM/ANN systems deal with the optimal combination of artificial neural
networks ANN and hidden Markov models Especially in the area of automatic
speech recognition it has been shown that hybrid approaches can lead to very powerful
and efficient systems combining the discriminative capabilities of neural networks and
the superior dynamic time warping abilities of HMM's The most popular hybrid
approach is described in Hochberg and replaces the component modeling the
emission probabilities of the HMM by a neural net This is possible because it is shown
Mutual In/ormation Neural Networks/or Hybrid HMMIANN Speech Recognition
in Bourlard that neural networks can be trained so that the output of the m-th
neuron approximates the posterior probability p(QmIX In this paper an alternative
method for constructing a hybrid system is presented It is based on the use of discrete
HMM's which are combined with a neural vector quantizer in order to form a hybrid
system Each speech feature vector is presented to the neural network which generates a
firing neuron in its output layer This neuron is processed as VQ label by the HMM's
There are the following arguments for this alternative hybrid approach
The neural vector quantizer has to be trained on a special information theory criterion
based on the mutual information between network input and resulting neuron firing
sequence It will be shown that such a network is the optimal acoustic processor for a
discrete HMM system resulting in a profound mathematical theory for this approach
Resulting from this theory a formula can be derived which jointly describes the
behavior of the HMM and the neural acoustic processor In that way both systems can
be described in a unified manner and both major components of the hybrid system can
be trained using a unified learning criterion
The above mentioned theoretical background leads to the development of new neural
network paradigms using novel training algorithms that have not been used before in
other areas of neurocomputing and therefore represent major challenges and issues in
learning and training for neural systems
The neural networks can be easily combined with any HMM system of arbitrary
complexity This leads to the combination of optimally trained neural networks with
very powerful HMM's having all features useful for speech recognition triphones
function words crossword triphones etc Context-dependency which is very desirable
but relatively difficult to realize with a pure neural approach can be left to the HMM's
The resulting hybrid system has still the basic structure of a discrete system and
therefore has all the effective features associated with discrete systems quick and
easy training as well as recognition procedures real-time capabilities etc
The work presented in this paper has been also successfully implemented for a
demanding speech recognition problem the word speaker-independent continuous
Resource Management speech recognition task For this task the hybrid system
produces one of the best recognition results obtained by any speech recognition system
In the following section the theoretical foundations of the hybrid approach are briefly
explained A unified probabilistic model for the combined HMMIANN system is derived
describing the interaction of the neural and the HMM component Furthermore it is
shown that the optimal neural acoustic processor can be obtained from a special
information theoretic network training algorithm
INFORMATION THEORY PRINCIPLES FOR NEURAL
NETWORK TRAINING
We are considering now a neural network of arbitrary topology used as neural vector
quantizer for a discrete HMM system If patterns are presented to the hybrid system
during training the feature vectors resulting from these patterns using any feature
extraction method can be denoted as If these feature vectors are presented to
the input layer of a neural network the network will generate one firing neuron for each
presentation Hence all presentations will generate a stream of firing neurons with
length resulting from the output layer of the neural net This label stream is denoted as
The label stream will be presented to the HMM's which calculate the
probability that this stream has been observed while a pattern of a certain class has been
presented to the system It is assumed that different classes are active in the
G. Rigoll and C. Neukirchen
system the words or phonemes in speech recognition Each feature vector will
belong to one of these classes The class Om to which feature vector belongs is
denoted as The major training issue for the neural network can be now formulated
as follows How should the weights of the network be trained so that the network
produces a stream of firing neurons that can be used by the discrete HMM's in an optimal
way It is known that HMM's are usually trained with information theory methods which
mostly rely on the Maximum Likelihood principle If the parameters of the hybrid
system transition and emission probabilities and network weights are summarized in
the vector the probability denotes the probability of the pattern at
discrete time under the assumption that it has been generated by the model representing
class with parameter set The ML principle will then try to maximize the joint
probability of all presented training patterns according to the following Maximum
Likelihood function
fl arg max
log I Q(k?j
where is the optimal parameter vector maximizing this equation Our goal is to feed
the feature vector into a neural network and to present the neural network output to the
Markov model Therefore one has to introduce the neural network output in a suitable
manner into the above formula If the vector is presented to the network input layer and
we assume that there is a chance that any neuron Yn with network output layer
size can fire with a certain probability then the output probability in can
be written as
p(KIQ
p(x IQ
p(y IQ p(x Iy
Now the combination of the neural component with the HMM can be made more
obvious In typically the probability P(YnIQ will be described by the Markov model
in terms of the emission probabilities of the HMM For instance in continuous
parameter HMM's these probabilities are interpreted as weights for Gaussian mixtures In
the case of semi-continuous systems or discrete HMM's these probabilities will serve as
discrete emission probabilities of the codebook labels The probability p(xIYn,Q
describes the acoustic processor of the system and is characterizing the relation between
the vector as input to the acoustic processor and the label Yn which can be considered
as the n-th output component of the acoustic processor This n-th output component may
characterize the n-th Gaussian mixture component in continuous parameter HMM's
or the generation of the n-th label of a vector quantizer in a discrete system This
probability is often considered as independent of the class and can then be expressed as
p(xIYn It is exactly this probability that can be modeled efficiently by our neural
network In this case the vector serves as input to the neural network and Yn
characterizes the n-th neuron in the output layer of the network Using Bayes law this
probability can be written as
P(YnIK pW
p(xl Yn
p(y
I
I
yielding for
Using again Bayes law to express
Mutual Information Neural Networks for Hybrid HMMIANN Speech Recognition
one obtains from
p(.Qly p(ynlo!J
We have now modified the class-dependent probability of the feature vector in a way
that allows the incorporation of the probability P(YnIX This probability allows a better
characterization of the behavior of the neural network because it describes the probability
of the various neurons Yn if the vector is presented to the network input Therefore
these probabilities give a good description of the input/output behavior of the neural
network can therefore be considered as probabilistic model for the hybrid system
where the neural acoustic processor is characterized by its input/output behavior Two
cases can be now distinguished In the first case the neural network is assumed to be a
probabilistic paradigm where each neuron fires with a certain probability if an input
vector is presented In this case all neurons contribute to the information forwarded to the
HMM's As already mentioned in this paper the second possible case is considered
namely that only one neuron in the output layer fires and will be fed as observed label to
the HMM. In this case we have a deterministic decision and the probability P(YnIX
describes what neuron Yn fires if vector is presented to the input layer Therefore this
probability reduces to
Then yields
Now the class-dependent probability p(Xln is expressed through the probability
p(nIYn involving directly the firing neuron when feature vector is presented
One has now to turn back to recalling the fact that this equation describes the fact
that the Markov models are trained with the ML criterion It should also be recalled that
the entire sequence of feature vectors results in a label stream of firing
neurons where is the firing neuron if the k-th vector is
presented to the neural network Now can be substituted into for each presentation
yielding the modified ML criterion
arg;ax
log P(Q I
arg;ax log p(x IOg
Usually in a continuous parameter system the probability can be expressed as
LP(K,ly p(y
and is therefore dependent of the parameter vector ft because in this case p(xIYn can be
interpreted as the probability provided by the Gaussian distributions and the parameters of
G. Rigoll and C. Neukirchen
the Gaussians will depend on ft As just mentioned before in a discrete system only one
firing neuron Yn survives resulting in the fact that only the n*-th member remains in
the sum in This would correspond to only one firing Gaussian in the continuous
case leading to the following expression for
p(x Iy nJ p(y nJ p(K,y nJ p(y n"lx
Considering now the fact that the acoustic processor is not represented by a Gaussian but
instead by a vector quantizer where the probability P(Yn*IX of the firing neuron is equal
to then reduces to and it becomes obvious that this probability is not
affected by any distribution that depends on the parameter vector ft This would be
different if P(Yn*IX in would not have binary characteristics as in but would be
computed by a continuous function which in this case would depend on the parameter
vector ft Thus without consideration of the remaining expression to be maximized
in reduces to
arg;ax
IOg
arg max
log I
log log I
These expectations of logarithmic probabilities are also defined as entropies Therefore
can be also written as
arg max I
This equation can be interpreted as follows The term on the right side of is also
known as the mutual information between the probabilistic variables nand
H(YI.o
Therefore the final information theory-based training criterion for the neural network can
be formulated as follows The synaptic weights of the neural network should be chosen as
to maximize the mutual information between the string representing the classes of the
vectors presented to the network input layer during training and the string representing the
resulting sequence of firing neurons in the output layer of the neural network This can be
also expressed as the Maximum Mutual Information MMI criterion for neural network
training This concludes the proof that MMI neural networks are indeed optimal acoustic
processors for HMM's trained with maximum likelihood principles
REALIZATION OF MMI TRAINING ALGORITHMS FOR
NEURAL NETWORKS
Training the synaptic weights of a neural network in order to achieve mutual information
maximization is not easy Two different algorithms have been developed for this task and
can only be briefly outlined in this paper A detailed description can be found in Rigoll
and Neukirchen The first experiments used a single-layer neural network
with Euclidean distance as propagation function The first implementation of the MMI
training paradigm has been realized in Rigoll and is based on a self-organizing
procedure starting with initial weights derived from k-means clustering of the training
vectors followed by an iterative procedure to modify the weights The mutual
information increases in a self-organizing way from a low value at the start to a much
higher value after several iteration cycles The second implementation has been realized
Mutual Information Neural Networks for Hybrid HMMIANN Speech Recognition
recently and is described in detail in Neukirchen It is based on the idea of using
gradient methods for finding the MMI value This technique has not been used before
because the maximum search for finding the firing neuron in the output layer has
prevented the calculation of derivatives This maximum search can be approximated using
the softmax function denoted as sn for the n-th neuron It can be computed from the
activations Zl of all neurons as
IT
Sn=e
ZI
IT
where a small value for parameter approximates a crisp maximum selection Since the
string in is always fixed during training and independent of the parameters in ft
only the function H(nIY has to be minimized This function can also be expressed as
I
p(y I
A derivative with respect to a weight Wlj of the neural network yields
aH
JW/j
As shown in Neukirchen all the required terms in can be computed
effectively and it is possible to realize a gradient descend method in order to maximize the
mutual information of the training data The great advantage of this method is the fact
that it is now possible to generalize this algorithm for use in all popular neural network
architectures including multilayer and recurrent neural networks
RESULTS FOR THE HYBRID SYSTEM
The new hybrid system has been developed and extensively tested using the Resource
Management word speaker-independent continuous speech recognition task First a
baseline discrete HMM system has been built up with all well-known features of a
context-dependent HMM system The performance of that baseline system is shown in
column of Table The 1st column shows the performance of the hybrid system with
the neural vector quantizer This network has some special features not mentioned in the
previous sections it uses multiple frame input and has been trained on contextdependent classes That means that the mutual information between the stream of firing
neurons and the corresponding input stream of triphones has been maximized In this
way the firing behavior of the network becomes sensitive to context-dependent units
Therefore this network may be the only existing context-dependent acoustic processor
carrying the principle of triphone modeling from the HMM structure to the acoustic front
end It can be seen that a substantially higher recognition performance is obtained with
the hybrid system that compares well with the leading continuous system HTK in
column It is expected that the system will be further improved in the near future
through various additional features including full exploitation of multilayer neural VQ's
G. Rigoll and C. Neukirchen
and several conventional HMM improvements the use of crossword triphones
Recent results on the larger Wall Street Journal WSJ database have shown a error
rate for the hybrid system compared to a error rate for a standard discrete system
using the 5k vocabulary test with bigram language model of perplexity This error
rate can be further reduced to using crossword triphones and with a trigram
language model This rate compares already quite favorably with the best continuous
systems for the same task It should be noted that this hybrid WSJ system is still in its
initial stage and the neural component is not yet as sophisticated as in the RM system
CONCLUSION
A new neural network paradigm and the resulting hybrid HMMIANN speech recognition
system have been presented in this paper The new approach performs already very well
and is still perfectible It gains its good performance from the following facts The use
of information theory-based training algorithms for the neural vector quantizer which can
be shown to be optimal for the hybrid approach The possibility of introducing
context-dependency not only to the HMM's but also to the neural quantizer The fact
that this hybrid approach allows the combination of an optimal neural acoustic processor
with the most advanced context-dependent HMM system We will continue to further
implement various possible improvements for our hybrid speech recognition system

<<----------------------------------------------------------------------------------------------------------------------->>

title: 1968-not-bounding-the-true-error.pdf

Not Bounding the True Error
John Langford
Department of Computer Science
Carnegie-Mellon University
Pittsburgh PA
jcl+@cs.cmu.edu
Rich Caruana
Department of Computer Science
Cornell University
Ithaca NY
caruana@cs.cornell.edu
Abstract
We present a new approach to bounding the true error rate of a continuous
valued classifier based upon PAC-Bayes bounds The method first constructs a distribution over classifiers by determining how sensitive each
parameter in the model is to noise The true error rate of the stochastic
classifier found with the sensitivity analysis can then be tightly bounded
using a PAC-Bayes bound In this paper we
demonstrate
the method on
order of magnitude
artificial neural networks with results of a
improvement the best deterministic neural net bounds
Introduction
In machine learning it is important to know the true error rate a classifier will achieve on
future test cases Estimating this error rate can be suprisingly difficult For example all
known bounds on the true error rate of artificial neural networks tend to be extremely loose
and often result in the meaningless bound of always err error rate
In this paper we do not bound the true error rate of a neural network Instead we bound
the true error rate of a distribution over neural networks which we create by analysing one
neural network Hence the title This approach proves to be much more fruitful than
trying to bound the true error rate of an individual network The best current approaches
often require or more examples before producing a nontrivial bound on
the true error rate We produce nontrivial bounds on the true error rate of a stochastic neural
network with less than
examples A stochastic neural network is a neural network
where each weight
is perturbed by a gaussian with variance every time it is evaluated
Our approach uses the PAC-Bayes bound The approach can be thought of as a
redivision of the work between the experimenter and the theoretician we make the experimenter work harder so that the theoretician?s true error bound becomes much tighter This
extra work on the part of the experimenter is significant but tractable and the resulting
bounds are much tighter
An alternative viewpoint is that the classification problem is finding a hypothesis with
a low upper bound on the future error rate We present a post-processing phase for neural
networks which results in a classifier with a much lower upper bound on the future error
rate The post-processing can be used with any artificial neural net trained with any optimization method it does not require the learning procedure be modified re-run or even
that the threshold function be differentiable In fact this post-processing step can easily be
adapted to other learning algorithms
David MacKay has done significant work to make approximate Bayesian learning
tractable with a neural network Our work here is complimentary rather than competitive
We exhibit a technique which will likely give nontrivial true error rate bounds for Bayesian
neural networks regardless of approximation or prior modeling errors Verification of this
statement is work in progress
The post-processing step finds a large distribution over classifiers which has a small
average empirical error rate Given the average empirical error rate it is straightforward
to apply the PAC-Bayes bound in order to find a bound on the average true error rate We
find this large distribution over classifiers by performing a simple noise sensitivy analysis
on the learned model The noise model allows us to generate a distribution of classifiers
with a known small average empirical error rate In this paper we refer to the distribution
of neural nets that results from this noise analysis as a stochastic neural net model
Why do we expect the PAC-Bayes bound to be a significant improvement over standard
covering number and VC bound approaches There exist learning problems for which
the difference between the lower bound and the PAC-Bayes upper bound are tight up to
where is the number of training examples This is superior to the guarantees
which can be made for typical covering number bounds where the gap is at best known
up to an asymptotic constant The guarantee that PAC-Bayes bounds are sometimes quite
tight encourages us to apply them here
The next sections will
Describe the bounds we will compare
Describe our algorithm for constructing a distribution over neural networks
Present experimental results
Theoretical setup
We will work in the standard supervised batch learning setting This setting starts with the
over
assumption that all examples are drawn from some fixed unknown distribution
and the,input
input output pairs
The output is drawn from the space
space is arbitrary The goal of machine learning is to use a sample set of pairs to find
a classifier which maps the input space to the output space and has a small true error
Since the distribution is unknown the true error rate is not
observable However we can observe the empirical error rate
Now that the basic quantities of interest are defined we will first present a modern neural network bound then specialize the PAC-Bayes bound to a stochastic neural network A
stochastic neural network is simply a neural network where each weight in the neural network is drawn from some distribution whenever it is used We will describe our technique
for constructing the distribution of the stochastic neural network
Neural Network bound
We will compare a specialization of the best current neural network true error rate bound
with our approach The neural network bound is described in terms of the following
parameters
A margin
An arbitrary function unrelated to the neural network sigmoid function defined by
if
if and linear in between
an upper bound on the sum of the magnitude of the weights in the th layer of
the neural network
a Lipschitz constant which holds for the th layer of the neural network A
Lipschitz constant is a bound on the magnitude of the derivative
the size of the input space
With these parameters defined we get the following bound
Theorem layer feed-forward Neural Network true error bound
@
A
EGF
HJI L>9M5NPQSO T8UWVYX[Z
A
where
1B 1B @ 1@
Proof Given in
The theorem is actually only given up to a universal constant might be the right
choice but this is just an educated guess The neural network true error bound above is
perhaps the tightest known bound for general feed-forward neural networks and so it is
the natural bound to compare with
This layer feed-forward bound is not easily applied in a tight manner because we can?t
calculate a priori what our weight bound should be This can be patched up using the
principle of structural risk minimization In particular we can state the bound for
where is some non-negative integer and
is a constant If the th bound holds with
probability then all bounds will hold simultaneously with probability
since
@
41
Applying this approach to the values of both
EF
@
@
and
@
we get the following theorem
Theorem layer feed-forward Neural Network true error bound
HJI NO T8 X9Z
where
1B 1B
Proof Apply the union bound to all possible values of and as discussed above
and report the value of the tightest applicable bound
In practice we will use
for all
23
Stochastic Neural Network bound
Our approach will start with a simple refinement of the original PAC-Bayes bound
We will first specialize this bound to stochastic neural networks and then show that the use
of this bound in conjunction with a post-processing algorithm results in a much tighter true
error rate upper bound
First we will need to define some parameters of the theorem
is a distribution over the hypotheses which can be found in an example depen
dent manner
@
is a distribution over the hypotheses which is chosen a priori?without dependence on the examples
is the true error rate of the stochastic hypothesis which in
any evaluation draws a hypothesis from and outputs
is the average empirical error rate of the same stochastic
hypothesis
BA
CD
BA
FCG
HE
A
A
Now we are ready to state the theorem
EF
KL
KL
where KL
is the Kullback-Leibler divergence between the distributions and and KL
and a coin of bias is the KL divergence between a coin of bias
Theorem PAC-Bayes Relative Entropy Bound For all priors @
A
HA
SR
UT
NIOI @
@
JII
WX
ZA
A
IOI
A
HA
M?NIOI @
LK
QP
Proof Given in
We need to specialize this theorem for application to a stochastic neural network with a
choice of the prior Our prior will be zero on all neural net structures other than the
one we train and a multidimensional isotropic gaussian on the values of the weights in our
neural network The multidimensional gaussian will have a mean of and a variance in
each dimension of This choice is made for convenience and happens to work
The optimal value of is unknown and dependent on the learning problem so we will
wish to parameterize it in an example dependent manner We can do this using the same
trick as for the original neural net bound Use a sequence of bounds where
for
and some constants and a nonnegative number For the th bound set
Now
the union bound will imply that all bounds hold simultaneously with probability at least
Now assuming that our posterior is also defined by a multidimensional gaussian
with the mean and variance in each dimension defined by and we can specialize to
the following corollary
Corollary Stochastic Neural Network bound Let be the number of weights in a
neural net be the th weight and be the variance of the th weight Then we have
A
A
KL 9M5NPO
A
JII
HA
Proof Analytic calculation of the KL divergence between two multidimensional Gaussians and the union bound applied for each value of
We will choose
and as reasonable default values
One more step is necessary in order to apply this bound The essential difficulty is
evaluting A
This quantity is observable although calculating it to high precision is
difficult We will avoid the need for a direct evaluation by a monte carlo evaluation and
A
a bound on the tail of the monte carlo evaluation Let A
be the
observed rate of failure of a random hypotheses drawn according to and applied to a
random training example Then the following simple bound holds
Theorem Sample Convergence Bound For all distributions for all sample sets
A
KL
X[Z
A
IOI
HA
where is the number of evaluations of the stochastic hypothesis
Proof This is simply an application of the Chernoff bound for the tail of a Binomial
where a head occurs when an error is observed and the bias is A
In order to calculate a bound on the expected true error rate we will first bound the expected
empirical error rate ZA
with confidence then bound the expected true error rate A
Since the total probability of failure is only
with confidence using our bound on A
In practice we will use
our bound will hold with probability
evaluations
of the empirical error rate of the stochastic neural network
Distribution Construction algorithm
One critical step is missing in the description How do we calculate the multidimensional
gaussian The variance of the posterior gaussian needs to be dependent on each weight
in order to achieve a tight bound since we want any meaningless weights to not contribute
significantly to the overall sample complexity We use a simple greedy algorithm to find
the appropriate variance in each dimension
Train a neural net on the examples
For every weight search for the variance which reduces the empirical
accuracy
of the stochastic neural network by some fixed target percentage we use
while holding all other weights fixed
error
error
SNN bound
NN bound
SNN Train error
NN Train error
SNN Test error
NN Test error
pattern presentations
pattern presentations
Figure Plot of measured errors and error bounds for the neural network and the
stochastic neural network SNN on the synthetic problem The training set has cases
and the reduction in empirical error is Note that a true error bound of visible
in the graph on the left implies that at least more examples are required in order to
make a nonvacuous bound The graph on the right expands the vertical scale by excluding
the poor true error bound that has error above The curves for NN and SNN are qualitatively similar on the train and test sets As expected the SNN consistently performs
worse than the NN on the train set easier to see in the graph on the right Surprisingly
the SNN performs worse than the NN by less than on the test sets Both NN and SNN
exhibit overfitting after about pattern presentations epochs The
shape of the SNN bound roughly mimics the shape of the empirically measured true error
this is more visible in the graph on the right and thus might be useful for indicating where
the net begins overfitting
The stochastic neural network defined by
will generally have a too-large
empirical error Therefore we calculate a global multiplier such that the
stochastic neural network defined by
decreases the empirical accuracy
by only the same absolute error rate used in Step
Then we evaluate the empirical error rate of the resulting stochastic neural net
by repeatedly drawing samples from the stochastic neural network In the work
reported here we use samples
Experimental Results
How well can we bound the true error rate of a stochastic neural network The answer is
much better than we can bound the true error rate of a neural network
We use two datasets to empirically evaluate the quality of the new bound The first is a
synthetic dataset which has input dimensions and one output dimension Most of these
dimensions are useless?simply random numbers drawn from a
Gaussian One of
the input dimensions is dependent on the label First the label is drawn uniformly
from
then the special dimension is drawn from a
Gaussian Note that this
learning problem can not be solved perfectly because some examples will be drawn from
the tails where the gaussians overlap The ideal neural net to use in solving this synthetic
problem is a single node perceptron We will instead use a layer neural net with hidden
nodes using the sigmoid transfer function This overly complex neural net will result in the
potential for significant overfitting which makes the bound prediction problem interesting
It is also somewhat more realistic if the neural net structure does not exactly match the
learning problem
The second dataset is the ADULT problem from the UCI Machine Learning Repository We use a layer neural net with hidden units for this problem as well because
preliminary experiments showed that nets this small can overfit the ADULT dataset if the
training sample is small
To keep things challenging we use just examples in our experiments As
error
error
SNN bound
NN bound
SNN Train error
NN Train error
SNN Test error
NN Test error
pattern presentations
pattern presentations
Figure Plot of measured errors and error bounds for the neural network and the
stochastic neural network SNN on the UCI ADULT dataset These graphs show the
results obtained using a reduction in empirical error instead of the reduction used
in Figure The training sample size for this problem is cases NN and SNN exhibit
overfitting after approximately pattern presentations epochs As in Figure a
true error bound of implies that at least more examples are required in order to
make a nonvacuous bound The graph on the right expands the vertical scale by excluding
the poor true error bound
we will see in Figures and constructing a nonvacuous bound for a continuous hypothesis space with only examples is quite difficult The conventional bounds are
hopelessly loose
Figure shows the results for the synthetic problem For this problem we use
training cases and a reduction in empirical error The results for the ADULT problem
are presented in Figure For this problem we use training cases and a reduction
in empirical error Experiments performed on these problems using somewhat smaller and
larger training samples yielded similar results The choice of reduction in empirical error
is somewhat arbitrary We see qualitatively similar results if we switch to a reduction
for the synthetic problem and a reduction for the ADULT problem
There are several things worth noting about the results in the two figures
The SNN upper bounds are orders of magnitude lower than the NN upper
bounds While not as tight as might be desired the SNN upper bounds are orders
of magnitude better and are not vacuous
The SNNs perform somewhat better than expected In particular on the synthetic
problem the SNN true error rate is at most worse than the true error rate of
the NN true error rates are estimated using large test sets This is suprising
considering that we fixed the difference in empirical error rates at for the
synthetic problem Similarly on the ADULT problem we observe that the true
error rates between the SNN and NN typically is only about about half of
the target difference of This is good because it suggests that we do not lose
as much accuracy as might be expected when creating the SNN.
On both test problems the shape of the SNN bound is somewhat similar to the
shape of the true error rate In particular the local minima in the SNN bound
occur roughly where the local minima in the true error rates occur The SNN
bound may weakly predict the overfitting points of the SNN and NN nets
The comparison between the neural network bound and the stochastic neural network
bound is not quite fair due to the form of the bound In particular the stochastic neural
network bound can never return a value greater than always err This implies that when
the bound is near the value of it is difficult to judge how rapidly extra examples will
improve the stochastic neural network bound We can judge the sample complexity of
the stochastic bound by plotting the value of the numerator in equation Figure plots
the complexity versus the number of pattern presentations in training In this figure we
Complexity
Complexity
pattern presentations
Figure We plot the complexity of the stochastic network model numerator of equation
training epoch Note that the complexity increases with more training as expected
and stays below
implying nonvacuous bounds on a training set of size
observe the expected result the complexity numerator of equation increases with
more training and is significantly less than the number of examples
The stochastic bound is a radical improvement on the neural network bound but it is not
yet a perfectly tight bound Given that we do not have a perfectly tight bound one important consideration arises does the minimum of the stochastic bound predict the minimum
of the true error rate as predicted by a large holdout dataset In particular can we use
the stochastic bound to determine when we should cease training The stochastic bound
depends upon the complexity which increases with training time and the training error which decreases with training time This dependence results in a minima which occurs
at approximately pattern presentations for both of our test problems The point of
minimal true error for the stochastic and deterministic neural networks occurs at approximately pattern presentations for the synthetic problem and at about pattern
presentations for the ADULT problem indicating that the stochastic bound weakly predicts
the point of minimum error The neural network bound has no such minimum
Is the choice of increased empirical error optimal In general the optimal
choice of the extra error rate depends upon the learning problem Since the stochastic
neural network bound corollary holds for all multidimensional gaussian distributions
we are free to optimize the choice of distribution in anyway we desire Figure shows the
resulting bound for different choices of posterior The bound has a minimum at
extra error indicating that our initial choices of and are in the right ballpark and
may be unnecessarily large Larger differences in empirical error rate such as are
easier to obtain reliably with fewer samples from the stochastic neural net but we have not
had difficulty using as few as samples from the SNN with as small as a increase in
empirical error Also note that the complexity always decreases with increasing entropy in
the distribution of our stochastic neural net The existence of a minimum in Figure is the
right behaviour the increased empirical error rate is significant in the calculation of the
true error bound
Conclusion
We have applied a PAC-Bayes bound for the true error rate of a stochastic
network
neural
The stochastic neural network bound results in a radically tighter
orders of mag
true error bound or complexity
Stochastic NN bound
Complexity
extra training error
Figure Plot of the stochastic neural net SNN bound for posterior distributions chosen
according to the extra empirical error they introduce
nitude bound on the true error rate of a classifier while increasing the empirical and true
error rates only a small amount
Although
stochastic neural net bound is not completely tight it is not vacuous with
theexamples
just
and the minima of the bound weakly predicts the point where
overtraining occurs
The results with two datasets one synthetic and one from UCI are extremely
promising?the bounds are orders of magnitude better Our next step will be to test the
method on more datasets using a greater variety of net architectures to insure that the
bounds remain tight In addition there remain many opportunities for improving the application of the bound For example it is possible that shifting the weights when finding a
maximum acceptable variance will result in a tighter bound Also we have not taken into
account symmetries within the network which would allow for a tighter bound calculation

<<----------------------------------------------------------------------------------------------------------------------->>

title: 503-refining-pid-controllers-using-neural-networks.pdf

Refining PIn Controllers using Neural Networks
Gary M. Scott
Department of Chemical Engineering
Johnson Drive
University of Wisconsin
Madison WI
Jude W. Shavlik
Department of Computer Sciences
W. Dayton Street
University of Wisconsin
Madison WI
W. Harmon Ray
Department of Chemical Engineering
Johnson Drive
University of Wisconsin
Madison WI
Abstract
The KBANN approach uses neural networks to refine knowledge that can
be written in the form of simple propositional rules We extend this idea
further by presenting the MANNCON algorithm by which the mathematical
equations governing a PID controller determine the topology and initial
weights of a network which is further trained using backpropagation We
apply this method to the task of controlling the outflow and temperature
of a water tank producing statistically-significant gains in accuracy over
both a standard neural network approach and a non-learning PID controller Furthermore using the PID knowledge to initialize the weights of
the network produces statistically less variation in testset accuracy when
compared to networks initialized with small random numbers
INTRODUCTION
Research into the design of neural networks for process control has largely ignored
existing knowledge about the task at hand One form this knowledge often called
the domain theory can take is embodied in traditional controller paradigms The
Scott Shavlik and Ray
recently-developed KBANN Knowledge-Based Artificial Neural Networks approach
Towell addresses this issue for tasks for which a domain theory written
using simple propositional rules is available The basis of this approach is to use
the existing knowledge to determine an appropriate network topology and initial
weights such that the network begins its learning process at a good starting
point
This paper describes the MANNCON Multivariable Artificial Neural Network Control algorithm a method of using a traditional controller paradigm to determine
the topology and initial weights of a network The used of a PID controller in this
way eliminates network-design problems such as the choice of network topology
the number of hidden units and reduces the sensitivity of the network to the
initial values of the weights Furthermore the initial configuration of the network
is closer to its final state than it would normally be in a randomly-configured network Thus the MANNCON networks perform better and more consistently than
the standard randomly-initialized three-layer approach
The task we examine here is learning to control a Multiple-Input Multiple-Output
MIMO system There are a number of reasons to investigate this task using neural networks One it usually involves nonlinear input-output relationships which
matches the nonlinear nature of neural networks Two there have been a number
of successful applications of neural networks to this task Bhat McAvoy
Jordan Jacobs Miller Finally there are a number of existing
controller paradigms which can be used to determine the topology and the initial
weights of the network
CONTROLLER NETWORKS
The MANNCON algorithm uses a Proportional-Integral-Derivative PID controller
Stephanopoulos one of the simplest of the traditional feedback controller
schemes as the basis for the construction and initialization of a neural network controller The basic idea of PID control is that the control action vector should
be proportional to the error the integral of the error over time and the temporal
derivative of the error Several tuning parameters determine the contribution of
these various components Figure depicts the resulting network topology based
on the PID controller paradigm The first layer of the network that from Y$P desired process output or setpoint and actual process output of the past time
step calculates the simple error A simple vector difference
e=Y$p-Y
accomplishes this The second layer that between and calculates the
actual error to be passed to the PID mechanism In effect this layer acts as a
steady-state pre-compensator Ray where
GIe
and produces the current error and the error signals at the past two time steps
This compensator is a constant matrix I with values such that interactions at a
steady state between the various control loops are eliminated The final layer that
between and controller output/plant input calculates the controller action
Refining PID Controllers using Neural Networks
Fd
Td
den Water
Tank
Yen
WCO
WHO
WCI
WHI
WC2
WH2
Figure
MANNCON network showing weights that are initialized using
Ziegler-Nichols tuning parameters
based on the velocity form of the discrete PID controller
UC(n
UC(n-l WCOCI(n WCICI(n-l WC2
where Wca wCb and WC2 are constants determined by the tuning parameters of the
controller for that loop A similar set of equations and constants WHO WHI
exist for the other controller loop
Figure shows a schematic of the water tank Ray that the network controls This figure also shows the controller variables Fc and the tank output
variables and and the disturbance variables Fd and Td). The controller
cannot measure the disturbances which represent noise in the system
MANN CON initializes the weights of Figure network with va.lues that mimic
the behavior of a PID controller tuned with Ziegler-Nichols parameters
Stephanopoulos at a particular operating condition Using the KBANN
approach Towell it adds weights to the network such that all units
in a layer are connected to all units in all subsequent layers and initializes these
weights to small random numbers several orders of magnitude smaller than the
weights determined by the PID parameters We scaled the inputs and outputs of
the network to be in the range
Initializing the weights of the network in the manner given above assumes that the
activation functions of the units in the network are linear that is
Scott Shavlik and Ray
Cold Stream
Fe
Hot Stream at TH
Dis urban ce
Fd,Td
I
Temperature
Flow Rate
Output
I I
Figure Stirred mixing tank requiring outflow and temperature control
Table Topology and initialization of networks
Network
Standard neural network
MANNCON network I
MANNCON network
Topology
3-layer hidden units
PID topology
PID topology
Weight Initialization
random
random
Z-N tuning
The strength of neural networks however lie in their having nonlinear typically
sigmoidal activation functions For this reason the MANNCON system initially sets
the weights and the biases of the units so that the linear response dictated by the
PID initialization is approximated by a sigmoid over the output range of the unit
For units that have outputs in the range the activation function becomes
exp
where
Wji
WjiOi
are the linear weights described above
Once MANNCON configures and initializes the weights of the network it uses a set
of training examples and backpropagation to improve the accuracy of the network
The weights initialized with PID information as well as those initialized with small
random numbers change during backpropagation training
EXPERIMENTAL DETAILS
We compared the performance of three networks that differed in their topology
and/or their method of initialization Table summarizes the network topology
and weight initialization method for each network In this table PID topology
is the network structure shown in Figure Random weight initialization sets
Refining PID Controllers using Neural Networks
Table Range and average duration of setpoints for experiments
Experiment
Training Set
22 instances
22 instances
22 instances
Testing Set
22 instances
instances
instances
all weights to small random numbers centered around zero We also compare these
networks to a non-learning PID controller
We trained the networks using backpropagation over a randomly-determined schedule of setpoint YsP and disturbance changes that did not repeat The setpoints
which represent the desired output values that the controller is to maintain are the
temperature and outflow of the tank The disturbances which represent noise are
the inflow rate and temperature of a disturbance stream The magnitudes of the
setpoints and the disturbances formed a Gaussian distribution centered at The
number of training examples between changes in the setpoints and disturbances
were exponentially distributed
We performed three experiments in which the characteristics of the training and/or
testing set differed Table summarizes the range of the setpoints as well as their
average duration for each data set in the experiments As can be seen in Experiment
the training set and testing sets were qualitatively similar in Experiment the
test set was of longer duration setpoints and in Experiment the training set was
restricted to a subrange of the testing set We periodically interrupted training and
tested the network Results are averaged over runs Scott
We used the error at the output of the tank in Figure to determine the network
error at by propagating the error backward through the plant Psaltis
In this method the error signal at the input to the tank is given by
8u
Yi
netui
8y OUi
where 8yj represents the simple error at the output of the water tank and 8ui is the
error signal at the input of the tank Since we used a model of the process and not a
real tank we can calculate the partial derivatives from the process model equations
RESULTS
Figure compares the performance of the three networks for Experiment As can
be seen the MANNCON networks show an increase in correctness over the standard
neural network approach Statistical analysis of the errors using a t-test show
that they differ significantly at the confidence level Furthermore while the
difference in performance between MANNCON network I and MANNCON network is
Scott Shavlik and Ray
Standard neural network
MANNCON network I
MANN CON network
PID controller non-learning
Training Instances
Figure Mean square error of networks on the testset as a function of
the number of training instances presented for Experiment
not significant the difference in the variance of the testing error over different runs
is significant confidence level Finally the MANNCON networks perform
significantly better confidence level than the non-learning PID controller
The performance of the standard neural network represents the best of several trials
with a varying number of hidden units ranging from to
A second observation from Figure is that the MANNCON networks learned much
more quickly than the standard neural-network approach The MANNCON networks
required significantly fewer training instances to reach a performance level within
of its final error rate For each of the experiments Table summarizes the
final mean error as well as the number of training instances required to achieve a
performance within of this value
In Experiments and we again see a significant gain in correctness of the
MAN
NCON networks over both the standard neural network approach confidence
level as well as the non-learning PID controller confidence level In these
experiments the MANNCON network initialized with Z-N tuning also learned significantly quicker confidence level than the standard neural network
FUTURE WORK
One question is whether the introduction of extra hidden units into the network
would improve the performance by giving the network room to learn concepts
that are outside the given domain theory The addition of extra hidden units as
well as the removal of unneeded units is an area with much ongoing research
Refining PID Controllers using Neural Networks
Table Comparison of network performance
I Mean Square Error I Training Instances
Method
Experiment
Standard neural network
MANN CON network I
MANN CON network
PID control tuning
Fixed control action
Experiment
Standard neural network
MANN CON network I
MANN CON network
PID control tuning
Fixed con trol action
Experiment
Standard neural network
MANN CON network I
MANN CON network
PID control tuning
Fixed control action
The indicates that the true value lies within these bounds at a
confidence level The values given for fixed control action represent
the errors resulting from fixing the control actions at a level that produces
outputs of at steady state
Ringing rapid changes in controller actions occurred in some of the trained
networks A future enhancement of this approach would be to create a network
architecture that prevented this ringing perhaps by limiting the changes in the
controller actions to some relatively small values
Another important goal of this approach is the application of it to other real-world
processes The water tank in this project while illustrative of the approach was
quite simple Much more difficult problems such as those containing significant
time delays exist and should be explored
There are several other controller paradigms that could be used as a basis for network construction and initialization There are several different digital controllers
such as Deadbeat or Dahlin's Stephanopoulos that could be used in place
of the digital PID controller used in this project Dynamic Matrix Control DMC
Pratt and Internal Model Control IMC Garcia Morari are
also candidates for consideration for this approach
Finally neural networks are generally considered to be black boxes in that their
inner workings are completely uninterpretable Since the neural networks in this
approach are initialized with information it may be possible to interpret the weights
of the network and extract useful information from the trained network
Scott Shavlik and Ray
CONCLUSIONS
We have described the MANNCON algorithm which uses the information from a
PID controller to determine a relevant network topology without resorting to trialand-error methods In addition the algorithm through initialization of the weights
with prior knowledge gives the backpropagtion algorithm an appropriate direction
in which to continue learning Finally we have shown that using the MANNCON
algorithm significantly improves the performance of the trained network in the following ways
Improved mean testset accuracy
Less variability between runs
Faster rate of learning
Better generalization and extrapolation ability
Acknowledgements
This material based upon work partially supported under a National Science Foundation Graduate Fellowship to Scott Office of Naval Research Grant and National Science Foundation Grants and

<<----------------------------------------------------------------------------------------------------------------------->>

title: 40-neural-networks-for-template-matching-application-to-real-time-classification-of-the-action-potentials-of-real-neurons.pdf

NEURAL NETWORKS FOR TEMPLATE MATCHING
APPLICATION TO REAL-TIME CLASSIFICATION
OF THE ACTION POTENTIALS OF REAL NEURONS
Yiu-fai Wongt Jashojiban Banikt and James M. Bower
tDivision of Engineering and Applied Science
Division of Biology
California Institute of Technology
Pasadena CA
ABSTRACT
Much experimental study of real neural networks relies on the proper classification of
extracellulary sampled neural signals action potentials recorded from the brains of experimental animals In most neurophysiology laboratories this classification task is simplified
by limiting investigations to single electrically well-isolated neurons recorded one at a time
However for those interested in sampling the activities of many single neurons simultaneously
waveform classification becomes a serious concern In this paper we describe and constrast
three approaches to this problem each designed not only to recognize isolated neural events
but also to separately classify temporally overlapping events in real time First we present two
formulations of waveform classification using a neural network template matching approach
These two formulations are then compared to a simple template matching implementation
Analysis with real neural signals reveals that simple template matching is a better solution to
this problem than either neural network approach
INTRODUCTION
For many years neurobiologists have been studying the nervous system by
using single electrodes to serially sample the electrical activity of single neurons in the brain However as physiologists and theorists have become more
aware of the complex nonlinear dynamics of these networks it has become
apparent that serial sampling strategies may not provide all the information
necessary to understand functional organization In addition it will likely be
necessary to develop new techniques which sample the activities of multiple
neurons simultaneouslyl Over the last several years we have developed two
different methods to acquire multineuron data Our initial design involved
the placement of many tiny micro electrodes individually in a tightly packed
pseudo-floating configuration within the brain More recently we have been
developing a more sophisticated approach which utilizes recent advances in
silicon technology to fabricate multi-ported silicon based electrodes
Using these electrodes we expect to be able to readily record the activity patterns of larger number of neurons
As research in multi-single neuron recording techniques continue it has become very clear that whatever technique is used to acquire neural signals from
many brain locations the technical difficulties associated with sampling data
compressing storing analyzing and interpreting these signals largely dwarf the
development of the sampling device itself In this report we specifically consider
the need to assure that neural action potentials also known as spikes on
each of many parallel recording channels are correctly classified which is just
one aspect of the problem of post-processing multi-single neuron data With
more traditional single electrode/single neuron recordings this task usually in American Institute or Physics
volves passing analog signals through a Schmidt trigger whose output indicates
the occurence of an event to a computer at the same time as it triggers an
oscilloscope sweep of the analog data The experimenter visually monitors the
oscilloscope to verify the accuracy of the discrimination as a well-discriminated
signal from a single neuron will overlap on successive oscilloscope traces
Ic). Obviously this approach is impractical when large numbers of channels
are recorded at the same time Instead it is necessary to automate this classification procedure In this paper we will describe and contrast three approaches
we have developed to do this
Traces
on upper
layer
IV
Traces
Ume msec
on lower
layer
C.
Recording s~e
75sq.jllT1
Silicon probe being developed in our lababoratory for multi-single unit recording
in cerebellar cortex a complete probe surface view of one recording tip several
superimposed neuronal action potentials recorded from such a silicon electrode ill cerebellar
cortex
While our principal design objective is the assurance that neural waveforms
are adequately discriminated on multiple channels technically the overall objective of this research project is to sample from as many single neurons as
possible Therefore it is a natural extention of our effort to develop a neural
waveform classification scheme robust enough to allow us to distinguish activities arising from more than one neuron per recording site To do this however
we now not only have to determine that a particular signal is neural in origin
but also from which of several possible neurons it arose While
in general signals from different neurons have different waveforms aiding in
the classification neurons recorded on the same channel firing simultaneously
or nearly simultaneously will produce novel combination waveforms
which also need to be classified It is this last complication which particularly
bedevils previous efforts to classify neural signals For review see also see
In summary then our objective was to design a circuit that would
distinguish different waveforms even though neuronal discharges tend
to be quite similar in shape
recognize the same waveform even though unavoidable movements
such as animal respiration often result in periodic changes in the amplitude
of a recorded signal by moving the brain relative to the tip of the electrode
be considerably robust to recording noise which variably corrupts all
neural recordings
resolve overlapping waveforms which are likely to be particularly interesting events from a neurobiological point of view
provide real-time performance allowing the experimenter to detect
problems with discrimination and monitor the progress of the experiment
be implementable in hardware due to the need to classify neural signals on many channels simultaneously Simply duplicating a software-based
algorithm for each channel will not work but rather multiple small independent and programmable hardware devices need to be constructed
I
Jl.V
signal recorded
electrode
a
Schematic diagram of an electrode recording from two neuronal cell bodies An
actual multi-neuron recording Note the similarities in the two waveforms and the overlapping
event and Synthesized data with different noise levels for testing classificat.ion algorithms
NSR NSR
METHODS
The problem of detecting and classifying multiple neural signals on single voltage records involves two steps First the waveforms that are present
in a particular signal must be identified and the templates be generated
second these waveforms must be detected and classified in ongoing data
records To accomplish the first step we have modified the principal component analysis procedure described by Abeles and Goldstein to automatically extract templates of the distinct waveforms found in an initial sample of the digitized analog data This will not be discussed further as it is
the means of accomplishing the second step which concerns us here Specifically in this paper we compare three new approaches to ongoing waveform classification which deal explicitly with overlapping spikes and variably meet other design criteria outlined above These approaches consist of
a modified template matching scheme and two applied neural network implementations We will first consider the neural network approaches On
a point of nomenclature to avoid confusion in what follows the real neurons whose signals we want to classify will be referred to as neurons while
computing elements in the applied neural networks will be called Hopons
Neural Network Approach Overall the problem of classifying neural
waveforms can best be seen as an optimization problem in the presence of
noise Much recent work on neural-type network algorithms has demonstrated
that these networks work quite well on problems of this sort In particular
in a recent paper Hopfield and Tank describe an A/D converter network and
suggest how to map the problem of template matching into a similar context
The energy functional for the network they propose has the form
I
VI
where Tij connectivity between Hopon and Hopon voltage output
of Hopon Ii input current to Hopon and each Hopon has a sigmoid
input-output characteristic exp
If the equation of motion is set to be
du;fdt
oE/oV
T;jVj
Ii
then we see that dE/dt I:iTijVj Ii)dV/dt du/dt)(dV/dt
Hence will go to to a minimum which in a network
constructed as described below will correspond to a proposed solution to a
particular waveform classification problem
Template Matching using a Hopfield-type Neural Net We have
taken the following approach to template matching using a neural network For
simplicity we initially restricted the classification problem to one involving two
waveforms and have accordingly constructed a neural network made up of two
groups of Hopons each concerned with discriminating one or the other waveform The classification procedure works as follows first a Schmidt trigger
is used to detect the presence of a voltage on the signal channel above a set
threshold When this threshold is crossed implying the presence of a possible
neural signal msecs of data around the crossing are stored in a buffer
samples at KHz Note that biophysical limitations assure that a single real
neuron cannot discharge more than once in this time period so only one waveform of a particular type can occur in this data sample Also action potentials
are of the order of msec in duration so the msec window will include the full
signal for single or overlapped waveforms In the next step explained later
the data values are correlated and passed into a Hopfield network designed to
minimize the mean-square error between the actual data and the linear combination of different delays of the templates Each Hopon in the set of Hopons
concerned with one waveform represents a particular temporal delay in the
occurrence of that waveform in the buffer To express the network in terms of
an energy function formulation Let input waveform amplitude in the
tth time bin Sj(t amplitude of the ph template Vjk denote if Sj(t k)(J?th
template delayed by time bins)is present in the input waveform Then the
appropriate energy function is
The first term is designed to minimize the mean-square error and specifies
the best match Since the second term is minimized only when each
Vjk assumes values or It also sets the diagonal elements Tij to The
third term creates mutual inhibition among the processing nodes evaluating
the same neuronal signal which as described above can only occur once per
sample
Expanding and simplifying expression the connection matrix is
and the input current
As it can be seen the inputs are the correlations between the actual data and
the various delays of the templates subtracting a constant term
Modified Hopfield Network As documented in more detail in
the above full Hopfield-type network works well for temporally isolated
spikes at moderate noise levels but for overlapping spikes it has a local minima
problem This is more severe with more than two waveforms in the network
Further we need to build our network in hardware and the full Hopfield network is difficult to implement with current technology below For these
reasons we developed a modified neural network approach which significantly
reduces the necessary hardware complexity and also has improved performance
To understand how this works let us look at the information contained in the
quantities Tij and Iij 3a and 3b and make some use of them These
quantities have to be calculated at a pre-processing stage before being loaded
into the Hopfield network If after calculating these quantities we can quickly
rule out a large number of possible template combinations then we can significantly reduce the size of the problem and thus use a much smaller and
hence more efficient neural network to find the optimal solution To make the
derivation simple we define slightly modified versions of and Iij 4a
and for two-template case
Iij
si(t
In the case of overlaping spikes the are the cross-correlations between SI
and with different delays and Ii;'s are the cross-correlations between input
and weighted combination of SI(t and Now if SI(t
the overlap of the first template with time bin delay and the
second template with time bin delay then Iijl However
in the presence of noise ij will not be identically zero but will equal to the
noise and if where for and this
simple algorithm may make unacceptable errors A solution to this problem
for overlapping spikes will be described below but now let us consider the
problem of classifying non-overlapping spikes In this case we can compare
the input cross-correlation with the auto-correlations 4c and
Lsi(t Ls~(t
So for non-overlapping cases if SI(t then IT If
then
In the absence of noise then the minimum of ij and represents the
correct classification However in the presence of noise none of these quantities
will be identically zero but will equal the noise in the input which will
give rise to unacceptible errors Our solution to this noise related problem is
to choose a few minima three have chosen in our case instead of one For
each minimum there is either a known corresponding linear combination of
templates for overlapping cases or a simple template for non-overlapping cases
A three neuron Hopfield-type network is then programmed so that each neuron
corresponds to each of the cases The input is fed to this tiny network to
resolve whatever confusion remains after the first step of cross-correlation
comparisons Note Simple template matching as described below can also be
used in the place of the tiny Hopfield type network
Simple Template Matching To evaluate the performances of these
neural network approaches we decided to implement a simple template matching scheme which we will now describe However as documented below this
approach turned out to be the most accurate and require the least complex
hardware of any of the three approaches The first step is again to fill a buffer
with data based on the detection of a possible neural signal Then we calculate
the difference between the recorded waveform and all possible combinations of
the two previously identified templates Formally this consists of calculating
the distances between the input and all possible cases generated by all
the combinations of the two templates
d,j
Ix(t Sl(t
Jonl
Ix(t Sl(t
Ix(t
dmin min(dij,d~,dn
dm,n gives the best fit of all possible combinations of templates to the actual
voltage signal
TESTING PROCEDURES
To compare the performance of each of the three approaches we devised a
common set of test data using the following procedures First we used the principal component method of Abeles and Goldstein to generate two templates
from a digitized analog record of neural activity recorded in the cerebellum
of the rat The two actual spike waveform templates we decided to use had
a peak-to-peak ratio of From a second set of analog recordings made
from a site in the cerebellum in which no action potential events were evident
we determined the spectral characteristics of the recording noise These two
components derived from real neural recordings were then digitally combined
the objective being to construct realistic records while also knowing absolutely
what the correct solution to the template matching problem was for each occurring spike As shown in 2c and data sets corresponding to different
noise to signal ratios were constructed We also carried out simulations with
the amplitudes of the templates themselves varied in the synthesized records to
simulate waveform changes due to brain movements often seen in real recordings In addition to two waveform test sets we also constructed three waveform
sets by generating a third template that was the average of the first two templates To further quantify the comparisons of the three diffferent approaches
described above we considered non-overlapping and overlapping spikes separately To quantify the performance of the three different approaches two
standards for classification were devised In the first and hardest case to be
judged a correct classification the precise order and timing of two waveforms
had to be reconstructed In the second and looser scheme classification was
judged correct if the order of two waveforms was correct but timing was allowed to vary by lOO Jlsecs(i.e time bins which for most neurobiological
applications is probably sufficient resolution Figs compare the performance results for the three approaches to waveform classification implemented
as digital simulations
PERFORMANCE COMPARISON
Two templates non-overlapping waveforms As shown in at
low noise-to-signal ratios NSRs below each of the three approaches were
comparable in performance reaching close to accuracy for each criterion
As the ratio was increased however the neural network implementations did
less and less well with respect to the simple template matching algorithm with
the full Hopfield type network doing considerably worse than the modified
network In the range of NSR most often found in real data simple
template matching performed considerably better than either of the neural
network approaches Also it is to be noted that simple template matching
gives an estimate of the goodness of fit betwwen the waveform and the closest
template which could be used to identify events that should not be classified
signals due to noise
a
noise level 3a/peak amplitude
I
noise level 3a/peak amplitude
I
I
I
I
I
tli
I
degrees of overlap
light line absolute criteria
heavy line less stringent criteria
simple template matching
Hopfield network
modified Hopfield network
Comparisons of the three approaches detecting two non-overlapping and overlapping waveforms compares the performances of the neural network approaches for
different degrees of waveform overlap
Two templates overlapping waveforms 3b and 3c compare performances when waveforms overlapped In 3b the serious local minima problem encountered in the full neural network is demonstrated as is the improved
performance of the modified network Again overall performance in physi
ological ranges of noise is clearly best for simple template matching When
the noise level is low the modified approach is the bet ter of the two neural
networks due to the reliability of the correlation number which reflects the
resemblence between the input data and the template When the noise level
is high errors in the correlation numbers may exclude the right combination
from the smaller network In this case its performance is actually a little worse
than the larger Hopfield network 3c documents in detail which degrees
of overlap produce the most trouble for the neural network approaches at average NSR levels found in real neural data It can be seen that for the neural
networks the most serious problem is encountered when the delays between
the two waveforms are small enough that the resulting waveform looks like the
larger waveform with some perturbation
Three templates overlapping and non-overlapping In are shown
the comparisons between the full Hopfield network approach and the simple
template matching approach For nonoverlapping waveforms the performance
of these two approaches is much more comparable than for the two waveform
case although simple template matching is still the optimal method
In the overlapping waveform condition however the neural network approach
fails badly 4b and For this particular application and implementation the neural network approach does not scale well
a
28
noise level 3a peak amplitude
I
noise level 3a peak amplitude
Hopfield network
simple template matching
light line absolute criteria
heavy line less stringent criteria
a variance of the noise
noise level 3a peak amplitude
Comparisons of performance for three waveforms nonoverlapping waveforms
two waveforms overlapping three waveforms overlapping
HARDWARE COMPARISONS
As described earlier an important design requi~ement for this work was the
ability to letect neural signals in analog records in real-time originating from
many simultaneously active sampling electrodes Because it is not feasible to
run the algorithms in a computer in real time for all the channels simultaneously it is necessary to design and build dedicated hardware for each channel
To do this we have decided to design VLSI implementations of our circuitry
In this regard it is well recognized that large modifiable neural networks need
very elaborate hardware implementations Let us consider for example implementing hard wares for a two-template case for comparisons Let no
of neurons per template one neuron for each delay of the template
no of iterations to reach the stable state simulating the discretized differential equation with step size no of samples in a template
Then the number of connections in the full Hopfield network will be
4n The total no of synaptic calculations 4mn So for two templates
and Thus building the full Hopfield-type
network digitally requires a system too large to be put in a single VLSI chip
which will work in real time If we want to build an analog system we need
to have many 4n easily modifiable synapses As yet this technology is
not available for nets of this size The modified Hopfield-type network on the
other hand is less technically demanding To do the preprocessing to obtain
the minimum values we have to do about additions to find all possible
Iijs and require subtractions and comparisons to find three minima The
costs associated with doing input cross-correlations are the same as for the full
neural network 2nl mUltiplications The saving with the
modified approach is that the network used is small and fast multiplications and additions to construct the modifiable synapses no of synaptic
calculations 90 with
In contrast to the neural networks simple temrlate matching is simple
indeed For example it must perform about additions and
comparisons to find the minimum ij Additions are considerably less
costly in time and hardware than multiplications In fact because this method
needs only addition operations our preliminary design work suggests it can be
built on a single chip and will be able to do the two-template classification
in as little as microseconds This actually raises the possibility that with
switching and buffering one chip might be able to service more than one channel
in essentially real time
CONCLUSIONS
Template matching using a full Hopfield-type neural network is found to
be robust to noise and changes in signal waveform for the two neural waveform
classification problem However for a three-waveform case the network does
not perform well Further the network requires many modifiable connections
and therefore results in an elaborate hardware implementation The overall
performance of the modified neural network approach is better than the full
Iopfield network approach The computation has been reduced largly and
the hardware requirements are considerably less demanding demonstrating the
value of designing a specific network to a specified problem However even the
modified neural network performs less well than a simple template-matching
algorithm which also has the simplest hardware implementation Using the
simple template matching algorithm our simulations suggest it will be possible to build a two or three waveform classifier on a single VLSI chip using
CMOS technology that works in real time with excellent error characteristics
Further such a chip will be able to accurately classify variably overlapping
neural signals

<<----------------------------------------------------------------------------------------------------------------------->>

title: 232-analog-neural-networks-of-limited-precision-i-computing-with-multilinear-threshold-functions.pdf

Obradovic and Pclrberry
Analog Neural Networks of Limited Precision I
Computing with Multilinear Threshold Functions
Preliminary Version
Zoran Obradovic and Ian Parberry
Department of Computer Science
Penn State University
University Park Pa.
ABSTRACT
Experimental evidence has shown analog neural networks to be ex~mely fault-tolerant in particular their performance does not appear to be significantly impaired when precision is limited Analog
neurons with limited precision essentially compute k-ary weighted
multilinear threshold functions which divide into regions with
k-l hyperplanes The behaviour of k-ary neural networks is investigated There is no canonical set of threshold values for
although they exist for binary and ternary neural networks The
weights can be made integers of only log bits where
is the number of processors without increasing hardware or running time The weights can be made while increasing running
time by a constant multiple and hardware by a small polynomial in
and Binary neurons can be used if the running time is allowed to
increase by a larger constant multiple and the hardware is allowed to
increase by a slightly larger polynomial in and Any symmetric
k-ary function can be computed in constant depth and size
and any k-ary function can be computed in constant
depth and size The alternating neural networks of Olafsson
and Abu-Mostafa and the quantized neural networks of Fleisher are
closely related to this model
Analog Neural Networks of Limited Precision I
INTRODUCTION
Neural networks are typically circuits constructed from processing units which compute simple functions of the form f(Wl wlI):RII-+S where SeR wieR for
and
WII)(Xl xlI)=g LWi
for some output function There are two choices for the set which are
currently popular in the literature The first is the discrete model with S=B where
denotes the Boolean set In this case is typically a linear threshold function
iff and is called a weighted linear threshold function The second is
the analog model with where denotes re In this case
is typically a monotone increasing function such as the sigmoid function
for some constant R. The analog neural network model is popular
because it is easy to construct processors with the required characteristics using a few
transistors The digital model is popular because its behaviour is easy to analyze
Experimental evidence indicates that analog neural networks can produce accurate
computations when the precision of their components is limited Consider what actually happens to the analog model when the precision is limited Suppose the neurons
can take on distinct excitation values for example by restricting the number of digits in their binary or decimal expansions Then is isomorphic to
We will show that is essentially the multilinear threshold function
hloh2 defined by
Here and throughout this paper we will assume that and for convenience define ho=-oo and h/c=oo We will call a k-ary weighted multilinear threshold
function when is a multilinear threshold function
We will study neural networks constructed from k-ary multilinear threshold functions
We will call these k-ary neural networks in order to distinguish them from the standard 2-ary or binary neural network We are particularly concerned with the resources
of time size number of processors and weight sum of all the weights of k-ary
neural networks when used in accordance with the classical computational paradigm
The reader is referred to parberry for similar results on binary neural networks
A companion paper Obradovic Parberry deals with learning on k-ary neural networks A more detailed version of this paper appears in Obradovic Parberry
A K-ARY NEURAL NETWORK MODEL
A k-ary neural network is a weighted graph where is a set of processors and cVxV is a set of connections between processors Function
w:VxV assign weights to interconnections and h:V assign a set of k-l
thresholds to each of the processors We assume that if eE The
size of is defined to be the number of processors and the weight of is
Obradovic and Parberry
The processors of a k-ary neural network are relatively limited in computing power
A k-ary function is a function Let denote the set of all n-input k-ary
functions Define by It where
It iff hi
The set of k-ary weighted multilinear threshold functions is the union over all N.
of the range of Each processor of a k-ary neural network can compute a k-ary
weighted multilinear threshold function of its inputs
Each processor can be in one of states through Initially the input processors of are placed into states which encode the input If processor was updated
during interval its state at time was and output was then at time its state
will be A k-ary neural network computes by having the processors change state until a stable configuration is reached The output of are the states of the output processors after a stable state has been reached A neural network is said to be equivalent to iff for all inputs for every computation of on input which
terminates in time there is a computation of on input which terminates in time
with the same output A neural network is said to be equivalent to iff it
is equivalent to it
ANALOG NEURAL NETWORKS
Let be a function with range Any limited-precision device which purports to
compute must actually compute some function with range the rational values
for some keN This is sufficient for all practical purposes
provided is large enough Since is isomorphic to Z". we will formally define
the limited precision variant of to be the function defined by
f,,(x)=round(j where round:R~N is the natural rounding function defined
by round(x)=n iff
Theorem Letf(Wlo where WieR for
be defined by
LWiXi
i=l
where is monotone increasing and invertible Then f(Wlo
is a k-ary weighted multilinear threshold function
Proof It is easy to verify that f(Wlo where
hi
Thus we see that analog neural networks with limited precision are essentially k-ary
neural networks
Analog Neural Networks of Limited Precision I
CANONICAL THRESHOLDS
Binary neural networks have the advantage that all thresholds can be taken equal to
zero see for example Theorem of Parberry A similar result holds for
ternary neural networks
Theorem For every n-input ternary weighted multilinear threshold function there
is an equivalent I)-input ternary weighted multilinear threshold function with
threshold values equal to zero and one
Proof Suppose WII hloh2E R. Without loss of generality assume
l<h
Define W=(Wl RII+I by wj=wjl(hrh for and
wlI It can be demonstrated by a simple case analysis that for all
xll)e
Z;.
l,hz)(x xll
The choice of threshold values in Theorem was arbitrary Unfortunately there is
no canonical set of thresholds for
Theorem For every 1o hk 1E R. there exists an n-input k-ary
weighted multilinear threshold function
such that for all input k-ary weighted multilinear threshold functions
WII+m hk-l
A
Proof Sketch Suppose that I tk-l is a canonical set of thresholds and
assume Let 1o hk where l=h hi for 4Si and
By hypothesis there exist wlo and y=(ylo such that for all xeZi
Let I:Wi+2Yi Since it follows that
2(Wl+Wz+S
Since and it follows that
Obradovic and Pdrberry
Inequalities and imply that
By similar arguments from we can conclude that
But contradicts
NETWORKS OF BOUNDED WEIGHT
Although our model allows each weight to take on an infinite number of possible
values there are only a finite number of threshold functions since there are only a
finite number of k-ary functions with a fixed number of inputs Thus the number of
input threshold functions is bounded above by some function in and In fact
something stronger can be shown All weights can be made integral and
log bits are sufficient to describe each one
Theorem For every k-ary neural network of size there exists an equivalent
k-ary neural network M2 of size and weight with integer
weights
Proof Sketch It is sufficient to prove that for every weighted threshold function
f:(Wlt for some neN there is an equivalent we1f.hted threshold function w:.hi such that for
By extending the techniques used by Muroga Toda and Takasu in the
binary case we see that the weights are bounded above by the maximum determinant
of a matrix of dimension lover Z".
Thus if is bounded above by a polynomial in we are guaranteed of being able to
describe the weights using a polynomial number of bits
THRESHOLD CIRCUITS
A k-ary neural network with weights drawn from is said to have unit weights A
unit-weight directed acyclic k-ary neural network is called a k-ary threshold circuit
A k-ary threshold circuit can be divided into layers with each layer receiving inputs
only from the layers above it The depth of a k-ary threshold circuit is defined to be
the number of layers The weight is equal to the number of edges which is bounded
above by the square of the size Despite the apparent handicap of limited weights kary threshold circuits are surprisingly powerful
Much interest has focussed on the computation of symmetric functions by neural networks motivated by the fact that the visual system appears to be able to recognize objects regardless of their position on the retina A function is called symmetric if its output remains the same no matter how the input is permuted
Analog Neural Networks of Limited Precision I
Theorem Any symmetric k-ary function on inputs can be computed by a k-ary
threshold circuit of depth and size
Proof Omitted
It has been noted many times that neural networks can compute any Boolean function
in constant depth The same is true of k-ary neural networks although both results
appear to require exponential size for many interesting functions
Theorem Any k-ary function of inputs can be computed by a k-ary threshold
circuit with size and depth
Proof Similar to that for Chandra Parberry
The interesting problem remaining is to determine which functions require exponential
size to achieve constant depth and which can be computed in polynomial size and
constant depth We will now consider the problem of adding integers represented in
k-ary notation
Theorem The sum of two k-ary integers of size can be computed by a k-ary
threshold circuit with size and depth
Proof First compute the carry of and in luadratic size and depth using the standard elementary school algorithm Then the it position of the result can be computed
from the tit position of the operands and a carry propagated in that position in constant size and depth
Theorem The sum of integers of size can be computed by a k-ary
threshold circuit with size and constant depth
Proof Similar to the proof for using Theorem Chandra Parberry
Theorem For every k-ary neural network of size there exists an t)equivalent unit-weight k-ary neural network M2 of size
Proof By Theorem we can bound all weights to have size in
binary notation By Theorem we can replace every processor with non-unit
weights by a threshold circuit of size and constant depth
Theorem implies that we can assume unit weights by increasing the size by a polynomial and the running time by only a constant multiple provided the number of
logic levels is bounded above by a polynomial in the size of the network The
number of thresholds can also be reduced to one if the size is increased by a larger
polynomial
Theorem For every k-ary neural network of size there exists an equivalent unit-weight binary neural network of size 4k log
which outputs the binary encoding of the required result
Proof Similar to the proof of Theorem
This result is primarily of theoretical interest Binary neural networks appear simpler
and hence more desirable than analog neural networks However analog neural networks are actually more desirable since they are easier to build With this in mind
Theorem simply serves as a limit to the functions that an analog neural network
Obradovic and Parberry
can be expected to compute efficiently We are more concerned with constructing a
model of the computational abilities of neural networks rather than a model of their
implementation details
NONMONOTONE MULTILINEAR NEURAL NETWORKS
Olafsson and Abu-Mostafa study
f(Wlt for w;ER where
information
capacity
of functions
xlI)=g
and is the alternating threshold function for some monotone
increasing h;ER defined by if for some We
will call an alternating weighted multilinear threshold function and a neural network constructed from functions of this form alternating multilinear neural networks
Alternating multilinear neural networks are closely related to k-ary neural networks
Theorem For every k-ary neural network of size and weight there is an
equivalent alternating multilinear neural network of size log and weight
log which produces the output of the former in binary notation
Proof Sketch Each k-ary gate is replaced by log gates which together essentially
perform a binary search to determine each bit of the k-ary gate Weights which increase exponentially are used to provide the correct output value
Theorem For every alternating multilinear neural network of size and weight
there is a 3t-equivalent k-ary neural network of size 4z and weight
Proof Sketch Without loss of generality assume is odd Each alternating gate is
replaced by a k-ary gate with identical weights and thresholds The output of this gate
goes with weight one to a k-ary gate with thresholds and with weight
minus one to a k-ary gate with thresholds The output of these gates
goes to a binary gate with threshold
Both k-ary and alternating multilinear neural networks are a special case of nonmonotone multilinear neural networks where is the defined by iff
hi~<h;+lt for some monotone increasing h;ER and co Ck-1EZk Nonmonotone neural networks correspond to analog neural networks whose output function is not necessarily monotone nondecreasing Many of the result of this paper including Theorems and also apply to nonmonotone neural networks The
size weight and running time of many of the upper-bounds can also be improved by a
small amount by using nonmonotone neural networks instead of k-ary ones The details are left to the interested reader
MUL TILINEAR HOPFIELD NETWORKS
A multilinear version of the Hopfield network called the quantized neural network has
been studied by Fleisher Using the terminology of parberry a quantized neural network is a simple symmetric k-ary neural network that is its interconnection pattern is an undirected graph without self-loops with the additional property
that all processors have an identical set of thresholds Although the latter assumption
Analog Neural Networks of Limited Precision I
is reasonable for binary neural networks see for example Theorem of Parberry
and ternary neural networks Theorem it is not necessarily so for k-ary
neural networks with Theorem However it is easy to extend Fleisher's
main result to give the following
Theorem Any productive sequential computation of a simple symmetric k-ary
neural network will converge
CONCLUSION
It has been shown that analog neural networks with limited precision are essentially
k-ary neural networks If is limited to a polynomial then polynomial size constant
depth k-ary neural networks are equivalent to polynomial size constant depth binary
neural networks Nonetheless the savings in time at most a constant multiple and
hardware at most a polynomial arising from using k-ary neural networks rather than
binary ones can be quite significant We do not suggest that one should actually construct binary or k-ary neural networks Analog neural networks can be constructed by
exploiting the analog behaviour of transistors rather than using extra hardware to inhibit it Rather we suggest that k-ary neural networks are a tool for reasoning about the
behaviour of analog neural networks
Acknowledgements
The financial support of the Air Force Office of Scientific Research Air Force ysterns Command DSAF under grant numbers AFOSR and AFOSR
and NSF grant to Ian Parberry is gratefully acknowledged

<<----------------------------------------------------------------------------------------------------------------------->>

title: 822-bounds-on-the-complexity-of-recurrent-neural-network-implementations-of-finite-state-machines.pdf

Bounds on the complexity of recurrent
neural network implementations of finite
state machines
Bill G. Horne
NEC Research Institute
Independence Way
Princeton NJ
Don R. Hush
EECE Department
University of New Mexico
Albuquerque NM
Abstract
In this paper the efficiency of recurrent neural network implementations of m-state finite state machines will be explored Specifically
it will be shown that the node complexity for the unrestricted case
can be bounded above by fo It will also be shown that the
node complexity is log when the weights and thresholds
are restricted to the set and when the fan-in is restricted to two Matching lower bounds will be provided for each
of these upper bounds assuming that the state of the FSM can be
encoded in a subset of the nodes of size rlog
Introduction
The topic of this paper is understanding how efficiently neural networks scale to
large problems Although there are many ways to measure efficiency we shall be
concerned with node complexity which as its name implies is a calculation of the
required number of nodes Node complexity is a useful measure of efficiency since
the amount of resources required to implement or even simulate a recurrent neural
network is typically related to the number of nodes Node complexity can also
be related to the efficiency of learning algorithms for these networks and perhaps
to their generalization ability as well We shall focus on the node complexity of
recurrent neural network implementations of finite state machines FSMs when
the nodes of the network are restricted to threshold logic units
Home and Hush
In the it was shown that recurrent neural networks are capable of implementing arbitrary FSMs The first result in this area was due to Minsky who
showed that m-state FSMs can be implemented in a fully connected recurrent neural network Although circuit complexity was not the focus of his investigation it
turns out that his construction yields nodes This construction was also
guaranteed to use weight values limited to the set Since a recurrent neural
network with hard-limiting nodes is capable of representing as many as 2k states
one might wonder if an m-state FSM could be implemented by a network with
log nodes However it was shown in that the node complexity for a standard
fully connected network is
log They were also able to improve upon
Minsky's result by providing a construction which is guaranteed to yield no more
than nodes In the same paper lower bounds on node complexity were investigated as the network was subject to restrictions on the possible range of weight
values and the fan-in and fan-out of the nodes in the network Their investigation
was limited to fully connected recurrent neural networks and they discovered that
the node complexity for the case where the weights are restricted to a finite size set
is log Alternatively if the nodes in the network were restricted to have a
constant fan-in then the node complexity becomes However they left open
the question of how tight these bounds are and if they apply to variations on the
basic architecture Other recent work includes investigation of the node complexity
for networks with continuous valued nonlinearities However it can also be
shown that when continuous nonlinearities are used recurrent neural networks are
far more powerful than FSMs in fact they are Turing equivalent
In this paper we improve the upper bound on the node complexity for the unrestricted case to We also provide upper bounds that match the lower
bounds above for various restrictions Specifically we show that a node complexity
of y'm log can be achieved if the weights are restricted to the set I and
that the node complexity is for the case when the fan-in of each node in the
network is restricted to two Finally we explore the possibility that implementing
finite state machines in more complex models might yield a lower node complexity
Specifically we explore the node complexity of a general recurrent neural network
topology that is capable of simulating a variety of popular recurrent neural network architectures Except for the unrestricted case we will show that the node
complexity is no different for this architecture than for the fully connected case if
the number of feedback variables is limited to rlog if the state of the FSM
is encoded optimally in a subset of the nodes We leave it as an open question if a
sparser encoding can lead to a more efficient implementation
Background
Finite State Machines
FSMs may be defined in several ways In this paper we shall be concerned with
Mealy machines although our approach can easily be extended to other formulations
to yield equivalent results
Bounds on the Complexity of Recurrent Neural Network Implementations
Definition A Mealy machine is a quintuple qo where is a
finite set of states qo is the initial state is the input alphabet is the output
alphabet and is the combined transition and output function
Throughout this paper both the input and output alphabets will be binary
In general the number of states
IQI may be arbitrary Since any
element of can be encoded as a binary vector whose minimum length is pog
the function can be implemented as a boolean logic function of the form
pogm1+l
pogm1+l
The number of different minimal FSMs with states will be used to determine
lower bounds on the number of gates required to implement an arbitrary FSM in a
recurrent neural network It can easily be shown that NM However
it will be convenient to reexpress in terms of flog as follows
Recurrent Neural Networks
The fundamental processing unit in the models we wish to consider is the perceptron
which is a biased linearly weighted sum of its inputs followed by a hard-limiting
nonlinearity whose output is zero if its input is negative and one otherwise The
fan-in of the perceptron is defined to be the number of non-zero weights When the
values of are binary as they are in this paper the perceptron is often referred
to as a threshold logic unit TL U).
A count of the number of different partially specified threshold logic functions which
are threshold logic functions whose values are only defined over vertices of the
unit hypercube will be needed to develop lower bounds on the node complexity
required to implement an arbitrary logic function It has been shown that this
number denoted is
2v
As pointed out in many of the most popular discrete-time recurrent neural
network models can be implemented as a feedforward network whose outputs are
fed back recurrently through a set of unit time delays In the most generic version of
this architecture the feed forward section is lower triangular meaning the th node is
the only node in layer I and receives input from all nodes in previous layers including
the input layer A lower triangular network of threshold logic elements is the
most general topology possible for a feedforward network since all other feedforward
networks can be viewed as a special case of this network with the appropriate weights
set equal to zero The most direct implementation of this model is the architecture
proposed in However many recurrent neural network architectures can be cast
into this framework For example fully connected networks fit this model when
the the feedforward network is simply a single layer of nodes Even models which
appear very different can be cast into this framework
Home and Hush
The unrestricted case
The unrestricted case is the most general and thus explores the inherent power of
recurrent neural networks The unrestricted case is also important because it serves
as a baseline from which one can evaluate the effect of various restrictions on the
node complexity
In order to derive an upper bound on the node complexity of recurrent neural
network implementations of FSMs we shall utilize the following lemma due to
Lupanov The proof of this lemma involves a construction that is extremely
complex and beyond the scope of this paper
Lemma Lupanov Arbitrary boolean logic functions with inputs and
outputs can be implemented in a network of perceptrons with a node complexity
of
Theorem Multilayer recurrent neural networks can implement FSMs having
states with a node complexity of Jffi
Proof Since an m-state FSM can be implemented in a recurrent neural network
in which the multilayer network performs a mapping of the form in equation
then using flog and applying Lemma gives an upper bound of
O(.Jffi
Theorem Multilayer recurrent neural networks can implement FSMs having
states with a node complexity of if the number of unit time delays is flog
Proof In order to prove the theorem we derive an expression for the maximum
number of functions that a k-node recurrent neural network can compute and compare that against the minimum number of finite state machines Then we solve for
in terms of the number of states of the FSM.
Specifically we wish to manipulate the inequality
krr-l
where the left hand side is given in equation represents the total number of
ways to choose the outputs and feedback variables of the network and represents the total number of logic functions computable by the feed forward section of
the network which is lower triangular Part is found by simple combinatorial
arguments and noting that the last node in the network must be used as either
an output or feedback node Part is obtained by the following argument If
the state is optimally encoded in flog m1 nodes then only flog m1 variables need
Bounds on the Complexity of Recurrent Neural Network Implementations
to be fed back Together with the external input this gives rlog m1 local
inputs to the feedforward network Repeated application of with 2n yields
expression
Following a series of algebraic manipulations it can easily be shown that there exists
a constant such that
n2n ck
Since flog ml
it follows that f2
Restriction on weights and thresholds
All threshold logic functions can be implemented with perceptrons whose weight
and threshold values are integers It is well known that there are threshold logic
functions of variables that require a perceptron with weights whose maximum
magnitude is and This implies that if a perceptron is to be
implemented digitally the number of bits required to represent each weight and
threshold in the worst case will be a super linear function of the fan-in This is
generally undesirable it would be far better to require only a logarithmic number
of bits per weight or even better a constant number of bits per weight We will be
primarily be interested in the most extreme case where the weights are limited to
values from the set I}.
In order to derive the node complexity for networks with weight restrictions we
shall utilize the following lemma proved in
Lemma Arbitrary boolean logic functions with inputs and outputs can be
implemented in a network ofperceptrons whose weights and thresholds are restricted
to the set I with a node complexity of
This lemma is not difficult to prove however it is beyond the scope of this paper
The basic idea involves using a decomposition of logic functions proposed in
Specifically a boolean function may always be decomposed into a disjunction of
terms of the form XIX2 Xr fi(X one for each conjunction of the
first variables where Xj represents either a complemented or uncomplemented
version of the input variable Xj and each Ii is a logic function of the last
variables This expression can be implemented directly in a neural network With
negligible number of additional nodes the construction can be implemented in such
a way that all weights are either lor Finally the variable is optimized to
yield the minimum number of nodes in the network
Theorem Multilayer recurrent neural networks that have nodes whose weights
and thresholds are restricted to the set I can implement FSMs having
states with a node complexity of Jm log
Proof Since an m-state FSM can be implemented in a recurrent neural network
in which the multilayer network performs a mapping of the form in equation
then using flog and applying Lemma gives an upper bound of
Jmlogm
Home and Hush
Theorem Multilayer recurrent neural networks that have nodes whose weights
and thresholds are restricted to a set of size IWI can implement FSMs having
states with a node complexity of
if the number of unit time delays is
flogml
Proof The proof is similar to the proof of Theorem which gave a lower bound
for the node complexity required in an arbitrary network of threshold logic units
Here the inequality we wish to manipulate is given by
k-l
n-I
IWln+i
i=O
where the left hand side and are computed as before and represents the
maximum number of ways to configure the nodes in the network when there are
only IWI choices for each weight and threshold Following a series of algebraic
manipulations it can be shown that there exists a constant such that
n2n ck log IWI.
Since
pog it follows that
Clearly for
mlogm
loglWI
I this lower bound matches the upper bound in Theorem
Restriction on fan-in
A limit on the fan-in of a perceptron is another important practical restriction
In the networks discussed so far each node has an unlimited fan-in In fact in
the constructions described above many nodes receive inputs from a polynomial
number of nodes terms of in a previous layer In practice it is not possible
to build devices that have such a large connectivity Restricting the fan-in to is
the most severe restriction and will be of primary interest in this paper
Once again in order to derive the node complexity for restricted fan-in we shall
utilize the following lemma proved in
Lemma Arbitrary boolean logic functions with inputs and outputs can be
implemented in a network of perceptrons restricted to fan-in with a node complexityof
y2X
logy
This proof of this lemma is very similar to the proof of Lemma Here Shannon's
decomposition is used with to recursively decompose the logic function into
a set of trees until each tree has depth Then all possible functions of the last
variables are implemented in an inverted tree-like structure which feeds into
the bottom of the trees Finally is optimized to yield the minimum number of
nodes
Bounds on the Complexity of Recurrent Neural Network Implementations
Theorem Multilayer recurrent neural networks that have nodes whose fan-in is
restricted to two can implement FSMs having states with a node complexity of
Oem
Proof Since an m-state FSM can be implemented in a recurrent neural network
in which the multilayer network performs a mapping of the form in equation
then using rlog and applying Lemma gives an upper bound of
Theorem Multilayer recurrent neural networks that have nodes whose fan-in is
restricted to two can implement FSMs having states with a node complexity of
if the number of unit time delays is rlog
Proof Once again the proof is similar to Theorem which gave a lower bound
for the node complexity required in an arbitrary network of threshold logic units
Here the inequality we need to solve for is given by
D.
where the left hand side and are computed as before and represents the maximum number of ways to configure the nodes in the network The term
is used since a node in the ith layer has possible inputs from which two are
chosen The constant represents the fourteen possible threshold logic functions
of two variables Following a series of algebraic manipulations it can be shown that
there exists a constant such that
ck logk
Since rlog m1 it follows that
n2n
Summary
In summary we provide new bounds on the node complexity of implementing FSMs
with recurrent neural networks These upper bounds match lower bounds developed in for fully connected recurrent networks when the size of the weight set
or the fan-in of each node is finite Although one might speculate that more complex networks might yield more efficient constructions we showed that these lower
bounds do not change for restrictions on weights or fan-in at least when the state
of the FSM is encoded optimally in a subset of flog m1 nodes When the network
is unrestricted this lower bound matches our upper bound We leave it as an open
question if a sparser encoding of the state variables can lead to a more efficient
implementation
One interesting aspect of this study is that there is really not much difference
in efficiency when the network is totally unrestricted and when there are severe
restrictions placed on the weights Assuming that our bounds are tight then there
Home and Hush
is only a y'log penalty for restricting the weights to either or To get some
idea for how marginal this difference is consider that for a finite state machine with
18 18 states y'log is only eight
A more detailed version of this paper can be found in

<<----------------------------------------------------------------------------------------------------------------------->>

title: 70-on-the-power-of-neural-networks-for-solving-hard-problems.pdf

On the Power of Neural Networks for
Solving Hard Problems
ehoshua Bruck
Joseph W. Goodman
Information Systems Laboratory
Departmen of Electrical Engineering
Stanford University
Stanford CA
Abstract
This paper deals with a neural network model in which each neuron
performs a threshold logic function An important property of the model
is that it always converges to a stable state when operating in a serial
mode This property is the basis of the potential applications of the
model such as associative memory devices and combinatorial optimization
One of the motivations for use of the model for solving hard combinatorial
problems is the fact that it can be implemented by optical devices and
thus operate at a higher speed than conventional electronics
The main theme in this work is to investigate the power of the model for
solving NP-hard problems and to understand the relation between
speed of operation and the size of a neural network In particular it will
be shown that for any NP-hard problem the existence of a polynomial
size network that solves it implies that NP=co-NP Also for Traveling
Salesman Problem even a polynomial size network that gets an
approximate solution does not exist unless P=NP
The above results are of great practical interest because right now it is
possible to build neural networks which will operate fast but are limited
in the number of neurons
Background
The neural network model is a discrete time system that can be represented by
a weighted and undirected graph There is a weight attached to each edge of
the graph and a threshold value attached to each node neuron of the graph
American Institute of Physics
The order of the network is the number of nodes in the corresponding graph
Let be a neural network of order then is uniquely defined by
where
is an symmetric matrix Wii is equal to the weight attached to
edge
is a vector of dimension Ti denotes the threshold attached to node
Every node neuron can be in one of two possible states either or The
state of node at time is denoted by The state of the neural network at
time is the vector
The next state of a node is computed by
Vi(t
where
Hi(t
WiiVj(t Ti
i=l
The next state of the network V(t is computed from the current
state by performing the evaluation at a subset of the nodes of the network
to be denoted by S. The modes of operation are determined by the method
by which the set is selected in each time interval If the computation is
performed at a single node in any time interval 1S then we will say
that the network is operating in a serial mode if 1S then we will say that
that the network is operating in a fully parallel mode All the other cases
I will be called parallel modes of operation The set can be chosen
at random or according to some deterministic rule
A state is called stable iff sgn(WV(t there is no
change in the state of the network no matter what the mode of operation is
One of the most important properties of the model is the fact that it always
converges to a stable state while operating in a serial mode The main idea in
the proof of the convergence property is to define a so called energy function
and to show that this energy function is nondecreasing when the state of the
network changes The energy function is
An important note is that originally the energy function was defined such that
it is nonincreasing we changed it such that it will comply with some known
graph problems Min Cut
A neural network will always get to a stable state which corresponds to a
local maximum in the energy function This suggests the use of the network as a
device for performing a local search algorithm for finding a maximal value of the
energy function Thus the network will perform a local search by operating
in a random and serial mode It is also known that maximization of
associated with a given network in which is equivalent to finding
the Minimum Cut in N. Actually many hard problems can be formulated as
maximization of a quadratic form TSP and thus can be mapped to a
neural network
The Main Results
The set of stable states is the set of possible final solutions that one will get
using the above approach These final solutions correspond to local maxima of
the energy function but do not necessarily correspond to global optima of the
corresponding problem The main question is suppose we allow the network to
operate for a very long time until it converges can we do better than just getting
some local optimum is it possible to design a network which will always
find the exact solution some guaranteed approximation of the problem
Definition Let be an instance of problem Then denotes the size of
that is the number of bits required to represent For example for
being an instance of TSP I is the number of bits needed to represent the
matrix of the distances between cities
Definition Let be a neural network Then denotes the size of the
network N. Namely the number of bits needed to represent Wand T.
Let us start by defining the desired setup for using the neural network as a
model for solving hard problems
Consider an optimization problem we would like to have for every instance
of a neural network with the following properties
Every local maximum of the energy function associated with corresponds to a global optimum of
The network is small that is
in 1X I.
I
Nx
is bounded by some polynomial
Moreover we would like to have an algorithm to be denoted by A which given
an instance generates the description for in polynomial I I
time
Now we will define the desired setup for using the neural network as a model
for finding approximate solutions for hard problems
Definition Let
Eglo
be the global maximum of the energy function Let
Eloc
be a local maximum of the energy function We will say that a local maximum
is an f-approximate of the global iff
Eglo Eloc
Eglo
The setup for finding approximate solutions is similar to the one for finding
exact solutions For fo being some fixed number We would like to have a
network in which every local maximum is an f-approximate of the global
and that the global corresponds to an optimum of The network should
be small namely should be bounded by a polynomial in I. Also
we would like to have an algorithm such that given an instance it
generates the description for in polynomial I time
Note that in both the exact case and the approximate case we do not put any
restriction on the time it takes the network to converge to a solution it can be
exponential
A this point the reader should convince himself that the above description is
what he imagined as the setup for using the neural network model for solving
hard problems because that is what the following definition is about
Definition We will say that a neural network for solving finding an fapproximation of a problem exists if the algorithm AL ALJ which generates the description of exists
The main results in the paper are summarized by the following two propositions The first one deals with exact solutions of NP-hard problems while the
second deals with approximate solutions to TSP.
Proposition Let be an NP-hard problem Then the existence of a neural
network for solving implies that NP co-NP
Proposition Let be some fixed number The existence of a neural
network for finding an f-approximate solution to TSP implies that P=NP
Both and NP=co-NP are believed to be false statements hence
we can not use the model in the way we imagine
The key observation for proving the above propositions is the fact that a
single iteration in a neural network takes time which is bounded by a polynomial
in the size of the instance of the corresponding problem The proofs of the above
two propositions follow directly from known results in complexity theory and
should not be considered as new results in complexity theory
The Proofs
Proof of Proposition The proof follows from the definition of the classes
NP and co-NP and Lemma The definitions and the lemma appear in Chapters and in and also in Chapters and in
Lemma If the complement of an NP-complete problem is in NP
then NP=co-NP
Let be an NP-hard problem Suppose there exists a neural network that solves
L. Let be an NP-complete problem By definition can be polynomialy
reduced to L. Thus for every instance we have a neural network such
that from any of its global maxima we can efficiently recognize whether is a
yes or a instance of
We claim that we have a nondeterministic polynomial time algorithm to decide
that a given instance is a instance Here is how we do it for
we construct the neural network that solves it by using the reduction to L. We
then check every state of the network to see if it is a local maximum that is
done in polynomial time In case it is a local maximum we check if the instance
is a yes or a instance this is also done in polynomial time
Thus we have a nondeterministic polynomial time algorithm to recognize any
instance of Thus the complement of the problem is in NP. But is
an NP-complete problem hence from Lemma it follows that NP=co-NP
Proof of Proposition The result is a corollary of the results in the
reader can refer to it for a more complete presentation
The proof uses the fact that the Restricted Hamiltonian Circuit RHC is an
NP-complete problem
Definiton of RHC Given a graph and a Hamiltonian path in G.
The question is whether there is a Hamiltonian circuit in
It is proven in that RHC is NP-complete
Suppose there exists a polynomial size neural network for finding an
f-approximate solution to TSP. Then it can be shown that an instance
RHC can be reduced to an instance TSP such that in the network
the following holds if the Hamiltonian path that is given in corresponds to a
local maximum in then is a instance else if it does not correspond
to a local maximum in then is a yes instance Note that we can check
for locality in polynomial time
Hence the existence of xe for all TSP implies that we have a polynomial
time algorithm for RHC.
Concluding Remarks
In Proposition we let I I and I I be arbitrary but bounded by a
polynomial in the size of a given instance of a problem If we assume
that I I and I I are fixed for all instances then a similar result to
Proposition can be proved without using complexity theory this result
appears in
The network which corresponds to TSP as suggested in can not solve
the TSP with guaranteed quality However one should note that all the
analysis in this paper is a worst case type of analysis So it might be that
there exist networks that have good behavior on the average
Proposition is general to all NP-hard problems while Proposition is
specific to TSP. Both propositions hold for any type of networks in which
an iteration takes polynomial time
Clearly every network has an algorithm which is equivalent to it but an
algorithm does not necessarily have a corresponding network Thus if we
do not know of an algorithmic solution to a problem we also will not be able
to find a network which solves the problem If one believes that the neural
network model is a good model it is amenable to implementation with
optics one should develop techniques to program the network to perform
an algorithm that is known to have some guaranteed good behavior
Acknowledgement Support of the U.S. Air Force Office of Scientific Research
is gratefully acknowledged

<<----------------------------------------------------------------------------------------------------------------------->>

