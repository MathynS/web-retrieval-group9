query sentence: duplicated documents detection
---------------------------------------------------------------------
title: 2639-a-probabilistic-model-for-online-document-clustering-with-application-to-novelty-detection.pdf

A Probabilistic Model for Online Document
Clustering with Application to Novelty Detection

Jian Zhang?
?School of Computer Science
Cargenie Mellon University
Pittsburgh, PA 15213
jian.zhang@cs.cmu.edu

Zoubin Ghahramani??
? Gatsby Computational Neuroscience Unit
University College London
London WC1N 3AR, UK
zoubin@gatsby.ucl.ac.uk

Yiming Yang?
?School of Computer Science
Cargenie Mellon University
Pittsburgh, PA 15213
yiming@cs.cmu.edu

Abstract
In this paper we propose a probabilistic model for online document clustering. We use non-parametric Dirichlet process prior to model the growing number of clusters, and use a prior of general English language
model as the base distribution to handle the generation of novel clusters.
Furthermore, cluster uncertainty is modeled with a Bayesian Dirichletmultinomial distribution. We use empirical Bayes method to estimate
hyperparameters based on a historical dataset. Our probabilistic model
is applied to the novelty detection task in Topic Detection and Tracking
(TDT) and compared with existing approaches in the literature.

1

Introduction

The task of online document clustering is to group documents into clusters as long as
they arrive in a temporal sequence. Generally speaking, it is difficult for several reasons:
First, it is unsupervised learning and the learning has to be done in an online fashion,
which imposes constraints on both strategy and efficiency. Second, similar to other learning
problems in text, we have to deal with a high-dimensional space with tens of thousands of
features. And finally, the number of clusters can be as large as thousands in newswire data.
The objective of novelty detection is to identify the novel objects from a sequence of data,
where ?novel? is usually defined as dissimilar to previous seen instances. Here we are interested in novelty detection in the text domain, where we want to identify the earliest report
of every new event in a sequence of news stories. Applying online document clustering
to the novelty detection task is straightforward by assigning the first seed of every cluster
as novel and all its remaining ones as non-novel. The most obvious application of novelty
detection is that, by detecting novel events, systems can automatically alert people when
new events happen, for example.

In this paper we apply Dirichlet process prior to model the growing number of clusters, and
propose to use a General English language model as a basis of newly generated clusters.
In particular, the new clusters will be generated according to the prior and a background
General English model, and each document cluster is modeled using a Bayesian Dirichletmultinomial language model. The Bayesian inference can be easily carried out due to
conjugacy, and model hyperparameters are estimated using a historical dataset by the empirical Bayes method. We evaluate our online clustering algorithm (as well as its variants)
on the novelty detection task in TDT, which has been regarded as the hardest task in that
literature [2].
The rest of this paper is organized as follows. We first introduce our probabilistic model
in Section 2, and in Section 3 we give detailed information on how to estimate model
hyperparameters. We describe the experiments in Section 4, and related work in Section 5.
We conclude and discuss future work in Section 6.

2

A Probabilistic Model for Online Document Clustering

In this section we will describe the generative probabilistic model for online document
(x)
(x)
(x)
clustering. We use x = (n1 , n2 , . . . , nV ) to represent a document vector where each
(x)
element nv denotes the term frequency of the v th corresponding word in the document
x, and V is the total size of the vocabulary.
2.1

Dirichlet-Multinomial Model

The multinomial distribution has been one of the most frequently used language models for
modeling documents in information retrieval. It assumes that given the set of parameters
? = (?1 , ?2 , . . . , ?V ), a document x is generated with the following probability:
PV
V
(x)
nv )! Y n(x)
(
p(x|?) = QVv=1 (x)
?v v .
v=1 nv ! v=1
From the formula we can see the so-called naive assumption: words are assumed to be independent of each other. Given a collection of documents generated from the same model,
the parameter ? can be estimated with Maximum Likelihood Estimation (MLE).
In a Bayesian approach we would like to put a Dirichlet prior over the parameter (? ?
Dir(?)) such that the probability
R of generating a document is obtained by integrating over
the parameter space: p(x) = p(?|?)p(x|?)d?. This integration can be easily written
down due to the conjugacy between Dirichlet and multinomial distributions. The key difference between the Bayesian approach and the MLE is that the former uses a distribution
to model the uncertainty of the parameter ?, while the latter gives only a point estimation.
2.2

Online Document Clustering with Dirichlet Process Mixture Model

In our system documents are grouped into clusters in an online fashion. Each cluster is
modeled with a multinomial distribution whose parameter ? follows a Dirichlet prior. First,
a cluster is chosen based on a Dirichlet process prior (can be either a new or existing
cluster), and then a document is drawn from that cluster.
We use Dirichlet Process (DP) to model the prior distribution of ??s, and our hierarchical
model is as follows:
xi |ci ? M ul(.|? (ci ) )
?i
G

iid.

?
?

G
DP (?, G0 )

(1)

where ci is the cluster indicator variable, ? i is the multinomial parameter 1 for each document, and ? (ci ) is the unique ? for the cluster ci . G is a random distribution generated from
the Dirichlet process DP (?, G0 ) [4], which has a precision parameter ? and a base distribution G0 . Here our base distribution G0 is a Dirichlet distribution Dir(??1 , ??2 , . . . , ??V )
PV
with t=1 ?t = 1, which reflects our expected knowledge about G. Intuitively, our G0
distribution can be treated as the prior over general English word frequencies, which has
been used in information retrieval literature [6] to model general English documents.
The exact cluster-document generation process can be described as follows:
1. Let xi be the current document under processing (the ith document in the input
sequence), and C1 , C2 , . . . , Cm are already generated clusters.
2. Draw a cluster ci based on the following Dirichlet process prior [4]:
|C |
Pmj
p(ci = Cj ) =
(j = 1, 2, . . . , m)
? + j=1 |Cj |
p(ci = Cm+1 )

=

?+

?
Pm

j=1

(2)

|Cj |

Pm
where |Cj | stands for the cardinality of cluster j with j=1 |Cj | = i ? 1, and
with certain probability a new cluster Cm+1 will be generated.
3. Draw the document xi from the cluster ci .
2.3

Model Updating

Our models for each cluster need to be updated based on incoming documents. We can
write down the probability that the current document xi is generated by any cluster as
Z
p(xi |Cj ) = p(?(Cj ) |Cj )p(xi |?(Cj ) )d?(Cj ) (j = 1, 2, . . . , m, m + 1)
where p(? (Cj ) |Cj ) is the posterior distribution of parameters of the j th cluster (j =
1, 2, . . . , m) and we use p(? (Cm+1 ) |Cm+1 ) = p(? (Cm+1 ) ) to represent the prior distribution of the parameters of the new cluster for convenience. Although the dimensionality of
? is high (V ? 105 in our case), closed-form solution can be obtained under our Dirichletmultinomial assumption. Once the conditional probabilities p(xi |Cj ) are computed, the
probabilities p(Cj |xi ) can be easily calculated using the Bayes rule:
p(Cj )p(xi |Cj )
p(Cj |xi ) = Pm+1
0
0
j 0 =1 p(Cj )p(xi |Cj )

where the prior probability of each cluster is calculated using equation (2).
Now there are several choices we can consider on how to update the cluster models. The
first choice, which is correct but obviously intractable, is to fork m + 1 children of the
current system where the j th child is updated with document xi assigned to cluster j, while
the final system is a probabilistic combination of those children with the corresponding
probabilities p(Cj |xi ). The second choice is to make a hard decision by assigning the
current document xi to the cluster with the maximum probability:
p(Cj )p(xi |Cj )
ci = arg max p(Cj |xi ) = Pm+1
.
Cj
0
0
j 0 =1 p(Cj )p(xi |Cj )

For ? we use ?v to denote the v th element in the vector, ? i to denote the parameter vector that
generates the ith document, and ? (j) to denote the parameter vector for the j th cluster.
1

The third choice is to use a soft probabilistic updating, which is similar in spirit to the
Assumed Density Filtering (ADF) [7] in the literature. That is, each cluster is updated by
exponentiating the likelihood function with probabilities:

p(Cj |xi )
p(?(Cj ) |xi , Cj ) ?
p(xi |?(Cj ) )
p(?(Cj ) |Cj )
However, we have to specially deal with the new cluster since we cannot afford both timewise and space-wise to generate a new cluster for each incoming document. Instead, we
will update all existing clusters as above, and new cluster will be generated only if c i =
Cm+1 . We will use HD and PD (hard decision and probabilistic decision) to denote the
last two candidates in our experiments.

3

Learning Model Parameters

In the above probabilistic model there are still several hyperparameters not specified,
namely the ? and ? in the base distribution G0 = Dir(??1 , ??2 , . . . , ??V ), and the precision parameter ? in the DP (?, G0 ). Since we can obtain a partially labeled historical
dataset 2 , we now discuss how to estimate those parameters respectively.
We will mainly use the empirical Bayes method [5] to estimate those parameters instead
of taking a full Bayesian approach, since it is easier to compute and generally reliable
when the number of data points is relatively large compared to the number of parameters.
Because the ? i ?s are iid. from the random distribution G, by integrating out the G we get
X
?
1
?i |?1 , ?2 , . . . , ? i?1 ?
G0 +
? j
?+i?1
? + i ? 1 j<i ?
where the distribution is a mixture of continuous and discrete distributions, and the ? ?
denotes the probability measure giving point mass to ?.
Now suppose we have a historical dataset H which contains K labeled clusters H j (j =
1, 2, . . . , K), with the k th cluster Hk = {xk,1 , xk,2 , . . . , xk,mk } having mk documents.
The joint probability of ??s of all documents can be obtained as
p(?1 , ?2 , . . . , ? |H| ) =

|H|
Y

(

i=1

X
?
1
G0 +
? j)
?+i?1
? + i ? 1 j<i ?

where |H| is the total number of documents. By integrating over the unknown parameter
??s we can get
?
?
Z Y
|H|
? p(xi |?i )? p(?1 , ?2 , . . . , ? |H| )d?1 d?2 . . . d? |H|
p(H) =
i=1

=

?
Z
|H|
Y
? p(xi |?i )(

i=1

1
?
G0 +
?+i?1
?+i?1

X
j<i

?

??j )d?i ?

(3)

Empirical Bayes method can be applied to equation (3) to estimate the model parameters
by maximization3 . In the following we discuss how to estimate parameters individually in
detail.
2
Although documents are grouped into clusters in the historical dataset, we cannot make directly
use of those labels due to the fact that clusters in the test dataset are different from those in the
historical dataset.
3
Since only a subset of documents are labeled in the historical dataset H, the maximization is
only taken over the union of the labeled clusters.

Estimating ?t ?s

3.1

Our hyperparameter ? vector contains V number of parameters for the base distribution G 0 ,
which can be treated as the expected distribution of G ? the prior of the cluster parameter
??s.
Although ? contains V ? 105 number of actual parameters in our case, we can still use
the empirical Bayes to do a reliable point estimation since the amount of data we have to
represent general English is large (in our historical dataset there are around 10 6 documents,
around 1.8 ? 108 English words in total) and highly informative about ?. We use the
P
(H)
(H)
(H)
(H)
(x)
smoothed estimation ? ? (1 + n1 , 1 + n2 , . . . , 1 + nV ) where nt = x?H nt
PV
is the total number of times that term t happened in the collection H, and t=1 ?t should
be normalized to 1. Furthermore, the pseudo-count one is added to alleviate the out-ofvocabulary problem.
Estimating ?

3.2

Though ? is just a scalar parameter, it has the effect to control the uncertainty of the prior
knowledge about how clusters are related to the general English model with the parameter
?. We can see that ? controls how far each new cluster can deviate from the general English
model 4 . It can be estimated as follows:
K
K Z
Y
Y
?? = arg max
p(Hk |?) = arg max
p(Hk |?(k) )p(?(k) |?)d? (k)
(4)
?

?

k=1

k=1

?? can be numerically computed by solving the following equation:
K?(?) ? K

V
X

?(??v )?v +

v=1

K X
V
X

k)
?(??v + n(H
)?v ?
v

k=1 v=1

where the digamma function ?(x) is defined as ?(x) ?

K
X

?(? +

k=1
d
dx

V
X

k)
n(H
)=0
v

v=1

ln ?(x).

Alternatively we can choose ? by evaluating over the historical dataset. This is applicable
(though computationally expensive) since it is only a scalar parameter and we can precompute its possible range based on equation (4).
Estimating ?

3.3

The precision parameter ? of the DP is also very important for the model, which controls
how far the random distribution G can deviate from the baseline model G0 . In our case, it is
also the prior belief about how quickly new clusters will be generated in the sequence. Similarly we can use equation (3) to estimate ?, since items related to ? can be factored out as
Q|H| ?yi
L
i=1 ?+i?1 . Suppose we have a labeled subset H = {(x1 , y1 ), (x2 , y2 ), . . . , (xM , yM )}
of training data, where yi is 1 if xi is a novel document or 0 otherwise. Here we describe
two possible choices:
1. The simplest way is to assume that ? is a fixed constant during the process, and it
?y t
L
? = arg max? Q
can be computed as ?
i?H L ?+i?1 , here H denotes the subset of
indices of labeled documents in the whole sequence.
2. The assumption that ? is fixed maybe restrictive in reality, especially considering
the fact that it reflects the generation rate of new clusters. More generally, we
4

The mean and variance of a Dirichlet distribution (?1 , ?2 , . . . , ?V ) ? Dir(??1 , ??2 , . . . , ??V )
(1??v )
are: E[?v ] = ?v and Var[?v ] = ?v(?+1)
.

can assume that ? is some function of variable i. In particular, we assume ? =
a/i + b + ci where a, b and c are non-negative numbers. This formulation is a
generalization of the above case, where the i?1 term allows a much faster decrease
at the beginning, and c is the asymptotic rate of events happening as i ? ?.
Again the parameters a, b and c are estimated by MLE over the training dataset:
yi
Q
a
?, ?b, c? = arg maxa,b,c>0 i?H L (a/i+b+ci)
a/i+b+ci+i .

4

Experiments

We apply the above online clustering model to the novelty detection task in Topic Detection
and Tracking (TDT). TDT has been a research community since its 1997 pilot study, which
is a research initiative that aims at techniques to automatically process news documents in
terms of events. There are several tasks defined in TDT, and among them Novelty Detection
(a.k.a. First Story Detection or New Event Detection) has been regarded as the hardest task
in this area [2]. The objective of the novelty detection task is to detect the earliest report
for each event as soon as that report arrives in the temporal sequence of news stories.
4.1

Dataset

We use the TDT2 corpus as our historical dataset for estimating parameters, and use the
TDT3 corpus to evaluate our model 5 . Notice that we have a subset of documents in the
historical dataset (TDT2) for which events labels are given. The TDT2 corpus used for
novelty detection task consists of 62,962 documents, among them 8,401 documents are
labeled in 96 clusters. Stopwords are removed and words are stemmed, and after that there
are on average 180 words per document. The total number of features (unique words) is
around 100,000.
4.2

Evaluation Measure

In our experiments we use the standard TDT evaluation measure [1] to evaluate our results.
The performance is characterized in terms of the probability of two types of errors: miss
and false alarm (PM iss and PF A ). These two error probabilities are then combined into a
single detection cost, Cdet , by assigning costs to miss and false alarm errors:
Cdet = CM iss ? PM iss ? Ptarget + CF A ? PF A ? Pnon?target
where
1. CM iss and CF A are the costs of a miss and a false alarm, respectively,
2. PM iss and PF A are the conditional probabilities of a miss and a false alarm, respectively, and
3. Ptarget and Pnon?target is the priori target probabilities (Ptarget = 1 ?
Pnon?target ).
It is the following normalized cost that is actually used in evaluating various TDT systems:
(Cdet )norm =

Cdet
min(CM iss ? Ptarget , CF A ? Pnon?target )

where the denominator is the minimum of two trivial systems. Besides, two types of evaluations are used in TDT, namely macro-averaged (topic-weighted) and micro-averaged
5
Strictly speaking we only used the subsets of TDT2 and TDT3 that is designated for the novelty
detection task.

(story-weighted) evaluations. In macro-averaged evaluation, the cost is computed for every
event, and then the average is taken. In micro-averaged evaluation the cost is averaged over
all documents? decisions generated by the system, thus large event will have bigger impact
on the overall performance. Note that macro-averaged evaluation is used as the primary
evaluation measure in TDT. In addition to the binary decision ?novel? or ?non-novel?, each
system is required to generated a confidence score for each test document. The higher the
score is, the more likely the document is novel. Here we mainly use the minimum cost to
evaluate systems by varying the threshold, which is independent of the threshold setting.
4.3

Methods

One simple but effective method is the ?GAC-INCR? clustering method [9] with cosine
similarity metric and TFIDF term weighting, which has remained to be the top performing
system in TDT 2002 & 2003 official evaluations. For this method the novelty confidence
score we used is one minus the similarity score between the current cluster xi and its nearest
neighbor cluster: s(xi ) = 1.0 ? maxj<i sim(ci , cj ), where ci and cj are the clusters that
xi and xj are assigned to, respectively, and the similarity is taken to be the cosine similarity
between two cluster vectors, where the ltc TFIDF term weighting scheme is used to scale
each dimension of the vector. Our second method is to train a logistic regression model
which combines multiple features generated by the GAC-INCR method. Those features
not only include the similarity score used by the first method, but also include the size of
its nearest cluster, the time difference between the current cluster and the nearest cluster,
etc. We call this method ?Logistic Regression?, where we use the posterior probability
p(novelty|xi ) as the confidence score. Finally, for our online clustering algorithm we
choose the quantity s(xi ) = log p(C0 |xi ) as the output confidence score.
4.4

Experimental Results

Our results for three methods are listed in Table 1, where both macro-averaged and microaveraged minimum normalized costs are reported 6 . The GAC-INCR method performs
very well, so does the logistic regression method. For our DP results, we observed that
using the optimized ?? will get results (not listed in the table) that are around 10% worse
than using the ? obtained through validation, which might be due to the flatness of the
optimal function value as well as the sample bias of the clusters in the historical dataset 7 .
Another observation is that the probabilistic decision does not actually improve the hard
decision performance, especially for the ?var option. Generally speaking, our DP methods
are comparable to the other two methods, especially in terms of topic-weighted measure.
Table 1: Results for novelty detection on TDT3 corpus
Method
GAC-INCR
Logistic Regression
DP with ?f ix , HD
DP with ?var , HD
DP with ?f ix , PD
DP with ?var , PD

Topic-weighted Cost
COST (Miss, FA)
0.6945 (0.5614, 0.0272)
0.7027 (0.5732, 0.0264)
0.7054 (0.4737, 0.0473)
0.6901 (0.5789, 0.0227)
0.7054 (0.4737, 0.0473)
0.9025 (0.8772, 0.0052)

Story-weighted Cost
COST (Miss, FA)
0.7090 (0.5614, 0.0301)
0.6911 (0.5732, 0.0241)
0.7744 (0.5965, 0.0363)
0.7541 (0.5789, 0.0358)
0.7744 (0.5965, 0.0363)
0.9034 (0.8772, 0.0053)

6
In TDT official evaluation there is also the DET curve, which is similar in spirit to the ROC curve
that can reflects how the performance changes as the threshold varies. We will report those results in
a longer version of this paper.
7
It is known that the cluster labeling process of LDC is biased toward topics that will be covered
in multiple languages instead of one single language.

5

Related Work

Zaragoza et al. [11] applied a Bayesian Dirichlet-multinomial model to the ad hoc information retrieval task and showed that it is comparable to other smoothed language models.
Blei et al. [3] used Chinese Restaurant Processes to model topic hierachies for a collection of documents. West et al. [8] discussed the sampling techniques for base distribution
parameters in the Dirichlet process mixture model.

6

Conclusions and Future Work

In this paper we used a hierarchical probabilistic model for online document clustering.
We modeled the generation of new clusters with a Dirichlet process mixture model, where
the base distribution can be treated as the prior of general English model and the precision
parameter is closely related to the generation rate of new clusters. Model parameters are
estimated with empirical Bayes and validation over the historical dataset. Our model is
evaluated on the TDT novelty detection task, and results show that our method is promising.
In future work we would like to investigate other ways of estimating parameters and use
sampling methods to revisit previous cluster assignments. We would also like to apply our
model to the retrospective detection task in TDT where systems do not need to make decisions online. Though its simplicity, the unigram multinomial model has its well-known
limitation, which is the naive assumption about word independence. We also plan to explore richer but still tractable language models in this framework. Meanwhile, we would
like to combine this model with the topic-conditioned framework [10] as well as incorporate hierarchical mixture model so that novelty detection will be conditioned on some topic,
which will be modeled by either supervised or semi-supervised learning techniques.
References
[1] The 2002 topic detection & tracking task definition
http://www.nist.gov/speech/tests/tdt/tdt2002/evalplan.htm, 2002.

and

evaluation

plan.

[2] Allan, J., Lavrenko, V. & Jin, H. First story detection in tdt is hard. In Proc. of CIKM 2000.
[3] Blei, D., Griffiths, T., Jordan, M. & Tenenbaum, J. Hierarchical topic models and the nested
chinese restaurant process. Advances in Neural Information Processing Systems, 15, 2003.
[4] Ferguson, T. A Bayesian analysis of some nonparametric problems. Annals of Statistics, 1:209?
230, 1973.
[5] Gelman A., Carlin, J., Stern, H. & Rubin, D. Bayesian Data Analysis (2nd ed.). CHAPMAN &
HALL/CRC, 2003.
[6] Miller, D., Leek, T. & Schwartz, R. Bbn at trec 7: Using hidden markov models for information
retrieval. In TREC-7, 1999.
[7] Minka, T. A family of algorithms for approximate Bayesian inference. Ph.D. thesis, MIT, 2001.
[8] West, M., Mueller, P. & Escobar, M.D. Hierarchical priors and mixture models, with application
in regression and density estimation. In Aspects of Uncertainty: A tribute to D. V. Lindley, A.F.M.
Smith and P. Freeman, (eds.), Wiley, New York.
[9] Yang, Y., Pierce, T. & Carbonell, J. A Study on Retrospective and On-line Event Detection. In
Proc. of SIGIR 1998.
[10] Yang, Y., Zhang, J., Carnobell, J. & Jin, C. Topic-conditioned novelty detection. In Proc. of 8th
ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2002.
[11] Zaragoza, H., Hiemstra, D., Tipping, D. & Robertson, S. Bayesian extension to the language
model for ad hoc information retrieval. In Proc. SIGIR 2003.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4571-online-l1-dictionary-learning-with-application-to-novel-document-detection.pdf

Online `1-Dictionary Learning with Application to
Novel Document Detection
Huahua Wang?
University of Minnesota
huwang@cs.umn.edu

Shiva Prasad Kasiviswanathan?
General Electric Global Research
kasivisw@gmail.com
Arindam Banerjee?
University of Minnesota
banerjee@cs.umn.edu

Prem Melville
IBM T.J. Watson Research Center
pmelvil@us.ibm.com

Abstract
Given their pervasive use, social media, such as Twitter, have become a leading
source of breaking news. A key task in the automated identification of such news
is the detection of novel documents from a voluminous stream of text documents
in a scalable manner. Motivated by this challenge, we introduce the problem of
online `1 -dictionary learning where unlike traditional dictionary learning, which
uses squared loss, the `1 -penalty is used for measuring the reconstruction error.
We present an efficient online algorithm for this problem based on alternating
directions method of multipliers, and establish a sublinear regret bound for this
algorithm. Empirical results on news-stream and Twitter data, shows that this
online `1 -dictionary learning algorithm for novel document detection gives more
than an order of magnitude speedup over the previously known batch algorithm,
without any significant loss in quality of results.

1

Introduction

The high volume and velocity of social media, such as blogs and Twitter, have propelled them to
the forefront as sources of breaking news. On Twitter, it is possible to find the latest updates on
diverse topics, from natural disasters to celebrity deaths; and identifying such emerging topics has
many practical applications, such as in marketing, disease control, and national security [14]. The
key challenge in automatic detection of breaking news, is being able to detect novel documents in
a stream of text; where a document is considered novel if it is ?unlike? documents seen in the past.
Recently, this has been made possible by dictionary learning, which has emerged as a powerful data
representation framework. In dictionary learning each data point y is represented as a sparse linear
combination Ax of dictionary atoms, where A is the dictionary and x is a sparse vector [1, 12]. A
dictionary learning approach can be easily converted into a novel document detection method: let A
be a dictionary representing all documents till time t ? 1, for a new data document y arriving at time
t, if one does not find a sparse combination x of the dictionary atoms, and the best reconstruction
Ax yields a large loss, then y clearly is not well represented by the dictionary A, and is hence novel
compared to documents in the past. At the end of timestep t, the dictionary is updated to represent
all the documents till time t.
Kasiviswanathan et al. [10] presented such a (batch) dictionary learning approach for detecting novel
documents/topics. They used an `1 -penalty on the reconstruction error (instead of squared loss com?

Part of this wok was done while the author was a postdoc at the IBM T.J. Watson Research Center.
H. Wang and A. Banerjee was supported in part by NSF CAREER grant IIS-0953274, NSF grants IIS0916750, 1029711, IIS-0812183, and NASA grant NNX12AQ39A.
?

1

monly used in the dictionary learning literature) as the `1 -penalty has been found to be more effective
for text analysis (see Section 3). They also showed this approach outperforms other techniques, such
as a nearest-neighbor approach popular in the related area of First Story Detection [16]. We build
upon this work, by proposing an efficient algorithm for online dictionary learning with `1 -penalty.
Our online dictionary learning algorithm is based on the online alternating directions method which
was recently proposed by Wang and Banerjee [19] to solve online composite optimization problems
with additional linear equality constraints. Traditional online convex optimization methods such
as [25, 8, 5, 6, 22] require explicit computation of the subgradient making them computationally
expensive to be applied in our high volume text setting, whereas in our algorithm the subgradients
are computed implicitly. The algorithm has simple closed form updates for all steps yielding a fast
and scalable algorithm for updating the dictionary. Under suitable assumptions
(to cope with the
?
non-convexity of the dictionary learning problem), we establish an O( T ) regret bound for the objective, matching the regret bounds of existing methods [25, 5, 6, 22]. Using this online algorithm
for `1 -dictionary learning, we obtain an online algorithm for novel document detection, which we
empirically validate on traditional news-streams as well as streaming data from Twitter. Experimental results show a substantial speedup over the batch `1 -dictionary learning based approach of
Kasiviswanathan et al. [10], without a loss of performance in detecting novel documents.
Related Work. Online convex optimization is an area of active research and for a detailed survey
on the literature we refer the reader to [18]. Online dictionary learning was recently introduced
by Mairal et al. [12] who showed that it provides a scalable approach for handling large dynamic
datasets. They considered an `2 -penalty and showed that their online algorithm converges to the
minimum objective value in the stochastic case (i.e., with distributional assumptions on the data).
However, the ideas proposed in [12] do not translate to the `1 -penalty. The problem of novel document/topics detection was also addressed by a recent work of Saha et al. [17], where they proposed a
non-negative matrix factorization based approach for capturing evolving and novel topics. However,
their algorithm operates over a sliding time window (does not have online regret guarantees) and
works only for `2 -penalty.

2

Preliminaries

Notation. Vectors P
are always column vectors
P and2are denoted by boldface letters. For a matrix Z
its norm, kZk1 = i,j |zij | and kZk2F = ij zij
. For arbitrary real matrices the standard inner
product is defined as hY, Zi = Tr(Y > Z). We use ?max (Z) to denote the largest eigenvalue of
Z > Z. For a scalar r ? R, let sign(r) = 1 if r > 0, ?1 if r < 0, and 0 if r = 0. Define
soft(r, T ) = sign(r) ? max{|r| ? T, 0}. The operators sign and soft are extended to a matrix by
applying it to every entry in the matrix. 0m?n denotes a matrix of all zeros of size m ? n and the
subscript is omitted when the dimension of the represented matrix is clear from the context.
Dictionary Learning Background. Dictionary learning is the problem of estimating a collection
of basis vectors over which a given data collection can be accurately reconstructed, often with sparse
encodings. It falls into a general category of techniques known as matrix factorization. Classic dictionary learning techniques for sparse representation (see [1, 15, 12] and references therein) consider
a finite training set of signalsPP = [p1 , . . . , pn ] ? Rm?n and optimize the empirical cost function
n
which is defined as f (A) = i=1 l(pi , A), where l(?, ?) is a loss function such that l(pi , A) should
be small if A is ?good? at representing the signal pi in a sparse fashion. Here, A ? Rm?k is referred
to as the dictionary. In this paper, we use a `1 -loss function with an `1 -regularization term, and our
l(pi , A) = min kpi ? Axk1 + ?kxk1 , where ? is the regularization parameter.
x

We define the problem of dictionary learning as that of minimizing the empirical cost f (A). In other
words, the dictionary learning is the following optimization problem
n
X
def
min f (A) = f (A, X) = min
l(pi , A) = min kP ? AXk1 + ?kXk1 .
A

A,X

A,X

i=1

For maintaining interpretability of the results, we would additionally require that the A and X matrices be non-negative. To prevent A from being arbitrarily large (which would lead to arbitrarily
small values of X), we add a scaling constant on A as follows. Let A be the convex set of matrices
defined as
A = {A ? Rm?k : A ? 0m?k ?j = 1, . . . , k , kAj k1 ? 1}, where Aj is the jth column in A.
2

We use ?A to denote the Euclidean projection onto the nearest point in the convex set A. The
resulting optimization problem can be written as
min

A?A,X?0

kP ? AXk1 + ?kXk1

(1)

The optimization problem (1) is in general non-convex. But if one of the variables, either A or X is
known, the objective function with respect to the other variable becomes a convex function (in fact,
can be transformed into a linear program).

3

Novel Document Detection Using Dictionary Learning

In this section, we describe the problem of novel document detection and explain how dictionary
learning could be used to tackle this problem. Our problem setup is similar to [10].
Novel Document Detection Task. We assume documents arrive in streams. Let {Pt : Pt ?
Rmt ?nt , t = 1, 2, 3, . . . } denote a sequence of streaming matrices where each column of Pt represents a document arriving at time t. Here, Pt represents the term-document matrix observed at time
t. Each document is represented is some conventional vector space model such as TF-IDF [13].
The t could be at any granularity, e.g., it could be the day that the document arrives. We use nt to
represent the number of documents arriving at time t. We normalize Pt such that each column (document) in Pt has a unit `1 -norm. For simplicity in exposition, we will assume that mt = m for all
t.1 We use the notation P[t] to denote the term-document matrix obtained by vertically concatenating
the matrices P1 , . . . , Pt , i.e., P[t] = [P1 |P2 | . . . |Pt ]. Let Nt be the number of documents arriving at
time ? t, then P[t] ? Rm?Nt . Under this setup, the goal of novel document detection is to identify
documents in Pt that are ?dissimilar? to the documents in P[t?1] .
Sparse Coding to Detect Novel Documents. Let At ? Rm?k represent the dictionary matrix after
time t ? 1; where dictionary At is a good basis to represent of all the documents in P[t?1] . The exact
construction of the dictionary is described later. Now, consider a document y ? Rm appearing at
time t. We say that it admits a sparse representation over At , if y could be ?well? approximated as
a linear combination of few columns from At . Modeling a vector with such a sparse decomposition
is known as sparse coding. In most practical situations it may not be possible to represent y as At x,
e.g., if y has new words which are absent in At . In such cases, one could represent y = At x + e
where e is an unknown noise vector. We consider the following sparse coding formulation
l(y, At ) = min ky ? At xk1 + ?kxk1 .
x?0

(2)

The formulation (2) naturally takes into account both the reconstruction error (with the ky ? At xk1
term) and the complexity of the sparse decomposition (with the kxk1 term). It is quite easy to
transform (2) into a linear program. Hence, it can be solved using a variety of methods. In our
experiments, we use the alternating directions method of multipliers (ADMM) [2] to solve (2).
ADMM has recently gathered significant attention in the machine learning community due to its
wide applicability to a range of learning problems with complex objective functions [2].
We can use sparse coding to detect novel documents as follows. For each document y arriving at
time t, we do the following. First, we solve (2) to check whether y could be well approximated as a
sparse linear combination of the atoms of At . If the objective value l(y, At ) is ?big? then we mark
the document as novel, otherwise we mark the document as non-novel. Since, we have normalized
all documents in Pt to unit `1 -length, the objective values are in the same scale.
Choice of the Error Function. A very common choice of reconstruction error is the `2 -penalty. In
fact, in the presence of isotopic Gaussian noise the `2 -penalty on e = y ? At x gives the maximum
likelihood estimate of x [21, 23]. However, for text documents, the noise vector e rarely satisfies the
Gaussian assumption, as some of its coefficients contain large, impulsive values. For example, in
fields such as politics and sports, a certain term may become suddenly dominant in a discussion [10].
In such cases imposing an `1 -penalty on the error is a better choice than imposing an `2 -penalty
(e.g., recent research [21, 24, 20] have successfully shown the superiority of `1 over `2 penalty for a
1
As new documents come in and new terms are identified, we expand the vocabulary and zero-pad the
previous matrices so that at the current time t, all previous and current documents have a representation over
the same vocabulary space.

3

different but related application domain of face recognition). We empirically validate the superiority
of using the `1 -penalty for novel document detection in Section 5.
Size of the Dictionary. Ideally, in our application setting, changing the size of the dictionary (k)
dynamically with t would lead to a more efficient and effective sparse coding. However, in our
theoretical analysis, we make the simplifying assumption that k is a constant independent of t. In
our experiments, we allow for small increases in the size of the dictionary over time when required.
Batch Algorithm for Novel Document Detection. We now describe a simple batch algorithm
(slightly modified from [10]) for detecting novel documents. The Algorithm BATCH alternates between a novel document detection and a batch dictionary learning step.
Algorithm 1 : BATCH
Input: P[t?1] ? Rm?Nt?1 , Pt = [p1 , . . . , pnt ] ? Rm?nt , At ? Rm?k , ? ? 0, ? ? 0
Novel Document Detection Step:
for j = 1 to nt do
Solve: xj = argminx?0 kpj ? At xk1 + ?kxk1
if kpj ? At xj k1 + ?kxj k1 > ?
Mark pj as novel
Batch Dictionary Learning Step:
Set P[t] ? [P[t?1] | p1 , . . . , pnt ]
Solve: [At+1 , X[t] ] = argminA?A,X?0 kP[t] ? AXk1 + ?kXk1
Batch Dictionary Learning. We now describe the batch dictionary learning step. At time t, the
dictionary learning step is2
[At+1 , X[t] ] = argminA?A,X?0 kP[t] ? AXk1 + ?kXk1 .

(3)

Even though conceptually simple, Algorithm BATCH is computationally inefficient. The bottleneck
comes in the dictionary learning step. As t increases, so does the size of P[t] , so solving (3) becomes
prohibitive even with efficient optimization techniques. To achieve computational efficiency, in [10],
the authors solved an approximation of (3) where in the dictionary learning step they only update
the A?s and not the X?s.3 This leads to faster running times, but because of the approximation, the
quality of the dictionary degrades over time and the performance of the algorithm decreases. In this
paper, we propose an online learning algorithm for (3) and show that this online algorithm is both
computationally efficient and generates good quality dictionaries under reasonable assumptions.

Online `1 -Dictionary Learning

4

In this section, we introduce the online `1 -dictionary learning problem and propose an efficient algorithm for it. The standard goal of online learning is to design algorithms whose regret is sublinear
in time T , since this implies that ?on the average? the algorithm performs as well as the best fixed
strategy in hindsight [18]. Now consider the `1 -dictionary learning problem defined in (3). Since
this problem is non-convex, it may not be possible to design efficient (i.e., polynomial running time)
algorithms that solves it without making any assumptions on either the dictionary (A) or the sparse
code (X). This also means that it may not be possible to design efficient online algorithm with
sublinear regret without making any assumptions on either A or X because an efficient online algorithm with sublinear regret would imply an efficient algorithm for solving (1) in the offline case.
Therefore, we focus on obtaining regret bounds for the dictionary update, assuming that the at each
timestep the sparse codes given to the batch and online algorithms are ?close?. This motivates the
following problem.
Definition 4.1 (Online `1 -Dictionary Learning Problem). At time t, the online algorithm picks
? t+1 ) with Pt+1 ? Rm?n and X
? t+1 ?
A?t+1 ? A. Then, the nature (adversary) reveals (Pt+1 , X
2

In our algorithms, it is quite straightforward to replace the condition A ? A by some other condition
A ? C, where C is some closed non-empty convex set.
3
e[t] = [X
e[t?1] | x1 , . . . , xnt ] where xj ?s are coming from the novel
In particular, define (recursively) X
e[t] k1 .
document detection step at time t. In [10], the dictionary learning step is At+1 = argminA?A kP[t] ? AX

4

Rk?n . The problem is to pick the A?t+1 sequence such that the following regret function is minimized4
T
T
X
X
? t k1 ? min
R(T ) =
kPt ? A?t X
kPt ? AXt k1 ,
A?A

t=1

t=1

? t = Xt + Et and Et is an error matrix dependent on t.
where X
The regret defined above admits the discrepancy between the sparse coding matrices supplied to the
batch and online algorithms through the error matrix. The reason for this generality is because in
our application setting, the sparse coding matrices used for updating the dictionaries of the batch
and online algorithms could be different. We will later establish the conditions on Et ?s under which
we can achieve sublinear regret. All missing proofs and details appear in the full version of the
paper [11].
Online `1 -Dictionary Algorithm

4.1

In this section, we design an algorithm for the online `1 -dictionary learning problem, which we
call Online Inexact ADMM (OIADMM)5 and bound its regret. Firstly note that because of the
non-smooth `1 -norms involved it is computationally expensive to apply standard online learning
algorithms like online gradient descent [25, 8], COMID [6], FOBOS [5], and RDA [22], as they
require computing a costly subgradient at every iteration. The subgradient of kP ? AXk1 at A = A?
is (X ? sign(X > A?> ? P > ))> .
Our algorithm for online `1 -dictionary learning is based on the online alternating direction method
which was recently proposed by Wang et al. [19]. Our algorithm first performs a simple variable
substitution by introducing an equality constraint. The update for each of the resulting variable has
a closed-form solution without the need of estimating the subgradients explicitly.
Algorithm 2 : OIADMM
? t ? Rk?n , ?t ? 0, ?t ? 0
Input: Pt ? Rm?n , A?t ? Rm?k , ?t ? Rm?n , X
e t ?? Pt ? A?t X
?t
?
e t ? ?i + (?t /2)k?
e t ? ?k2
?t+1 = argmin? k?k1 + h?t , ?
F
e t + ?t /?t , 1/?t ))
(? ?t+1 = soft(?
>
e
?
Gt+1 ?? ?(?t /?t + ?t ? ?t+1 )Xt
A?t+1 = argminA?A ?t (hGt+1 , A ? A?t i + (1/2?t )kA ? A?t k2F )
(? A?t+1 = ?A (max{0, A?t ? ?t Gt+1 }))
?
?
?t+1 = ?t + ?t (Pt ? At+1 Xt ? ?t+1 )
Return A?t+1 and ?t+1
The Algorithm OIADMM is simple. Consider the following minimization problem at time t
? t k1 .
min kPt ? AX

A?A

We can rewrite this above minimization problem as:
? t = ?.
min k?k1 such that Pt ? AX

A?A,?

(4)

The augmented Lagrangian of (4) is:
L(A, ?, ?)

=

min

A?A,?

? t ? ?i +
k?k1 + h?, Pt ? AX


2
?t 

? t ? ?

Pt ? AX

 , (5)
2
F

where ? ? Rm?n is a multiplier and ?t > 0 is a penalty parameter.
4

For ease of presentation and analysis, we will assume that m and n don?t vary with time. One could allow
for changing m and n by carefully adjusting the size of the matrices by zero-padding.
5
The reason for naming it OIADMM is because the algorithm is based on alternating directions method of
multipliers (ADMM) procedure.

5

OIADMM is summarized in Algorithm 2. The algorithm generates a sequence of iterates
{?t , At , ?t }?
t=1 . At each time t, instead of solving (4) completely, it only runs one step ADMM
update of the variables (?t , At , ?t ). The complete analysis of Algorithm 2 is presented in the full
version of the paper [11]. Here, we just summarize the main result in the following theorem.
Theorem 4.2. Let {?t , A?t , ?t } be the sequences generated by the OIADMM procedure and R(T )
be the regret as defined above. Assume the following conditions hold: (i) ?t, the Frobenius norm
of ?k?t k1 is upper bounded by ?, (ii) A?1 = 0m?k , kAopt kF ? D, (iii) ?1 = 0m?n , and (iv) ?t,
?
? t ). Setting ?t, ?t = ? ?m T where ?m = maxt {1/?t }, we have
1/?t ? 2?max (X
D
?
T
?D T X opt
R(T ) ? ?
+
kA Et k1 .
?m
t=1
In the above theorem one could replace ?m by any upper bound on it (i.e., we don?t need to know
?m exactly).
? t ) made
Condition on Et ?s for Sublinear Regret. In a standard online learning setting, the (Pt , X
available to the online learning algorithm will be the same as (Pt , Xt ) made available ?
to the batch
? t = Xt ? Et = 0, yielding a O( T ) regret.
dictionary learning algorithm in hindsight, so that X
PT
More generally, as long as t=1 kEt kp = o(T ) for some suitable p-norm, we get a sublinear regret
bound.6 For example, if {Zt } is a sequence of matrices such that for all t, kZt kp = O(1), then
setting Et = t? Zt ,  > 0 yields a sublinear regret. This gives a sufficient condition for sublinear
regret, and it is an interesting open problem to extend the analysis to other cases.
Running Time. For the ith column in the dictionary matrix the projection onto A can be done in
O(si log m) time where si is the number of non-zero elements in the ith column using the projection onto `1 -ball algorithm of Duchi et al. [4]. The simplest implementation of OIADMM takes
O(mnk) time at each timestep because of the matrix multiplications involved.

5

Experimental Results

In this section, we present experiments to compare and contrast the performance of `1 -batch and
`1 -online dictionary learning algorithms for the task of novel document detection. We also present
results highlighting the superiority of using an `1 - over an `2 -penalty on the reconstruction error for
this task (validating the discussion in Section 3).
Implementation of BATCH. In our implementation, we grow the dictionary size by ? in each
timestep. Growing the dictionary size is essential for the batch algorithm because as t increases the
number of columns of P[t] also increases, and therefore, a larger dictionary is required to compactly
represent all the documents in P[t] . For solving (3), we use alternative minimization over the variables. The pseudo-code description is given in the full version of the paper [11]. The optimization
problems arising in the sparse coding and dictionary learning steps are solved using ADMM?s.
Online Algorithm for Novel Document Detection. Our online algorithm7 uses the same novel
document detection step as Algorithm BATCH, but dictionary learning is done using OIADMM. For
a pseudo-code description, see full version of the paper [11]. Notice that the sparse coding matrices
?1, . . . , X
? t . If these sequence of
of the Algorithm BATCH, X1 , . . . , Xt could be different from X
matrices are close to each other, then we have a sublinear regret on the objective function.8
Evaluation of Novel Document Detection. For performance evaluation, we assume that documents
in the corpus have been manually identified with a set of topics. For simplicity, we assume that each
document is tagged with the single, most dominant topic that it associates with, which we call the
true topic of that document. We call a document y arriving at time t novel if the true topic of
y has not appeared before the time t. So at time t, given a set of documents, the task of novel
P
P
This follows from H?older?s inequality which gives Tt=1 kAopt Et k1 ? kAopt kq ( Tt=1 kEt kp ) for 1 ?
opt
p, q ? ? and 1/p + 1/q = 1, and by the assuming kA kq is bounded. Here, k ? kp denotes Schatten p-norm.
7
In our experiments, the number of documents introduced in each timestep is almost of the same order, and
hence there is no need to change the size of the dictionary across timesteps for the online algorithm.
8
As noted earlier, we can not do a comparison without making any assumptions.
6

6

document detection is to classify each document as either novel (positive) or non-novel (negative).
For evaluating this classification task, we use the standard Area Under the ROC Curve (AUC) [13].
Performance Evaluation for `1 -Dictionary Learning. We use a simple reconstruction error measure for comparing the dictionaries produced by our `1 -batch and `1 -online algorithms. We want the
dictionary at time t to be a good basis to represent all the documents in P[t] ? Rm?Nt . This leads
us to define the sparse reconstruction error (SRE) of a dictionary A at time t as


def 1
SRE(A) =
min kP[t] ? AXk1 + ?kXk1 .
Nt X?0
A dictionary with a smaller SRE is better on average at sparsely representing the documents in P[t] .
Novel Document Detection using `2 -dictionary learning. To justify the choice of using an `1 penalty (on the reconstruction error) for novel document detection, we performed experiments comparing `1 - vs. `2 -penalty for this task. In the `2 -setting, for the sparse coding step we used a fast
implementation of the LARS algorithm with positivity constraints [7] and the dictionary learning
was done by solving a non-negative matrix factorization problem with additional sparsity constraints
(also known as the non-negative sparse coding problem [9]). A complete pseudo-code description
is given in the full version of the paper [11].9
Experimental Setup. All reported results are based on a Matlab implementation running on a quadcore 2.33 GHz Intel processor with 32GB RAM. The regularization parameter ? is set to 0.1 which
? t ))
yields reasonable sparsities in our experiments. OIADMM parameters ?t is set 1/(2?max (X
(chosen according to Theorem 4.2) and ?t is fixed to 5 (obtained through tuning). The ADMM
parameters for the sparse coding and batch dictionary learning steps are set as suggested in [10]
(refer to the full version [11]). In the batch algorithms, we grow the dictionary sizes by ? = 10 in
each timestep. The threshold value ? is treated as a tunable parameter.
5.1

Experiments on News Streams

Our first dataset is drawn from the NIST Topic Detection and Tracking (TDT2) corpus which consists of news stories in the first half of 1998. In our evaluation, we used a set of 9000 documents
represented over 19528 terms and distributed into the top 30 TDT2 human-labeled topics over a
period of 27 weeks. We introduce the documents in groups. At timestep 0, we introduce the first
1000 documents and these documents are used for initializing the dictionary. We use an alternative
minimization procedure over the variables of (1) to initialize the dictionary. In these experiments
the size of the initial dictionary k = 200. In each subsequent timestep t ? {1, . . . , 8}, we provide
the batch and online algorithms the same set of 1000 documents. In Figure 1, we present novel
document detection results for those timesteps where at least one novel document was introduced.
Table 1 shows the corresponding AUC numbers. The results show that using an `1 -penalty on the
reconstruction error is better for novel document detection than using an `2 -penalty.

0.5
False Positive Rate

1

0.5

0
0

ONLINE
BATCH?IMPL
L2?BATCH

0.5
False Positive Rate

1

0.5

0
0

ONLINE
BATCH?IMPL
L2?BATCH

0.5
False Positive Rate

1

Timestep 8

1

0.5

0
0

ONLINE
BATCH?IMPL
L2?BATCH

0.5
False Positive Rate

1

True Positive Rate

0
0

ONLINE
BATCH?IMPL
L2?BATCH

Timestep 6

1

True Positive Rate

0.5

Timestep 5

1

True Positive Rate

Timestep 2
True Positive Rate

True Positive Rate

Timestep 1
1

1

0.5

0
0

ONLINE
BATCH?IMPL
L2?BATCH

0.5
False Positive Rate

Figure 1: ROC curves for TDT2 for timesteps where novel documents were introduced.
Comparison of the `1 -online and `1 -batch Algorithms. The `1 -online and `1 -batch algorithms
have almost identical performance in terms of detecting novel documents (see Table 1). However,
the online algorithm is much more computationally efficient. In Figure 2(a), we compare the running
times of these algorithms. As noted earlier, the running time of the batch algorithm goes up as
t increases (as it has to optimize over the entire past). However, the running time of the online
algorithm is independent of the past and only depends on the number of documents introduced
in each timestep (which in this case is always 1000). Therefore, the running time of the online
9

We used the SPAMS package http://spams-devel.gforge.inria.fr/ in our implementation.

7

1

Timestep
1
2
5
6
8
Avg.

No. of Novel Docs.
19
53
116
66
65

AUC `1 -online
0.791
0.694
0.732
0.881
0.757
0.771

No. of Nonnovel Docs.
981
947
884
934
935

AUC `1 -batch
0.815
0.704
0.764
0.898
0.760
0.788

AUC `2 -batch
0.674
0.586
0.601
0.816
0.701
0.676

Table 1: AUC Numbers for ROC Plots in Figure 1.
algorithm is almost the same across different timesteps. As expected the run-time gap between the
`1 -batch and `1 -online algorithms widen as t increases ? in the first timestep the online algorithm is
5.4 times faster, and this rapidly increases to a factor of 11.5 in just 7 timesteps.

200
100
0
0

2

4
Timestep

6

8

Sparse Reconstruction Error Plot for TDT2
1
ONLINE
BATCH?IMPL
0.9
0.8
0.7
0.6
0

2

4
Timestep

6

8

Run Time Plot for Twitter
400

ONLINE
BATCH?IMPL

300
200
100
0
0

5

Timestep

10

Sparse Reconstruction Error (SRE)

300

ONLINE
BATCH?IMPL
L2?BATCH

CPU Running Time (in mins)

CPU Running Time (in mins)

Running Time Plot for TDT2
400

Sparse Reconstruction Error (SRE)

In Figure 2(b), we compare the dictionaries produced by the `1 -batch and `1 -online algorithms
under the SRE metric. In the first few timesteps, the SRE of the dictionaries produced by the online
algorithm is slightly lower than that of the batch algorithm. However, this gets corrected after a few
timesteps and as expected later on the batch algorithm produces better dictionaries.
Sparse Reconstruction Error Plot for Twitter
1
0.9
0.8
0.7
0.6
0.5
0

ONLINE
BATCH?IMPL
5

Timestep

10

(b)
(c)
(d)
(a)
Figure 2: Running time and SRE plots for TDT2 and Twitter datasets.
5.2

Experiments on Twitter

Our second dataset is from an application of monitoring Twitter for Marketing and PR for smartphone and wireless providers. We used the Twitter Decahose to collect a 10% sample of all tweets
(posts) from Sept 15 to Oct 05, 2011. From this, we filtered the tweets relevant to ?Smartphones?
using a scheme presented in [3] which utilizes the Wikipedia ontology to do the filtering. Our dataset
comprises of 127760 tweets over these 21 days and the vocabulary size is 6237 words. We used the
tweets from Sept 15 to 21 (34292 in number) to initialize the dictionaries. Subsequently, at each
timestep, we give as input to both the algorithms all the tweets from a given day (for a period of 14
days between Sept 22 to Oct 05). Since this dataset is unlabeled, we do a quantitative evaluation of
`1 -batch vs. `1 -online algorithms (in terms of SRE) and do a qualitative evaluation of the `1 -online
algorithm for the novel document detection task. Here, the size of the initial dictionary k = 100.
Figure 2(c) shows the running times on the Twitter dataset. At first timestep the online algorithm is
already 10.8 times faster, and this speedup escalates to 18.2 by the 14th timestep. Figure 2(d) shows
the SRE of the dictionaries produced by these algorithms. In this case, the SRE of the dictionaries
produced by the batch algorithm is consistently better than that of the online algorithm, but as the
running time plots suggests this improvement comes at a very steep price.
Date
2011-09-26
2011-09-29
2011-10-03
2011-10-04
2011-10-05

Sample Novel Tweets Detected Using our Online Algorithm
Android powered 56 percent of smartphones sold in the last three months. Sad thing is it can?t lower the rating of ios!
How Windows 8 is faster, lighter and more efficient: WP7 Droid Bionic Android 2.3.4 HP TouchPad white ipods 72
U.S. News: AT&T begins sending throttling warnings to top data hogs: AT&T did away with its unlimited da... #iPhone
Can?t wait for the iphone 4s #letstalkiphone
Everybody put an iPhone up in the air one time #ripstevejobs

Table 2: Sample novel documents detected by our online algorithm.
Table 2 below shows a representative set of novel tweets identified by our online algorithm. Using
a completely automated process (refer to the full version [11]), we are able to detect breaking news
and trending relevant to the smartphone market, such as AT&T throttling data bandwidth, launch of
IPhone 4S, and the death of Steve Jobs.
8

References
[1] M. Aharon, M. Elad, and A. Bruckstein. The K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation. IEEE Transactions on Signal Processing, 54(11), 2006.
[2] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein. Distributed Optimization and Statistical Learning
via the Alternating Direction Method of Multipliers. Foundations and Trends in Machine Learning, 2011.
[3] V. Chenthamarakshan, P. Melville, V. Sindhwani, and R. D. Lawrence. Concept Labeling: Building Text
Classifiers with Minimal Supervision. In IJCAI, pages 1225?1230, 2011.
[4] J. Duchi, S. Shalev-Shwartz, Y. Singer, and T. Chandra. Efficient Projections onto the l1-ball for Learning
in High Dimensions. In ICML, pages 272?279, 2008.
[5] J. Duchi and Y. Singer. Efficient Online and Batch Learning using Forward Backward Splitting. JMLR,
10:2873?2898, 2009.
[6] J. C. Duchi, S. Shalev-Shwartz, Y. Singer, and A. Tewari. Composite Objective Mirror Descent. In COLT,
pages 14?26, 2010.
[7] J. Friedman, T. Hastie, H. Hfling, and R. Tibshirani. Pathwise Coordinate Optimization. The Annals of
Applied Statistics, 1(2):302?332, 2007.
[8] E. Hazan, A. Agarwal, and S. Kale. Logarithmic Regret Algorithms for Online Convex Optimization.
Machine Learning, 69(2-3):169?192, 2007.
[9] P. O. Hoyer. Non-Negative Sparse Coding. In IEEE Workshop on Neural Networks for Signal Processing,
pages 557?565, 2002.
[10] S. P. Kasiviswanathan, P. Melville, A. Banerjee, and V. Sindhwani. Emerging Topic Detection using
Dictionary Learning. In CIKM, pages 745?754, 2011.
[11] S. P. Kasiviswanathan, H. Wang, A. Banerjee, and P. Melville. Online `1 -Dictionary Learning
with Application to Novel Document Detection. http://www.cse.psu.edu/?kasivisw/
fullonlinedict.pdf.
[12] J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online Learning for Matrix Factorization and Sparse Coding.
JMLR, 11:19?60, 2010.
[13] C. Manning, P. Raghavan, and H. Sch?utze. Introduction to Information Retrieval. Cambridge University
Press, 2008.
[14] P. Melville, J. Leskovec, and F. Provost, editors. Proceedings of the First Workshop on Social Media
Analytics. ACM, 2010.
[15] B. Olshausen and D. Field. Sparse Coding with an Overcomplete Basis Set: A Strategy Employed by
V1? Vision Research, 37(23):3311?3325, 1997.
[16] S. Petrovi?c, M. Osborne, and V. Lavrenko. Streaming First Story Detection with Application to Twitter.
In HLT ?10, pages 181?189. ACL, 2010.
[17] A. Saha and V. Sindhwani. Learning Evolving and Emerging Topics in Social Media: A Dynamic NMF
Approach with Temporal Regularization. In WSDM, pages 693?702, 2012.
[18] S. Shalev-Shwartz. Online Learning and Online Convex Optimization. Foundations and Trends in Machine Learning, 4(2), 2012.
[19] H. Wang and A. Banerjee. Online Alternating Direction Method. In ICML, 2012.
[20] J. Wright and Y. Ma. Dense Error Correction Via L1-Minimization. IEEE Transactions on Information
Theory, 56(7):3540?3560, 2010.
[21] J. Wright, A. Yang, A. Ganesh, S. Sastry, and Y. Ma. Robust Face Recognition via Sparse Representation.
IEEE Transactions on Pattern Analysis and Machine Intelliegence, 31(2):210?227, Feb. 2009.
[22] L. Xiao. Dual Averaging Methods for Regularized Stochastic Learning and Online Optimization. JMLR,
11:2543?2596, 2010.
[23] A. Y. Yang, S. S. Sastry, A. Ganesh, and Y. Ma. Fast L1-minimization Algorithms and an Application
in Robust Face Recognition: A Review. In International Conference on Image Processing, pages 1849?
1852, 2010.
[24] J. Yang and Y. Zhang. Alternating Direction Algorithms for L1-Problems in Compressive Sensing. SIAM
Journal of Scientific Computing, 33(1):250?278, 2011.
[25] M. Zinkevich. Online Convex Programming and Generalized Infinitesimal Gradient Ascent. In ICML,
pages 928?936, 2003.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 368-a-four-neuron-circuit-accounts-for-change-sensitive-inhibition-in-salamander-retina.pdf

A four neuron circuit accounts for change sensitive
inhibition in salamander retina
Jeffrey L. Teeters
Lawrence Livennore Lab
PO Box 808, L-426
Livennore CA 94550

Frank H. Eeckman
Lawrence Livennore Lab
PO Box 808, L-270
Livennore CA 94550

Frank S. Werblin
UC-Berkeley
Room 145, LSA
Berkeley CA 94720

Abstract
In salamander retina, the response of On-Off ganglion cells to a central
flash is reduced by movement in the receptive field surround. Through
computer simulation of a 2-D model which takes into account their
anatomical and physiological properties, we show that interactions
between four neuron types (two bipolar and two amacrine) may be
responsible for the generation and lateral conductance of this change
sensitive inhibition. The model shows that the four neuron circuit can
account for previously observed movement sensitive reductions in
ganglion cell sensitivity and allows visualization and prediction of the
spatio-temporal pattern of activity in change sensitive retinal cells.

1 INTRODUCTION
In the salamander retina. the response of transient (On-Off) ganglion cells to a central
flash is reduced by movement in the receptive field surround (Werblin. 1972; Werblin &
Copenhagen. 1974) as illustrated in Fig 1. This phenomenon requires the detection of
change in the surround and the lateral transmission of this change sensitive inhibition to
the ganglion cell dendrites. Wunk & Werblin (1979) showed that all ganglion cells
receive change-sensitive inhibition. and Barnes & Werblin (1987) implicated a changesensitive amacrine cell with widely distributed processes. The change-sensitivity of these
amacrine cells has been traced in part to a truncation of synaptic release from the bipolar
tenninals that presumably drive them (Maguire et al., 1989). The transient response of
these amacrine cells, mediated by voltage gated currents (Barnes & Werblin, 1986; Eliasof
et al., 1987) also contributes to this change sensitivity.
These and other experiments suggest that interactions between four neuron types underlie
both the change detection and the lateral transmission of inhibition (Werblin et al., 1988;
Maguire et al., 1989). To test this hypothesis and make predictions that could be
compared with later experiments we have constructed a computational model of the four
neuron circuit and incorporated it into an overall model of the retina. This model allows
us to simulate the effect of inhibition generated by the four neuron circuit on ganglion
cells.
384

Stimulus:

I

1

Windmill with
central test spot

+1(]

Ganglion Cell Response:

t

Stationary
windmill

Spinning
I---t windmill
1 second

I

1

~@:U( T::::t:~""" "~"]

1

Resting level
NormaJ+

------ ---------I

Figure 1: Change-Sensitive Inhibition. Data is from Werblin (1972).

2 IMPLEMENTING THE HYPOTHETICAL CIRCUIT
The proposed change-sensitive circuit (Werblin et al.. 1988; Maguire et al .? 1989) is
reproduced in Figure 2. This is meant to describe a very local region of the retina where
the receptive fields of the two bipolar cells are spatially overlapping. When a visual
target enters this receptive field. the bipolar cells are both depolarized. The sustained
bipolar cell activates the narrow field amacrine cell that. in tum feeds back to the synaptic
terminal of the transient bipolar cell to truncate transmitter release after a brief (ca. 100
msec) delay. Because the signal reaching the wide field amacrine cell is truncated after
about 100 msec. the wide field amacrine cell will receive excitation when the target enters
the recepti ve field. but will not continue to respond in the presence of the target.
The spatial profiles of synaptic input and output for the cell types involved in the model
are summarized in Figure 3. The bipolar and narrow field amacrine cell sensitivities
extend over a region corresponding roughly to their dendritic spread. The wide field
amacrine cell appears to receive input over a local region near the cell body, but delivers
its inhibitory output over a much wider region corresponding the the full extent (ca. 500
mm) of its processes.
Figure 4 shows the electrical circuit model for each cell type. and illustrates the
interactions between cells that are implemented in the model. In Figure 4. boxes contain
the circuit for each cell and arrows between them represent synaptic interactions thought

.?? NarrowJietd (amacrine . .

To

_ Ganglion
Figure 2: Circuitry to be Analyzed

cells.

1\

Bipolar
Narrow

(Inpul and oulpull

fleld~ (Input and output)

amacrine /
Wide field

"

~Inpull
500

Distance from 0 cell center (Ilm)

500

Figure 3: Spatial Profiles of Input Sensitivity and Output Transmission
to occur as determined through experiments in which a neurotransmitter is puffed onto
bipolar dendrites. Bipolar cells are modeled using two compartments. corresponding to
the cell body and axon terminal as suggested in Maguire et at. (1989). Amacrine cells are
modeled using only one compartment as in Eliasof et at. (1987).
Each compartment has a voltage (Vbs. Vbst, Vbtt. Van. Vaw). The cell body for the
sustained and transient bipolar are assumed to be the same. Batteries in the figure
correspond to excitatory (E+. Ena) or inhibitory reversal potentials (E-. Ek, Eel).
Resistors represent ionic conductances. Circles and arrows through resisters indicate
transmitter dependent conductances which are controlled by the voltage of a presynaptic or
same cell. Functions relating voltages to conductances are mostly linear with a threshold.
More details are given in Teeters et at. (1991).

Neurotransmitter Input

Wide field

Fi~ure 4:

Details of Circuitry

A Four Neuron Circuit Accounts for Change Sensitive Inhibition

3 TESTING THE COMPUTATIONAL MODEL
Computer simulation was used to tune model parameters. and test whether the single cell
properties and proposed interactions between cells shown in Figure 4 are consistent with
the responses recorded from the neurons during applications of a neurotransmitter puff.
Results are shown in Figure 5. Voltage clamp experiments electrically clamp the cell
membrane potential to a constant voltage and determine the current required to maintain
the voltage over time. Downward traces indicate that current is flowing into the cell;
upward traces indicate outward current For simplicity. scales are not shown, but in all
cases the magnitude of the simulated response is close to that of the observed response.
The simulated and observed responses voltage clamps of the wide field amacrine shown in
the fourth row vary because there is a sustained outward current observed experimentally
that is not apparent in the simulations. This shows that the model is not perfect and is
something that needs further investigation.
This difference between the model and observed response does not prevent the
hypothesized function of the circuit from being simulated. This is shown on the bottom
row where both the observed and simulated voltage responses from the wide field amacrine
are transient.

4 SIMULATING INHIBITION TO GANGLION CELLS
Figure 5 illustrates that we have, to a large degree, succeeded in combining the
characteristics of single cells into a model which can explain many of the observed
properties thought to be due to the interaction between these cells in a local region.

Experiment

Observed response

Simulated Response

Neurotransm Itter
Puff Input

-.r--

J

Voltage clamp of
bipOlar cell body

"-

Voltage clamp of
narrow field amacrine

Wide field amacrine
Voltage clamp
Voltage clamp with
pIcrotoxin block
Voltage response

V'
~.,

-"

y-

~

P--

-

E=======::
--v-V-

--"'-

Figure 5: Example Puff Simulations

387

388

Teeters, Eeckman, and Werblin

The next step in our analysis is to investigate how this circuit influences the response of
ganglion cells. To do this requires simulating the input to the bipolar dendrites and
simulating the ganglion cells which receive the transient inhibition generated by the wide
field amacrine. This amounts to a integrated model of an entire patch of retina. including
receptors. horizontal cells. the four neuron circuit discussed earlier. and ganglion cells.
The manner in which we accomplish this is illustrated in Figure 6.
The left side of figure 6 shows the model elements. Receptors and horizontal cells are
modeled as low pass filters with different time constants and different spatial inputs. The
ganglion cell model receives a transient excitatory input generated phenomenologically by
a thresholded high pass filter from the transient bipolar. Inhibitory input to the ganglion
cell is implemented as coming from the transient wide field amacrine cells described
previously. For simplicity. voltage gated currents and spiking are not implemented in the
ganglion cell model. and only the off bipolar pathways are simulated.
The right hand of Figure 6 illustrates how the model is implemented spatially. The
circuit for each cell type is duplicated across the retina patch in a matrix fonnat. The
known spatial properties of each cell. such as the spatial range of transmitter sensitivity
and release are incorporated into the model. Details are given in Teeters et al. 1991.

5 SIMULATING INHIBITION TO GANGLION CELLS
To test if the model can account for the observed reduction in ganglion cell response
during movement in the receptive field surround. we simulated the experiment depicted in
Figure 1. mainly the flashing of a central light during the presence of a stationary and
spinning windmill. The results are shown in Figure 7.

Model Elements
Receptor

Spatial Implementation

R ?"

Horizontal Cell

Threshold
High-pass
filter

wCf).? 1:. .
..

ang Ion

..

.

el

'b~

~E
.'. - E
?t:t-rEcIT
r

?
?

1-} . . ... .....

..

On-Off Ganglion cells

'??

Figure 6: Integrated Retinal Model

A Four Neuron Circuit Accounts for Change Sensitive Inhibition

Rather than displaying a single curve representing the response of a single unit over time,
Figure 7 shows the simultaneous pattern of activity in an array of neurons spatially
distributed across the retina patch at an instant in time (just after a central light spot is
turned on). The neuron responses are the transient bipolar terminal, the wide field
amacrine neurotransmitter release, and the ganglion cell voltage response. On the left
column is shown the response to a flashing spot when the windmill is stationary. On the
right is shown the response to the same flashing spot but with a spinning windmill.
When the windmill is stationary, the transient bipolar terminal responds only to the
center flash. Responses to the windmill vanes are suppressed by the narrow field
amacrine cell causing the appearance of four regions of hyperpolarizing responses around
the center. The wide field amacrine responds to the central test flash and releases
transmitter as shown in the second row. The array of ganglion cells responds to both the
excitatory input generated by the spot at the bipolar terminals and the inhibitory input
generated by the wide field amacrines. Because the wide field inhibition has not yet taken
effect at this point in time, the ganglion cells respond well to the flashing spot.
When the windmill is spinning, as is shown on the right hand column, the transient
bipolar terminals generate a response to the leading edge of the windmill vanes. The wide
field amacrine cells receive excitatory input from the transient bipolar terminal responses
to the vane, and consequently release inhibitory neurotransmitter over a wide area as
shown in in the right column. Because inhibition is being continuously generated by the
spinning windmill, the response of the ganglion cells across the retinal patch has a large

Stationary Windmill

Spinning windmill

Transient Bipolar Terminal

Wide field

Ganglion cell

Fig. 7 - Ganglion Cell Inhibition Caused By Spinning Windmill

389

bowl shaped area of hyperpolarization which reduces the ganglion cell response of the
cells to the central test flash. This is seen by the fact that the height of depolarization in
the centrally located ganglion cells is much smaller under conditions of a spinning
windmill than if the windmill is stationary. This is consistent with the results found
experimentally which are illustrated in Figure 1. Experimental data not yet attained. but
which are predicted by the model simulations illustrated in Figure 7. are the spatial
patterns of activity generated in the bipolar. amacrine. and ganglion cells in response to
the different stimuli.

6 SUMMARY
Using computer simulation of a neurophysiologically based model. we demonstrate that
the experimental data describing properties of four neurons in the inner retina are
compatible with the hypothesis that these neurons are involved in the detection of change
and the feedforward of change-sensitive inhibition to ganglion cells. First. we build a
computational model of the hypothesized four neuron circuit and determine that the
proposed interactions between them are sufficient to reproduce many of the observed
network properties in response to a puff of neurotransmitter. Next. we integrate this
model into a full retina model to simulate their influence on ganglion cell responses.
The model verifies the consistency of presently available data. and allows formation of
predictions of neural activity are subject to refutation or verification by new experiments.
We are currently recording the spatio-temporal response of ganglion cells to moving
stimuli so that direct comparisons to these model predictions can be made.

References
Barnes. S. and Werblin. F.S. (1986). Gated currents generate single spike activity in
amacrine cells of the tiger salamander. Proc. Natl. Acad. Sci. USA 83: 1509 - 1512.
Barnes. S. and Werblin. F.S. (1987). Direct excitatory and lateral inhibitory synaptic
inputs to amacrine cells in the tiger salamander retina. Brain Res. 406: 233 - 237.
Eliasof S .? Barnes S. and Werblin. F.S. (1987). The interaction of ionic currents
mediating single spike activity in retinal amacrine cells of the tiger salamander. 1.
Neurosci. 7: 3512 - 3524.
Maguire. G .? Lukasiewicz. P. and Werblin F.S. (1989). Amacrine cell interactions underlying the response to change in the tiger salamander retina. 1. Neurosci. 9: 726 - 735.
Teeters. J.L .? Eeckman. F.H .? Werblin F.S. (1991). A computer model to visualize
change sensitive responses in the salamander retina. In MA. Arbib and J-P. Ewert (eds.)
Visuomotor Coordination: Amphibians. Comparisons. Models and Robots. Plenum.
Werblin. F.S. (1972). Lateral interactions at inner plexiform layer of a vertebrate retina:
antagonistic response to change. Science. 175: 1008 - 1010.
Werblin. F.S. and Copenhagen. D.R. (1974). Control of retinal sensitivity. III. Lateral
interactions at the inner plexiform layer. 1. Gen. Physiol. 63: 88 - 110.
Werblin. F.S .? Maguire. G., Lukasiewicz, P., Eliasof. S .? and Wu. S. (1988). Neural
interactions mediating the detection of motion in the retina of the tiger salamander. Visual
Neurosci. 1: 317 - 329.
Wunk, D.F. and Werblin, F.S. (1979). Synaptic inputs to ganglion cells in the tiger
salamander retina. 1. Gen. Physiol. 73: 265 - 286.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 600-a-neural-network-that-learns-to-interpret-myocardial-planar-thallium-scintigrams.pdf

A Neural Network that Learns to Interpret
Myocardial Planar Thallium Scintigrams

Charles Rosenberg, Ph.D:

Jacob Erel, M.D.

Department of Computer Science
Hebrew University
Jerusalem, Israel

Department of Cardiology
Sapir Medical Center
Meir General Hospital
Kfar Saba, Israel

Henri Atlan, M.D., PhD.
Department of Biophysics and Nuclear Medicine
Hadassah Medical Center
Jerusalem, Israel

Abstract
The planar thallium-201 myocardial perfusion scintigram is a widely used
diagnostic technique for detecting and estimating the risk of coronary
artery disease. Neural networks learned to interpret 100 thallium scintigrams as determined by individual expert ratings. Standard error backpropagation was compared to standard LMS, and LMS combined with
one layer of RBF units. Using the "leave-one-out" method, generalization was tested on all 100 cases. Training time was determined automatically from cross-validation perfonnance. Best perfonnance was attained
by the RBF/LMS network with three hidden units per view and compares
favorably with human experts.

1 Introduction
Coronary artery disease (CAD) is one of the leading causes of death in the Western World.
The planar thallium-201 is considered to be a reliable diagnostic tool in the detection of
? Current address: Geriatrics, Research, Educational and Clinical Center, VA Medical Center, Salt
Lake City, Utah.

755

756

Rosenberg, Erel, and Atlan

CAD. Thallium is a radioactive isotope that distributes in mammalian tissues after intervenous administration and is imaged by a gamma camera. The resulting scintigram is visually
interpreted by the physician for the presence or absence of defects - areas with relatively
lower perfusion levels. In myocardial applications, thallium is used to measure myocardial
ischemia and to differentiate between viable and non-viable (infarcted) heart muscle (pohost and Henzlova, 1990).
Diagnosis of CAD is based on the comparison of two sets of images, one set acquired
immediately after a standard effort test (BRUCE protocol), and the second following a
delay period of four hours. During this delay, the thallium redistributes in the heart muscle
and spontaneously decays. Defects caused by scar tissue are relatively unchanged over
the delay period (fixed defect), while those caused by ischemia are partially or completely
filled-in (reversible defect) (Beller, 1991; Datz et al., 1992).
Image interpretation is difficult for a number of reasons: the inherent variability in biological systems which makes each case essentially unique, the vast amount of irrelevant and
noisy information in an image, and the "context-dependency" of the interpretation on data
from many other tests and clinical history. Interpretation can also be significantly affected
by attentional shifts, perceptual abilities, and mental state (Franken Jr. and Berbaum, 1991;
Cuar6n et al., 1980).
While networks have found considerable application in ECG processing (e.g. (Artis et al.,
1991)) and clinical decision-making (Baxt, 1991b; Baxt, 1991a), they have thus far found
limited application in the field of nuclear medicine. Non-cardiac imaging applications include the grading of breast carcinomas (Dawson et al., 1991) and the discrimination of normal vs. Alzheimer's PET scans (Kippenhan et al., 1990). Of the studies dealing specifically
with cardiac imaging, neural networks have been applied to several problems in cardiology
including the identification of stenosis (Porenta et al., 1990; Cios et al., 1989; Cios et al.,
1991; Cianflone et al., 1990; Fujita et al., 1992). These studies encouraged us to explore
the use of neural networks in the interpretation of cardiac scintigraphy.

2

Methods

We trained one network consisting of a layer of gaussian RBF units in an unsupervised fashion to discover features in circumferential profiles in planar thallium scintigraphy. Then a
second network was trained in a supervised way to map these features to physician's visual
interpretations of those images using the delta rule (Widrow and Hoff, 1960). This architecture was previously found to compare favorably to other network learning algorithms
(2-layer backpropagation and single-layer networks) on this task (Rosenberg et al., 1993;
Erel et al., 1993).
In our experiments, all of the input vectors representing single views f were first normalized
to unit length V = IIfll . The activation value of a gaussian unit, OJ, is then given by:
(1)
netj

O1? = exp(--)
w

(2)

where j is an index to a gaussian unit and i is an input unit index. The width of the gaussian,

A Neural Network that Learns to Interpret Myocardial Planar Thallium Scintigrams
R~gion.1

Output

IL.

0

Ii:1/1

Ii:1/1

I\-

~

Scores

0

~

)(

IL.

<

IL.

Ii.
;!;

0

Ii.
~

IL.

.:.

t.

<;I
t-

t.

III I

Ill!

?
?

Severe
Moderate

o"

Mild
Normal

RBF
Input

ANT

LAO 45

LAT

VIEWS

Figure 1: The network architecture. The first layer (Input) encoded the three circumferential profiles representing the three views, anterior (ANT), left lateral oblique (LAO). and
left lateral (LAT). The second layer consisted of radial basis function (RBF) units, the third
layer, semi-linear units trained in a supervised fashion. The outputs of the network corresponded to the visual scores as given by the expert observer. An additional unit per view
encoded the scaling factor of the input patterns lost as a result of input normalization.

given by w, was fixed at 0.25 for all units 1?
The gaussian units were trained using a competitive learning rule which moves the center
of the unit closest to the current input pattern (Omax, i.e. the "winner") closer to the input
pattern2 :
~tui,winner

2.1

= 1](v; -

Wi,winner)

(3)

Data Acquisition and Selection

Scintigraphic images were acquired for each of three views: anterior (ANT), left lateral
oblique (LAO 45), and left lateral (LAT) for each patient case. Acquisition was performed
twice, once immediately following a standard effort test and once following a delay period
of four hours. Each image was pre-processed to produce a circumferential profile (Garcia
et aI., 1981; Francisco et aI., 1982) , in which maximum pixel counts within each of 60,
6? contiguous segmental regions are plotted as a function of angle (Garcia, 1991). Preprocessing involved positioning of the region of interest (ROI), interpolative background
subtraction, smoothing and rotational alignment to the heart's apex (Garcia, 1991).
1We have considered applying the learning rule to the unit widths (w) as well as the RBF weights,
however we have not as yet pursued this possibility.
2Following Rumelhart and Zipser (Rumelhart and Zipser, 1986), the other units were also pulled
towards the input vector, although to a much smaller extent than the winner. We used a ratio of 1 to
100.
3The profiles were generated using the Elscint CTL software package for planar quantitative
thallium-20l based on the Cedars-Sinai technique (Garcia et aI., 1981; Maddahi et aI., 1981; Areeda
et aI., 1982).

757

758

Rosenberg, Ere!, and Atlan

Lesion

mild

moderate

severe

Total

single

12

5

0

17

multiple

16

16

11

43

Total

28

21

11

60

Table 1: Distribution of Abnormal Cases as Scored by the Expert Observer. Defects occurring in any combination of two or more regions (even the proximal and distal subregions
of a single area) were treated as one multiple defect. The severity level of multiple lesions
was based on the most severe lesion present.
Cases were pre-selected based on the following criteria (Beller, 1991):
? Insufficient exercise. Cases in which the heart rate was less than 130 b.p.m. were
eliminated, as this level of stress is generally deemed insufficient to accurately
distinguish normal from abnormal conditions.
? Positional abnormalities. In a few cases, the "region of interest" was not positioned or aligned correctly by the technician.
? Increased lung uptake. Typically in cases of multi-vessel disease, a significant
proportion of the perfusion occurs in the lungs as well as in the heart, making it
more difficult to determine the condition of the heart due to the partially overlapping positions of the heart and lungs.
? Breast artifacts.
Cases were selected at random between August, 1989 and March, 1992. Approximately a
third of the cases were eliminated due to insufficient heart rate, 4-5% due to breast artifacts,
4% due to lung uptake, and 1-2% due to positional abnormalities. A set of one hundred
usable cases remained.
2.2

Visual Interpretation

Each case was visually scored by a single expert observer for each of nine anatomical regions generally accepted as those that best relate to the coronary circulation: Septal: proximal and distal, Anterior: proximal and distal, Apex, Inferior: proximal and distal, and
Posterior-Lateral: proximal and distal. Scoring for each region was from normal (I) to
severe (4), indicating the level of the observed perfusion deficit.
Intra-observer variability was examined by having the observer re-interpret 17 of the cases
a second time. The observer was unable to remember the cases from the first reading and
could not refer to the previous scores.
Exact matches were obtained on 91.5% of the regions; only 8 of the 153 total regions (5%)
were labeled as a defect (mild, moderate or severe) on one occasion and not on the other.
All differences, when they occurred, were of a single rating level4 ?
4In contrast, measured inter-observer variability was much higher. A set of 13 cases was individ-

A Neural Network that Learns to Interpret Myocardial Planar Thallium Scintigrams

2.3

The Network Model

The input units of the network were divided into 3 groups of 60 units each, each group
representing the circumferential profile for a single view. A set of 3 RBF units were assigned
to each input group. Then a second layer of weights was trained using the delta rule to
reproduce the target visual scores assigned by the expert observer. The categorical visual
scores were translated to numerical values to make the data suitable for network learning:
normal =0.0, mild defect =0.3, moderate defect =0.7, and severe defect = 1.0.
In order to make efficient use of the available data, we actually trained 100 identical networks; each network was trained on a subset of 99 of the 100 cases and tested on the remaining one. This procedure, sometimes referred to as the "leave-one-out" or "jack-knife"
method, enabled us to determine the generalization performance for each case. This procedure was followed for both the RBF and the delta rule training 5. Training of a single
network took only a few minutes of Sun 4 computer time.

3 Results
Because of the larger numbers of confusions between normal and mild regions in both the
inter- and intra-observer scores, disease was defined as moderate or severe defects. The
threshold value dividing the output values of the network into these two sets was varied
from 0 to 1 in 0.01 step increments. The number of agreements between the expert observer
and the network were computed for each threshold value. The resulting scores, accumulated
over all threshold values, were plotted as a Receiver Operating Characteristic (ROC) curve.
Best performance (percent correct) was achieved with a threshold value of 0.28, which
yielded an overall accuracy of 88.7% (798/900 regions) on the stress data. However, this
value of the threshold heavily favored specificity over sensitivity due to the preponderance
of normal regions in the data. Using the decision threshold which maximized the sum
of sensitivity and specificity, 0.10, accuracy dropped to 84.9% (764/900) but sensitivity
improved to 0.771 (121/157), and specificity was 0.865 (643/743).

3.1

Distinguishing Fixed vs. Reversible Defects

In order to take into account the delayed distribution as well as the stress set of images, the
network was essentially duplicated: one network processed the stress data, and the other,
ually interpreted by 3 expert observers in a previous experiment (Rosenberg et aI., 1993). Percent
agreement (exact matches) between the observers was 82% (288/351). Of the 63 mis-matches, 5 or
about 8% of the regions were of 2 levels of severity. There were no differences of 3 levels of severity.
Approximately two-thirds of the disagreements were between normal and mild regions. These results
indicate that the single observer data employed in the present study are more reliable than the mixed
consensus and individual scores used previously.
5Details of network learning were as follows: Each of the 100 networks was initialized and trained
in the same way. RBF-to-output unit weights were initialized to small random values between 0.5 and
-0.5. Input-to-RBF unit weights were first randomized and then normalized so that the weight vectors
to each RBF unit were of unit length. Unsupervised, competitive training of the RBF units continued
for 100 "epochs" or complete sweeps through the set of 99 cases: 20 epochs with a learning rate (11)
of 0.1 followed by 80 epochs at 0.01 without momentum (0'). Supervised training using a learning
rate of 0.05 and momentum 0.9, was terminated based on cross-validation testing after 200 epochs.
Further training led to over-training and poorer generalization.

759

760

Rosenberg, Erel, and Atlan

the redistribution data. (For details, see (Erel et al., 1993).)
The combined network exhibited only a limited ability to distinguish between scar and
ischemia. Performance on scar detection was good (sens. 0.728 (75/103), spec. 0.878
(700{797?, but the sensitivity of the network on ischemia detection was only 0.185 (10/54).
This result may be explained, at least in part, by the much smaller number of ischemic regions included in the data set as compared with scars (54 versus 103).

4 Conclusions and Future Directions
We suspect that our major limitation is in defect sampling. In order that a statistical system
(networks or otherwise) generalize well to new cases, the data used in training must be
representative of the full population of data likely to be sampled. This is unlikely to happen
when the number of positive cases is on the order of 50, as was the case with ischemia,
since each possible defect location, plus all the possible combinations of locations must be
included.
A variant ofbackpropagation, called competitive backpropagation, has recently been developed which is claimed to generalize appropriately in the presence of multiple defects (Cho
and Reggia, 1993). Weights in this network are constrained to take on positive values,
so that diagnoses made by the system add constructively. In a standard backpropagation
network, multiple diseases can cancel each other out, due to complex interactions of both
positive and negative connection strengths. We are currently planning to investigate the
application of this learning algorithm to the problem of ischemia detection.
Other improvements and extensions include:
? Elicit confidence ratings. Expert visual interpretations could be augmented by
degree of confidence ratings. Highly ambiguous cases could be reduced in importance or eliminated. The ratings could also be used as additional targets for
the network6: cases indicated by the network with low levels of confidence would
require closer inspection by a physician. Initial results are promising in this regard.
? Provide additional information. We have not yet incorporated clinical history,
gender, and examination EKG. Clinical history has been found to have a profound
impact on interpretation of radiographs (Doubilet and Herman, 1981). The inclusion of these variables should allow the network to approximate more closely a
complete diagnosis, and boost the utility of the network in the clinical setting.
? Add constraints. Currently we do not utilize the angles that relate the three views.
It may be possible to build these angles in as constraints and thereby cut down on
the number of free network parameters.
? Expand application. Besides planar thallium, our approach may also be applied
to non-planar 3-D imaging technologies such as SPECT and other nuclear agents or
stress-inducing modalities such as dipyridamole. Preliminary results are promising in this regard.
6See (fesauro and Sejnowski, 1988) for a related idea.

A Neural Network that Learns to Interpret Myocardial Planar Thallium Scintigrams

Acknowledgements
The authors wish to thank Mr. Haim Karger for technical assistance, and the Departments
of Computer Science and Psychology at the Hebrew University for computational support.
We would also like to thank Drs. David Shechter, Moshe Bocher, Roland Chisin and the
staff of the Department of Medical Biophysics and Nuclear Medicine for their help, both
large and small, and two anonymous reviewers. Terry Sejnowski suggested our use of RBF
units.

References
Areeda, J., Train, K. v., Garcia, E. Y., Maddahi, J., Rosanki, A., Waxman, A., and Berman,
D. (1982). Improved analysis of segmental thallium-201 myocardial scintigrams:
Quantitation of distribution, washout, and redistribution. In Esser, P. D., editor, Digital
Imaging. Society of Nuclear Medicine, New York.
Artis, S., Mark, R, and Moody, G. (1991). Detection of atrial fibrillation using artificial
neural networks. In Computers in Cardiology, pages 173-176, Venice, Italy. IEEE,
IEEE Computer Society Press.
Baxt, W. (1991a). Use of an artificial neural network for data analysis in clinical decisionmaking: The diagnosis of acute coronary occlusion. Neural Computation, 2:480-489.
Baxt, W. (1991b). Use of an artificial neural network for the diagnosis of myocardial infarction. Annals of Internal Medicine, 115:843-848.
Beller, G. A. (1991). Myocardial perfusion imaging with thallium-201. In Marcus, M. L.,
Schelbert, H. R., Skorton, D. J., and Wolf, G. L., editors, Cardiac Imaging. W. B.
Sanders.
Cho, S. and Reggia, J. (1993). Multiple disorder diagnosis with adaptive competitive neural
networks. Artificial Intelligence in Medicine. To appear.
Cianfione, D., Carandente, 0., Fragasso, G., Margononato, A., Meloni, C., Rossetti, E.,
Gerundini, P., and Chiechia, S. L. (1990). A neural network based model of predicting
the probability of coronary lesion from myocardial perfusion SPECT data. In Proceedings of the 37th Annual Meeting of the Society of Nuclear Medicine, page 797.
Cios, K. J., Goodenday, L. S., Merhi, M., and Langenderfer, R. (1989). Neural networks in
detection of coronary artery disease. In Computers in Cardiology Conference, pages
33-37, Jerusalem, Israel. IEEE, IEEE Computer Society Press.
Cios, K. J., Shin, 1., and Goodenday, L. S. (1991). Using fuzzy sets to diagnose coronary
artery stenosis. Computer, pages 57-63.
Cuar6n, A., Acero, A., Cardena, M., Huerta, D., Rodriguez, A., and de Garay, R. (1980). Interobserver variability in the interpretation of myocardial images with Tc-99m-Iabeled
diphosponate and pyrophosphate. Journal of Nuclear Medicine, 21(1):1-9.
Datz; E, Gabor, E, Christian, P., Gullber, G., Menzel, C., and Morton, K. (1992). The use of
computer-assisted diagnosis in cardiac-perfusion nuclear medicine studies: A review.
Journal of Digital Imaging, 5(4):1-14.
Dawson, A., Austin, R, and Weinberg, D. (1991). Nuclear grading of breast carcinoma by
image analysis. American Journal of Clinical Pathology, 95(4):S29-S37.

761

762

Rosenberg, Erel, and Atlan

Doubilet, P. and Herman, P. (1981). Interpretation of radiographs: Effect of clinical history.
American Journal of Roentgenology, 137: 1055-1058.
Erel, J., Rosenberg, c., and Atlan, H. (1993). Neural network for automatic interpretation
of thallium scintigrams. In preparation.
Francisco, D. A., Collins, S. M., and et al., R. T. G. (1982). Tomographic thallium-201
myocardial perfusion scintigrams after maximal coronary artery vasodiliation with intravenous dipyridamole: Comparison of qualitative and quantitative approaches. Circulation, 66(2).
Franken Jr., E. A. and Berbaum, K. S. (1991). Perceptual aspects of cardiac imaging. In
Marcus, M. L., Schelbert, H. R., Skorton, D. J., and Wolf, G. L., editors, Cardiac
Imaging. W. B. Sanders.
Fujita, H., Katafuchi, T., Uehara, T., and Nishimura, T. (1992). Application of artificial
neural network to computer-aided diagnosis of coronary artery disease in myocardial
SPECT bull's-eye images. The Journal of Nuclear Medicine, 33(2):272-276.
Garcia, E. V. (1991). Physics and instrumentation of radionuclide imaging. In Marcus,
M. L., Schelbert, H. R., Skorton, D. J., and Wolf, G. L., editors, Cardiac Imaging. W.
B. Sanders.
Garcia, E. V., Maddahi, J., Berman, D. S., and Waxman, A. (1981). Space-time quantitation
of thallium-201 myocardial scintigraphy. Journal of Nuclear Medicine, 22:309-317.
Kippenhan, J., Barker, W., Pascal, S., and Duara, R. (1990). A neural-network classifier
applied to PET scans of normal and Alzheimer's disease (AD) patients. In The Proceedings of the 37th Annual Meeting of the Society of Nuclear Medicine, volume 31,
Washington, D.C.
Maddahi, J., Garcia, E. V., Berman, D. S., Waxman, A., Swan, H. J. C., and Forrester,
J. (1981). Improved noninvasive assessment of coronary artery disease by quantitative analysis of regional stress myocardial distribution and washout of thallium-20l.
Circulation, 64 :924-935.
Pohost, G. M. and Henzlova, M. J. (1990). The value of thallium-201 imaging. New
Eng land Journal of Medicine, 323(3): 190-192.
Porenta, G., Kundrat, S., Dorffner, G., Petta, P., Duit, J., and r, H. S. (19~0). Computer based
image interpretations of thallium- 201 scintigrams: Assessment of coronary artery
disease using the parallel distributed processing approach. In Proceedings of the 37th
Annual Meeting of the Society of Nuclear Medicine, page 825.
Rosenberg, C., Erel, J., and Atlan, H. (1993). A neural network that learns to interpret
myocardial planar thallium scintigrams. Neural Computation. To appear.
Rumelhart, D. and Zipser, D. (1986). Feature discovery by competitive learning. In Rumelhart, D. and McClelland, J., editors, Parallel Distributed Processing, volume 1, chapter 5, pages 151-193. MIT Press, Cambridge, Mass.
Tesauro, G. and Sejnowski, T. J. (1988). A parallel network that learns to play backgammon.
Technical Report CCSR-88-2, University of Illinois at Urbana-Champaign Center for
Complex Systems Research.
Widrow, B. and Hoff, M. (1960). Adaptive switching circuits. In 1960 IRE WESCON
Convention Record, volume 4, pages 96-104. IRE, New York.

PART X

IMPLEMENTATIONS


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4518-factoring-nonnegative-matrices-with-linear-programs.pdf

Factoring nonnegative matrices with linear programs

Victor Bittorf
bittorf@cs.wisc.edu

Benjamin Recht
brecht@cs.wisc.edu
Computer Sciences
University of Wisconsin

Christopher R?e
chrisre@cs.wisc.edu

Joel A. Tropp
Computing and Mathematical Sciences
California Institute of Technology
tropp@cms.caltech.edu

Abstract
This paper describes a new approach, based on linear programming, for computing nonnegative matrix factorizations (NMFs). The key idea is a data-driven
model for the factorization where the most salient features in the data are used to
express the remaining features. More precisely, given a data matrix X, the algorithm identifies a matrix C that satisfies X ? CX and some linear constraints.
The constraints are chosen to ensure that the matrix C selects features; these features can then be used to find a low-rank NMF of X. A theoretical analysis
demonstrates that this approach has guarantees similar to those of the recent NMF
algorithm of Arora et al. (2012). In contrast with this earlier work, the proposed
method extends to more general noise models and leads to efficient, scalable algorithms. Experiments with synthetic and real datasets provide evidence that the
new approach is also superior in practice. An optimized C++ implementation can
factor a multigigabyte matrix in a matter of minutes.

1

Introduction

Nonnegative matrix factorization (NMF) is a popular approach for selecting features in data [16?18,
23]. Many machine-learning and data-mining software packages (including Matlab [3], R [12], and
Oracle Data Mining [1]) now include heuristic computational methods for NMF. Nevertheless, we
still have limited theoretical understanding of when these heuristics are correct.
The difficulty in developing rigorous methods for NMF stems from the fact that the problem is
computationally challenging. Indeed, Vavasis has shown that NMF is NP-Hard [27]; see [4] for
further worst-case hardness results. As a consequence, we must instate additional assumptions on
the data if we hope to compute nonnegative matrix factorizations in practice.
In this spirit, Arora, Ge, Kannan, and Moitra (AGKM) have exhibited a polynomial-time algorithm
for NMF that is provably correct?provided that the data is drawn from an appropriate model, based
on ideas from [8]. The AGKM result describes one circumstance where we can be sure that NMF
algorithms are capable of producing meaningful answers. This work has the potential to make an
impact in machine learning because proper feature selection is an important preprocessing step for
many other techniques. Even so, the actual impact is damped by the fact that the AGKM algorithm
is too computationally expensive for large-scale problems and is not tolerant to departures from the
modeling assumptions. Thus, for NMF, there remains a gap between the theoretical exercise and the
actual practice of machine learning.
1

The present work presents a scalable, robust algorithm that can successfully solve the NMF problem
under appropriate hypotheses. Our first contribution is a new formulation of the nonnegative feature
selection problem that only requires the solution of a single linear program. Second, we provide
a theoretical analysis of this algorithm. This argument shows that our method succeeds under the
same modeling assumptions as the AGKM algorithm with an additional margin constraint that is
common in machine learning. We prove that if there exists a unique, well-defined model, then we
can recover this model accurately; our error bound improves substantially on the error bound for
the AGKM algorithm in the high SNR regime. One may argue that NMF only ?makes sense? (i.e.,
is well posed) when a unique solution exists, and so we believe our result has independent interest.
Furthermore, our algorithm can be adapted for a wide class of noise models.
In addition to these theoretical contributions, our work also includes a major algorithmic and experimental component. Our formulation of NMF allows us to exploit methods from operations research
and database systems to design solvers that scale to extremely large datasets. We develop an efficient
stochastic gradient descent (SGD) algorithm that is (at least) two orders of magnitude faster than the
approach of AGKM when both are implemented in Matlab. We describe a parallel implementation
of our SGD algorithm that can robustly factor matrices with 105 features and 106 examples in a few
minutes on a multicore workstation.
Our formulation of NMF uses a data-driven modeling approach to simplify the factorization problem. More precisely, we search for a small collection of rows from the data matrix that can be
used to express the other rows. This type of approach appears in a number of other factorization
problems, including rank-revealing QR [15], interpolative decomposition [20], subspace clustering [10, 24], dictionary learning [11], and others. Our computational techniques can be adapted to
address large-scale instances of these problems as well.

2

Separable Nonnegative Matrix Factorizations and Hott Topics

Notation. For a matrix M and indices i and j, we write Mi? for the ith row of M and M?j for the
jth column of M . We write Mij for the (i, j) entry.
Let Y be a nonnegative f ? n data matrix with columns indexing examples and rows indexing
features. Exact NMF seeks a factorization Y = F W where the feature matrix F is f ? r, where
the weight matrix W is r ? n, and both factors are nonnegative. Typically, r  min{f, n}.
Unless stated otherwise, we assume that each row of the data matrix Y is normalized so it sums to
one. Under this hypothesis, we may also assume that each row of F and of W also sums to one [4].
It is notoriously difficult to solve the NMF problem. Vavasis showed that it is NP-complete to decide
whether a matrix admits a rank-r nonnegative factorization [27]. AGKM proved that an exact NMF
algorithm can be used to solve 3-SAT in subexponential time [4].
The literature contains some mathematical analysis of NMF that can be used to motivate algorithmic
development. Thomas [25] developed a necessary and sufficient condition for the existence of a
rank-r NMF. More recently, Donoho and Stodden [8] obtained a related sufficient condition for
uniqueness. AGKM exhibited an algorithm that can produce a nonnegative matrix factorization
under a weaker sufficient condition. To state their results, we need a definition.
Definition 2.1 A set of vectors {v1 , . . . , vr } ? Rd is simplicial if no vector vi lies in the convex
hull of {vj : j 6= i}. The set of vectors is ?-robust simplicial if, for each i, the `1 distance from vi
to the convex hull of {vj : j 6= i} is at least ?. Figure 1 illustrates these concepts.
These ideas support the uniqueness results of Donoho and Stodden and the AGKM algorithm. Indeed, we can find an NMF of Y efficiently if Y contains a set of r rows that is simplicial and whose
convex hull contains the remaining rows.
Definition 2.2 An NMF Y = F W is called separable if the rows of W are simplicial and there is
a permutation matrix ? such that


Ir
?F =
.
(1)
M

2

Algorithm 1: AGKM: Approximably Separable
Nonnegative Matrix Factorization [4]
1: Initialize R = ?.
2: Compute the f ? f matrix D with Dij =
3:
4:
5:
6:
7:
8:
9:
10:

1

1
d1

kXi? ? Xj? k1 .
for k = 1, . . . f do
Find the set Nk of rows that are at least
5/? + 2 away from Xk? .
Compute the distance ?k of Xk? from
conv({Xj? : j ? Nk }).
if ?k > 2, add k to the set R.
end for
Cluster the rows in R as follows: j and k are
in the same cluster if Djk ? 10/? + 6.
Choose one element from each cluster to
yield W .
F = arg minZ?Rf ?r kX ? ZW k?,1

d1
2

2

d2

3

Figure 1: Numbered circles are hott topics. Their
convex hull (orange) contains the other topics (small
circles), so the data admits a separable NMF. The arrow d1 marks the `1 distance from hott topic (1) to the
convex hull of the other two hott topics; definitions of
d2 and d3 are similar. The hott topics are ?-robustly
simplicial when each di ? ?.

To compute a separable factorization of Y , we must first identify a simplicial set of rows from Y .
Afterward, we compute weights that express the remaining rows as convex combinations of this
distinguished set. We call the simplicial rows hott and the corresponding features hott topics.
This model allows us to express all the features for a particular instance if we know the values of
the instance at the simplicial rows. This assumption can be justified in a variety of applications. For
example, in text, knowledge of a few keywords may be sufficient to reconstruct counts of the other
words in a document. In vision, localized features can be used to predict gestures. In audio data, a
few bins of the spectrogram may allow us to reconstruct the remaining bins.
While a nonnegative matrix one encounters in practice might not admit a separable factorization, it
may be well-approximated by a nonnnegative matrix with separable factorization. AGKM derived an
algorithm for nonnegative matrix factorization of a matrix that is well-approximated by a separable
factorization. To state their result, we introduce a norm on f ? n matrices:
k?k?,1 := max

1?i?f

n
X

|?ij | .

j=1
2

?
Theorem 2.3 (AGKM [4]) Let  and ? be nonnegative constants satisfying  ? 20+13?
. Let X be
a nonnegative data matrix. Assume X = Y + ? where Y is a nonnegative matrix whose rows
have unit `1 norm, where Y = F W is a rank-r separable factorization in which the rows of W
are ?-robust simplicial, and where k?k?,1 ? . Then Algorithm 1 finds a rank-r nonnegative


? that satisfies the error bound 
?
factorization F? W
? 10/? + 7.

X ? F? W

?,1

In particular, the AGKM algorithm computes the factorization exactly when  = 0. Although
this method is guaranteed to run in polynomial time, it has many undesirable features. First, the
algorithm requires a priori knowledge of the parameters ? and . It may be possible to calculate
, but we can only estimate ? if we know which rows are hott. Second, the algorithm computes
all `1 distances between rows at a cost of O(f 2 n). Third, for every row in the matrix, we must
determine its distance to the convex hull of the rows that lie at a sufficient distance; this step requires
us to solve a linear program for each row of the matrix at a cost of ?(f n). Finally, this method is
intimately linked to the choice of the error norm k?k?,1 . It is not obvious how to adapt the algorithm
for other noise models. We present a new approach, based on linear programming, that overcomes
these drawbacks.

3

Main Theoretical Results: NMF by Linear Programming

This paper shows that we can factor an approximately separable nonnegative matrix by solving a
linear program. A major advantage of this formulation is that it scales to very large data sets.
3

d3

3

Algorithm 2 Separable Nonnegative Matrix Factorization by Linear Programming
Require: An f ? n nonnegative matrix Y with a rank-r separable NMF.
Ensure: An f ? r matrix F and r ? n matrix W with F ? 0, W ? 0, and Y = F W .
1: Find the unique C ? ?(Y ) to minimize pT diag(C) where p is any vector with distinct values.
2: Let I = {i : Cii = 1} and set W = YI? and F = C?I .

Here is the key observation: Suppose that Y is any f ? n nonnegative matrix that admits a rank-r
separable factorization Y = F W . If we pad F with zeros to form an f ? f matrix, we have


Ir 0
T
Y =?
?Y =: CY
M 0
We call the matrix C factorization localizing. Note that any factorization localizing matrix C is an
element of the polyhedral set
?(Y ) := {C ? 0 : CY = Y , Tr(C) = r, Cjj ? 1 ?j, Cij ? Cjj ?i, j}.
Thus, to find an exact NMF of Y , it suffices to find a feasible element of C ? ?(Y ) whose
diagonal is integral. This task can be accomplished by linear programming. Once we have such
a C, we construct W by extracting the rows of X that correspond to the indices i where Cii =
1. We construct the feature matrix F by extracting the nonzero columns of C. This approach is
summarized in Algorithm 2. In turn, we can prove the following result.
Theorem 3.1 Suppose Y is a nonnegative matrix with a rank-r separable factorization Y = F W .
Then Algorithm 2 constructs a rank-r nonnegative matrix factorization of Y .
As the theorem suggests, we can isolate the rows of Y that yield a simplicial factorization by solving
a single linear program. The factor F can be found by extracting columns of C.
3.1

Robustness to Noise

Suppose we observe a nonnegative matrix X whose rows sum to one. Assume that X = Y + ?
where Y is a nonnegative matrix whose rows sum to one, which has a rank-r separable factorization
Y = F W such that the rows of W are ?-robust simplicial, and where k?k?,1 ? . Define the
polyhedral set
n
o
?? (X) := C ? 0 : kCX ? Xk?,1 ? ?, Tr(C) = r, Cjj ? 1 ?j, Cij ? Cjj ?i, j
The set ?(X) consists of matrices C that approximately locate a factorization of X. We can prove
the following result.
Theorem 3.2 Suppose that X satisfies the assumptions stated in the previous paragraph. Furthermore, assume that for every row Yj,? that is not hott, we have the margin constraint
kYj,? ?Y


 i,? k ? d0


?
?
for all hott rows i. Then we can find a nonnegative factorization satisfying 
X ? F W 
? 2
?,1

2

0 ,? }
. Furthermore, this factorization correctly identifies the hott topics
provided that  < min{?d
9(r+1)
appearing in the separable factorization of Y .

Algorithm 3 requires the solution of two linear programs. The first minimizes a cost vector over
? . Afterward, the matrix F? can be found by setting
?2 (X). This lets us find W



?
F? = arg min 
X ? Z W
.
(2)

Z?0

?,1

Our robustness result requires a margin-type constraint assuming that the original configuration
consists either of duplicate hott topics, or topics that are reasonably far away from the hott topics. On
the other hand, under such a margin constraint, we can construct a considerably better approximation
that guaranteed by the AGKM algorithm. Moreover, unlike AGKM, our algorithm does not need to
know the parameter ?.
4

Algorithm 3 Approximably Separable Nonnegative Matrix Factorization by Linear Programming
Require: An f ? n nonnegative matrix X that satisfies the hypotheses of Theorem 3.2.
Ensure: An f ? r matrix F and r ? n matrix W with F ? 0, W ? 0, and kX ? F W k?,1 ? 2.
1: Find C ? ?2 (X) that minimizes pT diag C where p is any vector with distinct values.
2: Let I = {i : Cii = 1} and set W = XI? .
3: Set F = arg minZ?Rf ?r kX ? ZW k?,1

The proofs of Theorems 3.1 and 3.2 can be found in the b version of this paper [6]. The main idea
is to show that we can only represent a hott topic efficiently using the hott topic itself. Some earlier
versions of this paper contained incomplete arguments, which we have remedied. For a signifcantly
stronger robustness analysis of Algorithm 3, see the recent paper [13].
Having established these theoretical guarantees, it now remains to develop an algorithm to solve
the LP. Off-the-shelf LP solvers may suffice for moderate-size problems, but for large-scale matrix
factorization problems, their running time is prohibitive, as we show in Section 5. In Section 4, we
turn to describe how to solve Algorithm 3 efficiently for large data sets.
3.2

Related Work

Localizing factorizations via column or row subset selection is a popular alternative to direct factorization methods such as the SVD. Interpolative decomposition such as Rank-Revealing QR [15]
and CUR [20] have favorable efficiency properties as compared to factorizations (such as SVD) that
are not based on exemplars. Factorization localization has been used in subspace clustering and has
been shown to be robust to outliers [10, 24].
In recent work on dictionary learning, Esser et al. and Elhamifar et al. have proposed a factorization
localization solution to nonnegative matrix factorization using group sparsity techniques [9, 11].
Esser et al. prove asymptotic exact recovery in a restricted noise model, but this result requires
preprocessing to remove duplicate or near-duplicate rows. Elhamifar shows exact representative
recovery in the noiseless setting assuming no hott topics are duplicated. Our work here improves
upon this work in several aspects, enabling finite sample error bounds, the elimination of any need
to preprocess the data, and algorithmic implementations that scale to very large data sets.

4

Incremental Gradient Algorithms for NMF

The rudiments of our fast implementation rely on two standard optimization techniques: dual decomposition and incremental gradient descent. Both techniques are described in depth in Chapters
3.4 and 7.8 of Bertsekas and Tstisklis [5].
We aim to minimize pT diag(C) subject to C ? ?? (X). To proceed, form the Lagrangian
T

L(C, ?, w) = p diag(C) + ?(Tr(C) ? r) +

f
X

wi (kXi? ? [CX]i? k1 ? ? )

i=1

with multipliers ? and w ? 0. Note that we do not dualize out all of the constraints. The remaining
ones appear in the constraint set ?0 = {C : C ? 0, diag(C) ? 1, and Cij ? Cjj for all i, j}.
Dual subgradient ascent solves this problem by alternating between minimizing the Lagrangian over
the constraint set ?0 , and then taking a subgradient step with respect to the dual variables
wi ? wi + s (kXi? ? [C ? X]i? k1 ? ? ) and ? ? ? + s(Tr(C ? ) ? r)
where C ? is the minimizer of the Lagrangian over ?0 . The update of wi makes very little difference
in the solution quality, so we typically only update ?.
We minimize the Lagrangian using projected incremental gradient descent. Note that we can rewrite
the Lagrangian as
?
?
n
X
X
?
L(C, ?, w) = ?? 1T w ? ?r +
wj kXjk ? [CX]jk k1 + ?j (pj + ?)Cjj ? .
k=1

j?supp(X?k )

5

Algorithm 4 H OTTOPIXX: Approximate Separable NMF by Incremental Gradient Descent
Require: An f ? n nonnegative matrix X. Primal and dual stepsizes sp and sd .
Ensure: An f ? r matrix F and r ? n matrix W with F ? 0, W ? 0, and kX ? F W k?,1 ? 2.
1: Pick a cost p with distinct entries.
2: Initialize C = 0, ? = 0
3: for t = 1, . . . , Nepochs do
4:
for i = 1, . . . n do
5:
Choose k uniformly at random from [n].
T
6:
C ? C + sp ? sign(X?k ? CX?k )X?k
? sp diag(? ? (?1 ? p)).
7:
end for
8:
Project C onto ?0 .
9:
? ? ? + sd (Tr(C) ? r)
10: end for
11: Let I = {i : Cii = 1} and set W = XI? .
12: Set F = arg minZ?Rf ?r kX ? ZW k?,1

Here, supp(x) is the set indexing the entries where x is nonzero, and ?j is the number of nonzeros
in row j divided by n. The incremental gradient method chooses one of the n summands at random
and follows its subgradient. We then project the iterate onto the constraint set ?0 . The projection
onto ?0 can be performed in the time required to sort the individual columns of C plus a linear-time
operation. The full procedure is described in the extended version of this paper [6]. In the case
where we expect a unique solution, we can drop the constraint Cij ? Cjj , resulting in a simple
clipping procedure: set all negative items to zero and set any diagonal entry exceeding one to one.
In practice, we perform a tradeoff. Since the constraint Cij ? Cjj is used solely for symmetry
breaking, we have found empirically that we only need to project onto ?0 every n iterations or so.
This incremental iteration is repeated n times in a phase called an epoch. After each epoch, we
update the dual variables and quit after we believe we have identified the large elements of the
diagonal of C. Just as before, once we have identified the hott rows, we can form W by selecting
these rows of X. We can find F just as before, by solving (2). Note that this minimization can
also be computed by incremental subgradient descent. The full procedure, called H OTTOPIXX, is
described in Algorithm 4.
4.1

Sparsity and Computational Enhancements for Large Scale.

For small-scale problems, H OTTOPIXX can be implemented in a few lines of Matlab code. But for
the very large data sets studied in Section 5, we take advantage of natural parallelism and a host
of low-level optimizations that are also enabled by our formulation. As in any numerical program,
memory layout and cache behavior can be critical factors for performance. We use standard techniques: in-memory clustering to increase prefetching opportunities, padded data structures for better
cache alignment, and compiler directives to allow the Intel compiler to apply vectorization.
Note that the incremental gradient step (step 6 in Algorithm 4) only modifies the entries of C where
X?k is nonzero. Thus, we can parallelize the algorithm with respect to updating either the rows
or the columns of C. We store X in large contiguous blocks of memory to encourage hardware
prefetching. In contrast, we choose a dense representation of our localizing matrix C; this choice
trades space for runtime performance.
Each worker thread is assigned a number of rows of C so that all rows fit in the shared L3 cache.
Then, each worker thread repeatedly scans X while marking updates to multiple rows of C. We
repeat this process until all rows of C are scanned, similar to the classical block-nested loop join in
relational databases [22].

5

Experiments

Except for the speedup curves, all of the experiments were run on an identical configuration: a dual
Xeon X650 (6 cores each) machine with 128GB of RAM. The kernel is Linux 2.6.32-131.
6

1

1

1

0.6
0.4

hott
hott (fast)
hott (lp)
AGKM

0.2
20

?

40

hott
hott (fast)
AGKM

0.2
20

?

40

0.8
0.6
0.4

hott
hott (fast)
hott (lp)
AGKM

0.2
20

?

40

60

0.8
0.6
0.4

hott
hott (fast)
AGKM

0.2
0
0

60

1

(d)

Pr(RMSE?? RMSEmin)

Pr(RMSE?? RMSEmin)

0.4

0
0

60

1

0
0

0.6

(c)

100

?

200

0.8
0.6
0.4

hott
hott (fast)
AGKM

0.2
0
0

300

1

(e)

20

?

40

60

(f)
Pr(error?? errormin)

0
0

0.8

Pr(time?? timemin)

0.8

(b)
Pr(error?? errormin)

Pr(error?? errormin)

(a)

0.8
0.6
0.4

hott
hott (fast)
AGKM

0.2
0
0

20

?

40

60

Figure 2: Performance profiles for synthetic data. (a) (?, 1)-norm error for 40 ? 400 sized instances and
(b) all instances. (c) is the performance profile for running time on all instances. RMSE performance profiles
for the (d) small scale and (e) medium scale experiments. (f) (?, 1)-norm error for the ? ? 1. In the noisy
examples, even 4 epochs of H OTTOPIXX is sufficient to obtain competitive reconstruction error.

In small-scale, synthetic experiments, we compared H OTTOPIXX to the AGKM algorithm and the
linear programming formulation of Algorithm 3 implemented in Matlab. Both AGKM and Algorithm 3 were run using CVX [14] coupled to the SDPT3 solver [26]. We ran H OTTOPIXX for 50
epochs with primal stepsize 1e-1 and dual stepsize 1e-2. Once the hott topics were identified, we fit
F using two cleaning epochs of incremental gradient descent for all three algorithms.
To generate our instances, we sampled r hott topics uniformly from the unit simplex in Rn . These
topics were duplicated d times. We generated the remaining f ? r(d + 1) rows to be random convex
combinations of the hott topics, with the combinations selected uniformly at random. We then
?2
added noise with (?, 1)-norm error bounded by ? ? 20+13?
. Recall that AGKM algorithm is only
guaranteed to work for ? < 1. We ran with f ? {40, 80, 160}, n ? {400, 800, 1600}, r ? {3, 5, 10},
d ? {0, 1, 2}, and ? ? {0.25, 0.95, 4, 10, 100}. Each experiment was repeated 5 times.
Because we ran over 2000 experiments with 405 different parameter settings, it is convenient to use
the performance profiles to compare the performance of the different algorithms [7]. Let P be the
set of experiments and A denote the set of different algorithms we are comparing. Let Qa (p) be
the value of some performance metric of the experiment p ? P for algorithm a ? A. Then the
performance profile at ? for a particular algorithm is the fraction of the experiments where the value
of Qa (p) lies within a factor of ? of the minimal value of minb?A Qb (p). That is,
Pa (? ) =

# {p ? P : Qa (p) ? ? mina0 ?A Qa0 (p)}
.
#(P)

In a performance profile, the higher a curve corresponding to an algorithm, the more often it outperforms the other algorithms. This gives a convenient way to contrast algorithms visually.
Our performance profiles are shown in Figure 2. The first two figures correspond to experiments
with f = 40 and n = 400. The third figure is for the synthetic experiments with all other values
of f and n. In terms of (?, 1)-norm error, the linear programming solver typically achieves the
lowest error. However, using SDPT3, it is prohibitively slow to factor larger matrices. On the other
hand, H OTTOPIXX achieves better noise performance than the AGKM algorithm in much less time.
Moreover, the AGKM algorithm must be fed the values of  and ? in order to run. H OTTOPIXX does
not require this information and still achieves about the same error performance.
We also display a graph for running only four epochs (hott (fast)). This algorithm is by far the fastest
algorithm, but does not achieve as optimal a noise performance. For very high levels of noise,
however, it achieves a lower reconstruction error than the AGKM algorithm, whose performance
7

data set
jumbo
clueweb
RCV1

features
1600
44739
47153

documents
64000
351849
781265

nonzeros
1.02e8
1.94e7
5.92e7

size (GB)
2.7
0.27
1.14

time (s)
338
478
430

Table 1: Description of the large data sets. Time is to find 100 hott topics on the 12 core machines.
40

16

jumbo
clueweb

20

25

class error

RMSE

speedup

30

14

30

12
10
8

10

20
15
10

6
5
0
0

10

20

threads

30

40

4
0

500

1000 1500 2000 2500

number of topics

0

1000 2000 3000 4000 5000

number of topics

Figure 3: (left) The speedup over a serial implementation for H OTTOPIXX on the jumbo and clueweb data
sets. Note the superlinear speedup for up to 20 threads. (middle) The RMSE for the clueweb data set. (right)
The test error on RCV1 CCAT class versus the number of hott topics. The horizontal line indicates the test
error achieved using all of the features.

degrades once ? approaches or exceeds 1 (Figure 2(f)). We also provide performance profiles for
the root-mean-square error of the nonnegative matrix factorizations (Figure 2 (d) and (e)). The
performance is qualitatively similar to that for the (?, 1)-norm.
We also coded H OTTOPIXX in C++, using the design principles described in Section 4.1, and ran on
three large data sets. We generated a large synthetic example (jumbo) as above with r = 100. We
generated a co-occurrence matrix of people and places from the ClueWeb09 Dataset [2], normalized
by TFIDF. We also used H OTTOPIXX to select features from the RCV1 data set to recognize the
class CCAT [19]. The statistics for these data sets can be found in Table 1.
In Figure 3 (left), we plot the speed-up over a serial implementation. In contrast to other parallel
methods that exhibit memory contention [21], we see superlinear speed-ups for up to 20 threads
due to hardware prefetching and cache effects. All three of our large data sets can be trained in
minutes, showing that we can scale H OTTOPIXX on both synthetic and real data. Our algorithm is
able to correctly identify the hott topics on the jumbo set. For clueweb, we plot the RMSE Figure 3
(middle). This curve rolls off quickly for the first few hundred topics, demonstrating that our algorithm may be useful for dimensionality reduction in Natural Language Processing applications. For
RCV1, we trained an SVM on the set of features extracted by H OTTOPIXX and plot the misclassification error versus the number of topics in Figure 3 (right). With 1500 hott topics, we achieve 7%
misclassification error as compared to 5.5% with the entire set of features.

6

Discussion

This paper provides an algorithmic and theoretical framework for analyzing and deploying any factorization problem that can be posed as a linear (or convex) factorization localizing program. Future
work should investigate the applicability of H OTTOPIXX to other factorization localizing algorithms,
such as subspace clustering, and should revisit earlier theoretical bounds on such prior art.
Acknowledgments
The authors would like to thank Sanjeev Arora, Michael Ferris, Rong Ge, Nicolas Gillis, Ankur
Moitra, and Stephen Wright for helpful suggestions. BR is generously supported by ONR award
N00014-11-1-0723, NSF award CCF-1139953, and a Sloan Research Fellowship. CR is generously
supported by NSF CAREER award under IIS-1054009, ONR award N000141210041, and gifts or
research awards from American Family Insurance, Google, Greenplum, and Oracle. JAT is generously supported by ONR award N00014-11-1002, AFOSR award FA9550-09-1-0643, and a Sloan
Research Fellowship.
8

References
[1] docs.oracle.com/cd/B28359_01/datamine.111/b28129/algo_nmf.htm.
[2] lemurproject.org/clueweb09/.
[3] www.mathworks.com/help/toolbox/stats/nnmf.html.
[4] S. Arora, R. Ge, R. Kannan, and A. Moitra. Computing a nonnegative matrix factorization ? provably. To
appear in STOC 2012. Preprint available at \arxiv.org/abs/1111.0952, 2011.
[5] D. P. Bertsekas and J. N. Tsitsiklis. Parallel and Distributed Computation: Numerical Methods. Athena
Scientific, Belmont, MA, 1997.
[6] V. Bittorf, B. Recht, C. R?e, and J. A. Tropp. Factoring nonnegative matrices with linear programs. Technical Report. Available at arxiv.org/1206.1270, 2012.
[7] E. D. Dolan and J. J. Mor?e. Benchmarking optimization software with performance profiles. Mathematical Programming, Series A, 91:201?213, 2002.
[8] D. Donoho and V. Stodden. When does non-negative matrix factorization give a correct decomposition
into parts? In Advances in Neural Information Processing Systems, 2003.
[9] E. Elhamifar, G. Sapiro, and R. Vidal. See all by looking at a few: Sparse modeling for finding representative objects. In Proceedings of CVPR, 2012.
[10] E. Elhamifar and R. Vidal. Sparse subspace clustering. In Proceedings of the IEEE Conference on
Computer Vision and Pattern Recognition, 2009.
[11] E. Esser, M. M?oller, S. Osher, G. Sapiro, and J. Xin. A convex model for non-negative matrix factorization
and dimensionality reduction on physical space. IEEE Transactions on Image Processing, 2012. To
appear. Preprint available at arxiv.org/abs/1102.0844.
[12] R. Gaujoux and C. Seoighe. NMF: A flexible R package for nonnegative matrix factorization. BMC
Bioinformatics, 11:367, 2010. doi:10.1186/1471-2105-11-367.
[13] N. Gillis. Robustness analysis of hotttopixx, a linear programming model for factoring nonnegative matrices. arxiv.org/1211.6687, 2012.
[14] M. Grant and S. Boyd. CVX: Matlab software for disciplined convex programming, version 1.21. http:
//cvxr.com/cvx, May 2010.
[15] M. Gu and S. C. Eisenstat. Efficient algorithms for computing a strong rank-revealing QR factorization.
SIAM Journal on Scientific Computing, 17:848?869, 1996.
[16] T. Hofmann. Probabilistic latent semantic indexing. In Proceedings of the 22nd Annual International
SIGIR Conference on Research and Development in Information Retrieval, 1999.
[17] D. D. Lee and H. S. Seung. Learning the parts of objects by non-negative matrix factorization. Nature,
401:788?791, 1999.
[18] D. D. Lee and H. S. Seung. Algorithms for non-negative matrix factorization. In Advances in Neural
Information Processing Systems, 2001.
[19] D. Lewis, Y. Yang, T. Rose, and F. Li. RCV1: A new benchmark collection for text categorization
research. Journal of Machine Learning Research, 5:361?397, 2004.
[20] M. W. Mahoney and P. Drineas. CUR matrix decompositions for improved data analysis. Proceedings of
the National Academy of Sciences, 106:697?702, 2009.
[21] F. Niu, B. Recht, C. R?e, and S. J. Wright. HOGWILD!: A lock-free approach to parallelizing stochastic
gradient descent. In Advances in Neural Information Processing Systems, 2011.
[22] L. D. Shapiro. Join processing in database systems with large main memories. ACM Transactions on
Database Systems, 11(3):239?264, 1986.
[23] P. Smaragdis. Non-negative matrix factorization for polyphonic music transcription. In IEEE Workshop
on Applications of Signal Processing to Audio and Acoustics, pages 177?180, 2003.
[24] M. Soltanolkotabi and E. J. Cand`es. A geometric analysis of subspace clustering with outliers. Preprint
available at arxiv.org/abs/1112.4258, 2011.
[25] L. B. Thomas. Problem 73-14, rank factorization of nonnegative matrices. SIAM Review, 16(3):393?394,
1974.
[26] K. C. Toh, M. Todd, and R. H. T?ut?unc?u.
SDPT3:
ware
package
for
semidefinite-quadratic-linear
programming.
http://www.math.nus.edu.sg/?mattohkc/sdpt3.html.

A

MATLAB
Available

softfrom

[27] S. A. Vavasis. On the complexity of nonnegative matrix factorization. SIAM Joural on Optimization,
20(3):1364?1377, 2009.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 3254-object-recognition-by-scene-alignment.pdf

Object Recognition by Scene Alignment

Bryan C. Russell Antonio Torralba Ce Liu Rob Fergus William T. Freeman
Computer Science and Artificial Intelligence Laboratory
Massachusetts Institute of Technology
Cambrige, MA 02139 USA
{brussell,torralba,celiu,fergus,billf}@csail.mit.edu

Abstract
Current object recognition systems can only recognize a limited number of object
categories; scaling up to many categories is the next challenge. We seek to build
a system to recognize and localize many different object categories in complex
scenes. We achieve this through a simple approach: by matching the input image, in an appropriate representation, to images in a large training set of labeled
images. Due to regularities in object identities across similar scenes, the retrieved
matches provide hypotheses for object identities and locations. We build a probabilistic model to transfer the labels from the retrieval set to the input image. We
demonstrate the effectiveness of this approach and study algorithm component
contributions using held-out test sets from the LabelMe database.

1

Introduction

The recognition of objects in a scene often consists of matching representations of image regions
to an object model while rejecting background regions. Recent examples of this approach include
aligning pictorial cues [4], shape correspondence [1], and modeling the constellation of parts [5].
Other models, exploiting knowledge of the scene context in which the objects reside, have proven
successful in boosting object recognition performance [18, 20, 15, 7, 13]. These methods model the
relationship between scenes and objects and allow information transfer across the two.
Here, we exploit scene context using a different approach: we formulate the object detection problem as one of aligning elements of the entire scene to a large database of labeled images. The
background, instead of being treated as a set of outliers, is used to guide the detection process. Our
approach relies on the observation that when we have a large enough database of labeled images, we
can find with high probability some images in the database that are very close to the query image
in appearance, scene contents, and spatial arrangement [6, 19]. Since the images in the database
are partially labeled, we can transfer the knowledge of the labeling to the query image. Figure 1
illustrates this idea. With these assumptions, the problem of object detection in scenes becomes a
problem of aligning scenes. The main issues are: (1) Can we find a big enough dataset to span the
required large number of scene configurations? (2) Given an input image, how do we find a set of
images that aligns well with the query image? (3) How do we transfer the knowledge about objects
contained in the labels?
The LabelMe dataset [14] is well-suited for this task, having a large number of images and labels
spanning hundreds of object categories. Recent studies using non-parametric methods for computer
vision and graphics [19, 6] show that when a large number of images are available, simple indexing
techniques can be used to retrieve images with object arrangements similar to those of a query image.
The core part of our system is the transfer of labels from the images that best match the query image.
We assume that there are commonalities amongst the labeled objects in the retrieved images and we
cluster them to form candidate scenes. These scene clusters give hints as to what objects are depicted
1

screen 2

desk 3
mousepad 2

keyboard 2

(a) Input image

(b) Images with similar scene
configuration

mouse 1

(c) Output image with object
labels transferred

Figure 1:

Overview of our system. Given an input image, we search for images having a similar scene
configuration in a large labeled database. The knowledge contained in the object labels for the best matching
images is then transfered onto the input image to detect objects. Additional information, such as depth-ordering
relationships between the objects, can also be transferred.

Figure 2: Retrieval set images. Each of the two rows depicts an input image (on the left) and 30 images from
the LabelMe dataset [14] that best match the input image using the gist feature [12] and L1 distance (the images
are sorted by their distances in raster order). Notice that the retrieved images generally belong to similar scene
categories. Also the images contain mostly the same object categories, with the larger objects often matching
in spatial location within the image. Many of the retrieved images share similar geometric perspective.

in the query image and their likely location. We describe a relatively simple generative model for
determining which scene cluster best matches the query image and use this to detect objects.
The remaining sections are organized as follows: In Section 2, we describe our representation for
scenes and objects. We formulate a model that integrates the information in the object labels with
object detectors in Section 3. In Section 4, we extend this model to allow clustering of the retrieved
images based on the object labels. We show experimental results of our system output in Section 5,
and conclude in Section 6.

2

Matching Scenes and Objects with the Gist Feature

We describe the gist feature [12], which is a low dimensional representation of an image region
and has been shown to achieve good performance for the scene recognition task when applied to an
entire image. To construct the gist feature, an image region is passed through a Gabor filter bank
comprising 4 scales and 8 orientations. The image region is divided into a 4x4 non-overlapping grid
and the output energy of each filter is averaged within each grid cell. The resulting representation
is a 4 ? 8 ? 16 = 512 dimensional vector. Note that the gist feature preserves spatial structure
information and is similar to applying the SIFT descriptor [9] to the image region.
We consider the task of retrieving a set of images (which we refer to as the retrieval set) that closely
matches the scene contents and geometrical layout of an input image. Figure 2 shows retrieval sets
for two typical input images using the gist feature. We show the top 30 closest matching images
from the LabelMe database based on the L1-norm distance, which is robust to outliers. Notice that
the gist feature retrieves images that match the scene type of the input image. Furthermore, many
of the objects depicted in the input image appear in the retrieval set, with the larger objects residing
in approximately the same spatial location relative to the image. Also, the retrieval set has many
2

images that share a similar geometric perspective. Of course, not every retrieved image matches
well and we account for outliers in Section 4.

3 Utilizing Retrieval Set
Images for Object Detection

1

0.95

screen

0.9

SVM (local appearance)

We evaluate the ability of the retrieval
set to predict the presence of objects in
the input image. For this, we found a
retrieval set of 200 images and formed
a normalized histogram (the histogram
entries sum to one) of the object categories that were labeled. We compute
performance for object categories with
at least 200 training examples and that
appear in at least 15 test images. We
compute the area under the ROC curve
for each object category. As a comparison, we evaluate the performance
of an SVM applied to gist features by
using the maximal score over a set of
bounding boxes extracted from the image. The area under ROC performance
of the retrieval set versus the SVM is
shown in Figure 3 as a scatter plot, with
each point corresponding to a tested object category. As a guide, a diagonal
line is displayed; those points that reside above the diagonal indicate better
SVM performance (and vice versa). Notice that the retrieval set predicts well
the objects present in the input image
and outperforms the detectors based on
local appearance information (the SVM)
for most object classes.

0.85

sidewalk
road
mouse
head
keyboard
phone
mousepad
table bookshelf
lampspeaker motorbike
pole cup
cabinet
mug
blindbottle
paper book
car
chair
streetlight
plant
tree
person
window
door
sky

0.8

0.75

0.7

0.65

0.6

0.55

0.5
0.5

0.55

0.6

0.65

0.7

0.75

0.8

0.85

0.9

0.95

1

Retrieval set

Figure 3: Evaluation of the goodness of the retrieval set by
how well it predicts which objects are present in the input image. We build a simple classifier based on object counts in the
retrieval set as provided by their associated LabelMe object labels. We compare this to detection based on local appearance
alone using an SVM applied to bounding boxes in the input image (the maximal score is used). The area under the ROC curve
is computed for many object categories for the two classifiers.
Performance is shown as a scatter plot where each point represents an object category. Notice that the retrieval set predicts
well object presence and in a majority cases outperforms the
SVM output, which is based only on local appearance.

In Section 2, we observed that the set of labels corresponding to images that best match an input
image predict well the contents of the input image. In this section, we will describe a model that
integrates local appearance with object presence and spatial likelihood information given by the
object labels belonging to the retrieval set.
We wish to model the relationship between object categories o, their spatial location x within an
image, and their appearance g. For a set of N images, each having Mi object proposals over L
object categories, we assume a joint model that factorizes as follows:
p(o, x, g|?, ?, ?) =

Mi X
N Y
1
Y

p(oi,j |hi,j , ?) p(xi,j |oi,j , hi,j , ?) p(gi,j |oi,j , hi,j , ?)

(1)

i=1 j=1 hi,j =0

We assume that the joint model factorizes as a product of three terms: (i) p(oi,j |hi,j = m, ?m ), the
likelihood of which object categories will appear in the image, (ii) p(xi,j |oi,j = l, hi,j = m, ?m,l ),
the likely spatial locations of observing object category l in the image, and (iii) p(gi,j |oi,j = l, hi,j =
m, ?m,l ), the appearance likelihood of object category l. We let hi,j = 1 indicate whether object
category oi,j is actually present in location xi,j (hi,j = 0 indicates absence). Figure 4 depicts the
above as a graphical model. We use plate notation, where the variable nodes inside a plate are
duplicated based on the counts depicted in the top-left corner of the plate.
We instantiate the model as follows. The spatial location of objects are parameterized as bounding
y
h
x
w w
boxes xi,j = (cxi,j , cyi,j , cw
i,j , ci,j ) where (ci,j , ci,j ) is the centroid and (ci,j ,ci,j ) is the width and
3

height (bounding boxes are extracted from object labels by tightly cropping the polygonal annotation). Each component of xi,j is normalized with respect to the image to lie in [0, 1]. We assume ?m
are multinomial parameters and ?m,l = (?m,l , ?m,l ) are Gaussian means and covariances over the
bounding box parameters. Finally, we assume gi,j is the output of a trained SVM applied to a gist
feature g?i,j . We let ?m,l parameterize the logistic function (1 + exp(??m,l [1 gi,j ]T ))?1 .
The parameters ?m,l are learned offline by first
training SVMs for each object class on the set
N
of all labeled examples of object class l and a
Mi
f0,1g
set of distractors. We then fit logistic functions
h
o
?
?m
to the positive and negative examples of each
i,j
?
i,j
class. We learn the parameters ?m and ?m,l
f0,1g
online using the object labels corresponding to
L
L
gi,j
?m,l
xi,j
?m,l
the retrieval set. These are learned by sim?
ply counting the object class occurrences and
fitting Gaussians to the bounding boxes corre- Figure 4: Graphical model that integrates information about which objects are likely to be present in the
sponding to the object labels.
image o, their appearance g, and their likely spatial lo-

For the input image, we wish to infer the latent cation x. The parameters for object appearance ? are
variables hi,j corresponding to a dense sam- learned offline using positive and negative examples for
pling of all possible bounding box locations each object class. The parameters for object presence
xi,j and object classes oi,j using the learned likelihood ? and spatial location ? are learned online
parameters ?m , ?m,l , and ?m,l . For this, we from the retrieval set. For all possible bounding boxes
compute the postierior distribution p(hi,j = in the input image, we wish to infer h, which indicates
m|oi,j = l, xi,j , gi,j , ?m , ?m,l , ?m,l ), which is whether an object is present or absent.
proportional to the product of the three learned distributions, for m = {0, 1}.
The procedure outlined here allows for significant computational savings over naive application of
an object detector. Without finding similar images that match the input scene configuration, we
would need to apply an object detector densely across the entire image for all object categories. In
contrast, our model can constrain which object categories to look for and where. More precisely,
we only need to consider object categories with relatively high probability in the scene model and
bounding boxes within the range of the likely search locations. These can be decided based on
thresholds. Also note that the conditional independences implied by the graphical model allows us
to fit the parameters from the retrieval set and train the object detectors separately.
Note that for tractability, we assume Dirichlet and Normal-Inverse-Wishart conjugate prior distributions over ?m and ?m,l with hyperparemters ? and ? = (?, ?, ?, ?) (expected mean ?, ? pseudocounts on the scale of the spatial observations, ? degrees of freedom, and sample covariance ?).
Furthermore, we assume a Bernoulli prior distribution over hi,j parameterized by ? = 0.5. We
hand-tuned the remaining parameters in the model. For hi,j = 0, we assume the noninformative
distributions oi,j ? U nif orm(1/L) and each component of xi,j ? U nif orm(1).

4

Clustering Retrieval Set Images for Robustness to Mismatches

While many images in the retrieval set match the input image scene configuration and contents,
there are also outliers. Typically, most of the labeled objects in the outlier images are not present
in the input image or in the set of correctly matched retrieval images. In this section, we describe
a process to organize the retrieval set images into consistent clusters based on the co-occurrence of
the object labels within the images. The clusters will typically correspond to different scene types
and/or viewpoints. The task is to then automatically choose the cluster of retrieval set images that
will best assist us in detecting objects in the input image.
We augment the model of Section 3 by assigning each image to a latent cluster si . The cluster assignments are distributed according to the mixing weights ?. We depict the model in Figure 5(a).
Intuitively, the model finds clusters using the object labels oi,j and their spatial location xi,j within
the retrieved set of images. To automatically infer the number of clusters, we use a Dirichlet Process
prior on the mixing weights ? ? Stick(?), where Stick(?) is the stick-breaking process of Grif4

N

si

?

?

Cluster counts

Input image

1

Mi

60

?k,m

oi,j

Counts

f0,1g

hi,j

?

?

40
20

f0,1g

L

L

?m,l

gi,j

xi,j

0

?k,m,l

?
(b)

(a)

Cluster 1

Cluster 2

Cluster 3

1

2 3 4
Clusters

5

(c)

Cluster 4

Cluster 5

(d)

(e)

0.05

0.05
0
w
w ch all
in ai
do r
pi flo w
ct or
u
ca tabre
bi le
n
la et
bomp
ok

sc
ke rdeen
yb e
m oask
bo ousrd
okchae
sh ir
e
peflo lf
porsoor
st n
er

0

0.2

0.8

0.15

0.6

0.1

0.1

0.4

0.05

0.05

0.2

0

0

0
pe
rs
be bon
ds ag
i
dde
fu ish
rn fo
ga itu ot
r re
glden
heass
ad

0.1

(f)

0.2
0.15

t
plree
an
c sk t
gr flolocy
ee w k
ne er
be lanry
r d
brries
us
h

0.1

w
sidindca
r
buew ow
ildalk
roing
pe sad
de t ky
do str ree
or ian
w
ay

0.2
0.15

(g)

Figure 5: (a) Graphical model for clustering retrieval set images using their object labels. We extend the
model of Figure 4 to allow each image to be assigned to a latent cluster si , which is drawn from mixing weights
?. We use a Dirichlet process prior to automatically infer the number of clusters. We illustrate the clustering
process for the retrieval set corresponding to the input image in (b). (c) Histogram of the number of images
assigned to the five clusters with highest likelihood. (d) Montages of retrieval set images assigned to each
cluster, along with their object labels (colors show spatial extent), shown in (e). (f) The likelihood of an object
category being present in a given cluster (the top nine most likely objects are listed). (g) Spatial likelihoods for
the objects listed in (f). Note that the montage cells are sorted in raster order.

fiths, Engen, and McCloskey [8, 11, 16] with concentration parameter ?. In the Chinese restaurant
analogy, the different clusters correspond to tables and the parameters for object presence ?k and
spatial location ?k are the dishes served at a given table. An image (along with its object labels)
corresponds to a single customer that is seated at a table.
We illustrate the clustering process for a retrieval set belonging to the input image in Figure 5(b).
The five clusters with highest likelihood are visualized in the columns of Figure 5(d)-(g). Figure 5(d)
shows montages of retrieval images with highest likelihood that were assigned to each cluster. The
total number of retrieval images that were assigned to each cluster are shown as a histogram in
Figure 5(c). The number of images assigned to each cluster is proportional to the cluster mixing
weights, ?. Figure 5(e) depicts the object labels that were provided for the images in Figure 5(d),
with the colors showing the spatial extent of the object labels. Notice that the images and labels
belonging to each cluster share approximately the same object categories and geometrical configuration. Also, the cluster that best matches the input image tends to have the highest number of
retrieval images assigned to it. Figure 5(f) shows the likelihood of objects that appear in the cluster
5

(the nine objects with highest likelihood are shown). This corresponds to ? in the model. Figure 5(g)
depicts the spatial distribution of the object centroid within the cluster. The montage of nine cells
correspond to the nine objects listed in Figure 5(f), sorted in raster order. The spatial distributions
illustrate ?. Notice that typically at least one cluster predicts well the objects contained in the input
image, in addition to their location, via the object likelihoods and spatial distributions.
To learn ?k and ?k , we use a Rao-Blackwellized Gibbs sampler to draw samples from the posterior
distribution over si given the object labels belonging to the set of retrieved images. We ran the
Gibbs sampler for 100 iterations. Empirically, we observed relatively fast convergence to a stable
solution. Note that improved performance may be achieved with variational inference for Dirichlet
Processes [10, 17]. We manually tuned all hyperparameters using a validation set of images, with
concentration parameter ? = 100 and spatial location parameters ? = 0.1, ? = 0.5, ? = 3, and
? = 0.01 across all bounding box parameters (with the exception of ? = 0.1 for the horizontal
centroid location, which reflects less certainty a priori about the horizontal location of objects). We
used a symmetric Dirichlet hyperparameter with ?l = 0.1 across all object categories l.
For final object detection, we use the learned parameters ?, ?, and ? to infer hi,j . Since si and hi,j
are latent random variables for the input image, we perform hard EM by marginalizing over hi,j to
infer the best cluster s?i . We then in turn fix s?i and infer hi,j , as outlined in Section 3.

5

Experimental Results

In this section we show qualitative and quantitative results for our model. We use a subset of the
LabelMe dataset for our experiments, discarding spurrious and nonlabeled images. The dataset is
split into training and test sets. The training set has 15691 images and 105034 annotations. The
test set has 560 images and 3571 annotations. The test set comprises images of street scenes and
indoor office scenes. To avoid overfitting, we used street scene images that were photographed in
a different city from the images in the training set. To overcome the diverse object labels provided
by users of LabelMe, we used WordNet [3] to resolve synonyms. For object detection, we extracted
3809 bounding boxes per image. For the final detection results, we used non-maximal suppression.
Example object detections from our system are shown in Figure 6(b),(d),(e). Notice that our system
can find many different objects embedded in different scene type configurations. When mistakes
are made, the proposed object location typically makes sense within the scene. In Figure 6(c), we
compare against a baseline object detector using only appearance information and trained with a
linear kernel SVM. Thresholds for both detectors were set to yield a 0.5 false positive rate per image
for each object category (?1.3e-4 false positives per window). Notice that our system produces
more detections and rejects objects that do not belong to the scene. In Figure 6(e), we show typical
failures of the system, which usually occurs when the retrieval set is not correct or an input image is
outside of the training set.
In Figure 7, we show quantitative results for object detection for a number of object categories.
We show ROC curves (plotted on log-log axes) for the local appearance detector, the detector from
Section 3 (without clustering), and the full system with clustering. We scored detections using the
PASCAL VOC 2006 criteria [2], where the outputs are sorted from most confident to least and the
ratio of intersection area to union area is computed between an output bounding box and groundtruth bounding box. If the ratio exceeds 0.5, then the output is deemed correct and the ground-truth
label is removed. While this scoring criteria is good for some objects, other objects are not well
represented by bounding boxes (e.g. buildings and sky).
Notice that the detectors that take into account context typically outperforms the detector using local
appearance only. Also, clustering does as well and in some cases outperforms no clustering. Finally,
the overall system sometimes performs worse for indoor scenes. This is due to poor retrieval set
matching, which causes a poor context model to be learned.

6

Conclusion

We presented a framework for object detection in scenes based on transferring knowledge about
objects from a large labeled image database. We have shown that a relatively simple parametric
6

(a)

sky

wall
wall
screen

sky
tree
building tree

(b)

road

road

car

car

car

car

keyboard

road

sky

keyboard

building
sky

wall

sky

building
sidewalk

(c)

sky
window

(d)

car

car

chair table
car
keyboard
road

tabletable
keyboard keyboard
keyboard
chair
keyboard

road

screen
building
table

table road
keyboard

window
window
person
person
person

car

wall

road

car

car

car
sidewalk

car
road

car

sky

sky
window screen screen

(e)

building building
chair
road

keyboard

Figure 6: (a) Input images. (b) Object detections from our system combining scene alignment with local
detection. (c) Object detections using appearance information only with an SVM. Notice that our system
detects more objects and rejects out-of-context objects. (d) More outputs from our system. Notice that many
different object categories are detected across different scenes. (e) Failure cases for our system. These often
occur when the retrieval set is incorrect.

model, trained on images loosely matching the spatial configuration of the input image, is capable
of accurately inferring which objects are depicted in the input image along with their location. We
showed that we can successfully detect a wide range of objects depicted in a variety of scene types.

7

Acknowledgments

This work was supported by the National Science Foundation Grant No. 0413232, the National
Geospatial-Intelligence Agency NEGI-1582-04-0004, and the Office of Naval Research MURI
Grant N00014-06-1-0734.

References
[1] A. Berg, T. Berg, and J. Malik. Shape matching and object recognition using low distortion correspondence. In CVPR, volume 1, pages 26?33, June 2005.
[2] M. Everingham, A. Zisserman, C.K.I. Williams, and L. Van Gool. The pascal visual object classes
challenge 2006 (voc 2006) results. Technical report, September 2006. The PASCAL2006 dataset can be
downloaded at http : //www.pascal ? network.org/challenges/VOC/voc2006/.

7

tree (531)

0

?3

10

?2

10

?1

car (138)

0

?3

10

?2

10

10

?1

10

road (232)

?3

10

?2

10

?1

screen (268)

0

10

10

?2

10

?1

sky (144)

0

?3

10

?2

10

10

?1

10

bookshelf (47)

?4

10

?3

10

?2

10

?1

10

motorbike (40)

0

10

?1

?4

10

?3

10

?2

10

?1

10

10

keyboard (154)

0

10

10

10

?1

?4

10

0

10

?3

10

10

?1

?4

10

?1

?4

10

10

?1

10

?1

?4

10

0

10

10

10

10

sidewalk (196)

0

10

?1

?4

10

person (113)

0

10

?1

10

building (547)

0

10

?4

10

?3

10

?1

10

wall (69)

0

10

?2

10

10

SVM
No clustering
Clustering

?1

10

?1

?4

10

?3

10

?2

10

?1

10

10

?1

?4

10

?3

10

?2

10

10

?1

10

?1

?4

10

?3

10

?2

10

?1

10

10

?4

10

?3

10

?2

10

?1

10

Figure 7: Comparison of full system against local appearance only detector (SVM). Detection rate for a
number of object categories tested at a fixed false positive per window rate of 2e-04 (0.8 false positives per
image per object class). The number of test examples appear in parenthesis next to the category name. We
plot performance for a number of classes for the baseline SVM object detector (blue), the detector of Section 3
using no clustering (red), and the full system (green). Notice that detectors taking into account context performs
better in most cases than using local appearance alone. Also, clustering does as well, and sometimes exceeds no
clustering. Notable exceptions are for some indoor object categories. This is due to poor retrieval set matching,
which causes a poor context model to be learned.
[3] C. Fellbaum. Wordnet: An Electronic Lexical Database. Bradford Books, 1998.
[4] P. Felzenszwalb and D. Huttenlocher. Pictorial structures for object recognition. Intl. J. Computer Vision,
61(1), 2005.
[5] R. Fergus, P. Perona, and A. Zisserman. Object class recognition by unsupervised scale-invariant learning.
In CVPR, 2003.
[6] James Hays and Alexei Efros. Scene completion using millions of photographs. In ?SIGGRAPH?, 2007.
[7] D. Hoiem, A. Efros, and M. Hebert. Putting objects in perspective. In CVPR, 2006.
[8] H. Ishwaran and M. Zarepour. Exact and approximate sum-representations for the dirichlet process.
Canadian Journal of Statistics, 30:269?283, 2002.
[9] David G. Lowe. Distinctive image features from scale-invariant keypoints. Intl. J. Computer Vision,
60(2):91?110, 2004.
[10] J. McAuliffe, D. Blei, and M. Jordan. Nonparametric empirical bayes for the Dirichlet process mixture
model. Statistics and Computing, 16:5?14, 2006.
[11] R. M. Neal. Density modeling and clustering using Dirichlet diffusion trees. In Bayesian Statistics,
7:619?629, 2003.
[12] A. Oliva and A. Torralba. Modeling the shape of the scene: a holistic representation of the spatial
envelope. Intl. J. Computer Vision, 42(3):145?175, 2001.
[13] A. Rabinovich, A. Vedaldi, C. Galleguillos, E. Wiewiora, and S. Belongie. Objects in context. In IEEE
Intl. Conf. on Computer Vision, 2007.
[14] B. C. Russell, A. Torralba, K. P. Murphy, and W. T. Freeman. Labelme: a database and web-based tool
for image annotation. Technical Report AIM-2005-025, MIT AI Lab Memo, September, 2005.
[15] E. Sudderth, A. Torralba, W. T. Freeman, and W. Willsky. Learning hierarchical models of scenes, objects,
and parts. In IEEE Intl. Conf. on Computer Vision, 2005.
[16] Y. W. Teh, M. I. Jordan, M. J. Beal, and D. M. Blei. Hierarchical Dirichlet processes. Journal of the
American Statistical Association, 2006.
[17] Y. W. Teh, D. Newman, and Welling M. A collapsed variational bayesian inference algorithm for latent
dirichlet allocation. In Advances in Neural Info. Proc. Systems, 2006.
[18] A. Torralba. Contextual priming for object detection. Intl. J. Computer Vision, 53(2):153?167, 2003.
[19] A. Torralba, R. Fergus, and W.T. Freeman. Tiny images. Technical Report AIM-2005-025, MIT AI Lab
Memo, September, 2005.
[20] A. Torralba, K. Murphy, W. Freeman, and M. Rubin. Context-based vision system for place and object
recognition. In Intl. Conf. Computer Vision, 2003.

8


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 2478-multiple-instance-learning-via-disjunctive-programming-boosting.pdf

Multiple Instance Learning via
Disjunctive Programming Boosting

Stuart Andrews
Department of Computer Science
Brown University, Providence, RI, 02912
stu@cs.brown.edu
Thomas Hofmann
Department of Computer Science
Brown University, Providence, RI, 02912
th@cs.brown.edu

Abstract
Learning from ambiguous training data is highly relevant in many
applications. We present a new learning algorithm for classification
problems where labels are associated with sets of pattern instead
of individual patterns. This encompasses multiple instance learning as a special case. Our approach is based on a generalization
of linear programming boosting and uses results from disjunctive
programming to generate successively stronger linear relaxations of
a discrete non-convex problem.

1

Introduction

In many applications of machine learning, it is inherently difficult or prohibitively
expensive to generate large amounts of labeled training data. However, it is often
considerably less challenging to provide weakly labeled data, where labels or annotations y are associated with sets of patterns or bags X instead of individual patterns
x ? X. These bags reflect a fundamental ambiguity about the correspondence of
patterns and W
the associated label which can be expressed logically as a disjunction
of the form: x?X (x is an example of class y). In plain English, each labeled bag
contains at least one pattern (but possibly more) belonging to this class, but the
identities of these patterns are unknown.
A special case of particular relevance is known as multiple instance learning [5]
(MIL). In MIL labels are binary and the ambiguity is asymmetric in the sense that
bags with negative labels are always of size one. Hence the label uncertainty is
restricted to members of positive bags. There are many interesting problems where
training data of this kind arises quite naturally, including drug activity prediction
[5], content-based image indexing [10] and text categorization [1]. The ambiguity
typically arises, because of polymorphisms allowing multiple representations, e.g. a
molecule which can be in different conformations, or because of a part/whole am-

biguity, e.g. annotations may be associated with images or documents where they
should be attached to objects in an image or passages in a document. Notice also
that there are two intertwined objectives: the goal may be to learn a pattern-level
classifier from ambiguous training examples, but sometimes one may be primarily
interested in classifying new bags without necessarily resolving the ambiguity for
individual patterns.
A number of algorithms have been developed for MIL, including special purpose
algorithms using axis-parallel rectangular hypotheses [5], diverse density [10, 14],
neural networks [11], and kernel methods [6]. In [1] two versions of a maximummargin learning architecture for solving the multiple instance learning problem have
been presented. Because of the combinatorial nature of the problem, a simple
optimization heuristic was used in [1] to learn discriminant functions. In this paper,
we take a more principled approach by carefully analyzing the nature of the resulting
optimization problem and by deriving a sequence of successively stronger relaxations
that can be used to compute lower and upper bounds on the objective. Since it
turns out that exploiting sparseness is a crucial aspect, we have focused on a linear
programming formulation by generalizing the LPBoost algorithm [7, 12, 4] we call
the resulting method Disjunctive Programming Boosting (DPBoost).

2

Linear Programming Boosting

LPBoost is a linear programming approach to boosting, which
P aims at learning
ensemble classifiers of the form G(x) = sgn F (x) with F (x) = k ?k hk (x), where
hk : <d ? {?1, 1}, k = 1, . . . , n are the so-called base classifiers, weak hypotheses,
or features and ?k ? 0 are combination weights. The ensemble margin of a labeled
example (x, y) is defined as yF (x).
Given a set of labeled training examples {(x1 , y1 ), . . . , (xm , ym )}, LPBoost formulates the supervised learning problem using the 1-norm soft margin objective
min
?, ?

n
X

?k + C

m
X

?i

s.t. yi F (xi ) ? 1 ? ?i , ?i ? 0, ?i, ?k ? 0, ?k .

(1)

i=1

k=1

Here C > 0 controls the tradeoff between the Hinge loss and the L1 regularization
term. Notice that this formulation remains meaningful even if all training examples
are just negative or just positive [13].
Following [4] the dual program of Eq. (1) can be written as
max
u

m
X
i=1

ui ,

s.t.

m
X

ui yi hk (xi ) ? 1, ?k,

0 ? ui ? C, ?i .

(2)

i=1

It is useful to take a closer look at the KKT complementary conditions
!
m
X
ui (yi F (xi ) + ?i ? 1) = 0, and ?k
ui yi hk (xi ) ? 1 = 0.

(3)

i=1

Since the optimal values of the slack variables are implicitly determined by ? as
?i (?) = [1 ? yi F (xi )]+ , the first set of conditions states that ui = 0 whenever
yi F (xi ) > 1. Since ui can be interpreted as the ?misclassification? cost, this implies
that only instances with tight margin constraints may have non-vanishing
associated
Pm
costs. The second set of conditions ensures that ?k = 0, if i=1 ui yi hk (xi ) < 1,
which states that
P a weak hypothesis hk is never included in the ensemble, if its
weighted score i ui yi hk (xi ) is strictly below the maximum score of 1. So a typical

LPBoost solution may be sparse in two ways: (i) Only a small number of weak
hypothesis with ?k > 0 may contribute to the ensemble and (ii) the solution may
only depend on a subset of the training data, i.e. those instances with ui > 0.
LPBoost exploits the sparseness of the ensemble by incrementally selecting columns
from the simplex tableau and optimizing the smaller tableau. This amounts to
finding in each round a hypothesis hk for which the constraint in Eq. (2) is violated,
adding it to the ensemble and re-optimizing the tableau with the selected columns.
As a column selection heuristic the authors of [4] propose to use the
P magnitude of
the violation, i.e. pick the weak hypothesis hk with maximal score i ui yi hk (xi ).

3

Disjunctive Programming Boosting

In order to deal with pattern ambiguity, we employ the disjunctive programming
framework [2, 9]. In the spirit of transductive large margin methods [8, 3], we
propose to estimate the parameters ? of the discriminant function in a way that
achieves a large margin for at least one of the patterns in each bag. Applying this
principle, we can compile the training data into a set of disjunctive constraints on
?. To that extend, let us define the following polyhedra
(
)
X
Hi (x) ? (?, ?) : yi
?k hk (x) + ?i ? 1 , Q ? {(?, ?) : ?, ? ? 0} . (4)
k

Then we can formulate the following disjunctive program:
min
?,?

n
X

?k + C

m
X

?i ,

s.t. (?, ?) ? Q ?

Hi (x) .

(5)

i x?Xi

i=1

k=1

\ [

Notice that if |Xi | ? 2 then the constraint imposed by Xi is highly non-convex,
since it is defined via a union of halfspaces. However, for trivial bags with |Xi | = 1,
the resulting constraints are the same as in Eq. (1). Since we will handle these two
cases quite differently in the sequel, let us introduce index sets I = {i : |Xi | ? 2}
and J = {j : |Xj | = 1}.
A suitable way to define a relaxation to this non-convex optimization problem is
to replace the disjunctive set in Eq. (5) by its convex hull. As shown in [2], a
whole hierarchy of such relaxations can be built, using the fundamental fact that
cl-conv(A) ? cl-conv(B) ? cl-conv(A ? B), where cl-conv(A) denotes the closure of
the convex hull of the limiting points of A. This means a tighter convex relaxation
is obtained, if we intersect as many sets as possible, before taking their convex hull.
Since repeated intersections of disjunctive sets with more than one element each
leads to an combinatorial blow-up in the number of constraints, we propose to intersect every ambiguous disjunctive constraint with every non-ambiguous constraint
as well as with Q. This is also called a parallel reduction step [2]. It results in the
following convex relaxation of the constraints in Eq. (5)
?
?
??
\
[
\
?Hi (x) ? Q ?
cl-conv ?
Hj (xj )?? ,
(?, ?) ?
(6)
i?I

x?Xi

j?J

where we have abused the notation slightly and identified Xj = {xj } for bags with
one pattern. The rationale in using this relaxation is that the resulting convex
optimization problem is tractable and may provide a reasonably accurate approximation to the original disjunctive program, which can be further strengthened by
using it in combination with branch-and-bound search.

There is a lift-and-project representation of the convex hulls in Eq. (6), i.e. one
can characterize the feasible set as a projection of a higher dimensional polyhedron
which can be explicitly characterized [2].
Proposition 1. Assume a set of non-empty
linear constraints Hi ? {z : Ai z ?
S
i
b } 6= ? is given. Then z ? cl-conv i Hi if and only if there exist z j and ? j ? 0
such that
X
X
z=
zj ,
? j = 1, Aj z j ? ? j bj .
j

j

Proof. [2]
Let us pause here briefly and recapitulate what we have achieved so far. We have
derived a LP relaxation of the original disjunctive program for boosting with ambiguity. This relaxation was obtained by a linearization of the original non-convex
constraints. Furthermore, we have demonstrated how this relaxation can be improved using parallel reduction steps.
Applying this linearization to every convex hull in Eq. (6) individually, notice that
one needs to introduce duplicates ?x , ? x of the parameters ? and slack
P variables ?,
for every x ? Xi . In addition to the constraints ?kx , ?ix , ?jx , ?ix ? 0 and x?Xi ?ix = 1
the relevant constraint set for ambiguous bag Xi for i ? I of the resulting LP can
be written as
X
?x ? Xi : yi
?kx hk (x) + ?ix ? ?ix ,
(7a)
k

?x ? Xi , ?j ? J : yj

X

?kx hk (xj ) + ?jx ? ?ix ,

(7b)

X

(7c)

k

?k, ?j ? I ? J : ?k =

x?Xi

?kx ,

?j =

X

?jx .

x?Xi

The first margin constraint in Eq. (7a) is the one associated with the specific pattern
x, while the second set of margin constraints in Eq. (7b) stems from the parallel
reduction performed with unambiguous bags. One can calculate the dual LP of
the above relaxation, the derivation of which can be found in the appendix. The
resulting program has a more complicated bound structure on the u-variables and
the following crucial constraints involving the data
X
X
?i, ?x ? Xi : yi uxi hk (x) +
yj uxj hk (xj ) ? ?ik ,
?ik = 1 .
(8)
j?J

i?I

However, the size of the resulting problem is significant. As a result of linearization
and parallel reductions, the number of parameters in the primal LP is now O(q ? n +
q ?r), where q, r ? m denote the number of patterns in ambiguous and unambiguous
bags, compared to O(n + m) of the standard LPBoost. The number of constraints
(variables in the dual) has also been inflated significantly from O(m) to O(q?r+p?n)),
where p ? q is the number of ambiguous bags.
In order to maintain the spirit of LPBoost in dealing efficiently with a large-scale
linear program, we propose to maintain the column selection scheme of selecting
one or more ?kx in every round. Notice that the column
P selection can not proceed
independently because of the equality constraints x?Xi ?kx = ?k for all Xi ; in
particular, ?kx > 0 implies ?k > 0, so that ?kz > 0 for at least some z ? Xi for each
Xi , i ? I. We hence propose to simultaneously add all columns {?kx : x ? Xi , i ? I}
involving the same weak hypothesis and to prune those back after each boosting

round in order to exploit the expected sparseness of the solution. In order to select
a feature hk , we compute the following score
?
?
X
X
S(k) =
??ik ? 1, ??ik ? max ?yi uxi hk (x) +
yj uxj hk (xj )? .
(9)
x

i

j?J

Notice that due to the block structure of the tableau, working with a reduced set of
columns also eliminates a large number of inequalities (rows). However, the large
set of q ? r inequalities for the parallel reductions is still prohibitive.
In order to address this problem, we propose to perform incremental row selection
in an outer loop. Once we have converged to a column basis for the current relaxed
LP, we add a subset of rows corresponding to the most useful parallel reductions.
One can use the magnitude of the margin violation as a heuristic to perform this
row selection. Hence we propose to use the following score
X
T (x, j) = ?ix ? yj
?kx hk (xj ), where x ? Xi , i ? I, j ? J
(10)
k

This means that for current values of the duplicated ensemble weights ?kx , one
selects the parallel reduction margin constraint associated with ambiguous pattern
x and unambiguous pattern j that is violated most strongly.

Although the margin constraints imposed by unambiguous training instances
(xj , yj ) are redundant after we performed the parallel reduction step in Eq. (6),
we add them to the problem, because this will give us a better starting point with
respect to the row selection process, and may lead to a sparser solution. We hence
add the following constraints to the primal
X
yj
?k hk (xj ) + ?j ? 1, ?j ? J ,
(11)
k

which will introduce additional dual variables uj , j ? J. Notice that in the worst
case where all inequalities imposed by ambiguous training instances Xi are vacuous,
this will make sure that one recovers the standard LPBoost formulation on the
unambiguous examples. One can then think of the row generation process as a way
of deriving useful information from ambiguous examples. This information takes
the form of linear inequalities in the high dimensional representation of the convex
hull and will sequentially reduce the version space, i.e. the set of feasible (?, ?) pairs.
Algorithm 1 DPBoost Algorithm
1: initialize H = ?, C = {?i : i ? I ? J}, R = {ux
i : x ? Xi , i ? I} ? {uj : j ? J}
1
2: uj = |J|
, uxi = 0, ?i = 0
3: repeat
4:
repeat
5:
column selection: select hk 6? H with maximal S(k)
6:
H = H ? {hk }
7:
C = C ? {?k } ? {?kx : ?x ? Xi , ?i ? I}
8:
solve LP (C, R)
9:
until max S(k) < 
10:
row selection: select a set S of pairs (x, j) 6? R with maximal T (x, j) > 0
11:
R = R ? {uxj : (x, j) ? S}, C = C ? {?jx : (x, j) ? S}
12:
solve LP (C, R)
13: until max T (x, j) < 

90
80
70
60
50

90
80
70
60
50
1

3

5

7

90
80
70
60
50
1

3

5

7

1

3

5

7

Figure 1: (Left) Normalized intensity plot used to generate synthetic data sets.
(Right) Performance relative to the degree of label ambiguity. Mean and standard
deviation of the pattern-level classification accuracy plotted versus ?, for perfectknowledge (solid), perfect-selector (dotted), DPboost (dashed), and naive (dashdot) algorithms. The three plots correspond to data sets of size |I| = 10, 20, 30.

4

Experiments

We generated a set of synthetic weakly labeled data sets to evaluate DPboost on a
small scale. These were multiple-instance data sets, where the label uncertainty was
asymmetric; the only ambiguous bags (|Xi | > 1) were positive. More specifically, we
generated instances x ? [0, 1] ? [0, 1] sampled uniformly at random from the white
(yi = 1) and black (yi = ?1) regions of Figure 1, leaving the intermediate gray
area as a separating margin. The degree of ambiguity was controlled by generating
ambiguous bags of size k ? Poisson(?) having only one positive and k ? 1 negative
patterns. To control data set size, we generated a pre-specified number of ambiguous
bags, and the same number of singleton unambiguous bags.
As a proof of concept benchmark, we compared the classification perfomance of
DPboost with two other LPboost variants: perfect-knowledge, perfect-selector, and
naive algorithms. All variants use LPboost as their base algorithm and have slightly
different preprocessing steps to accomodate the MIL data sets. The first corresponds
to the supervised LPboost algorithm; i.e. the true pattern-level labels are used.
Since this algorithm does not have to deal with ambiguity, it will perform better
than DPboost. The second uses the true pattern-level labels to prune the negative
examples from ambiguous bags and solves the smaller supervised problem with
LPboost as above. This algorithm provides an interesting benchmark, since its
performance is the best we can hope for from DPboost. At the other extreme, the
third variant assumes the ambiguous pattern labels are equal to their respective
bag labels. For all algorithms, we used thresholded ?RBF-like? features.
Figure 2 shows the discriminant boundary (black line), learned by each of the four
algorithms for a data set generated with ? = 3 and having 20 ambiguous bags
(i.e. |I| = 20, no. ambig. = 71, no. total = 91). The ambiguous patterns are
marked by ?o?, unambiguous ones ?x?, and the background is shaded to indicate
the value of the ensemble F (x) (clamped to [?3, 3]). It is clear from the shading that
the ensemble has a small number of active features for DPboost, perfect-selector
and perfect-knowledge algorithms. For each classifier, we report the pattern-level
classification accuracy for a uniform grid (21 x 21) of points. The sparsity of the dual
variables was also verified; less than 20 percent of the dual variables and reductions
were active.
We ran 5-fold cross-validation on the synthetic data sets for ? = 1, 3, 5, 7 and for
data sets having |I| = 10, 20, 30. Figure 1 (right side) shows the mean pattern-level
classification accuracy with error bars showing one standard deviation, as a function

3

2

1

0

?1

?2

?3

Figure 2: Discriminant boundaries learned by naive (accuracy = 53.3 %), DPboost
(85.3 %), perfect-selector (86.6 %) and perfect-knowledge (92.7 %) algorithms.
of the parameter ?.

5

Conclusion

We have presented a new learning algorithm for classification problems where labels
are associated with sets of pattern instead of individual patterns. Using synthetic
data, the expected behaviour of the algorithm has been demonstrated. Our current
implementation could not handle large data sets, and so improvements, followed by
a large-scale validation and comparison to other algorithms using benchmark MIL
data sets, will follow.
Acknowledgments
David Musicant for making his CPLEX MEX interface available online. Also, to
Ioannis Tsochantaridis and Keith Hall, for useful discussion and advice. This work
was sponsored by an NSF-ITR grant, award number IIS-0085836.

References
[1] Stuart Andrews, Ioannis Tsochantaridis, and Thomas Hofmann. Support vector machines for multiple-instance learning. In Advances in Neural Information Processing
Systems, volume 15. MIT Press, 2003.
[2] Egon Balas. Disjunctive programming and a hierarchy of relaxations for discrete
optimization problems. SIAM Journal on Algebraic and Discrete Methods, 6(3):466?
486, July 1985.
[3] A. Demirez and K. Bennett. Optimization approaches to semisupervised learning.
In M. Ferris, O. Mangasarian, and J. Pang, editors, Applications and Algorithms of
Complementarity. Kluwer Academic Publishers, Boston, 2000.
[4] Ayhan Demiriz, Kristin P. Bennett, and John Shawe-Taylor. Linear programming
boosting via column generation. Machine Learning, 46(1-3):225?254, 2002.
[5] T. G. Dietterich, R. H. Lathrop, and T. Lozano-Perez. Solving the multiple instance
problem with axis-parallel rectangles. Artificial Intelligence, 89(1-2):31?71, 1997.
[6] T. G?
artner, P. A. Flach, A. Kowalczyk, and A. J. Smola. Multi-instance kernels. In
Proc. 19th International Conf. on Machine Learning. Morgan Kaufmann, San Francisco, CA, 2002.
[7] A.J. Grove and D. Schuurmans. Boosting in the limit: Maximizing the margin of
learned ensembles. In Proceedings of the Fifteenth National Conference on Artifical
Intelligence, 1998.
[8] T. Joachims. Transductive inference for text classification using support vector machines. In Proceedings 16th International Conference on Machine Learning, pages
200?209. Morgan Kaufmann, San Francisco, CA, 1999.

[9] Sangbum Lee and Ignacio E. Grossmann. New algorithms for nonlinear generalized disjunctive programming. Computers and Chemical Engineering Journal, 24(910):2125?2141, October 2000.
[10] O. Maron and A. L. Ratan. Multiple-instance learning for natural scene classification. In Proc. 15th International Conf. on Machine Learning, pages 341?349. Morgan
Kaufmann, San Francisco, CA, 1998.
[11] J. Ramon and L. De Raedt. Multi instance neural networks. In Proceedings of ICML2000, Workshop on Attribute-Value and Relational Learning, 2000.
[12] G. R?
atsch, T. Onoda, and K.-R. M?
uller. Soft margins for AdaBoost. Technical Report
NC-TR-1998-021, Department of Computer Science, Royal Holloway, University of
London, Egham, UK, 1998.
[13] Gunnar R?
atsch, Sebastian Mika, Bernhard Sch?
olkopf, and Klaus-Robert M?
uller. Constructing boosting algorithms from svms: an application to one-class classification.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 24(9):1184?1199,
2002.
[14] Qi Zhang and Sally A. Goldman. EM-DD: An improved multiple-instance learning
technique. In Advances in Neural Information Processing Systems, volume 14. MIT
Press, 2002.

Appendix
The primal variables are ?k , ?kx , ?i , ?ix , ?jx , and ?ix . The dual variables are ux and
uxj for the margin constraints, and ?ik , ?i , and ?i for the equality constraints on ?k ,
? and ?, respectively.
The Lagrangian is given by
?
?
X
X
X
X X
L=
?k + C ?
?i +
?j ? ?
uxi
i

k

?

X X X
i

?

x?Xi

X

?ik

?k ?

x?Xi

i

?kx hk (xj )

?kx

X

yj

x?Xi

+

?jx

?

k

X

x?Xi

X X X
i

uxj

j

i,k

?

j

X

?
? kx ?kx

?

k

!

?

?i ?

i

X X
i

?i

x?Xi

yi

??ix ?ix ?

?ix

X
k

!

X

x?Xi

+

X

?i

?

X

x?Xi

1?

i

?ix

!

X X X
i

?kx hk (x) + ?ix ? ?ix
X

x?Xi

?ij

?j ?

i,j

??jx ?jx ?

j

i

x?Xi

i

?i ? uxi +

X

uxj ,

uxi ? C,

uxj ? ?ij ,

?ij ? C

i

j

yi uxi hk (x) +

X

X
j

yj uxj hk (xj ) ? ?ik ,

X
i

!

X

?jx

x?Xi

X X

Taking derivatives w.r.t. primal variables, leads to the following dual
X
max
?i
s.t.

?ix

!

?ik = 1

??ix ?ix .

!


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 3278-spatial-latent-dirichlet-allocation.pdf

Spatial Latent Dirichlet Allocation

Xiaogang Wang and Eric Grimson
Computer Science and Artificial Intelligence Lab
Massachusetts Institute of Technology, Cambridge, MA, 02139, USA
xgwang@csail.mit.edu, welg@csail.mit.edu

Abstract
In recent years, the language model Latent Dirichlet Allocation (LDA), which
clusters co-occurring words into topics, has been widely applied in the computer
vision field. However, many of these applications have difficulty with modeling
the spatial and temporal structure among visual words, since LDA assumes that a
document is a ?bag-of-words?. It is also critical to properly design ?words? and
?documents? when using a language model to solve vision problems. In this paper, we propose a topic model Spatial Latent Dirichlet Allocation (SLDA), which
better encodes spatial structures among visual words that are essential for solving
many vision problems. The spatial information is not encoded in the values of
visual words but in the design of documents. Instead of knowing the partition of
words into documents a priori, the word-document assignment becomes a random
hidden variable in SLDA. There is a generative procedure, where knowledge of
spatial structure can be flexibly added as a prior, grouping visual words which are
close in space into the same document. We use SLDA to discover objects from a
collection of images, and show it achieves better performance than LDA.

1

Introduction

Latent Dirichlet Allocation (LDA) [1] is a language model which clusters co-occurring words into
topics. In recent years, LDA has been widely used to solve computer vision problems. For example,
LDA was used to discover objects from a collection of images [2, 3, 4] and to classify images into
different scene categories [5]. [6] employed LDA to classify human actions. In visual surveillance,
LDA was used to model atomic activities and interactions in a crowded scene [7]. In these applications, LDA clustered low-level visual words (which were image patches, spatial and temporal
interest points or moving pixels) into topics with semantic meanings (which corresponded to objects,
parts of objects, human actions or atomic activities) utilizing their co-occurrence information.
Even with these promising achievements, however, directly borrowing a language model to solve
vision problems has some difficulties. First, LDA assumes that a document is a bag of words,
such that spatial and temporal structures among visual words, which are meaningless in a language
model but important in many computer vision problems, are ignored. Second, users need to define
the meaning of ?documents? in vision problems. The design of documents often implies some
assumptions on vision problems. For example, in order to cluster image patches, which are treated
as words, into classes of objects, researchers treated images as documents [2]. This assumes that
if two types of patches are from the same object class, they often appear in the same images. This
assumption is reasonable, but not strong enough. As an example shown in Figure 1, even though
sky is far from vehicles, if they often exist in the same images in some data set, they would be
clustered into the same topic by LDA. Furthermore, since in this image most of the patches are sky
and building, a patch on a vehicle is likely to be labeled as building or sky as well. These problems
could be solved if the document of a patch, such as the yellow patch in Figure 1, only includes other
1

Figure 1: There will be some problems (see text) if the whole image is treated as one document
when using LDA to discover classes of objects.

patches falling within its neighborhood, marked by the red dashed window in Figure 1, instead of
the whole image. So a better assumption is that if two types of image patches are from the same
object class, they are not only often in the same images but also close in space. We expect to utilize
spatial information in a flexible way when designing documents for solving vision problems.
In this paper, we propose a Spatial Latent Dirichlet Allocation (SLDA) model which encodes the
spatial structure among visual words. It clusters visual words (e.g. an eye patch and a nose patch),
which often occur in the same images and are close in space, into one topic (e.g. face). This is
a more proper assumption for solving many vision problems when images often contain several
objects. It is also easy for SLDA to model activities and human actions by encoding temporal
information. However the spatial or temporal information is not encoded in the values of visual
words, but in the design of documents. LDA and its extensions, such as the author-topic model [8],
the dynamic topic model [9], and the correlated topic model [10], all assume that the partition
of words into documents is known a priori. A key difference of SLDA is that the word-document
assignment becomes a hidden random variable. There is a generative procedure to assign words to
documents. When visual words are close in space or time, they have a high probability to be grouped
into the same document. Some approaches such as [11, 3, 12, 4] could also capture some spatial
structures among visual words. [11] assumed that the spatial distribution of an object class could
be modeled as Gaussian and the number of objects in the image was known. Both [3] and [4] first
roughly segmented images using graph cuts and added spatial constraint using these segments. [12]
modeled the spatial dependency among image patches as Markov random fields.
As an example application, we use the SLDA model to discover objects from a collection of images.
As shown in Figure 2, there are different classes of objects, such as cows, cars, faces, grasses,
sky, bicycles, etc., in the image set. And an image usually contains several objects of different
classes. The goal is to segment objects from images, and at the same time, to label these segments
as different object classes in an unsupervised way. It integrates object segmentation and recognition.
In our approach images are divided into local patches. A local descriptor is computed for each
image patch and quantized into a visual word. Using topic models, the visual words are clustered
into topics which correspond to object classes. Thus an image patch can be labeled as one of the
object classes. Our work is related to [2] which used LDA to cluster image patches. As shown in
Figure 2, SLDA achieves much better performance than LDA. We will compare more results of
LDA and SLDA in the experimental section.

2

Computation of Visual Words

To obtain the local descriptors, images are convolved with the filter bank proposed in [13], which is
a combination of 3 Gaussians, 4 Laplacian of Gaussians, and 4 first order derivatives of Gaussians,
and was shown to have good performance for object categorization. Instead of only computing
visual words at interest points as in [2], we divide an image into local patches on a grid and densely
sample a local descriptor for each patch. A codebook of size W is created by clustering all the
local descriptors in the image set using K-means. Each local patch is quantized into a visual word
according to the codebook. In the next step, these visual words (image patches) will be further
clustered into classes of objects. We will compare two clustering methods, LDA and SLDA.
2

Figure 2: Given a collection of images as shown in the first row (which are selected from the MSRC
image dataset [13]), the goal is to segment images into objects and cluster these objects into different
classes. The second row uses manual segmentation and labeling as ground truth. The third row is
the LDA result and the fourth row is the SLDA result. Under the same labeling approach, image
patches marked in the same color are in one object cluster, but the meaning of colors changes across
different labeling methods.

3

LDA

When LDA is used to solve our problem, we treat local patches of images as words and the whole
image as a document. The graphical model of LDA is shown in Figure 3 (a). There are M documents (images) in the corpus. Each document j has Nj words (image patches). wji is the observed
value of word i in document j. All the words in the corpus will be clustered into K topics (classes
of objects). Each topic k is modeled as a multinomial distribution over the codebook. and ? are
Dirichlet prior hyperparameters. k , j , and zji are hidden variables to be inferred. The generative
process of LDA is:
1. For a topic k, a multinomial parameter k is sampled from Dirichlet prior k Dir(?).
2. For a document j, a multinomial parameter j over the K topics is sampled from Dirichlet
prior j Dir( ).
3. For a word i in document j, a topic label zji is sampled from discrete distribution zji
Discrete( j ).
4. The value wji of word i in document j is sampled from the discrete distribution of topic
zji , wji Discrete( zji ).
zji can be sampled through a Gibbs sampling procedure which integrates out
p(zji = k z
where n

(k)
ji w

ji

w

?)

(k)
n ji wji

+ ?wji


(k)
+
?
n
w
ji w
w=1

W

j

and

(j)
n ji k + k
K  (j)
k=1 n ji k+

k



[14].
(1)

k

is the number of words in the corpus with value w assigned to topic k excluding word
(j)

i in document j, and n ji k is the number of words in document j assigned to topic k excluding
word i in document j. Eq 1 is the product of two ratios: the probability of word wji under topic k
and the probability of topic k in document j. So LDA clusters the visual words often co-occurring
in the same images into one object class.
As shown by some examples in Figure 2 (see more results in the experimental section), there are
two problems in using LDA for object segmentation and recognition. The segmentation result is
3

Figure 3: Graphical model of LDA (a) and SLDA (b). See text for details.

noisy since spatial information is not considered. Although LDA assumes that one image contains
multiple topics, from experimental results we observe that the patches in the same image are likely
to have the same labels. Since the whole image is treated as one document, if one object class, e.g.
car in Figure 2, is dominant in the image, the second ratio in Eq 1 will lead to a large bias towards
the car class, and thus the patches of street are also likely to be labeled as car. This problem could
be solved if a local patch only considers its neighboring patches as being in the same document.

4

SLDA

We assume that if visual words are from the same class of objects, they not only often co-occur in the
same images but also are close in space. So we try to group image patches which are close in space
into the same documents. One straightforward way is to divide the image into regions as shown in
Figure 4 (a). Each region is treated as a document instead of the whole image. However, since these
regions are not overlapped, some patches, such as A (red patch) and B (cyan patch) in Figure 4 (a),
even though very close in space, are assigned to different documents. In Figure 4 (a), patch A on
the cow is likely to be labeled as grass, since most other patches in its document are grass. To solve
this problem, we may put many overlapped regions, each of which is a document, on the images as
shown in Figure 4 (b). If a patch is inside a region, it ?could? belong to that document. Any two
patches whose distance is smaller than the region size ?could? belong to the same document if the
regions are placed densely enough. We use the word ?could? because each local patch is covered
by several regions, so we have to decide to which document it belongs. Different from the LDA
model, in which the word-document relationship is known a priori, we need a generative procedure
assigning words to documents. If two patches are closer in space, they have a higher probability
to be assigned to the same document since there are more regions covering both of them. Actually
we can go even further. As shown in Figure 4 (c), each document can be represented by a point
(marked by magenta circle) in the image, assuming its region covers the whole image. If an image
patch is close to a document, it has a high probability to be assigned to that document.
The graphical model is shown in Figure 3 (b). In SLDA, there are M documents and N words in the
corpus. A hidden variable di indicates which document word i is assigned to. For each document
j there is a hyperparameter cdj = gjd , xdj , yjd known a priori. gjd is the index of the image where

document j is placed and xdj , yjd is the location of the document. For a word i, in addition to the
observed word value wi , its location (xi , yi ) and image index gi are also observed and stored in
variable ci = (gi , xi , yi ). The generative procedure of SLDA is:
1. For a topic k, a multinomial parameter ?k is sampled from Dirichlet prior ?k ? Dir(?).
4

Figure 4: There are several ways to add spatial information among image patches when designing
documents. (a): Divide the image into regions without overlapping. Each region, marked by a
dashed window, corresponds to a document. Image patches inside the region are assigned to the
corresponding document. (b): densely put overlapped regions over images. One image patch is
covered by multiple regions. (c): Each document is associated with a point (marked in magenta
color). These points are densely placed over the image. If a image patch is close to a document, it
has a high probability to be assigned to that document.
2. For a document j, a multinomial parameter j over the K topics is sampled from Dirichlet
prior j Dir( ).
3. For a word (image patch) i, a random variable di is sampled from prior p(di ?) indicating
to which document word i is assigned. We choose p(di ?) as a uniform prior.
4. The image index and location of word i is sampled from distribution p(ci cddi ). We may
choose this as a Gaussian kernel.
 
2 
2 
d d d 
xddi xi + yddi yi
) ?gdd (gi ) exp
p((gi xi yi ) gdi xdi ydi
2
i

p(ci cddi ) = 0 if the word and the document are not in the same image.
5. The topic label zi of word i is sampled from the discrete distribution of document di ,
zi Discrete( di ).
6. The value wi of word i is sampled from the discrete distribution of topic zi , wi
Discrete( zi ).
4.1

Gibbs Sampling

zi and di can be sampled through a Gibbs sampling procedure integrating out
the conditional distribution of zi given di is the same as in LDA.
p(zi = k di = j d
(k)
iw
(j)
n ik

where n

i

z

i

?)

w

k

and

(j)
ik + k
K  (j)
k=1 n i k+

(k)
i wi + ?wi

W  (k)
w=1 n i w + ?w

j.

In SLDA

n

n



(2)

k

is the number of words in the corpus with value w assigned to topic k excluding word

i, and
is the number of words in document j assigned to topic k excluding word i. This is
easy to understand since if the word-document assignment is fixed, SLDA is the same as LDA.
In addition, we also need to sample di from the conditional distribution given zi .


p di = j zi = k z i d i ci cdj
? ?


p (di = j ?) p ci cdj
p (zi = k z i di = j d i )
p (zi = k z

i

di = j d

p (zi = k z

i

) is obtained by integrating out j .
M 
p( j  )p(zj  ji )d
di = j d i ) =
i

j

j =1

=

M
j =1




K

k=1



K
k=1

5

(

k
k)


 
(j )
nk  + k 


K
(j )
K

k=1 nk +
k=1 k


K
k=1


We choose p (di = j|?) as a uniform prior and p ci |cdj , ? as a Gaussian kernel. Thus the conditional distribution of di is

p di = j|zi = k, z?i , d?i , ci , {cdj0 }, ?, ?, ?, ?
2

? ?gjd (gi ) ? e?

(xdj ?xi ) +(yjd ?yi )
?2

2

(j)

n?i,k + ?k


(j)
0
n
+
?
0
0
k
k =1
?i,k

?P
K

(3)

Word i is likely to be assigned to document j if they are in the same image, close in space and word
i has the same topic label as other words in document j. In real applications, we only care about the
distribution of zi while dj can be marginalized by simply ignoring its samples. From Eq 2 and 3,
we observed that a word tends to have the same topic label as other words in its document and words
closer in space are more likely to be assigned to the same documents. So essentially under SLDA a
word tends to be labeled as the same topic as other words close to it. This satisfies our assumption
that visual words from the same object class are closer in space.
Since we densely place many documents over one image, during Gibbs sampling some documents
are only assigned a few words and the distributions cannot be well estimated. To solve this problem
we replicate each image patch to get many particles. These particles have the same word value and
location but can be assigned to different documents and have different labels. Thus each document
will have enough samples of words to estimate the distributions.
4.2

Discussion

SLDA is a flexible model intended to encode spatial structure among image patches and design
documents. If there is only one document placed over one image, SLDA simply reduces to LDA.
If p(ci |cdj ) is an uniform distribution inside a local region, SLDA implements the scheme described
in Figure 4 (b). If these local regions are not overlapped, it is the case of Figure 4 (a). There are
also other possible ways to add spatial information by choosing different spatial priors p(ci |cdj ). In
SLDA, the spatial information is used when designing documents. However the object class model
?k , simply a multinomial distribution over the codebook, has no spatial structure. So the objects of
a class could be in any shape and anywhere in the images, as long as they smoothly distribute in
space. By simply adding a time stamp to ci and cdj , it is easy for SLDA to encode temporal structure
among visual words. So SLDA also can be applied to human action and activity analysis.

5

Experiments

We test LDA and SLDA on the MSRC image dataset [13] with 240 images. Our codebook size is
200 and the topic number is 15. In Figure 2, we show some examples of results using LDA and
SLDA. Colors are used indicate different topics. The results of LDA are noisy and within one image
most of the patches are labeled as one topic. SLDA achieves much better results than LDA. The
results are smoother and objects are well segmented. The detection rate and false alarm rate of four
classes, cows, cars, faces, and bicycles are shown in Table 1. They are counted in pixels. We use the
manual segmentation and labeling in [13] as ground truth.
The two models are also tested on a tiger video sequence with 252 frames. We treat all the frames
in the sequence as an image collection and ignore their temporal order. Figure 5 shows their results
on two sampled frames. Please see the result of the whole video sequence from our website [15].
Using LDA, usually there are one or two dominant topics distributed like noise in a frame. Topics
change as the video background changes. LDA cannot segment out any objects. SLDA clusters
image patches into tigers, rock, water, and grass. If we choose the topic of tiger, as shown in the last
row of Figure 5, all the tigers in the video can be segmented out.

6

Conclusion

We propose a novel Spatial Latent Dirichlet Allocation model which clusters co-occurring and spatially neighboring visual words into the same topic. Instead of knowing word-document assignment
a priori, SLDA has a generative procedure partitioning visual words which are close in space into
the same documents. It is also easy to extend SLDA to including temporal information.
6

Figure 5: Discovering objects from a video sequence. The first column shows two frames in the
video sequence. In the second column, we label the patches in the two frames as different topics
using LDA. The thrid column plots the topic labels using SLDA. The red color indicates the topic
of tigers. In the fourth column, we segment tigers out by choosing the topic marked in red.
Table 1: Detection(D) rate and False Alarm (FA) rate of LDA and SLDA on the MSRC data set
LDA(D)
SLDA(D)
LDA(FA)
SLDA(FA)

7

cows
0.3755
0.5662
0.5576
0.0334

cars
0.5552
0.6838
0.3963
0.2437

faces
0.7172
0.6973
0.5862
0.3714

bicycles
0.5563
0.5661
0.5285
0.4217

Acknowledgement

The authors wish to acknowledge DSO National Laboratory of Singapore for partially supporting
this research.

References
[1] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet allocation. Journal of Machine Learning Research,
3:993?1022, 2003.
[2] J. Sivic, B. C. Russell, A. A. Efros, A. Zisserman, and W. T. Freeman. Discovering object categories in
image collections. In Proc. ICCV, 2005.
[3] B. C. Russell, A. A. Efros, J. Sivic, W. T. Freeman, and A. Zisserman. Using multiple segmentations to
discover objects and their extent in image collections. In Proc. CVPR, 2006.
[4] L. Cao and L. Fei-Fei. Spatially coherent latent topic model for concurrent object segmentation and
classification. In Proc. ICCV, 2007.
[5] L. Fei-Fei and P. Perona. A bayesian hierarchical model for learning natural scene categories. In Proc.
CVPR, 2005.
[6] J. C. Niebles, H. Wang, and L. Fei-Fei. Unsupervised learning of human action categories using spatialtemporal words. In Proc. BMVC, 2006.
[7] X. Wang, X. Ma, and E. Grimson. Unsupervised activity perception by hierarchical bayesian models. In
Proc. CVPR, 2007.
[8] M. Rosen-Zvi, T. Griffiths, M. Steyvers, and P. Smyth. The author-topic model for authors and documents.
In Proc. of Uncertainty in Artificial Intelligence, 2004.
[9] D. Blei and J. Lafferty. Dynamic topic models. In Proc. ICML, 2006.
[10] D. Blei and J. Lafferty. Correlated topic models. In Proc. NIPS, 2006.
[11] E. B. Sudderth, A. Torralba, W. T. Freeman, and A. S. Willsky. Learning hierarchical models of scenes,
objects, and parts. In Proc. ICCV, 2005.
[12] J. Verbeek and B. Triggs. Region classification with markov field aspect models. In Proc. CVPR, 2007.

7

(a)

(b)

(c)
Figure 6: Examples of experimental results on the MSRC image data set. (a): original images; (b):
LDA results; (c) SLDA results.
[13] J. Winn, A. Criminisi, and T. Minka. Object categorization by learned universal visual dictionary. In
Proc. ICCV, 2005.
[14] T. Griffiths and M. Steyvers. Finding scientific topics. In Proc. of the National Academy of Sciences,
2004.
[15] http://people.csail.mit.edu/xgwang/slda.html.

8


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 3063-detecting-humans-via-their-pose.pdf

Detecting Humans via Their Pose

Alessandro Bissacco
Computer Science Department
University of California, Los Angeles
Los Angeles, CA 90095
bissacco@cs.ucla.edu

Ming-Hsuan Yang
Honda Research Institute
800 California Street
Mountain View, CA 94041
mhyang@ieee.org

Stefano Soatto
Computer Science Department
University of California, Los Angeles
Los Angeles, CA 90095
soatto@cs.ucla.edu

Abstract
We consider the problem of detecting humans and classifying their pose from a
single image. Specifically, our goal is to devise a statistical model that simultaneously answers two questions: 1) is there a human in the image? and, if so, 2) what
is a low-dimensional representation of her pose? We investigate models that can
be learned in an unsupervised manner on unlabeled images of human poses, and
provide information that can be used to match the pose of a new image to the ones
present in the training set. Starting from a set of descriptors recently proposed for
human detection, we apply the Latent Dirichlet Allocation framework to model
the statistics of these features, and use the resulting model to answer the above
questions. We show how our model can efficiently describe the space of images
of humans with their pose, by providing an effective representation of poses for
tasks such as classification and matching, while performing remarkably well in
human/non human decision problems, thus enabling its use for human detection.
We validate the model with extensive quantitative experiments and comparisons
with other approaches on human detection and pose matching.

1

Introduction

Human detection and localization from a single image is an active area of research that has witnessed
a surge of interest in recent years [9, 18, 6]. Simply put, given an image, we want to devise an
automatic procedure that locates the regions that contain human bodies in arbitrary pose. This is
hard because of the wide variability that images of humans exhibit. Given that it is impractical
to explicitly model nuisance factors such as clothing, lighting conditions, viewpoint, body pose,
partial and/or self-occlusions, one can learn a descriptive model of human/non human statistics.
The problem then reduces to a binary classification task for which we can directly apply general
statistical learning techniques. Consequently, the main focus of research on human detection so far
has been on deriving a suitable representation [9, 18, 6], i.e. one that is most insensitive to typical
appearance variations, so that it provides good features to a standard classifier.
Recently local descriptors based on histograms of gradient orientations such as [6] have proven
to be particularly successful for human detection tasks. The main idea is to use distributions of
gradient orientations in order to be insensitve to color, brightness and contrast changes and, to some
extent, local deformations. However, to account for more macroscopic variations, due for example
to changes in pose, a more complex statistical model is warranted. We show how a special class of
hierarchical Bayesian processes can be used as generative models for these features and applied to
the problem of detection and pose classification.

This work can be interpreted as an attempt to bridge the gap between the two related problems of
human detection and pose estimation in the literature. In human detection, since a simple yes/no
answer is required, there is no need to introduce a complex model with latent variables associated
to physical quantities. In pose estimation, on the other hand, the goal is to infer these quantities and
therefore a full generative model is a natural approach. Between these extremes lies our approach.
We estimate a probabilistic model with a set of latent variables, which do not necessarily admit a
direct interpretation in terms of configurations of objects in the image. However, these quantities are
instrumental to both human detection and the pose classification problem.
The main difficulty is in the representation of the pose information. Humans are highly articulated
objects with many degrees of freedom, which makes defining pose classes a remarkably difficult
problem. Even with manual labeling, how does one judge the distance between two poses or cluster
them? In such situations, we believe that the only avenue is an unsupervised method. We propose an approach which allows for unsupervised clustering of images of humans and provides a
low dimensional representation encoding essential information on their pose. The chief difference
with standard clustering or dimensionality reduction techniques is that we derive a full probabilistic
framework, which provides principled ways to combine and compare different models, as required
for tasks such as human detection, pose classification and matching.

2

Context and Motivation

The literature on human detection and pose estimation is too broad for us to review here. So we focus
on the case of a single image, neglecting scenarios where temporal information or a background
model are available and effective algorithms based on silhouettes [20, 12, 1] or motion patterns [18]
can be applied.
Detecting humans and estimating poses from single images is a fundamental problem with a range
of sensible applications, such as image retrieval and understanding. It makes sense to tackle this
problem as we know humans are capable of telling the locations and poses of people from the visual
information contained in photographs. The question is how to represent such information, and the
answer we give constitutes the main novelty of this work.
Numerous representation schemes have been exploited for human detection, e.g., Haar wavelets
[18], edges [9], gradient orientations [6], gradients and second derivatives [19] and regions from
image segmentation [15]. With these representations, algorithms have been applied for the detection
process such as template matching [9], support vector machine [19, 6], Adaboost [18], and grouping
[15], to name a few. Most approaches to pose estimation are based on body part detectors, using
either edge, shape, color and texture cues [7, 21, 15], or learned from training data [19]. The optimal
configuration of the part assembly is then computed using dynamic programming as first introduced
in [7], or by performing inference on a generative probabilistic model, using either Data Driven
Markov Chain Monte Carlo, Belief Propagation or its non-Gaussian extensions [21].
These works focus on only one of the two problems, either detection or pose estimation. Our approach is different, in that our goal is to extract more information than a simple yes/no answer, while
at the same time not reaching the full level of detail of determining the precise location of all body
parts. Thus we want to simultaneously perform detection and pose classification, and we want to
do it in an unsupervised manner. In this aspect, our work is related to the constellation models of
Weber et al. [23], although we do not have an explicit decomposition of the object in parts.
We start from the representation [6] based on gradient histograms recently applied to human detection with excellent results, and derive a probabilistic model for it. We show that with this model
one can successfully detect humans and classify their poses. The statistical tools used in this work,
Latent Dirichlet Allocation (LDA) [3] and related algorithms [5, 4], have been introduced in the
text analysis context and recently applied to the problem of recognition of object and action classes
[8, 22, 2, 16]. Contrary to most approaches (all but [8]) where the image is treated as a ?bag of
features? and all spatial information is lost, we encode the location and orientation of edges in the
basic elements (words) so that this essential information is explicitly represented by the model.

3

A Probabilistic Model for Gradient Orientations

We first describe the features that we use as the basic representations of images, and then propose a
probabilistic model with its application to the feature generation process.

3.1 Histogram of Oriented Gradients
Local descriptors based on gradient orientations are one of the most successful representations for
image-based detection and matching, as was firstly demonstrated by Lowe in [14]. Among the various approaches within this class, the best performer for humans appears to be [6]. This descriptor is
obtained by computing weighted histograms of gradient orientations over a grid of spatial neighborhoods (cells), which are then grouped in overlapping regions (blocks) and normalized for brightness
and contrast changes.
Assume that we are given a patch of 64 ? 128 pixels, we divide the patch into cells of 8 ? 8
pixels, and for each cell a gradient orientation histogram is computed. The histogram represents
a quantization in 9 bins of gradient orientations in the range 0? ? 180? . Each pixel contributes
to the neighboring bins, both in orientation and space, by an amount proportional to the gradient
magnitude and linearly decreasing with the distance from the bin center. These cells are grouped in
2 ? 2 blocks, and the contribution of each pixel is also weighted by a Gaussian kernel with ? = 8,
centered in the block. Finally the vectors v of cell histograms within one block are normalized in
L2 norm: v
? = v/(||v||2 + ). The final descriptor is a collection of histograms from overlapping
blocks (each cell shared by 4 blocks).
The main characteristic of such a representation is robustness to local deformations, illumination
changes and, to a limited extent, viewpoint and pose changes due to coarsening of the histograms.
In order to handle the larger variations typical of human body images, we need to complement this
representation with a model. We propose a probabilistic model that can accurately describe the
generation process of these features.
3.2 Latent Dirichlet Allocation
Latent Dirichlet Allocation (LDA) [3] is a hierachical model for sparse discrete mixture distributions, where the basic elements (words) are sampled from a mixture of component distributions, and
each component defines a discrete distribuition over the set of words.
We are given a collection of documents where words w, the basic units of our data, take values in
a dictionary of W unique elements w ? { 1, ? ? ? , W }. A document w = ( w1 , w2 , ? ? ? , wW )
PW
is a collection of word counts wj : j=1 wj = N . The standard LDA model does not include the
distribution of N , so it can be omitted in what follows. The corpus D = { w1 , w2 , ? ? ? , wM } is a
collection of M documents.
The LDA model introduces a set of K latent variables, called topics. Each word in the document
is assumed to be generated by one of the topics. Under this model, the generative process for each
document w in the corpus is as follows:
1. Choose ? ? Dirichlet(?).
2. For each word j = 1, ? ? ? , W in the dictionary, choose a word count wj ? p(wj |?, ?).
where the word counts wj are drawn from a discrete distribution conditioned on the topic proportions ?: p(wj |?, ?) = ?j. ?. Recently several variants to this model have been developed, notably
the Multinomial PCA [4], where the discrete distributions are replaced by multinomials, and the
Gamma-Poisson process [5], where the number of words ?i from each component are independent
Gamma samples and p(wj |?, ?) is Poisson. The hyperparameter ? ? RK
+ represents the prior on
W ?K
the topic distribution, ? ? RK
are the parameters of the
+ are the topic proportions, and ? ? R+
word distributions conditioned on topics. In the context of this work, words correspond to oriented
gradients, and documents as well as corpus correspond to images and a set of images respectively.
The topic derived by the LDA model is the pose of interest in this work. Here we can safely assume
that the topic distributions ? are deterministic parameters, later for the purpose of inference we will
treat them as random variables and assign them a Dirichlet prior: ?.k ? Dirichlet(?) , where ?.k
denotes the k-th column of ?.
Then the likelihood of a document w is:
Z
p(w|?, ?) =

p(?|?)

W
Y

p(wn |?, ?)d?

(1)

n=1

where documents are represented as a continuous mixture distribution. The advantage over standard
mixture of discrete distributions [17], is that we allow each document to be generated by more than
one topic.

3.3 A Bayesian Model for Gradient Orientation Histograms
Now we can show how the described two-level Bayesian process finds a natural application in modeling the spatial distribution of gradient orientations. Here we consider the histogram of oriented
gradients [6] as the basic feature from which we build our generative model, but let us point out
that the framework we introduce is more general and can be applied to any descriptor based on histograms1 . In this histogram descriptor, we have that each bin represents the intensity of the gradient
at a particular location, defined by a range of orientations and a local neighborhood (cell). Thus the
bin height denotes the strength and number of the edges in the cell.
The first thing to notice in deriving a generative models for this class of features is that, since they
represent a weighted histogram, they have non-negative elements. Thus a proper generative model
for these descriptors imposes non-negativity constraints. As we will see in the experiments, a linear approach such as Non-negative Matrix Factorization [13] leads to extremely poor performance,
probably due to the high curvature of the space. On the opposite end, representing the nonlinearity
of the space with a set of samples by Vector Quantization is feasible only using a large number of
samples, which is against our goal of deriving an economical representation of the pose.
We propose using the Latent Dirichlet Allocation model to represent the statistics of the gradient
orientation features. In order to do so we need to quantize feature values. While not investigated
in the original paper [6], quantization is common practice for similar histogram-based descriptors,
such as [14]. We tested the effect of quantization on the performance of the human detector based
on Histogram of Oriented Gradient descriptors and linear Support Vector Machines described in [6].
As evident in Figure 1, with 16 or more discrete levels we practically obtain the same performance
as with the original continuous descriptors. Thus in what follows we can safely assume that the
basic features are collections of small integers, the histogram bin counts wj .
Thus, if we quantize histogram bins and assign a unique word to each bin, we obtain a representation for which we can directly apply the LDA framework. Analogous to document analysis, an
orientation histogram computed on an image patch is a document w represented as a bag of words
( w1 , ? ? ? , wW ), where the word counts wj are the bin heights. We assume that such a histogram
is generated by a mixture of basic components (topics), where each topic z induces a discrete distribution p(r|?.z ) on bins representing a typical configuration of edges common to a class of elements
in the dataset. By summing the contributions from each topic we obtain the total count wj for each
bin, distributed according to p(wj |?, ?).
The main property of such feature formation process, desirable for our applications, is the fact that
topics combine additively. That is, the same bin may have contributions from multiple topics, and
this models the fact that the bin height is the count of edges in a neighborhood which may include
parts generated by different components. Finally, let us point out that by assigning a unique word
to each bin we model spatial information, encoded in the word identity, whereas most previous
approaches (e.g. [22]) using similar probabilistic models for object class recognition did not exploit
this kind of information.

4

Probabilistic Detection and Pose Estimation

The first application of our approach is human detection. Notice that our main goal is to develop a
model to represent the statistics of images for human pose classification. We use the human detection
problem as a convenient testbed for validating the goodness of our representation, since for this
application large labelled datasets and efficient algorithms are available. By no means we intend
to compete with state-of-the-art discriminative approaches for human detection alone, which are
optimized to represent the decision boundary and thus are supposed to perform better than generative
approaches in binary classification tasks. However, if the generative model is good at capturing the
statistics of human images we expect it to perform well also in discriminating humans from the
background.
In human detection, given a set of positive and negative examples and a previously unseen image
Inew , we are asked to choose between two hypotheses: either it contains a human or it is a background image. The first step is to compute the gradient histogram representation w(I) for the test
and training images. Then we learn a model for humans and background images and use a threshold
1

Notice that, due to the particular normalization procedure applied, the histogram features we consider here
do not have unit norm (in fact, they are zero on uniform regions).

on the likelihood ratio2 for detection:
L=

P (w(Inew )|Human)
(2)
P (w(Inew )|Background)
For the the LDA (and related models [5, 4], the likelihoods p(w(I)|?, ?) are computed as in (1),
where ?, ? are model parameters and can be learned from data. In practice, we can assume ?
is known and compute an estimate of ? from the training corpus. In doing so, we can choose
from two main inference algorithms: mean field or variational inference [3] and Gibbs sampling
[10]. Mean field algorithms provide a lower bound on the likelihood, while Gibbs sampling gives
statistics based on a sequential sampling scheme. As shown in Figure 1, in our experiments Gibbs
sampling exhibited superior performance over mean field in terms of classification accuracy. We
have experimented with two variations, a direct method and Rao-Blackwellised sampling (see [4]
for details). Both methods gave similar performance, here we report the results obtained using the
direct method, whose main iteration is as follows:
1. For each document wi = (wi,1 , ? ? ? , wi,W ):
(i)
First sample ?(i) ? p(?|wi , ?, ?), and then sample vj. ? Multinomial(?j. ?(i) , wi,j )
2. For each topic k:
P (i)
Sample ?.k ? Dirichlet( i v.k + ?)
In pose classification, we start from a set of unlabeled training examples of human poses and learn
the topic distribution ?. This defines a probabilistic mapping to the topic variables, which can be
seen as an economical representation encoding essential information of the pose. That is, from a
?
image Inew , we estimate the topic proportions
Z ?(Inew ) as:
? new ) = ?p(?|w(Inew ), ?, ?)d?
?(I
(3)
Pose information can be recovered by matching the new image Inew to an image I in the training set. For matching, ideally we would like to compute the matching score as Sopt (I, Inew ) =
P (w(Inew )|w(I), ?, ?), i.e. the posterior probability of the test image Inew given the training image I and the model ?, ?. However this would be computationally expensive as for each pair I, Inew
it requires computing an expectation of the form (3), thus we opted for a suboptimal solution. For
?
each training document I, in the learning step we compute the posterior topic proportions ?(I)
as
in (3). Then the matching score S between Inew and I is given by the dot product between the two
? and ?(I
? new ):
vectors ?(I)
?
? new ) >
S(I, Inew ) =< ?(I),
?(I
(4)
?
The computation of this score requires only a dot product between low dimensional unit vectors ?,
so our approach represent an efficient method for matching and clustering poses in large datasets.

5

Experiments

We first tested the efficacy of our model for the human detection task. We used the dataset provided
by [6], consisting of 2340 64 ? 128 images of pedestrians in various configurations and 1671 images
of outdoor scenes not containing humans. We collected negative examples by random sampling 10
patches from each of the first 1218 non-human images. These, together with 1208 positive examples
and their left-right reflections, constituted our first training set. We used the learned model to classify
remaining 1132 positive and on 5889 patches randomly extracted from the residual background
images.
We first computed the histograms of oriented gradients from the image patches following the procedure outlined in Section 3.1. These feature are quantized so that they can be represented by our
discrete stochastic model.
We tested the effect of different quantization levels on the performances of the boosted SVM classifier [6]: a initial training on the provided dataset is followed by a boosting round where the trained
classifier is applied to the background images to find false positive; these hard examples are then
added to for a second training of the classifier. As Figure 1 shows, the effect of quantization is significant only if we use less than 4 bits. Therefore, we chose to discretize the features to 16 quantization
levels.
2

Ideally we would like to use the posterior ratio R = P (Human|Inew )/P (Background|Inew ). However
notice that R is equal to (2) if we assume equal priors P (Human) = P (Background).

Given the number of topics K and the prior hyperparameters ?, ?, we learned topic distributions ?
? using either Gibbs sampling or Mean Field. We tested both Gamma [5]
and topic proportions ?(I)
and Dirichlet [3, 4] distributions for topic priors, obtaining best results with the multinomial model
[4] with scalar priors ?i = a, ?i = b, in these experiments a = 2/K and b = 0.5.
The number of topics K is an important parameter that should be carefully chosen based on considerations on modeling power and complexity. With a higher number of topics we can more accurately
fit the data, which can be measured by the increase in the likelihood of the training set. This does
not come for free: we have a larger number of parameters and an increased computational cost for
learning. Eventually, an excessive topic number causes overfitting, which can be measured as the
likelihood in the test dataset decreases. For the INRIA data, experimental evaluations suggested that
a good tradeoff is obtained with K = 24.
We learned two models, one for positive and one for negative examples. For learning we run the
Gibbs sampling algorithm described in Section 4 for a total number of 300 samples per document,
including 50 samples to compute the likelihoods (1). We also trained the model using the Mean
Field approximation, but as we can see in Figures 1 and 4 the results using Gibbs sampling are
better. For details on the implementation we refer to [4]. We then obtain a detector by computing
the likelihood ratio (2) and comparing it with a threshold.
In Figure 1 we show the performances of our detector on the INRIA dataset, where for the sake of
comparison with other approaches boosting is not performed. We show the results for:
? Linear SVM classifier: Trained as described, using the SVMLight software package.
? Vector Quantization: Positive and negative models learned as collections of K clusters
using the K-Means algorithm. Then the decision rule is Nearest Neighbor, that is whether
the closest cluster belongs to positive or negative model.
? Non-negative Matrix Factorization: Feature vectors are collected in a matrix V , and the factorization that minimizes ||Y ? W H||22 with W, H nonnegative is computed using the multiplicative update algorithm of [13]. Using an analogy with the LDA model, the columns
of W contain the topic distributions, while the columns of H represent the component
weights. A classifier is obtained as the difference of the residuals of the feature projections
on the positive and negative models.
From the plot we see how the results of our approach are comparable with the performance of the
Linear SVM, while being far superior to the other generative approaches. We would like to stress
that a sole comparison on detection performance with state-of-the discriminative classifiers would
be inappropriate, since our model targets pose classification which is harder than binary detection.
A fair comparison should divide the dataset in classes and compare our model with a multiclass
classifier. But then we would face the difficult problem of how to label human poses.
For the experiments on pose classification and matching, we used the CMU Mobo dataset [11]. It
consists of sequences of subjects performing different motion patterns, each sequence taken from 6
different views. In the experiments we used 22 sequences of fast walking motion, picking the first
100 frames from each sequence.
In the first experiment we trained the model with all the views and set the number of topics equal
to the number of views, K = 6. As expected, each topic distribution represents a view and by
assigning every image I to the topic k with highest proportion k = arg maxk ??k (I) we correctly
associated all the images from the same view to the same topic.
To obtain a more challenging setup, we restricted to a single view and tested the classification performance of our approach in matching poses. We learned a model with K = 8 topics from 16 training
sequences, and used the remaining 6 for testing. In Figure 2 we show sample topics distributions
from this model. In Figure 3, for each test sequence we display a sample frame and the associated top ten matches from the training data according to the score (4). We can see how the pose is
matched against change of appearance and motion style, specifically a test subject pose is matched
to similar poses of different subjects in the training set. This shows how the topic representation
factors out most of the appearance variations and retains only essential information on the pose.
In order to give a quantitative evaluation of the pose matching performance and compare with other
approaches, we labeled the dataset by mapping the set of walking poses to the interval [0, 1]. We
manually assigned 0 to the frames at the beginning of the double support phase, when the swinging

Effect of Histogram Quantization on Human Detection

Detector Performance Comparison

0.2
0.5
0.1

miss rate

miss rate

0.2
0.05

0.1
0.05

0.02

0.01 ?6
10

Continous
32 Levels
16 Levels
8 Levels
4 Levels
?5

10

0.02

?4

?3

?2

10
10
10
false positives per window (FPPW)

?1

10

0.01 ?3
10

NMF
VQ
LDA Gibbs
LDA MF
Linear SVM
?2

?1

10
10
false positives per window (FPPW)

Figure 1: Human detection results. (Left) Effect on human detection performances of quantizing the histogram of oriented gradient descriptor [6] for a boosted linear SVM classifier based on these features. Here
we show false positive vs. false negative curves on log scale. We can see that for 16 quantization levels or
more the differences are negligible, thus validating our discrete approach. (Right) Performances of five detectors using HOG features trained without boosting and tested on the INRIA dataset: LDA detectors learned by
Gibbs Sampling and Mean Field, Vector Quantization, Non-negative Matrix Factorization - all with K = 24
components/codewords - and Linear SVM. We can see how the Gibbs LDA outperform by far the other unsupervised clustering techniques and scores comparably with the Linear SVM, which is specifically optimized
for the simpler binary classification problem.

Figure 2: Topics distributions and clusters. We show sample topics (2 out of 8) from the LDA model trained
on the single view Mobo sequences. For each topic k, we show 12 images in 2 rows. The first column shows the
distribution of local orientations associated with topic k: (top) visualization of the orientations and (bottom)
average gradient intensities for each cell. The right 5 columns show the top ten images in the dataset with
highest topic proportion ??k , shown below each image. We can see that topics are tightly related to pose classes.

foot touches the ground, and 1 to the frames where the legs are approximately parallel. We labeled
the remaining frames automatically using linear interpolation between keyframes. The average interval between keyframes is 8.1 frames, this motivates our choice of the number of topics K = 8.
For each test frame, we computed the pose error as the difference between the associated pose value
and the average pose of the best top 10 matches in the training dataset. We obtained an average error
of 0.16, corresponding to 1.3 frames. In Figure 4 we show the average pose error per test sequence
obtained with our approach compared with Vector Quantization, where the pose is obtained as average of labels associated with the closest clusters, and Non-negative Matrix Factorization, where as in
LDA similarity of poses is computed as dot product of the component weights. In all the models we
set equal number of components/clusters to K = 8. We can see that our approach performs best in
all testing sequences. In Figure 4 we also show the average pose error when matching test frames to
a single train sequence. Although the different appearance affects the matching performance, overall the results shows how our approach can be successfully applied to automatically match poses of
different subjects.

6

Conclusions

We introduce a novel approach to human detection, pose classification and matching from a single
image. Starting from a representation robust to a limited range of variations in the appearance of
humans in images, we derive a generative probabilistic model which allows for automatic discovery
of pose information. The model can successfully perform detection and provides a low dimensional
representation of the pose. It automatically clusters the images using representative distributions and
allows for an efficient approach to pose matching. Our experiments show that our approach matches
or exceeds the state of the art in human detection, pose classification and matching.

Figure 3: Pose matching examples. On the left one sample frame from test sequences, on the right the top
10 matches in the training set based on the similarity score (4), reported below the image. We can see how
our approach allows to match poses even despite large changes in appearance, and the same pose is correctly
matched across different subjects.

Average Pose Error

0.5

LDA Gibbs
LDA MF
NMF
VQ

0.4
0.3
0.2
0.1
0

Figure 4: Pose matching error. (Left) Average pose error in matching test sequences to the training set, for
our model (both Gibbs and Mean Field learning), Non-Negative Matrix Factorization and Vector Quantization.
We see how our model trained with Gibbs sampling model clearly outperforms the other approaches. (Right)
Average pose error in matching test and training sequence pairs with our approach, where each row is a test
sequence and each column a training sequence. The highest error corresponds to about 2 frames, while the
mean error is 0.16 and amounts to approximately 1.3 frames.

Acknowledgments
This work was conducted while the first author was an intern at Honda Research Institute in 2005.
Work at UCLA was supported by AFOSR F49620-03-1-0095 and ONR N00014-03-1-0850:P0001.

References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]
[20]
[21]
[22]
[23]

A. Agarwal and B. Triggs. 3d human pose from silhouettes by relevance vector regression. CVPR, 2004.
A. Agarwal and B. Triggs. Hyperfeatures: Multilevel local coding for visual recognition. ECCV, 2006.
D. Blei, A. Ng, and M. Jordan. Latent drichlet allocation. Journal on Machine Learning Research, 2003.
W. Buntine and A. Jakulin. Discrete principal component analysis. HIIT Technical Report, 2005.
J. Canny. GaP: a factor model for discrete data. ACM SIGIR, pages 122?129, 2004.
N. Dalal and B. Triggs. Histograms of oriented gradients for human detection. CVPR, 2005.
P. F. Felzenszwalb and D. P. Huttenlocher. Efficient matching of pictorial structures. CVPR, 2000.
R. Fergus, L. Fei-Fei, P. Perona, and A. Zisserman. Learning object categories from Google?s image
search. Proc. ICCV, pages 1816?1823, 2005.
D. M. Gavrila and V. Philomin. Real-time object detection for smart vehicles. Proc. ICCV, 1999.
T. L. Griffiths and M. Steyvers. Finding scientific topics. Proc. National Academy of Science, 2004.
R. Gross and J. Shi. The cmu motion of body dataset. Technical report, CMU, 2001.
G.Shakhnarovich, P.Viola, andT.Darrell. Fast pose estimation with parameter-sensitive hashing. ICCV, 2003..
D. Lee and H. Seung. Learning the parts of objects by non-negative matrix factorization. Nature, 1999.
D. G. Lowe. Object recognition from local scale-invariant features. Proc. ICCV, pages 1150?1157, 1999.
G. Mori, X. Ren, A. A. Efros, and J. Malik. Recovering human body configurations: Combining segmentation and recognition. Proc. CVPR, 2:326?333, 2004.
J. C. Niebles, H. Wang, and L. Fei-Fei. Unsupervised learning of human action categories using spatialtemporal words. Proc. BMVC, 2006.
K. Nigam, A. K. McCallum, S. Thurn, and T. Mitchell. Text classification from labeled and unlabeled
documents using EM. Machine Learning, pages 1?34, 2000.
P.Viola, M.Jones, and D.Snow. Detecting pedestrians using patterns of motion and appearance. ICCV, 2003
.
R. Ronfard, C. Schmid, and B. Triggs. Learning to parse pictures of people. ECCV, 2002.
R. Rosales and S. Sclaroff. Inferring body without tracking body parts. Proc. CVPR, 2:506?511, 2000.
L. Sigal, M. Isard, B. H. Sigelman, and M. Black. Attractive people: Assembling loose-limbed models
using non-parametric belief propagation. Proc. NIPS, pages 1539?1546, 2003.
J. Sivic, B. C. Russell, A. A. Efros, A. Zisserman, and W. T. Freeman. Discovering object categories in
image collections. Proc. ICCV, 2005.
M. Weber, M. Welling, and P. Perona. Toward automatic discovery of object categories. CVPR, 2000.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 802-constructive-learning-using-internal-representation-conflicts.pdf

Constructive Learning Using Internal
Representation Conflicts

Laurens R. Leerink and Marwan A. J abri
Systems Engineering & Design Automation Laboratory
Department of Electrical Engineering
The University of Sydney
Sydney, NSW 2006, Australia

Abstract
We present an algorithm for the training of feedforward and recurrent neural networks. It detects internal representation conflicts
and uses these conflicts in a constructive manner to add new neurons to the network . The advantages are twofold: (1) starting with
a small network neurons are only allocated when required; (2) by
detecting and resolving internal conflicts at an early stage learning
time is reduced. Empirical results on two real-world problems substantiate the faster learning speed; when applied to the training
of a recurrent network on a well researched sequence recognition
task (the Reber grammar), training times are significantly less than
previously reported .

1

Introduction

Selecting the optimal network architecture for a specific application is a nontrivial
task, and several algorithms have been proposed to automate this process. The
first class of network adaptation algorithms start out with a redundant architecture
and proceed by pruning away seemingly unimportant weights (Sietsma and Dow,
1988; Le Cun et aI, 1990). A second class of algorithms starts off with a sparse
architecture and grows the network to the complexity required by the problem.
Several algorithms have been proposed for growing feedforward networks. The
upstart algorithm of Frean (1990) and the cascade-correlation algorithm of Fahlman
(1990) are examples of this approach.

279

280

Leerink and Jabri

The cascade correlation algorithm has also been extended to recurrent networks
(Fahlman, 1991), and has been shown to produce good results. The recurrent
cascade-correlation (RCC) algorithm adds a fully connected layer to the network
after every step, in the process attempting to correlate the output of the additional
layer with the error. In contrast, our proposed algorithm uses the statistical properties of the weight adjustments produced during batch learning to add additional
units.
The RCC algorithm will be used as a baseline against which the performance of
our method will be compared. In a recent paper, Chen et al (1993) presented an
algorithm which adds one recurrent neuron with small weights every N epochs.
However, no significant improvement in training speed was reported over training
the corresponding fixed size network, and the algorithm will not be further analyzed.
To the authors knowledge little work besides the two mentioned papers have applied
constructive algorithms to recurrent networks.
In the majority of our empirical studies we have used partially recurrent neural
networks, and in this paper we will focus our attention on such networks. The motivation for the development of this algorithm partly stemmed from the long training
times experienced with the problems of phoneme and word recognition from continuous speech. However, the algorithm is directly applicable to feedforward networks.
The same criteria and method used to add recurrent neurons to a recurrent network
can be used for adding neurons to any hidden layer of a feed-forward network.

2

Architecture

In a standard feedforward network, the outputs only depend on the current inputs,
the network architecture and the weights in the network. However, because of the
temporal nature of several applications, in particular speech recognition, it might
be necessary for the network to have a short term memory.
Partially recurrent networks, often referred to as Jordan (1989) or Elman (1990)
networks, are well suited to these problems. The architecture examined in this
paper is based on the work done by Robinson and Fallside (1991) who have applied
their recurrent error propagation network to continuous speech recognition.
A common feature of all partially recurrent networks is that there is a special set
of neurons called context units which receive feedback signals from a previous time
step. Let the values of the context units at time t be represented by C(t). During
normal operation the input vector at time t are applied to the input nodes I(t), and
during the feedforward calculation values are produced at both the output nodes
O(t + 1) and the context units C(t + 1). The values of the context units are then
copied back to the input layer for use as input in the following time step.
Several training algorithms exist for training partially recurrent neural networks,
but for tasks with large training sets the back-propagation through time (Werbos,
1990) is often used. This method is computationally efficient and does not use
any approximations in following the gradient. For an application where the time
information is spread over T. input patterns, the algorithm simply duplicates the
network T times - which results in a feedforward network that can be trained by a
variation of the standard backpropagation algorithm.

Constructive Learning Using Internal Representation Conflicts

3

The Algorithm

For partially recurrent networks consisting of input, output and context neurons,
the following assertions can be made:
? The role of the context units in the network is to extract and store all
relevant prior information from the sequence pertaining to the classification
problem.
? For weights entering context units the weight update values accumulated
during batch learning will eventually determine what context information
is stored in the unit (the sum of the weight update values is larger than the
initial random weights).
? We assume that initially the number of context units in the network is
insufficient to implement this extraction and storage of information (we
start training with a small network). Then, at different moments in time
during the recognition of long temporal sequences, a context unit could be
required to preserve several different contexts.
? These conflicts are manifested as distinct peaks in the distribution of the
weight update values during the epoch.
All but the last fact follows directly from the network architecture and requires no
further elaboration. The peaks in the distribution of the weight update values are a
result of the training algorithm attempting to adjust the value of the context units in
order to provide a context value that will resolve short-term memory requirements.
After the algorithm had been developed, it was discovered that this aspect of the
weight update values had been used in the past by Wynne-Jones (1992) and in
the Meiosis Networks of Hanson (1990). The method of Wynne-Jones (1992) in
particular is very closely related; in this case principal component analysis of the
weight updates and the Hessian matrix is used to detect oscillating nodes in fully
trained feed-forward networks. This aspect of backpropagation training is fully
discussed in Wynne-Jones (1992), to which reader is referred for further details.
The above assertions lead to the proposed training algorithm, which states that if
there are distinct maxima in the distribution of weight update values of the weights
entering a context unit, then this is an indication that the batch learning algorithm
requires this context unit for the storage of more than one context.
If this conflict can be resolved, the network can effectively store all the contexts
required, leading to a reduction in training time and potentially an increase III
performance .
The training algorithm is given below (the mode of the distribution is defined as
the number of distinct maxima):

For all context units {
Set N = modality ot the distribution ot weight update values;
It N > 1 then {
Add N-1 new context units to the network which are identical
(in terms ot weighted inputs) to the current context unit.

281

282

Leerink and Jabri

Adjust each of these N context units (including the
original) by the weight update value determined by each
maxima (the average value of the mode).
Adjust all weights leaving these N context units so that the
addition of the new units do not affect any subsequent layers
(division by N). This ensures that the network retains all
previously acquired knowledge.
}
}

The main problem in the implementation of the above algorithm is the automatic
detection of significant maxima in the distribution of weight updates. A standard
statistical approach for the determination of the modality (the number of maxima)
of a distribution of noisy data is to fit a curve of a certain predetermined order to
the data. The maxima (and minima) are then found by setting the derivative to
zero. This method was found to be unsuitable mainly because after curve fitting it
was difficult to determine the significance of the detected peaks.
It was decided that only instances of bi-modality and tri-modality were to be iden-

tified, each corresponding to the addition of one or two context units. The following
heuristic was constructed:
? Calculate the mean and standard deviation of the weight update values.
? Obtain the maximum value in the distribution.
? If there are any peaks larger than 60% of the maxima outside one standard
deviation of the mean, regard this as significant.
This heuristic provided adequate identification of the modalities. The distribution
was divided into three areas using the mean ? the standard deviation as boundaries.
Depending on the number of maxima detected, the average within each area is used
to adjust the weights.

4

Discussion

According to our algorithm it follows that if at least one weight entering a context
unit has a multi-modal distribution, then that context unit is duplicated. In the
case where multi-modality is detected in more than one weight, context units were
added according to the highest modality.
Although this algorithm increases the computational load during training, the standard deviation of the weight updates rapidly decreases as the network converges.
The narrowing of the distribution makes it more difficult to determine the modality. In practice it was only found useful to apply the algorithm during the initial
training epochs, typically during the first 20.
During simulations in which strong multi-modalities were detected in certain nodes,
frequently the multi-modalities would persist in the newly created nodes. In this

Constructive Learning Using Internal Representation Conflicts

manner a strong bi-modality would cause one node to split into two, the two nodes
to grow to four, etc. This behaviour was prevented by disabling the splitting of
a node for a variable number of epochs after a multi-modality had been detected.
Disabling this behaviour for two epochs provided good results.

5

Simulation Results

The algorithm was evaluated empirically on two different tasks:
? Phoneme recognition from continuous multi-speaker speech usmg the
TIMIT (Garofolo, 1988) acoustic-phonetic database .
? Sequence Recognition: Learning a finite-state grammar from examples of
valid sequences.
For the phoneme recognition task the algorithm decreased training times by a factor
of 2 to 10, depending on the size of the network and the size of the training set.
The sequence recognition task has been studied by other researchers in the past, notably Fahlman (1991). Fahlman compared the performance of the recurrent cascade
correlation (RCC) network with that of previous results by Cleeremans et al (1989)
who used an Elman (1990) network. It was concluded that the RCC algorithm
provides the same or better performance than the Elman network with less training
cycles on a smaller training set. Our simulations have shown that the recurrent
error propagation network of Robinson and Fallside (1991), when trained with our
constructive algorithm and a learning rate adaptation heuristic, can provide the
same performance as the RCC architecture in 40% fewer training epochs using a
training set of the same size. The resulting network has the same number of weights
as the minimum size RCC network which correctly solves this problem.
Constructive algorithms are often criticized in terms of efficiency, i.e. "Is the increase in learning speed due to the algorithm or just the additional degrees of
freedom resulting from the added neuron and associated weights?". To address this
question several simulations were conducted on the speech recognition task, comparing the performance and learning time of a network with N fixed context units
to that of a network with small number of context units and growing a network
with a maximum of N context units. Results indicate that the constructive algorithm consistently trains faster, even though both networks often have the same
final performance.

6

Summary

In this paper the statistical properties of the weight update values obtained during
the training of a simple recurrent network using back-propagation through time
have been examined. An algorithm has been presented for using these properties to
detect internal representation conflicts during training and to use this information
to add recurrent units to the network. Simulation results show that the algorithm
decreases training time compared to networks which have a fixed number of context
units. The algorithm has not been applied to feedforward networks, but can III
principle be added to all training algorithms that operate in batch mode.

283

284

Leerink and Jabri

References

Chen, D., Giles, C.L., Sun, G.Z., Chen, H.H., Lee, Y.C., Goudreau, M.W. (1993).
Constructive Learning of Recurrent Neural Networks. In 1993 IEEE International
Conference on Neural Networks, 111:1196-1201. Piscataway, NJ: IEEE Press.
Cleeremans, A., Servan-Schreiber, D., and McClelland, J.L. (1989). Finite State
Automata and Simple Recurrent Networks. Neural Computation 1:372-381.
Elman, J .L. (1990). Finding Structure in Time. Cognitive Science 14:179-21l.
Fahlman, S.E. and C. Lebiere (1990). The Cascade Correlation Learning Architecture. In D. S. Touretzky (ed.), Advances in Neural Information Processing Systems
2, 524-532. San Mateo, CA: Morgan Kaufmann.
Fahlman, S.E. (1991). The Recurrent Cascade Correlation Architecture. Technical
Report CMU-CS-91-100. School of Computer Science, Carnegie Mellon University.
Frean, M. (1990). The Upstart Algorithm: A Method for Constructing and Training
Feedforward Neural Networks. Neural Computation 2:198-209.
Garofolo, J.S. (1988). Getting Started with the DARPA TIMIT CD-ROM: an
Acoustic Phonetic Continuous Speech Database. National Institute of Standards
and Technology (NIST), Gaithersburgh, Maryland.
Hanson, S.J. (1990). Meiosis Networks. In D. S. Touretzky (ed.), Advances in Neural Information Processing Systems 2, 533-541, San Mateo, CA: Morgan Kaufmann.
Jordan, M.1. (1989). Serial Order: A Parallel, Distributed Processing Approach. In
Advances in Connectionist Theory: Speech, eds. J.L. Elman and D.E. Rumelhart.
Hillsdale: Erlbaum.
Le Cun, Y., J .S. Denker, and S.A Solla (1990). Optimal Brain Damage. In D. S.
Touretzky (ed.), Advances in Neural Information Processing Systems 2, 598-605.
San Mateo, CA: Morgan Kaufmann.
Reber, A.S. (1967). Implicit learning of artificial grammars. Journal of Verbal
Learning and Verbal Behavior 5:855-863.

Robinson, A.J. and Fallside F. (1991). An error propagation network speech recognition system. Computer Speech and Language 5:259-274.
Sietsma, J. and RJ.F Dow (1988). Neural Net Pruning-\Vhy and How. In IEEE
International Conference on Neural Networks. (San Diego 1988), 1:325-333.
Wynne-Jones, M. (1992) Node Splitting: A Constructive Algorithm for FeedForward Neural Networks. In D. S. Touretzky (ed.), Advances in Neural Information Processing Systems 4, 1072-1079. San Mateo, CA: Morgan Kaufmann.
Werbos, P.J. (1990). Backpropagation Through Time, How It Works and How to
Do It. Proceedings of the IEEE, 78:1550-1560.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

