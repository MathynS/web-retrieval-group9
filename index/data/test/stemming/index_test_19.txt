query sentence: Sentiment of tweets on twitter
---------------------------------------------------------------------
title: 5275-global-belief-recursive-neural-networks.pdf

global belief recurs neural network romain paulus richard socher metamind palo alto ca romain richard metamind.io christoph d. man stanford univers serra mall stanford ca man stanford.edu abstract recurs neural network recent obtain state art perform sever natur languag process task howev feedforward architectur correct predict phrase word label determin context problem task aspect-specif sentiment classif tri instanc predict word android posit sentenc android beat io introduc global belief recurs neural network gb-rnns base idea extend pure feedforward neural network includ one feedbackward step infer allow phrase level predict represent give feedback word show effect model task contextu sentiment analysi also show dropout improv rnn train combin unsupervis supervis word vector represent perform better either alon feedbackward step improv f1 perform standard rnn task obtain state-of-the-art perform semev challeng accur predict sentiment specif entiti introduct model natur languag need abil compos mean word phrase order understand complex utter fact multi-word entiti sentenc stori recent lot work extend singl word semant vector space composit model bigram phrase arbitrari length work area far focus comput mean longer phrase pure feedforward type architectur mean shorter constitu compos alter howev full treatment semant interpret achiev without take consider mean word phrase also chang sentenc context observ take instanc sentenc android screen better iphon current recurs deep learn sentiment model would attempt classifi phrase android screen iphon simpli neutral sentiment overal sentenc undefin depend entiti user sentiment analysi care general mani analys social media text user inde interest sentiment direct toward specif entiti phrase order solv contextu classif problem general aspect-specif sentiment classif particular introduc global belief recurs neural network gb-rnn model general pure feedforward recurs neural network rnns includ feedbackward step infer time backward comput use represent step recurs allow phrase updat predict base global context sentenc unlik recurr neural network window-bas method import context mani part research perform author stanford univers android beat io figur illustr problem sentiment classif use phrase label ignor context word android neutral isol becom posit context word away phrase label allow model correct classifi sentenc android describ posit sentiment io neither possibl determin respect phrase isol order valid gb-rnn abil contextu disambigu sentiment real text use twitter dataset annot semev challeng task gb-rnn outperform standard rnn baselin well winner sentiment competit semev show success make use surround context relat work neural word vector one common way repres word use distribut word vector learn via dimension reduct larg co-occurr matric document latent semant analysi local context window combin word similar mean close vector space sinc unsupervis word vector comput local context window alway encod task-specif inform sentiment word vector also fine-tun specif task introduc hybrid approach dimens obtain unsupervis model other learn supervis task show perform better pure supervis unsupervis semant word vector recurs neural network idea recurs neural network rnns natur languag process nlp train deep learn model appli input length unlik comput vision task easi resiz imag fix number pixel natur sentenc fix size input howev phrase sentenc grammat structur pars binari tree follow tree structur assign fixed-length vector word leav tree combin word phrase pair recurs creat intermedi node vector length eventu one final vector repres whole sentenc multipl recurs combin function explor linear transform matric tensor product work use simpl singl matrix rnn combin node vector recurs step bidirectional-recurr bidirectional-recurs neural network recurr neural network special case recurs neural network oper chain tree unlik recurs neural network requir tree structur usual appli time seri recurr neural network everi node combin summar represent past node result combin forward next node bidirect recurr neural network architectur also explor usual comput represent independ end time seri bidirect recurs model develop parallel extend definit recurs neural netword ad backward propag step inform also flow tree root back leav compar model theoret model section empir experi http //www.cs.york.ac.uk/semeval-2013/task2 figur propag step gb-rnn step describ standard rnn feedforward process show vector represent android independ rest document step comput addit vector node red use inform higher level node tree blue allow android io differ represent given context unfold autoencod multipl time give represent power number paramet model differ take consider inform step eventu make better local predict use global context sentiment analysi sentiment analysi subject research time approach sentiment analysi use bag word represent take phrase structur account learn word-level featur explor model abil determin contextu sentiment twitter social media platform global belief recurs neural network section introduc new model comput context-depend composit vector represent variabl length phrase vector train use featur classifi phrase word show exampl phrase comput describ detail section begin motiv composit context-depend follow definit standard recurs neural network next introduc novel global belief model hybrid unsupervised-supervis word vector context-depend motiv global belief common simplifi assumpt map sentenc featur vector word order matter bag word howev prevent detail understand languag exemplifi overal sentiment phrase android beat io unclear instead need understand phrase lead us deep recurs model first step map sentenc vector space pars binari tree structur captur grammat relationship word input depend binari tree determin architectur recurs neural network comput hidden vector bottom-up fashion start word vector result phrase vector given featur classifi standard rdl architectur work well classifi inher contextindepend label phrase instanc correct classifi beauti day negat sentiment howev phrase inher sentiment shown gb-rnn address issu propag inform root node back leaf node describ way context incorpor bi-direct recurr neural network window-bas method method howev incorpor inform word away phrase label standard recurs neural network first describ simpl recurs neural network use context-independ phraselevel classif also seen first step gb-rnn assum word vector rn obtain sampl element uniform distribut vector column larg embed matrix rn |v size vocabulari word vector learn togeth model exampl word vector sequenc abc rnn equat becom p1 p2 p1 rn 2n matrix govern composit non-linear activ function node vector given input softmax classifi classif task sentiment analysi gb-rnn global belief recurs neural network goal includ contextu inform recurs node vector represent one simpl solut would includ context word left right pair howev work necessari context word away furthermor order captur complex linguist phenomena may necessari allow multipl word compos contextu shift mean instead use feedforward node standard rnn architectur simpli move back tree also interpret unfold tree move branch henc keep comput forward node vector introduc new feedbackward vector denot arrow everi level pars tree unlik feedforward vector comput bottom-up recurs function feedbackward vector comput top-down recurs function backward pass start root node propag way singl word vector root note exampl node p2 p2 vnd node vector nd dimension start recurs get node vector everi node go tree p2 p1 p2 p1 all vector nd dimension henc r n+nd new de-composit matrix figur step illustr top-down recurs comput exampl onc feedforward feedbackward vector given node concaten employ standard softmax classifi final predict instanc classif word make becom ya softmax wc fold bias c-class classifi weight wc root node equat x root could replac simpli copi x root xroot there two advantag introduc transform matrix first help clear differenti featur comput forward step backward step multipl second allow use differ dimens vector reduc number paramet wclass matric add flexibl model also perform better empir hybrid word vector represent there two way initi word vector given input rnn model simplest one initi small random number mention backpropag error signal order captur necessari inform task hand advantag requir pre-train method vector sure captur domain knowledg howev vector like overfit less like general well word usual smaller label train set anoth approach figur hybrid unsupervised-supervis vector represent frequent word dataset horizont vector first dimens train unlabel twitter messag last dimens train label contextu sentiment exampl use unsupervis method learn semant word vector one option backpropag task specif error vector keep initi backpropag still potenti disadvantag hurt general apart slow train sinc increas number paramet larg amount there usual mani paramet embed matrix l without propag inform howev one hope unsupervis method realli captur all necessari semant inform often case sentiment suffer antonym problem paper propos combin idea repres word concaten unsupervis vector kept initi train ad small addit vector propag task specif error signal vector represent appli feedforward word vector shold confus combin feedwordard feedbackward node vector softmax figur show result word vector train unlabel document one part first dimens train label exampl part remain dimens train gb-rnn train use backpropag structur train paramet optim regular cross-entropi error label node vector mini-batch adagrad sinc label everi node train tree decid unlabel node add addit error train all model use develop set cross-valid regular differ weight word vector size mini-batch size dropout probabl activ function rectifi linear logist function also appli dropout techniqu improv train high dimension word vector node vector unit random set zero probabl train step experi show appli dropout way help differenti word vector unit hidden unit lead better perform high-dimension hybrid word vector introduc previous obtain higher accuraci word vector use dropout comparison model idea unfold neural network common use autoencod well recurs set set unfold use train infer time updat belief input irsoy cardi introduc bidirect rnn similar employ standard feedforward rnn differ comput backward vector practic model defin forward equat howev equat comput backward vector instead wlb wrb p1 correct fusion 5th general meet tonight ic come carv pumpkin mid-quart us correct i would rather eat left foot take sat tomorrow correct special thank everyon come taboo tuesday dst tonight fun educ xietadst correct tough loss statebasebal today good luck monday select sunday correct i got job clayton i start monday sheetrock moneymakin correct st patti big deal fuck given cinco de mayo hand that 2nd bday incorrect hannah sunder walk dead great tv show bad ass start watch 2nd season catch 3rd figur exampl predict made gb-rnn twitter document exampl red phrase negat blue phrase posit last exampl model predict incorrect bad ass negat wlb wrb two matric dimens nd nd better comparison model rewrit make explicit block wlf wlb wlf p1 wlb let wrf wrb wrf p1 wrb p1 dimens wlf wrf nd dimens wld wrd nd nd closer comparison eq reveal use left right forward transfor mation wlf p1 wrf p1 part sum differ bidirectional-rnn transform children defin forward parent independ posit left right node wherea gb-rnn make use forward backward parent node intuit behind choic use node help push model disentangl children backward parent vector also note model use forward node vector comput backward node vector but find necessari sinc softmax function alreadi combin two vector model also nd paramet comput feedbackward vector bidirectional-rnn matrix our model 2n nd paramet other model total nd paramet wlf wrf matric we show next section gb-rnn outperform bidirect rnn our experi experi we present qualit quantit analysi gb-rnn contextu sentiment classif task main dataset provid semev task competit we outperform winner challeng well sever baselin model ablat evalu dataset semev competit dataset compos tweet label differ sentiment class posit neutral negat tweet dataset split train label phrase develop development-test set final test set compos exampl show exampl gb-rnn predict phrase mark classif this dataset develop dataset consist tweet wherea final evalu dataset includ also short text messag sms in tabl tweet pars use stanford parser includ token negat becom two token we constrain parser keep phrase label dataset insid subtre label exampl repres singl node classifi easili classifi svm svm svm gb-rnn featur set stem word cluster sentiwordnet score negat pos lexicon negat emoticon elong word score syntact depend pmi punctuat word n-gram emoticon charact n-gram elong word upper case stopword phrase length negat phrase posit larg sentiment lexicon microblog featur parser unsupervis word vector ensembl twitter sms tabl comparison best semev task system featur set f1 result dataset predict sentiment phrase in context gb-rnn obtain state art perform dataset model bigram naiv bay logist regress svm rnn bidirectional-rnn irsoy cardi gb-rnn best singl model twitter sms tabl comparison baselin f1 score semev test dataset comparison competit system first comparison sever high tune system semev task competit competit score averag posit negat class f1 score tabl list result sever method togeth resourc featur use method most system use consider amount hand-craft featur in contrast gb-rnn need parser tree structur unsupervis word vector train data sinc competit allow extern data we outlin addit train data we use our best model ensembl top gb-rnn model train independ predict averag produc final output comparison baselin next we compar our singl best model sever baselin model ablat we use hybrid word vector dropout train rnn bidirect rnn gb-rnn best model select cross-valid dev set sever hyper-paramet word vector dimens hidden node vector dimens number train epoch regular paramet activ function train batch size dropout probabl we kept model highest cross-valid accuraci tabl show these result the most import comparison the pure feedforward rnn take backward sentenc context account this model perform wors the gb-rnn the logist regress bigram naiv bay classif label phrase taken separ exampl remov the surround context anoth set baselin use context window for classif well the entir tweet input the classifi optim perform for the singl best gb-rnn achiev use vector size dimens pre-train fix word vector train sentiment data mini-batch size dropout sigmoid non-linear in tabl we show the concaten fix unsupervis vector addit random initi supervis vector perform better method model analysi addit train data the competit allow the usag arbitrari resourc we includ train data label unigram bigram extract the nrc-canada system sentiment lexicon ad these addit train exampl increas accuraci although this lexicon help reduc7 word vector supervis word vector semant word vector hybrid word vector dimens twitter sms tabl f1 score comparison word vector the semev task test dataset chelski want this chelski bad want this make even it bad even think we may happier beat make think we may happier twice in beat day sb twice in day at sb figur chang in sentiment predict in the tweet chelski want this bad it make even happier think we may beat twice in day at sb the rnn left the gb-rnn right in particular we see the chang for the phrase want this bad where it correct predict posit with context ing the number unknown token it good job for train recurs composit function becaus each exampl short we also includ our dataset compos noisili label tweet use heurist smiley face well the movi review dataset in both dataset the label denot the context-independ sentiment phrase full sentenc henc we train the final model in two step train the standard rnn train the full gb-rnn model on the smaller context-specif competit data train the gb-rnn joint in this fashion gave accuraci improv conclus we introduc global belief recurs neural network appli the task contextu sentiment analysi the idea propag belief neural network a power import piec for interpret natur languag the applic this idea general rnns help for a varieti nlp task such word-sens disambigu acknowledg we thank the anonym review for their valuabl comment
----------------------------------------------------------------

title: 5860-on-the-job-learning-with-bayesian-decision-theory.pdf

on-the-job learn bayesian decis theori keenon werl depart comput scienc stanford univers keenon cs.stanford.edu arun chaganti depart comput scienc stanford univers chaganti cs.stanford.edu perci liang depart comput scienc stanford univers pliang cs.stanford.edu christoph d. man depart comput scienc stanford univers man cs.stanford.edu abstract goal deploy high-accuraci system start zero train exampl consid on-the-job set input arriv use real-tim crowdsourc resolv uncertainti need output predict confid model improv time relianc crowdsourc queri decreas cast set stochast game base bayesian decis theori allow us balanc latenc cost accuraci object principl way comput optim polici intract develop approxim base mont carlo tree search test approach three dataset named-ent recognit sentiment classif imag classif ner task obtain order magnitud reduct cost compar full human annot boost perform relat expert provid label also achiev f1 improv singl human label whole set f1 improv onlin learn poor pupil surpass master leonardo da vinci introduct two road accur ai system today gather huge amount label train data supervis learn use crowdsourc direct perform task howev solut requir non-trivi amount time money mani situat one wish build new system twitter inform extract aid disast relief effort monitor public opinion one simpli lack resourc follow either pure ml pure crowdsourc road paper propos framework call on-the-job learn formal extend idea first implement produc high qualiti result start without requir train model new input arriv system choos asynchron queri crowd part input uncertain queri label singl token sentenc collect enough evid system make predict goal maintain high accuraci initi use crowd crutch gradual becom self-suffici model improv onlin learn onlin activ learn differ activ seek new inform prior make predict maintain high accuraci independ number data instanc seen far activ classif like us get belief decid ask crowd learn model georg worker real time person resourc none locat http //www.crowd-workers.com georg soup georg str katrina y1 y2 y3 y4 y5 x3 x4 x5 soup georg str katrina incorpor feedback return predict resourc locat soup georg str katrina y1 y2 y3 y4 y5 x3 x4 x5 locat person resourc r1 none figur name entiti recognit tweet on-the-job learn strateg seek inform queri subset label prior predict base static polici wherea improv model test time base observ data determin queri make model on-the-job learn stochast game base crf predict model use bayesian decis theori tradeoff latenc cost accuraci principl manner framework natur give rise intuit strategi achiev high accuraci ask redund label offset noisi respons achiev low latenc issu queri parallel wherea latenc unimport issu queri sequenti order adapt comput optim polici intract develop approxim base mont carlo tree search progress widen reason continu time implement evalu system three differ task named-ent recognit sentiment classif imag classif ner task obtain order magnitud reduct cost compar full human annot boost perform relat expert provid label also achiev f1 improv singl human label whole set f1 improv onlin learn open-sourc implement system dub lens learn expens noisi slow expert avail http //www.github.com/keenon/lens problem formul consid structur predict problem input output yn exampl named-ent recognit ner tweet sequenc word tweet georg correspond sequenc label none locat locat full set label person locat resourc none on-the-job learn set input arriv stream input make zero queri q1 q2 crowd obtain label potenti posit respons r1 r2 come back asynchron incorpor current predict model figur left show one possibl outcom queri posit q1 georg q2 first queri return r1 locat upon make anoth queri posit q3 georg suffici model confid entir output return like predict queri qi issu time si respons come back time ti assum queri cost cent goal choos queri maxim accuraci minim latenc cost input make sever remark set first must make predict stream unlik activ learn interest pool stream exampl purpos build good model second respons use updat predict og og og legend none res loc per r1 res q1 r2 loc q2 og og og system crowd tnow r1 loc og r1 loc q1 r1 res r2 per q2 q4 r4 loc incorpor inform respons bar graph repres margin label token indic first charact differ point time two timelin show system updat confid label base crowd respons system continu issu queri suffici confid label see paragraph behavior section inform game tree exampl partial game tree construct system decid action take state queri q1 alreadi issu system must decid whether issu anoth queri wait respons q1 figur exampl behavior run structur predict tweet soup georg str omit resourc game tree visual clariti model like onlin learn allow number queri need thus cost latenc decreas time without compromis accuraci model model on-the-job learn stochast game two player system crowd game start system receiv input end system turn set label yn system turn system may choos queri action ask crowd label yq system may also choos wait action wait crowd respond pend queri return action termin game return predict given respons receiv thus far system make mani queri row simultan want decid wait turn wait action chosen turn switch crowd provid respons one pend queri advanc game clock time taken crowd respond turn immedi revert back system game end system choos return action system evalu util depend accuraci predict number queri issu total time taken system choos queri wait action maxim util predict eventu return rest section describ detail game tree choic util specifi model crowd respons follow brief explor behavior admit model game tree let us formal game tree term state action transit reward see figur 2b exampl game state tnow consist current time tnow action issu time respons receiv time let rj tj iff qj queri action respons receiv time tnow dure system turn system choos action qk state updat tnow q0 s0 r0 t0 q0 qk s0 tnow r0 t0 qk system choos anoth action new state qk crowd make stochast move final qk game end rule possibl launch queri midway wait next respons howev feel like reason limit signific simplifi search space system return best estim label use respons receiv obtain util defin later let qj rj set in-flight request dure crowd turn system choos next respons crowd chosen arg minj f t0j t0j sampl response-tim model t0j pt sj t0j tnow final respons sampl use respons model rj0 p rj0 state updat tj r0 t0 r0 rj0 rk t0 t0j tk util under bayesian decis theori optim choic action state tnow one attain maximum expect util valu game start recal system return time point receiv util trade two thing first accuraci map estim accord model best guess incorpor respons receiv time second cost make queri monetari cost wm per queri made penalti wt per unit time taken formal defin util expacc p nq wm tnow wt expacc p ep accuraci arg max p nq qj number queri made p predict model incorpor crowd respons util wait return action comput take expect subsequ trajectori game tree intract comput exact propos approxim algorithm section environ model final compon model environ crowd given input queri qk issu time sk defin distribut output respons rk respons time tk follow pr ri yqi pt ti si three compon follow predict model standard linear-chain crf pr yq respons model describ distribut crowd respons given queri true answer yq pt ti si specifi latenc queri qi crf model learn base actual respons simul one use adagrad model annot error set pr yq iff yq distribut remain probabl uniform given full model comput simpli margin equat when condit ignor respons yet receiv when rj behavior let look typic behavior expect model util captur figur 2a show margin label chang crowd provid respons run exampl name entiti recognit sentenc soup georg timelin system issu queri soup georg confid predict token first timelin crowd correct respond soup resourc georg locat integr respons system also confid predict turn correct sequenc label second timelin crowd worker make error label georg person system still uncertainti georg issu addit queri receiv correct respons follow system turn correct sequenc label answer still correct system could taken less time respond make addit queri georg begin found human hire rough accur experi game play section model on-the-job learn stochast game play system crowd turn problem actual find polici maxim expect util cours intract larg state space algorithm algorithm combin idea mont carlo tree search systemat explor state space progress widen deal challeng continu variabl time some intuit algorithm provid when simul system turn next state henc action chosen use upper confid tree uct decis rule trade maxim valu next state exploit number visit explor crowd turn simul base transit defin section handl unbound fanout dure crowd turn use progress widen maintain current set activ explor state gradual grown time let number time state visit successor state algorithm sampl algorithm approxim expect util mcts progress widen function mont arlovalu state increment system turn log arg max initi visit util sum children choos next state use uct mont arlovalu record observ util return els crowd spturn restrict continu sampl use pw sampl set alreadi visit base els drawn base end return mont arlovalu els if game termin return util accord end if end function experi section empir evalu approach three task while on-the-job set propos target scenario data begin use exist label dataset tabl gold standard baselin evalu follow four method dataset human n-queri major vote human crowd worker use predict onlin learn use classifi train gold output exampl seen far return mle predict best possibl offlin system see perfect inform data seen far queri crowd while make predict threshold baselin use follow heurist label ask queri instead comput expect margin respons queri flight we simpli count in-flight request given variabl reduc uncertainti variabl factor system continu launch request threshold adjust number queri flight cross dataset exampl ner task note we evalu ner task3 sequenc label problem english sentenc we consid four tag correspond person locat organ none4 sentiment we evalu subset imdb sentiment dataset consist polar movi review goal binari classif document class pos neg we evalu celebr face classif task imag must label one follow four choic andersen cooper daniel craig scarlet johansson miley cyrus face featur we use standard featur current word current lemma previous next lemma lemma window size three left right word shape word prefix suffix well word embed we use two featur set first unigram contain word unigram second rnn also contain sentenc vector embed we use last layer 11layer alexnet train imagenet input featur embed though we leav back-propag net futur work tabl dataset use paper number exampl we evalu system 1-vote 3-vote 5-vote onlin threshold lens delay/tok ms ms ms n/a ms ms name entiti recognit qs/tok per f1 loc f1 n/a org f1 f1 face identif latenc qs/ex acc ms ms ms n/a n/a ms ms tabl result ner face task compar latenc queri per token qs/tok perform metric ner accuraci face predict made use mle model given respons baselin reason time make queri begin lens full system describ section implement crowdsourc setup we implement retain model amazon mechan turk creat pool crowd worker could respond queri real-tim worker given short tutori each task join pool minim systemat error caus misunderstand task we paid worker join retain pool addit per queri ner sinc respons time much faster we paid per queri worker respons time general rang second ner second sentiment second face when run experi we found result vari base current worker qualiti control varianc worker qualiti across evalu differ method we collect worker respons delay each label ahead time5 dure simul we sampl worker respons delay without replac frozen pool worker respons summari result tabl tabl summar perform method three task three dataset we found on-the-job learn outperform machin human-on http //www.cnts.ua.ac.be/conll2003/n origin also includ fifth tag miscellan howev definit miscellaneo complex make difficult non-expert crowd worker provid accur label dataset avail code repositori paper system 1-vote 3-vote 5-vote unigram unigram rnn embed queri per exampl qs/ex acc n/a n/a n/a n/a unigram onlin threshold lens rnn latenc onlin threshold lens time figur queri per exampl lens sentiment simpl unigram featur model quick learn capac answer confid must queri crowd complex rnn featur model learn confid queri crowd less time tabl result sentiment task compar latenc queri per exampl accuraci queri per token f1 lens vote baselin lens onlin learn time time figur compar f1 queri per token ner task time left graph compar lens onlin learn queri human test time highlight lens maintain high f1 score even small train set size fall back crowd when unsur right graph compar queri rate time 1-vote clear show model learn need queri crowd less comparison qualiti cost ner we achiev f1 an order magnitud reduct cost achiev compor qualiti result use 5-vote approach sentiment face we reduc cost compar accuraci factor around latter two task on-the-job learn method perform less well ner we suspect this due presenc domin class ner model quick learn expend almost effort on lens outperform threshold baselin support import bayesian decis theori figur track perform cost lens time on ner task lens abl consist outperform baselin cost system steadili reduc time on ner task we find lens abl trade time produc accur result 1-vote baselin fewer queri wait respons make anoth queri while on-the-job learn allow us deploy quick ensur good result we would like eventu oper without crowd supervis figur we show number queri per exampl on sentiment two differ featur set unigram rnn describ tabl simpler featur unigram the model satur earli we continu need queri the crowd achiev accuraci target specifi the loss function on the hand use richer featur rnn the model abl learn the crowd the amount supervis need reduc time note even when the model capac limit lens abl guarante consist high level perform reproduc all code data experi this paper avail on codalab https //www.codalab.org/worksheets/0x2ae89944846444539c2d08a0b7ff3f6f relat work on-the-job learn draw idea mani area onlin learn activ learn activ classif crowdsourc structur predict onlin learn the fundament premis onlin learn algorithm improv with time there rich bodi work in this area in set algorithm improv time maintain high accuraci the begin wherea regret bound achiev this asymptot activ learn activ learn survey algorithm strateg select inform exampl build classifi onlin activ learn perform activ learn in the onlin set sever author also consid use crowd worker noisi oracl differ setup in assum label observ after classif make near imposs maintain high accuraci in the begin activ classif activ classif ask what the inform featur measur test time exist activ classif algorithm reli on fulli label dataset use learn static polici when certain featur queri chang test time on-the-job learn differ activ classif in two respect true label never observ system improv test time learn stronger model notabl except legion ar like us oper in on-the-job learn set real-tim activ classif howev explor the machin learn foundat associ with oper in this set the aim this paper crowdsourc burgenon subset the crowdsourc communiti overlap with machin learn one exampl flock first crowdsourc the identif featur an imag classif task ask the crowd annot these featur it learn decis tree in anoth line work turkontrol model individu crowd worker reliabl optim the number human vote need achiev confid consensus use pomdp structur predict an import aspect our predict task the output structur lead to much richer set one-the-job learn sinc tag correl the import coher framework optim queri resourc increas make activ partial observ on structur explor in the measur framework in the distant supervis set conclus we introduc new framework learn noisi crowd on-the-job to maintain high accuraci reduc cost signific time the technic core our approach model the on-the-job set as stochast game use idea game play to approxim the optim polici we built system lens obtain signific cost reduct pure crowd approach signific accuraci improv a pure ml approach acknowledg we grate to kelvin guu volodymyr kuleshov for use feedback regard the calibr our model ami bearman for provid the imag embed for the face classif experi we would also like to thank our anonym review for help feedback final our work sponsor a sloan fellowship to the third author
----------------------------------------------------------------

title: 6139-supervised-word-movers-distance.pdf

supervis word mover distanc gao huang chuan guo cornel univers gh349 cg563 cornell.edu yu sun kilian q. weinberg cornel univers ys646 kqw4 cornell.edu matt j. kusner alan ture institut univers warwick mkusner turing.ac.uk fei sha univers california los angel feisha cs.ucla.edu abstract recent new document metric call word mover distanc wmd propos unpreced result knn-base document classif wmd elev high-qual word embed document metric formul distanc two document optim transport problem embed word howev document distanc entir unsupervis lack mechan incorpor supervis avail paper propos effici techniqu learn supervis metric call supervised-wmd s-wmd metric supervis train minim stochast leave-one-out nearest neighbor classif error perdocu level updat affin transform under word embed space word-impor weight vector gradient origin wmd distanc would result ineffici nest optim problem provid arbitrarili close approxim result practic effici updat rule evalu s-wmd eight real-world text classif task consist outperform almost competit baselin introduct document distanc key compon mani text retriev task web-search rank book recommend news categor varieti potenti applic wealth work toward develop accur document distanc larg part prior work focus extract meaning document represent start classic bag word bow term frequency-invers document frequenc tf-idf represent spars high-dimension represent frequent near orthogon pair similar document may therefor near distanc pair differ possibl design meaning represent eigendecompos bow space latent semant index lsi learn probabilist cluster bow vector latent dirichlet alloc lda work general lda use denois autoencod learn suitabl document represent recent kusner propos word mover distanc new distanc text document leverag word embed given high-qual embed wmd defin distanc two document optim transport cost move word one document anoth within word embed space approach shown lead state-of-the-art error rate k-nearest neighbor knn document classif author contribut equal work done author student washington univers st. loui confer neural inform process system nip barcelona spain import prior work entir unsupervis learn explicit particular task exampl text document could classifi topic author would lead differ measur dissimilar late vast amount work metric learn focus learn general linear euclidean metric method often scale quadrat input dimension appli high-dimension text document dimension reduct techniqu pca paper propos algorithm learn metric improv word mover distanc wmd stand prior work comput distanc document without ever learn new document represent instead leverag low-dimension word represent exampl word2vec comput distanc allow us transform word embed instead document remain low-dimension space throughout time propos learn word-specif import weight emphas use certain word distinguish document class first glanc incorpor supervis wmd appear comput prohibit individu wmd comput scale cubic respect spars dimension document howev devis effici techniqu exploit relax version under optim transport problem call sinkhorn distanc combin probabilist filter train set reduc comput time signific metric learn algorithm supervis word mover distanc direct minim stochast version leave-one-out classif error wmd metric differ classic metric learn learn linear transform word represent also learn re-weight word frequenc transform learn make wmd distanc match semant mean similar encod label show across dataset baselin method superior method background here describ word embed techniqu use word2vec recent introduc word mover distanc detail set linear metric learn solut propos neighborhood compon analysi nca inspir method word2vec may popular techniqu learn word embed billion word introduc mikolov word train corpus associ initi word vector optim two word w1 w2 frequent occur togeth high condit probabl probabl hierarch softmax word vector vw1 vw2 easily-comput quantiti allow simplifi neural languag model word2vec model train effici desktop comput train embed billion word allow word2vec captur surpris accur word relationship word embed learn hundr million paramet typic design unsupervis allow train larg unlabel text corpora ahead time throughout paper use word2vec although mani word embed could use word mover distanc leverag compel word vector relationship word embed kusner introduc word mover distanc wmd distanc text document high level wmd minimum distanc requir transport word one document anoth assum given word embed matrix rd n vocabulari word let rd represent ith word defin embed addit let da db n-dimension normal bag-of-word bow vector two document dai number time word occur da normal word da wmd introduc auxiliari transport matrix rn n tij describ much dai transport dbj formal wmd learn minim xi min tij kxi kp2 subject tij dai tij dbj usual set way document share mani word even relat one smaller distanc document dissimilar word note kusner wmd special case earth mover distanc emd also known general wasserstein distanc author also introduc word centroid distanc use fast approxim first describ rubner kxd xd0 shown wcd alway lower bound wmd intuit wcd repres document weight averag word vector weight normal bow count time complex solv wmd optim problem o q log maximum number uniqu word either d0 wcd scale asymptot regular transport problem allevi cubic time complex wasserstein distanc comput cuturi formul smooth version under transport problem ad entropi regular transport object make object function strict convex effici pn algorithm adopt solv particular given transport matrix let tij log tij entropi t. regular primal transport problem defin min tij kxi kp2 subject tij dai tij dbj larger closer relax origin wasserstein distanc cuturi propos effici algorithm solv optim transport use clever matrix-sc algorithm specif may defin matrix kij exp kxi solv scale vector fixed-point comput da db altern fashion yield relax transport diag u k diag v algorithm shown empir time complex o q signific faster solv wmd problem exact linear metric learn assum access train set rd arrang column matrix rd n correspond label yn contain finit number class linear metric learn learn matrix rr defin general euclidean distanc two document da ka xi popular linear metric learn algorithm nca lmnn itml amongst other method learn matrix minim loss function often approxim leave-one-out loo classif error knn classifi neighborhood compon analysi nca introduc goldberg learn general euclidean metric here author approxim non-continu leave-one-out knn error defin stochast neighborhood process input assign input nearest neighbor probabl exp d2a pij exp xk defin pii under stochast neighborhood assign input label classifi correct nearest neighbor isp class yj probabl event state pi learn maxim j yj pij nca expect loo accuraci pi equival minim log pi kl-diverg perfect classif distribut pi learn word embed metric section propos method learn supervis document distanc way learn general euclidean metric within word embed space word import vector refer learn document distanc supervis word mover distanc swmd learn metric assum train dataset consist document dm n -dimension simplex thus document repres normal histogram word vocabulari size document given label possibl class ym c addit given word embed matrix rd n word2vec embed defin d-dimension word vector word vocabulari supervis wmd describ previous section possibl defin distanc two document da db minimum cumul word distanc move da db word embed space done wmd given label train set would like improv distanc document share label close differ label far apart captur notion similar two way first transform word embed captur latent represent word adapt represent linear transform axi repres embed ith word second differ classif task data set may valu word differ also introduc histogram import vector re-weigh word histogram valu reflect import word distinguish class da da denot element-wis hadamard product appli vector linear map wmd distanc document da db becom da w da db min tij ka xi tij ai tij d bj loss function goal learn matrix vector make distanc da w reflect semant definit similar encod label data similar prior work metric learn achiev minim knn-loo error distanc da w document space loo error non-differenti use stochast neighborhood relax propos hinton rowei also use nca similar prior work use squar euclidean word distanc use kl-diverg loss propos nca alongsid definit neighborhood probabl yield exp d w log exp da dc b yb ya gradient comput gradient loss respect follow pab da w da db pa ab ya yb ab otherwis fast comput da w da db notic remain gradient term da w da db contain nest linear program defin fact comput gradient singl pair document requir time complex o q log largest set uniqu word either document this quick becom prohibit slow document size becom larg number document increas gradient alway guarante exist instead must resort subgradi descent motiv recent work fast wasserstein distanc comput propos relax modifi linear program eq use entropi eq describ section this allow us approxim solv eq o q time via diag u k diag v use this approxim solut follow gradient gradient shown da w da db 2a tab ij tab optim long uniqu otherwis subgradi replac tab alway uniqu relax transport strong convex gradient obtain gradient respect need optim solut dual transport problem ka xi da w da db max function given da w da da db b db da w da w da db instead solv dual direct obtain relax optim dual variabl via vector use deriv relax transport specif solv log u log v log v dual variabl log u p-dimension one vector general observ eq approxim process becom accur grow howev set larg make algorithm converg slower experi use lead nice trade-off speed approxim accuraci optim alongsid fast gradient comput process algorithm s-wmd troduc speed train clever initi batch gradient de input word1 embed dataset y1 dm ym scent ca xda initi loss function eq non4 nca c1 y1 cm ym convex thus high depend initi set good initi also dras loop converg tical reduc number gradient step requir random select initi entri word comput gradient use eq assign weight begin ga ning propos learn initi project gw within word centroid distanc defin end d0 da db kxda xdb describ section wcd reason approxim wmd kusner point wcd lower bound wmd hold true transform obtain initi appli nca word embed space use wcd distanc document this say construct wcd dataset cm rd repres text document word centroid appli nca usual way describ section call this learn word distanc supervis word centroid distanc batch gradient descent onc initi matrix obtain minim loss batch gradient descent at iter instead optim full train set random pick batch document train set comput gradient document we speed train observ vast major nca probabl pab near zero this document far away given document thus document da we use wcd get cheap neighbor order comput nca probabl closest set document na base wcd we comput gradient select document we use document nearest neighbor document defin wcd distanc comput nca neighborhood probabl particular gradient comput follow ga w pab pa pa da db b b na na set nearest neighbor document gradient we updat learn rate respect algorithm summar s-wmd pseudo code complex empir time complex solv dual transport problem scale quadrat therefor complex algorithm o t bn d2 denot number batch gradient descent iter batch size na size nearest neighbor set maximum number uniqu word document this comput t ij use altern fix point algorithm section requir time construct gradient eq take time approxim gradient eq requir this comput repeat bn time experi we set comput gradient at iter done second result we evalu s-wmd differ document corpora compar knn error unsupervis wcd wmd document represent addit document represent baselin tabl document dataset descript use visual evalu name bbcsport twitter recip ohsum classic reuter amazon news twitter recip ohsum classic ne reuter bow dim avg word amazon 20new s-wmd wmd bbcsport descript bbc sport articl label sport tweet categor sentiment recip procedur label origin medic abstract class subsampl academ paper label publish news dataset train/test split review label product canon news articl dataset figur t-sne plot wmd s-wmd dataset use without lead supervis metric learn algorithm result overal total competit baselin code implement matlab freeli avail at https //github.com/gaohuang/s-wmd dataset baselin we evalu approach document dataset set news categor sentiment analysi product identif among other tabl describ classif task well size number class dataset we evalu follow document representation/dist method bag-of-word count number word occurr document length vector number uniqu word corpus term frequency-invers document frequenc tf-idf bow vector normal document frequenc word across corpus okapi tf-idf-lik rank function first use search engin latent semant index lsi project bow vector onto an orthogon basi via singular valu decomposit latent dirichlet alloc lda generat probabilist method model document mixtur word topic we train lda transduct combin collect train test word use topic probabl document represent margin stack denois autoencod msda fast method train stack denois autoencod state-of-the-art error rate sentiment analysi task dataset larger recip we use either high-dimension variant msda take featur occur often whichev better perform word centroid distanc describ section word mover distanc describ section complet we also show result supervis word centroid distanc s-wcd initi swmd s-wmd init describ section method propos document represent as oppos distanc we use euclidean distanc these vector represent visual knn classif supervis metric learn result we first reduc dimension represent dimens necessari pca run either nca itml lmnn project data we tune free hyperparamet compar method bayesian optim use implement gardner knn classif we show knn test error document represent distanc method tabl dataset predefin train/test split bbcsport twitter recip classic amazon we averag result five train/test split report standard error dataset we highlight best result bold whose standard error http //tinyurl.com/bayesopt tabl knn test error for dataset distanc dataset bbcsport twitter bow tf-idf kapi lsi lda sda bow tf-idf kapi lsi lda sda bow tf-idf kapi lsi lda sda bow tf-idf kapi lsi lda sda wcd wmd s-wcd s-wmd init s-wmd recip ohsum classic reuter nsupervis itml lmnn nca istanc ord over famili amazon news averag rank overlap mean best result right we also show averag rank across dataset relat unsupervis bow bold indic best method we highlight unsupervis wmd blue wmd new result red despit larg number competit baselin s-wmd achiev lowest knn test error dataset except bbcsport classic amazon these dataset achiev 4th lowest bbcsport classic tie at 2nd news averag across dataset it outperform method anoth observ s-wmd right initi s-wmd init perform quit well howev as train s-wmd effici shown tabl it often well worth train time for unsupervis baselin dataset bbcsport ohsum previous state-of-the-art mazdatiffboon fit motherboardhappen wmd beaten lsi s-wmd reduc eraskedautomotivehomosexu playoff motorcycl ror lsi relat respect gay dolphin comput anim western atheism moon general supervis seem help method keith control tappedmotif graphic clippersecur averag one reason nca tf-idf orbitisrael pro list rutgershel document represent may perform better talknhl driver hockeybibl firedbikergun auto saint s-wmd could long docu virtual gunaltcircuit auto sell cute ment length bbcsport ohsum havlabelrid riderrocket islam offerflight ing denser bow vector may improv invers ride keydod cardriv document frequenc weight in turn may ideship baseballcrypto imag bike good initi for nca further fine-tun monitor stori armenian card polygon isra forsalefirearmsspac dataset smaller document as twitwarn turkishcopyencrypt risc bus mous ter classic reuter s-wmd outperform compatiblemotorcycl summar powerbookelectron diamond nca tf-idf relat scsi govern chip sun doctornasa respect classic wmd outperform dos s-wmd possibl becaus poor initi s-wmd use squar euclidean dis figur word upweight tanc word vector may subop s-wmd news timal for this dataset this howev occur for other dataset appl bike window sale mac visual figur show 2d embed test split dataset wmd s-wmd use t-stochast neighbor embed t-sne qualiti a distanc visual cluster point in class use this metric s-wmd notic improv upon wmd on almost dataset figur visual top word largest weight learn s-wmd on news dataset size each word proport learn weight we observ these upweight word inde repres for true class this dataset more detail result analysi found in supplementari train time tabl show train time for s-wmd note time learn initi metric a includ in time shown in second column relat initi s-wmd surpris fast this due the fast gradient approxim the batch gradient descent introduc in section we note these time compar even faster the time it take train a linear metric on the baselin method after pca tabl distanc comput time ull rain ime dataset bbcsport twitter recip ohsum classic reuter amazon news relat work metric wcd wmd init 1m 1h 2h 7m 2h wmd 4m 7m 1h metric learn a vast field includ supervis unsupervis techniqu yang jin for a larg survey alongsid nca describ in section a number popular method for general euclidean metric learn larg margin nearest neighbor lmnn learn a metric encourag input similar label close in a local region encourag input differ label farther a larg margin information-theoret metric learn itml learn a metric minim a kl-diverg subject general euclidean distanc constraint cuturi avi the first consid learn the ground distanc in the earth mover distanc in a similar work wang guiba learn a ground distanc a metric with good perform in certain vision task most similar our work wang learn a metric within a general euclidean emd ground distanc use the framework itml for imag classif howev consid re-weight the histogram allow our method extra flexibl until recent relat littl work toward learn supervis word embed as state-of-the-art result reli on make use larg unlabel text corpora tang propos a neural languag model use label inform emoticon learn sentiment-specif word embed conclus we propos a power method learn a supervis word mover distanc demonstr it may well the best perform distanc metric for document date similar wmd our s-wmd benefit the larg unsupervis corpus use learn the word2vec embed the word embed give rise to a good document distanc particular forgiv when two document use syntact differ conceptu similar word two word may similar in one sens dissimilar in anoth depend on the articl in they contain it these differ s-wmd manag to captur supervis train learn a linear metric histogram re-weight the optim transport the word mover distanc we abl to produc state-of-the-art classif result effici acknowledg the author support in part by the grant the nation scienc foundat the bill melinda gate foundat we also thank dor kedem for mani insight discuss
----------------------------------------------------------------

title: 5754-coevolve-a-joint-point-process-model-for-information-diffusion-and-network-co-evolution.pdf

coevolv joint point process model inform diffus network co-evolut mehrdad farajtabar yichen wang manuel gomez-rodriguez shuang li hongyuan zha le song georgia institut technolog mpi softwar system mehrdad yichen.wang sli370 gatech.edu manuelgr mpi-sws.org zha lsong cc.gatech.edu abstract inform diffus onlin social network affect under network topolog also power chang onlin user constant creat new link expos new inform sourc turn link altern way inform spread howev two high intertwin stochast process inform diffus network evolut predomin studi separ ignor co-evolutionari dynam propos tempor point process model coevolv joint dynam allow intens one process modul model allow us effici simul interleav diffus network event generat trace obey common diffus network pattern observ real-world network furthermor also develop convex optim framework learn paramet model histor diffus network evolut trace experi synthet data data gather twitter show model provid good fit data well accur predict altern introduct onlin social network twitter weibo becom larg inform network peopl share discuss search inform person interest well break news context user often forward follow inform expos via followe trigger emerg inform cascad travel network constant creat new link inform sourc trigger chang network time import recent empir studi twitter data shown inform diffus network evolut coupl network chang often trigger inform diffus while mani recent work model inform diffus network evolut treat two stochast process independ separ ignor influenc one may time thus better understand inform diffus network evolut urgent need joint probabilist model two process larg inexist date paper propos probabilist generat model coevolv joint dynam inform diffus network evolut model base framework tempor point process explicit character continu time interv event consist two interwoven interdepend compon refer appendix illustr i inform diffus process design ident reveal multivari hawk process captur mutual excit behavior retweet event intens event user boost previous event time-vari set followe al1 though hawk process use inform diffus key innov approach explicit model excit due particular sourc node henc reveal ident sourc design reflect realiti inform sourc explicit acknowledg also allow particular inform sourc acquir new link rate accord inform ii network evolut process model link creation inform driven surviv process coupl intens process retweet event although surviv process use link creation key innov model incorpor retweet event drive forc process sinc model captur sourc ident retweet event new link target toward inform sourc intens proport degre excit sourc influenc model design way allow two process inform diffus network evolut unfold simultan time scale excis bidirect influenc allow sophist coevolutionari dynam generat see figur import flexibl model prevent us effici simul diffus link event model learn paramet real world data effici simul design scalabl sampl procedur exploit sparsiti generat network complex o nd log number sampl number node maximum number followe per user convex paramet learn show model paramet maxim joint likelihood observ diffus link creation event found via convex optim final experiment verifi model produc coevolutionari dynam inform diffus network evolut generat retweet link event obey common inform diffus pattern cascad structur size depth static network pattern node degre tempor network pattern shrink diamet describ relat literatur furthermor show model coevolutionari dynam model provid signific accur link diffus event predict altern larg scale twitter dataset background tempor point process tempor point process random process whose realize consist list discret event local time ti ti mani differ type data produc onlin social network repres tempor point process time retweet link creation tempor point process equival repres count process record number event time let histori list time event t2 tn includ time number observ event small time window dt t+dt dn ti dt henc dn dirac delta function general given function defin convolut respect dn dn dn ti ti point process represent tempor data fundament differ discret time represent typic use social network analysi direct model time interv event random variabl avoid need pick time window aggreg event allow tempor event model fine grain fashion remark rich theoret support import way character tempor point process via condit intens function stochast model time next event given time previous event formal condit intens function intens short condit probabl observ event small window dt given histori dt event e dn one typic assum one event happen small window size dt dn given time also character condit probabl event happen condit densiti event occur time exp respect furthermor express log-likelihood list event t2 tn observ window log ti tn simpl log-likelihood later enabl us learn paramet model observ data final function form intens often design captur phenomena interest some use function form use later poisson process intens assum independ histori time-vari function hawk process intens model mutual excit event dn ti ti exp i exponenti trigger kernel baselin intens independ histori here occurr histor event increas intens certain amount determin kernel weight make intens histori depend stochast process focus exponenti kernel paper howev function form trigger kernel log-logist function possibl model depend particular choic iii surviv process one event instanti process becom event alreadi happen generat model inform diffus network co-evolut section use background tempor point process formul probabilist generat model joint dynam inform diffus network evolut event represent model generat two type event tweet/retweet event er link creation event el instead time record event triplet sourc er el destin time retweet event triplet mean destin node retweet time tweet origin post sourc node record sourc node reflect real world scenario inform sourc explicit acknowledg note occurr event er mean direct retweet connect event happen retweet messag anoth node origin inform sourc acknowledg node pass sourc acknowledg follow i agre b c origin tweet post node allow notat case event simpli er given list retweet event includ time histori hus retweet due sourc hus ei ui si ti si entir histori retweet event denot hr hus link creation event triplet mean destin node creat time link sourc node time node start follow node eas exposit restrict case link delet thus direct link creat howev model easili augment consid multipl link creation delet per node pair discuss section denot link creation histori hl joint model two interwoven compon given user use two set count process record generat event one inform diffus network evolut specif i. retweet event record use matrix size fix time point -th entri matrix nus count number retweet due sourc time count process ident reveal sinc keep track sourc node trigger retweet matrix dens sinc nus nonzero even node direct follow also let dn dnus ii link event record use adjac matrix size fix time point -th entri matrix aus indic whether direct follow aus mean direct link creat simplic exposit allow self-link matrix typic spars number nonzero entri chang time also defin da daus interwoven inform diffus network evolut process character use respect intens e dn hr hl dt e da hr hl dt us sign mean intens matric depend joint histori hr hl henc evolut coupl coupl make count process link creation inform driven evolut link structur chang inform diffus process refer appendix illustr joint model next two section specifi detail two intens matric inform diffus process model intens retweet event use multivari hawk process us i u i u auv dnvs v fu indic function fu auv current set followe term intens origin tweet user initi becom sourc cascad term v fu auv dnvs model propag peer influenc network trigger kernel model decay peer influenc time note retweet intens matrix stochast process depend timevari network topolog non-zero entri whose growth control network evolut process section henc model design captur influenc network topolog sourc influenc inform diffus process specif comput us one first find current set fu followe aggreg retweet followe due sourc note followe may may direct follow sourc frequent node expos retweet tweet origin sourc via followe like also retweet tweet origin sourc node retweet due sourc correspond nus increment turn increas likelihood trigger retweet due sourc among follow thus sourc simpli broadcast messag node direct follow influenc propag network even node direct follow final this inform diffus model allow node repeat generat event cascad differ independ cascad linear threshold model allow one event per node per cascad network evolut process model intens link creation use combin surviv hawk process aus dnus term aus effect ensur link creat onc correspond intens set zero term denot baselin intens model node decid follow sourc spontan initi term dnus correspond retweet node due tweet origin publish sourc trigger kernel model decay interest time here higher correspond retweet intens like find inform sourc use creat direct link link creation intens also stochast process depend retweet event driven retweet count increment dnus captur influenc retweet link creation close loop mutual influenc inform diffus network topolog note creat link ad path allow inform sourc take shortcut diffus network evolut make fundament chang diffus dynam stationari distribut diffus process section shown given fix network structur expect retweet intens time due sourc depend network structur high nonlinear fashion i i rm singl nonzero entri valu i matrix exponenti stationari intens i also nonlinear relat network structur thus given two network structur two point time differ edg effect edg inform diffus simpli addit relat depend newli creat edg modifi eigen-structur spars matrix effect drastic inform diffus remark model user expos inform time-vari set neighbor coupl inform diffus network evolut increas practic applic model real-network dataset particular definit exposur retweet neighbor depend type histor inform avail remark flexibl model allow differ type diffus event broad classifi two categori first categori event correspond time inform cascad hit person exampl retweet one neighbor explicit like forward associ post second categori person decid explicit like forward associ post event correspond time intuit event latter categori prone trigger new connect also less frequent therefor most suitabl larg event dataset exampl one generat synthet contrast event former categori less like inspir new link found abund therefor suitabl real-world spars data consequ synthet experi use latter real one use former noteworthi written base latter categori appendix drawn base former effici simul coevolutionari dynam simul sampl link creation tweet retweet model adapt ogata thin algorithm origin design multidimension hawk process howev naiv implement ogata algorithm would scale poor sampl would need re-evalu thus draw sampl would need perform n2 oper number node design sampl procedur especi well-fit structur model algorithm base follow key idea consid intens function separ hawk process draw sampl easi show minimum among sampl valid sampl model howev draw sampl intens comput complex would improv howev network spars whenev sampl new node link event model small number intens function local neighborhood node link chang consequ reus sampl intens function next new sampl find intens function need chang o log oper use heap final exploit properti exponenti function updat individu intens new sampl let ti two consecut event then comput ti ti without need compar previous event complet simul algorithm summar algorithm appendix c. use algorithm reduc complex m2 o nd log maximum number followe per node mean algorithm scale logarithm number node linear number edg point time simul we also note event link creation tweet retweet generat tempor intertwin inter5 retweet intens event occurr time link cross covari link spike train retweet event occurr time lag figur coevolutionari dynam synthet data spike train link retweet event link retweet intens cross covari link retweet intens data power law fit poisson fit power law fit poisson fit data data poisson fit power law fit poisson fit power law fit data figur degre distribut network sparsiti level reach fix leav fashion algorithm this everi new retweet event modifi intens link creation link creation we also need updat retweet intens effici paramet estim coevolutionari event given collect retweet event eri link creation event eli record within time window we easili estim paramet need model use maximum likelihood estim here we comput joint log-likelihood event use log ui si ti us log ui si ti eri tweet retweet eli link term correspond retweet log term sum actual observ event integr term actual sum possibl combin destin sourc pair even event particular pair destin sourc pair observ event correspond count process essenti surviv observ window term us simpli correspond log surviv probabl term correspond link similar structur retweet sinc us linear paramet respect then log us log us concav function these paramet integr us us still result linear function paramet thus overal object concav global optimum found mani algorithm experi we adapt effici algorithm develop previous work furthermor optim problem decompos independ problem one per node readili parallel properti simul co-evolut network cascad this section we perform empir investig properti network inform cascad generat model particular we show model generat coevolutionari retweet link dynam wide spectrum static tempor network pattern inform cascad appendix contain addit simul result visual appendix contain evalu model estim method synthet data retweet link coevolut figur visual retweet link event aggreg across differ sourc correspond intens one node one realize pick random here it alreadi appar retweet link creation cluster time often follow further figur show cross-covari retweet link creation intens comput across multipl realize node two intens cross-covari function time lag defin dt it seen cross-covari peak around retweet link creation sparsiti diamet diamet sparsiti diamet diamet figur diamet network sparsiti panel show diamet sparsiti time fix fix respect percentag percentag other cascad size other other cascad depth figur distribut cascad structur size depth differ valu fix high correl co-evolv time eas exposit we illustr co-evolut use one node howev we found consist result across node degre distribut empir studi shown degre distribut onlin social network microblog site follow power law argu it consequ rich get richer phenomena degre distribut network power law expect number node md degre given md intuit higher valu paramet closer result degre distribut follow power-law lower valu closer distribut erdos-renyi random graph figur confirm this intuit show degre distribut differ valu small shrink diamet there empir evid diamet onlin social network microblog site exhibit relat small diamet shrink flatten network grow figur show diamet largest connect compon lcc sparsiti network time differ valu although begin there short increas diamet due merg small connect compon diamet decreas network evolv here node arriv network when follow follow node largest connect compon cascad pattern model produc common occur cascad structur well heavy-tail cascad size depth distribut observ in histor twitter data figur summar result higher valu shallow wider cascad experi real dataset in this section we valid model use larg twitter dataset contain near tweet retweet link event more user we show model captur co-evolutionari dynam it predict retweet link creation event more accur sever altern appendix contain detail inform dataset addit experi retweet link coevolut figur visual retweet link event aggreg across differ sourc correspond intens given train model for one node pick random here it alreadi appar retweet link creation cluster in time often follow fit model intens success track behavior further figur compar cross-covari empir retweet link creation intens retweet link creation intens given train model comput across multipl realize for node similar cross-covari strike peak around retweet link creation high correl co-evolv time for eas exposit in section we illustr co-evolut use one node howev we found consist result across node appendix f link predict we use model predict ident sourc for test link event given histor link retweet event time predict compar perform two state art method denot trf weng trf measur implement code avail https //github.com/farajtabar/coevolut intens link event occurr time retweet event occurr time cross covari link spike train retweet estim empir lag figur coevolutionari dynam for real data spike train link retweet event estim link retweet intens empir estim cross covari link retweet intens event coevolv trf weng event coevolv hawk top1 avgrank coevolv trf weng top1 avgrank event coevolv hawk event link ar link top-1 activ ar activ top-1 figur predict perform in twitter dataset mean averag rank success probabl true test event rank among top-1 event probabl creat link sourc given time simpli comput proport new link creat sourc respect total number link creat given time weng consid differ link creation strategi make predict combin we evalu perform comput probabl potenti link use differ method then comput averag rank true test event avgrank success probabl true test event rank among top-1 potenti event test time we summar result in we consid increas number train retweet/tweet event model outperform trf weng consist for exampl for train event our model achiev sp time larger trf weng activ predict we use our model predict ident node that go generat test diffus event given histor event time predict compar it perform baselin consist a hawk process without network evolut for hawk baselin we take a snapshot network right predict time use histor retweet event fit model here we evalu perform the via the two measur in the link predict task summar the result in figur increas number train event the result show that model the co-evolutionari dynam our model perform signific better the baselin discuss we propos a joint continuous-tim model inform diffus network evolut captur the coevolutionari dynam mimic the common static tempor network pattern observ in real-world network inform diffus data predict the network evolut inform diffus more accur previous state-of-the-art use point process model intertwin event in inform network open mani interest futur model work our current model a show-cas a rich set possibl offer by a point process framework rare explor in larg scale social network model for exampl we general our model support link delet by introduc an intens matrix model link delet surviv process gus aus then consid the count process associ the adjac matrix evolv as e da |hr hl dt dt we also consid the number node vari time furthermor a larg divers rang point process also use in the framework without chang the effici the simul the convex the paramet estim condit the intens addit extern featur such as node attribut acknowledg the author would like to thank demetri antoniad constantin dovroli for provid the dataset the research support in part by nsf/nih bigdata onr nsf nsf career
----------------------------------------------------------------

title: 6193-learning-and-forecasting-opinion-dynamics-in-social-networks.pdf

learn forecast opinion dynam social network abir de isabel valera niloy ganguli sourangshu bhattacharya manuel gomez-rodriguez iit kharagpur mpi softwar system abir.d niloy sourangshu cse.iitkgp.ernet.in ivalera manuelgr mpi-sws.org abstract social media social network site becom global pinboard exposit discuss news topic idea social media user often updat opinion particular topic learn opinion share friend context learn data-driven model opinion dynam abl accur forecast user opinion paper introduc slant probabilist model framework opinion dynam repres user opinion time mean mark jump diffus stochast differenti equat allow effici model simul paramet estim histor fine grain event data leverag framework deriv set effici predict formula opinion forecast identifi condit opinion converg steadi state experi data gather twitter show model provid good fit data formula achiev accur forecast altern introduct social media social network site increas use peopl express opinion give hot take latest break news polit issu sport event new product consequ increas interest leverag social media social network site sens forecast opinion well understand opinion dynam exampl polit parti routin use social media sens peopl opinion polit discourse1 quantit invest firm measur investor sentiment trade use social media corpor leverag brand sentiment estim user post like share social media social network site design market campaigns2 context multipl method sens opinion typic base sentiment analysi propos recent year howev method accur forecast opinion still scarc despit extens literatur theoret model opinion dynam paper develop novel model framework opinion dynam social media social network site slant3 allow accur forecast individu user opinion propos framework base two simpl intuit idea user opinion hidden decid share friend neighbor ii user may updat opinion particular topic learn opinion share friend latter one main under premis use mani well-known theoret model opinion dynam former ignor model opinion dynam despit relev close relat process inform diffus http //www.nytimes.com/2012/10/08/technology/campaigns-use-social-media-to-lure-younger-voters.html http //www.nytimes.com/2012/07/31/technology/facebook-twitter-and-foursquare-as-corporate-focus-groups.html slant particular point view someth seen present confer neural inform process system nip barcelona spain detail propos model repres user latent opinion continuous-tim stochast process driven set mark jump stochast differenti equat sdes construct allow user latent opinion modul time opinion asynchron express neighbor sentiment messag everi time user express opinion post sentiment messag reveal noisi estim current latent opinion exploit key properti model markov properti develop i effici estim procedur find paramet maxim likelihood set million sentiment messag via convex program ii scalabl simul procedur sampl million sentiment messag propos model matter minut iii set novel predict formula effici accur opinion forecast also use identifi condit opinion converg steadi state consensus polar final experi synthet real data gather twitter show model provid good fit data predict formula achiev accur opinion forecast sever altern relat work extens line work theoret model opinion dynam opinion format howev previous model typic share follow limit distinguish latent opinion sentiment express opinion noisi observ opinion thumb up/down text sentiment consid user opinion updat synchron discret time howev opinion may updat asynchron follow complex tempor pattern iii model paramet difficult learn real fine-grain data instead set arbitrarili consequ provid inaccur fine-grain predict focus analyz steadi state user opinion neglect transient behavior real opinion dynam allow opinion forecast method recent there effort design model overcom limit provid accur predict howev distinguish opinion sentiment still consid opinion updat synchron discret time model framework address limit achiev accur opinion forecast altern propos model section first formul model opinion dynam start data design introduc effici method model paramet estim model simul opinion data given direct social network record messag triplet mean user post messag sentiment time given collect messag m1 t1 en un mn tn histori hu gather messag post user includ time hu ei ui mi ti ti hu denot entir histori messag includ time generat process repres user latent opinion multidimension stochast process u-th entri x u repres opinion user time sign mean may depend histori everi time user post messag time draw sentiment sentiment distribut p m|x u also think sentiment messag sampl noisi stochast process mu p mu repres messag time set count process particular denot set count process vector u-th entri nu count number sentiment messag user post includ time character messag rate user use correspond condit intens e dn dt dn dnu denot number messag per user window dt denot associ user intens may depend histori denot set user follow next specifi intens function dynam user opinion sentiment distribut p m|x u intens messag there wide varieti messag intens function one choos model user intens work consid two popular function form use grow literatur social activ model use point process i. poisson process intens assum independ histori constant ii multivari hawk process intens captur mutual excit phenomena messag event depend whole histori messag event hv bvu ti bvu dnv v u n ei hv v u n first term model public messag user initi second term bvu model public addit messag user due influenc previous messag post user follow intens here exponenti trigger kernel model decay influenc past event time denot convolut oper case coupl markov process futur state process condit past present state depend upon present state express user intens compact use follow jump stochast differenti equat bdn initi condit markov properti becom import later stochast process opinion opinion x u user time adopt follow form x u avu mi g ti avu mv dnv v n ei hv v n first term model origin opinion user start second term avu model updat user u opinion due influenc previous messag opinion mi post user follow opinion here denot exponenti trigger kernel model decay influenc time greater valu greater user tendenc retain opinion form result opinion dynam markovian compact repres set coupl mark jump stochast differenti equat proven appendix proposit tupl markov process whose dynam defin follow mark jump stochast differenti equat dx dn dn initi condit mark sentiment messag mu mu p m|x u sign denot pointwis product mention markov properti key design effici model paramet estim model simul algorithm sentiment distribut particular choic sentiment distribut p m|x u depend record mark exampl one may consid i. gaussian distribut sentiment assum real random variabl p m|xu xu fit well scenario sentiment extract text use sentiment analysi ii logist sentiment assum binari random variabl p m|xu exp xu fit well scenario sentiment measur mean vote vote like model estim method easili adapt log-concav sentiment distribut howev remaind paper consid gaussian distribut sinc experi sentiment extract text use sentiment analysi model paramet estim given collect messag h mi ti record time period social network find optim paramet solv maximum likelihood estim mle problem4 easi show log-likelihood messag given xz log p mi x ui ti log ti ei messag sentiment ei maxim b u v messag time find optim paramet use mle note long sentiment distribut log-concav mle problem concav thus solv effici moreov problem decompos independ subproblem two per user sinc first term depend wherea last two term depend thus readili parallel find use spectral project gradient descent work well practic achiev accuraci iter find analyt sinc gaussian sentiment distribut problem reduc least-squar problem fortun subproblem use markov properti proposit precomput sum integr linear time o |hu hv appendix summar overal estim algorithm model simul leverag effici sampl algorithm multivari hawk introduc farajtabar design scalabl algorithm sampl opinion model two key idea allow us adapt procedur farajtabar model opinion dynam keep effici follow opinion dynam defin eq markovian thus updat individu intens opinion let ti two consecut event comput ti ti ti ti respect social network typic spars thus also spars whenev node express opinion small number opinion intens function local neighborhood chang consequ reus major sampl intens function sentiment distribut next new sampl appendix i summar overal simul algorithm opinion forecast goal here develop effici method leverag model forecast user u opinion xu time given histori time t0 context probabilist model forecast opinion effici comput condit expect denot averag across histori t0 condit histori aim develop analyt sampl base method comput condit expect moreov use former identifi condit user averag opinion converg steadi state find steadi state opinion section write ht lighten notat denot eigenvalu matrix analyt forecast section deriv set formula comput condit expect poisson hawk messag intens howev sinc deriv such formula general multivari hawk difficult focus here case bvu reli effici sampl base method general case i. poisson intens consid user messag follow poisson process rate condit averag opinion given proven appendix here one decid model messag intens poisson process theorem given collect messag ht0 record time period t0 eht i diag v n auv ti hv ti mv ti remark effici comput term use iter algorithm almohi matrix exponenti well-known gmres method matrix invers given predict formula easili studi stabil condit stabl system find steadi state condit averag opinion proven appendix theorem given condit theorem then lim eht i result indic condit averag opinion nonlinear relat paramet matrix depend network structur messag rate case assum constant independ network structur figur provid empir evid result ii multivari hawk process consid user messag follow multivari hawk process given bvu then condit averag opinion given proven appendix theorem given collect messag ht0 record time period t0 buu ei hu then condit averag satisfi follow differenti equat deht t eht dt diag eht eht i t0 buv ti v n ti hv diag here comput condit averag solv numer differenti equat stochast effici comput vector eht use algorithm al-mohi gmres method case stabil condit steadi state condit averag opinion given proven appendix theorem given condit theorem transit matrix associ timevari linear system describ satisfi e ct then lim eht i diag i result indic condit averag opinion nonlinear relat paramet matric b suggest effect tempor influenc opinion evolut mean paramet matrix multivari hawk process non trivial illustr this result empir figur theoret e xu u v opinion-trajectori opinion-trajectori network g1 theoret experiment e xu u v network g2 hawk hawk u v e xu time tempor evolut time time u v e xu time time tempor evolut time time hawk node-id hawk experiment node-id node-id node-id opinion-trajectori opinion-trajectori tempor evolut time tempor evolut figur opinion dynam two 50-node network g1 top g2 bottom poisson hawk messag intens first column visual two network opinion node positive/neg opinion red/blu second column show tempor evolut theoret empir averag opinion poisson intens third column show tempor evolut empir averag opinion hawk intens comput averag separ posit negat opinion steadi state fourth fifth column show polar averag opinion per user time simul base forecast given effici simul procedur describ section readili deriv general simul base formula opinion forecast 1x eht xl number time simul opinion dynam x l gather user opinion time l-th simul moreov follow theoret guarante proven appendix theorem simul opinion dynam time t0 follow number time 4xmax max maxu g maximum varianc user opinion analyz appendix xmax xu upper bound user absolut opinion then user error true estim averag opinion satisfi x u eht probabl least experi experi synthet data first provid empir evid model abl produc differ type opinion dynam may may converg steadi state consensus polar then show model estim simul algorithm well predict formula scale network million user event appendix contain evalu accuraci model paramet estim method differ type opinion dynam first simul model two differ small network use poisson intens then simul model network use hawk intens bvu node chosen random origin poisson intens remain node figur summar result show model abl produc opinion dynam converg consensus second column polar third column opinion forecast formula describ section close match simul base estim second column iii evolut node poisson hawk node time time time time inform tempor node estim vs node simul vs node forecast vs node poisson hawk forecast-tim t hr forecast vs figur panel show run time estim simul procedur number node averag number event per node panel show run time need comput analyt formula number node time horizon t0 number node panel hour panel averag degre per node experi carri singl machin core gb main memori averag opinion whether opinion converg steadi state consensus polar depend function form messag intensity5 scalabl figur show model estim simul algorithm describ section analyt predict formula describ section scale network million user event exampl algorithm take minut estim model paramet million event generat one million node use singl machin core gb ram experi real data use real data gather twitter show model forecast user opinion accur six state art method appendix l experiment setup experi five twitter dataset current real-world event polit movi fight bollywood record messag comput sentiment valu mi use popular sentiment analysi toolbox special design twitter here sentiment take valu consid sentiment polar simpli sign appendix contain further detail statist dataset opinion forecast first evalu perform model predict sentiment express opinion a messag level dataset first estim paramet model slant use messag a train set contain chronolog first messag here set decay paramet exponenti trigger kernel cross-valid then we evalu predict perform opinion forecast formula use last messages6 more specif we predict sentiment valu messag post user test set given histori hour time messag eht ht t we compar perform model asynchron linear model aslm degroot model voter model bias voter model flock model sentiment predict method base collabor filter kim term mean squar error true estim sentiment valu messag held-out set failur rate defin probabl true estim polar coincid p sign sign baselin algorithm work discret time we simul nt round in nt number post in time figur summar result show opinion forecast formula consist outperform other in term mse often order magnitud failur rate forecast perform degrad grace respect in contrast compet method often fail catastroph iii achiev addit mileag use hawk process instead poisson process extent we believ slant superior perform due abil leverag histor data learn model paramet then simul realist tempor pattern final we look forecast result a network level show forecast formula also predict evolut opinion macroscop term averag opinion across user figur summar result two real world dataset show forecast particular network poisson intens lead consensus while hawk intens lead polar howev we find exampl in poisson intens lead polar hawk intens lead consensus here we distinguish analyt sampl base forecast sinc in practic close match failur rate close zero dataset in user post messag polar flock collab-filt biasedvot degroot linear slant slant voter mse failure-r hour hour hour hour hour hour polit hour movi hour fight hour bollywood hour us 1h 3h 5h april may time may 1h 3h 5h april may time may tw movi hawk tw movi poisson 1h 3h 5h april april time april tw us hawk averag opinion averag opinion averag opinion averag opinion figur sentiment predict perform use a held-out set real-world dataset perform measur in term mean squar error mse sentiment valu failur rate sentiment polar p sign sign for messag in held-out set we predict the sentiment valu given the histori hour the time the messag for differ valu nowcast correspond forecast the sentiment valu the sentiment polar sign 1h 3h 5h april april time april tw us poisson figur macroscop sentiment predict given model for two real-world dataset the panel show the observ sentiment blue run averag infer opinion the train set red forecast opinion eht ht t xu for hour the test set black green gray respect the symbol denot averag across user opinion becom less accur the time becom larger sinc the averag comput longer time period expect model more accur the messag intens model use multivari hawk we found qualit similar result for the remain dataset conclus we propos a model framework opinion dynam whose key innov model user latent opinion as continuous-tim stochast process driven a set mark jump stochast differenti equat sdes such construct allow user latent opinion modul time the opinion asynchron express neighbor as sentiment messag we then exploit a key properti model the markov properti design effici paramet estim simul algorithm scale network million node moreov we deriv a set novel predict formula for effici accur opinion forecast identifi condit opinion converg a steadi state consensus polar final we experi real data gather twitter show framework achiev more accur opinion forecast state-of-the-art our model open mani interest venu for futur work for exampl in our model assum a linear depend user opinion howev in scenario this may a coars approxim a natur follow-up improv the opinion forecast accuraci would consid nonlinear depend opinion would interest augment our model to joint consid correl differ topic one could leverag our model framework to design opinion shape algorithm base stochast optim control final one the key model idea realiz user express opinion in the form thumb up/down text sentiment view as noisi discret sampl the user latent opinion local in time it would interest to general this idea to type event data deriv sampl theorem condit an under general continu signal interest it user opinion expertis recov event data provabl guarante acknowledg abir de partial support googl india under the googl india phd fellowship award isabel valera support a humboldt post-doctor fellowship
----------------------------------------------------------------

title: 5793-the-population-posterior-and-bayesian-modeling-on-streams.pdf

popul posterior bayesian model stream jame mcinerney columbia univers jame cs.columbia.edu rajesh ranganath princeton univers rajeshr cs.princeton.edu david blei columbia univers david.blei columbia.edu abstract mani modern data analysi problem involv infer stream data howev stream data easili amen standard probabilist model approach requir condit finit data develop popul variat bay new approach use bayesian model analyz stream data approxim new type distribut popul posterior combin notion popul distribut data bayesian infer probabilist model develop popul posterior latent dirichlet alloc dirichlet process mixtur studi method sever large-scal data set introduct probabilist model emerg power tool data analysi intuit languag describ assumpt data provid effici algorithm analyz real data assumpt main idea come bayesian statist encod assumpt data structur probabl model hidden observ variabl condit data set reveal posterior distribut hidden variabl use result posterior need exampl form predict posterior predict distribut explor data posterior expect hidden variabl mani modern data analysi problem involv infer stream data exampl includ explor content massiv social media stream twitter facebook analyz live video stream estim prefer user onlin platform recommend new item predict human mobil pattern anticipatori comput problem howev easili take advantag standard approach probabilist model requir condit finit data set might surpris reader one tenet bayesian paradigm updat posterior given new inform yesterday posterior today prior two problem use bayesian updat data stream first problem bayesian infer comput posterior uncertainti assumpt model correct theori sensibl imposs scenario data truli came propos model practic model provid approxim data-gener distribut model incorrect uncertainti maxim predict likelihood may larger smaller bayesian posterior varianc problem exacerb potenti never-end stream see data point uncertainti high eventu model becom overconfid second problem data stream might chang time issu frequent goal appli probabilist model stream character chang rather accommod would like current estim latent variabl accur current state stream adapt stream might slowli chang contrast exampl time seri model tradit bayesian updat handl either explicit model time seri pay heavi inferenti cost tacit assum data exchang under distribut chang paper develop new idea analyz data stream probabilist model approach combin frequentist notion popul distribut probabilist model bayesian infer main idea popul posterior consid latent variabl model data point unconvent notat describ use follow defin model two kind hidden variabl global hidden variabl contain latent structur potenti govern data point local hidden variabl zi contain latent structur govern ith data point model defin joint p xi zi tradit bayesian statist condit fix data set obtain posterior distribut hidden variabl discuss framework accommod data stream need differ way use model defin new distribut popul posterior enabl us consid bayesian model stream suppos observ data point independ under popul distribut induc posterior function random data popul posterior expect valu distribut ef ef notic distribut function observ data function popul distribut data size data size hyperparamet set effect control varianc popul posterior best set depend close model true data distribut defin new problem given endless stream data point come valu goal approxim correspond popul posterior paper approxim algorithm base variat infer stochast optim show algorithm justifi appli variant stochast variat infer data stream use method analyz sever data stream two modern probabilist model latent dirichlet alloc dirichlet process mixtur held-out likelihood measur model fit found method give better model data approach base full bayesian infer bayesian updat relat work research propos sever method infer stream data ref propos extend markov chain mont carlo method stream data howev sampling-bas approach scale massiv dataset variat approxim enabl scalabl infer variat infer ref propos onlin variat infer exponenti forget variat paramet associ old data stochast variat infer svi also decay paramet deriv old data interpret context stochast optim neither method appli stream data implicit reli data known size even subsampl data obtain noisi gradient appli variat approxim stream data ref ref propos bayesian updat approxim famili ref adapt framework nonparametr mixtur model here take differ approach chang variat object incorpor popul distribut follow stochast gradient new object section show general perform better bayesian updat independ ref appli svi stream data accumul new data point grow window uniform sampl window updat variat paramet method justifi approach further propos updat paramet along trust region instead follow natur gradient way mitig local optima innov incorpor method variat infer popul posterior develop popul variat bay method approxim popul posterior method base variat infer stochast optim f-elbo idea behind variat infer approxim difficult-to-comput distribut optim introduc approxim famili distribut latent variabl tri find member minim kullback-leibl diverg target distribut popul variat bay use variat infer approxim popul posterior aim minim kl diverg approxim famili arg min popul posterior object function popul distribut data point notic differ classic vb classic vb optim kl diverg posterior object function fix data set contrast object function popul distribut use mean-field variat famili latent variabl independ govern free paramet q zi free variat paramet global paramet local paramet though focus mean-field famili extens could consid structur famili depend variabl classic vb approxim usual posterior comput kl thus optim proxi object call elbo evid lower bound equal negat kl addit constant maxim elbo equival minim kl diverg posterior popul vb also optim proxi object f-elbo f-elbo expect elbo popul distribut data ef eq log log log p xi zi log q zi f-elbo lower bound popul evid log ef lower bound negat kl popul posterior see appendix inner expect latent variabl function variat distribut outer expect random data point function popul distribut f-elbo thus function variat distribut popul distribut mention classic vb maxim classic elbo equival minim kl f-elbo contrast bound negat kl popul posterior thus maxim f-elbo suggest guarante minim kl said studi show good quantiti optim appendix show f-elbo minim ef popul kl condit conjug model next section develop stochast optim algorithm maxim first describ class model work follow focus condit conjug model condit conjug model one complet condit condit distribut latent variabl given latent variabl observ exponenti famili class includ mani model modern machin learn such mixtur model topic model mani bayesian nonparametr model hierarch regress model use condit conjug model simplifi mani calcul variat infer joint write condit conjug model two exponenti famili p zi h zi exp zi exp overload notat base measur suffici statist log normal note hyperparamet condit conjug model complet condit exponenti famili use famili factor variat distribut thus index famili index famili p zi exampl latent dirichlet alloc complet condit topic dirichlet complet condit per-docu topic mixtur dirichlet complet condit per-word topic assign categor see detail popul variat bay describ ingredi problem given condit conjug model describ eq parameter variat famili stream data unknown popul distribut f. goal optim f-elbo respect variat paramet f-elbo function popul distribut unknown quantiti overcom hurdl use stream data form noisi gradient f-elbo updat variat paramet stochast optim techniqu find local optimum follow noisi unbias gradient describ algorithm howev acknowledg one technic detail mirror optim f-elbo function global variat paramet one-paramet popul vi object lf max lf implicit optim local paramet function global paramet allow us convert potenti infinite-dimension optim problem finit one result object ident replac detail appendix b next step form noisi gradient f-elbo use stochast optim maxim it stochast optim maxim object follow noisi unbias gradient write gradient f-elbo expect respect use mont carlo estim form noisi gradient comput gradient f-elbo bring gradient oper insid expect this result popul expect classic vb gradient data point take natur gradient simpl form complet conjug model specif natur gradient f-elbo ef e xi zi approxim this express use mont carlo comput noisi unbias natur gradient form mont carlo estim collect data point comput optim local paramet function sampl data point variat paramet comput quantiti insid bracket averag result give mont carlo estim natur gradient follow noisi natur gradient repeat algorithm summar algorithm mont carlo estim free draw data point rescal suffici statist this make natur gradient estim noisier faster calcul highlight this strategi comput effici earli iter algorithm inaccur valu it wast pass lot data befor make updat discuss thus far defin popul posterior show approxim it popul variat infer deriv justifi use algorithm like stochast variat infer svi stream data it near ident svi but includ addit paramet number data point popul posterior model interest this justifi domin converg theorem algorithm popul variat bay random initi global variat paramet set iter repeat draw data minibatch optim local variat paramet see calcul natur gradient updat global variat paramet learn rate updat iter count forev note recov origin svi algorithm instanc popul vi thus reinterpret it minim kl diverg popul posterior recov svi set equal number data point data set replac stream data f x empir distribut observ stream this case come sampl replac f x result precis origin svi algorithm.2 focus condit conjug famili conveni simpl gradient emphas howev use recent tool nonconjug infer adapt new idea describ popul posterior f-elbo outsid condit conjug model final we analyz popul posterior distribut under assumpt way stream affect model data formal this mean unobserv variabl model stream independ given data popul posterior without local latent variabl margin ef x expand expect give x p x show popul posterior distribut written as this depict as graphic model this mean first popul posterior well defin even model specifi margin distribut data second rather classic bayesian set posterior condit finit fix dataset popul posterior distribut posterior condit stream empir evalu we studi perform popul variat bay popul vb svi stream variat bay svb larg real-world data we studi two model latent dirichlet alloc bayesian nonparametr mixtur model compar held-out predict perform algorithm three method share local variat updat domin comput cost we studi data come true order stream permut stream better match assumpt svi across data model popul vb usual outperform exist approach model we studi two model first latent dirichlet alloc lda lda mixed-membership model text collect frequent use find latent topic lda assum topic multinomi distribut fix vocabulari document drawn first choos distribut topic this deriv svi applic efron plug-in principl appli infer popul posterior plug-in principl say we replac popul empir distribut data make popul infer empir studi howev we found popul vi often outperform stochast vi treat data true stream set number data point differ true number improv predict accuraci held log likelihood time-ord stream new york time twitter population-vb streaming-vb scienc number document seen held log likelihood random time-permut stream new york time scienc population-vb streaming-vb svi twitter number document seen figur held predict log likelihood lda large-scal stream text corpora populationvb outperform exist method two three set we use best set draw word choos topic assign zdn mult final choos word correspond topic wdn zdn joint distribut p zdi p wdi zdi fix hyperparamet infer problem estim condit distribut topic given larg collect document second model dirichlet process mixtur loos dp mixtur mixtur model potenti infinit number compon thus choos number compon part posterior infer problem use variat infer dp mixtur we take advantag stick break represent construct truncat variat approxim variabl mixtur proport stick mixtur compon infinit mixtur assign zi observ g zi joint p zi likelihood prior compon general observ hand studi real-valu data we use normal prior normal likelihood studi text data we use dirichlet prior multinomi likelihood model we vari usual fix number data point tradit analysi dataset lda we analyz three large-scal stream corpora articl new york time span year scienc articl written year tweet collect twitter feb we process similar way choos vocabulari base frequent word corpus stop word remov new york time scienc twitter twitter tweet document we remov duplic tweet tweet contain least word vocabulari data stream algorithm took hour process exampl we collect dp mixtur we analyz human locat behavior data data allow us build period model human popul mobil applic disast respons urban plan such model account period includ hour week as one dimens time-ord stream held log likelihood ivori coast locat geolif locat new york time population-vb best streaming-vb number data point seen held log likelihood random time-permut stream ivori coast locat geolif locat population-vb best streaming-vb svi new york time number data point seen figur held predict log likelihood dirichlet process mixtur model large-scal stream locat text data set note we appli gaussian likelihood in geolif dataset report predict perform measur probabl densiti we chose best population-vb curv held log likelihood population-vb sensit lda new york time scienc twitter population-vb true logarithm base held log likelihood population-vb sensit dp-mixtur ivori coast locat geolif locat new york time population-vb true logarithm base figur we show sensit population-vb hyperparamet base final log likelihood in time-ord stream find best set often differ true number data point may known in case in practic data model ivori coast locat data contain discret cell tower locat user record month microsoft geolif dataset contain latitude-longitud gps locat user year data set our observ reflect down-sampl data ensur individu seen everi minut result we compar popul vb svi svb lda dp mixtur svb updat variat approxim global paramet use densiti filter with exponenti famili complex approxim remain fix as expect suffici statist minibatch observ in stream combin with current approxim here we give final result we includ detail how we set fit hyperparamet we measur model fit evalu averag predict log likelihood held-out data this involv split held-out observ involv in posterior approxim two equal halv infer local compon distribut base first half test with second half dp-mixtur we condit observ hour week predict geograph locat held-out data point in standard offlin studi held-out set random select data with stream howev we test next document new york time scienc tweet twitter locat geo data this valid held-out set data ahead current posit in the stream yet seen the infer algorithm figur show the perform lda we look two type stream one in the data appear in order the in permut exchang stream the time permut stream reveal perform when data minibatch safe assum sampl this result in smoother improv predict likelihood our data we found popul vb outperform svi svb two the data set outperform svi the data svb perform better popul vb twitter figur show similar studi for dp mixtur we analyz the human mobil data the new york time ref also analyz the new york time on these data popul vb outperform svb svi in settings.3 hyperparamet unlik tradit bayesian method the data set size hyperparamet popul vb it help control the posterior varianc the popul posterior figur report sensit for all studi for the time-ord stream these plot indic the optim set often differ the true number data point the best perform popul posterior varianc necessarili the one impli the data the hyperparamet our experi report in appendix c. conclus futur work we introduc the popul posterior distribut latent variabl combin tradit bayesian infer with the frequentist idea the popul distribut with this idea we deriv popul variat bay effici algorithm for probabilist infer on stream on two complex bayesian model sever larg data set we found popul variat bay usual perform better exist approach stream infer in this paper we made assumpt the structur the popul distribut make assumpt such as the abil obtain stream condit on queri lead variant our algorithm that learn data point to see next infer final understand the theoret properti the popul posterior also avenu interest acknowledg we thank allison chaney john cunningham alp kucukelbir stephan mandt peter orbanz theo weber frank wood the anonym review for comment this work support nsf onr darpa ndseg facebook adob amazon the siebel scholar john templeton foundat though our purpos to compar algorithm we make one note specif data set the predict accuraci for the ivori coast data set plummet data point this becaus the data collect polici for privaci reason the data set provid the cell tower locat a random select cohort user everi week the new cohort data point behav differ to previous cohort in a way that affect predict perform howev algorithm steadili improv this shock
----------------------------------------------------------------

title: 5237-learning-with-fredholm-kernels.pdf

learn fredholm kernel qichao que mikhail belkin yusu wang depart comput scienc engin ohio state univers columbus oh que mbelkin yusu cse.ohio-state.edu abstract paper propos framework supervis semi-supervis learn base reformul learn problem regular fredholm integr equat approach fit natur kernel framework interpret construct new data-depend kernel call fredholm kernel proceed discuss nois assumpt semi-supervis learn provid theoret experiment evid fredholm kernel effect util unlabel data nois assumpt demonstr method base fredholm learn show competit perform standard semi-supervis learn set introduct kernel method method base integr oper becom one central area machin learn learn theori method combin rich mathemat foundat strong empir perform paper propos framework supervis unsupervis learn invers problem base solv integr equat known fredholm problem first kind develop regular base algorithm solv system lead call fredholm kernel basic set supervis learn given data set r. would like construct function nice enough general new data point typic done choos class function reproduc kernel hilbert space rkhs correspond posit definit kernel kernel method optim certain loss function squar loss hing loss paper formul new framework learn base interpret learn problem fredholm integr equat formul share similar usual kernel learn framework unlik standard method also allow easi incorpor unlabel data also show interpret result algorithm standard kernel method non-standard data-depend kernel somewhat resembl approach taken discuss reason incorpor unlabel data may desir concentr particular may term nois assumpt semi-supervis learn relat distint manifold cluster assumpt popular semi-supervis learn literatur provid theoret empir result show fredholm formul allow effici denois classifi summar main contribut paper follow formul new framework base solv regular fredholm equat framework natur combin label unlabel data show framework express kernel method non-standard data-depend kernel discuss nois assumpt semi-supervis learn provid theoret evid fredholm kernel abl improv perform classifi assumpt specif analyz behavior sever version fredholm kernel base combin linear gaussian kernel demonstr model nois assumpt fredholm kernel provid better estim tradit data-independ kernel thus unlabel data provabl improv infer show fredholm kernel perform well synthet exampl design illustr nois assumpt well number real-world dataset relat work kernel integr method machin learn larg divers literatur work direct relat approach fredholm integr equat introduc address problem densiti ratio estim covari shift work problem densiti ratio estim express fredholm integr equat solv use regular rkhs set also relat line work kernel mean embed data point embed reproduc kernel hilbert space use integr oper applic densiti ratio estim task interest recent work explor shrinkag estim estim mean rkhs follow steinjam estim origin use estim mean euclidean space result obtain show estim reduc varianc similar work theoret result present section also show varianc reduct certain estim kernel although differ set anoth line relat work class semi-supervis learn techniqu comprehens overview relat manifold regular addit graph laplacian regular ad take advantag geometric/manifold structur data reformul fredholm learn kernel address call nois assumpt parallel data-depend kernel manifold regular propos fredholm kernel start formul learn framework propos paper suppos given label pair y1 xl yl data distribut defin unlabel point xl+u margin distribut px simplic assum featur space euclidean space rd label set either binari classif real line regress semi-supervis learn algorithm aim construct predictor function incorpor inform unlabel data distribut end introduc integr oper kpx associ kernel function set posit semi-definit even symmetr kernel kpx kpx z f z px space square-integr function law larg number oper approxim use unlabel data px l+u kp x approxim provid natur way incorpor unlabel data algorithm fredholm learn framework use function kpx kpx appropri reproduc kernel hilbert space rkhs classif regress function note unlik rkhs space function kpx densiti depend particular allow us formul follow optim problem semi-supervis classification/regress way similar mani supervis learn algorithm fredholm learn framework solv follow optim problem1 1x kf k2h arg min use squar loss simplifi exposit loss function also use eqn final classifi kp x kp x oper defin eqn discret regular version fredholm integr equat kpx thus give name fredholm learn framework even though first glanc set look similar convent kernel method extra layer introduc kp x make signific differ particular allow integr inform unlabel data distribut contrast solut standard kernel method kernel linear polynomi gaussian kernel complet independ unlabel data note approach close relat fredholm equat use estim densiti ratio two probabl distribut fredholm learn framework general standard kernel framework fact kernel function formul equival regular kernel pl least squar equat arg minf 1l kf k2h could also replac loss eqn loss function hing loss result svm-like classifi final even though eqn optim problem potenti infinit dimension function space standard deriv use represent theorem see full version detail yield comput access solut follow l+u kh vj kl+u kl+u kh i kl+u kl+u ij k xi kh ij kh note kl+u matrix fredholm kernel conveni reformul fact see fredholm learn problem induc new data-depend kernel refer fredholm kernel2 show connect use follow ident easili verifi kl+u kl+u kh i kl+u kl+u kl+u kh kl+u i defin kf kl+u kh kl+u kernel matrix associ new kernel defin k f l+u kh consid unlabel data fix comput new kernel use new kernel k f final classifi function eqn rewritten l+u k f xs kf becaus eqn sometim refer kernel kh inner outer kernel respect observ solut equival standard kernel method use new data depend kernel k f call fredholm kernel sinc induc fredholm problem formul eqn proposit fredholm kernel defin eqn posit semi-definit long kh posit semi-definit set data xl+u proof given full version outer kernel either posit definit even symmetr use gaussian kernel discret approxim eqn might unstabl kernel width small also introduc normal fredholm kernel l+u kh k fn easi check result fredholm kernel k fn still symmetr posit semi-definit even though fredholm kernel deriv use loss could also deriv hing loss use explain full version note term fredholm kernel use mathemat page also differ learn context usag repres differ object nois assumpt semi-supervis learn order unlabel data use classif task necessari margin distribut unlabel data contain inform condit distribut label sever way inform encod propos includ cluster assumpt manifold assumpt cluster assumpt state cluster high densiti area contain most point belong class belong cluster correspond label y1 y2 manifold assumpt assum regress function smooth respect under manifold structur data interpret say geodes distanc use instead ambient distanc optim classif success algorithm base idea indic these assumpt captur certain characterist real data still better understand unlabel data may still lead progress data analysi nois assumpt propos formul new assumpt nois assumpt neighborhood everi point direct low varianc unlabel data uninform respect class label regard nois intuit far know explicit formul context semi-supervis learn algorithm appli theoret analysi figur left label point right unlabel point note even nois varianc small along singl direct could still signific decreas perform supervis learn algorithm nois high-dimension these accumul non-inform variat particular increas difficulti learn good classifi amount label data small first figur right illustr issu nois two label point seem optim classif boundari red line differ correct one black due noisi variat along axi two label point intuit unlabel data shown right panel figur help set low varianc direct estim local algorithm could suppress influenc noisi variat learn classifi connect cluster manifold assumpt nois assumpt compat manifold assumpt within manifold+nois model specif assum function interest vari along manifold constant orthogon direct altern think direct high varianc signal/manifold direct low varianc nois note nois assumpt requir data conform low-dimension manifold strict mathemat sens word nois assumpt orthogon cluster assumpt exampl figur illustr situat data cluster nois assumpt appli theoret result fredholm kernel non-inform variat data could degrad tradit supervis learn algorithm show fredholm kernel use replac tradit kernel inject noise-suppress power help unlabel data section present two view illustr nois suppress achiev specif section show certain setup linear fredholm kernel suppress princip compon small varianc section prove certain condit abl provid good approxim true kernel hidden under space make argument clear assum there infinit amount unlabel data know margin distribut data exact consid follow continu version un-norm andznorm fredholm kernel eqn kfu u kh v p u p v dudv kfn kh p u p v dudv w p w dw w p w dw note equat follow sometim write instead px margin distribut choic clear context typic use kf denot appropri normal unnorm kernel depend context linear fredholm kernel inner product section consid unorm fredholm kernel kf kfu if outer kernel linear hu vi result fredholm kernel view inner product specif un-norm fredholm kernel eqn rewritten kf ukh v v p u p v dudv thus kf simpli inner product depend unlabel data distribut inner kernel kh inner product re-weight standard norm featur space base varianc along princip direct matrix show model unlabel data sampl normal distribut kernel view soft threshold pca suppress direct low varianc specif following3 theorem let kh exp kx zk assum distribut px unlabel data 2t singl multi-vari normal distribut diag assum data mean-subtract see xt re-scal project along princip compon comput inner product rescal factor i-th princip direct note rescal factor hand 2i henc consid soft threshold elimin effect princip compon small varianc small rescal factor approxim case proport covari matrix proport data xx kernel approxim nois seen one special case fredholm kernel could achiev effect princip compon re-scal use linear kernel outer kernel section give general interpret nois suppress fredholm kernel first give simpl senario provid intuit behind definit fredholm kernl consid standard supervis learn set use solut pl arg minf 1l k2h classifi let target kh denot ideal kernel intend use clean data call target kernel suppos two noisi label point xe ze true data xe ze target evalu kh xe ze quit differ true target signal kh lead suboptim final classifi red line figur hand consid rr fredholm kernel eqn similar eqn kf xe ze k xe kh k ze v p v dudv set outer kernel gaussian kernel inner kernel kh target target kernel kh think kf xe ze averag kh possibl pair data weight k xe k ze respect specif point proof result found full version close xe resp ze high densiti receiv larger weight henc weight averag bias toward respect presum lie high densiti region around xe ze valu kf xe ze tend provid accur estim kh see right figur illustr arrow indic point stronger influenc comput kf xe ze kh xe ze result classifi obtain use fredholm kernel also resili nois closer optimum fredholm learn framework rather flexibl term choic kernel kh remaind section we consid specif scenario provid quantit analysi show nois robust fredholm kernel problem setup assum we ground-truth distribut subspac span first dimens euclidean space rd we assum distribut singl gaussian id suppos distribut corrupt gaussian nois along orthogon subspac dimens true point drawn id observ xe drawn id sinc nois lie space orthogon data distribut mean observ point label unlabel sampl px diag id id we show fredholm kernel provid better approxim origin kernel given unlabel data simpli comput kernel noisi point we choos basic set abl state theoret result clean manner even though this gaussian distribut linear subspac nois this framework general implic sinc local neighborhood manifold almost linear space note this section we use normal fredholm kernel given eqn kf kfn un-norm fredholm kernel display similar behavior bound trickier target linear kernel first we consid case target kernel kh linear kernel target kh we set kh in fredholm kernel also linear gaussian ku vk2 kernel 2t we compar kf xe ze target kernel two observ target target point kh xe ze goal estim kh we see target kf xe ze appropri scale kh xe ze unbias estim kh howev target varianc kf xe ze smaller kh xe ze make more precis estim theorem suppos probabl distribut unlabel data px diag id id fredholm kernel defin in eqn we target exe ze kh xe ze exe ze kf xe ze target kf xe ze varx ze kh xe ze moreov varx ze remark note we normal constant fredholm kernel make unbias estim in practic choos normal subsum in select regular paramet kernel method thus we see fredholm kernel provid approxim true linear kernel smaller varianc compar actual linear kernel noisi data gaussian kernel we now consid case target kernel gaussian kernel target kh exp ku vk approxim this kernel we set kh gaus2r sian kernel simplifi present result we assum kh kernel width result fredholm kernel turn also gaussian kernel whose kernel width depend choic our main result follow again similar case linear kernel fredholm estim target target kf xe ze kh xe ze unbias estim target kh constant kf xe ze smaller varianc theorem suppos probabl distribut unlabel data px target diag id id given target kernel kh exp ku vk ker2r nel width we choos given equat two scale constant c1 c2 target target exe ze kh xe ze exe ze kf xe ze kh target when we varx ze kh xe ze varx ze kf xe ze remark in practic when appli kernel method real world applic optim kernel width usual unknown chosen cross-valid method similar our fredholm kernel one also use cross-valid choos optim kf experi use linear gaussian kernel kh respect we defin three instanc fredholm kernel follow fredlin1 xt kh exp kx zk 2r kx zk2 fredlin2 exp 2r kh fredgauss kh exp kx zk 2r kernel in use gaussian kernel outsid kernel we also defin normal version we denot fredlin2 n fredgauss n respect synthet exampl nois cluster assumpt isol abil fredholm kernel deal nois cluster assumpt we construct two synthet exampl violat cluster assumpt shown in figur figur show first two dimens multi-vari gaussian nois varianc in ad classif boundari indic color class we provid sever label point larg amount unlabel data note that classif boundari in circl exampl non-linear we compar fredholm kernel base classifi rlsc regular least squar classifi two wide use semisupervis method transduct support vector machin nois laprlsc sinc exampl violat cluster assumpt the figur cluster assumpt gaussian two exist semi-supervis learn algorithm transduct nois in ad linear svm laprlsc gain much the unlabel data tsvm we use the primal tsvm propos in we non-linear beus the implement laprlsc given in differ num low class boundari ber label point given class togeth anoth unlabel point choos the optim paramet method we pick the paramet base perform the valid set while the final classif error comput the held-out test data set result report in tabl in fredholm kernel show clear improv other method synthet exampl in term classif error real-world data set unlik artifici exampl usual difficult to verifi whether certain assumpt satisfi in real-world problem in this section we examin the perform fredholm kernel sever real-world data set compar the baselin algorithm mention linear kernel here we consid text categor sentiment analysi linear method known to perform well we use the follow data repres tf-idf featur news group document class we select the first categori our experi webkb the origin data set contain document unbalanc class we pick the two largest class instanc respect imdb movi review it posit review negat review movi imdb.com twitter sentiment data sem-ev it contain tweet posit neural negat sentiment we combin neutral negat class to set a binari classif problem result report in tabl in table4 we use webkb exampl to illustr the chang the perform number label point increas number label rlsc tsvm method linear laprlsc fredlin1 fredlin2 n tabl predict error differ classifi the two line exampl number label k-rlsc method gaussian tsvm laprlsc fredgauss n tabl predict error differ classifi for the circl exampl gaussian kernel we test our method hand-written digit recognit the experi use subset two handwrit digit data set mnist usp the one mnist contain digit in total balanc exampl for class the one for usp the origin test set contain 2k imag the pixel valu normal to featur result report in tabl in tabl we show that we add addit gaussian nois to mnist data fredholm kernel start to show signific improv data set webkb 20new imdb twitter rlsc tsvm method linear fredlin1 fredlin2 fredlin2 n tabl the error various method the text data set label data per class given rest the data set unlabel point optim paramet for method use number label rlsc tsvm method linear fredlin1 fredlin2 fredlin2 n tabl predict error webkb differ number label point data set uspst mnist k-rlsc method gaussian laprlsc fredgauss fredgauss n tabl predict error nonlinear classifi on the mnist usp label data per class given rest the data set as unlabel point optim paramet for method use number label k-rlsc method gaussian laprlsc fredgauss fredgauss n tabl the predict error nonlinear classifi on mnist corrupt gaussian nois standard deviat with differ number label point to optim paramet for method use acknowledg the work partial support by nsf grant ri we thank the anonym nip review for insight comment
----------------------------------------------------------------

title: 5365-shaping-social-activity-by-incentivizing-users.pdf

shape social activ incentiv user mehrdad farajtabar nan du manuel gomez-rodriguez isabel valera hongyuan zha le song georgia institut technolog mpi softwar system univ carlo iii madrid mehrdad dunan gatech.edu manuelgr mpi-sws.org zha lsong cc.gatech.edu ivalera tsc.uc3m. abstract event onlin social network categor rough endogen event user respond action neighbor within network exogen event user take action due drive extern network much extern drive provid user network activ steer toward target state paper model social event use multivari hawk process captur endogen exogen event intens deriv time depend linear relat intens exogen event overal network activ exploit connect develop convex optim framework determin requir level extern drive order network reach desir activ level experi event data gather twitter show method steer activ network accur altern introduct onlin social platform routin track record larg volum event data may correspond usag servic url shorten servic bit.li event categor rough endogen event user respond action neighbor within network exogen event user take action due drive extern network instanc user tweet may contain link provid bit.li either due forward link friend due initi use servic creat new link model exploit data steer onlin communiti desir activ level specif drive overal usag servic certain level least twice per day per user incentiv small number user take initi goal make usag level servic homogen across user maxim overal servic usag target group user furthermor activ shape problem need address take account budget constraint sinc incent usual provid form monetari credit reward activ shape problem signific challeng tradit influenc maxim problem aim identifi set user convinc adopt product shall influenc other network trigger larg cascad adopt first influenc maxim state user often assum binari either adopt product howev assumpt captur recurr natur product usag frequenc usag matter second influenc maxim method identifi set user provid incent typic provid quantit prescript much incent provid user third activ shape concern larger varieti target state minimum activ homogen activ activ maxim paper address activ shape problem use multivari hawk process model endogen exogen recurr social event shown good fit data number recent work import go beyond model fit deriv novel predict formula overal network activ given intens exogen event individu user use connect process branch process base relat propos convex optim framework address divers rang activ shape problem given budget constraint compar previous method influenc maxim framework provid fine-grain control network activ steer network desir steady-st activ level also time-sensit fashion exampl framework allow us answer complex time-sensit queri user incentiv much steer set user use product twice per week one month addit novel framework also develop effici gradient base optim algorithm matrix exponenti need gradient comput approxim use truncat taylor seri expans algorithm allow us valid framework varieti activ shape task scale network ten thousand node also conduct experi network twitter user use popular url shorten servic use held-out data show algorithm shape network behavior much accur altern model endogenous-exogen recurr social event model event generat user social network m-dimension count process n2 nm ni record total number event generat user time furthermor repres event tupl ui ti ui user ident ti event time let histori process time ht ti ti ht histori time increment process dn infinitesim window dt parametr intens e dn dt intuit larger intens greater likelihood observ event time window instanc poisson process view special count process constant intens function independ time histori model presenc endogen exogen event decompos intens two term overal event intens exogen event intens endogen event intens exogen event intens model drive outsid network endogen event intens model interact within network assum host social platform potenti drive exogen event intens provid incent user endogen event generat due user interest influenc network peer host interfer direct key question activ shape context model endogen event intens realist recurr social interact link exogen event intens endogen event intens assum exogen event intens independ histori time multivari hawk process recurr endogen event often exhibit characterist self-excit user tend repeat what recent mutual-excit user simpli follow what neighbor due peer pressur social phenomena made analog occurr earthquak spread epidem well-captur multivari hawk process shown number recent work specif multivari hawk process count process particular form intens assum strength influenc user parameter spars nonneg influenc matrix auu auu mean user direct excit user also allow nonneg diagon model self-excit user intens u-th dimens auui g ti auu g dnu ti nonneg kernel function ds second equal obtain group event accord user use fact t1 t2 t3 exampl social network branch structur event figur panel direct edg indic target node follow influenc sourc node activ network model use hawk process result branch structur event shown panel exogen event root node branch top left red circl t1 occur due user initi event trigger one endogen event blue squar t2 new endogen event creat next generat endogen event green triangl t3 forth social network constrain branch structur event sinc event produc user user trigger endogen event user one follow user g dnu ui ti g ti intuit model propag peer influenc network event ui ti occur neighbor user boost intens certain amount decay time thus frequent event occur user neighbor like persuad generat new event simplic focus exponenti kernel g ti ti remind paper howev multivari hawk process branch process explain next section independ kernel choic extend kernel powerlaw rayleigh long tail distribut nonneg real domain furthermor rewrit equat vectori format g dn defin time-vari matrix auu note multivari hawk process intens random quantiti depend histori ht denot expect intens respect histori eht connect branch process branch process markov process model popul individu generat produc random number individu generat accord distribut section conceptu assign exogen event endogen event multivari hawk process level generat associ event branch structur record inform event trigger event figur exampl note genealog event interpret probabilist term may observ actual data connect discuss hawk origin paper one dimension hawk process recent revisit context multivari hawk process branch structur play crucial role deriv novel link intens exogen event overal network activ specif assign exogen event zero-th generat record number event exogen event trigger first generat endogen event whose number record next these first generat endogen event trigger second generat endogen event total number event network sum number event generat ht furthermor denot event generat independ event ui ti ht generat trigger poisson process neighbor independ intens auui g ti due superposit theorem independ poisson process intens event node generat simpli sum condit intens poisson process trigger neighbor ui ti auui g ti concaten intens use g dnu time-vari matrix g dn intens count process k-th generat again due superposit independ poisson process decompos intens sum condit intens differ generat next base decomposit develop close form relat expect intens eht intens exogen event relat form basi activ shape framework link exogen event intens overal network activ strategi first link expect intens eht event k-th generat deriv close form infinit seri sum defin seri auto-convolut matric one generat i g ds expect intens event k-th generat relat exogen intens lemma next sum togeth auto-convolut matric i obtain linear relat expect intens network intens exogen event entri matrix rough encod influenc pair user precis entri uv expect intens event node due unit level exogen intens node also deriv sever use quantiti exampl uv thought overal influenc user user surpris exponenti kernel infinit sum matric result close form use matrix exponenti first let denot laplac transform function follow intermedi result laplac transform lemma dt ak lemma posit prove main theorem theorem i theorem provid us linear relat exogen event intens expect overal intens point time stationari intens signific result allow us later design divers rang convex program determin intens exogen event order achiev target intens fact recov previous result stationari case special case general result specif multivari hawk process stationari spectral radius dt dt auu u u strict smaller case expect intens i independ time obtain relat theorem let corollari i limt refer appendix proof convex activ shape framework given linear relat exogen event intens expect overal event intens propos convex optim framework varieti activ shape task task discuss optim exogen event intens expect overal event intens maxim respect concav util maxim subject cm cost per unit event user total budget addit regular also ad either restrict number incentiv user norm promot spars solut norm obtain smooth solut regular next discuss sever instanc general framework achiev differ goal constraint remain henc omit cap activ maxim real network upper bound cap activ user generat due limit attent user exampl twitter user typic post limit number shorten url retweet limit number tweet suppos know upper bound user activ how much activ user will generat then perform follow cap activ maxim task maxim min minimax activ shape suppos goal instead maintain activ user network certain minimum level altern make user minimum activ activ possibl then perform follow minimax activ shape task maxim minu least-squar activ shape sometim want achiev pre-specifi target activ level user exampl may like divid user group desir differ level activ group inspir these exampl perform follow least-squar activ shape task maxim encod potenti addit constraint group partit besid euclidean distanc famili bregman diverg use measur differ given function rm convex argument use object function activ homogen mani concav util function use exampl may want steer user activ homogen profil measur homogen activ shannon entropi then perform follow activ homogen task maxim scalabl algorithm activ shape problem defin requir effici evalu instantan averag intens time entail comput matrix exponenti obtain small medium network reli well-known numer method comput matrix exponenti howev larg network explicit comput becom intract fortun exploit follow key properti convex activ shape framework instantan averag intens depend matrix-vector product oper particular start use theorem rewrit multipl vector then get tractabl solut first comput effici subtract solv spars linear system equat effici step illustr algorithm next elabor two effici algorithm comput product matrix exponenti vector solv spars linear system equat comput product matrix exponenti vector reli iter algorithm al-mohi combin scale squar method truncat taylor seri approxim matrix exponenti solv spars linear system equa5 algorithm averag instantan intens algorithm pgd activ shape input output v1 v2 v2 v3 v2 return v1 initi repeat project evalu gradient updat use gradient converg tion use well-known gmres method arnoldi process construct l2 orthogon basi krylov subspac method solv linear system iter minim norm residu vector krylov subspac perhap surpris show possibl comput gradient object function activ shape problem use algorithm develop comput averag instantan intens need defin vector appropri problem follow activ maxim defin vj vj otherwis minimax activ shape defin ej if min ej otherwis iii least-squar activ shape activ homogen vector element-wis natur logarithm sinc activ maxim minimax activ shape task requir one evalu time vector algorithm use direct howev comput gradient least-squar activ shape activ homogen slight involv requir care order perform oper refer appendix detail equip effici way comput gradient solv correspond convex optim problem activ shape problem appli project gradient descent pgd appropri gradient1 algorithm summar key step experiment evalu evalu framework use simul real world held-out data show approach signific outperform sever baselin appendix contain addit experi dataset descript network infer use data gather twitter report compris public tweet post user 8-month period januari septemb everi user record time use six popular url shorten servic refer appendix detail evalu perform framework subset activ user link edg call 2k dataset we evalu scalabl overal user link edg we call dataset 2k dataset account url shorten servic use dataset account million use final we treat servic independ cascad event experi we estim nonneg influenc matrix exogen intens use maximum log-likelihood previous work we use tempor resolut one minut select bandwidth cross valid loos speak correspond loos initi influenc minut may explain rapid rate user news feed get updat evalu scheme we focus three task cap activ maxim minimax activ shape least squar activ shape we set total budget correspond support total extra activ equal action per unit time assum user entail cost cap activ maxim we set upper limit user intens ad nonneg random vector infer initi intens least-squar activ shape we set i aim creat three user group less-act moder super-act we use three differ evalu scheme increas resembl real world scenario theoret object we comput expect overal theoret intens appli theorem optim exogen event intens three activ shape task well learn we then comput report valu object function nondifferenti object subgradi algorithm use instead logarithm time logarithm time gr ls lsgrd op logarithm time prop pr lsash lsgrd ls prop rank correl lsash euclidean distanc gr grd lp lp i minmu mu uni mi mmash un grd lp mm minmu rank correl uni minimum activ minimum activ logarithm time logarithm time euclidean distanc pr prk mmash deg logarithm time wei de xmu cam we i prk xm deg ca wei rank correl xmu sum user activ sum user activ cam theoret object simul object held-out data figur row cap activ maxim row minimax activ shape row leastsquar activ shape mean statist signific level pair t-test method second best simul object we simul cascad ogata thin algorithm use optim exogen event intens three activ shape task learn we then estim empir overal event intens base simul cascad comput run averag non-overlap time window report valu object function base estim overal intens appendix provid comparison simul theoret object held-out data interest evalu scheme would entail carri real intervent in social platform howev sinc challeng instead in evalu scheme we use held-out data simul process proceed follow we first partit 8-month data five-day long contigu interv then we use one interv train remain interv test suppos interv use train procedur follow we estim a1 use event interv then we fix a1 estim all interv given a1 we find optim exogen event intens opt three activ shape task solv associ convex program we then sort estim accord similar opt use euclidean distanc opt we estim overal event intens interv as in simul object evalu scheme sort these interv accord valu correspond object function last we comput report rank correl score two order obtain in step larger rank correl better method we repeat procedur time choos each differ interv train comput report averag rank correl detail found in appendix rank correl number pair consist order total number pair cap activ maxim we compar number altern xmu heurist base without optim deg wei heurist base degre user prank heurist base page rank refer appendix for detail first row figur summar result for three differ evalu scheme we find method cam consist outperform altern for theoret object cam better second best deg differ in overal user intens deg rough speak lead least increas in overal number event in month in term simul object held-out data result similar provid empir evid compar heurist degre an appropri surrog for influenc base poor perform xmu seem high activ necessarili entail influenti elabor interpret real-world experi held-out data consid for exampl differ in rank correl cam deg almost then rough speak this mean incentiv user base approach accommod order real activ pattern in pair realize minimax activ shape mmash we compar a number altern uni heurist base equal alloc minmu heurist base without optim lp linear program base heurist grd a greedi approach leverag activ appendix for more detail second row figur summar result for three differ evalu scheme we find method mmash consist outperform altern for theoret object better second best lp import differ mmash lp trifl least activ user carri more action in averag a month as one may expect grd lp best among heurist poor perform minmu direct relat object mmash may assign budget a low activ user regardless influenc howev method clever distribut budget user action trigger mani user action like one low activ benefit budget in term simul object held-out data algorithm perform becom more similar least-squar activ shape lsash we compar two altern prop assign budget proport desir activ lsgrd greedili alloc budget accord the differ current desir activ refer appendix for more detail the third row figur summar the result for the three differ evalu scheme we find that method lsash consist outperform the altern perhap surpris prop despit simplic seem perform slight better lsgrd this may due the way alloc the budget user aim strict fulfil user target activ benefit more user assign budget proport refer appendix for addit experi sparsiti activ shape in applic a limit the number user we incentiv in propos framework we can handl this requir includ a sparsiti constraint the optim problem in order maintain the convex the optim problem we consid a l1 regular term a regular paramet provid the trade-off sparsiti the activ shape goal refer appendix for more detail experiment result for differ valu scalabl the comput demand part the propos algorithm the evalu matrix exponenti we scale util techniqu matrix algebra such as gmres al-mohi method as a result we abl run method in a reason amount time the dataset specif in comparison with a naiv implement matrix exponenti evalu refer to appendix for detail experiment result scalabl appendix discuss the limit our framework futur work acknowledg this project support in part nsf nsf/nih bigdata nsf career raytheon faculti fellowship to le song isabel valera acknowledg the support plan regional-programa i+d comunidad de madrid ages-cm ministerio de ciencia innovaci spain project deipro program consolider-ingenio comonsen
----------------------------------------------------------------

title: 4532-learning-to-discover-social-circles-in-ego-networks.pdf

learn discov social circl ego network jure leskovec stanford usa jure cs.stanford.edu julian mcauley stanford usa jmcauley cs.stanford.edu abstract person social network big clutter current good way organ social network site allow user manual categor friend social circl circl googl list facebook twitter howev labori construct must updat whenev user network grow defin novel machin learn task identifi user social circl pose problem node cluster problem user ego-network network connect friend develop model detect circl combin network structur well user profil inform circl learn member circle-specif user profil similar metric model node membership multipl circl allow us detect overlap well hierarch nest circl experi show model accur identifi circl divers set data facebook googl twitter obtain hand-label ground-truth introduct onlin social network allow user follow stream post generat hundr friend acquaint user friend generat overwhelm volum inform cope inform overload need organ person social network one main mechan user social network site organ network content generat categor friend refer social circl practic major social network provid function exampl circl googl list facebook twitter onc user creat circl use content filter filter status updat post distant acquaint privaci hide person inform cowork share group user other may wish follow current user facebook googl twitter identifi circl either manual na fashion identifi friend share common attribut neither approach particular satisfactori former time consum updat automat user add friend latter fail captur individu aspect user communiti may function poor profil inform miss withheld paper studi problem automat discov user social circl particular given singl user person social network goal identifi circl subset friend circl user-specif user organ person network friend independ user connect mean formul problem circl detect cluster problem ego-network network friendship friend figur given singl user form network friend vi refer user ego node vi alter task identifi circl alter vi belong figur word goal find nest well overlap communities/clust u ego-network general two use sourc data help task first set edg ego-network expect circl form densely-connect set alter figur ego-network label circl network show typic behavior observ data approxim ground-truth circl facebook contain complet within anoth circl overlap anoth circl circl member common circl goal discov circl given network ego friend aim discov circl membership find common properti around circl form howev differ circl overlap heavili alter belong multipl circl simultan mani circl hierarch nest larger one figur thus import model alter membership multipl circl second expect circl dens connect member also share common properti trait thus need explicit model differ dimens user profil along circl emerg model circl affili latent variabl similar alter function common profil inform propos unsupervis method learn dimens profil similar lead dens link circl model two innov first contrast mixedmembership model predict hard assign node multipl circl prove critic good perform second propos parameter definit profil similar learn dimens similar along link emerg extend notion homophili allow differ circl form along differ social dimens idea relat concept blau space achiev allow circl differ definit profil similar one circl might form around friend school anoth around friend locat learn model simultan choos node circl membership profil similar function best explain observ data introduc dataset ego-network facebook googl twitter obtain hand-label ground-truth differ circles.1 experiment result show simultan consid social network structur well user profil inform method perform signific better natur altern current state-of-the-art besid accur method also allow us generat automat explan certain node belong common communiti method complet unsupervis abl automat determin number circl well circl further relat work topic-model techniqu use uncov mixedmembership node multipl group extens allow entiti attribut text inform classic algorithm tend identifi communiti base node featur graph structur rare use concert work relat sens perform cluster social-network data model membership multipl communiti final work model network data similar though under model form communiti shall see problem uniqu characterist requir new model extend version articl appear generat model friendship social circl desir model circl format follow properti node within circl common properti aspect differ circl form differ aspect one circl might form famili member anoth student attend univers circl allow overlap stronger circl allow form within weaker one circl friend degre program may form within circl http //snap.stanford.edu/data univers figur would like leverag profil inform network structur order identifi circl ideal would like abl pinpoint aspect profil caus circl form model interpret user input model ego-network along profil user center node ego-network includ rather consist u friend alter defin ego-network way precis creator circl appear circl ego-network goal predict set circl ck ck associ paramet vector encod circl emerg encod user profil pairwis featur way captur properti user common first describ model appli use arbitrari featur vector section describ sever way construct featur vector suit particular applic describ model social circl treat circl membership latent variabl node within common circl given opportun form edg natur lead hierarch overlap circl devis unsupervis algorithm joint optim latent variabl profil similar paramet best explain observ network data model social circl defin follow given ego-network set circl ck model probabl pair node form edg exp ck ck circl contain node circl circl ck profil similar paramet learn idea high node belong ck low either trades-off two effect sinc featur vector encod similar profil two user paramet vector encod dimens profil similar caus circl form node within circl ck look similar accord consid edg generat independ write probabl p e p e e e set model paramet defin shorthand notat dk ck ck dk ck allow us write log-likelihood log e v e e next describ optim node circl membership well paramet user profil similar function given graph user profil unsupervis learn model paramet treat circl latent variabl aim find maxim regular log-likelihood argmax solv problem use coordin ascent ct argmax l argmax note concav optim gradient ascent partial deriv given de e v dk e e ck e v ck e e fix ci note solv argmaxci ci express pseudo-boolean optim pairwis graphic model written ck argmax c word want edg high weight p appear ck edg low weight appear outsid ck defin ok ck c\ci dk energi ee ee ee ee ee ok log eok log eok ok log eok log eok e e e e express problem form draw upon exist work pseudo-boolean optim use publicly-avail qpbo softwar describ abl accur approxim problem form shown solv ck random order two optim step repeat converg pk regular use norm lead spars readili interpret paramet sinc ego-network natur relat small algorithm readili handl problem scale requir case facebook averag ego-network around node largest network encount node note sinc method unsupervis infer perform independ ego-network mean method could run full facebook graph exampl circl independ detect user ego-network typic contain hundr node hyperparamet estim choos optim number circl choos minim approxim bayesian inform criterion bic argmin bic set paramet predict particular number communiti bic log regular paramet determin use leave-one-out cross valid though experi signific impact perform dataset descript goal evalu unsupervis method ground-truth data expend signific time effort resourc obtain high qualiti hand-label data.2 abl obtain ego-network ground-truth three major social network site facebook googl twitter facebook obtain profil network data ego-network consist circl user develop facebook applic conduct survey ten user ask manual identifi circl friend belong averag user identifi circl ego-network averag circl size friend exampl circl includ student common univers sport team relat etc http //snap.stanford.edu/data rst name alan last name ture posit compani name work type name educ type rst name dilli last name knox posit compani posit work educ compani name type cryptanalyst gc cs cambridg colleg princeton graduat school cryptanalyst gc cs cryptanalyst royal navi cambridg colleg 203first name dilli 607last name knox 607first name alan 607last name ture 617work posit cryptanalyst 617work locat gc cs 607work locat royal navi 617educ name cambridg 617educ type colleg educ name princeton educ type graduat school first name 607last name 617work posit 617work locat 415educ name educ type figur featur construct profil tree-structur construct featur compar path tree exampl tree two user blue pink shown left two scheme construct featur vector profil shown right top right construct binari indic measur differ leav two tree work posit cryptanalyst appear tree bottom right sum leaf node first scheme maintain fact two user work institut discard ident institut two dataset obtain public access data googl obtain data ego-network consist circl user ego-network repres googl user share least two circl whose network inform public access time crawl googl circl quit differ facebook sens creator chosen releas public googl direct network note model natur appli direct undirect network exampl one circl contain candid republican primari presum follow follow final twitter obtain data ego-network consist circl list user ego-network obtain rang size node taken togeth data contain differ ego-network circl user size differ dataset simpli reflect avail data three sourc facebook data fulli label sens obtain everi circl user consid cohes communiti wherea googl twitter data partial label sens access public circl design evalu procedur section partial label caus issu construct featur user profil profil inform dataset repres tree level encod increas specif inform figur left googl collect data six categori gender last name job titl institut univers place live facebook collect data categori includ hometown birthday colleagu polit affili etc twitter mani choic exist proxi user profil simpli collect data two categori name set hashtag mention use user two-week worth tweet categori correspond parent leaf node profil tree shown figur first describ differ vector encod relationship two profil non-techn descript given figur suppos user associ profil tree tv tv leaf tree defin differ vector two user binari indic encod profil aspect user differ figur top right tx ty note featur descriptor defin per ego-network mani thousand high school exampl exist among facebook user small number appear among particular user friend although differ vector advantag encod profil inform fine granular disadvantag high-dimension dimens data consid one way address form differ vector base parent leaf node way encod profil categori two user common disregard specif valu figur bottom right exampl encod mani hashtag two user tweet common discard hashtag tweet l children p scheme advantag requir constant number dimens regardless size ego-network facebook googl twitter describ base differ vector describ construct edg featur first properti wish model member circl common relationship second properti wish model member circl common relationship ego ego-network case consid profil tree tu ego user we defin featur term user taken elementwis these two parameter allow us assess mechan better captur user subject definit circl case we includ constant featur control probabl edg form within circl equival measur extent circl made friend import this allow us predict membership even user profil inform simpli due pattern connect we defin similar compress differ vector summar we identifi four way repres compat differ aspect profil two user we consid two way construct differ vector two way captur compat pair profil experi although method unsupervis we evalu ground-truth data examin maximum-likelihood assign latent circl ck converg goal proper regular model latent variabl align close human label ground-truth circl evalu metric measur align predict circl ground-truth we comput balanc error rate ber two circl ber c circl this measur assign equal import fals posit fals negat trivial random predict incur an error averag measur prefer loss exampl assign extrem low error trivial predict we also report f1 score we find produc qualit similar result align predict ground-truth circl sinc we know correspond we comput optim match via linear assign maxim circl max ber c c dom f number predict circl partial correspond c. everi circl must match less number ground-truth circl we incur penalti addit predict could circl includ ground-truth we use establish techniqu estim number circl none baselin suffer disadvantag mispredict method predict trivial solut return powerset user we note remov biject requir forc circl align allow multipl predict circl match singl groundtruth circl vice versa lead qualit similar result accuraci ber accuraci score accuraci detect communiti balanc error rate higher better multi-assign cluster streich frank low-rank embed yoshida block-lda balasubramanyan cohen model friend-to-friend featur eq model friend-to-us featur eq model compress featur eq model compress featur eq facebook twitter googl accuraci detect communiti score higher better multi-assign cluster streich frank low-rank embed yoshida block-lda balasubramanyan cohen model friend-to-friend featur eq model friend-to-us featur eq model compress featur eq model compress featur eq facebook googl twitter figur perform facebook googl twitter term balanc error rate f1 score bottom higher better error bar show standard error improv best featur compar nearest competitor signific level better baselin we consid wide number baselin method includ consid network structur consid profil inform consid first we experi mix membership stochast block model consid network inform variant also consid text attribut node mixedmembership model predict stochast vector encod partial circl membership we threshold generat hard assign we also consid block-lda we generat document treat aspect user profil word bag-of-word model second we experi classic cluster algorithm such k-mean hierarch cluster form cluster base node profil ignor network convers we consid link cluster cliqu percol use network inform ignor profil we also consid low-rank embed approach node attribut edg inform project featur space classic cluster techniqu appli final we consid multi-assign cluster promis predict hard assign multipl cluster though without use network eight baselin highlight we report three whose overal perform best name block-lda slight outperform mix membership stochast block model low-rank embed multi-assign cluster perform facebook googl twitter data figur show result our facebook googl twitter data circl align describ number circl determin describ section non-probabilist baselin we chose maxim modular describ term absolut perform our best model achiev ber score facebook googl twitter score respect lower f1 score googl twitter explain fact mani circl maintain sinc initi creat we achiev high recal we recov friend circl low precis we recov addit friend appear circl creat compar our method baselin we notic we outperform baselin dataset statist signific margin compar nearest competitor our best perform featur improv ber facebook googl twitter improv term f1 score similar regard perform baselin method we note good perform seem depend critic predict hard membership multipl circl use combin node edg inform none baselin exhibit precis this combin shortcom our model address featur we propos friend-to-friend featur friend-to-us featur perform similar reveal scheme ultim encod similar inform surpris studi degre speak languag featur index american weight featur index weight weight featur index for german went school studi degre featur index for level educ featur index for colleg educ peopl work particular institut featur index for featur index for weight live s.f stanford weight peopl phds weight weight weight figur three detect circl small ego-network facebook compar three groundtruth circl ber blue node true posit grey true negat red fals posit yellow fals negat our method correct identifi largest circl left sub-circl contain within center third circl signific overlap right work for employ time featur index for figur paramet vector four communiti for particular facebook user top four plot show complet featur bottom four plot show compress featur both case ber for exampl former featur encod fact member particular communiti tend speak german latter featur encod fact speak languag person identifi annot suppress sinc user friend similar profil use compress featur signific impact perform promis sinc far lower dimens the full featur this reveal suffici model categori attribut user common school town rather the attribut valu we found algorithm perform signific better facebook googl twitter there explan first our facebook data complet the sens survey particip manual label everi circl ego-network wherea in dataset we observ publicly-vis circl may up-to-d second the profil categori avail from facebook inform the categori from googl the tweet-bas profil we build from twitter basic differ lie in the natur the network edg in facebook encod mutual tie wherea edg in googl twitter encod follow relationship chang the role circl serv the latter two point explain algorithm use either edg profil inform in isol unlik perform well this data qualit analysi final we examin the output our model in greater detail figur show result of our method on an exampl ego-network from facebook differ color indic true fals posit negat our method correct abl to identifi overlap circl well as sub-circl circl within circl figur show paramet vector learn for four circl for particular facebook user posit weight indic properti user in particular circl in common notic the model natur learn the social dimens lead to a social circl moreov the first paramet correspond to a constant featur the highest weight this reveal membership to the communiti provid the strongest signal that edg form profil data provid a weaker still relev signal acknowledg this research support in part by nsf darpa xdata darpa graph albert yu mari bechmann foundat boe ally samsung intel alfr p. sloan fellowship the microsoft faculti fellowship
----------------------------------------------------------------

title: 5116-a-latent-source-model-for-nonparametric-time-series-classification.pdf

latent sourc model nonparametr time seri classif georg h. chen mit georgehc mit.edu stanislav nikolov twitter snikolov twitter.com devavrat shah mit devavrat mit.edu abstract classifi time seri nearest-neighbor approach wide use practic perform often competit better elabor method neural network decis tree support vector machin develop theoret justif effect nearest-neighbor-lik classif time seri guid hypothesi mani applic forecast topic becom trend twitter actual mani prototyp time seri begin relat number time seri access topic becom trend twitter distinct manner wherea collect massiv amount twitter data operation hypothesi propos latent sourc model time seri natur lead weight major vote classif rule approxim nearest-neighbor classifi establish nonasymptot perform guarante weight major vote nearest-neighbor classif model account much time seri observ model complex experiment result synthet data show weight major vote achiev misclassif rate nearest-neighbor classif observ less time seri use weight major forecast news topic twitter becom trend abl detect trend topic advanc twitter time mean earli advantag hour minut true posit rate fals posit rate introduct recent year seen explos avail time seri data relat virtual everi human endeavor data demand analyz turn valuabl insight key recur task mine data abl classifi time seri run exampl use throughout paper consid time seri track much activ particular news topic twitter given time seri present time ask news topic go viral borrow twitter terminolog label time seri trend call correspond news topic trend topic news topic goe viral otherwis time seri label trend seek forecast whether news topic becom trend declar trend twitter amount binari classif problem import skirt discuss make topic consid trend irrelev mathemat development.1 furthermor remark handl case singl time seri differ label differ time beyond scope paper public knowledg twitter defin topic trend topic twitter provid inform topic trend topic take label ground truth effect treat topic goe viral black box suppli twitter numer standard classif method tailor classifi time seri yet simpl nearest-neighbor approach hard beat term classif perform varieti dataset result competit better various elabor method neural network decis tree support vector machin recent research examin distanc use nearest-neighbor classif boost classif perform appli differ transform time seri use nearest-neighbor classif exist result most experiment lack theoret justif nearest-neighbor-lik time seri classifi expect perform well well confin classifi time seri amount data tend infin nearest-neighbor classif shown achiev probabl error worst twice bay error rate consid nearest neighbor allow grow amount data error rate approach bay error rate howev rather examin asymptot case amount data goe infin instead pursu nonasymptot perform guarante term larg train dataset much observ time seri classifi arriv nonasymptot guarante impos low-complex structur time seri contribut present model nearest-neighbor-lik classif perform well operation follow hypothesi mani time seri applic small number prototyp time seri relat number time seri collect exampl post twitter generat human often behavior predict aggreg suggest topic post becom trend twitter distinct manner yet dispos enorm volum twitter data context present novel latent sourc model time seri generat small collect unknown latent sourc one two label say trend trend model maximum posteriori map time seri classifi approxim weight major vote compar time seri classifi time seri label train data train time seri cast weight vote favor ground truth label weight depend similar time seri classifi train exampl final classif trend trend depend label higher overal vote vote nonparametr learn paramet model driven entir train data unknown latent sourc never estim train data serv proxi latent sourc weight major vote approxim nearest-neighbor classifi also analyz model show suffici condit log time seri train data weight major vote nearest-neighbor classif correct classifi new time seri probabl least observ first log time step analysi account much time seri observ result readili appli onlin set time seri classifi stream case forecast trend topic well offlin set access entir time seri also analysi yield match error upper bound two classifi experiment result synthet data suggest weight major vote outperform nearest-neighbor classif earli observ littl time seri classifi meanwhil specif instanti model lead spheric gaussian mixtur model latent sourc gaussian mixtur compon show exist perform guarante learn spheric gaussian mixtur model requir stringent condit result need suggest learn latent sourc overkil goal classif last appli weight major vote forecast trend topic twitter emphas goal precognit trend predict whether topic go trend actual declar trend twitter theori third parti collect ground truth label exist work identifi trend twitter instead part trend detect defin model trend assum access definit could said previous work novel document detect twitter experi weight major vote abl predict whether topic trend advanc twitter time mean earli advantag hour minut true posit rate fals posit rate empir find twitter activ news topic becom trend tend follow one finit number pattern could thought latent sourc outlin weight major vote nearest-neighbor classif time seri present section provid latent sourc model theoret perform guarante weight major vote nearest-neighbor classif model section experiment result synthet data forecast trend topic twitter section weight major vote nearest-neighbor classif given time-series2 want classifi either label trend trend access label train data denot set train time seri label respect weight major vote positively-label exampl cast weight vote whether time seri label measur similar two time seri superscript indic allow look first time step time step allow look outsid time step train time seri constant scale paramet determin sphere influenc exampl similar negatively-label exampl also cast weight vote whether time seri label similar measur could exampl squar euclidean distanc t pt kr sk2t howev similar measur look first time step train time seri sinc time seri train data known need restrict attent first time step thus use follow similar measur t min max max min max max kr sk2t minim integ time shift pre-specifi maximum allow shift max use denot time seri advanc time step final sum weight vote weight vote label major overal weight vote declar label t t r2r otherwis use larger time window size correspond wait longer make predict need trade long wait accur want predict note knearest-neighbor classif correspond consid nearest neighbor among train time seri vote set obtain follow classifi nearest-neighbor classifi let rb arg minr2r t nearest neighbor declar label rb ln rb latent sourc model theoret guarante assum unknown latent sourc time seri generat observ time seri let denot set latent sourc latent sourc true label let set latent sourc label set label observ time seri generat latent sourc follow sampl latent sourc uniform random.3 let label index time use notate conveni assum time seri start time step while keep sampl uniform clariti present theoret guarante easili extend case sampl uniform chang number train data need larger factor 1min min smallest probabl particular latent sourc occur activ time figur exampl latent sourc superimpos latent sourc shift vertic amplitud everi latent sourc label rest label sampl integ time shift uniform max output time seri latent sourc advanc time step follow ad nois signal label associ generat time seri l. entri nois zero-mean sub-gaussian paramet mean time index e exp exp r. famili sub-gaussian distribut includ varieti distribut zeromean gaussian standard deviat uniform distribut generat process defin latent sourc model import make assumpt structur latent sourc instanc latent sourc could tile shown figur even separ vertic altern two differ class parametr model like k-compon gaussian mixtur model estim latent sourc could problemat exampl take two adjac latent sourc label cluster cluster could confus latent sourc label sandwich nois complic estim latent sourc exampl k-compon gaussian mixtur model need label would requir exact number latent sourc label unknown general number sampl need gaussian mixtur mixtur model estim mixtur compon mean exponenti number mixtur compon discuss next classif sidestep learn latent sourc altogeth instead use train data proxi latent sourc end section compar sampl complex classif versus exist sampl complex learn gaussian mixtur model classif knew latent sourc nois entri across maximum posteriori map estim label given observ time seri map lmap otherwis map max 2v exp exp kv kv sk2t sk2t howev know latent sourc know nois gaussian assum access train data given section make assumpt train data sampl latent sourc model differ train time seri denot max max approxim map classifi use train data proxi latent sourc specif take ratio replac inner sum minimum expon replac replac obtain ratio min 2d kr sk2t 2r exp min 2d kr sk2t 2r exp plug place map classif rule yield weight major vote rule note weight major vote could interpret smooth nearest-neighbor approxim wherebi consid time-shift version exampl time seri closest observ time seri t replac summat time shift minimum expon kernel densiti estim numer denomin chapter kernel gaussian main theoret result weight major vote follow would still hold use proof.4 last applic may call trade true fals posit rate general decis rule declar label vari paramet result decis rule refer general weight major vote thus otherwis set recov usual weight major vote modif classifi thought adjust prior relat size two class theoret result follow actual cover general case rather theoret guarante present main theoret result paper identifi suffici condit general weight major vote nearest-neighbor classif classifi time seri correct high probabl account size train dataset much observ time seri classifi first defin gap restrict time length maximum time shift max g t max min 2r 2d kr k2t quantiti measur far apart two differ class look length-t chunk time seri allow shift max time step either direct first main result state defer proof longer version paper theorem perform guarante general weight major vote let number latent sourc label number latent sourc label latent sourc model log time seri train data probabl misclassifi time seri label use general satisfi bound weight major vote p l max exp max immedi consequ given error toler choic upper bound two term right-hand side if log 2m log log g t log log max log log this mean if access larg enough pool label time seri pool log time seri subsampl log use train data choic general weight major vote correct classifi new time seri probabl least if g t max log log max log max thus gap set need grow logarithm number latent sourc order weight major vote classifi correct high probabl assum use minimum rather summat time shift make method similar exist time seri classif work minim time warp rather simpl shift origin unknown latent sourc separ otherwis hope distinguish class use classifi gap train data grow g t max otherwis closest two train time seri opposit class within nois observ first log max log time step time seri suffici classifi correct probabl least similar result hold nearest-neighbor classifi theorem perform guarante nearest-neighbor classif latent sourc model log time seri train data probabl satisfi misclassifi time seri label use nearest-neighbor classifi nn bound max exp p l g t max nn general weight major vote bound correspond regular weight major vote match nearest-neighbor classif bound suggest two method similar behavior gap grow practic we find weight major vote outperform nearest-neighbor classif small grow larg two method exhibit similar perform agreement our theoret analysi small could still fair like nearest neighbor found wrong label doom nearest-neighbor classifi failur weight major vote hand recov this situat may enough correct label train time seri close contribut higher overal vote correct class this robust weight major vote make favor onlin set we want make predict earli possibl sampl complex learn latent sourc if we estim latent sourc accur we could plug estim place true latent sourc map classifi achiev classif perform close optim if we restrict nois gaussian assum max latent sourc model correspond spheric gaussian mixtur model we could learn model use dasgupta schulman modifi em algorithm theoret guarante depend true separ closest two latent sourc name minv v 2v kv need satisfi log g t log max log max algorithm achiev probabl least addit error euclidean distanc close optim estim everi latent sourc contrast our result term gap g t max depend true separ two latent sourc instead minimum observ separ train data two time seri opposit label fact our gap set grow even gap g t grow sublinear pt particular while their result handl regim log use log train time seri observ first log time step classifi time seri correct probabl least see longer version this paper detail vempala wang spectral method learn gaussian mixtur model hane m2 train data dle smaller g t dasgupta schulman approach requir we hidden depend variabl interest clariti present hsu kakad moment-bas estim t gap condit differ non-degeneraci condit requir substanti sampl our problem setup achiev approxim mixtur compon these result need substanti train data we shown suffici classif fit gaussian mixtur model massiv train dataset practic use train data could prohibit expens scenario one could instead non-uniform subsampl o t m3 time seri train data use procedur given then feed result smaller dataset refer coreset em algorithm learn latent sourc this procedur still requir more train time seri need classif lack guarante estim latent sourc close true latent sourc classif error rate test data classif error rate test data weight major vote nearest neighbor classifi oracl map classifi weight major vote nearest neighbor classifi oracl map classifi activ figur result synthet data classif error rate number initi time step use train set size log classif error rate experi repeat time newli generat latent sourc train data test data each time error bar denot one standard deviat mean valu time figur news topic becom trend twitter top left show time seri activ lead news topic becom trend these time seri superimpos look like clutter we separ differ cluster shown next five plot each cluster repres way news topic becom trend experiment result synthet data we generat latent sourc each latent sourc construct first sampl entri per time step then appli 1d gaussian smooth filter scale paramet half latent sourc label half then log train time seri sampl per latent sourc model nois ad max we similar generat time seri use test data we set for weight major vote for we compar classif error rate test data for weight major vote nearest-neighbor classif map classifi with oracl access true latent sourc shown figur we see weight major vote outperform nearest-neighbor classif grow larg two method perform converg map classifi fix we then compar classif error rate three method use vari amount train data shown in figur oracl map classifi also shown actual depend train data we see increas weight major vote nearest-neighbor classif steadili improv in perform forecast trend topic twitter we provid overview our twitter result here defer full detail longer version this paper we sampl exampl trend at random list june news trend exampl non-trend base phrase appear in user post month as we know twitter choos phrase consid as candid phrase for trend topic unclear size figur result twitter data weight major vote achiev low error rate fpr tpr detect trend topic in advanc twitter time with mean hour paramet tsmooth envelop roc curv show the tradeoff tpr fpr distribut detect time for aggress conserv bottom in-between center paramet set non-trend categori in comparison the size the trend categori thus for simplic we intent control for the class size set equal in practic one could still expressli assembl the train data pre-specifi class size then tune for general weight major vote in our experi we use the usual weight major vote classifi time seri max set the maximum possibl we consid all shift per topic we creat time seri base pre-process version the raw rate often the topic share tweet rate we empir found news topic becom trend tend to follow finit number pattern exampl these pattern shown in figur we random divid the set trend non-trend two halv one to use as train data one to use as test data we appli weight major vote sweep data pre-process paramet as shown in figur one choic paramet allow us to detect trend topic in advanc twitter the time we we detect averag hour earlier furthermor we achiev a true posit rate tpr a fals posit rate fpr natur tradeoff tpr fpr earli we make a predict how small as shown in figur aggress paramet set yield earli detect high tpr high fpr a conserv paramet set yield low fpr late detect low tpr an in-between set strike the right balanc acknowledg this work support in part the armi research offic under muri award ghc support an ndseg fellowship
----------------------------------------------------------------

