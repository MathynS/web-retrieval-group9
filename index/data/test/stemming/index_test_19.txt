query sentence: Sentiment of tweets on twitter
---------------------------------------------------------------------
title: 5275-global-belief-recursive-neural-networks.pdf

Global Belief Recursive Neural Networks
Romain Paulus, Richard Socher?
MetaMind
Palo Alto, CA
{romain,richard}@metamind.io

Christopher D. Manning
Stanford University
353 Serra Mall
Stanford, CA 94305
manning@stanford.edu

Abstract
Recursive Neural Networks have recently obtained state of the art performance on
several natural language processing tasks. However, because of their feedforward
architecture they cannot correctly predict phrase or word labels that are determined by context. This is a problem in tasks such as aspect-specific sentiment
classification which tries to, for instance, predict that the word Android is positive
in the sentence Android beats iOS. We introduce global belief recursive neural
networks (GB-RNNs) which are based on the idea of extending purely feedforward neural networks to include one feedbackward step during inference. This
allows phrase level predictions and representations to give feedback to words. We
show the effectiveness of this model on the task of contextual sentiment analysis. We also show that dropout can improve RNN training and that a combination
of unsupervised and supervised word vector representations performs better than
either alone. The feedbackward step improves F1 performance by 3% over the
standard RNN on this task, obtains state-of-the-art performance on the SemEval
2013 challenge and can accurately predict the sentiment of specific entities.

1

Introduction

Models of natural language need the ability to compose the meaning of words and phrases in order
to understand complex utterances such as facts, multi-word entities, sentences or stories. There has
recently been a lot of work extending single word semantic vector spaces [27, 11, 15] to compositional models of bigrams [16, 29] or phrases of arbitrary length [25, 28, 24, 10]. Work in this
area so far has focused on computing the meaning of longer phrases in purely feedforward types
of architectures in which the meaning of the shorter constituents that are being composed is not
altered. However, a full treatment of semantic interpretation cannot be achieved without taking into
consideration that the meaning of words and phrases can also change once the sentence context is
observed. Take for instance the sentence in Fig. 1: The Android?s screen is better than the iPhone?s.
All current recursive deep learning sentiment models [26] would attempt to classify the phrase The
Android?s screen or than the iPhone?s, both of which are simply neutral. The sentiment of the overall sentence is undefined; it depends on which of the entities the user of the sentiment analysis cares
about. Generally, for many analyses of social media text, users are indeed most interested in the
sentiment directed towards a specific entity or phrase.
In order to solve the contextual classification problem in general and aspect-specific sentiment classification in particular, we introduce global belief recursive neural networks (GB-RNN). These models
generalize purely feedforward recursive neural networks (RNNs) by including a feedbackward step
at inference time. The backward computation uses the representations from both steps in its recursion and allows all phrases, to update their prediction based on the global context of the sentence.
Unlike recurrent neural networks or window-based methods [5] the important context can be many
?

Part of this research was performed while the author was at Stanford University.

1

?

-

0

Android

0

0

beats

iOS

Figure 1: Illustration of the problem of sentiment classification that uses only the phrase to be labeled
and ignores the context. The word Android is neutral in isolation but becomes positive in context.
words away from the phrase that is to be labeled. This will allow models to correctly classify that in
the sentence of Fig. 1, Android is described with positive sentiment and iOS was not. Neither was
possible to determine only from their respective phrases in isolation.
In order to validate the GB-RNN?s ability to contextually disambiguate sentiment on real text, we
use the Twitter dataset and annotations from Semeval Challenge 2013 Task 2.1 The GB-RNN outperforms both the standard RNN and all other baselines, as well the winner of the Sentiment competition of SemEval 2013, showing that it can successfully make use of surrounding context.

2

Related Work

Neural word vectors One common way to represent words is to use distributional word vectors
[27] learned via dimensionality reduction of large co-occurrence matrices over documents (as in
latent semantic analysis [13]), local context windows [15, 18] or combinations of both [11]. Words
with similar meanings are close to each other in the vector space. Since unsupervised word vectors computed from local context windows do not always encode task-specific information, such
as sentiment, word vectors can also be fine-tuned to such specific tasks [5, 24]. We introduce a
hybrid approach where some dimensions are obtained from an unsupervised model and others are
learned for the supervised task. We show that this performs better than both the purely supervised
and unsupervised semantic word vectors.
Recursive Neural Networks The idea of recursive neural networks (RNNs) for natural language
processing (NLP) is to train a deep learning model that can be applied to inputs of any length.
Unlike computer vision tasks, where it is easy to resize an image to a fixed number of pixels, natural sentences do not have a fixed size input. However, phrases and sentences have a grammatical
structure that can be parsed as a binary tree [22].
Following this tree structure, we can assign a fixed-length vector to each word at the leaves of
the tree, and combine word and phrase pairs recursively to create intermediate node vectors of the
same length, eventually having one final vector representing the whole sentence [19, 25]. Multiple
recursive combination functions have been explored, from linear transformation matrices to tensor
products [26]. In this work, we use the simple single matrix RNN to combine node vectors at each
recursive step.
Bidirectional-recurrent and bidirectional-recursive neural networks. Recurrent neural networks
are a special case of recursive neural networks that operate on chains and not trees. Unlike recursive
neural networks, they don?t require a tree structure and are usually applied to time series. In a recurrent neural network, every node is combined with a summarized representation of the past nodes
[8], and then the resulting combination will be forwarded to the next node. Bidirectional recurrent neural network architectures have also been explored [21] and usually compute representations
independently from both ends of a time series.
Bidirectional recursive models [12, 14], developed in parallel with ours, extend the definition of the
recursive neural netword by adding a backward propagation step, where information also flows from
the tree root back to the leaves. We compare our model to theirs theoretically in the model section,
and empirically in the experiments.
1

http://www.cs.york.ac.uk/semeval-2013/task2/

2

Figure 2: Propagation steps of the GB-RNN. Step 1 describes the standard RNN feedforward process, showing that the vector representation of ?Android? is independent of the rest of the document.
Step 2 computes additional vectors at each node (in red), using information from the higher level
nodes in the tree (in blue), allowing ?Android? and ?iOS? to have different representations given the
context.
[20] unfold the same autoencoder multiple times which gives it more representational power with
the same number of parameters. Our model is different in that it takes into consideration more
information at each step and can eventually make better local predictions by using global context.
Sentiment analysis. Sentiment analysis has been the subject of research for some time [4, 2, 3, 6,
1, 23]. Most approaches in sentiment analysis use ?bag of words? representations that do not take
the phrase structure into account but learn from word-level features. We explore our model?s ability
to determine contextual sentiment on Twitter, a social media platform.

3

Global Belief Recursive Neural Networks

In this section, we introduce a new model to compute context-dependent compositional vector representations of variable length phrases. These vectors are trained to be useful as features to classify
each phrase and word. Fig. 2 shows an example phrase computation that we will describe in detail
below. This section begins by motivating compositionality and context-dependence, followed by a
definition of standard recursive neural networks. Next, we introduce our novel global belief model
and hybrid unsupervised-supervised word vectors.
3.1

Context-Dependence as Motivation for Global Belief

A common simplifying assumption when mapping sentences into a feature vector is that word order
does not matter (?bag of words?). However, this will prevent any detailed understanding of language
as exemplified in Fig. 1, where the overall sentiment of the phrase ?Android beats iOS?, is unclear.
Instead, we need an understanding of each phrase which leads us to deep recursive models.
The first step for mapping a sentence into a vector space is to parse them into a binary tree structure
that captures the grammatical relationships between words. Such an input dependent binary tree then
determines the architecture of a recursive neural network which will compute the hidden vectors in a
bottom-up fashion starting with the word vectors. The resulting phrase vectors are given as features
to a classifier. This standard RDL architecture works well for classifying the inherent or contextindependent label of a phrase. For instance, it can correctly classify that a not so beautiful day is
negative in sentiment. However, not all phrases have an inherent sentiment as shown in Fig. 1.
The GB-RNN addresses this issue by propagating information from the root node back to the
leaf nodes as described below. There are other ways context can be incorporated such as with
bi-directional recurrent neural networks or with window-based methods. Both of these methods,
however, cannot incorporate information from words further away from the phrase to be labeled.
3.2

Standard Recursive Neural Networks

We first describe a simple recursive neural network that can be used for context-independent phraselevel classification. It can also be seen as the first step of a GB-RNN.
3

Assume, for now, that each word vector a ? Rn is obtained by sampling each element from a
uniform distribution: ai ? U(?0.001, 0.001). All these vectors are columns of a large embedding
matrix L ? Rn?|V | , where |V | is the size of the vocabulary. All word vectors are learned together
with the model.
For the example word vector sequence (abc) of Fig. 2, the RNN equations become:
  
 

b
a
p1 = f W
, p2 = f W
,
c
p1

(1)

where W ? Rn?2n is the matrix governing the composition and f the non-linear activation function. Each node vector is the given as input to a softmax classifier for a classification task such as
sentiment analysis.
3.3

GB-RNN: Global Belief Recursive Neural Networks

Our goal is to include contextual information in the recursive node vector representations. One
simple solution would be to just include the k context words to the left and right of each pair as in
[25]. However, this will only work if the necessary context is at most k words away. Furthermore,
in order to capture more complex linguistic phenomena it may be necessary to allow for multiple
words to compose the contextual shift in meaning. Instead, we will use the feedforward nodes from
a standard RNN architecture and simply move back down the tree. This can also be interpreted as
unfolding the tree and moving up its branches.
Hence, we keep the same Eq. 1 for computing the forward node vectors, but we introduce new
feedbackward vectors, denoted with a down arrow ? , at every level of the parse tree. Unlike the
feedforward vectors, which were computed with a bottom-up recursive function, feedbackward vectors are computed with a top-down recursive function. The backwards pass starts at the root node
and propagates all the way down to the single word vectors. At the root note, in our example the
node p2 , we have:
p?2 = f (V p2 ) ,
(2)
where V ? Vnd ?n so that all ?-node vectors are nd -dimensional. Starting from p?2 , we recursively
get ?-node vectors for every node as we go down the tree:
 ? 



 ? 



p2
p1
a
b
?
?
=
f
W
,
=
f
W
(3)
?
?
c?
p2
p1
p?1
where all ?-vectors, are nd -dimensional and hence W ? ? R(n+nd )?(n+nd ) is a new de-composition
matrix. Figure 2 step 2 illustrates this top-down recursive computation on our example. Once we
have both feedforward and feedbackward vectors for a given node, we concatenate them and employ
the standard softmax classifier
the final prediction. For instance, the classification for word
 to make
a
a becomes: ya = softmax Wc
, where we fold the bias into the C-class classifier weights
a?
Wc ? RC?(n+1) .
At the root node, the equation for x?root could be replaced by simply copying x?root = xroot . But
there are two advantages of introducing a transform matrix V . First, it helps clearly differentiating features computed during the forward step and the backward step in multiplication with W ? .
Second, it allows to use a different dimension for the x? vectors, which reduces the number of parameters in the W ? and Wclass matrices, and adds more flexibility to the model. It also performs
better empirically.
3.4

Hybrid Word Vector Representations

There are two ways to initialize the word vectors that are given as inputs to the RNN models. The
simplest one is to initialize them to small random numbers as mentioned above and backpropagate
error signals into them in order to have them capture the necessary information for the task at hand.
This has the advantage of not requiring any other pre-training method and the vectors are sure to
capture domain knowledge. However, the vectors are more likely to overfit and less likely to generalize well to words that have not been in the (usually smaller) labeled training set. Another approach
4

Figure 3: Hybrid unsupervised-supervised vector representations for the most frequent 50 words
of the dataset. For each horizontal vector, the first 100 dimensions are trained on unlabeled twitter
messages, and the last dimensions are trained on labeled contextual sentiment examples.

is to use unsupervised methods that learn semantic word vectors such as [18]. One then has the
option to backpropagate task specific errors into these vectors or keep them at their initialization.
Backpropagating into them still has the potential disadvantage of hurting generalization apart from
slowing down training since it increases the number of parameters by a large amount (there are usually 100, 000 ? 50 many parameters in the embedding matrix L). Without propagating information
however one has to hope that the unsupervised method really captures all the necessary semantic
information which is often not the case for sentiment (which suffers from the antonym problem).
In this paper we propose to combine both ideas by representing each word as a concatenation of both
unsupervised vectors that are kept at their initialization during training and adding a small additional
vector into which we propagate the task specific error signal. This vector representation applies only
to the feedforward word vectors and shold not be confused with the combination of the feedwordard
and feedbackward node vectors in the softmax.
Figure 3.4 shows the resulting word vectors trained on unlabeled documents on one part (the first
100 dimensions), and trained on labeled examples on the other part (the remaining dimensions).
3.5

Training

The GB-RNN is trained by using backpropagation through structure [9]. We train the parameters by
optimizing the regularized cross-entropy error for labeled node vectors with mini-batched AdaGrad
[7]. Since we don?t have labels for every node of the training trees, we decided that unlabeled
nodes do not add an additional error during training. For all models, we use a development set to
cross-validate over regularization of the different weights, word vector size, mini-batch size, dropout
probability and activation function (rectified linear or logistic function).
We also applied the dropout technique to improve training with high dimensional word vectors.
Node vector units are randomly set to zero with a probability of 0.5 at each training step. Our
experiments show that applying dropout in this way helps differentiating word vector units and
hidden units, and leads to better performance. The high-dimensional hybrid word vectors that we
introduced previously have obtained a higher accuracy than other word vectors with the use of
dropout.
3.6

Comparison to Other Models

The idea of unfolding of neural networks is commonly used in autoencoders as well as in a recursive
setting [23], in this setting the unfolding is only used during training and not at inference time to
update the beliefs about the inputs.
Irsoy and Cardie [12] introduced a bidirectional RNN similar to ours. It employs the same standard
feedforward RNN, but a different computation for the backward ? vectors. In practice, their model is
defined by the same forward equations as ours. However, equation 3 which computes the backward
vectors is instead:
 ? 


b
V b + Wlb? p?1
=f
(4)
? ?
c?
V c + Wrb
p1
5

Correct FUSION?s 5th General Meeting is tonight at 7 in ICS 213! Come out and carve pumpkins mid-quarter
with us!
Correct I would rather eat my left foot then to be taking the SATs tomorrow
Correct Special THANKS to EVERYONE for coming out to Taboo Tuesday With DST tonight! It was
FUN&educational!!! :) @XiEtaDST
Correct Tough loss for @statebaseball today. Good luck on Monday with selection Sunday
Correct I got the job at Claytons!(: I start Monday doing Sheetrock(: #MoneyMakin
Correct St Pattys is no big deal for me, no fucks are given, but Cinco De Mayo on the other hand .. thats my
2nd bday .
Incorrect ?@Hannah Sunder: The Walking Dead is just a great tv show? its bad ass just started to watch the
2nd season to catch up with the 3rd

Figure 4: Examples of predictions made by the GB-RNN for twitter documents. In this example,
red phrases are negative and blue phrases are positive. On the last example, the model predicted
incorrectly ?bad ass? as negative.
?
Where Wlb? and Wrb
are two matrices with dimensions nd ? nd . For a better comparison with our
model we rewrite Eq. 3 and make explicit the 4 blocks of W ? :
"
#
"
#!
 ? 
?
?
Wlf
Wlb?
Wlf
p1 + Wlb? p?1
b
?
Let W =
, then
=f
,
(5)
?
?
?
? ?
c?
Wrf
Wrb
Wrf
p1 + Wrb
p1
?
?
?
?
where the dimensions of Wlf
and Wrf
are nd ? n, and the dimensions of Wld
and Wrd
are nd ? nd .

A closer comparison between Eqs. 4 and 5 reveals that both use a left and right forward transfor?
?
mation Wlf
p1 and Wrf
p1 , but the other parts of the sums differ. In the bidirectional-RNN, the
transformation of any children is defined by the forward parent and independent on its position (left
or right node). Whereas our GB-RNN makes uses of both the forward and backward parent node.
The intuition behind our choice is that using both nodes helps to push the model to disentangled
the children from their backward parent vector. We also note that our model does not use the forward node vector for computing the backward node vector, but we find this not necessary since the
softmax function already combines the two vectors.
Our model also has n ? nd more parameters to compute the feedbackward vectors than the
bidirectional-RNN. The W ? matrix of our model has 2n2d + 2n ? nd parameters, while the other
?
?
model has a total of 2n2d + n ? nd parameters with the Wlf
, Wrf
and V matrices. We show in the
next section that GB-RNN outperforms the bidirectional RNN in our experiments.

4

Experiments

We present a qualitative and quantitative analysis of the GB-RNN on a contextual sentiment classification task. The main dataset is provided by the SemEval 2013, Task 2 competition [17]. We
outperform the winners of the 2013 challenge, as well as several baseline and model ablations.
4.1

Evaluation Dataset

The SemEval competition dataset is composed of tweets labeled for 3 different sentiment classes:
positive, neutral and negative. The tweets in this dataset were split into a train (7862 labeled phrases),
development (7862) and development-test (7862) set. The final test set is composed of 10681 examples. Fig. 4 shows example GB-RNN predictions on phrases marked for classification in this dataset.
The development dataset consists only of tweets whereas the final evaluation dataset included also
short text messages (SMS in the tables below).
Tweets were parsed using the Stanford Parser [22] which includes tokenizing of negations (e.g.,
don?t becomes two tokens do and n?t). We constrained the parser to keep each phrase labeled by the
dataset inside its own subtree, so that each labeled example is represented by a single node and can
be classified easily.
6

Classifier
SVM
SVM
SVM

GB-RNN

Feature Sets
stemming, word cluster, SentiWordNet
score, negation
POS, lexicon, negations, emoticons,
elongated words, scores, syntactic dependency, PMI
punctuation, word n-grams, emoticons,
character n-grams, elongated words,
upper case, stopwords, phrase length,
negation, phrase position, large sentiment lexicons, microblogging features
parser, unsupervised word vectors (ensemble)

Twitter 2013 (F1)
85.19

SMS 2013 (F1)
88.37

87.38

85.79

88.93

88.00

89.41

88.40

Table 1: Comparison to the best Semeval 2013 Task 2 systems, their feature sets and F1 results on
each dataset for predicting sentiment of phrases in context. The GB-RNN obtains state of the art
performance on both datasets.
Model
Bigram Naive Bayes
Logistic Regression
SVM
RNN
Bidirectional-RNN (Irsoy and Cardie)
GB-RNN (best single model)

Twitter 2013
80.45
80.91
81.87
82.11
85.77
86.80

SMS 2013
78.53
80.37
81.91
84.07
84.77
87.15

Table 2: Comparison with baselines: F1 scores on the SemEval 2013 test datasets.
4.2 Comparison with Competition Systems
The first comparison is with several highly tuned systems from the SemEval 2013, Task 2 competition. The competition was scored by an average of positive and negative class F1 scores. Table 1
lists results for several methods, together with the resources and features used by each method. Most
systems used a considerable amount of hand-crafted features. In contrast, the GB-RNN only needs
a parser for the tree structure, unsupervised word vectors and training data. Since the competition
allowed for external data we outline below the additional training data we use. Our best model is an
ensemble of the top 5 GB-RNN models trained independently. Their predictions were then averaged
to produce the final output.
4.3 Comparison with Baselines
Next we compare our single best model to several baselines and model ablations. We used the same
hybrid word vectors with dropout training for the RNN, the bidirectional RNN and the GB-RNN.
The best models were selected by cross-validating on the dev set for several hyper-parameters (word
vectors dimension, hidden node vector dimension, number of training epochs, regularization parameters, activation function, training batch size and dropout probability) and we kept the models with
the highest cross-validation accuracy. Table 2 shows these results. The most important comparison
is against the purely feedforward RNN which does not take backward sentence context into account.
This model performs over 5% worse than the GB-RNN.
For the logistic regression and Bigram Naive Bayes classification, each labeled phrase was taken
as a separate example, removing the surrounding context. Another set of baselines used a context
window for classification as well as the entire tweet as input to the classifier.
Optimal performance for the single best GB-RNN was achieved by using vector sizes of 130 dimensions (100 pre-trained, fixed word vectors and 30 trained on sentiment data), a mini-batch size of
30, dropout with p = 0.5 and sigmoid non-linearity. In table 3, we show that the concatenation of
fixed, unsupervised vectors with additional randomly initialized, supervised vectors performs better
than both methods.
4.4 Model Analysis: Additional Training Data
Because the competition allowed the usage of arbitrary resources we included as training data labeled unigrams and bigrams extracted from the NRC-Canada system?s sentiment lexicon. Adding
these additional training examples increased accuracy by 2%. Although this lexicon helps reduc7

Word vectors
supervised word vectors
semantic word vectors
hybrid word vectors

dimension
15
100
100 + 34

Twitter 2013
85.15
85.67
86.80

SMS 2013
85.66
84.70
87.15

Table 3: F1 score comparison of word vectors on the SemEval 2013 Task 2 test dataset.
-

-

-

-

Chelski

-

-

+
-

+

want

-

this

+

Chelski

+

+

+

that it

-

-

so

bad

+
+

+

+

want +
this +
so

+

makes-

+

me

+

even

+

that +
it
-

bad

+
-

-

+

+

+

me

+

+
+

+

+

even

+

+
thinking+
+
we +
may
happier

-

+
-

+

beat

+

makes

+

+
thinking+
we may
happier

+

+
+

-

-

twice
them

+

+
+

+

in

+

+

beat

-

-

-

-

4

days

at

+

SB

+
+

+

+

twice
them

+

in
+

+

+

+

+

+

4

days

at

SB

Figure 5: Change in sentiment predictions in the tweet chelski want this so bad that it makes me even
happier thinking we may beat them twice in 4 days at SB between the RNN (left) and the GB-RNN
(right). In particular, we can see the change for the phrase want this so bad where it is correctly
predicted as positive with context.
ing the number of unknown tokens, it does not do a good job for training recursive composition
functions, because each example is short.
We also included our own dataset composed 176,311 noisily labeled tweets (using heuristics such as
smiley faces) as well as the movie reviews dataset from [26]. In both datasets the labels only denote
the context-independent sentiment of a phrase or full sentence. Hence, we trained the final model in
two steps: train the standard RNN, then train the full GB-RNN model on the smaller context-specific
competition data. Training the GB-RNN jointly in this fashion gave a 1% accuracy improvement.

5

Conclusion

We introduced global belief recursive neural networks, applied to the task of contextual sentiment
analysis. The idea of propagating beliefs through neural networks is a powerful and important piece
for interpreting natural language. The applicability of this idea is more general than RNNs and can
be helpful for a variety of NLP tasks such as word-sense disambiguation.
Acknowledgments
We thank the anonymous reviewers for their valuable comments.

References
[1] B.R. Routledge B. O?Connor, R. Balasubramanyan and N.A. Smith. From tweets to polls:
Linking text sentiment to public opinion time series. International AAAI Conference on Weblogs and Social Media, 2010.
[2] L. Barbosa and J. Feng. Robust sentiment detection on twitter from biased and noisy data.
COLING ?10 Proceedings of the 23rd International Conference on Computational Linguistics:
Posters, pages 36?44, 2010.
[3] A. Bifet and E. Frank. Sentiment knowledge discovery in twitter streaming data. Proceedings
of the 13th international conference on Discovery science, 2010.
[4] K. Sobel B.J. Jansen, M. Zhang and A. Chowdury. Twitter power: Tweets as electronic word
of mouth. Journal of the American Society for Information Science and Technology, 2009.
[5] R. Collobert, J. Weston, L. Bottou, M. Karlen, K. Kavukcuoglu, and P. Kuksa. Natural Language Processing (Almost) from Scratch. JMLR, 12:2493?2537, 2011.
8

[6] O. Tsur D. Davidov and A. Rappoport. Enhanced sentiment learning using twitter hashtags
and smileys. Association for Computational Linguistics, 2010.
[7] J. Duchi, E. Hazan, and Y. Singer. Adaptive subgradient methods for online learning and
stochastic optimization. JMLR, 12, July 2011.
[8] J. L. Elman. Distributed representations, simple recurrent networks, and grammatical structure.
Machine Learning, 7(2-3):195?225, 1991.
[9] C. Goller and A. K?uchler. Learning task-dependent distributed representations by backpropagation through structure. In Proceedings of the International Conference on Neural Networks,
1996.
[10] E. Grefenstette, G. Dinu, Y.-Z. Zhang, M. Sadrzadeh, and M. Baroni. Multi-step regression
learning for compositional distributional semantics. In IWCS, 2013.
[11] E. H. Huang, R. Socher, C. D. Manning, and A. Y. Ng. Improving Word Representations via
Global Context and Multiple Word Prototypes. In ACL, 2012.
[12] O. Irsoy and C. Cardie. Bidirectional recursive neural networks for token-level labeling with
structure. NIPS Deep Learning Workshop, 2013.
[13] T. K. Landauer and S. T. Dumais. A solution to Plato?s problem: the Latent Semantic Analysis theory of acquisition, induction and representation of knowledge. Psychological Review,
104(2):211?240, 1997.
[14] P. Le and W. Zuidema. The inside-outside recursive neural network model for dependency
parsing. EMNLP, 2014.
[15] T. Mikolov, W. Yih, and G. Zweig. Linguistic regularities in continuous spaceword representations. In HLT-NAACL, 2013.
[16] J. Mitchell and M. Lapata. Composition in distributional models of semantics. Cognitive
Science, 34(8):1388?1429, 2010.
[17] Z. Kozareva P. Nakov. Semeval-2013 task 2: Sentiment analysis in twitter. Proceedings of the
Seventh International Workshop on Semantic Evaluation (SemEval 2013), 2013.
[18] J. Pennington, R. Socher, and C. D. Manning. Glove: Global vectors for word representation.
EMNLP, 2014.
[19] J. B. Pollack. Recursive distributed representations. Artificial Intelligence, 46, November
1990.
[20] J.T. Rolfe and Y. LeCun. Discriminative recurrent sparse auto-encoders. arXiv:1301.3775v4,
2013.
[21] M. Schuster and K.K. Paliwal. Bidirectional recurrent neural networks. Signal Processing,
IEEE Transactions, 1997.
[22] R. Socher, J. Bauer, C. D. Manning, and A. Y. Ng. Parsing With Compositional Vector Grammars. In ACL, 2013.
[23] R. Socher, E. H. Huang, J. Pennington, A. Y. Ng, and C. D. Manning. Dynamic Pooling and
Unfolding Recursive Autoencoders for Paraphrase Detection. In NIPS, 2011.
[24] R. Socher, B. Huval, C. D. Manning, and A. Y. Ng. Semantic Compositionality Through
Recursive Matrix-Vector Spaces. In EMNLP, 2012.
[25] R. Socher, C. D. Manning, and A. Y. Ng. Learning continuous phrase representations and syntactic parsing with recursive neural networks. In Proceedings of the NIPS-2010 Deep Learning
and Unsupervised Feature Learning Workshop, 2010.
[26] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. Manning, A. Ng, and C. Potts. Recursive deep
models for semantic compositionality over a sentiment treebank. In EMNLP, 2013.
[27] P. D. Turney and P. Pantel. From frequency to meaning: Vector space models of semantics.
Journal of Artificial Intelligence Research, 37:141?188, 2010.
[28] A. Yessenalina and C. Cardie. Compositional matrix-space models for sentiment analysis. In
EMNLP, 2011.
[29] F.M. Zanzotto, I. Korkontzelos, F. Fallucchi, and S. Manandhar. Estimating linear models for
compositional distributional semantics. In COLING, 2010.

9


----------------------------------------------------------------

title: 5860-on-the-job-learning-with-bayesian-decision-theory.pdf

On-the-Job Learning with Bayesian Decision Theory

Keenon Werling
Department of Computer Science
Stanford University
keenon@cs.stanford.edu

Arun Chaganty
Department of Computer Science
Stanford University
chaganty@cs.stanford.edu

Percy Liang
Department of Computer Science
Stanford University
pliang@cs.stanford.edu

Christopher D. Manning
Department of Computer Science
Stanford University
manning@cs.stanford.edu

Abstract
Our goal is to deploy a high-accuracy system starting with zero training examples.
We consider an on-the-job setting, where as inputs arrive, we use real-time crowdsourcing to resolve uncertainty where needed and output our prediction when confident. As the model improves over time, the reliance on crowdsourcing queries
decreases. We cast our setting as a stochastic game based on Bayesian decision
theory, which allows us to balance latency, cost, and accuracy objectives in a principled way. Computing the optimal policy is intractable, so we develop an approximation based on Monte Carlo Tree Search. We tested our approach on three
datasets?named-entity recognition, sentiment classification, and image classification. On the NER task we obtained more than an order of magnitude reduction
in cost compared to full human annotation, while boosting performance relative to
the expert provided labels. We also achieve a 8% F1 improvement over having a
single human label the whole set, and a 28% F1 improvement over online learning.
?Poor is the pupil who does not surpass his master.?
? Leonardo da Vinci

1

Introduction

There are two roads to an accurate AI system today: (i) gather a huge amount of labeled training
data [1] and do supervised learning [2]; or (ii) use crowdsourcing to directly perform the task [3, 4].
However, both solutions require non-trivial amounts of time and money. In many situations, one
wishes to build a new system ? e.g., to do Twitter information extraction [5] to aid in disaster relief
efforts or monitor public opinion ? but one simply lacks the resources to follow either the pure ML
or pure crowdsourcing road.
In this paper, we propose a framework called on-the-job learning (formalizing and extending ideas
first implemented in [6]), in which we produce high quality results from the start without requiring
a trained model. When a new input arrives, the system can choose to asynchronously query the
crowd on parts of the input it is uncertain about (e.g. query about the label of a single token in a
sentence). After collecting enough evidence the system makes a prediction. The goal is to maintain
high accuracy by initially using the crowd as a crutch, but gradually becoming more self-sufficient
as the model improves. Online learning [7] and online active learning [8, 9, 10] are different in that
they do not actively seek new information prior to making a prediction, and cannot maintain high
accuracy independent of the number of data instances seen so far. Active classification [11], like us,
1

Get beliefs under

Decide to ask a crowd

1. learned model
?George?

2. worker in real time

44%: PERSON
12%: RESOURCE
2%: NONE
32%: LOCATION

http://www.crowd-workers.com

What is `George` here?

Soup

on

George

str.

#Katrina

y1

y2

y3

y4

y5

x1

x2

x3

x4

x5

soup on george str,
#katrina

3.

Incorporate feedback,
return a prediction

RESOURCE

LOCATION

Soup

on

George

str.

#Katrina

y1

y2

y3

y4

y5

x1

x2

x3

x4

x5

location
person
resource

r1

none

Figure 1: Named entity recognition on tweets in on-the-job learning.

strategically seeks information (by querying a subset of labels) prior to prediction, but it is based on
a static policy, whereas we improve the model during test time based on observed data.
To determine which queries to make, we model on-the-job learning as a stochastic game based on
a CRF prediction model. We use Bayesian decision theory to tradeoff latency, cost, and accuracy
in a principled manner. Our framework naturally gives rise to intuitive strategies: To achieve high
accuracy, we should ask for redundant labels to offset the noisy responses. To achieve low latency,
we should issue queries in parallel, whereas if latency is unimportant, we should issue queries sequentially in order to be more adaptive. Computing the optimal policy is intractable, so we develop
an approximation based on Monte Carlo tree search [12] and progressive widening to reason about
continuous time [13].
We implemented and evaluated our system on three different tasks: named-entity recognition, sentiment classification, and image classification. On the NER task we obtained more than an order of
magnitude reduction in cost compared to full human annotation, while boosting performance relative to the expert provided labels. We also achieve a 8% F1 improvement over having a single human
label the whole set, and a 28% F1 improvement over online learning. An open-source implementation of our system, dubbed LENSE for ?Learning from Expensive Noisy Slow Experts? is available
at http://www.github.com/keenon/lense.

2

Problem formulation

Consider a structured prediction problem from input x = (x1 , . . . , xn ) to output y = (y1 , . . . , yn ).
For example, for named-entity recognition (NER) on tweets, x is a sequence of words in the tweet
(e.g., ?on George str.?) and y is the corresponding sequence of labels (e.g., NONE LOCATION
LOCATION ). The full set of labels of PERSON , LOCATION , RESOURCE, and NONE .
In the on-the-job learning setting, inputs arrive in a stream. On each input x, we make zero or more
queries q1 , q2 , . . . on the crowd to obtain labels (potentially more than once) for any positions in
x. The responses r1 , r2 , . . . come back asynchronously, which are incorporated into our current
prediction model p? . Figure 2 (left) shows one possible outcome: We query positions q1 = 2
(?George?) and q2 = 3 (?str.?). The first query returns r1 = LOCATION, upon which we make
another query on the the same position q3 = 3 (?George?), and so on. When we have sufficient
? under the model. Each
confidence about the entire output, we return the most likely prediction y
query qi is issued at time si and the response comes back at time ti . Assume that each query costs
m cents. Our goal is to choose queries to maximize accuracy, minimize latency and cost.
? on each input x in
We make several remarks about this setting: First, we must make a prediction y
the stream, unlike in active learning, where we are only interested in the pool or stream of examples
for the purposes of building a good model. Second, the responses are used to update the prediction
2

S oGs

S oGs

S oGs

Legend

none
res
loc
per

1
r1 = res

q1 = 1

r2 = loc

q2 = 3
S oGs

S oGs

S oGs

= system
= crowd
4

?W

? = (tnow , q, s, r, t)
(1, (3), (0), (?), (?))

?W
r1 = loc

S oGs

(1.7, (3), (0), (1.7), (loc))
r1 = loc ?
R

2

0.47

q1 = 1

?R
0.27

r1 = res
r2 = per

q2 = 3
q4 = 3

r4 = loc

(a) Incorporating information from responses. The bar graphs
represent the marginals over the labels for each token (indicated
by the first character) at different points in time. The two timelines show how the system updates its confidence over labels
based on the crowd?s responses. The system continues to issue
queries until it has sufficient confidence on its labels. See the
paragraph on behavior in Section 3 for more information.

(b) Game tree. An example of a partial
game tree constructed by the system when
deciding which action to take in the state
? = (1, (3), (0), (?), (?)), i.e. the query
q1 = 3 has already been issued and the
system must decide whether to issue another query or wait for a response to q1 .

Figure 2: Example behavior while running structure prediction on the tweet ?Soup on George str.?
We omit the RESOURCE from the game tree for visual clarity.

model, like in online learning. This allows the number of queries needed (and thus cost and latency)
to decrease over time without compromising accuracy.

3

Model

We model on-the-job learning as a stochastic game with two players: the system and the crowd.
The game starts with the system receiving input x and ends when the system turns in a set of labels
y = (y1 , . . . , yn ). During the system?s turn, the system may choose a query action q ? {1, . . . , n}
to ask the crowd to label yq . The system may also choose the wait action (q = ?W ) to wait for the
crowd to respond to a pending query or the return action (q = ?R ) to terminate the game and return
its prediction given responses received thus far. The system can make as many queries in a row (i.e.
simultaneously) as it wants, before deciding to wait or turn in.1 When the wait action is chosen,
the turn switches to the crowd, which provides a response r to one pending query, and advances
the game clock by the time taken for the crowd to respond. The turn then immediately reverts back
to the system. When the game ends (the system chooses the return action), the system evaluates a
utility that depends on the accuracy of its prediction, the number of queries issued and the total time
taken. The system should choose query and wait actions to maximize the utility of the prediction
eventually returned.
In the rest of this section, we describe the details of the game tree, our choice of utility and specify
models for crowd responses, followed by a brief exploration of behavior admitted by our model.
Game tree. Let us now formalize the game tree in terms of its states, actions, transitions and
rewards; see Figure 2b for an example. The game state ? = (tnow , q, s, r, t) consists of the current
time tnow , the actions q = (q1 , . . . , qk?1 ) that have been issued at times s = (s1 , . . . , sk?1 ) and the
responses r = (r1 , . . . , rk?1 ) that have been received at times t = (t1 , . . . , tk?1 ). Let rj = ? and
tj = ? iff qj is not a query action or its responses have not been received by time tnow .
During the system?s turn, when the system chooses an action qk , the state is updated to ? 0 =
(tnow , q0 , s0 , r0 , t0 ), where q0 = (q1 , . . . , qk ), s0 = (s1 , . . . , sk?1 , tnow ), r0 = (r1 , . . . , rk?1 , ?) and
t0 = (t1 , . . . , tk?1 , ?). If qk ? {1, . . . n}, then the system chooses another action from the new state
? 0 . If qk = ?W , the crowd makes a stochastic move from ? 0 . Finally, if qk = ?R , the game ends,
1
This rules out the possibility of launching a query midway through waiting for the next response. However,
we feel like this is a reasonable limitation that significantly simplifies the search space.

3

and the system returns its best estimate of the labels using the responses it has received and obtains
a utility U (?) (defined later).
Let F = {1 ? j ? k ? 1 | qj 6= ?W ? rj = ?} be the set of in-flight requests. During the crowd?s
turn (i.e. after the system chooses ?W ), the next response from the crowd, j ? ? F , is chosen: j ? =
arg minj?F t0j where t0j is sampled from the response-time model, t0j ? pT (t0j | sj , t0j > tnow ), for
each j ? F . Finally, a response is sampled using a response model, rj0 ? ? p(rj0 ? | x, r), and the state
is updated to ? 0 = (tj ? , q, s, r0 , t0 ), where r0 = (r1 , . . . , rj0 ? , . . . , rk ) and t0 = (t1 , . . . , t0j ? , . . . , tk ).
Utility. Under Bayesian decision theory, the optimal choice for an action in state ? =
(tnow , q, r, s, t) is the one that attains the maximum expected utility (i.e. value) for the game starting
at ?. Recall that the system can return at any time, at which point it receives a utility that trades
off two things: The first is the accuracy of the MAP estimate according to the model?s best guess
of y incorporating all responses received by time ? . The second is the cost of making queries: a
(monetary) cost wM per query made and penalty of wT per unit of time taken. Formally, we define
the utility to be:
U (?) , ExpAcc(p(y | x, q, s, r, t)) ? (nQ wM + tnow wT ),
0

ExpAcc(p) = Ep(y) [Accuracy(arg max
p(y ))],
0
y

(1)
(2)

where nQ = |{j | qj ? {1, . . . , n}| is the number of queries made, p(y | x, q, s, r, t) is a prediction
model that incorporates the crowd?s responses.
The utility of wait and return actions is computed by taking expectations over subsequent trajectories
in the game tree. This is intractable to compute exactly, so we propose an approximate algorithm in
Section 4.
Environment model. The final component is a model of the environment (crowd). Given input
x and queries q = (q1 , . . . , qk ) issued at times s = (s1 , . . . , sk ), we define a distribution over the
output y, responses r = (r1 , . . . , rk ) and response times t = (t1 , . . . , tk ) as follows:
p(y, r, t | x, q, s) , p? (y | x)

k
Y

pR (ri | yqi )pT (ti | si ).

(3)

i=1

The three components are as follows: p? (y | x) is the prediction model (e.g. a standard linear-chain
CRF); pR (r | yq ) is the response model which describes the distribution of the crowd?s response
r for a given a query q when the true answer is yq ; and pT (ti | si ) specifies the latency of query
qi . The CRF model p? (y | x) is learned based on all actual responses (not simulated ones) using
AdaGrad. To model annotation errors, we set pR (r | yq ) = 0.7 iff r = yq ,2 and distribute the
remaining probability for r uniformly. Given this full model, we can compute p(r0 | x, r, q) simply
by marginalizing out y and t from Equation 3. When conditioning on r, we ignore responses that
have not yet been received (i.e. when rj = ? for some j).
Behavior. Let?s look at typical behavior that we expect the model and utility to capture. Figure 2a
shows how the marginals over the labels change as the crowd provides responses for our running
example, i.e. named entity recognition for the sentence ?Soup on George str.?. In the both timelines,
the system issues queries on ?Soup? and ?George? because it is not confident about its predictions
for these tokens. In the first timeline, the crowd correctly responds that ?Soup? is a resource and
that ?George? is a location. Integrating these responses, the system is also more confident about
its prediction on ?str.?, and turns in the correct sequence of labels. In the second timeline, a crowd
worker makes an error and labels ?George? to be a person. The system still has uncertainty on
?George? and issues an additional query which receives a correct response, following which the
system turns in the correct sequence of labels. While the answer is still correct, the system could
have taken less time to respond by making an additional query on ?George? at the very beginning.
2

We found the humans we hired were roughly 70% accurate in our experiments

4

4

Game playing

In Section 3 we modeled on-the-job learning as a stochastic game played between the system and
the crowd. We now turn to the problem of actually finding a policy that maximizes the expected
utility, which is, of course, intractable because of the large state space.
Our algorithm (Algorithm 1) combines ideas from Monte Carlo tree search [12] to systematically
explore the state space and progressive widening [13] to deal with the challenge of continuous variables (time). Some intuition about the algorithm is provided below. When simulating the system?s
turn, the next state (and hence action) is chosen using the upper confidence tree (UCT) decision
rule that trades off maximizing the value of the next state (exploitation) with the number of visits
(exploration). The crowd?s turn is simulated based on transitions defined in Section 3. To handle the
unbounded fanout during the crowd?s turn, we use progressive widening that maintains a current set
of ?active? or ?explored? states, which is gradually grown with time. Let N (?) be the number of
times a state has been visited, and C(?) be all successor states that the algorithm has sampled.
Algorithm 1 Approximating expected utility with MCTS and progressive widening
1: For all ?, N (?) ? 0, V (?) ? 0, C(?) ? [ ]
2: function MONTE C ARLOVALUE(state ?)
3:
increment N (?)
4:
if system?s turn then n
q
o
V (? 0 )
log N (?)
5:
? 0 ? arg max?0 N
+
c
0
0
(? )
N (? )

. Initialize visits, utility sum, and children

. Choose next state ? 0 using UCT

6:
v ?MONTE C ARLOVALUE(? 0 )
7:
V (?) ? V (?) + v
. Record observed utility
8:
return v
9:
else if crowd?spturn then
. Restrict continuous samples using PW
10:
if max(1, N (?)) ? |C(?)| then
11:
? 0 is sampled from set of already visited C(?) based on (3)
12:
else
13:
? 0 is drawn based on (3)
14:
C(?) ? C(?) ? {[? 0 ]}
15:
end if
16:
return MONTE C ARLOVALUE(? 0 )
17:
else if game terminated then
18:
return utility U of ? according to (1)
19:
end if
20: end function

5

Experiments

In this section, we empirically evaluate our approach on three tasks. While the on-the-job setting we
propose is targeted at scenarios where there is no data to begin with, we use existing labeled datasets
(Table 1) to have a gold standard.
Baselines. We evaluated the following four methods on each dataset:
1. Human n-query: The majority vote of n human crowd workers was used as a prediction.
2. Online learning: Uses a classifier that trains on the gold output for all examples seen so
far and then returns the MLE as a prediction. This is the best possible offline system: it
sees perfect information about all the data seen so far, but can not query the crowd while
making a prediction.
3. Threshold baseline: Uses the following heuristic: For each label, yi , we ask for m queries
such that (1?p? (yi | x))?0.3m ? 0.98. Instead of computing the expected marginals over
the responses to queries in flight, we simply count the in-flight requests for a given variable,
and reduces the uncertainty on that variable by a factor of 0.3. The system continues
launching requests until the threshold (adjusted by number of queries in flight) is crossed.
5

Dataset (Examples)
NER (657)

Task and notes
We evaluate on the CoNLL-2003
NER task3 , a sequence labeling
problem over English sentences.
We only consider the four tags corresponding to persons, locations,
organizations or none4 .

Sentiment (1800)

We evaluate on a subset of the
IMDB sentiment dataset [15] that
consists of 2000 polar movie reviews; the goal is binary classification of documents into classes POS
and NEG.
We evaluate on a celebrity face
classification task [17]. Each image must be labeled as one of the
following four choices: Andersen
Cooper, Daniel Craig, Scarlet Johansson or Miley Cyrus.

Face (1784)

Features
We used standard features [14]: the
current word, current lemma, previous and next lemmas, lemmas in
a window of size three to the left
and right, word shape and word
prefix and suffixes, as well as word
embeddings.
We used two feature sets, the
first (UNIGRAMS) containing only
word unigrams, and the second
(RNN) that also contains sentence
vector embeddings from [16].
We used the last layer of a 11layer AlexNet [2] trained on ImageNet as input feature embeddings,
though we leave back-propagating
into the net to future work.

Table 1: Datasets used in this paper and number of examples we evaluate on.
System
1-vote
3-vote
5-vote
Online
Threshold
LENSE

Delay/tok
467 ms
750 ms
1350 ms
n/a
414 ms
267 ms

Named Entity Recognition
Qs/tok PER F1 LOC F1
1.0
90.2
78.8
3.0
93.6
85.1
5.0
95.5
87.7
n/a
56.9
74.6
0.61
95.2
89.8
0.45
95.2
89.7

ORG F1
71.5
74.5
78.7
51.4
79.8
81.7

F1
80.2
85.4
87.3
60.9
88.3
88.8

Face Identification
Latency Qs/ex Acc.
1216 ms
1.0 93.6
1782 ms
3.0 99.1
2103 ms
5.0 99.8
n/a
n/a 79.9
1680 ms
2.66 93.5
1590 ms
2.37 99.2

Table 2: Results on NER and Face tasks comparing latencies, queries per token (Qs/tok) and performance metrics (F1 for NER and accuracy for Face).
Predictions are made using MLE on the model given responses. The baseline does not
reason about time and makes all its queries at the very beginning.
4. LENSE: Our full system as described in Section 3.
Implementation and crowdsourcing setup. We implemented the retainer model of [18] on Amazon Mechanical Turk to create a ?pool? of crowd workers that could respond to queries in real-time.
The workers were given a short tutorial on each task before joining the pool to minimize systematic
errors caused by misunderstanding the task. We paid workers $1.00 to join the retainer pool and
an additional $0.01 per query (for NER, since response times were much faster, we paid $0.005
per query). Worker response times were generally in the range of 0.5?2 seconds for NER, 10?15
seconds for Sentiment, and 1?4 seconds for Faces.
When running experiments, we found that the results varied based on the current worker quality. To
control for variance in worker quality across our evaluations of the different methods, we collected
5 worker responses and their delays on each label ahead of time5 . During simulation we sample the
worker responses and delays without replacement from this frozen pool of worker responses.
Summary of results. Table 2 and Table 3 summarize the performance of the methods on the three
tasks. On all three datasets, we found that on-the-job learning outperforms machine and human-only
3

http://www.cnts.ua.ac.be/conll2003/ner/
The original also includes a fifth tag for miscellaneous, however the definition for miscellaneos is complex,
making it very difficult for non-expert crowd workers to provide accurate labels.
5
These datasets are available in the code repository for this paper
4

6

3.9

System
1-vote
3-vote
5-vote

Unigrams
Unigrams + RNN embeddings

3.8

Queries per example

3.7

Qs/ex
1.00
3.00
5.00

Acc.
89.2
95.8
98.7

n/a
10.9 s
11.7 s

n/a
2.99
3.48

78.1
95.9
98.6

n/a
11.0 s
11.0 s

n/a
2.85
3.19

85.0
96.0
98.6

UNIGRAMS

3.6

Online
Threshold
LENSE

3.5
3.4

RNN

3.3
3.2

Latency
6.6 s
10.9 s
13.5 s

0

20

40

60

80

100

120

140

160

180

Online
Threshold
LENSE

200

Time

Figure 3: Queries per example for LENSE on
Sentiment. With simple UNIGRAM features, the
model quickly learns it does not have the capacity to answer confidently and must query the
crowd. With more complex RNN features, the
model learns to be more confident and queries
the crowd less over time.

Table 3: Results on the Sentiment task comparing latency, queries per example and accuracy.

1

0.8

1.2

Queries per token

0.7
0.6
F1

LENSE
1 vote baseline

1.4

0.9

0.5
0.4
0.3

1
0.8
0.6
0.4

0.2
0.1
0

0.2

LENSE
online learning
0

100

200

300

400

500

600

0

700

Time

0

100

200

300

400

500

600

700

Time

Figure 4: Comparing F1 and queries per token on the NER task over time. The left graph compares
LENSE to online learning (which cannot query humans at test time). This highlights that LENSE
maintains high F1 scores even with very small training set sizes, by falling back the crowd when it
is unsure. The right graph compares query rate over time to 1-vote. This clearly shows that as the
model learns, it needs to query the crowd less.
comparisons on both quality and cost. On NER, we achieve an F1 of 88.4% at more than an order of
magnitude reduction on the cost of achieving comporable quality result using the 5-vote approach.
On Sentiment and Faces, we reduce costs for a comparable accuracy by a factor of around 2. For the
latter two tasks, both on-the-job learning methods perform less well than in NER. We suspect this
is due to the presence of a dominant class (?none?) in NER that the model can very quickly learn to
expend almost no effort on. LENSE outperforms the threshold baseline, supporting the importance
of Bayesian decision theory.
Figure 4 tracks the performance and cost of LENSE over time on the NER task. LENSE is not only
able to consistently outperform other baselines, but the cost of the system steadily reduces over time.
On the NER task, we find that LENSE is able to trade off time to produce more accurate results than
the 1-vote baseline with fewer queries by waiting for responses before making another query.
While on-the-job learning allows us to deploy quickly and ensure good results, we would like to
eventually operate without crowd supervision. Figure 3, we show the number of queries per example
on Sentiment with two different features sets, UNIGRAMS and RNN (as described in Table 1). With
simpler features (UNIGRAMS), the model saturates early and we will continue to need to query to
the crowd to achieve our accuracy target (as specified by the loss function). On the other hand,
using richer features (RNN) the model is able to learn from the crowd and the amount of supervision
needed reduces over time. Note that even when the model capacity is limited, LENSE is able to
guarantee a consistent, high level of performance.
7

Reproducibility. All code, data, and experiments for this paper are available on CodaLab at
https://www.codalab.org/worksheets/0x2ae89944846444539c2d08a0b7ff3f6f/.

6

Related Work

On-the-job learning draws ideas from many areas: online learning, active learning, active classification, crowdsourcing, and structured prediction.
Online learning. The fundamental premise of online learning is that algorithms should improve
with time, and there is a rich body of work in this area [7]. In our setting, algorithms not only
improve over time, but maintain high accuracy from the beginning, whereas regret bounds only
achieve this asymptotically.
Active learning. Active learning (see [19] for a survey) algorithms strategically select most informative examples to build a classifier. Online active learning [8, 9, 10] performs active learning
in the online setting. Several authors have also considered using crowd workers as a noisy oracle
e.g. [20, 21]. It differs from our setup in that it assumes that labels can only be observed after
classification, which makes it nearly impossible to maintain high accuracy in the beginning.
Active classification. Active classification [22, 23, 24] asks what are the most informative features
to measure at test time. Existing active classification algorithms rely on having a fully labeled
dataset which is used to learn a static policy for when certain features should be queried, which does
not change at test time. On-the-job learning differs from active classification in two respects: true
labels are never observed, and our system improves itself at test time by learning a stronger model.
A notable exception is Legion:AR [6], which like us operates in on-the-job learning setting to for
real-time activity classification. However, they do not explore the machine learning foundations
associated with operating in this setting, which is the aim of this paper.
Crowdsourcing. A burgenoning subset of the crowdsourcing community overlaps with machine
learning. One example is Flock [25], which first crowdsources the identification of features for an
image classification task, and then asks the crowd to annotate these features so it can learn a decision
tree. In another line of work, TurKontrol [26] models individual crowd worker reliability to optimize
the number of human votes needed to achieve confident consensus using a POMDP.
Structured prediction. An important aspect our prediction tasks is that the output is structured,
which leads to a much richer setting for one-the-job learning. Since tags are correlated, the importance of a coherent framework for optimizing querying resources is increased. Making active partial
observations on structures and has been explored in the measurements framework of [27] and in the
distant supervision setting [28].

7

Conclusion

We have introduced a new framework that learns from (noisy) crowds on-the-job to maintain high
accuracy, and reducing cost significantly over time. The technical core of our approach is modeling
the on-the-job setting as a stochastic game and using ideas from game playing to approximate the
optimal policy. We have built a system, LENSE, which obtains significant cost reductions over a
pure crowd approach and significant accuracy improvements over a pure ML approach.
Acknowledgments
We are grateful to Kelvin Guu and Volodymyr Kuleshov for useful feedback regarding the calibration of our models and Amy Bearman for providing the image embeddings for the face classification
experiments. We would also like to thank our anonymous reviewers for their helpful feedback. Finally, our work was sponsored by a Sloan Fellowship to the third author.

References
[1] J. Deng, W. Dong, R. Socher, L. Li, K. Li, and L. Fei-Fei. ImageNet: A large-scale hierarchical image
database. In Computer Vision and Pattern Recognition (CVPR), pages 248?255, 2009.
[2] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet classification with deep convolutional neural
networks. In Advances in Neural Information Processing Systems (NIPS), pages 1097?1105, 2012.

8

[3] M. S. Bernstein, G. Little, R. C. Miller, B. Hartmann, M. S. Ackerman, D. R. Karger, D. Crowell, and
K. Panovich. Soylent: a word processor with a crowd inside. In Symposium on User Interface Software
and Technology, pages 313?322, 2010.
[4] N. Kokkalis, T. K?ohn, C. Pfeiffer, D. Chornyi, M. S. Bernstein, and S. R. Klemmer. Emailvalet: Managing email overload through private, accountable crowdsourcing. In Conference on Computer Supported
Cooperative Work, pages 1291?1300, 2013.
[5] C. Li, J. Weng, Q. He, Y. Yao, A. Datta, A. Sun, and B. Lee. Twiner: named entity recognition in targeted
twitter stream. In ACM Special Interest Group on Information Retreival (SIGIR), pages 721?730, 2012.
[6] Walter S Lasecki, Young Chol Song, Henry Kautz, and Jeffrey P Bigham. Real-time crowd labeling for
deployable activity recognition. In Proceedings of the 2013 conference on Computer supported cooperative work, 2013.
[7] N. Cesa-Bianchi and G. Lugosi. Prediction, learning, and games. Cambridge University Press, 2006.
[8] D. Helmbold and S. Panizza. Some label efficient learning results. In Conference on Learning Theory
(COLT), pages 218?230, 1997.
[9] D. Sculley. Online active learning methods for fast label-efficient spam filtering. In Conference on Email
and Anti-spam (CEAS), 2007.
[10] W. Chu, M. Zinkevich, L. Li, A. Thomas, and B. Tseng. Unbiased online active learning in data streams.
In International Conference on Knowledge Discovery and Data Mining (KDD), pages 195?203, 2011.
[11] T. Gao and D. Koller. Active classification based on value of classifier. In Advances in Neural Information
Processing Systems (NIPS), pages 1062?1070, 2011.
[12] L. Kocsis and C. Szepesv?ari. Bandit based Monte-Carlo planning. In European Conference on Machine
Learning (ECML), pages 282?293, 2006.
[13] R. Coulom. Computing elo ratings of move patterns in the game of go. Computer Games Workshop,
2007.
[14] J. R. Finkel, T. Grenager, and C. Manning. Incorporating non-local information into information extraction systems by Gibbs sampling. In Association for Computational Linguistics (ACL), pages 363?370,
2005.
[15] Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts.
Learning word vectors for sentiment analysis. In ACL: HLT, pages 142?150, Portland, Oregon, USA,
June 2011. Association for Computational Linguistics.
[16] R. Socher, A. Perelygin, J. Y. Wu, J. Chuang, C. D. Manning, A. Y. Ng, and C. Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In Empirical Methods in Natural Language
Processing (EMNLP), 2013.
[17] N. Kumar, A. C. Berg, P. N. Belhumeur, and S. K. Nayar. Attribute and Simile Classifiers for Face
Verification. In ICCV, Oct 2009.
[18] M. S. Bernstein, J. Brandt, R. C. Miller, and D. R. Karger. Crowds in two seconds: Enabling realtime
crowd-powered interfaces. In User Interface Software and Technology, pages 33?42, 2011.
[19] B. Settles. Active learning literature survey. Technical report, University of Wisconsin, Madison, 2010.
[20] P. Donmez and J. G. Carbonell. Proactive learning: cost-sensitive active learning with multiple imperfect
oracles. In Conference on Information and Knowledge Management (CIKM), pages 619?628, 2008.
[21] D. Golovin, A. Krause, and D. Ray. Near-optimal Bayesian active learning with noisy observations. In
Advances in Neural Information Processing Systems (NIPS), pages 766?774, 2010.
[22] R. Greiner, A. J. Grove, and D. Roth. Learning cost-sensitive active classifiers. Artificial Intelligence,
139(2):137?174, 2002.
[23] X. Chai, L. Deng, Q. Yang, and C. X. Ling. Test-cost sensitive naive Bayes classification. In International
Conference on Data Mining, pages 51?58, 2004.
[24] S. Esmeir and S. Markovitch. Anytime induction of cost-sensitive trees. In Advances in Neural Information Processing Systems (NIPS), pages 425?432, 2007.
[25] J. Cheng and M. S. Bernstein. Flock: Hybrid Crowd-Machine learning classifiers. In Proceedings of the
18th ACM Conference on Computer Supported Cooperative Work & Social Computing, pages 600?611,
2015.
[26] P. Dai, Mausam, and D. S. Weld. Decision-theoretic control of crowd-sourced workflows. In Association
for the Advancement of Artificial Intelligence (AAAI), 2010.
[27] P. Liang, M. I. Jordan, and D. Klein. Learning from measurements in exponential families. In International Conference on Machine Learning (ICML), 2009.
[28] G. Angeli, J. Tibshirani, J. Y. Wu, and C. D. Manning. Combining distant and partial supervision for
relation extraction. In Empirical Methods in Natural Language Processing (EMNLP), 2014.

9


----------------------------------------------------------------

title: 6139-supervised-word-movers-distance.pdf

Supervised Word Mover?s Distance

Gao Huang? , Chuan Guo?
Cornell University
{gh349,cg563}@cornell.edu
Yu Sun, Kilian Q. Weinberger
Cornell University
{ys646,kqw4}@cornell.edu

Matt J. Kusner?
Alan Turing Institute, University of Warwick
mkusner@turing.ac.uk
Fei Sha
University of California, Los Angeles
feisha@cs.ucla.edu

Abstract
Recently, a new document metric called the word mover?s distance (WMD) has
been proposed with unprecedented results on kNN-based document classification.
The WMD elevates high-quality word embeddings to a document metric by formulating the distance between two documents as an optimal transport problem
between the embedded words. However, the document distances are entirely unsupervised and lack a mechanism to incorporate supervision when available. In
this paper we propose an efficient technique to learn a supervised metric, which
we call the Supervised-WMD (S-WMD) metric. The supervised training minimizes the stochastic leave-one-out nearest neighbor classification error on a perdocument level by updating an affine transformation of the underlying word embedding space and a word-imporance weight vector. As the gradient of the original WMD distance would result in an inefficient nested optimization problem, we
provide an arbitrarily close approximation that results in a practical and efficient
update rule. We evaluate S-WMD on eight real-world text classification tasks on
which it consistently outperforms almost all of our 26 competitive baselines.

1

Introduction

Document distances are a key component of many text retrieval tasks such as web-search ranking
[24], book recommendation [16], and news categorization [25]. Because of the variety of potential applications, there has been a wealth of work towards developing accurate document distances
[2, 4, 11, 27]. In large part, prior work focused on extracting meaningful document representations,
starting with the classical bag of words (BOW) and term frequency-inverse document frequency
(TF-IDF) representations [30]. These sparse, high-dimensional representations are frequently nearly
orthogonal [17] and a pair of similar documents may therefore have nearly the same distance as a
pair that are very different. It is possible to design more meaningful representations through eigendecomposing the BOW space with Latent Semantic Indexing (LSI) [11], or learning a probabilistic
clustering of BOW vectors with Latent Dirichlet Allocation (LDA) [2]. Other work generalizes LDA
[27] or uses denoising autoencoders [4] to learn a suitable document representation.
Recently, Kusner et al. [19] proposed the Word Mover?s Distance (WMD), a new distance for text
documents that leverages word embeddings [22]. Given these high-quality embeddings, the WMD
defines the distances between two documents as the optimal transport cost of moving all words from
one document to another within the word embedding space. This approach was shown to lead to
state-of-the-art error rates in k-nearest neighbor (kNN) document classification.
?
?

Authors contributing equally
This work was done while the author was a student at Washington University in St. Louis

30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.

Importantly, these prior works are entirely unsupervised and not learned explicitly for any particular
task. For example, text documents could be classified by topic or by author, which would lead to
very different measures of dissimilarity. Lately, there has been a vast amount of work on metric
learning [10, 15, 36, 37], most of which focuses on learning a generalized linear Euclidean metric.
These methods often scale quadratically with the input dimensionality, and can only be applied to
high-dimensional text documents after dimensionality reduction techniques such as PCA [36].
In this paper we propose an algorithm for learning a metric to improve the Word Mover?s Distance.
WMD stands out from prior work in that it computes distances between documents without ever
learning a new document representation. Instead, it leverages low-dimensional word representations,
for example word2vec, to compute distances. This allows us to transform the word embedding
instead of the documents, and remain in a low-dimensional space throughout. At the same time we
propose to learn word-specific ?importance? weights, to emphasize the usefulness of certain words
for distinguishing the document class.
At first glance, incorporating supervision into the WMD appears computationally prohibitive, as
each individual WMD computation scales cubically with respect to the (sparse) dimensionality of
the documents. However, we devise an efficient technique that exploits a relaxed version of the
underlying optimal transport problem, called the Sinkhorn distance [6]. This, combined with a
probabilistic filtering of the training set, reduces the computation time significantly.
Our metric learning algorithm, Supervised Word Mover?s Distance (S-WMD), directly minimizes a
stochastic version of the leave-one-out classification error under the WMD metric. Different from
classic metric learning, we learn a linear transformation of the word representations while also learning re-weighted word frequencies. These transformations are learned to make the WMD distances
match the semantic meaning of similarity encoded in the labels. We show across 8 datasets and 26
baseline methods the superiority of our method.

2

Background

Here we describe the word embedding technique we use (word2vec) and the recently introduced
Word Mover?s Distance. We then detail the setting of linear metric learning and the solution proposed by Neighborhood Components Analysis (NCA) [15], which inspires our method.
word2vec may be the most popular technique for learning a word embedding over billions of words
and was introduced by Mikolov et al. [22]. Each word in the training corpus is associated with
an initial word vector, which is then optimized so that if two words w1 and w2 frequently occur
together, they have high conditional probability p(w2 |w1 ). This probability is the hierarchical softmax of the word vectors vw1 and vw2 [22], an easily-computed quantity which allows a simplified
neural language model (the word2vec model) to be trained efficiently on desktop computers. Training an embedding over billions of words allows word2vec to capture surprisingly accurate word
relationships [23]. Word embeddings can learn hundreds of millions of parameters and are typically
by design unsupervised, allowing them to be trained on large unlabeled text corpora ahead of time.
Throughout this paper we use word2vec, although many word embeddings could be used [5, 21? ].
Word Mover?s Distance. Leveraging the compelling word vector relationships of word embeddings, Kusner et al. [19] introduced the Word Mover?s Distance (WMD) as a distance between text
documents. At a high level, the WMD is the minimum distance required to transport the words
from one document to another. We assume that we are given a word embedding matrix X ? Rd?n
for a vocabulary of n words. Let xi ? Rd be the representation of the ith word, as defined by this
embedding. Additionally, let da , db be the n-dimensional normalized bag-of-words (BOW) vectors
for two documents, where dai is the number of times word i occurs in da (normalized over all words
in da ). The WMD introduces an auxiliary ?transport? matrix T ? Rn?n , such that Tij describes
how much of dai should be transported to dbj . Formally, the WMD learns T to minimize
n
n
n
X
X
X
D(xi , xj ) = min
Tij kxi ? xj kp2 , subject to,
Tij = dai ,
Tij = dbj ?i, j, (1)
T?0

j=1

i,j=1

i=1

where p is usually set to 1 or 2. In this way, documents that share many words (or even related ones)
should have smaller distances than documents with very dissimilar words. It was noted in Kusner
et al. [19] that the WMD is a special case of the Earth Mover?s Distance (EMD) [29], also known
more generally as the Wasserstein distance [20]. The authors also introduce the word centroid distance (WCD), which uses a fast approximation first described by Rubner et al. [29]: kXd ? Xd0 k2 .
2

It can be shown that the WCD always lower bounds the WMD. Intuitively the WCD represents each
document by the weighted average word vector, where the weights are the normalized BOW counts.
The time complexity of solving the WMD optimization problem is O(q 3 log q) [26], where q is the
maximum number of unique words in either d or d0 . The WCD scales asymptotically by O(dq).
Regularized Transport Problem. To alleviate the cubic time complexity of the Wasserstein distance computation, Cuturi [6] formulated a smoothed version of the underlying transport problem by
adding an entropy regularizer to the transport objective. This makes the objective function strictly
convex, and efficient
Pn algorithms can be adopted to solve it. In particular, given a transport matrix
T, let h(T) = ? i,j=1 Tij log(Tij ) be the entropy of T. For any ? > 0, the regularized (primal)
transport problem is defined as
n
n
n
X
X
X
1
min
Tij kxi ? xj kp2 ? h(T) subject to,
Tij = dai ,
Tij = dbj ?i, j.
(2)
T?0
?
i,j=1
j=1
i=1
The larger ? is, the closer this relaxation is to the original Wasserstein distance. Cuturi [6] propose
an efficient algorithm to solve for the optimal transport T?? using a clever matrix-scaling algorithm.
Specifically, we may define the matrix Kij = exp(??kxi ? xj k2 ) and solve for the scaling vectors
u, v to a fixed-point by computing u = da ./(Kv), v = db ./(K> u) in an alternating fashion.
These yield the relaxed transport T?? = diag(u)K diag(v). This algorithm can be shown to have
empirical time complexity O(q 2 ) [6], which is significantly faster than solving the WMD problem
exactly.
Linear Metric Learning. Assume that we have access to a training set {x1 , . . . , xn } ? Rd , arranged as columns in matrix X ? Rd?n , and corresponding labels {y1 , . . . , yn } ? Y n , where Y
contains some finite number of classes C = |Y|. Linear metric learning learns a matrix A ? Rr?d ,
where r ? d, and defines the generalized Euclidean distance between two documents xi and xj as
dA (xi , xj ) = kA(xi ?xj )k2 . Popular linear metric learning algorithms are NCA [15], LMNN [36],
and ITML [10] amongst others [37]. These methods learn a matrix A to minimize a loss function
that is often an approximation of the leave-one-out (LOO) classification error of the kNN classifier.
Neighborhood Components Analysis (NCA) was introduced by Goldberger et al. [15] to learn
a generalized Euclidean metric. Here, the authors approximate the non-continuous leave-one-out
kNN error by defining a stochastic neighborhood process. An input xi is assigned input xj as its
nearest neighbor with probability
exp(?d2A (xi , xj ))
,
(3)
pij = P
2
k6=i exp (?dA (xi , xk ))
where we define pii = 0. Under this stochastic neighborhood assignment, an input xi with label
yi is classified correctly if its nearest neighbor isP
any xj 6= xi from the same class (yj = yi ). The
probability of this event can be stated as pi =
learns A by maximizing the
j:yj =yi pij . NCA
P
P
expected LOO accuracy i pi , or equivalently by minimizing ? i log(pi ), the KL-divergence
from a perfect classification distribution (pi = 1 for all xi ).

3

Learning a Word Embedding Metric

In this section we propose a method for learning a supervised document distance, by way of learning a generalized Euclidean metric within the word embedding space and a word importance vector. We will refer to the learned document distance as the Supervised Word Mover?s Distance (SWMD). To learn such a metric we assume we have a training dataset consisting of m documents
{d1 , . . . , dm } ? ?n , where ?n is the (n?1)-dimensional simplex (thus each document is represented as a normalized histogram over the words in the vocabulary, of size n). For each document
we are given a label out of C possible classes, i.e. {y1 , . . . , ym } ? {1, . . . , C}m . Additionally,
we are given a word embedding matrix X ? Rd?n (e.g., the word2vec embedding) which defines a
d-dimensional word vector for each of the words in the vocabulary.
Supervised WMD. As described in the previous section, it is possible to define a distance between
any two documents da and db as the minimum cumulative word distance of moving da to db in
word embedding space, as is done in the WMD. Given a labeled training set we would like to
improve the distance so that documents that share the same labels are close, and those with different
labels are far apart. We capture this notion of similarity in two ways: First we transform the word
embedding, which captures a latent representation of words. We adapt this representation with a
3

linear transformation xi ? Axi , where xi represents the embedding of the ith word. Second, as
different classification tasks and data sets may value words differently, we also introduce a histogram
importance vector w that re-weighs the word histogram values to reflect the importance of words
for distinguishing the classes:
? a = (w ? da )/(w> da ),
d
(4)
where ??? denotes the element-wise Hadamard product. After applying the vector w and the linear
mapping A, the WMD distance between documents da and db becomes
DA,w (da , db ) , min
T?0

n
X

Tij kA(xi ? xj )k22 s.t.

i,j=1

n
X
j=1

Tij = d?ai and

n
X

Tij = d?bj ?i, j. (5)

i=1

Loss Function. Our goal is to learn the matrix A and vector w to make the distance DA,w reflect
the semantic definition of similarity encoded in the labeled data. Similar to prior work on metric
learning [10, 15, 36] we achieve this by minimizing the kNN-LOO error with the distance DA,w
in the document space. As the LOO error is non-differentiable, we use the stochastic neighborhood
relaxation proposed by Hinton & Roweis [18], which is also used for NCA. Similar to prior work
we use the squared Euclidean word distance in Eq. (5). We use the KL-divergence loss proposed in
NCA alongside the definition of neighborhood probability in (3) which yields,
?
?
m
m
X
X
exp(?D
(d
,
d
))
A,w
a
b
?.
P
(6)
`(A, w) = ?
log ?
c6=a exp (?DA,w (da , dc ))
a=1
b:yb =ya

Gradient. We can compute the gradient of the loss `(A, w) with respect to A and w as follows,
m X
X
?
pab
?
`(A, w) =
DA,w (da , db ),
(?ab ? pa )
?(A, w)
p
?(A,
w)
a
a=1

(7)

b6=a

where ?ab = 1 if and only if ya = yb , and ?ab = 0 otherwise.
3.1

Fast computation of ?DA,w (da , db )/?(A, w)

Notice that the remaining gradient term above ?DA,w (da , db )/?(A, w) contains the nested linear
program defined in (5). In fact, computing this gradient just for a single pair of documents will
require time complexity O(q 3 log q), where q is the largest set of unique words in either document
[8]. This quickly becomes prohibitively slow as the document size becomes large and the number
of documents increase. Further, the gradient is not always guaranteed to exist [1, 7] (instead we
must resort to subgradient descent). Motivated by the recent works on fast Wasserstein distance
computation [6, 8, 12], we propose to relax the modified linear program in eq. (5) using the entropy
as in eq. (2). As described in Section 2, this allows us to approximately solve eq. (5) in O(q 2 ) time
via T?? = diag(u)K diag(v). We will use this approximate solution in the following gradients.
Gradient w.r.t. A. It can be shown that,
n
X
?
>
DA,w (da , db ) = 2A
Tab
ij (xi ? xj )(xi ? xj ) ,
?A
i,j=1

(8)

where Tab is the optimizer of (5), so long as it is unique (otherwise it is a subgradient) [1]. We
replace Tab by T?? which is always unique as the relaxed transport is strongly convex [9].
Gradient w.r.t. w. To obtain the gradient with respect to w, we need the optimal solution to the
dual transport problem:
?
? a + ?> d
? b ; s.t. ?i + ?j ? kA(xi ? xj )k2 ?i, j.
DA,w
(da , db ) , max ?> d
2
(?,?)

(9)

? a and d
? b are functions of w, we have
Given that both d
?
?
? a ?DA,w
? b ?? ?da ?(?? > d
? a)da ? ? ?db ?(? ? > d
? b)db
?DA,w
?
?d
?d
DA,w (da , db ) =
+
=
+
.
>
a
>
b
? a ?w
? b ?w
?w
w d
w d
?d
?d
(10)

4

Instead of solving the dual directly, we obtain the relaxed optimal dual variables ??? , ? ?? via the
vectors u, v that were used to derive our relaxed transport T?? . Specifically, we can solve for the
>

>

1
1
? log(u)
1 and ? ?? = log(v)
? log(v)
1, where 1 is the
dual variables as such: ??? = log(u)
?
p
?
p
p-dimensional all ones vector. In general, we can observe from eq. (2) that the above approximation
process becomes more accurate as ? grows. However, setting ? too large can make the algorithm
converges slower. In our experiments, we use ? = 10, which leads to a nice trade-off between speed
and approximation accuracy.

3.2

Optimization

Alongside the fast gradient computation process in- Algorithm 1 S-WMD
troduced above, we can further speed up the training with a clever initialization and batch gradient de- 1: Input: word1 embedding: X,
2: dataset: {(d , y1 ), . . . , (dm , ym )}
scent.
3: ca = Xda , ?a ? {1, . . . , m}
Initialization. The loss function in eq. (6) is non4: A = NCA((c1 , y1 ), . . . , (cm , ym ))
convex and is thus highly dependent on the initial 5: w = 1
setting of A and w. A good initialization also dras- 6: while loop until convergence do
tically reduces the number of gradient steps required. 7:
Randomly select B ? {1, . . . , m}
For w, we initialize all its entries to 1, i.e., all words 8:
Compute gradients using eq. (11)
are assigned with the same weights at the begin- 9:
A ? A ? ?A gA
ning. For A, we propose to learn an initial projection 10:
w ? w ? ?w gw
within the word centroid distance (WCD), defined 11: end while
as D0 (da , db ) = kXda ? Xdb k2 , described in Section 2. The WCD should be a reasonable approximation to the WMD. Kusner et al. [19] point out
that the WCD is a lower bound on the WMD, which holds true after the transformation with A.
We obtain our initialization by applying NCA in word embedding space using the WCD distance
between documents. This is to say that we can construct the WCD dataset: {c1 , . . . , cm } ? Rd ,
representing each text document as its word centroid, and apply NCA in the usual way as described
in Section 2. We call this learned word distance Supervised Word Centroid Distance (S-WCD).
Batch Gradient Descent. Once the initial matrix A is obtained, we minimize the loss `(A, w) in
(6) with batch gradient descent. At each iteration, instead of optimizing over the full training set,
we randomly pick a batch of documents B from the training set, and compute the gradient for these
documents. We can further speed up training by observing that the vast majority of NCA probabilities pab near zero. This is because most documents are far away from any given document. Thus,
for a document da we can use the WCD to get a cheap neighbor ordering and only compute the
NCA probabilities for the closest set of documents Na , based on the WCD. When we compute the
gradient for each of the selected documents, we only use the document?s M nearest neighbor documents (defined by WCD distance) to compute the NCA neighborhood probabilities. In particular,
the gradient is computed as follows,
X X
?
gA,w =
(pab /pa )(?ab ? pa )
D(A,w) (da , db ),
(11)
?(A, w)
a?B b?Na

where again Na is the set of nearest neighbors of document a. With the gradient, we update A and
w with learning rates ?A and ?w , respectively. Algorithm 1 summarizes S-WMD in pseudo code.
Complexity. The empirical time complexity of solving the dual transport problem scales quadratically with p [26]. Therefore, the complexity of our algorithm is O(T BN [p2 + d2 (p + r)]), where
T denotes the number of batch gradient descent iterations, B = |B| the batch size, N = |Na | the
size of the nearest neighbor set, and p the maximum number of unique words in a document. This
is because computing T?ij , ?? and ? ? using the alternating fixed point algorithm in Section 3.1
requires O(p2 ) time, while constructing the gradients from eqs. (8) and (10) takes O(d2 (p + r))
time. The approximated gradient eq. (11) requires this computation to be repeated BN times. In
our experiments, we set B = 32 and N = 200, and computing the gradient at each iteration can be
done in seconds.

4

Results

We evaluate S-WMD on 8 different document corpora and compare the kNN error with unsupervised
WCD, WMD, and 6 document representations. In addition, all 6 document representation baselines
5

Table 1: The document datasets (and their descriptions) used for visualization and evaluation.
name
BBCSPORT
TWITTER
RECIPE
OHSUMED
CLASSIC
REUTERS
AMAZON
20 NEWS

twitter

recipe

ohsumed

C
5
3
15
10
4
8
4
20

classic

n
517
2176
3059
3999
4965
5485
5600
11293

ne
220
932
1311
5153
2128
2189
2400
7528

reuters

BOW
dim.
13243
6344
5708
31789
24277
22425
42063
29671

avg
words
117
9.9
48.5
59.2
38.6
37.1
45.0
72

amazon

20news

S-WMD

WMD

bbcsport

description
BBC sports articles labeled by sport
tweets categorized by sentiment [31]
recipe procedures labeled by origin
medical abstracts (class subsampled)
academic papers labeled by publisher
news dataset (train/test split [3])
reviews labeled by product
canonical news article dataset [3]

Figure 1: t-SNE plots of WMD and S-WMD on all datasets.
are used with and without 3 leading supervised metric learning algorithms?resulting in an overall
total of 26 competitive baselines. Our code is implemented in Matlab and is freely available at
https://github.com/gaohuang/S-WMD.
Datasets and Baselines. We evaluate all approaches on 8 document datasets in the settings of
news categorization, sentiment analysis, and product identification, among others. Table 1 describes
the classification tasks as well as the size and number of classes C of each of the datasets. We
evaluate against the following document representation/distance methods: 1. bag-of-words (BOW):
a count of the number of word occurrences in a document, the length of the vector is the number
of unique words in the corpus; 2. term frequency-inverse document frequency (TF-IDF): the BOW
vector normalized by the document frequency of each word across the corpus; 3. Okapi BM25 [28]:
a TF-IDF-like ranking function, first used in search engines; 4. Latent Semantic Indexing (LSI)
[11]: projects the BOW vectors onto an orthogonal basis via singular value decomposition; 5. Latent Dirichlet Allocation (LDA) [2]: a generative probabilistic method that models documents as
mixtures of word ?topics?. We train LDA transductively (i.e., on the combined collection of training
& testing words) and use the topic probabilities as the document representation ; 6. Marginalized
Stacked Denoising Autoencoders (mSDA) [4]: a fast method for training stacked denoising autoencoders, which have state-of-the-art error rates on sentiment analysis tasks [14]. For datasets larger
than RECIPE we use either a high-dimensional variant of mSDA or take 20% of the features that
occur most often, whichever has better performance.; 7. Word Centroid Distance (WCD), described
in Section 2; 8. Word Mover?s Distance (WMD), described in Section 2. For completeness, we
also show results for the Supervised Word Centroid Distance (S-WCD) and the initialization of SWMD (S-WMD init.), described in Section 3. For methods that propose a document representation
(as opposed to a distance), we use the Euclidean distance between these vector representations for
visualization and kNN classification. For the supervised metric learning results we first reduce the
dimensionality of each representation to 200 dimensions (if necessary) with PCA and then run either NCA, ITML, or LMNN on the projected data. We tune all free hyperparameters in all compared
methods with Bayesian optimization (BO), using the implementation of Gardner et al. [13]3 .
kNN classification. We show the kNN test error of all document representation and distance methods in Table 2. For datasets that do not have a predefined train/test split: BBCSPORT, TWITTER,
RECIPE , CLASSIC , and AMAZON we average results over five 70/30 train/test splits and report standard errors. For each dataset we highlight the best results in bold (and those whose standard error
3

http://tinyurl.com/bayesopt

6

Table 2: The kNN test error for all datasets and distances.
DATASET

BBCSPORT

TWITTER

BOW
TF-IDF
O KAPI BM25 [28]
LSI [11]
LDA [2]
M SDA [4]

20.6 ? 1.2
21.5 ? 2.8
16.9 ? 1.5
4.3 ? 0.6
6.4 ? 0.7
8.4 ? 0.8

43.6 ? 0.4
33.2 ? 0.9
42.7 ? 7.8
31.7 ? 0.7
33.8 ? 0.3
32.3 ? 0.7

BOW
TF-IDF
O KAPI BM25 [28]
LSI [11]
LDA [2]
M SDA [4]

7.4 ? 1.4
1.8 ? 0.2
3.7 ? 0.5
5.0 ? 0.7
6.5 ? 0.7
25.5 ? 9.4

32.0 ? 0.4
31.1 ? 0.3
31.9 ? 0.3
32.3 ? 0.4
33.9 ? 0.9
43.7 ? 7.4

BOW
TF-IDF
O KAPI BM25 [28]
LSI [11]
LDA [2]
M SDA [4]

2.4 ? 0.4
4.0 ? 0.6
1.9 ? 0.7
2.4 ? 0.5
4.5 ? 0.4
22.7 ? 10.0

31.8 ? 0.3
30.8 ? 0.3
30.5 ? 0.4
31.6 ? 0.2
31.9 ? 0.6
50.3 ? 8.6

BOW
TF-IDF
O KAPI BM25 [28]
LSI [11]
LDA [2]
M SDA [4]

9.6 ? 0.6
0.6 ? 0.3
4.5 ? 0.5
2.4 ? 0.7
7.1 ? 0.9
21.8 ? 7.4

31.1 ? 0.5
30.6 ? 0.5
31.8 ? 0.4
31.1 ? 0.8
32.7 ? 0.3
37.9 ? 2.8

WCD [19]
WMD [19]
S-WCD
S-WMD INIT.
S-WMD

11.3 ? 1.1
4.6 ? 0.7
4.6 ? 0.5
2.8 ? 0.3
2.1 ? 0.5

30.7 ? 0.9
28.7 ? 0.6
30.4 ? 0.5
28.2 ? 0.4
27.5 ? 0.5

RECIPE

OHSUMED

CLASSIC

REUTERS

U NSUPERVISED
61.1
36.0 ? 0.5
13.9
62.7
35.0 ? 1.8
29.1
66.2
40.6 ? 2.7
32.8
44.2
6.7 ? 0.4
6.3
51.0
5.0 ? 0.3
6.9
49.3
6.9 ? 0.4
8.1
ITML [10]
63.1 ? 0.9
70.1
7.5 ? 0.5
7.3
51.0 ? 1.4
55.1
9.9 ? 1.0
6.6
53.8 ? 1.8
77.0
18.3 ? 4.5
20.7
55.7 ? 0.8
54.7
5.5 ? 0.7
6.9
59.3 ? 0.8
59.6
6.6 ? 0.5
9.2
54.5 ? 1.3
61.8
14.9 ? 2.2
5.9
LMNN [36]
48.4 ? 0.4
49.1
4.7 ? 0.3
3.9
43.7 ? 0.3
40.0
4.9 ? 0.3
5.8
41.7 ? 0.7
59.4
19.0 ? 9.3
9.2
44.8 ? 0.4
40.8
3.0 ? 0.1
3.2
51.4 ? 0.4
49.9
4.9 ? 0.4
5.6
46.3 ? 1.2
41.6
11.1 ? 1.9
5.3
NCA [15]
55.2 ? 0.6
57.4
4.0 ? 0.1
6.2
41.4 ? 0.4
35.8
5.5 ? 0.2
3.8
45.8 ? 0.5
56.6
20.6 ? 4.8
10.5
41.6 ? 0.5
37.5
3.1 ? 0.2
3.3
50.9 ? 0.4
50.7
5.0 ? 0.2
7.9
48.0 ? 1.6
40.4
11.2 ? 1.8
5.2
D ISTANCES IN THE W ORD M OVER ? S FAMILY
49.4 ? 0.3
48.9
6.6 ? 0.2
4.7
42.6 ? 0.3
44.5
2.8 ? 0.1
3.5
51.3 ? 0.2
43.3
5.8 ? 0.2
3.9
39.8 ? 0.4
38.0
3.3 ? 0.3
3.5
39.2 ? 0.3
34.3
3.2 ? 0.2
3.2
59.3 ? 1.0
53.4 ? 1.0
53.4 ? 1.9
45.4 ? 0.5
51.3 ? 0.6
48.0 ? 1.4

AMAZON

20 NEWS

AVERAGE - RANK

28.5 ? 0.5
41.5 ? 1.2
58.8 ? 2.6
9.3 ? 0.4
11.8 ? 0.6
17.1 ? 0.4

57.8
54.4
55.9
28.9
31.5
39.5

26.1
25.0
26.1
12.0
16.6
18.0

20.5 ? 2.1
11.1 ? 1.9
11.4 ? 2.9
10.6 ? 2.2
15.7 ? 2.0
37.4 ? 4.0

60.6
45.3
81.5
39.6
87.8
47.7

23.0
14.8
21.5
17.6
22.5
23.9

10.7 ? 0.3
6.8 ? 0.3
6.9 ? 0.2
6.6 ? 0.2
12.1 ? 0.6
24.0 ? 3.6

40.7
28.1
57.4
25.1
32.0
27.1

11.5
7.8
14.4
5.1
14.6
17.3

16.8 ? 0.3
6.5 ? 0.2
8.5 ? 0.4
7.7 ? 0.4
11.6 ? 0.8
23.6 ? 3.1

46.4
29.3
55.9
30.7
30.9
26.8

17.5
5.4
17.9
6.3
16.5
16.1

9.2 ? 0.2
7.4 ? 0.3
7.6 ? 0.3
5.8 ? 0.2
5.8 ? 0.1

36.2
26.8
33.6
28.4
26.8

13.5
6.1
11.4
4.3
2.4

overlaps the mean of the best result). On the right we also show the average rank across datasets,
relative to unsupervised BOW (bold indicates the best method). We highlight the unsupervised
WMD in blue (WMD) and our new result in red (S-WMD). Despite the very large number of competitive baselines, S-WMD achieves the lowest kNN test error on 5/8 datasets, with the exception
of BBCSPORT, CLASSIC and AMAZON. On these datasets it achieves the 4th lowest on BBCSPORT
and CLASSIC, and tied at 2nd on 20 NEWS. On average across all datasets it outperforms all other
26 methods. Another observation is that S-WMD right after initialization (S-WMD init.) performs
quite well. However, as training S-WMD is efficient (shown in Table 3), it is often well worth the
training time.
For unsupervised baselines, on datasets BBCSPORT
and OHSUMED, where the previous state-of-the-art
MazdaTIFFBoone
fit motherboardhappening
WMD was beaten by LSI, S-WMD reduces the eraskedautomotivehomosexuals
playoff motorcycles
ror of LSI relatively by 51% and 22%, respectively.
gay
dolphins computer animation
western
atheism
moon
In general, supervision seems to help all methods
Keith
controller
tappedmotif graphics clippersecurity
on average. One reason why NCA with a TF-IDF
orbitIsrael pro
lists Rutgershell
document representation may be performing better
talkNHL driver
hockeybiblical
firedbikerguns
auto saint
than S-WMD could be because of the long docu- virtual
gunaltcircuit
autos
sell
cute
ment lengths in BBCSPORT and OHSUMED. Havlabelride
riderrocket
Islamic
offerflight
ing denser BOW vectors may improve the inverse riding
keyDOD
cardrivers
document frequency weights, which in turn may be IDEshipping
baseballcrypto
image
bikes
a good initialization for NCA to further fine-tune.
monitor
story
Armenian card
polygon
Israeli
forsalefirearmsspace
On datasets with smaller documents such as TWITwarning
Turkishcopyencryption RISC
bus mouse
TER , CLASSIC , and REUTERS, S-WMD outperforms
compatiblemotorcycle summarized
powerbookelectronics diamond
NCA with TF-IDF relatively by 10%, 42%, and
SCSI government chip
sun doctorNASA
15%, respectively. On CLASSIC WMD outperforms
DOS
S-WMD possibly because of a poor initialization
and that S-WMD uses the squared Euclidean dis- Figure 2: The Top-100 words upweighted by
tance between word vectors, which may be subop- S-WMD on 20 NEWS.
timal for this dataset. This however, does not occur
for any other dataset.

apple

bike

windows
sale
mac

Visualization. Figure 1 shows a 2D embedding of the test split of each dataset by WMD and
S-WMD using t-Stochastic Neighbor Embedding (t-SNE) [33]. The quality of a distance can be
visualized by how clustered points in the same class are. Using this metric, S-WMD noticeably
improves upon WMD on almost all the 8 datasets. Figure 2 visualizes the top 100 words with
7

1/1

largest weights learned by S-WMD on the 20 NEWS dataset. The size of each word is proportional
its learned weight. We can observe that these upweighted words are indeed most representative for
the true classes of this dataset. More detailed results and analysis can be found in the supplementary.
Training time. Table 3 shows the training
times for S-WMD. Note that the time to learn
the initial metric A is not included in time
shown in the second column. Relative to the
initialization, S-WMD is surprisingly fast. This
is due to the fast gradient approximation and
the batch gradient descent introduced in Section 3.1 and 3.2. We note that these times are
comparable or even faster than the time it takes
to train a linear metric on the baseline methods
after PCA.

5

Table 3: Distance computation times.
F ULL T RAINING T IMES
DATASET
BBCSPORT
TWITTER
RECIPE
OHSUMED
CLASSIC
REUTERS
AMAZON
20 NEWS

Related Work

METRICS
S - WCD / S - WMD INIT.
1M 25S
28M 59S
23M 21S
46M 18S
1H 18M
2H 7M
2H 15M
14M 42S

S - WMD
4M 56S
7M 53S
23M 58S
29M 12S
36M 22S
34M 56S
20M 10S
1H 55M

Metric learning is a vast field that includes both
supervised and unsupervised techniques (see
Yang & Jin [37] for a large survey). Alongside NCA [15], described in Section 2, there are a number of popular methods for generalized Euclidean metric learning. Large Margin Nearest Neighbors
(LMNN) [36] learns a metric that encourages inputs with similar labels to be close in a local region,
while encouraging inputs with different labels to be farther by a large margin. Information-Theoretic
Metric Learning (ITML) [10] learns a metric by minimizing a KL-divergence subject to generalized
Euclidean distance constraints. Cuturi & Avis [7] was the first to consider learning the ground distance in the Earth Mover?s Distance (EMD). In a similar work, Wang & Guibas [34] learns a ground
distance that is not a metric, with good performance in certain vision tasks. Most similar to our
work Wang et al. [35] learn a metric within a generalized Euclidean EMD ground distance using
the framework of ITML for image classification. They do not, however, consider re-weighting the
histograms, which allows our method extra flexibility. Until recently, there has been relatively little
work towards learning supervised word embeddings, as state-of-the-art results rely on making use
of large unlabeled text corpora. Tang et al. [32] propose a neural language model that uses label
information from emoticons to learn sentiment-specific word embeddings.

6

Conclusion

We proposed a powerful method to learn a supervised word mover?s distance, and demonstrated
that it may well be the best performing distance metric for documents to date. Similar to WMD,
our S-WMD benefits from the large unsupervised corpus, which was used to learn the word2vec
embedding [22, 23]. The word embedding gives rise to a very good document distance, which
is particularly forgiving when two documents use syntactically different but conceptually similar
words. Two words may be similar in one sense but dissimilar in another, depending on the articles in
which they are contained. It is these differences that S-WMD manages to capture through supervised
training. By learning a linear metric and histogram re-weighting through the optimal transport of
the word mover?s distance, we are able to produce state-of-the-art classification results efficiently.
Acknowledgments
The authors are supported in part by the, III-1618134, III-1526012, IIS-1149882 grants from the
National Science Foundation and the Bill and Melinda Gates Foundation. We also thank Dor Kedem
for many insightful discussions.

References
[1] Bertsimas, D. and Tsitsiklis, J. N. Introduction to linear optimization. Athena Scientific, 1997.
[2] Blei, D. M., Ng, A. Y., and Jordan, M. I. Latent dirichlet allocation. JMLR, 2003.
[3] Cardoso-Cachopo, A. Improving Methods for Single-label Text Categorization. PdD Thesis, Instituto
Superior Tecnico, Universidade Tecnica de Lisboa, 2007.
[4] Chen, M., Xu, Z., Weinberger, K. Q., and Sha, F. Marginalized denoising autoencoders for domain
adaptation. In ICML, 2012.
[5] Collobert, R. and Weston, J. A unified architecture for natural language processing: Deep neural networks
with multitask learning. In ICML, pp. 160?167. ACM, 2008.

8

[6] Cuturi, M. Sinkhorn distances: Lightspeed computation of optimal transport. In Advances in Neural
Information Processing Systems, pp. 2292?2300, 2013.
[7] Cuturi, M. and Avis, D. Ground metric learning. JMLR, 2014.
[8] Cuturi, M. and Doucet, A. Fast computation of wasserstein barycenters. In Jebara, Tony and Xing, Eric P.
(eds.), ICML, pp. 685?693. JMLR Workshop and Conference Proceedings, 2014.
[9] Cuturi, M. and Peyre, G. A smoothed dual approach for variational wasserstein problems. SIAM Journal
on Imaging Sciences, 9(1):320?343, 2016.
[10] Davis, J.V., Kulis, B., Jain, P., Sra, S., and Dhillon, I.S. Information-theoretic metric learning. In ICML,
pp. 209?216, 2007.
[11] Deerwester, S. C., Dumais, S. T., Landauer, T. K., Furnas, G. W., and Harshman, R. A. Indexing by latent
semantic analysis. Journal of the American Society of Information Science, 41(6):391?407, 1990.
[12] Frogner, C., Zhang, C., Mobahi, H., Araya, M., and Poggio, T.A. Learning with a wasserstein loss. In
Advances in Neural Information Processing Systems, pp. 2044?2052, 2015.
[13] Gardner, J., Kusner, M. J., Xu, E., Weinberger, K. Q., and Cunningham, J. Bayesian optimization with
inequality constraints. In ICML, pp. 937?945, 2014.
[14] Glorot, X., Bordes, A., and Bengio, Y. Domain adaptation for large-scale sentiment classification: A deep
learning approach. In ICML, pp. 513?520, 2011.
[15] Goldberger, J., Hinton, G.E., Roweis, S.T., and Salakhutdinov, R. Neighbourhood components analysis.
In NIPS, pp. 513?520. 2005.
[16] Gopalan, P. K., Charlin, L., and Blei, D. Content-based recommendations with poisson factorization. In
NIPS, pp. 3176?3184, 2014.
[17] Greene, D. and Cunningham, P. Practical solutions to the problem of diagonal dominance in kernel
document clustering. In ICML, pp. 377?384. ACM, 2006.
[18] Hinton, G.E. and Roweis, S.T. Stochastic neighbor embedding. In NIPS, pp. 833?840. MIT Press, 2002.
[19] Kusner, M. J., Sun, Y., Kolkin, N. I., and Weinberger, K. Q. From word embeddings to document distances. In ICML, 2015.
[20] Levina, E. and Bickel, P. The earth mover?s distance is the mallows distance: Some insights from statistics.
In ICCV, volume 2, pp. 251?256. IEEE, 2001.
[21] Levy, O. and Goldberg, Y. Neural word embedding as implicit matrix factorization. In NIPS, 2014.
[22] Mikolov, T., Chen, K., Corrado, G., and Dean, J. Efficient estimation of word representations in vector
space. In Workshop at ICLR, 2013.
[23] Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., and Dean, J. Distributed representations of words
and phrases and their compositionality. In NIPS, pp. 3111?3119, 2013.
[24] Mohan, A., Chen, Z., and Weinberger, K. Q. Web-search ranking with initialized gradient boosted regression trees. JMLR, 14:77?89, 2011.
[25] Ontrup, J. and Ritter, H. Hyperbolic self-organizing maps for semantic navigation. In NIPS, 2001.
[26] Pele, O. and Werman, M. Fast and robust earth mover?s distances. In ICCV, pp. 460?467. IEEE, 2009.
[27] Perina, A., Jojic, N., Bicego, M., and Truski, A. Documents as multiple overlapping windows into grids
of counts. In NIPS, pp. 10?18. 2013.
[28] Robertson, S. E., Walker, S., Jones, S., Hancock-Beaulieu, M. M., Gatford, M., et al. Okapi at trec-3.
NIST SPECIAL PUBLICATION SP, pp. 109?109, 1995.
[29] Rubner, Y., Tomasi, C., and Guibas, L. J. A metric for distributions with applications to image databases.
In ICCV, pp. 59?66. IEEE, 1998.
[30] Salton, G. and Buckley, C. Term-weighting approaches in automatic text retrieval. Information processing
& management, 24(5):513?523, 1988.
[31] Sanders, N. J. Sanders-twitter sentiment corpus, 2011.
[32] Tang, D., Wei, F., Yang, N., Zhou, M., Liu, T., and Qin, B. Learning sentiment-specific word embedding
for twitter sentiment classification. In ACL, pp. 1555?1565, 2014.
[33] Van der Maaten, L. and Hinton, G. Visualizing data using t-sne. JMLR, 9(2579-2605):85, 2008.
[34] Wang, F. and Guibas, L. J. Supervised earth movers distance learning and its computer vision applications.
In ECCV. 2012.
[35] Wang, X-L., Liu, Y., and Zha, H. Learning robust cross-bin similarities for the bag-of-features model.
Technical report, Peking University, China, 2009.
[36] Weinberger, K.Q. and Saul, L.K. Distance metric learning for large margin nearest neighbor classification.
JMLR, 10:207?244, 2009.
[37] Yang, L. and Jin, R. Distance metric learning: A comprehensive survey. 2, 2006.

9


----------------------------------------------------------------

title: 5754-coevolve-a-joint-point-process-model-for-information-diffusion-and-network-co-evolution.pdf

COEVOLVE: A Joint Point Process Model for
Information Diffusion and Network Co-evolution
Mehrdad Farajtabar?
Yichen Wang?
Manuel Gomez-Rodriguez?
?
?
Shuang Li
Hongyuan Zha
Le Song?
?
Georgia Institute of Technology
MPI for Software Systems?
{mehrdad,yichen.wang,sli370}@gatech.edu
manuelgr@mpi-sws.org
{zha,lsong}@cc.gatech.edu

Abstract
Information diffusion in online social networks is affected by the underlying network topology, but it also has the power to change it. Online users are constantly
creating new links when exposed to new information sources, and in turn these
links are alternating the way information spreads. However, these two highly intertwined stochastic processes, information diffusion and network evolution, have
been predominantly studied separately, ignoring their co-evolutionary dynamics.
We propose a temporal point process model, COEVOLVE, for such joint dynamics, allowing the intensity of one process to be modulated by that of the other.
This model allows us to efficiently simulate interleaved diffusion and network
events, and generate traces obeying common diffusion and network patterns observed in real-world networks. Furthermore, we also develop a convex optimization framework to learn the parameters of the model from historical diffusion and
network evolution traces. We experimented with both synthetic data and data gathered from Twitter, and show that our model provides a good fit to the data as
well as more accurate predictions than alternatives.

1

Introduction

Online social networks, such as Twitter or Weibo, have become large information networks where
people share, discuss and search for information of personal interest as well as breaking news [1].
In this context, users often forward to their followers information they are exposed to via their
followees, triggering the emergence of information cascades that travel through the network [2],
and constantly create new links to information sources, triggering changes in the network itself
over time. Importantly, recent empirical studies with Twitter data have shown that both information
diffusion and network evolution are coupled and network changes are often triggered by information
diffusion [3, 4, 5].
While there have been many recent works on modeling information diffusion [2, 6, 7, 8] and network
evolution [9, 10, 11], most of them treat these two stochastic processes independently and separately,
ignoring the influence one may have on the other over time. Thus, to better understand information
diffusion and network evolution, there is an urgent need for joint probabilistic models of the two
processes, which are largely inexistent to date.
In this paper, we propose a probabilistic generative model, COEVOLVE, for the joint dynamics of
information diffusion and network evolution. Our model is based on the framework of temporal
point processes, which explicitly characterize the continuous time interval between events, and it
consists of two interwoven and interdependent components (refer to Appendix B for an illustration):
I. Information diffusion process. We design an ?identity revealing? multivariate Hawkes process [12] to capture the mutual excitation behavior of retweeting events, where the intensity of
such events in a user is boosted by previous events from her time-varying set of followees. Al1

though Hawkes processes have been used for information diffusion before [13, 14, 15, 16, 17, 18,
19], the key innovation of our approach is to explicitly model the excitation due to a particular
source node, hence revealing the identity of the source. Such design reflects the reality that information sources are explicitly acknowledged, and it also allows a particular information source to
acquire new links in a rate according to her ?informativeness?.
II. Network evolution process. We model link creation as an ?information driven? survival process,
and couple the intensity of this process with retweeting events. Although survival processes have
been used for link creation before [20, 21], the key innovation in our model is to incorporate retweeting events as the driving force for such processes. Since our model has captured the source
identity of each retweeting event, new links will be targeted toward the information sources, with
an intensity proportional to their degree of excitation and each source?s influence.
Our model is designed in such a way that it allows the two processes, information diffusion and
network evolution, unfold simultaneously in the same time scale and excise bidirectional influence
on each other, allowing sophisticated coevolutionary dynamics to be generated (e.g., see Figure 5).
Importantly, the flexibility of our model does not prevent us from efficiently simulating diffusion
and link events from the model and learning its parameters from real world data:
? Efficient simulation. We design a scalable sampling procedure that exploits the sparsity of the
generated networks. Its complexity is O(nd log m), where n is the number of samples, m is the
number of nodes and d is the maximum number of followees per user.
? Convex parameters learning. We show that the model parameters that maximize the joint likelihood of observed diffusion and link creation events can be found via convex optimization.
Finally, we experimentally verify that our model can produce coevolutionary dynamics of information diffusion and network evolution, and generate retweet and link events that obey common
information diffusion patterns (e.g., cascade structure, size and depth), static network patterns (e.g.,
node degree) and temporal network patterns (e.g., shrinking diameter) described in related literature [22, 10, 23]. Furthermore, we show that, by modeling the coevolutionary dynamics, our model
provide significantly more accurate link and diffusion event predictions than alternatives in large
scale Twitter dataset [3].

2

Backgrounds on Temporal Point Processes

A temporal point process is a random process whose realization consists of a list of discrete events
localized in time, {ti } with ti ? R+ and i ? Z+ . Many different types of data produced in online
social networks can be represented as temporal point processes, such as the times of retweets and
link creations. A temporal point process can be equivalently represented as a counting process, N (t),
which records the number of events before time t. Let the history H(t) be the list of times of events
{t1 , t2 , . . . , tn } up to but not including time t. Then, the number of observed events in a small time
"t
!
window dt between [t, t+dt) is dN (t) = ti ?H(t) ?(t?ti ) dt, and hence N (t) = 0 dN (s), where
?(t) is a Dirac delta function. More generally, given a function f (t), we can define the convolution
with respect to dN (t) as
# t
$
f (t) ? dN (t) :=
f (t ? ? ) dN (? ) =
f (t ? ti ).
(1)
ti ?H(t)

0

The point process representation of temporal data is fundamentally different from the discrete time
representation typically used in social network analysis. It directly models the time interval between
events as random variables, and avoid the need to pick a time window to aggregate events. It allows
temporal events to be modeled in a more fine grained fashion, and has a remarkably rich theoretical
support [24].

An important way to characterize temporal point processes is via the conditional intensity function
? a stochastic model for the time of the next event given all the times of previous events. Formally, the conditional intensity function ?? (t) (intensity, for short) is the conditional probability of
observing an event in a small window [t, t + dt) given the history H(t), i.e.,
?? (t)dt := P {event in [t, t + dt)|H(t)} = E[dN (t)|H(t)],
(2)
where one typically assumes that only one event can happen in a small window of size dt,
i.e., dN (t) ? {0, 1}. Then, given a time t? ! t, we can also characterize the conditional probability that no event happens during [t, t? ) and the conditional density that an event occurs at time t?
2

" t?
as S ? (t? ) = exp(? t ?? (? ) d? ) and f ? (t? ) = ?? (t? ) S ? (t? ) respectively [24]. Furthermore, we can
express the log-likelihood of a list of events {t1 , t2 , . . . , tn } in an observation window [0, T ) as
# T
n
$
?
L=
log ? (ti ) ?
?? (? ) d?, T ! tn .
(3)
i=1

0

This simple log-likelihood will later enable us to learn the parameters of our model from observed
data.
Finally, the functional form of the intensity ?? (t) is often designed to capture the phenomena of
interests. Some useful functional forms we will use later are [24]:
(i) Poisson process. The intensity is assumed to be independent of the history H(t), but it can be
a time-varying function, i.e., ?? (t) = g(t) ! 0;
(ii) Hawkes Process. The intensity models a mutual excitation between events, i.e.,
$
?? (t) = ? + ??? (t) ? dN (t) = ? + ?
?? (t ? ti ),
(4)
ti ?H(t)

where ?? (t) := exp(??t)I[t ! 0] is an exponential triggering kernel, ? ! 0 is a baseline
intensity independent of the history. Here, the occurrence of each historical event increases the
intensity by a certain amount determined by the kernel and the weight ? ! 0, making the intensity
history dependent and a stochastic process by itself. We will focus on the exponential kernel in
this paper. However, other functional forms for the triggering kernel, such as log-logistic function,
are possible, and our model does not depend on this particular choice; and,
(iii) Survival process. There is only one event for an instantiation of the process, i.e.,
?? (t) = g ? (t)(1 ? N (t)),
where ?? (t) becomes 0 if an event already happened before t.

3

(5)

Generative Model of Information Diffusion and Network Co-evolution

In this section, we use the above background on temporal point processes to formulate our probabilistic generative model for the joint dynamics of information diffusion and network evolution.
3.1

Event Representation

We model the generation of two types of events: tweet/retweet events, er , and link creation events,
el . Instead of just the time t, we record each event as a triplet
source
?

er or el := ( u, s, t ).
?

destination

?

(6)

time

For retweet event, the triplet means that the destination node u retweets at time t a tweet originally
posted by source node s. Recording the source node s reflects the real world scenario that information sources are explicitly acknowledged. Note that the occurrence of event er does not mean
that u is directly retweeting from or is connected to s. This event can happen when u is retweeting
a message by another node u? where the original information source s is acknowledged. Node u
will pass on the same source acknowledgement to its followers (e.g., ?I agree @a @b @c @s?).
Original tweets posted by node u are allowed in this notation. In this case, the event will simply be
r
er = (u, u, t). Given a list of retweet events up to but not including time t, the history Hus
(t) of
r
r
retweets by u due to source s is Hus (t) = {ei = (ui , si , ti )|ui = u and si = s} . The entire history
r
of retweet events is denoted as Hr (t) := ?u,s?[m] Hus
(t).
For link creation event, the triplet means that destination node u creates at time t a link to source
node s, i.e., from time t on, node u starts following node s. To ease the exposition, we restrict
ourselves to the case where links cannot be deleted and thus each (directed) link is created only
once. However, our model can be easily augmented to consider multiple link creations and deletions
per node pair, as discussed in Section 8. We denote the link creation history as Hl (t).
3.2

Joint Model with Two Interwoven Components

Given m users, we use two sets of counting processes to record the generated events, one for information diffusion and the other for network evolution. More specifically,
3

I. Retweet events are recorded using a matrix N (t) of size m ? m for each fixed time point t. The
(u, s)-th entry in the matrix, Nus (t) ? {0} ? Z+ , counts the number of retweets of u due to
source s up to time t. These counting processes are ?identity revealing?, since they keep track of
the source node that triggers each retweet. This matrix N (t) can be dense, since Nus (t) can be
nonzero even when node u does not directly follow s. We also let dN (t) := ( dNus (t) )u,s?[m] .
II. Link events are recorded using an adjacency matrix A(t) of size m ? m for each fixed time point
t. The (u, s)-th entry in the matrix, Aus (t) ? {0, 1}, indicates whether u is directly following s.
That is Aus (t) = 1 means the directed link has been created before t. For simplicity of exposition,
we do not allow self-links. The matrix A(t) is typically sparse, but the number of nonzero entries
can change over time. We also define dA(t) := ( dAus (t) )u,s?[m] .
Then the interwoven information diffusion and network evolution processes can be characterized
using their respective intensities E[dN (t) | Hr (t) ? Hl (t)] = ?? (t) dt and E[dA(t) | Hr (t) ?
?
Hl (t)] = ?? (t) dt, where ?? (t) = ( ?us
(t) )u,s?[m] and ?? (t) = ( ??us (t) )u,s?[m] . The sign
?
means that the intensity matrices will depend on the joint history, Hr (t) ? Hl (t), and hence their
evolution will be coupled. By this coupling, we make: (i) the counting processes for link creation to
be ?information driven? and (ii) the evolution of the linking structure to change the information diffusion process. Refer to Appendix B for an illustration of our joint model. In the next two sections,
we will specify the details of these two intensity matrices.
3.3

Information Diffusion Process

We model the intensity, ?? (t), for retweeting events using multivariate Hawkes process [12]:
$
?
?us
(t) = I[u = s] ?u + I[u ?= s] ?s
??1 (t) ? (Auv (t) dNvs (t)) ,
v?Fu (t)

(7)

where I[?] is the indicator function and Fu (t) := {v ? [m] : Auv (t) = 1} is the current set of followees of u. The term ?u ! 0 is the intensity of original
tweets by a user u on his own initiative,
!
becoming the source of a cascade and the term ?s v?Fu (t) ?? (t) ? (Auv (t) dNvs (t)) models the
propagation of peer influence over the network, where the triggering kernel ??1 (t) models the decay
of peer influence over time.
Note that the retweet intensity matrix ?? (t) is by itself a stochastic process that depends on the timevarying network topology, the non-zero entries in A(t), whose growth is controlled by the network
evolution process in Section 3.4. Hence the model design captures the influence of the network
topology and each source?s influence, ?s , on the information diffusion process. More specifically,
?
to compute ?us
(t), one first finds the current set Fu (t) of followees of u, and then aggregates
the retweets of these followees that are due to source s. Note that these followees may or may
not directly follow source s. Then, the more frequently node u is exposed to retweets of tweets
originated from source s via her followees, the more likely she will also retweet a tweet originated
from source s. Once node u retweets due to source s, the corresponding Nus (t) will be incremented,
and this in turn will increase the likelihood of triggering retweets due to source s among the followers
of u. Thus, the source does not simply broadcast the message to nodes directly following her but
her influence propagates through the network even to those nodes that do not directly follow her.
Finally, this information diffusion model allows a node to repeatedly generate events in a cascade,
and is very different from the independent cascade or linear threshold models [25] which allow at
most one event per node per cascade.
3.4

Network Evolution Process

We model the intensity, ?? (t), for link creation using a combination of survival and Hawkes process:
??us (t) = (1 ? Aus (t))(?u + ?u ??2 (t) ? dNus (t))
(8)

where the term 1 ? Aus (t) effectively ensures a link is created only once, and after that, the corresponding intensity is set to zero. The term ?u ! 0 denotes a baseline intensity, which models when a
node u decides to follow a source s spontaneously at her own initiative. The term ?u ??2 (t)?dNus (t)
corresponds to the retweets of node u due to tweets originally published by source s, where the triggering kernel ??2 (t) models the decay of interests over time. Here, the higher the corresponding
retweet intensity, the more likely u will find information by source s useful and will create a direct
link to s.
4

The link creation intensity ?? (t) is also a stochastic process by itself, which depends on the retweet
events, and is driven by the retweet count increments dNus (t). It captures the influence of retweets
on the link creation, and closes the loop of mutual influence between information diffusion and
network topology.
Note that creating a link is more than just adding a path or allowing information sources to take
shortcuts during diffusion. The network evolution makes fundamental changes to the diffusion
dynamics and stationary distribution of the diffusion process in Section 3.3. As shown in [14],
given a fixed network structure A, the expected retweet intensity ?s (t) at time t due to source
s will depend of the network structure in a highly nonlinear fashion, i.e., ?s (t) := E[???s (t)] =
(e(A??1 I)t + ?1 (A ? ?1 I)?1 (e(A??1 I)t ? I)) ?s , where ?s ? Rm has a single nonzero entry
with value ?s and e(A??1 I)t is the matrix exponential. When t ? ?, the stationary intensity
? s = (I ? A/?)?1 ?s is also nonlinearly related to the network structure. Thus given two network
?
structures A(t) and A(t? ) at two points in time, which are different by a few edges, the effect of
these edges on the information diffusion is not just simply an additive relation. Depending on how
these newly created edges modify the eigen-structure of the sparse matrix A(t), their effect can be
drastic to the information diffusion.
Remark 1. In our model, each user is exposed to information through a time-varying set of neighbors. By doing so, we couple information diffusion with the network evolution, increasing the
practical application of our model to real-network datasets. The particular definition of exposure
(e.g., a retweet?s neighbor) will depend on the type of historical information that is available. Remarkably, the flexibility of our model allows for different types of diffusion events, which we can
broadly classify into two categories. In a first category, events corresponds to the times when an
information cascade hits a person, for example, through a retweet from one of her neighbors, but
she does not explicitly like or forward the associated post. In a second category, the person decides
to explicitly like or forward the associated post and events corresponds to the times when she does
so. Intuitively, events in the latter category are more prone to trigger new connections but are also
less frequent. Therefore, it is mostly suitable to large event dataset for examples those ones generated synthetically. In contrast, the events in the former category are less likely to inspire new links
but found in abundance. Therefore, it is very suitable for real-world sparse data. Consequently, in
synthetic experiments we used the latter and in the real one we used the former. It?s noteworthy that
Eq. (8) is written based on the latter category, but, Fig. 7 in appendix is drawn based on the former.

4

Efficient Simulation of Coevolutionary Dynamics

We can simulate samples (link creations, tweets and retweets) from our model by adapting Ogata?s
thinning algorithm [26], originally designed for multidimensional Hawkes processes. However, a
naive implementation of Ogata?s algorithm would scale poorly, i.e., for each sample, we would
need to re-evaluate ?? (t) and ?? (t), thus, to draw n samples, we would need to perform O(m2 n2 )
operations, where m is the number of nodes.
We designed a sampling procedure that is especially well-fitted for the structure of our model. The
algorithm is based on the following key idea: if we consider each intensity function in ?? (t) and
?? (t) as a separate Hawkes process and draw a sample from each, it is easy to show that the minimum among all these samples is a valid sample from the model [12]. However, by drawing samples
from all intensities, the computational complexity would not improve. However, when the network
is sparse, whenever we sample a new node (or link) event from the model, only a small number
of intensity functions, in the local neighborhood of the node (or the link), will change. As a consequence, we can reuse most of the samples from the intensity functions for the next new sample
and find which intensity functions we need to change in O(log m) operations, using a heap. Finally, we exploit the properties of the exponential function to update individual intensities for each
new sample in O(1): let ti and ti+1 be two consecutive events, then, we can compute ?? (ti+1 ) as
(?? (ti ) ? ?) exp(??(ti+1 ? ti )) + ? without the need to compare all previous events.

The complete simulation algorithm is summarized in Algorithm 2 in Appendix C. By using Algorithm 2, we reduce the complexity from O(n2 m2 ) to O(nd log m), where d is the maximum number
of followees per node. That means, our algorithm scales logarithmically with the number of nodes
and linearly with the number of edges at any point in time during the simulation. We also note that
the events for link creations, tweets and retweets are generated in a temporally intertwined and inter5

Retweet

Intensity

0

20
40
60
Event occurrence time

4

Link

Cross covariance

Link

Spike trains

Retweet

0.6

0
0

2

0

20
40
60
Event occurrence time

?50

0
Lag

50

(a)
(b)
(c)
Figure 1: Coevolutionary dynamics for synthetic data. a) Spike trains of link and retweet events. b)
Link and retweet intensities. c) Cross covariance of link and retweet intensities.
Data

Power?law fit

Poisson fit

4

Power?law fit

Poisson fit

Data

2

2

Data

2

0

Poisson fit

2

10

0

10 0
10

1

10

Power?law fit

4

10

10

10 0
10

1

10

Poisson fit

10

10

0

Power?law fit

4

10

10

10 0
10

Data
4

10

0

10 0
10

1

10

1

10

2

10

(a) ? = 0
(b) ? = 0.001
(c) ? = 0.1
(d) ? = 0.8
Figure 2: Degree distributions when network sparsity level reaches 0.001 for fixed ? = 0.1.
leaving fashion by Algorithm 2. This is because every new retweet event will modify the intensity
for link creation, and after each link creation we also need to update the retweet intensities.

5

Efficient Parameter Estimation from Coevolutionary Events

Given a collection of retweet events E = {eri } and link creation events A = {eli } recorded within
a time window [0, T ), we can easily estimate the parameters needed in our model using maximum
likelihood estimation. Here, we compute the joint log-likelihood L({?u } , {?u } , {?u } , {?s }) of
these events using Eq. (3), i.e.,
$
$ # T
$
$ # T
% ?
&
% ?
&
?
log ?ui si (ti ) ?
?us (? ) d? +
log ?ui si (ti ) ?
??us (? ) d? . (9)
eri ?E

'

u,s?[m]

()

tweet / retweet

0

*

eli ?A

'

u,s?[m]

0

()

links

*

For the terms corresponding to retweets, the log term only sums over the actual observed events,
but the integral term actually sums over all possible combination of destination and source pairs,
even if there is no event between a particular pair of destination and source. For such pairs with
no observed events, the corresponding counting processes have essentially survived the observation
"T ?
window [0, T ), and the term ? 0 ?us
(? )d? simply corresponds to the log survival probability.
Terms corresponding to links have a similar structure to those for retweet.
?
?
Since ?us
(t) and ??us are linear in the parameters (?u , ?s ) and (?u , ?u ) respectively, then log(?us
(t))
?
?
?
and log(?us ) are concave functions in these parameters. Integration of ?us (t) and ?us still results
in linear functions of the parameters. Thus the overall objective in Eq. (9) is concave, and the global
optimum can be found by many algorithms. In our experiments, we adapt the efficient algorithm
developed in previous work [18, 19]. Furthermore, the optimization problem decomposes in m
independent problems, one per node u, and can be readily parallelized.

6

Properties of Simulated Co-evolution, Networks and Cascades?

In this section, we perform an empirical investigation of the properties of the networks and information cascades generated by our model. In particular, we show that our model can generate coevolutionary retweet and link dynamics and a wide spectrum of static and temporal network patterns
and information cascades. Appendix D contains additional simulation results and visualizations.
Appendix E contains an evaluation of our model estimation method in synthetic data.
Retweet and link coevolution. Figures 1(a,b) visualize the retweet and link events, aggregated
across different sources, and the corresponding intensities for one node and one realization, picked
at random. Here, it is already apparent that retweets and link creations are clustered in time and often
follow each other. Further, Figure 1(c) shows the cross-covariance of the retweet and link creation
intensity, computed across multiple realizations, for the same node, i.e., if f (t)"and g(t) are two
intensities, the cross-covariance is a function of the time lag ? defined as h(? ) = f (t + ? )g(t) dt.
It can be seen that the cross-covariance has its peak around 0, i.e., retweets and link creations are
6

?=0

?=0.05

?=0.1

?=0.2

?=0

40

0

5
sparsity

?=0.001

?=0.1

?=0.8

80
diameter

diameter

80

40

0

10

5
sparsity

?4

x 10

10
?4

x 10

(a) Diameter, ? = 0.1 (b) Diameter, ? = 0.1
Figure 3: Diameter for network sparsity 0.001. Panels (a) and (b) show the diameter against sparsity
over time for fixed ? = 0.1, and for fixed ? = 0.1 respectively. 100%
100%

,=0

,=0.1

percentage

percentage

,=0.1

,=0.8

10%

1%

1%
0.1%

0.1%
Others

0

,=0

,=0.8

10%

0
1

2

3

4

5

6

cascade size

7

8 others

0

1

2

3

4

5

6

7 others

cascade depth

Figure 4: Distribution of cascade structure, size and depth for different ? values and fixed ? = 0.2.
highly correlated and co-evolve over time. For ease of exposition, we illustrated co-evolution using
one node, however, we found consistent results across nodes.
Degree distribution. Empirical studies have shown that the degree distribution of online social
networks and microblogging sites follow a power law [9, 1], and argued that it is a consequence of
the rich get richer phenomena. The degree distribution of a network is a power law if the expected
number of nodes md with degree d is given by md ? d?? , where ? > 0. Intuitively, the higher the
values of the parameters ? and ?, the closer the resulting degree distribution follows a power-law;
the lower their values, the closer the distribution to an Erdos-Renyi random graph [27]. Figure 2
confirms this intuition by showing the degree distribution for different values of ?.
Small (shrinking) diameter. There is empirical evidence that the diameter of online social networks
and microblogging sites exhibit relatively small diameter and shrinks (or flattens) as the network
grows [28, 9, 22]. Figures 3(a-b) show the diameter on the largest connected component (LCC)
against the sparsity of the network over time for different values of ? and ?. Although at the
beginning, there is a short increase in the diameter due to the merge of small connected components,
the diameter decreases as the network evolves. Here, nodes arrive to the network when they follow
(or are followed by) a node in the largest connected component.
Cascade patterns. Our model can produce the most commonly occurring cascades structures as
well as heavy-tailed cascade size and depth distributions, as observed in historical Twitter data [23].
Figure 4 summarizes the results. The higher the ? value, the shallower and wider the cascades.

7

Experiments on Real Dataset

In this section, we validate our model using a large Twitter dataset containing nearly 550,000 tweet,
retweet and link events from more than 280,000 users [3]. We will show that our model can capture
the co-evolutionary dynamics and, by doing so, it predicts retweet and link creation events more
accurately than several alternatives. Appendix F contains detailed information about the dataset and
additional experiments.
Retweet and link coevolution. Figures 5(a, b) visualize the retweet and link events, aggregated
across different sources, and the corresponding intensities given by our trained model for one node,
picked at random. Here, it is already apparent that retweets and link creations are clustered in time
and often follow each other, and our fitted model intensities successfully track such behavior. Further, Figure 5(c) compares the cross-covariance between the empirical retweet and link creation
intensities and between the retweet and link creation intensities given by our trained model, computed across multiple realizations, for the same node. The similarity between both cross-covariances
is striking and both has its peak around 0, i.e., retweets and link creations are highly correlated and
co-evolve over time. For ease of exposition, as in Section 6, we illustrated co-evolution using one
node, however, we found consistent results across nodes (see Appendix F).
Link prediction. We use our model to predict the identity of the source for each test link event,
given the historical (link and retweet) events before the time of the prediction, and compare its
performance with two state of the art methods, denoted as TRF [3] and WENG [5]. TRF measures
?

Implementation codes are available at https://github.com/farajtabar/Coevolution

7

Intensity

0

Link

0.5

0
0

20
40
60
80
Event occurrence time

Retweet

20
40
60
80
Event occurrence time

Cross covariance

1

Link

Spike trains

Retweet

Estimated

4

Empirical

2

0
?100

0
Lag

100

(a)
(b)
(c)
Figure 5: Coevolutionary dynamics for real data a) Spike trains of link and retweet events. b)
Estimated link and retweet intensities. c) Empirical and estimated cross covariance of link and
retweet intensities
80

3

# events

5
?105

COEVOLVE
TRF
WENG

0.1
0
1

3

# events

5
?105

40

1

0.3

COEVOLVE
HAWKES

Top1

70

10
1

0.2

AvgRank

COEVOLVE
TRF
WENG

Top1

AvgRank

140

3

# events

5
?105

COEVOLVE
HAWKES

0.15

0
1

3

# events

5
?105

(a) Links: AR
(b) Links: Top-1
(c) Activity: AR
Activity: Top-1
Figure 6: Prediction performance in the Twitter dataset by means of average rank (AR) and success
probability that the true (test) events rank among the top-1 events (Top-1).
the probability of creating a link from a source at a given time by simply computing the proportion
of new links created from the source with respect to the total number of links created up to the given
time. WENG considers different link creation strategies and makes a prediction by combining them.
We evaluate the performance by computing the probability of all potential links using different
methods, and then compute (i) the average rank of all true (test) events (AvgRank) and, (ii) the
success probability (SP) that the true (test) events rank among the top-1 potential events at each test
time (Top-1). We summarize the results in Fig. 6(a-b), where we consider an increasing number of
training retweet/tweet events. Our model outperforms TRF and WENG consistently. For example,
for 8 ? 104 training events, our model achieves a SP 2.5x times larger than TRF and WENG.
Activity prediction. We use our model to predict the identity of the node that is going to generate
each test diffusion event, given the historical events before the time of the prediction, and compare
its performance with a baseline consisting of a Hawkes process without network evolution. For
the Hawkes baseline, we take a snapshot of the network right before the prediction time, and use
all historical retweeting events to fit the model. Here, we evaluate the performance the via the
same two measures as in the link prediction task and summarize the results in Figure 6(c-d) against
an increasing number of training events. The results show that, by modeling the co-evolutionary
dynamics, our model performs significantly better than the baseline.

8

Discussion

We proposed a joint continuous-time model of information diffusion and network evolution, which
can capture the coevolutionary dynamics, mimics the most common static and temporal network
patterns observed in real-world networks and information diffusion data, and predicts the network
evolution and information diffusion more accurately than previous state-of-the-arts. Using point
processes to model intertwined events in information networks opens up many interesting future
modeling work. Our current model is just a show-case of a rich set of possibilities offered by a point
process framework, which have been rarely explored before in large scale social network modeling. For example, we can generalize our model to support link deletion by introducing an intensity
?
matrix ?? (t) modeling link deletions as survival processes, i.e., ?? (t) = (gus
(t)Aus (t))u,s?[m] ,
and then consider the counting process A(t) associated with the adjacency matrix to evolve as
E[dA(t)|Hr (t) ? Hl (t)] = ?? (t) dt ? ?? (t) dt. We also can consider the number of nodes varying over time. Furthermore, a large and diverse range of point processes can also be used in the
framework without changing the efficiency of the simulation and the convexity of the parameter
estimation, e.g., condition the intensity on additional external features, such as node attributes.
Acknowledge
The authors would like to thank Demetris Antoniades and Constantine Dovrolis for providing them
with the dataset. The research was supported in part by NSF/NIH BIGDATA 1R01GM108341, ONR
N00014-15-1-2340, NSF IIS-1218749, NSF CAREER IIS-1350983.
8

References

[1] H. Kwak, C. Lee, H. Park, and others. What is Twitter, a social network or a news media? WWW, 2010.
[2] J. Cheng, L. Adamic, P. A. Dow, and others. Can cascades be predicted? WWW, 2014.
[3] D. Antoniades and C. Dovrolis. Co-evolutionary dynamics in social networks: A case study of twitter.
arXiv:1309.6001, 2013.

[4] S. Myers and J. Leskovec. The bursty dynamics of the twitter information network. WWW, 2014.
[5] L. Weng, J. Ratkiewicz, N. Perra, B. Goncalves, C. Castillo, F. Bonchi, R. Schifanella, F. Menczer, and
A. Flammini. The role of information diffusion in the evolution of social networks. KDD, 2013.
[6] N. Du, L. Song, M. Gomez-Rodriguez, and H. Zha. Scalable influence estimation in continuous-time
diffusion networks. NIPS, 2013.
[7] M. Gomez-Rodriguez, D. Balduzzi, and B. Sch?olkopf. Uncovering the temporal dynamics of diffusion
networks. ICML, 2011.
[8] M. Gomez-Rodriguez, J. Leskovec, A. Krause. Inferring networks of diffusion and influence. KDD, 2010.
[9] D. Chakrabarti, Y. Zhan, and C. Faloutsos. R-mat: A recursive model for graph mining. Computer Science
Department, page 541, 2004.
[10] J. Leskovec, D. Chakrabarti, J. Kleinberg, C. Faloutsos, and J. Leskovec. Kronecker graphs: An approach
to modeling networks. JMLR, 2010.
[11] J. Leskovec, L. Backstrom, R. Kumar, and others. Microscopic evolution of social networks. KDD, 2008.
[12] T.J. Liniger. Multivariate Hawkes Processes. PhD thesis, ETHZ, 2009.
[13] C. Blundell, J. Beck, K. Heller. Modelling reciprocating relationships with hawkes processes. NIPS, 2012.
[14] M. Farajtabar, N. Du, M. Gomez-Rodriguez, I. Valera, H. Zha, and L. Song. Shaping social activity by
incentivizing users. NIPS, 2014.
[15] T. Iwata, A. Shah, and Z. Ghahramani. Discovering latent influence in online social activities via shared
cascade poisson processes. KDD, 2013.
[16] S. Linderman and R. Adams. Discovering latent network structure in point process data. ICML, 2014.
[17] I. Valera, M. Gomez-Rodriguez, Modeling adoption of competing products and conventions in social
media. ICDM, 2015.
[18] K. Zhou, H. Zha, and L. Song. Learning social infectivity in sparse low-rank networks using multidimensional hawkes processes. AISTATS, 2013.
[19] K. Zhou, H. Zha, and L. Song. Learning triggering kernels for multi-dimensional hawkes processes.
ICML, 2013.
[20] D. Hunter, P. Smyth, D. Q. Vu, and others. Dynamic egocentric models for citation networks. ICML, 2011.
[21] D. Q. Vu, D. Hunter, P. Smyth, and A. Asuncion. Continuous-time regression models for longitudinal
networks. NIPS, 2011.
[22] J. Leskovec, J. Kleinberg, and C. Faloutsos. Graphs over time: densification laws, shrinking diameters
and possible explanations. KDD, 2005.
[23] S. Goel, D. J. Watts, and D. G. Goldstein. The structure of online diffusion networks. EC, 2012.
[24] O. Aalen, O. Borgan, and H. Gjessing. Survival and event history analysis: a process point of view, 2008.
? Tardos. Maximizing the spread of influence through a social network.
[25] D. Kempe, J. Kleinberg, and E.
KDD, 2003.
[26] Y. Ogata. On lewis? simulation method for point processes. IEEE TIT, 27(1):23?31, 1981.
[27]
[28]
[29]
[30]

P. Erdos and A R?enyi. On the evolution of random graphs. Hungar. Acad. Sci, 5:17?61, 1960.
L. Backstrom, P. Boldi, M. Rosa, J. Ugander, and S. Vigna. Four degrees of separation. WebSci, 2012.
M. Granovetter. The strength of weak ties. American journal of sociology, pages 1360?1380, 1973.
D. Romero and J. Kleinberg. The directed closure process in hybrid social-information networks, with an
analysis of link formation on twitter. ICWSM, 2010.

[31] J. Ugander, L. Backstrom, and J. Kleinberg. Subgraph frequencies: Mapping the empirical and extremal
geography of large graph collections. WWW, 2013.
[32] D.J. Watts and S.H. Strogatz. Collective dynamics of small-world networks. Nature, 1998.
[33] T. Gross and B. Blasius. Adaptive coevolutionary networks: a review. Royal Society Interface, 2008.
[34] P. Singer, C. Wagner, and M. Strohmaier. Factors influencing the co-evolution of social and content
networks in online social media. Modeling and Mining Ubiquitous Social Media, pages 40?59. Springer,
2012.

9


----------------------------------------------------------------

title: 6193-learning-and-forecasting-opinion-dynamics-in-social-networks.pdf

Learning and Forecasting Opinion Dynamics in
Social Networks
Abir De?
Isabel Valera?
Niloy Ganguly?
?
Sourangshu Bhattacharya
Manuel Gomez-Rodriguez?
?
IIT Kharagpur
MPI for Software Systems?
{abir.de,niloy,sourangshu}@cse.iitkgp.ernet.in
{ivalera,manuelgr}@mpi-sws.org

Abstract
Social media and social networking sites have become a global pinboard for exposition and discussion of news, topics, and ideas, where social media users often
update their opinions about a particular topic by learning from the opinions shared
by their friends. In this context, can we learn a data-driven model of opinion dynamics that is able to accurately forecast users? opinions? In this paper, we introduce SLANT, a probabilistic modeling framework of opinion dynamics, which
represents users? opinions over time by means of marked jump diffusion stochastic differential equations, and allows for efficient model simulation and parameter
estimation from historical fine grained event data. We then leverage our framework to derive a set of efficient predictive formulas for opinion forecasting and
identify conditions under which opinions converge to a steady state. Experiments
on data gathered from Twitter show that our model provides a good fit to the data
and our formulas achieve more accurate forecasting than alternatives.

1

Introduction

Social media and social networking sites are increasingly used by people to express their opinions,
give their ?hot takes?, on the latest breaking news, political issues, sports events, and new products.
As a consequence, there has been an increasing interest on leveraging social media and social networking sites to sense and forecast opinions, as well as understand opinion dynamics. For example,
political parties routinely use social media to sense people?s opinion about their political discourse1 ;
quantitative investment firms measure investor sentiment and trade using social media [18]; and,
corporations leverage brand sentiment, estimated from users? posts, likes and shares in social media
and social networking sites, to design their marketing campaigns2 . In this context, multiple methods
for sensing opinions, typically based on sentiment analysis [21], have been proposed in recent years.
However, methods for accurately forecasting opinions are still scarce [7, 8, 19], despite the extensive
literature on theoretical models of opinion dynamics [6, 9].
In this paper, we develop a novel modeling framework of opinion dynamics in social media and social networking sites, SLANT3 , which allows for accurate forecasting of individual users? opinions.
The proposed framework is based on two simple intuitive ideas: i) users? opinions are hidden until
they decide to share it with their friends (or neighbors); and, ii) users may update their opinions
about a particular topic by learning from the opinions shared by their friends. While the latter is one
of the main underlying premises used by many well-known theoretical models of opinion dynamics [6, 9, 22], the former has been ignored by models of opinion dynamics, despite its relevance on
closely related processes such as information diffusion [12].
1

http://www.nytimes.com/2012/10/08/technology/campaigns-use-social-media-to-lure-younger-voters.html
http://www.nytimes.com/2012/07/31/technology/facebook-twitter-and-foursquare-as-corporate-focus-groups.html
3
Slant is a particular point of view from which something is seen or presented.
2

30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.

More in detail, our proposed model represents users? latent opinions as continuous-time stochastic
processes driven by a set of marked jump stochastic differential equations (SDEs) [14]. Such construction allows each user?s latent opinion to be modulated over time by the opinions asynchronously
expressed by her neighbors as sentiment messages. Here, every time a user expresses an opinion by
posting a sentiment message, she reveals a noisy estimate of her current latent opinion. Then, we
exploit a key property of our model, the Markov property, to develop:
I. An efficient estimation procedure to find the parameters that maximize the likelihood of a
set of (millions of) sentiment messages via convex programming.
II. A scalable simulation procedure to sample millions of sentiment messages from the proposed model in a matter of minutes.
III. A set of novel predictive formulas for efficient and accurate opinion forecasting, which
can also be used to identify conditions under which opinions converge to a steady state of
consensus or polarization.
Finally, we experiment on both synthetic and real data gathered from Twitter and show that our
model provides a good fit to the data and our predictive formulas achieve more accurate opinion
forecasting than several alternatives [7, 8, 9, 15, 26].
Related work. There is an extensive line of work on theoretical models of opinion dynamics and
opinion formation [3, 6, 9, 15, 17, 26]. However, previous models typically share the following
limitations: (i) they do not distinguish between latent opinion and sentiment (or expressed opinion), which is a noisy observation of the opinion (e.g., thumbs up/down, text sentiment); (ii) they
consider users? opinions to be updated synchronously in discrete time, however, opinions may be
updated asynchronously following complex temporal patterns [12]; (iii) the model parameters are
difficult to learn from real fine-grained data and instead are set arbitrarily, as a consequence, they
provide inaccurate fine-grained predictions; and, (iv) they focus on analyzing only the steady state
of the users? opinions, neglecting the transient behavior of real opinion dynamics which allows for
opinion forecasting methods. More recently, there have been some efforts on designing models that
overcome some of the above limitations and provide more accurate predictions [7, 8]. However,
they do not distinguish between opinion and sentiment and still consider opinions to be updated
synchronously in discrete time. Our modeling framework addresses the above limitations and, by
doing so, achieves more accurate opinion forecasting than alternatives.

2

Proposed model

In this section, we first formulate our model of opinion dynamics, starting from the data it is designed
for, and then introduce efficient methods for model parameter estimation and model simulation.
Opinions data. Given a directed social network G = (V, E), we record each message as e :=
(u, m, t), where the triplet means that the user u ? V posted a message with sentiment m at time
t. Given a collection of messages {e1 = (u1 , m1 , t1 ), . . . , en = (un , mn , tn )}, the history Hu (t)
gathers all messages posted by user u up to but not including time t, i.e.,
Hu (t) = {ei = (ui , mi , ti )|ui = u and ti < t},

(1)

and H(t) := ?u?V Hu (t) denotes the entire history of messages up to but not including time t.

Generative process. We represent users? latent opinions as a multidimensional stochastic process
x? (t), in which the u-th entry, x?u (t) ? R, represents the opinion of user u at time t and the sign ?
means that it may depend on the history H(t). Then, every time a user u posts a message at time t,
we draw its sentiment m from a sentiment distribution p(m|x?u (t)). Here, we can also think of the
sentiment m of each message as samples from a noisy stochastic process mu (t) ? p(mu (t)|x?u (t)).
Further, we represent the message times by a set of counting processes. In particular, we denote
the set of counting processes as a vector N (t), in which the u-th entry, Nu (t) ? {0} ? Z+ , counts
the number of sentiment messages user u posted up to but not including time t. Then, we can
characterize the message rate of the users using their corresponding conditional intensities as
E[dN (t) | H(t)] = ?? (t) dt,
(2)
where dN (t) := ( dNu (t) )u?V denotes the number of messages per user in the window [t, t + dt)
and ?? (t) := ( ??u (t) )u?V denotes the associated user intensities, which may depend on the history
H(t). We denote the set of user that u follows by N (u). Next, we specify the the intensity functions
?? (t), the dynamics of the users? opinions x? (t), and the sentiment distribution p(m|x?u (t)).
2

Intensity for messages. There is a wide variety of message intensity functions one can choose from
to model the users? intensity ?? (t) [1]. In this work, we consider two of the most popular functional
forms used in the growing literature on social activity modeling using point processes [10, 24, 5]:
I. Poisson process. The intensity is assumed to be independent of the history H(t) and
constant, i.e., ??u (t) = ?u .
II. Multivariate Hawkes processes. The intensity captures a mutual excitation phenomena between message events and depends on the whole history of message events
?v?{u?N (u)} Hv (t) before t:
X
X
X
??u (t) = ?u +
bvu
?(t ? ti ) = ?u +
bvu (?(t) ? dNv (t)), (3)
v?u?N (u)

ei ?Hv (t)

v?u?N (u)

where the first term, ?u > 0, models the publication of messages by user u on her own
initiative, and the second term, with bvu > 0, models the publication of additional messages
by user u due to the influence that previous messages posted by the users she follows have
on her intensity. Here, ?(t) = e??t is an exponential triggering kernel modeling the decay
of influence of the past events over time and ? denotes the convolution operation.
In both cases, the couple (N (t), ?? (t)) is a Markov process, i.e., future states of the process (conditional on past and present states) depends only upon the present state, and we can express the users?
intensity more compactly using the following jump stochastic differential equation (SDE):
d?? (t) = ?(? ? ?? (t))dt + BdN (t),

where the initial condition is ?? (0) = ?. The Markov property will become important later.
Stochastic process for opinion. The opinion x?u (t) of a user u at time t adopts the following form:
X
X
X
x?u (t) = ?u +
avu
mi g(t ? ti ) = ?u +
avu (g(t) ? (mv (t)dNv (t))), (4)
v?N (u)

ei ?Hv (t)

v?N (u)

where the first term, ?u ? R, models the original opinion a user u starts with, the second term,
with avu ? R, models updates in user u?s opinion due to the influence that previous messages with
opinions mi posted by the users that u follows has on her opinion. Here, g(t) = e??t (where
? > 0) denotes an exponential triggering kernel, which models the decay of influence over time.
The greater the value of ?, the greater the user?s tendency to retain her own opinion ?u . Under this
form, the resulting opinion dynamics are Markovian and can be compactly represented by a set of
coupled marked jumped stochastic differential equations (proven in Appendix A):
Proposition 1 The tuple (x? (t), ?? (t), N (t)) is a Markov process, whose dynamics are defined by
the following marked jumped stochastic differential equations (SDE):
dx? (t) = ?(? ? x? (t))dt + A(m(t)  dN (t))
?

?

d? (t) = ?(? ? ? (t))dt + B dN (t)

(5)
(6)

where the initial conditions are ?? (0) = ? and x? (0) = ?, the marks are the sentiment messages
m(t) = ( mu (t) )u?V , with mu (t) ? p(m|x?u (t)), and the sign  denotes pointwise product.
The above mentioned Markov property will be the key to the design of efficient model parameter
estimation and model simulation algorithms.
Sentiment distribution. The particular choice of sentiment distribution p(m|x?u (t)) depends on the
recorded marks. For example, one may consider:
I. Gaussian Distribution The sentiment is assumed to be a real random variable m ? R, i.e.,
p(m|xu (t)) = N (xu (t), ?u ). This fits well scenarios in which sentiment is extracted from
text using sentiment analysis [13].
II. Logistic. The sentiment is assumed to be a binary random variable m ? {?1, 1}, i.e.,
p(m|xu (t)) = 1/(1 + exp(?m ? xu (t))). This fits well scenarios in which sentiment is
measured by means of up votes, down votes or likes.
Our model estimation method can be easily adapted to any log-concave sentiment distribution. However, in the remainder of the paper, we consider the Gaussian distribution since, in our experiments,
sentiment is extracted from text using sentiment analysis.
3

2.1 Model parameter estimation
Given a collection of messages H(T ) = {(ui , mi , ti )} recorded during a time period [0, T ) in
a social network G = (V, E), we can find the optimal parameters ?, ?, A and B by solving a
maximum likelihood estimation (MLE) problem4 . To do so, it is easy to show that the log-likelihood
of the messages is given by
X
X
XZ T
??u (? ) d? .
L(?, ?, A, B) =
log p(mi |x?ui (ti )) +
log ??ui (ti ) ?
(7)
ei ?H(T )

|

{z

message sentiments

ei ?H(T )

|

}

maximize

L(?, ?, A, B).

u?V

message times

Then, we can find the optimal parameters (?, ?, A, B) using MLE as
?,??0,A,B?0

{z

0

}

(8)

Note that, as long as the sentiment distributions are log-concave, the MLE problem above is concave and thus can be solved efficiently. Moreover, the problem decomposes in 2|V| independent
subproblems, two per user u, since the first term in Eq. 7 only depends on (?, A) whereas the last
two terms only depend on (?, B), and thus can be readily parallelized. Then, we find (?? , B ? ) using spectral projected gradient descent [4], which works well in practice and achieves ? accuracy in
O(log(1/?)) iterations, and find (?? , A? ) analytically, since, for Gaussian sentiment distributions,
the problem reduces to a least-square problem. Fortunately, in each subproblem, we can use the
Markov property from Proposition 1 to precompute the sums and integrals in (8) in linear time, i.e.,
O(|Hu (T )| + | ?v?N (u) Hv (T )|). Appendix H summarizes the overall estimation algorithm.
2.2 Model simulation
We leverage the efficient sampling algorithm for multivariate Hawkes introduced by Farajtabar et
al. [11] to design a scalable algorithm to sample opinions from our model. The two key ideas that
allow us to adapt the procedure by Farajtabar et al. to our model of opinion dynamics, while keeping
its efficiency, are as follows: (i) the opinion dynamics, defined by Eqs. 5 and 6, are Markovian and
thus we can update individual intensities and opinions in O(1) ? let ti and ti+1 be two consecutive
events, then, we can compute ?? (ti+1 ) as (?? (ti ) ? ?) exp(??(ti+1 ? ti )) + ? and x? (ti+1 ) as
(x? (ti ) ? ?) exp(??(ti+1 ? ti )) + ?, respectively; and, (ii) social networks are typically sparse
and thus both A and B are also sparse, then, whenever a node expresses its opinion, only a small
number of opinions and intensity functions in its local neighborhood will change. As a consequence,
we can reuse the majority of samples from the intensity functions and sentiment distributions for the
next new sample. Appendix I summarizes the overall simulation algorithm.

3

Opinion forecasting

Our goal here is developing efficient methods that leverage our model to forecast a user u?s
opinion xu (t) at time t given the history H(t0 ) up to time t0 <t. In the context of our probabilistic model, we will forecast this opinion by efficiently computing the conditional expectation
EH(t)\H(t0 ) [x?u (t)|H(t0 )], where H(t)\H(t0 ) denotes the average across histories from t0 to t,
while conditioning on the history up to H(t0 ).
To this aim, we will develop analytical and sampling based methods to compute the above conditional expectation. Moreover, we will use the former to identify under which conditions users?
average opinion converges to a steady state and, if so, find the steady state opinion. In this section,
we write Ht = H(t) to lighten the notation and denote the eigenvalues of a matrix X by ?(X).
3.1 Analytical forecasting
In this section, we derive a set of formulas to compute the conditional expectation for both Poisson
and Hawkes messages intensities. However, since the derivation of such formulas for general multivariate Hawkes is difficult, we focus here on the case when bvu = 0 for all v, u ? G, v 6= u, and
rely on the efficient sampling based method for the general case.
I. Poisson intensity. Consider each user?s messages follow a Poisson process with rate ?u . Then,
the conditional average opinion is given by (proven in Appendix C):
4

Here, if one decides to model the message intensities with a Poisson process, B = 0.

4

Theorem 2 Given a collection of messages Ht0 recorded during a time period [0, t0 ) and ??u (t) =
?u for all u ? G, then,


EHt \Ht0 [x? (t)|Ht0 ] = e(A?1 ??I)(t?t0 ) x(t0 ) + ?(A?1 ? ?I)?1 e(A?1 ??I)(t?t0 ) ? I ?,
where ?1 := diag[?] and (x(t0 ))u?V = ?u +

P

v?N (u)

auv

P

ti ?Hv (t0 )

(9)

e

??(t0 ?ti )

mv (ti ).

Remarkably, we can efficiently compute both terms in Eq. 9 by using the iterative algorithm by AlMohy et al. [2] for the matrix exponentials and the well-known GMRES method [23] for the matrix
inversion. Given this predictive formula, we can easily study the stability condition and, for stable
systems, find the steady state conditional average opinion (proven in Appendix D):
Theorem 3 Given the conditions of Theorem 2, if Re[?(A?1 )] < ?, then,

?1
A?1
lim EHt \Ht0 [x? (t)|Ht0 ] = I ?
?.
t??
w

(10)

The above results indicate that the conditional average opinions are nonlinearly related to the parameter matrix A, which depends on the network structure, and the message rates ?, which in this case
are assumed to be constant and independent on the network structure. Figure 1 provides empirical
evidence of these results.
II. Multivariate Hawkes Process. Consider each user?s messages follow a multivariate Hawkes
process, given by Eq. 3, and bvu = 0 for all v, u ? G, v 6= u. Then, the conditional average opinion
is given by (proven in Appendix E):
Theorem P
4 Given a collection of messages Ht0 recorded during a time period [0, t0 ) and ??u (t) =
?u + buu ei ?Hu (t) e??(t?ti ) for all u ? G, then, the conditional average satisfies the following
differential equation:
dEHt \Ht0 [x? (t)|Ht0 ]
(11)
= [??I + A?(t)]EHt \Ht0 [x? (t)|Ht0 ] + ??,
dt
where


?(t) = diag EHt \Ht0 [?? (t)|Ht0 ] ,



EHt \Ht0 [?? (t)|Ht0 ] = e(B??I)(t?t0 ) ?(t0 ) + ?(B ? ?I)?1 e(B??I)(t?t0 ) ? I ? ?t ? t0 ,
X
X
(?(t0 ))u?V = ?u +
buv
e??(t0 ?ti ) ,
v?N (u)

ti ?Hv (t0 )


B = diag [b11 , . . . , b|V||V| ]> .

Here, we can compute the conditional average by solving numerically the differential equation
above, which is not stochastic, where we can efficiently compute the vector EHt [?? (t)] by using
again the algorithm by Al-Mohy et al. [2] and the GMRES method [23].
In this case, the stability condition and the steady state conditional average opinion are given by
(proven in Appendix F):
Theorem 5 Given the conditions of Theorem 4, if the transition matrix ?(t) associated to the timevarying linear system described by Eq. 11 satisfies that ||?(t)|| ? ?e?ct ?t > 0, where ?, c > 0,
then,

?1
A?2
?
lim EHt \Ht0 [x (t)|Ht0 ] = I ?
?,
(12)
t??
w
h
i
?1
where ?2 := diag I ? B
?
?
The above results indicate that the conditional average opinions are nonlinearly related to the parameter matrices A and B. This suggests that the effect of the temporal influence on the opinion
evolution, by means of the parameter matrix B of the multivariate Hawkes process, is non trivial.
We illustrate this result empirically in Figure 1.
5

Theoretical

0.01

E[xu (t)]
u?V ?
|V ? |

H:
Opinion-Trajectory?

P:
Opinion-Trajectory?

Network G1

0

-0.5
-1

-1.5

Theoretical
Experimental

-2
0.005

0

0.01

0.015

P
E[xu (t)]
u?V ?
|V ? |

Network G2

P:

Hawkes (+)
Hawkes (-)

30
20
10
0

-200

0.005

0.01

0.015

50

40

40

30
20

H:

P
u?V E[xu (t)]
|V |

0.005

0.01

Time

0.015

H: Temporal evolution

50

30
20
10

00

0.005 0.01
Time

Time

u?V E[xu (t)]
|V |

20

00

0.015

10

-10

Time

P

0.005 0.01
Time

P: Temporal evolution

40

30

10

00

0.015

Time

Time

P

0.01

0.005

20
10

Hawkes (-)

-40

0.015

30

Node-ID

0.005

40

0

-2 Hawkes (+)

Experimental
0
0

50

40

Node-ID

0.5

50

Node-ID

1

4
2

Node-ID

Opinion-Trajectory?

Opinion-Trajectory?

1.5

0.015

P: Temporal evolution

00

0.005

0.01

Time

0.015

H: Temporal evolution

Figure 1: Opinion dynamics on two 50-node networks G1 (top) and G2 (bottom) for Poisson (P)
and Hawkes (H) message intensities. The first column visualizes the two networks and opinion of
each node at t = 0 (positive/negative opinions in red/blue). The second column shows the temporal
evolution of the theoretical and empirical average opinion for Poisson intensities. The third column
shows the temporal evolution of the empirical average opinion for Hawkes intensities, where we
compute the average separately for positive (+) and negative (?) opinions in the steady state. The
fourth and fifth columns shows the polarity of average opinion per user over time.
3.2

Simulation based forecasting

Given the efficient simulation procedure described in Section 2.2, we can readily derive a general
simulation based formula for opinion forecasting:
n

1X ?
? (t) =
EHt \Ht0 [x (t)|Ht0 ] ? x
xl (t),
n
?

?

(13)

l=1

where n is the number of times that we simulate the opinion dynamics and x?l (t) gathers the users?
opinion at time t for the l-th simulation. Moreover, we have the following theoretical guarantee
(proven in Appendix G):
Theorem 6 Simulate the opinion dynamics up to time t > t0 the following number of times:
n?

1
2
(6?max
+ 4xmax ) log(2/?),
32

(14)

2
2
where ?max
= maxu?G ?H
(x?u (t)|Ht0 ) is the maximum variance of the users? opinions, which
t \Ht0
we analyze in Appendix G, and xmax ? |xu (t)|, ?u ? G is an upper bound on the users? (absolute)
opinions. Then, for each user u ? G, the error between her true and estimated average opinion
satisfies that |?
x?u (t) ? EHt \Ht0 [x?u (t)|Ht0 ]| ?  with probability at least 1 ? ?.

4
4.1

Experiments
Experiments on synthetic data

We first provide empirical evidence that our model is able to produce different types of opinion
dynamics, which may or may not converge to a steady state of consensus or polarization. Then, we
show that our model estimation and simulation algorithms as well as our predictive formulas scale
to networks with millions of users and events. Appendix J contains an evaluation of the accuracy of
our model parameter estimation method.
Different types of opinion dynamics. We first simulate our model on two different small networks
using Poisson intensities, i.e., ??u (t) = ?u , ?u ? U (0, 1) ?u, and then simulate our model on the
same networks while using Hawkes intensities with bvu ? U (0, 1) on 5% of the nodes, chosen at
random, and the original Poisson intensities on the remaining nodes. Figure 1 summarizes the results, which show that (i) our model is able to produce opinion dynamics that converge to consensus
(second column) and polarization (third column); (ii) the opinion forecasting formulas described in
Section 3 closely match an simulation based estimation (second column); and, (iii) the evolution of
6

Nodes

105
Poisson
Hawkes
104
103
102
101
100
10?1
10?2
102 103 104

10

5

10

6

15

10

2

10

3

10

4

Nodes

10

5

10

6

Time (s)

Time (s)

105
104
103
102
101
101
10?1
10?2101

Time(s)

Time (s)

105
Informational
Temporal
104
103
102
1
10
100
10?1
10?2101 102 103 104

10

5

Nodes

10

6

10

7

(a) Estimation vs # nodes (b) Simulation vs # nodes (c) Forecast vs # nodes

Poisson
Hawkes

10
5
02

4

6

8

10

Forecast-Time[T(hr)]

(d) Forecast vs T

Figure 2: Panels (a) and (b) show running time of our estimation and simulation procedures against
number of nodes, where the average number of events per node is 10. Panels (c) and (d) show the
running time needed to compute our analytical formulas against number of nodes and time horizon
T = t ? t0 , where the number of nodes is 103 . In Panel (c), T = 6 hours. For all panels, the average
degree per node is 30. The experiments are carried out in a single machine with 24 cores and 64 GB
of main memory.
the average opinion and whether opinions converge to a steady state of consensus or polarization
depend on the functional form of message intensity5 .
Scalability. Figure 2 shows that our model estimation and simulation algorithms, described in Sections 2.1 and 2.2, and our analytical predictive formulas, described in Section 3.1, scale to networks
with millions of users and events. For example, our algorithm takes 20 minutes to estimate the
model parameters from 10 million events generated by one million nodes using a single machine
with 24 cores and 64 GB RAM.
4.2 Experiments on real data
We use real data gathered from Twitter to show that our model can forecast users? opinions more
accurately than six state of the art methods [7, 8, 9, 15, 19, 26] (see Appendix L).
Experimental Setup. We experimented with five Twitter datasets about current real-world events
(Politics, Movie, Fight, Bollywood and US), in which, for each recorded message i, we compute its
sentiment value mi using a popular sentiment analysis toolbox, specially designed for Twitter [13].
Here, the sentiment takes values m ? (?1, 1) and we consider the sentiment polarity to be simply
sign(m). Appendix K contains further details and statistics about these datasets.
Opinion forecasting. We first evaluate the performance of our model at predicting sentiment (expressed opinion) at a message level. To do so, for each dataset, we first estimate the parameters of
our model, SLANT, using messages from a training set containing the (chronologically) first 90%
of the messages. Here, we set the decay parameters of the exponential triggering kernels ?(t) and
g(t) by cross-validation. Then, we evaluate the predictive performance of our opinion forecasting
formulas using the last 10% of the messages6 . More specifically, we predict the sentiment value m
for each message posted by user u in the test set given the history up to T hours before the time
of the message as m
? = EHt \Ht?T [x?u (t)|Ht?T ]. We compare the performance of our model with
the asynchronous linear model (AsLM) [8], DeGroot?s model [9], the voter model [26], the biased
voter model [7], the flocking model [15], and the sentiment prediction method based on collaborative filtering by Kim et al. [19], in terms of: (i) the mean squared error between the true (m) and the
estimated (m)
? sentiment value for all messages in the held-out set, i.e., E[(m ? m)
? 2 ], and (ii) the
failure rate, defined as the probability that the true and the estimated polarity do not coincide, i.e.,
P(sign(m) 6= sign(m)).
?
For the baselines algorithms, which work in discrete time, we simulate NT
rounds in (t ? T, t), where NT is the number of posts in time T . Figure 3 summarizes the results,
which show that: (i) our opinion forecasting formulas consistently outperform others both in terms
of MSE (often by an order of magnitude) and failure rate;7 (ii) its forecasting performance degrades
gracefully with respect to T , in contrast, competing methods often fail catastrophically; and, (iii) it
achieves an additional mileage by using Hawkes processes instead of Poisson processes. To some
extent, we believe SLANT?s superior performance is due to its ability to leverage historical data to
learn its model parameters and then simulate realistic temporal patterns.
Finally, we look at the forecasting results at a network level and show that our forecasting formulas
can also predict the evolution of opinions macroscopically (in terms of the average opinion across
users). Figure 4 summarizes the results for two real world datasets, which show that the forecasted
5

For these particular networks, Poisson intensities lead to consensus while Hawkes intensities lead to polarization, however, we did find
other examples in which Poisson intensities lead to polarization and Hawkes intensities lead to consensus.
6
Here, we do not distinguish between analytical and sampling based forecasting since, in practice, they closely match each other.
7
The failure rate is very close to zero for those datasets in which most users post messages with the same polarity.

7

Flocking

Collab-Filter

BiasedVoter

DeGroot

Linear

SLANT (H)

SLANT (P)

Voter

101

MSE

100

10?1

Failure-Rate

10?20

2

1

4

6

8

10 0

2

4

6

8

10 0

2

T, hours

4

6

8

10 0

2

4

6

8

10 0

2

T, hours

4

6

8

10

0

2

4

6

8

10

0

2

T, hours

4

6

8

10

0

2

4

6

8

10

0

2

T, hours

4

6

8

10

4

6

8

10

T, hours

0.8
0.6
0.4

0.2
00

2

T, hours

(a) Politics

T, hours

(b) Movie

T, hours

(c) Fight

T, hours

(d) Bollywood

T, hours

(e) US

0.6

m(t)
?
x
?(t)
T = 1h
T = 3h
T = 5h

0.5
0.4
28 April

2 May
Time

5 May

0.8
0.7
0.6

m(t)
?
x
?(t)
T = 1h
T = 3h
T = 5h

0.5
0.4
28 April

2 May
Time

5 May

(a) Tw: Movie (Hawkes) (b) Tw: Movie (Poisson)

0.8 m(t)
?
x
?(t)
0.6
T = 1h
0.4 T = 3h
T
= 5h
0.2
0
-0.2
-0.47 April
10 April

Time

13 April

(c) Tw: US (Hawkes)

Average Opinion?

0.7

Average Opinion?

0.8

Average Opinion?

Average Opinion?

Figure 3: Sentiment prediction performance using a 10% held-out set for each real-world dataset.
Performance is measured in terms of mean squared error (MSE) on the sentiment value, E[(m ?
m)
? 2 ], and failure rate on the sentiment polarity, P(sign(m) 6= sign(m)).
?
For each message in the
held-out set, we predict the sentiment value m given the history up to T hours before the time of
the message, for different values of T . Nowcasting corresponds to T = 0 and forecasting to T > 0.
The sentiment value m ? (?1, 1) and the sentiment polarity sign (m) ? {?1, 1}.
0.8 m(t)
?
x
?(t)
0.6
T = 1h
0.4 T = 3h
T
= 5h
0.2
0
-0.2
-0.47 April
10 April

Time

13 April

(d) Tw: US (Poisson)

Figure 4: Macroscopic sentiment prediction given by our model for two real-world datasets. The
panels show the observed sentiment m(t)
?
(in blue, running average), inferred opinion x
?(t) on the
training set (in red), and forecasted opinion EHt \Ht?T [xu (t)|Ht?T ] for T = 1, 3, and 5 hours on
the test set (in black, green and gray, respectively), where the symbol ? denotes average across users.
opinions become less accurate as the time T becomes larger, since the average is computed on longer
time periods. As expected, our model is more accurate when the message intensities are modeled
using multivariate Hawkes. We found qualitatively similar results for the remaining datasets.

5

Conclusions

We proposed a modeling framework of opinion dynamics, whose key innovation is modeling users?
latent opinions as continuous-time stochastic processes driven by a set of marked jump stochastic
differential equations (SDEs) [14]. Such construction allows each user?s latent opinion to be modulated over time by the opinions asynchronously expressed by her neighbors as sentiment messages.
We then exploited a key property of our model, the Markov property, to design efficient parameter
estimation and simulation algorithms, which scale to networks with millions of nodes. Moreover, we
derived a set of novel predictive formulas for efficient and accurate opinion forecasting and identified
conditions under which opinions converge to a steady state of consensus or polarization. Finally, we
experimented with real data gathered from Twitter and showed that our framework achieves more
accurate opinion forecasting than state-of-the-arts.
Our model opens up many interesting venues for future work. For example, in Eq. 4, our model
assumes a linear dependence between users? opinions, however, in some scenarios, this may be a
coarse approximation. A natural follow-up to improve the opinion forecasting accuracy would be
considering nonlinear dependences between opinions. It would be interesting to augment our model
to jointly consider correlations between different topics. One could leverage our modeling framework to design opinion shaping algorithms based on stochastic optimal control [14, 25]. Finally, one
of the key modeling ideas is realizing that users? expressed opinions (be it in the form of thumbs
up/down or text sentiment) can be viewed as noisy discrete samples of the users? latent opinion localized in time. It would be very interesting to generalize this idea to any type of event data and
derive sampling theorems and conditions under which an underlying general continuous signal of
interest (be it user?s opinion or expertise) can be recovered from event data with provable guarantees.
Acknowledgement: Abir De is partially supported by Google India under the Google India PhD Fellowship
Award, and Isabel Valera is supported by a Humboldt post-doctoral fellowship.

8

References
[1] O. Aalen, ?. Borgan, and H. Gjessing. Survival and event history analysis: a process point of view.
Springer Verlag, 2008.
[2] A. H. Al-Mohy and N. J. Higham. Computing the action of the matrix exponential, with an application
to exponential integrators. SIAM journal on scientific computing, 33(2):488?511, 2011.
[3] R. Axelrod. The dissemination of culture a model with local convergence and global polarization. Journal
of conflict resolution, 41(2):203?226, 1997.
[4] E. G. Birgin, J. M. Mart??nez, and M. Raydan. Nonmonotone spectral projected gradient methods on
convex sets. SIAM Journal on Optimization, 10(4), 2000.
[5] C. Blundell, J. Beck, and K. A. Heller. Modelling reciprocating relationships with hawkes processes. In
Advances in Neural Information Processing Systems, pages 2600?2608, 2012.
[6] P. Clifford and A. Sudbury. A model for spatial conflict. Biometrika, 60(3):581?588, 1973.
[7] A. Das, S. Gollapudi, and K. Munagala. Modeling opinion dynamics in social networks. In WSDM, 2014.
[8] A. De, S. Bhattacharya, P. Bhattacharya, N. Ganguly, and S. Chakrabarti. Learning a linear influence
model from transient opinion dynamics. In CIKM, 2014.
[9] M. H. DeGroot. Reaching a consensus. Journal of the American Statistical Association, 69(345), 1974.
[10] M. Farajtabar, N. Du, M. Gomez-Rodriguez, I. Valera, L. Song, and H. Zha. Shaping social activity by
incentivizing users. In NIPS, 2014.
[11] M. Farajtabar, Y. Wang, M. Gomez-Rodriguez, S. Li, H. Zha, and L. Song. Coevolve: A joint point
process model for information diffusion and network co-evolution. In NIPS, 2015.
[12] M. Gomez-Rodriguez, D. Balduzzi, and B. Sch?olkopf. Uncovering the Temporal Dynamics of Diffusion
Networks. In ICML, 2011.
[13] A. Hannak, E. Anderson, L. F. Barrett, S. Lehmann, A. Mislove, and M. Riedewald. Tweetin?in the rain:
Exploring societal-scale effects of weather on mood. In ICWSM, 2012.
[14] F. B. Hanson. Applied Stochastic Processes and Control for Jump-Diffusions. SIAM, 2007.
[15] R. Hegselmann and U. Krause. Opinion dynamics and bounded confidence models, analysis, and simulation. Journal of Artificial Societies and Social Simulation, 5(3), 2002.
[16] D. Hinrichsen, A. Ilchmann, and A. Pritchard. Robustness of stability of time-varying linear systems.
Journal of Differential Equations, 82(2):219 ? 250, 1989.
[17] P. Holme and M. E. Newman. Nonequilibrium phase transition in the coevolution of networks and opinions. Physical Review E, 74(5):056108, 2006.
[18] T. Karppi and K. Crawford. Social media, financial algorithms and the hack crash. TC&S, 2015.
[19] J. Kim, J.-B. Yoo, H. Lim, H. Qiu, Z. Kozareva, and A. Galstyan. Sentiment prediction using collaborative
filtering. In ICWSM, 2013.
[20] J. Leskovec, D. Chakrabarti, J. M. Kleinberg, C. Faloutsos, and Z. Ghahramani. Kronecker graphs: An
approach to modeling networks. JMLR, 2010.
[21] B. Pang and L. Lee. Opinion mining and sentiment analysis. F&T in information retrieval, 2(1-2), 2008.
[22] B. H. Raven. The bases of power: Origins and recent developments. Journal of social issues, 49(4), 1993.
[23] Y. Saad and M. H. Schultz. Gmres: A generalized minimal residual algorithm for solving nonsymmetric
linear systems. SIAM Journal on scientific and statistical computing, 7(3):856?869, 1986.
[24] I. Valera and M. Gomez-Rodriguez. Modeling adoption and usage of competing products. In Proceedings
of the 2015 IEEE International Conference on Data Mining, 2015.
[25] Y. Wang, E. Theodorou, A. Verma, and L. Song. Steering opinion dynamics in information diffusion
networks. arXiv preprint arXiv:1603.09021, 2016.
[26] M. E. Yildiz, R. Pagliari, A. Ozdaglar, and A. Scaglione. Voting models in random networks. In Information Theory and Applications Workshop, pages 1?7, 2010.

9


----------------------------------------------------------------

title: 5793-the-population-posterior-and-bayesian-modeling-on-streams.pdf

The Population Posterior
and Bayesian Modeling on Streams

James McInerney
Columbia University
james@cs.columbia.edu

Rajesh Ranganath
Princeton University
rajeshr@cs.princeton.edu

David Blei
Columbia University
david.blei@columbia.edu

Abstract
Many modern data analysis problems involve inferences from streaming data. However, streaming data is not easily amenable to the standard probabilistic modeling
approaches, which require conditioning on finite data. We develop population
variational Bayes, a new approach for using Bayesian modeling to analyze streams
of data. It approximates a new type of distribution, the population posterior, which
combines the notion of a population distribution of the data with Bayesian inference in a probabilistic model. We develop the population posterior for latent
Dirichlet allocation and Dirichlet process mixtures. We study our method with
several large-scale data sets.

1

Introduction

Probabilistic modeling has emerged as a powerful tool for data analysis. It is an intuitive language
for describing assumptions about data and provides efficient algorithms for analyzing real data under
those assumptions. The main idea comes from Bayesian statistics. We encode our assumptions about
the data in a structured probability model of hidden and observed variables; we condition on a data
set to reveal the posterior distribution of the hidden variables; and we use the resulting posterior as
needed, for example to form predictions through the posterior predictive distribution or to explore the
data through the posterior expectations of the hidden variables.
Many modern data analysis problems involve inferences from streaming data. Examples include
exploring the content of massive social media streams (e.g., Twitter, Facebook), analyzing live video
streams, estimating the preferences of users on an online platform for recommending new items, and
predicting human mobility patterns for anticipatory computing. Such problems, however, cannot
easily take advantage of the standard approach to probabilistic modeling, which requires that we
condition on a finite data set.
This might be surprising to some readers; after all, one of the tenets of the Bayesian paradigm is that
we can update our posterior when given new information. (?Yesterday?s posterior is today?s prior.?)
But there are two problems with using Bayesian updating on data streams. The first problem is that
Bayesian inference computes posterior uncertainty under the assumption that the model is correct.
In theory this is sensible, but only in the impossible scenario where the data truly came from the
proposed model. In practice, all models provide approximations to the data-generating distribution,
and when the model is incorrect, the uncertainty that maximizes predictive likelihood may be larger or
smaller than the Bayesian posterior variance. This problem is exacerbated in potentially never-ending
streams; after seeing only a few data points, uncertainty is high, but eventually the model becomes
overconfident.
The second problem is that the data stream might change over time. This is an issue because,
frequently, our goal in applying probabilistic models to streams is not to characterize how they
change, but rather to accommodate it. That is, we would like for our current estimate of the latent
variables to be accurate to the current state of the stream and to adapt to how the stream might slowly
1

change. (This is in contrast, for example, to time series modeling.) Traditional Bayesian updating
cannot handle this. Either we explicitly model the time series, and pay a heavy inferential cost, or we
tacitly assume that the data are exchangeable, i.e., that the underlying distribution does not change.
In this paper we develop new ideas for analyzing data streams with probabilistic models. Our
approach combines the frequentist notion of the population distribution with probabilistic models and
Bayesian inference.
Main idea: The population posterior. Consider a latent variable model of ? data points. (This
is unconventional notation; we will describe why we use it below.) Following [14], we define the
model to have two kinds of hidden variables: global hidden variables ? contain latent structure that
potentially governs any data point; local hidden variables zi contain latent structure that only governs
the ith data point. Such models are defined by the joint,
?

p(? , z, x) = p(? ) ? p(xi , zi | ? ),

(1)

i=1

where x = x1:? and z = z1:? . Traditional Bayesian statistics conditions on a fixed data set x to obtain
the posterior distribution of the hidden variables p(? , z | x). As we discussed, this framework cannot
accommodate data streams. We need a different way to use the model.
We define a new distribution, the population posterior, which enables us to consider Bayesian
modeling of streams. Suppose we observe ? data points independently from the underlying population
distribution, X ? F? . This induces a posterior p(? , z | X), which is a function of the random data.
The population posterior is the expected value of this distribution,


p(? , z, X)
EF? [p(z, ? |X)] = EF?
.
(2)
p(X)
Notice that this distribution is not a function of observed data; it is a function of the population
distribution F and the data size ?. The data size is a hyperparameter that can be set; it effectively
controls the variance of the population posterior. How to best set it depends on how close the model
is to the true data distribution.
We have defined a new problem. Given an endless stream of data points coming from F and a value
for ?, our goal is to approximate the corresponding population posterior. In this paper, we will
approximate it through an algorithm based on variational inference and stochastic optimization. As
we will show, our algorithm justifies applying a variant of stochastic variational inference [14] to
a data stream. We used our method to analyze several data streams with two modern probabilistic
models, latent Dirichlet allocation [5] and Dirichlet process mixtures [11]. With held-out likelihood
as a measure of model fitness, we found our method to give better models of the data than approaches
based on full Bayesian inference [14] or Bayesian updating [8].
Related work. Researchers have proposed several methods for inference on streams of data.
Refs. [1, 9, 27] propose extending Markov chain Monte Carlo methods for streaming data. However,
sampling-based approaches do not scale to massive datasets; the variational approximation enables
more scalable inference. In variational inference, Ref. [15] propose online variational inference by
exponentially forgetting the variational parameters associated with old data. Stochastic variational
inference (SVI) [14] also decay parameters derived from old data, but interprets this in the context of
stochastic optimization. Neither of these methods applies to streaming data; both implicitly rely on
the data being of known size (even when subsampling data to obtain noisy gradients).
To apply the variational approximation to streaming data, Ref. [8] and Ref. [12] both propose
Bayesian updating of the approximating family; Ref. [22] adapts this framework to nonparametric
mixture models. Here we take a different approach, changing the variational objective to incorporate
a population distribution and then following stochastic gradients of this new objective. In Section 3
we show that this generally performs better than Bayesian updating.
Independently, Ref. [23] applied SVI to streaming data by accumulating new data points into a
growing window and then uniformly sampling from this window to update the variational parameters.
Our method justifies that approach. Further, they propose updating parameters along a trust region,
instead of following (natural) gradients, as a way of mitigating local optima. This innovation can be
incorporated into our method.
2

2

Variational Inference for the Population Posterior

We develop population variational Bayes, a method for approximating the population posterior in
Eq. 2. Our method is based on variational inference and stochastic optimization.
The F-ELBO. The idea behind variational inference is to approximate difficult-to-compute distributions through optimization [16, 25]. We introduce an approximating family of distributions over the
latent variables q(? , z) and try to find the member of q(?) that minimizes the Kullback-Leibler (KL)
divergence to the target distribution.
Population variational Bayes (VB) uses variational inference to approximate the population posterior
in Eq. 2. It aims to minimize the KL divergence from an approximating family,
q? (? , z) = arg min KL(q(? , z)||EF? [p(? , z | X)]).

(3)

q

As for the population posterior, this objective is a function of the population distribution of ? data
points F? . Notice the difference to classical VB. In classical VB, we optimize the KL divergence
between q(?) and a posterior, KL(q(? , z)||p(? , z | x); its objective is a function of a fixed data set x.
In contrast, the objective in Eq. 3 is a function of the population distribution F? .
We will use the mean-field variational family, where each latent variable is independent and governed
by a free parameter,
?

q(? , z) = q(? | ? ) ? q(zi | ?i ).

(4)

i=1

The free variational parameters are the global parameters ? and local parameters ?i . Though we
focus on the mean-field family, extensions could consider structured families [13, 20], where there is
dependence between variables.
In classical VB, where we approximate the usual posterior, we cannot compute the KL. Thus, we
optimize a proxy objective called the ELBO (evidence lower bound) that is equal to the negative KL
up to an additive constant. Maximizing the ELBO is equivalent to minimizing the KL divergence to
the posterior.
In population VB we also optimize a proxy objective, the F-ELBO. The F-ELBO is an expectation of
the ELBO under the population distribution of the data,
" "
##
?

L (? , ? ; F? ) = EF? Eq log p(? ) ? log q(? | ? ) + ? log p(Xi , Zi | ? ) ? log q(Zi )]

.

(5)

i=1

The F-ELBO is a lower bound on the population evidence log EF? [p(X)] and a lower bound on the
negative KL to the population posterior. (See Appendix A.) The inner expectation is over the latent
variables ? and Z, and is a function of the variational distribution q(?). The outer expectation is over
the ? random data points X, and is a function of the population distribution F? (?). The F-ELBO is
thus a function of both the variational distribution and the population distribution.
As we mentioned, classical VB maximizes the (classical) ELBO, which is equivalent to minimizing
the KL. The F-ELBO, in contrast, is only a bound on the negative KL to the population posterior.
Thus maximizing the F-ELBO is suggestive but is not guaranteed to minimize the KL. That said, our
studies show that this is a good quantity to optimize, and in Appendix A we show that the F-ELBO
does minimize EF? [KL(q(z||p(z, ? |X))], the population KL.
Conditionally conjugate models. In the next section we will develop a stochastic optimization
algorithm to maximize Eq. 5. First, we describe the class of models that we will work with.
Following [14] we focus on conditionally conjugate models. A conditionally conjugate model is one
where each complete conditional?the conditional distribution of a latent variable given all the other
latent variables and the observations?is in the exponential family. This class includes many models
in modern machine learning, such as mixture models, topic models, many Bayesian nonparametric
models, and some hierarchical regression models. Using conditionally conjugate models simplifies
many calculations in variational inference.
3

Under the joint in Eq. 1, we can write a conditionally conjugate model with two exponential families:

	
p(zi , xi | ? ) = h(zi , xi ) exp ? >t(zi , xi ) ? a(? )
(6)
 >
	
p(? | ? ) = h(? ) exp ? t(? ) ? a(? ) .
(7)
We overload notation for base measures h(?), sufficient statistics t(?), and log normalizers a(?). Note
that ? is the hyperparameter and that t(? ) = [? , ?a(? )] [3].
In conditionally conjugate models each complete conditional is in an exponential family, and we
use these families as the factors in the variational distribution in Eq. 4. Thus ? indexes the same
family as p(? | z, x) and ?i indexes the same family as p(zi | xi , ? ). For example, in latent Dirichlet
allocation [5], the complete conditional of the topics is a Dirichlet; the complete conditional of
the per-document topic mixture is a Dirichlet; and the complete conditional of the per-word topic
assignment is a categorical. (See [14] for details.)
Population variational Bayes. We have described the ingredients of our problem. We are given a
conditionally conjugate model, described in Eqs. 6 and 7, a parameterized variational family in Eq. 4,
and a stream of data from an unknown population distribution F. Our goal is to optimize the F-ELBO
in Eq. 5 with respect to the variational parameters.
The F-ELBO is a function of the population distribution, which is an unknown quantity. To overcome
this hurdle, we will use the stream of data from F to form noisy gradients of the F-ELBO; we then
update the variational parameters with stochastic optimization (a technique to find a local optimum
by following noisy unbiased gradients [7]).
Before describing the algorithm, however, we acknowledge one technical detail. Mirroring [14], we
optimize an F-ELBO that is only a function of the global variational parameters. The one-parameter
population VI objective is LF? (? ) = max? LF? (? , ? ). This implicitly optimizes the local parameter
as a function of the global parameter and allows us to convert the potentially infinite-dimensional
optimization problem in Eq. 5 to a finite one. The resulting objective is identical to Eq. 5, but with ?
replaced by ? (? ). (Details are in Appendix B).
The next step is to form a noisy gradient of the F-ELBO so that we can use stochastic optimization
to maximize it. Stochastic optimization maximizes an objective by following noisy and unbiased
gradients [7, 19]. We will write the gradient of the F-ELBO as an expectation with respect to F? , and
then use Monte Carlo estimates to form noisy gradients.
We compute the gradient of the F-ELBO by bringing the gradient operator inside the expectations of
Eq. 5.1 This results in a population expectation of the classical VB gradient with ? data points.
We take the natural gradient [2], which has a simple form in completely conjugate models [14].
Specifically, the natural gradient of the F-ELBO is
"
#
?
?
?? L (? ; F? ) = ? ? ? + EF? ? E?i (? ) [t(xi , Zi )] .
(8)
i=1

We approximate this expression using Monte Carlo to compute noisy, unbiased natural gradients at ? .
To form the Monte Carlo estimate, we collect ? data points from F; for each we compute the optimal
local parameters ?i (? ), which is a function of the sampled data point and variational parameters; we
then compute the quantity inside the brackets in Eq. 8. Averaging these results gives the Monte Carlo
estimate of the natural gradient. We follow the noisy natural gradient and repeat.
The algorithm is summarized in Algorithm 1. Because Eq. 8 is a Monte Carlo estimate, we are free to
draw B data points from F? (where B << ?) and rescale the sufficient statistics by ?/B. This makes
the natural gradient estimate noisier, but faster to calculate. As highlighted in [14], this strategy is
more computationally efficient because early iterations of the algorithm have inaccurate values of ? .
It is wasteful to pass through a lot of data before making updates to ? .
Discussion. Thus far, we have defined the population posterior and showed how to approximate
it with population variational inference. Our derivation justifies using an algorithm like stochastic
variational inference (SVI) [14] on a stream of data. It is nearly identical to SVI, but includes an
additional parameter: the number of data points in the population posterior ?.
1 For

most models of interest, this is justified by the dominated convergence theorem.

4

Algorithm 1 Population Variational Bayes
Randomly initialize global variational parameter ? (0)
Set iteration t ? 0
repeat
Draw data minibatch x1:B ? F?
Optimize local variational parameters ?1 (? (t) ), . . . , ?B (? (t) )
? ? L (? (t) ; F? ) [see Eq. 8]
Calculate natural gradient ?
Update global variational parameter with learning rate ? (t)
? ? L (? (t) ; F? )
? (t+1) = ? (t) + ? (t) ?B ?
Update iteration count t ? t + 1
until forever
Note we can recover the original SVI algorithm as an instance of population VI, thus reinterpreting it
as minimizing the KL divergence to the population posterior. We recover SVI by setting ? equal to
the number of data points in the data set and replacing the stream of data F with F?x , the empirical
distribution of the observations. The ?stream? in this case comes from sampling with replacement
from F?x , which results in precisely the original SVI algorithm.2
We focused on the conditionally conjugate family for convenience, i.e., the simple gradient in Eq. 8.
We emphasize, however, that by using recent tools for nonconjugate inference [17, 18, 24], we
can adapt the new ideas described above?the population posterior and the F-ELBO?outside of
conditionally conjugate models.
Finally, we analyze the population posterior distribution under the assumption the only way
the stream affects the model is through the data. Formally, this means the unobserved variables in the model and the stream F? are independent given the data X. The population posterior without the local latent variables
z (which can be marginalized out) is EF? [p(? | X)].
R
Expanding the expectation gives p(? | X)p(X | F? )dX, showing that the population posterior distribution can be written as p(? | F? ). This can be depicted as a graphical model:

F?

X

?

This means first, that the population posterior is well defined even when the model does not specify
the marginal distribution of the data and, second, rather than the classical Bayesian setting where the
posterior is conditioned on a finite fixed dataset, the population posterior is a distributional posterior
conditioned on the stream F? .

3

Empirical Evaluation

We study the performance of population variational Bayes (population VB) against SVI and streaming
variational Bayes (SVB) [8]. With large real-world data we study two models, latent Dirichlet
allocation [5] and Bayesian nonparametric mixture models, comparing the held-out predictive
performance of the algorithms. All three methods share the same local variational update, which
is the dominating computational cost. We study the data coming in a true ordered stream, and in a
permuted stream (to better match the assumptions of SVI). Across data and models, population VB
usually outperforms the existing approaches.
Models. We study two models. The first is latent Dirichlet allocation (LDA) [5]. LDA is a
mixed-membership model of text collections and is frequently used to find its latent topics. LDA
assumes that there are K topics ?k ? Dir(?), each of which is a multinomial distribution over a fixed
vocabulary. Documents are drawn by first choosing a distribution over topics ?d ? Dir(?) and then
2 This derivation of SVI is an application of Efron?s plug-in principle [10] applied to inference of the
population posterior. The plug-in principle says that we can replace the population F with the empirical
distribution of the data F? to make population inferences. In our empirical study, however, we found that
population VI often outperforms stochastic VI. Treating the data in a true stream, and setting the number of data
points different to the true number, can improve predictive accuracy.

5

held out log likelihood

Time-ordered stream
New York Times

?7.2
?7.4

Twitter
?7.4
?7.6

?7.4

?7.6

?7.8

?7.6

?7.8

2

4

6

8 10 12 14 16 18

Population-VB ?=1M
Streaming-VB [8]

?8.0
?8.2

?7.8

?8.0
0

Science
?7.2

?8.4

?8.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4

?8.6
0

10 20 30 40 50 60 70

number of documents seen (?10 )
5

held out log likelihood

Random time-permuted stream
New York Times

?7.5
?7.6

?7.0

Science

?7.3

?7.2

?7.7

?7.5

?7.4

?7.8

?7.7
?7.8

?8.0

?7.8

?8.1
0

?8.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2 1.4

2

4

6

8 10 12 14 16 18

Population-VB ?=1M
Streaming-VB [8]
SVI [15]

?7.6

?7.6

?7.9

Twitter

?7.4

?7.9

?8.0
0

10 20 30 40 50 60 70

number of documents seen (?105)

Figure 1: Held out predictive log likelihood for LDA on large-scale streamed text corpora. PopulationVB outperforms existing methods for two out of the three settings. We use the best settings of ?.
drawing each word by choosing a topic assignment zdn ? Mult(?d ) and finally choosing a word from
the corresponding topic wdn ? ?zdn . The joint distribution is
N

?

p(? , ? , z, w|?, ?) = p(? |?) ? p(?d |?) ? p(zdi |?d )p(wdi |? , zdi ).

(9)

i=1

d=1

Fixing hyperparameters, the inference problem is to estimate the conditional distribution of the topics
given a large collection of documents.
The second model is a Dirichlet process (DP) mixture [11]. Loosely, DP mixtures are mixture models
with a potentially infinite number of components; thus choosing the number of components is part
of the posterior inference problem. When using variational inference for DP mixtures [4], we take
advantage of the stick breaking representation to construct a truncated variational approximation [21].
The variables are mixture proportions ? ? Stick(?), mixture components ?k ? H(?) (for infinite k),
mixture assignments zi ? Mult(?), and observations xi ? G(?zi ). The joint is
?

p(? , ?, z, x|?, ?) = p(?|?)p(? |?) ? p(zi |?)p(xi |? , xi ).

(10)

i=1

The likelihood and prior on the components are general to the observations at hand. In our study
of real-valued data we use normal priors and normal likelihoods; in our study of text data we use
Dirichlet priors and multinomial likelihoods.
For both models we vary ?, usually fixed to the number of data points in traditional analysis.
Datasets. With LDA we analyze three large-scale streamed corpora: 1.7M articles from the New
York Times spanning 10 years, 130K Science articles written over 100 years, and 7.4M tweets
collected from Twitter on Feb 2nd, 2014. We processed them all in a similar way, choosing a
vocabulary based on the most frequent words in the corpus (with stop words removed): 8,000 for the
New York Times, 5,855 for Science, and 13,996 for Twitter. On Twitter, each tweet is a document,
and we removed duplicate tweets and tweets that did not contain at least 2 words in the vocabulary.
For each data stream, all algorithms took a few hours to process all the examples we collected.
With DP mixtures, we analyze human location behavior data. These data allow us to build periodic
models of human population mobility, with applications to disaster response and urban planning.
Such models account for periodicity by including the hour of the week as one of the dimensions of the
6

Time-ordered stream
held out log likelihood

Ivory Coast Locations

Geolife Locations

New York Times
?7.8

?6.5

0.1

?6.6

0.0

?7.9

?6.7

?0.1

?8.1

?8.0

Population-VB ?=best
Streaming-VB [8]

?8.2

?6.8

?0.2

?6.9

?0.3

?7.0
0 20 40 60 80 100 120 140 160 180

?0.4
0.00 0.05 0.10 0.15 0.20 0.25 0.30

?8.3
?8.4

?8.5
0

2

4

6

8 10 12 14 16 18

number of data points seen (?10 )
5

held out log likelihood

Random time-permuted stream
?6.70

Ivory Coast Locations

Geolife Locations

?6.72

0.1

?6.74
?6.76
?6.78

0.0

?8.1

?0.1

?8.2

?0.2

?6.80
?6.84
0 20 40 60 80 100 120 140 160 180

Population-VB ?=best
Streaming-VB [8]
SVI [15]

?8.3

?0.3

?6.82

New York Times

?8.0

?8.4

?0.4

?0.5
0.00 0.05 0.10 0.15 0.20 0.25 0.30

?8.5
0

2

4

6

8 10 12 14 16 18

number of data points seen (?105)

Figure 2: Held out predictive log likelihood for Dirichlet process mixture models on large-scale
streamed location and text data sets. Note that we apply Gaussian likelihoods in the Geolife dataset,
so the reported predictive performance is measured by probability density. We chose the best ? for
each population-VB curve.

held out log likelihood

Population-VB sensitivity to ? for LDA
New York Times

?7.60

Science

?7.65

?7.9

?7.18

?7.70

?8.0

?7.20

?7.75
?7.80
?7.85
?7.90
4

5

6

7

8

9

?7.22

?8.1

?7.26

?8.3

?7.24

?8.2

?7.28

?8.4

?7.30
4

Twitter

?7.8

?7.16

5

6

7

8

9

?8.5
4

Population-VB ?=true N

5

6

7

8

9

logarithm (base 10) of ?

held out log likelihood

Population-VB sensitivity to ? for DP-Mixture
?6.75

Ivory Coast Locations

?6.76
?6.77
?6.78
?6.79
?6.80
?6.81

?6.82
4

5

6

7

8

9 10 11 12

0.00

Geolife Locations

New York Times

?0.05

?8.0

?0.10

?8.5

?0.15

?9.0

?0.20
4

5

6

7

8

9

?9.5
3

Population-VB ?=true N

4

5

6

7

8

9

logarithm (base 10) of ?

Figure 3: We show the sensitivity of population-VB to hyperparameter ? (based on final log
likelihoods in the time-ordered stream) and find that the best setting of ? often differs from the true
number of data points (which may not be known in any case in practice).

data to be modeled. The Ivory Coast location data contains 18M discrete cell tower locations for 500K
users recorded over 6 months [6]. The Microsoft Geolife dataset contains 35K latitude-longitude
GPS locations for 182 users over 5 years. For both data sets, our observations reflect down-sampling
the data to ensure that each individual is seen no more than once every 15 minutes.
7

Results. We compare population VB with SVI [14] and SVB [8] for LDA [8] and DP mixtures [22].
SVB updates the variational approximation of the global parameter using density filtering with
exponential families. The complexity of the approximation remains fixed as the expected sufficient
statistics from minibatches observed in a stream are combined with those of the current approximation.
(Here we give the final results. We include details of how we set and fit hyperparameters below.)
We measure model fitness by evaluating the average predictive log likelihood on held-out data. This
involves splitting held-out observations (that were not involved in the posterior approximation of ? )
into two equal halves, inferring the local component distribution based on the first half, and testing
with the second half [14, 26]. For DP-mixtures, we condition on the observed hour of the week and
predict the geographic location of the held-out data point.
In standard offline studies, the held-out set is randomly selected from the data. With streams, however,
we test on the next 10K documents (for New York Times, Science), 500K tweets (for Twitter), or 25K
locations (on Geo data). This is a valid held-out set because the data ahead of the current position in
the stream have not yet been seen by the inference algorithms.
Figure 1 shows the performance for LDA. We looked at two types of streams: one in which the data
appear in order and the other in which they have been permuted (i.e., an exchangeable stream). The
time permuted stream reveals performance when each data minibatch is safely assumed to be an
i.i.d. sample from F; this results in smoother improvements to predictive likelihood. On our data, we
found that population VB outperformed SVI and SVB on two of the data sets and outperformed SVI
on all of the data. SVB performed better than population VB on Twitter.
Figure 2 shows a similar study for DP mixtures. We analyzed the human mobility data and the
New York Times. (Ref. [22] also analyzed the New York Times.) On these data population VB
outperformed SVB and SVI in all settings.3
Hyperparameters Unlike traditional Bayesian methods, the data set size ? is a hyperparameter to
population VB. It helps control the posterior variance of the population posterior. Figure 3 reports
sensitivity to ? for all studies (for the time-ordered stream). These plots indicate that the optimal
setting of ? is often different from the true number of data points; the best performing population
posterior variance is not necessarily the one implied by the data. The other hyperparameters to our
experiments are reported in Appendix C.

4

Conclusions and Future Work

We introduced the population posterior, a distribution over latent variables that combines traditional
Bayesian inference with the frequentist idea of the population distribution. With this idea, we derived
population variational Bayes, an efficient algorithm for probabilistic inference on streams. On two
complex Bayesian models and several large data sets, we found that population variational Bayes
usually performs better than existing approaches to streaming inference.
In this paper, we made no assumptions about the structure of the population distribution. Making
assumptions, such as the ability to obtain streams conditional on queries, can lead to variants of
our algorithm that learn which data points to see next during inference. Finally, understanding the
theoretical properties of the population posterior is also an avenue of interest.
Acknowledgments. We thank Allison Chaney, John Cunningham, Alp Kucukelbir, Stephan Mandt,
Peter Orbanz, Theo Weber, Frank Wood, and the anonymous reviewers for their comments. This work
is supported by NSF IIS-0745520, IIS-1247664, IIS-1009542, ONR N00014-11-1-0651, DARPA
FA8750-14-2-0009, N66001-15-C-4032, NDSEG, Facebook, Adobe, Amazon, and the Siebel Scholar
and John Templeton Foundations.
3 Though our purpose is to compare algorithms, we make one note about a specific data set. The predictive
accuracy for the Ivory Coast data set plummets after 14M data points. This is because of the data collection
policy. For privacy reasons the data set provides the cell tower locations of a randomly selected cohort of 50K
users every 2 weeks [6]. The new cohort at 14M data points behaves differently to previous cohorts in a way that
affects predictive performance. However, both algorithms steadily improve after this shock.

8

References
[1] A. Ahmed, Q. Ho, C. H. Teo, J. Eisenstein, E. P. Xing, and A. J. Smola. Online inference for the infinite
topic-cluster model: Storylines from streaming text. In International Conference on Artificial Intelligence
and Statistics, pages 101?109, 2011.
[2] S. I. Amari. Natural gradient works efficiently in learning. Neural Computation, 10(2):251?276, 1998.
[3] J. M. Bernardo and A. F. Smith. Bayesian Theory, volume 405. John Wiley & Sons, 2009.
[4] D. M. Blei, M. I. Jordan, et al. Variational inference for Dirichlet process mixtures. Bayesian Analysis,
1(1):121?143, 2006.
[5] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent Dirichlet allocation. The Journal of Machine Learning
Research, 3:993?1022, 2003.
[6] V. D. Blondel, M. Esch, C. Chan, F. Cl?rot, P. Deville, E. Huens, F. Morlot, Z. Smoreda, and C. Ziemlicki.
Data for development: the D4D challenge on mobile phone data. arXiv preprint arXiv:1210.0137, 2012.
[7] L. Bottou. Online learning and stochastic approximations. Online learning in Neural Networks, 17:9,
1998.
[8] T. Broderick, N. Boyd, A. Wibisono, A. C. Wilson, and M. Jordan. Streaming variational Bayes. In
Advances in Neural Information Processing Systems, pages 1727?1735, 2013.
[9] A. Doucet, S. Godsill, and C. Andrieu. On sequential Monte Carlo sampling methods for Bayesian filtering.
Statistics and Computing, 10(3):197?208, 2000.
[10] B. Efron and R. J. Tibshirani. An introduction to the bootstrap. CRC press, 1994.
[11] M. D. Escobar and M. West. Bayesian density estimation and inference using mixtures. Journal of the
American Statistical Association, 90(430):577?588, 1995.
[12] Z. Ghahramani and H. Attias. Online variational Bayesian learning. In Slides from talk presented at NIPS
2000 Workshop on Online learning, pages 101?109, 2000.
[13] M. D. Hoffman and D. M. Blei. Structured stochastic variational inference. In International Conference
on Artificial Intelligence and Statistics, pages 101?109, 2015.
[14] M. D. Hoffman, D. M. Blei, C. Wang, and J. Paisley. Stochastic variational inference. The Journal of
Machine Learning Research, 14(1):1303?1347, 2013.
[15] A. Honkela and H. Valpola. On-line variational Bayesian learning. In 4th International Symposium on
Independent Component Analysis and Blind Signal Separation, pages 803?808, 2003.
[16] M. I. Jordan, Z. Ghahramani, T. S. Jaakkola, and L. K. Saul. An introduction to variational methods for
graphical models. Machine learning, 37(2):183?233, 1999.
[17] D. P. Kingma and M. Welling. Auto-encoding variational Bayes. arXiv preprint arXiv:1312.6114, 2013.
[18] R. Ranganath, S. Gerrish, and D. M. Blei. Black box variational inference. In Proceedings of the
Seventeenth International Conference on Artificial Intelligence and Statistics, pages 805?813, 2014.
[19] H. Robbins and S. Monro. A stochastic approximation method. The Annals of Mathematical Statistics,
pages 400?407, 1951.
[20] L. K. Saul and M. I. Jordan. Exploiting tractable substructures in intractable networks. Advances in Neural
Information Processing Systems, pages 486?492, 1996.
[21] J. Sethuraman. A constructive definition of Dirichlet priors. Statistica Sinica, 4:639?650, 1994.
[22] A. Tank, N. Foti, and E. Fox. Streaming variational inference for Bayesian nonparametric mixture models.
In International Conference on Artificial Intelligence and Statistics, 2015.
[23] L. Theis and M. D. Hoffman. A trust-region method for stochastic variational inference with applications
to streaming data. In International Conference on Machine Learning, 2015.
[24] M. Titsias and M. L?zaro-Gredilla. Doubly stochastic variational Bayes for non-conjugate inference. In
Proceedings of the 31st International Conference on Machine Learning, pages 1971?1979, 2014.
[25] M. J. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational inference.
Foundations and Trends in Machine Learning, 1(1-2):1?305, Jan. 2008.
[26] H. Wallach, I. Murray, R. Salakhutdinov, and D. Mimno. Evaluation methods for topic models. In
International Conference on Machine Learning, 2009.
[27] L. Yao, D. Mimno, and A. McCallum. Efficient methods for topic model inference on streaming document
collections. In Conference on Knowledge Discovery and Data Mining, pages 937?946. ACM, 2009.

9


----------------------------------------------------------------

title: 5237-learning-with-fredholm-kernels.pdf

Learning with Fredholm Kernels

Qichao Que Mikhail Belkin Yusu Wang
Department of Computer Science and Engineering
The Ohio State University
Columbus, OH 43210
{que,mbelkin,yusu}@cse.ohio-state.edu

Abstract
In this paper we propose a framework for supervised and semi-supervised learning
based on reformulating the learning problem as a regularized Fredholm integral
equation. Our approach fits naturally into the kernel framework and can be interpreted as constructing new data-dependent kernels, which we call Fredholm
kernels. We proceed to discuss the ?noise assumption? for semi-supervised learning and provide both theoretical and experimental evidence that Fredholm kernels
can effectively utilize unlabeled data under the noise assumption. We demonstrate
that methods based on Fredholm learning show very competitive performance in
the standard semi-supervised learning setting.

1

Introduction

Kernel methods and methods based on integral operators have become one of the central areas of
machine learning and learning theory. These methods combine rich mathematical foundations with
strong empirical performance. In this paper we propose a framework for supervised and unsupervised learning as an inverse problem based on solving the integral equation known as the Fredholm
problem of the first kind. We develop regularization based algorithms for solving these systems
leading to what we call Fredholm kernels.
In the basic setting of supervised learning we are given the data set (xi , yi ), where xi ? X, yi ? R.
We would like to construct a function f : X ? R, such that f (xi ) ? yi and f is ?nice enough?
to generalize to new data points. This is typically done by choosing f from a class of functions (a
Reproducing Kernel Hilbert Space (RKHS) corresponding to a positive definite kernel for the kernel
methods) and optimizing a certain loss function, such as the square loss or hinge loss.
In this paper we formulate a new framework for learning based on interpreting the learning problem
as a Fredholm integral equation. This formulation shares some similarities with the usual kernel
learning framework but unlike the standard methods also allows for easy incorporation of unlabeled
data. We also show how to interpret the resulting algorithm as a standard kernel method with a
non-standard data-dependent kernel (somewhat resembling the approach taken in [13]).
We discuss reasons why incorporation of unlabeled data may be desirable, concentrating in particular on what may be termed ?the noise assumption? for semi-supervised learning, which is related
but distint from manifold and cluster assumption popular in the semi-supervised learning literature.
We provide both theoretical and empirical results showing that the Fredholm formulation allows for
efficient denoising of classifiers.
To summarize, the main contributions of the paper are as follows:
(1) We formulate a new framework based on solving a regularized Fredholm equation. The framework naturally combines labeled and unlabeled data. We show how this framework can be expressed
as a kernel method with a non-standard data-dependent kernel.
1

(2) We discuss ?the noise assumption? in semi-supervised learning and provide some theoretical evidence that Fredholm kernels are able to improve performance of classifiers under this assumption.
More specifically, we analyze the behavior of several versions of Fredholm kernels, based on combining linear and Gaussian kernels. We demonstrate that for some models of the noise assumption,
Fredholm kernel provides better estimators than the traditional data-independent kernel and thus
unlabeled data provably improves inference.
(3) We show that Fredholm kernels perform well on synthetic examples designed to illustrate the
noise assumption as well as on a number of real-world datasets.
Related work. Kernel and integral methods in machine learning have a large and diverse literature
(e.g., [12, 11]). The work most directly related to our approach is [10], where Fredholm integral
equations were introduced to address the problem of density ratio estimation and covariate shift. In
that work the problem of density ratio estimation was expressed as a Fredholm integral equation and
solved using regularization in RKHS. This setting also relates to a line of work on on kernel mean
embedding where data points are embedded in Reproducing Kernel Hilbert Spaces using integral
operators with applications to density ratio estimation and other tasks [5, 6, 7]. A very interesting
recent work [9] explores a shrinkage estimator for estimating means in RKHS, following the SteinJames estimator originally used for estimating the mean in an Euclidean space. The results obtained
in [9] show how such estimators can reduce variance. There is some similarity between that work
and our theoretical results presented in Section 4 which also show variance reduction for certain
estimators of the kernel although in a different setting. Another line of related work is the class
of semi-supervised learning techniques (see [15, 2] for a comprehensive overview) related to manifold regularization [1], where an additional graph Laplacian regularizer is added to take advantage
of the geometric/manifold structure of the data. Our reformulation of Fredholm learning as a kernel, addressing what we called ?noise assumptions?, parallels data-dependent kernels for manifold
regularization proposed in [13].

2

Fredholm Kernels

We start by formulating learning framework proposed in this paper. Suppose we are given l labeled
pairs (x1 , y1 ), . . . , (xl , yl ) from the data distribution p(x, y) defined on X ? Y and u unlabeled
points xl+1 , . . . , xl+u from the marginal distribution pX (x) on X. For simplicity we will assume
that the feature space X is a Euclidean space RD , and the label set Y is either {?1, 1} for binary
classification or the real line R for regression. Semi-supervised learning algorithms aim to construct
a (predictor) function f : X ? Y by incorporating the information of unlabeled data distribution.
To this end, we introduce the integral operator KpX associated with a kernel function k(x, z). In our
setting k(x, z) does not have to be a positive semi-definite (or even symmetric) kernel.
Z
KpX : L2 ? L2 and KpX f (x) = k(x, z)f (z)pX (z)dz,
(1)
where L2 is the space of square-integrable functions. By the law of large numbers, the above operator can be approximated using unlabeled data from pX as
l+u

Kp?X f (x) =

1 X
k(x, xi )f (xi ).
l + u i=1

This approximation provides a natural way of incorporating unlabeled data into algorithms. In our
Fredholm learning framework, we will use functions in KpX H = {KpX f : f ? H}, where H is
an appropriate Reproducing Kernel Hilbert Space (RKHS) as classification or regression functions.
Note that unlike RKHS, this space of functions, KpX H, is density dependent.
In particular, this now allows us to formulate the following optimization problem for semi-supervised
classification/regression in a way similar to many supervised learning algorithms:
The Fredholm learning framework solves the following optimization problem1 :
l

1X
((Kp?X f )(xi ) ? yi )2 + ?kf k2H ,
f ?H l
i=1

f ? = arg min
1

(2)

We will be using the square loss to simplify the exposition. Other loss functions can also be used in Eqn 2.

2

The final classifier is c(x) = (Kp?X f ? ) (x), where Kp?X is the operator defined above. Eqn 2 is a
discretized and regularized version of the Fredholm integral equation KpX f = y, thus giving the
name of Fredholm learning framework.
Even though at a first glance this setting looks similar to conventional kernel methods, the extra
layer introduced by Kp?X makes significant difference, in particular, by allowing the integration
of information from unlabeled data distribution. In contrast, solutions to standard kernel methods
for most kernels, e.g., linear, polynomial or Gaussian kernels, are completely independent of the
unlabeled data. We note that our approach is closely related to [10] where a Fredholm equation is
used to estimated the density ratio for two probability distributions.
The Fredholm learning framework is a generalization of the standard kernel framework. In fact, if
the kernel k is the ?-function, then our formulation above is equivalent to the Regularized Kernel
Pl
Least Squares equation f ? = arg minf ?H 1l i=1 (f (xi ) ? yi )2 + ?kf k2H . We could also replace
the L2 loss in Eqn 2 by other loss functions, such as hinge loss, resulting in a SVM-like classifier.
Finally, even though Eqn 2 is an optimization problem in a potentially infinite dimensional function
space H, a standard derivation, using the Representer Theorem (See full version for details), yields
a computationally accessible solution as follows:
l+u

f ? (x) =

?1 T
1 X
T
kH (x, xj )vj , v = Kl+u
Kl+u KH + ?I
Kl+u y,
l + u j=1

(3)

where (Kl+u )ij = k(xi , xj ) for 1 ? i ? l, 1 ? j ? l + u, and (KH )ij = kH (xi , xj ) for
1 ? i, j ? l + u. Note that Kl+u is a l ? (l + u) matrix.
Fredholm kernels: a convenient reformulation. In fact we will see that Fredholm learning problem induces a new data-dependent kernel, which we will refer to as Fredholm kernel2 . To show this
connection, we use the following identity, which can be easily verified:
?1 T
?1
T
T
T
Kl+u
Kl+u KH + ?I
Kl+u = Kl+u
Kl+u KH Kl+u
+ ?I
.
T
Define KF = Kl+u KH Kl+u
to be the l ? l kernel matrix associated with a new kernel defined by

k?F (x, z) =

l+u
X
1
k(x, xi )kH (xi , xj )k(z, xj ),
(l + u)2 i,j=1

(4)

and we consider the unlabeled data are fixed for computing this new kernel. Using this new kernel
k?F , the final classifying function from Eqn 3 can be rewritten as:
l+u
l
X
1 X
?1
c? (x) =
k(x, xi )f ? (xi ) =
k?F (x, xs )?s , ? = (KF + ?I) y.
l + u i=1
s=1
Because of Eqn 4 we will sometimes refer to the kernels kH and k as the ?inner? and ?outer? kernels
respectively. It can be observed that this solution is equivalent to a standard kernel method, but using
a new data dependent kernel k?F , which we will call the Fredholm kernel, since it is induced from
the Fredholm problem formulated in Eqn 2.
Proposition 1. The Fredholm kernel defined in Eqn 4 is positive semi-definite as long as KH is
positive semi-definite for any set of data x1 , . . . , xl+u .
The proof is given in the full version. The ?outer? kernel k does not have to be either positive definite
or even symmetric. When using Gaussian kernel for k, discrete approximation in Eqn 4 might be
unstable when the kernel width is small, so we also introduce the normalized Fredholm kernel,
l+u
X
k(z, xj )
k(x, xi )
P
kH (xi , xj ) P
.
(5)
k?FN (x, z) =
k(x,
x
)
n
n
n k(z, xn )
i,j=1
It is easy to check that the resulting Fredholm kernel k?FN is still symmetric positive semi-definite.
Even though Fredholm kernel was derived using L2 loss here, it could also be derived when hinge
loss is used, which will be explained in full version.
2
We note that the term Fredholm Kernel has been used in mathematics ([8], page 103) and also in a different
learning context [14]. Our usage represents a different object.

3

3

The Noise Assumption and Semi-supervised Learning

In order for unlabeled data to be useful in classification tasks it is necessary for the marginal distribution of the unlabeled data to contain information about the conditional distribution of the labels.
Several ways in which such information can be encoded has been proposed including the ?cluster
assumption? [3] and the ?manifold assumption? [1]. The cluster assumption states that a cluster (or
a high density area) contains only (or mostly) points belonging to the same class. That is, if x1 and
x2 belong to the same cluster, the corresponding labels y1 , y2 should be the same. The manifold
assumption assumes that the regression function is smooth with respect to the underlying manifold
structure of the data, which can be interpreted as saying that the geodesic distance should be used
instead of the ambient distance for optimal classification. The success of algorithms based on these
ideas indicates that these assumptions do capture certain characteristics of real data. Still, better
understanding of unlabeled data may still lead to progress in data analysis.
The noise assumption. We propose to formulate a new assumption, the ?noise assumption?, which is that in the neighborhood of every point, the directions with low variance (for
the unlabeled data) are uninformative with respect to the class labels, and can be regarded as
noise. While intuitive, as far as we know, it has
not been explicitly formulated in the context
of semi-supervised learning algorithms, nor applied to theoretical analysis.

Figure 1: Left: only labelled points, and Right:
with unlabelled points.
Note that even if the noise variance is small along a single direction, it could still significantly decrease the performance of a supervised learning algorithm if the noise is high-dimensional. These
accumulated non-informative variations in particular increase the difficulty of learning a good classifier when the amount of labeled data is small. The first figure on right illustrates the issue of noise
with two labeled points. The seemingly optimal classification boundary (the red line) differs from
the correct one (in black) due to the noisy variation along the y axis for the two labeled points.
Intuitively unlabeled data shown in the right panel of Figure 1 can be helpful in this setting as low
variance directions can be estimated locally such that algorithms could suppress the influences of
the noisy variation when learning a classifier.
Connection to cluster and manifold assumptions. The noise assumption is compatible with the
manifold assumption within the manifold+noise model. Specifically, we can assume that the functions of interest vary along the manifold and are constant in the orthogonal direction. Alternatively,
we can think of directions with high variance as ?signal/manifold? and directions with low variance as ?noise?. We note that the noise assumption does not require the data to conform to a
low-dimensional manifold in the strict mathematical sense of the word. The noise assumption is
orthogonal to the cluster assumption. For example, Figure 1 illustrates a situation where data has no
clusters but the noise assumption applies.

4

Theoretical Results for Fredholm Kernels

Non-informative variation in data could degrade traditional supervised learning algorithms. We
will now show that Fredholm kernels can be used to replace traditional kernels to inject them with
?noise-suppression? power with the help of unlabeled data. In this section we will present two views
to illustrate how such noise suppression can be achieved. Specifically, in Section 4.1) we show that
under certain setup, linear Fredholm kernel suppresses principal components with small variance.
In Section 4.2) we prove that under certain conditions we are able to provide good approximations
to the ?true? kernel on the hidden underlying space.
To make our arguments more clear, we assume that there are infinite amount of unlabelled data; that
is, we know the marginal distribution of data exactly. We will then consider the following continuous
versions of the un-normalized andZnormalized
Fredholm kernels as in Eqn 4 and 5:
Z
kFU (x, z) =
k(x, u)kH (u, v)k(z, v)p(u)p(v)dudv
Z Z
k(x, u)
k(z, v)
R
kFN (x, z) =
kH (u, v) R
p(u)p(v)dudv.
k(x, w)p(w)dw
k(z, w)p(w)dw
4

(6)
(7)

Note, in the above equations and in what follows, we sometimes write p instead of pX for the
marginal distribution when its choice is clear from context. We will typically use kF to denote
appropriate normalized or unnormalized kernels depending on the context.
4.1

Linear Fredholm kernels and inner products

For this section, we consider the unormalized Fredholm kernel, that is kF = kFU . If the ?outer?
kernel k(u, v) is linear, i.e. k(u, v) = hu, vi, the resulting Fredholm kernel can be viewed as an
inner product. Specifically, the un-normalized Fredholm kernel from Eqn 6 can be rewritten as:
Z Z
T
kF (x, z) = x ?F z, where ?F =
ukH (u, v)v T p(u)p(v)dudv.
Thus kF (x, z) is simply an inner product which depends on both the unlabeled data distribution p(x)
and the ?inner? kernel kH . This inner product re-weights the standard norm in feature space based
on variances along the principal directions of the matrix ?F . We show that for the model when unlabeled data is sampled from a normal distribution this kernel can be viewed as a ?soft thresholding?
PCA, suppressing the directions with low variance. Specifically, we have the following3


2
Theorem 2. Let kH (x, z) = exp ? kx?zk
and assume the distribution pX for unlabeled data is
2t
a single multi-variate normal distribution, N (?, diag(?12 , . . . , ?d2 )). We have
!
s


D
4
Y
?14
?D
t
T
?? + diag
,..., 2
.
?F =
2?d2 + t
2?12 + t
2?D + t
d=1

Assuming that the data is mean-subtracted, i.e. ? = 0, we see that xT ?F z re-scales the projections
along the principal components
q when computing the inner product; that is, the rescaling factor for
the i-th principal direction is

Note that this rescaling factor
?4

?2

?i4
.
2?i2 +t
?i4
?
2?i2 +t

0 when ?i2  t. On the other hand when ?i2  t, we

have that 2?2i+t ? 2i . Hence t can be considered as a soft threshold that eliminates the effects of
i
principal components with small variances. When t is small the rescaling factors are approximately
2
), in which case ?F is is proportional to the covariance matrix
proportional to diag(?12 , ?22 , . . . , ?D
T
of the data XX .
4.2

Kernel Approximation With Noise

We have seen that one special case of Fredholm kernel could achieve the effect of principal components re-scaling by using linear kernel as the ?outer? kernel k. In this section we give a more general
interpretation of noise suppression by the Fredholm kernel.
First, we give a simple senario to provide some intuition behind the definition of Fredholm kernle. Consider a standard supervised learning setting which uses the solution f ? =
Pl
arg minf ?H 1l i=1 (f (xi )?yi )2 +?kf k2H as the classifier. Let
target
kH
denote the ideal kernel that we intend to use on the clean
data, which we call the target kernel from now on. Now suppose what we have are two noisy labelled points xe and ze for
?true? data x
? and z?, i.e. xe = x
? + ?x , ze = z? + ?z . The
target
evaluation of kH
(xe , ze ) can be quite different from the true
target
signal kH
(?
x, z?), leading to an suboptimal final classifier (the
red line in Figure 1 (a)). On the other hand, now consider the
RR
Fredholm kernel from Eqn 6 (or similarly from Eqn 7): kF (xe , ze ) =
k(xe , u)p(u) ? kH (u, v) ?
k(ze , v)p(v)dudv, and set the outer kernel k to be the Gaussian kernel, and the inner kernel kH to be
target
the same as target kernel kH
. We can think of kF (xe , ze ) as an averaging of kH (u, v) over all possible pairs of data u, v, weighted by k(xe , u)p(u) and k(ze , v)p(v) respectively. Specifically, points
3

The proof of this and other results can be found in the full version.

5

that are close to xe (resp. ze ) with high density will receive larger weights. Hence the weighted
averages will be biased towards x
? and z? respectively (which presumably lie in high density regions
around xe and ze ). The value of kF (xe , ze ) tends to provide a more accurate estimate of kH (?
x, z?).
See the right figure for an illustration where the arrows indicate points with stronger influences in the
computation of kF (xe , ze ) than kH (xe , ze ). As a result, the classifier obtained using the Fredholm
kernel will also be more resilient to noise and closer to the optimum.
The Fredholm learning framework is rather flexible in terms of the choices of kernels k and kH .
In the remainder of this section, we will consider a few specific scenarios and provide quantitative
analysis to show the noise robustness of the Fredholm kernel.
Problem setup. Assume that we have a ground-truth distribution over the subspace spanned by
the first d dimension of the Euclidean space RD . We will assume that this distribution is a single Gaussian N (0, ?2 Id ). Suppose this distribution is corrupted with Gaussian noise along the orthogonal subspace of dimension D ? d. That is, for any ?true? point x
? drawn from N (0, ?2 Id ),
2
its observation xe is drawn from N (?
x, ? ID?d ). Since the noise lies in a space orthogonal
to data distribution, this means that any observed point, labelled or unlabeled, is sampled from
pX = N (0, diag(?2 Id , ? 2 ID?d ). We will show that Fredholm kernel provides a better approximation to the ?original? kernel given unlabeled data than simply computing the kernel of noisy points.
We choose this basic setting to be able to state the theoretical results in a clean manner. Even though
this is a Gaussian distribution over a linear subspace with noise, this framework has more general
implications since local neighborhoods of manifolds are (almost) linear spaces.
Note: In this section we use normalized Fredholm kernel given in Eqn 7, that is kF = kFN for now
on. Un-normalized Fredholm kernel displays similar behavior, while the bounds are trickier.
target
Linear Kernel. First we consider the case where the target kernel kH
(u, v) is the linear kernel,
target
T
kH (u, v) = u v. We will set kH in Fredholm kernel to also be linear, and k to be the Gaussian
ku?vk2

kernel k(u, v) = e? 2t We will compare kF (xe , ze ) with the target kernel on the two observed
target
target
points, that is, with kH
(xe , ze ). The goal is to estimate kH
(?
x, z?). We will see that (1) both
target
kF (xe , ze ) and (appropriately scaled) kH (xe , ze ) are unbiased estimators of kH
(?
x, z?), however (2)
target
the variance of kF (xe , ze ) is smaller than that of kH (xe , ze ), making it a more precise estimator.
Theorem 3. Suppose the probability distribution for the unlabeled data pX
=
N (0, diag(?2 Id , ? 2 ID?d )). For Fredholm kernel defined in Eqn 7, we have
!


2 2
t
+
?
target
Exe ,ze (kH
(xe , ze )) = Exe ,ze
kF (xe , ze ) = x
?T z?
?2


2
target
t+?2
kF (xe , ze ) < Varxe ,ze (kH
(xe , ze )).
Moreover, when ? > ?, Varxe ,ze
?2
Remark: Note that we have a normalization constant for the Fredholm kernel to make it an unbiased
estimator of x
?T z?. In practice, choosing normalization is subsumed in selecting the regularization
parameter for kernel methods.
Thus we can see the Fredholm kernel provides an approximation of the ?true? linear kernel, but with
smaller variance compared to the actual linear kernel on noisy data.
Gaussian Kernel.  We now consider the case where the target kernel is the Gaussian kernel:
2
target
kH
(u, v) = exp ? ku?vk
. To approximate this kernel, we will set both k and kH to be Gaus2r
sian kernels. To simplify the presentation of results, we assume that k and kH have the same kernel
width t. The resulting Fredholm kernel turns out to also be a Gaussian kernel, whose kernel width
depends on the choice of t.
Our main result is the following. Again, similar to the case of linear kernel, the Fredholm estimation
target
target
kF (xe , ze ) and kH
(xe , ze ) are both unbiased estimator for the target kH
(?
x, z?) up to a constant;
but kF (xe , ze ) has a smaller variance.
Theorem 4. Suppose the probability distribution for the unlabeled
data pX
=

2
target
N (0, diag(?2 Id , ? 2 ID?d )). Given the target kernel kH
(u, v) = exp ? ku?vk
with
ker2r
nel width r > 0, we can choose t, given by the equation
6

t(t+?2 )(t+3?2 )
?4

= r, and two scaling

constants c1 , c2 , such that
target
target
?1
Exe ,ze (c?1
x, z?).
1 kH (xe , ze )) = Exe ,ze (c2 kF (xe , ze )) = kH (?
target
?1
and when ? > ?, we have Varxe ,ze (c?1
1 kH (xe , ze )) > Varxe ,ze (c2 kF (xe , ze )).

Remark. In practice, when applying kernel methods for real world applications, optimal kernel
width r is usually unknown and chosen by cross-validation or other methods. Similarly, for our
Fredholm kernel, one can also use cross-validation to choose the optimal t for kF .

5

Experiments

Using linear and Gaussian kernel for k or kH respectively, we will define three instances of the
Fredholm kernel as follows.


2
.
(1) FredLin1: k(x, z) = xT z and kH (x, z) = exp ? kx?zk
2r


kx?zk2
T
(2) FredLin2: k(x, z) = exp ? 2r
and kH (x, z) = x z.


2
(3) FredGauss: k(x, z) = kH (x, z) = exp ? kx?zk
.
2r
For the kernels in (2) and (3) that use the Gaussian kernel as outside
kernel k we can also define their normalized version, which we will
denote by by FredLin2(N) and FredGauss(N) respectively.
2

1.5

1

0.5

0

?0.5

?1

Synthetic examples. Noise and cluster assumptions.

?1.5

?2
?1

To isolate the ability of Fredholm kernels to deal with noise from
the cluster assumption, we construct two synthetic examples that
violate the cluster assumption, shown in Figure 2. The figures show
first two dimensions, with multi-variate Gaussian noise with variance ? 2 = 0.01 in R100 added. The classification boundaries are
indicated by the color. For each class, we provide several labeled
points and large amount of unlabeled data. Note that the classification boundary in the ?circle? example is non-linear.

?0.8

?0.6

?0.4

?0.2

0

0.2

0.4

0.6

0.8

1

1.5

1

0.5

0

?0.5

?1

?1.5

?1

?0.5

0

0.5

1

1.5

We compare Fredholm kernel based classifier with RLSC (Regularized Least Squares Classifier), and two widely used semisupervised methods, the transductive support vector machine and
Noise but not
LapRLSC. Since the examples violate the cluster assumption, the Figure 2:
cluster
assumption.
Gaussian
two existing semi-supervised learning algorithms, Transductive
100
noise
in
R
is
added.
Linear
SVM and LapRLSC, should not gain much from the unlabeled data.
For TSVM, we use the primal TSVM proposed in [4], and we will (above) and non-linear (beuse the implementation of LapRLSC given in [1]. Different num- low) class boundaries.
bers of labeled points are given for each class, together with another
2000 unlabeled points. To choose the optimal parameters for each method, we pick the parameters
based on their performance on the validation set, while the final classification error is computed on
the held-out testing data set. Results are reported in Table 1 and 2, in which Fredholm kernels show
clear improvement over other methods for synthetic examples in term of classification error.
Real-world Data Sets. Unlike artificial examples, it is usually difficult to verify whether certain
assumptions are satisfied in real-world problems. In this section, we examine the performance of
Fredholm kernels on several real-world data sets and compare it with the baseline algorithms mentioned above.
Linear Kernels. Here we consider text categorization and sentiment analysis, where linear methods
are known to perform well. We use the following data (represented by TF-IDF features):
(1) 20 news group: it has 11269 documents with 20 classes, and we select the first 10 categories
for our experiment. (2) Webkb: the original data set contains 7746 documents with 7 unbalanced
classes, and we pick the two largest classes with 1511 and 1079 instances respectively. (3) IMDB
movie review: it has 1000 positive reviews and 1000 negative reviews of movie on IMDB.com. (4)
Twitter sentiment data from Sem-Eval 2013: it contains 5173 tweets, with positive, neural and negative sentiment. We combine neutral and negative classes to set up a binary classification problem.
Results are reported in Table 3. In Table4, we use WebKB as an example to illustrate the change of
the performance as number of labeled points increases.
7

Number
of Labeled
8
16
32

RLSC
10.0(? 3.9)
9.1(? 1.9)
5.8(? 3.2)

TSVM
5.2(? 2.2)
5.1(? 1.1)
4.5(? 0.8)

Methods(Linear)
LapRLSC
FredLin1
10.0(? 3.5) 3.7(? 2.6)
9.1(? 2.2) 2.9(? 2.0)
6.0(? 3.2) 2.3(? 2.3)

FredLin2(N)
4.5(? 2.1)
3.6(? 1.9)
2.6(? 2.2)

Table 1: Prediction error of different classifiers for the?two lines? example.
Number
of Labeled
16
32
64

K-RLSC
17.4(? 5.0)
16.5(? 7.1)
8.7(? 1.7)

Methods(Gaussian)
TSVM
LapRLSC
32.2(? 5.2) 17.0(? 4.6)
29.9(? 9.3) 18.0(? 6.8)
20.3(? 4.2) 9.7(? 2.0)

FredGauss(N)
7.1(? 2.4)
6.0(? 1.6)
5.5(? 0.7)

Table 2: Prediction error of different classifiers for the ?circle? example.
Gaussian Kernel. We test our methods on hand-written digit recognition. The experiment use
subsets of two handwriting digits data sets MNIST and USPS: (1) the one from MNIST contains
10k digits in total with balanced examples for each class, and the one for USPS is the original testing
set containing about 2k images. The pixel values are normalized to [0, 1] as features. Results are
reported in Table 5. In Table 6, we show that as we add additional Gaussian noise to MNIST data,
Fredholm kernels start to show significant improvement.
Data Set
Webkb
20news
IMDB
Twitter

RLSC
16.9(? 1.4)
22.2(? 1.0)
30.0(? 2.0)
38.7(? 1.1)

TSVM
12.7(? 0.8)
21.0(? 0.9)
20.2(? 2.6)
37.6(? 1.4)

Methods(Linear)
FredLin1
FredLin2
13.0(? 1.3) 12.0(? 1.6)
20.5 (? 0.7) 20.5 (?0.7)
19.9(? 2.3) 21.7(? 2.9)
37.4(? 1.2) 37.4(? 1.2)

FredLin2(N)
12.0(? 1.6)
20.5(? 0.7)
21.7(? 2.7)
37.5(? 1.2)

Table 3: The error of various methods on the text data sets. 20 labeled data per class are given with
rest of the data set as unlabeled points. Optimal parameter for each method are used.
Number
of Labeled
10
20
80

RLSC
20.7(? 2.4)
16.9(? 1.4)
10.9(? 1.4)

TSVM
13.5(? 0.5)
12.7(? 0.8)
9.7(? 1.0)

Methods(Linear)
FredLin1
FredLin2
14.8(? 2.4) 14.6(? 2.4)
13.0(? 1.3) 12.0(? 1.6)
8.1(? 1.0)
7.9(? 0.9)

FredLin2(N)
14.6(? 2.3)
12.0(? 1.6)
7.9(? 0.9)

Table 4: Prediction error on Webkb with different number of labeled points.
Data Set
USPST
MNIST

K-RLSC
11.8(? 1.4)
14.3(? 1.2)

Methods(Gaussian)
LapRLSC
FredGauss
10.2 (?0.5) 12.4(? 1.8)
8.6(? 1.2)
12.2(?1.0)

FredGauss(N)
10.8(? 1.1)
13.0(? 0.9)

Table 5: Prediction error of nonlinear classifiers on the MNIST and USPS. 20 labeled data per class
are given with rest of the data set as unlabeled points. Optimal parameter for each method are used.
Number
of Labeled
10
20
40
80

K-RLSC
34.1(? 2.1)
27.2(? 1.1)
20.0(? 0.7)
15.6(? 0.4)

Methods(Gaussian)
LapRLSC
FredGauss
35.6 (?3.5) 27.9(? 1.6)
27.3 (?1.8) 21.9(? 1.2)
20.3 (?0.8) 17.3(? 0.5)
15.6 (?0.5) 14.8(? 0.6)

FredGauss(N)
29.0(? 1.5)
22.9(? 1.2)
18.4(? 0.4)
15.4(? 0.5)

Table 6: The prediction error of nonlinear classifiers on MNIST corrupted with Gaussian noise with
standard deviation 0.3, with different numbers of labeled points, from 10 to 80. Optimal parameter
for each method are used.
Acknowledgments. The work was partially supported by NSF Grants CCF-1319406 and RI
1117707. We thank the anonymous NIPS reviewers for insightful comments.

8

References
[1] Mikhail Belkin, Partha Niyogi, and Vikas Sindhwani. Manifold regularization: A geometric
framework for learning from labeled and unlabeled examples. Journal of Machine Learning
Research, 7:2399?2434, 2006.
[2] Oliver Chapelle, Bernhard Sch?olkopf, and Alexander Zien, editors. Semi-Supervised Learning.
MIT Press, Cambridge, MA, 2006.
[3] Oliver Chapelle, Jason Weston, and Bernhard Sch?olkopf. Cluster kernels for semi-supervised
learning. In Advances in Neural Information Processing Systems 17, pages 585?592, 2003.
[4] Oliver Chapelle and Alexander Zien. Semi-supervised classification by low density separation.
In Robert G. Cowell and Zoubin Ghahramani, editors, AISTATS, pages 57?64, 2005.
[5] Arthur Gretton, Alex Smola, Jiayuan Huang, Marcel Schmittfull, Karsten Borgwardt, and
Bernhard Sch?olkopf. Covariate shift by kernel mean matching. Dataset shift in machine
learning, pages 131?160, 2009.
[6] S. Gr?unew?alder, G. Lever, L. Baldassarre, S. Patterson, A. Gretton, and M. Pontil. Conditional mean embeddings as regressors. In Proceedings of the 29th International Conference on
Machine Learning, volume 2, pages 1823?1830, 2012.
[7] Steffen Grunewalder, Gretton Arthur, and John Shawe-Taylor. Smooth operators. In Proceedings of the 30th International Conference on Machine Learning, pages 1184?1192, 2013.
[8] Michiel Hazewinkel. Encyclopaedia of Mathematics, volume 4. Springer, 1989.
[9] Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, Arthur Gretton, and Bernhard
Sch?olkopf. Kernel mean shrinkage estimators. arXiv preprint arXiv:1405.5505, 2014.
[10] Qichao Que and Mikhail Belkin. Inverse density as an inverse problem: the fredholm equation
approach. In Advances in Neural Information Processing Systems 26, pages 1484?1492, 2013.
[11] Bernhard Sch?olkopf and Alexander J Smola. Learning with kernels: Support vector machines,
regularization, optimization, and beyond. MIT press, 2001.
[12] John Shawe-Taylor and Nello Cristianini. Kernel methods for pattern analysis. Cambridge
university press, 2004.
[13] Vikas Sindhwani, Partha Niyogi, and Mikhail Belkin. Beyond the point cloud: from transductive to semi-supervised learning. In Proceedings of the 22nd International Conference on
Machine Learning, pages 824?831, New York, NY, USA, 2005. ACM Press.
[14] SVN Vishwanathan, Alexander J Smola, and Ren?e Vidal. Binet-cauchy kernels on dynamical systems and its application to the analysis of dynamic scenes. International Journal of
Computer Vision, 73(1):95?119, 2007.
[15] Xiaojin Zhu. Semi-supervised learning literature survey. Technical report, Computer Science,
University of Wisconsin-Madison, 2005.

9


----------------------------------------------------------------

title: 5365-shaping-social-activity-by-incentivizing-users.pdf

Shaping Social Activity by Incentivizing Users
Mehrdad Farajtabar?
Nan Du?
Manuel Gomez-Rodriguez?
?
Isabel Valera
Hongyuan Zha?
Le Song?
?
?
Georgia Institute of Technology
MPI for Software Systems
Univ. Carlos III in Madrid?
{mehrdad,dunan}@gatech.edu
manuelgr@mpi-sws.org
{zha,lsong}@cc.gatech.edu
ivalera@tsc.uc3m.es

Abstract
Events in an online social network can be categorized roughly into endogenous
events, where users just respond to the actions of their neighbors within the network, or exogenous events, where users take actions due to drives external to the
network. How much external drive should be provided to each user, such that the
network activity can be steered towards a target state? In this paper, we model
social events using multivariate Hawkes processes, which can capture both endogenous and exogenous event intensities, and derive a time dependent linear relation between the intensity of exogenous events and the overall network activity.
Exploiting this connection, we develop a convex optimization framework for determining the required level of external drive in order for the network to reach a
desired activity level. We experimented with event data gathered from Twitter,
and show that our method can steer the activity of the network more accurately
than alternatives.

1

Introduction

Online social platforms routinely track and record a large volume of event data, which may correspond to the usage of a service (e.g., url shortening service, bit.ly). These events can be categorized
roughly into endogenous events, where users just respond to the actions of their neighbors within
the network, or exogenous events, where users take actions due to drives external to the network.
For instance, a user?s tweets may contain links provided by bit.ly, either due to his forwarding of a
link from his friends, or due to his own initiative to use the service to create a new link.
Can we model and exploit these data to steer the online community to a desired activity level?
Specifically, can we drive the overall usage of a service to a certain level (e.g., at least twice per
day per user) by incentivizing a small number of users to take more initiatives? What if the goal is
to make the usage level of a service more homogeneous across users? What about maximizing the
overall service usage for a target group of users? Furthermore, these activity shaping problems need
to be addressed by taking into account budget constraints, since incentives are usually provided in
the form of monetary or credit rewards.
Activity shaping problems are significantly more challenging than traditional influence maximization problems, which aim to identify a set of users, who, when convinced to adopt a product, shall
influence others in the network and trigger a large cascade of adoptions [1, 2]. First, in influence
maximization, the state of each user is often assumed to be binary, either adopting a product or
not [1, 3, 4, 5]. However, such assumption does not capture the recurrent nature of product usage,
where the frequency of the usage matters. Second, while influence maximization methods identify
a set of users to provide incentives, they do not typically provide a quantitative prescription on how
much incentive should be provided to each user. Third, activity shaping concerns a larger variety of
target states, such as minimum activity and homogeneity of activity, not just activity maximization.
In this paper, we will address the activity shaping problems using multivariate Hawkes processes [6],
which can model both endogenous and exogenous recurrent social events, and were shown to be a
good fit for such data in a number of recent works (e.g., [7, 8, 9, 10, 11, 12]). More importantly,
1

we will go beyond model fitting, and derive a novel predictive formula for the overall network activity given the intensity of exogenous events in individual users, using a connection between the
processes and branching processes [13, 14, 15, 16]. Based on this relation, we propose a convex
optimization framework to address a diverse range of activity shaping problems given budget constraints. Compared to previous methods for influence maximization, our framework can provide
more fine-grained control of network activity, not only steering the network to a desired steady-state
activity level but also do so in a time-sensitive fashion. For example, our framework allows us to
answer complex time-sensitive queries, such as, which users should be incentivized, and by how
much, to steer a set of users to use a product twice per week after one month?
In addition to the novel framework, we also develop an efficient gradient based optimization algorithm, where the matrix exponential needed for gradient computation is approximated using the
truncated Taylor series expansion [17]. This algorithm allows us to validate our framework in a
variety of activity shaping tasks and scale up to networks with tens of thousands of nodes. We also
conducted experiments on a network of 60,000 Twitter users and more than 7,500,000 uses of a popular url shortening services. Using held-out data, we show that our algorithm can shape the network
behavior much more accurately than alternatives.

2

Modeling Endogenous-Exogenous Recurrent Social Events

We model the events generated by m users in a social network as a m-dimensional counting process
N (t) = (N1 (t), N2 (t), . . . , Nm (t))" , where Ni (t) records the total number of events generated by
user i up to time t. Furthermore, we represent each event as a tuple (ui , ti ), where ui is the user identity and ti is the event timing. Let the history of the process up to time t be Ht := {(ui , ti ) | ti ! t},
and Ht? be the history until just before time t. Then the increment of the process, dN (t), in an infinitesimal window [t, t + dt] is parametrized by the intensity ?(t) = (?1 (t), . . . , ?m (t))" " 0, i.e.,
E[dN (t)|Ht? ] = ?(t) dt.
(1)
Intuitively, the larger the intensity ?(t), the greater the likelihood of observing an event in the time
window [t, t + dt]. For instance, a Poisson process in [0, ?) can be viewed as a special counting
process with a constant intensity function ?, independent of time and history. To model the presence
of both endogenous and exogenous events, we will decompose the intensity into two terms
?(t)
!"#$

overall event intensity

=

?(0) (t)
! "# $

exogenous event intensity

+

?? (t)
! "# $

,

(2)

endogenous event intensity

where the exogenous event intensity models drive outside the network, and the endogenous event
intensity models interactions within the network. We assume that hosts of social platforms can
potentially drive up or down the exogenous events intensity by providing incentives to users; while
endogenous events are generated due to users? own interests or under the influence of network peers,
and the hosts do not interfere with them directly. The key questions in the activity shaping context
are how to model the endogenous event intensity which are realistic to recurrent social interactions,
and how to link the exogenous event intensity to the endogenous event intensity. We assume that the
exogenous event intensity is independent of the history and time, i.e., ?(0) (t) = ?(0) .
2.1 Multivariate Hawkes Process
Recurrent endogenous events often exhibit the characteristics of self-excitation, where a user tends
to repeat what he has been doing recently, and mutual-excitation, where a user simply follows what
his neighbors are doing due to peer pressure. These social phenomena have been made analogy to
the occurrence of earthquake [18] and the spread of epidemics [19], and can be well-captured by
multivariate Hawkes processes [6] as shown in a number of recent works (e.g., [7, 8, 9, 10, 11, 12]).
More specifically, a multivariate Hawkes process is a counting process who has a particular form
of intensity. We assume that the strength of influence between users is parameterized by a sparse
nonnegative influence matrix A = (auu! )u,u! ?[m] , where auu! > 0 means user u% directly excites
user u. We also allow A to have nonnegative diagonals to model self-excitation of a user. Then, the
intensity of the u-th dimension is
& t
%
%
?
?u (t) =
auui g(t ? ti ) =
auu!
g(t ? s) dNu! (s),
(3)
i:ti <t
u! ?[m]
0
'?
where g(s) is a nonnegative kernel function such that g(s) = 0 for s ? 0 and 0 g(s) ds <
?; the second equality is obtained by grouping events according to users and use the fact that
2

1

2
1
3

t1
3

1

2

5
4
2

1
3
5

1
5

1
6

1
5

t2

2

3

t3
3
6
5
5

6

3

4

2

2 3 1

1 2 4

t

(a) An example social network
(b) Branching structure of events
Figure 1: In Panel (a), each directed edge indicates that the target node follows, and can be influenced
by, the source node. The activity in this network is modeled using Hawkes processes, which result in
branching structure of events shown in Panel (b). Each exogenous event is the root node of a branch
(e.g., top left most red circle at t1 ), and it occurs due to a user?s own initiative; and each event can
trigger one or more endogenous events (blue square at t2 ). The new endogenous events can create
the next generation of endogenous events (green triangles at t3 ), and so forth. The social network
will constrain the branching structure of events, since an event produced by a user (e.g., user 1) can
only trigger endogenous events in the same user or one or more of her followers (e.g., user 2 or 3).
't
(
?
g(t ? s) dNu! (s) =
ui =u! ,ti <t g(t ? ti ). Intuitively, ?u (t) models the propagation of peer
0
influence over the network ? each event (ui , ti ) occurred in the neighbor of a user will boost her
intensity by a certain amount which itself decays over time. Thus, the more frequent the events
occur in the user?s neighbor, the more likely she will be persuaded to generate a new event.
For simplicity, we will focus on an exponential kernel, g(t ? ti ) = exp(??(t ? ti )) in the reminder
of the paper. However, multivariate Hawkes processes and the branching processed explained in
next section is independent of the kernel choice and can be extended to other kernels such as powerlaw, Rayleigh or any other long tailed distribution over nonnegative real domain. Furthermore, we
can rewrite equation (3) in vectorial format
& t
?
? (t) =
G(t ? s) dN (s),
(4)
0

by defining a m ? m time-varying matrix G(t) = (auu! g(t))u,u! ?[m] . Note that, for multivariate
Hawkes processes, the intensity, ?(t), itself is a random quantity, which depends on the history Ht .
We denote the expectation of the intensity with respect to history as
?(t) := EHt? [?(t)]
(5)

2.2 Connection to Branching Processes
A branching process is a Markov process that models a population in which each individual in
generation k produces some random number of individuals in generation k + 1, according some
distribution [20]. In this section, we will conceptually assign both exogenous events and endogenous
events in the multivariate Hawkes process to levels (or generations), and associate these events with
a branching structure which records the information on which event triggers which other events (see
Figure 1 for an example). Note that this genealogy of events should be interpreted in probabilistic
terms and may not be observed in actual data. Such connection has been discussed in Hawkes?
original paper on one dimensional Hawkes processes [21], and it has recently been revisited in the
context of multivariate Hawkes processes by [11]. The branching structure will play a crucial role in
deriving a novel link between the intensity of the exogenous events and the overall network activity.
More specifically, we assign all exogenous events to the zero-th generation, and record the number
of such events as N (0) (t). These exogenous events will trigger the first generation of endogenous
events whose number will be recorded as N (1) (t). Next these first generation of endogenous events
will further trigger a second generation of endogenous events N (2) (t), and so on. Then the total
number of events in the network is the sum of the numbers of events from all generations
N (t) = N (0) (t) + N (1) (t) + N (2) (t) + . . .
(k?1)
Ht
.

(6)

Furthermore, denote all events in generation k ? 1 as
Then, independently for each event
(k?1)
(ui , ti ) ? Ht
in generation k ? 1, it triggers a Poisson process in its neighbor u independently
with intensity auui g(t?ti ). Due to the superposition theorem of independent Poisson processes [22],
3

(k)

the intensity, ?u (t), of events at node u and generation k is simply the sum of conditional intensities
(
(k)
of the Poisson processes triggered by all its neighbors, i.e., ?u (t) = (ui ,ti )?H(k?1) auui g(t ?
t
't
(
(k?1)
ti ) =
(s). Concatenate the intensity for all u ? [m], and use the
u! ?[m] 0 g(t ? s) dNu!
time-varying matrix G(t) (4), we have
& t
?(k) (t) =
G(t ? s) dN (k?1) (s),
(7)
0

(k)
(k)
(?1 (t), . . . , ?m (t))"

where ? (t) =
is the intensity for counting process N (k) (t) at k-th generation. Again, due to the superposition of independent Poisson processes, we can decompose the
intensity of N (t) into a sum of conditional intensities from different generation
(k)

?(t) = ?(0) (t) + ?(1) (t) + ?(2) (t) + . . .
(8)
Next, based on the above decomposition, we will develop a closed form relation between the expected intensity ?(t) = EHt? [?(t)] and the intensity, ?(0) (t), of the exogenous events. This relation will form the basis of our activity shaping framework.

3

Linking Exogenous Event Intensity to Overall Network Activity

Our strategy is to first link the expected intensity ?(k) (t) := EHt? [?(k) (t)] of events at the k-th
generation with ?(0) (t), and then derive a close form for the infinite series sum
?(t) = ?(0) (t) + ?(1) (t) + ?(2) (t) + . . .

(9)

Define a series of auto-convolution matrices, one for each generation, with G (t) = I and
& t
G(!k) (t) =
G(t ? s) G(!k?1) (s) ds = G(t) # G(!k?1) (t)
(10)
(!0)

0

Then the expected intensity of events at the k-th generation is related to exogenous intensity ?(0) by
Lemma 1 ?(k) (t) = G(!k) (t) ?(0) .
Next, by summing together all auto-convolution matrices,
?(t) := I + G(!1) (t) + G(!2) (t) + . . .
we obtain a linear relation between the expected intensity of the network and the intensity of the
exogenous events, i.e., ?(t) = ?(t)?(0) . The entries in the matrix ?(t) roughly encode the ?influence? between pairs of users. More precisely, the entry ?uv (t) is the expected intensity of events
at node u due to a unit level of exogenous intensity at(node v. We can also derive several other
useful quantities from ?(t). For example, ??v (t) := u ?uv (t) can be thought of as the overall
influence user v has on all users. Surprisingly, for exponential kernel, the infinite sum of matrices
results in a closed form using matrix exponentials. First, let )? denote the Laplace transform of a
function, and we have the following intermediate results on the Laplace transform of G(!k) (t).
) (!k) (z) =
Lemma 2 G

'?
0

G(!k) (t) dt =

1
z

?

Ak
(z+?)k

With Lemma 2, we are in a position
* to prove our main theorem below:
+
Theorem 3 ?(t) = ?(t)?(0) = e(A??I)t + ?(A ? ?I)?1 (e(A??I)t ? I) ?(0) .
Theorem 3 provides us a linear relation between exogenous event intensity and the expected overall
intensity at any point in time but not just stationary intensity. The significance of this result is that
it allows us later to design a diverse range of convex programs to determine the intensity of the
exogenous event in order to achieve a target intensity.
In fact, we can recover the previous results in the stationary case as a special case of our general
result. More specifically, a multivariate Hawkes process is stationary if the spectral radius
,& ?
-.
& ?
/
A
? :=
G(t) dt =
g(t) dt
auu!
=
(11)
!
?
u,u ?[m]
0
0
is strictly smaller than 1 [6]. In this case, the expected intensity is ? = (I ? ?)?1 ?(0) independent
of the time. We can obtain this relation from theorem 3 if we let t ? ?.
?1
Corollary 4 ? = (I ? ?) ?(0) = limt?? ?(t) ?(0) .
Refer to Appendix A for all the proofs.
4

4

Convex Activity Shaping Framework

Given the linear relation between exogenous event intensity and expected overall event intensity, we
now propose a convex optimization framework for a variety of activity shaping tasks. In all tasks
discussed below, we will optimize the exogenous event intensity ?(0) such that the expected overall
event intensity ?(t) is maximized with respect to some concave utility U (?) in ?(t), i.e.,
maximize?(t),?(0) U (?(t))
(12)
subject to
?(t) = ?(t)?(0) , c" ?(0) ! C, ?(0) " 0
where c = (c1 , . . . , cm )" " 0 is the cost per unit event for each user and C is the total budget.
Additional regularization can also be added to ?(0) either to restrict the number of incentivized
users (with $0 norm '?(0) '0 ), or to promote a sparse solution (with $1 norm '?(0) '1 , or to obtain a
smooth solution (with $2 regularization '?(0) '2 ). We next discuss several instances of the general
framework which achieve different goals (their constraints remain the same and hence omitted).
Capped Activity Maximization. In real networks, there is an upper bound (or a cap) on the activity
each user can generate due to limited attention of a user. For example, a Twitter user typically posts
a limited number of shortened urls or retweets a limited number of tweets [23]. Suppose we know
the upper bound, ?u , on a user?s activity, i.e., how much activity each user is willing to generate.
Then we can perform the following capped activity maximization task
(
maximize?(t),?(0)
(13)
u?[m] min {?u (t), ?u }

Minimax Activity Shaping. Suppose our goal is instead maintaining the activity of each user in the
network above a certain minimum level, or, alternatively make the user with the minimum activity
as active as possible. Then, we can perform the following minimax activity shaping task
maximize?(t),?(0) minu ?u (t)
(14)
Least-Squares Activity Shaping. Sometimes we want to achieve a pre-specified target activity
levels, v, for users. For example, we may like to divide users into groups and desire a different level
of activity in each group. Inspired by these examples, we can perform the following least-squares
activity shaping task
maximize?(t),?(0) ?'B?(t) ? v'22
(15)
where B encodes potentially additional constraints (e.g., group partitions). Besides Euclidean distance, the family of Bregman divergences can be used to measure the difference between B?(t)
and v here. That is, given a function f (?) : Rm (? R convex in its argument, we can use
D(B?(t)'v) := f (B?(t)) ? f (v) ? )?f (v), B?(t) ? v+ as our objective function.
Activity Homogenization. Many other concave utility functions can be used. For example, we may
want to steer users activities to a more homogeneous profile. If we measure homogeneity of activity
with Shannon entropy, then we can perform the following activity homogenization task
(
maximize?(t),?(0) ? u?[m] ?u (t) ln ?u (t)
(16)

5

Scalable Algorithm

All the activity shaping problems defined above require an efficient evaluation of the instantaneous
average intensity ?(t) at time t, which entails computing matrix exponentials to obtain ?(t). In
small or medium networks, we can rely on well-known numerical methods to compute matrix exponentials [24]. However, in large networks, the explicit computation of ?(t) becomes intractable.
Fortunately, we can exploit the following key property of our convex activity shaping framework:
the instantaneous average intensity only depends on ?(t) through matrix-vector product operations.
In particular, we start by using Theorem 3* to rewrite the +multiplication of ?(t) and a vector v
as ?(t)v = e(A??I)t v + ?(A ? ?I)?1 e(A??I)t v ? v . We then get a tractable solution by
first computing e(A??I)t v *efficiently, subtracting
v from it, and solving a sparse linear system of
+
equations, (A ? ?I)x = e(A??I)t v ? v , efficiently. The steps are illustrated in Algorithm 1.
Next, we elaborate on two very efficient algorithms for computing the product of matrix exponential
with a vector and for solving a sparse linear system of equations.
For the computation of the product of matrix exponential with a vector, we rely on the iterative
algorithm by Al-Mohy et al. [17], which combines a scaling and squaring method with a truncated
Taylor series approximation to the matrix exponential. For solving the sparse linear system of equa5

Algorithm 1: Average Instantaneous Intensity

Algorithm 2: PGD for Activity Shaping

input : A, ?, t, v
output: ?(t)v
v1 = e(A??I)t v
v2 = v2 ? v;
v3 = (A ? ?I)?1 v2
return v1 + ?v3 ;

Initialize ?(0) ;
repeat
1- Project ?(0) into ?(0) " 0, c! ?(0) ! C;
2- Evaluate the gradient g(?(0) ) at ?(0) ;
3- Update ?(0) using the gradient g(?(0) );
until convergence;

tion, we use the well-known GMRES method [25], which is an Arnoldi process for constructing
an l2 -orthogonal basis of Krylov subspaces. The method solves the linear system by iteratively
minimizing the norm of the residual vector over a Krylov subspace.
Perhaps surprisingly, we will now show that it is possible to compute the gradient of the objective functions of all our activity shaping problems using the algorithm developed above for computing the average instantaneous intensity. We only need to define the vector v appropriately
for each problem, as follows: (i) Activity maximization: g(?(0) ) = ?(t)" v, where v is defined such that vj = 1 if ?j > ?j , and vj = 0, otherwise. (ii) Minimax activity shaping:
g(?(0) ) = ?(t)" e, where e is defined such that ej = 1 *if ?j = ?min , and
+ ej = 0, otherwise. (iii)
Least-squares activity shaping: g(?(0) ) = 2?(t)" B " B?(t)?(0) ? v . (iv) Activity homogenization: g(?(0) ) = ?(t)" ln (?(t)?(0) ) + ?(t)" 1, where ln(?) on a vector is the element-wise
natural logarithm. Since the activity maximization and the minimax activity shaping tasks require
only one evaluation of ?(t) times a vector, Algorithm 1 can be used directly. However, computing
the gradient for least-squares activity shaping and activity homogenization is slightly more involved
and it requires to be careful with the order in which we perform the operations (Refer to Appendix B
for details). Equipped with an efficient way to compute of gradients, we solve the corresponding
convex optimization problem for each activity shaping problem by applying projected gradient descent (PGD) [26] with the appropriate gradient1 . Algorithm 2 summarizes the key steps.

6

Experimental Evaluation

We evaluate our framework using both simulated and real world held-out data, and show that our
approach significantly outperforms several baselines. The appendix contains additional experiments.
Dataset description and network inference. We use data gathered from Twitter as reported in [27],
which comprises of all public tweets posted by 60,000 users during a 8-month period, from January
2009 to September 2009. For every user, we record the times she uses any of six popular url shortening services (refer to Appendix C for details). We evaluate the performance of our framework on
a subset of 2,241 active users, linked by 4,901 edges, which we call 2K dataset, and we evaluate its
scalability on the overall 60,000 users, linked by ? 200,000 edges, which we call 60K dataset. The
2K dataset accounts for 691,020 url shortened service uses while the 60K dataset accounts for ?7.5
million uses. Finally, we treat each service as independent cascades of events.
In the experiments, we estimated the nonnegative influence matrix A and the exogenous intensity
?(0) using maximum log-likelihood, as in previous work [8, 9, 12]. We used a temporal resolution
of one minute and selected the bandwidth ? = 0.1 by cross validation. Loosely speaking, ? = 0.1
corresponds to loosing 70% of the initial influence after 10 minutes, which may be explained by the
rapid rate at which each user? news feed gets updated.
Evaluation schemes. We focus on three tasks: capped activity maximization, minimax activity
shaping, and least square activity shaping. We set the total budget to C = 0.5, which corresponds
to supporting a total extra activity equal to 0.5 actions per unit time, and assume all users entail the
same cost. In the capped activity maximization, we set the upper limit of each user?s intensity, ?,
by adding a nonnegative random vector to their inferred initial intensity. In the least-squares activity
shaping, we set B = I and aim to create three user groups: less-active, moderate, and super-active.
We use three different evaluation schemes, with an increasing resemblance to a real world scenario:
Theoretical objective: We compute the expected overall (theoretical) intensity by applying Theorem 3 on the optimal exogenous event intensities to each of the three activity shaping tasks, as well
as the learned A and ?. We then compute and report the value of the objective functions.
1

For nondifferential objectives, subgradient algorithms can be used instead.

6

K

G

0

?4

4
3

0.4
0.2
0

2
0 1 2 3 4 5 6 7 8 9
logarithm of time
?4

1.2
0 1 2 3 4 5 6 7 8 9
logarithm of time

0.4
0.2
0

D

1.4

0.6

GR

1.6

0.8

LS

LSGRD

OP

1.2
0 1 2 3 4 5 6 7 8 9
logarithm of time

PROP

PR

1.4

LSASH

H

1.6

1.8 x 10

AS

LSGRD

LS

PROP

rank correlation

LSASH

Euclidean distance

?4

D

5

*

0.6

GR

GRD

LP

LP

I

2

MINMU

MU

4

UNI

6

MI
N

MMASH

UN

GRD

AS
H

LP

MM

MINMU

rank correlation

x 10
UNI

minimum activity

minimum activity

0.5

0 1 2 3 4 5 6 7 8 9
logarithm of time

0
0 1 2 3 4 5 6 7 8 9
logarithm of time
Euclidean distance

*

1

PR

0.6

?4

1.8 x 10

PRK

0.65

x 10

MMASH

DEG

0.7

0 1 2 3 4 5 6 7 8 9
logarithm of time

6

WEI

DE

0.6

XMU

U

0.65

CAM

WE
I

0.7

0.75

M

PRK

XM

DEG

CA

WEI

rank correlation

XMU

sum of users? activity

sum of users? activity

CAM

0.75

(a) Theoretical objective
(b) Simulated objective
(c) Held-out data
Figure 2: Row 1: Capped activity maximization. Row 2: Minimax activity shaping. Row 3: Leastsquares activity shaping. * means statistical significant at level of 0.01 with paired t-test between
our method and the second best
Simulated objective: We simulate 50 cascades with Ogata?s thinning algorithm [28], using the optimal exogenous event intensities to each of the three activity shaping tasks, and the learned A and ?.
We then estimate empirically the overall event intensity based on the simulated cascades, by computing a running average over non-overlapping time windows, and report the value of the objective
functions based on this estimated overall intensity. Appendix D provides a comparison between the
simulated and the theoretical objective.
Held-out data: The most interesting evaluation scheme would entail carrying out real interventions
in a social platform. However, since this is very challenging to do, instead, in this evaluation scheme,
we use held-out data to simulate such process, proceeding as follows. We first partition the 8-month
data into 50 five-day long contiguous intervals. Then, we use one interval for training and the
remaining 49 intervals for testing. Suppose interval 1 is used for training, the procedure is as follows:
(0)

1. We estimate A1 , ?1 and ?1 using the events from interval 1. Then, we fix A1 and ?1 ,
(0)
and estimate ?i for all other intervals, i = 2, . . . , 49.
(0)
2. Given A1 and ?1 , we find the optimal exogenous event intensities, ?opt , for each of the
three activity shaping task, by solving the associated convex program. We then sort the
(0)
(0)
estimated ?i (i = 2, . . . , 49) according to their similarity to ?opt , using the Euclidean
(0)

(0)

distance '?opt ? ?i '2 .
3. We estimate the overall event intensity for each of the 49 intervals (i = 2, . . . , 49), as in the
?simulated objective? evaluation scheme, and sort these intervals according to the value of
their corresponding objective function.
4. Last, we compute and report the rank correlation score between the two orderings obtained
in step 2 and 3.2 The larger the rank correlation, the better the method.
We repeat this procedure 50 times, choosing each different interval for training once, and compute
and report the average rank correlations. More details can be found in the appendix.
2

rank correlation = number of pairs with consistent ordering / total number of pairs.

7

Capped activity maximization (CAM). We compare to a number of alternatives. XMU: heuristic
based on ?(t) without optimization; DEG and WEI: heuristics based on the degree of the user;
PRANK: heuristic based on page rank (refer to Appendix C for further details). The first row of
Figure 2 summarizes the results for the three different evaluation schemes. We find that our method
(CAM) consistently outperforms the alternatives. For the theoretical objective, CAM is 11 % better
than the second best, DEG. The difference in overall users? intensity from DEG is about 0.8 which,
roughly speaking, leads to at least an increase of about 0.8 ? 60 ? 24 ? 30 = 34, 560 in the overall
number of events in a month. In terms of simulated objective and held-out data, the results are
similar and provide empirical evidence that, compared to other heuristics, degree is an appropriate
surrogate for influence, while, based on the poor performance of XMU, it seems that high activity
does not necessarily entail being influential. To elaborate on the interpretability of the real-world
experiment on held-out data, consider for example the difference in rank correlation between CAM
and DEG, which is almost 0.1. Then, roughly speaking, this means that incentivizing users based
on our approach accommodates with the ordering of real activity patterns in 0.1 ? 50?49
= 122.5
2
more pairs of realizations.
Minimax activity shaping (MMASH). We compare to a number of alternatives. UNI: heuristic
based on equal allocation; MINMU: heuristic based on ?(t) without optimization; LP: linear programming based heuristic; GRD: a greedy approach to leverage the activity (see Appendix C for
more details). The second row of Figure 2 summarizes the results for the three different evaluation
schemes. We find that our method (MMASH) consistently outperforms the alternatives. For the theoretical objective, it is about 2? better than the second best, LP. Importantly, the difference between
MMASH and LP is not trifling and the least active user carries out 2?10?4 ?60?24?30 = 4.3 more
actions in average over a month. As one may have expected, GRD and LP are the best among the
heuristics. The poor performance of MINMU, which is directly related to the objective of MMASH,
may be because it assigns the budget to a low active user, regardless of their influence. However,
our method, by cleverly distributing the budget to the users whom actions trigger many other users?
actions (like those ones with low activity), it benefits from the budget most. In terms of simulated
objective and held-out data, the algorithms? performance become more similar.
Least-squares activity shaping (LSASH). We compare to two alternatives. PROP: Assigning the
budget proportionally to the desired activity; LSGRD: greedily allocating budget according the difference between current and desired activity (refer to Appendix C for more details). The third row of
Figure 2 summarizes the results for the three different evaluation schemes. We find that our method
(LSASH) consistently outperforms the alternatives. Perhaps surprisingly, PROP, despite its simplicity, seems to perform slightly better than LSGRD. This is may be due to the way it allocates the
budget to users, e.g., it does not aim to strictly fulfill users? target activity but benefit more users by
assigning budget proportionally. Refer to Appendix E for additional experiments.
Sparsity and Activity Shaping. In some applications there is a limitation on the number of users we
can incentivize. In our proposed framework, we can handle this requirement by including a sparsity
constraint on the optimization problem. In order to maintain the convexity of the optimization
problem, we consider a l1 regularization term, where a regularization parameter ? provides the
trade-off between sparsity and the activity shaping goal. Refer to Appendix F for more details and
experimental results for different values of ?.
Scalability. The most computationally demanding part of the proposed algorithm is the evaluation of
matrix exponentials, which we scale up by utilizing techniques from matrix algebra, such as GMRES
and Al-Mohy methods. As a result, we are able to run our methods in a reasonable amount of time
on the 60K dataset, specifically, in comparison with a naive implementation of matrix exponential
evaluations. Refer to Appendix G for detailed experimental results on scalability.
Appendix H discusses the limitations of our framework and future work.
Acknowledgement. This project was supported in part by NSF IIS1116886, NSF/NIH BIGDATA
1R01GM108341, NSF CAREER IIS1350983 and Raytheon Faculty Fellowship to Le Song. Isabel Valera acknowledge the support of Plan Regional-Programas I+D of Comunidad de Madrid
(AGES-CM S2010/BMD-2422), Ministerio de Ciencia e Innovaci?on of Spain (project DEIPRO
TEC2009-14504-C02-00 and program Consolider-Ingenio 2010 CSD2008-00010 COMONSENS).

8

References
? Tardos. Maximizing the spread of influence through a social
[1] David Kempe, Jon Kleinberg, and Eva
network. In KDD, pages 137?146. ACM, 2003.
[2] Matthew Richardson and Pedro Domingos. Mining knowledge-sharing sites for viral marketing. In KDD,
pages 61?70. ACM, 2002.
[3] Wei Chen, Yajun Wang, and Siyu Yang. Efficient influence maximization in social networks. In KDD,
pages 199?208. ACM, 2009.
[4] Manuel G. Rodriguez and Bernard Sch?olkopf. Influence maximization in continuous time diffusion
networks. In ICML, 2012.
[5] Nan Du, Le Song, Manuel Gomez Rodriguez, and Hongyuan Zha. Scalable influence estimation in
continuous-time diffusion networks. In NIPS 26, 2013.
[6] Thomas .J. Liniger. Multivariate Hawkes Processes. PhD thesis, SWISS FEDERAL INSTITUTE OF
TECHNOLOGY ZURICH, 2009.
[7] Charles Blundell, Jeff Beck, and Katherine A Heller. Modelling reciprocating relationships with Hawkes
processes. In NIPS, 2012.
[8] Ke Zhou, Hongyuan Zha, and Le Song. Learning social infectivity in sparse low-rank networks using
multi-dimensional Hawkes processes. In AISTATS, 2013.
[9] Ke Zhou, Hongyuan Zha, and Le Song. Learning triggering kernels for multi-dimensional Hawkes processes. In ICML, 2013.
[10] Tomoharu Iwata, Amar Shah, and Zoubin Ghahramani. Discovering latent influence in online social
activities via shared cascade poisson processes. In KDD, pages 266?274. ACM, 2013.
[11] Scott W Linderman and Ryan P Adams. Discovering latent network structure in point process data. arXiv
preprint arXiv:1402.0914, 2014.
[12] Isabel Valera, Manuel Gomez-Rodriguez, and Krishna Gummadi. Modeling adoption of competing products and conventions in social media. arXiv preprint arXiv:1406.0516, 2014.
[13] Ian Dobson, Benjamin A Carreras, and David E Newman. A branching process approximation to cascading load-dependent system failure. In System Sciences, 2004. Proceedings of the 37th Annual Hawaii
International Conference on, pages 10?pp. IEEE, 2004.
[14] Jakob Gulddahl Rasmussen. Bayesian inference for Hawkes processes. Methodology and Computing in
Applied Probability, 15(3):623?642, 2013.
[15] Alejandro Veen and Frederic P Schoenberg. Estimation of space?time branching process models in seismology using an em?type algorithm. JASA, 103(482):614?624, 2008.
[16] Jiancang Zhuang, Yosihiko Ogata, and David Vere-Jones. Stochastic declustering of space-time earthquake occurrences. JASA, 97(458):369?380, 2002.
[17] Awad H Al-Mohy and Nicholas J Higham. Computing the action of the matrix exponential, with an
application to exponential integrators. SIAM journal on scientific computing, 33(2):488?511, 2011.
[18] David Marsan and Olivier Lengline. Extending earthquakes? reach through cascading. Science,
319(5866):1076?1079, 2008.
[19] Shuang-Hong Yang and Hongyuan Zha. Mixture of mutually exciting processes for viral diffusion. In
ICML, pages 1-9, 2013.
[20] Theodore E Harris. The theory of branching processes. Courier Dover Publications, 2002.
[21] Alan G Hawkes. Spectra of some self-exciting and mutually exciting point processes. Biometrika,
58(1):83?90, 1971.
[22] John Frank Charles Kingman. Poisson processes, volume 3. Oxford university press, 1992.
[23] Manuel Gomez-Rodriguez, Krishna Gummadi, and Bernhard Schoelkopf. Quantifying Information Overload in Social Media and its Impact on Social Contagions. In ICWSM, 2014.
[24] Gene H Golub and Charles F Van Loan. Matrix computations, volume 3. JHU Press, 2012.
[25] Youcef Saad and Martin H Schultz. Gmres: A generalized minimal residual algorithm for solving nonsymmetric linear systems. SIAM Journal on scientific and statistical computing, 7(3):856?869, 1986.
[26] Stephen Boyd and Lieven Vandenberghe. Convex Optimization. Cambridge University Press, Cambridge,
England, 2004.
[27] Meeyoung Cha, Hamed Haddadi, Fabricio Benevenuto, and P Krishna Gummadi. Measuring User Influence in Twitter: The Million Follower Fallacy. In ICWSM, 2010.
[28] Yosihiko Ogata. On lewis? simulation method for point processes. Information Theory, IEEE Transactions
on, 27(1):23?31, 1981.

9


----------------------------------------------------------------

title: 4532-learning-to-discover-social-circles-in-ego-networks.pdf

Learning to Discover Social Circles in Ego Networks

Jure Leskovec
Stanford, USA
jure@cs.stanford.edu

Julian McAuley
Stanford, USA
jmcauley@cs.stanford.edu

Abstract
Our personal social networks are big and cluttered, and currently there is no good
way to organize them. Social networking sites allow users to manually categorize
their friends into social circles (e.g. ?circles? on Google+, and ?lists? on Facebook
and Twitter), however they are laborious to construct and must be updated whenever a user?s network grows. We define a novel machine learning task of identifying users? social circles. We pose the problem as a node clustering problem on
a user?s ego-network, a network of connections between her friends. We develop
a model for detecting circles that combines network structure as well as user profile information. For each circle we learn its members and the circle-specific user
profile similarity metric. Modeling node membership to multiple circles allows us
to detect overlapping as well as hierarchically nested circles. Experiments show
that our model accurately identifies circles on a diverse set of data from Facebook,
Google+, and Twitter for all of which we obtain hand-labeled ground-truth.

1

Introduction

Online social networks allow users to follow streams of posts generated by hundreds of their friends
and acquaintances. Users? friends generate overwhelming volumes of information and to cope with
the ?information overload? they need to organize their personal social networks. One of the main
mechanisms for users of social networking sites to organize their networks and the content generated by them is to categorize their friends into what we refer to as social circles. Practically all
major social networks provide such functionality, for example, ?circles? on Google+, and ?lists? on
Facebook and Twitter. Once a user creates her circles, they can be used for content filtering (e.g. to
filter status updates posted by distant acquaintances), for privacy (e.g. to hide personal information
from coworkers), and for sharing groups of users that others may wish to follow.
Currently, users in Facebook, Google+ and Twitter identify their circles either manually, or in a
na??ve fashion by identifying friends sharing a common attribute. Neither approach is particularly
satisfactory: the former is time consuming and does not update automatically as a user adds more
friends, while the latter fails to capture individual aspects of users? communities, and may function
poorly when profile information is missing or withheld.
In this paper we study the problem of automatically discovering users? social circles. In particular,
given a single user with her personal social network, our goal is to identify her circles, each of which
is a subset of her friends. Circles are user-specific as each user organizes her personal network of
friends independently of all other users to whom she is not connected. This means that we can
formulate the problem of circle detection as a clustering problem on her ego-network, the network
of friendships between her friends. In Figure 1 we are given a single user u and we form a network
between her friends vi . We refer to the user u as the ego and to the nodes vi as alters. The task then
is to identify the circles to which each alter vi belongs, as in Figure 1. In other words, the goal is to
find nested as well as overlapping communities/clusters in u?s ego-network.
Generally, there are two useful sources of data that help with this task. The first is the set of edges
of the ego-network. We expect that circles are formed by densely-connected sets of alters [20].
1

Figure 1: An ego-network with labeled circles. This network shows typical behavior that we observe in our data: Approximately 25% of our ground-truth circles (from Facebook) are contained
completely within another circle, 50% overlap with another circle, and 25% of the circles have no
members in common with any other circle. The goal is to discover these circles given only the
network between the ego?s friends. We aim to discover circle memberships and to find common
properties around which circles form.
However, different circles overlap heavily, i.e., alters belong to multiple circles simultaneously [1,
21, 28, 29], and many circles are hierarchically nested in larger ones (Figure 1). Thus it is important
to model an alter?s memberships to multiple circles. Secondly, we expect that each circle is not only
densely connected but its members also share common properties or traits [18, 28]. Thus we need
to explicitly model different dimensions of user profiles along which each circle emerges.
We model circle affiliations as latent variables, and similarity between alters as a function of common profile information. We propose an unsupervised method to learn which dimensions of profile
similarity lead to densely linked circles. Our model has two innovations: First, in contrast to mixedmembership models [2] we predict hard assignment of a node to multiple circles, which proves
critical for good performance. Second, by proposing a parameterized definition of profile similarity, we learn the dimensions of similarity along which links emerge. This extends the notion of
homophily [12] by allowing different circles to form along different social dimensions, an idea related to the concept of Blau spaces [16]. We achieve this by allowing each circle to have a different
definition of profile similarity, so that one circle might form around friends from the same school,
and another around friends from the same location. We learn the model by simultaneously choosing
node circle memberships and profile similarity functions so as to best explain the observed data.
We introduce a dataset of 1,143 ego-networks from Facebook, Google+, and Twitter, for which we
obtain hand-labeled ground-truth from 5,636 different circles.1 Experimental results show that by
simultaneously considering social network structure as well as user profile information our method
performs significantly better than natural alternatives and the current state-of-the-art. Besides being
more accurate our method also allows us to generate automatic explanations of why certain nodes
belong to common communities. Our method is completely unsupervised, and is able to automatically determine both the number of circles as well as the circles themselves.
Further Related Work. Topic-modeling techniques have been used to uncover ?mixedmemberships? of nodes to multiple groups [2], and extensions allow entities to be attributed with
text information [3, 5, 11, 13, 26]. Classical algorithms tend to identify communities based on node
features [9] or graph structure [1, 21], but rarely use both in concert. Our work is related to [30] in
the sense that it performs clustering on social-network data, and [23], which models memberships
to multiple communities. Finally, there are works that model network data similar to ours [6, 17],
though the underlying models do not form communities. As we shall see, our problem has unique
characteristics that require a new model. An extended version of our article appears in [15].

2

A Generative Model for Friendships in Social Circles

We desire a model of circle formation with the following properties: (1) Nodes within circles should
have common properties, or ?aspects?. (2) Different circles should be formed by different aspects,
e.g. one circle might be formed by family members, and another by students who attended the same
university. (3) Circles should be allowed to overlap, and ?stronger? circles should be allowed to form
within ?weaker? ones, e.g. a circle of friends from the same degree program may form within a circle
1

http://snap.stanford.edu/data/

2

from the same university, as in Figure 1. (4) We would like to leverage both profile information and
network structure in order to identify the circles. Ideally we would like to be able to pinpoint which
aspects of a profile caused a circle to form, so that the model is interpretable by the user.
The input to our model is an ego-network G = (V, E), along with ?profiles? for each user v ? V .
The ?center? node u of the ego-network (the ?ego?) is not included in G, but rather G consists only of
u?s friends (the ?alters?). We define the ego-network in this way precisely because creators of circles
do not themselves appear in their own circles. For each ego-network, our goal is to predict a set of
circles C = {C1 . . . CK }, Ck ? V , and associated parameter vectors ?k that encode how each circle
emerged. We encode ?user profiles? into pairwise features ?(x, y) that in some way capture what
properties the users x and y have in common. We first describe our model, which can be applied
using arbitrary feature vectors ?(x, y), and in Section 5 we describe several ways to construct feature
vectors ?(x, y) that are suited to our particular application.
We describe a model of social circles that treats circle memberships as latent variables. Nodes within
a common circle are given an opportunity to form an edge, which naturally leads to hierarchical and
overlapping circles. We will then devise an unsupervised algorithm to jointly optimize the latent
variables and the profile similarity parameters so as to best explain the observed network data.
Our model of social circles is defined as follows. Given an ego-network G and a set of K circles
C = {C1 . . . CK }, we model the probability that a pair of nodes (x, y) ? V ? V form an edge as
(
)
X
X
p((x, y) ? E) ? exp
h?(x, y), ?k i ?
?k h?(x, y), ?k i .
(1)
Ck ?{x,y}

|

Ck +{x,y}

{z

}

|

circles containing both nodes

{z

all other circles

}

For each circle Ck , ?k is the profile similarity parameter that we will learn. The idea is that
h?(x, y), ?k i is high if both nodes belong to Ck , and low if either of them do not (?k trades-off
these two effects). Since the feature vector ?(x, y) encodes the similarity between the profiles of
two users x and y, the parameter vector ?k encodes what dimensions of profile similarity caused the
circle to form, so that nodes within a circle Ck should ?look similar? according to ?k .
Considering that edges e = (x, y) are generated independently, we can write the probability of G as
Y
Y
P? (G; C) =
p(e ? E) ?
p(e ?
/ E),
(2)
e6?E

e?E

where ? = {(?k , ?k )}

k=1...K

is our set of model parameters. Defining the shorthand notation
X
dk (e) = ?(e ? Ck ) ? ?k ?(e ?
/ Ck ), ?(e) =
dk (e) h?(e), ?k i
Ck ?C

allows us to write the log-likelihood of G:


X
X
l? (G; C) =
?(e) ?
log 1 + e?(e) .

(3)

e?V ?V

e?E

Next, we describe how to optimize node circle memberships C as well as the parameters of the user
profile similarity functions ? = {(?k , ?k )} (k = 1 . . . K) given a graph G and user profiles.

3

Unsupervised Learning of Model Parameters

??
? = {?,
Treating circles C as latent variables, we aim to find ?
? } so as to maximize the regularized
log-likelihood of (eq. 3), i.e.,
? C? = argmax l? (G; C) ? ??(?).
?,
(4)
?,C

We solve this problem using coordinate ascent on ? and C [14]:
Ct
?t+1

=

argmax l?t (G; C)

(5)

=

argmax l? (G; C t ) ? ??(?).

(6)

C

?

3

Noting that (eq. 3) is concave in ?, we optimize (eq. 6) through gradient ascent, where partial derivatives are given by
?l
??k

=

?l
??k

=

X

?de (k)?k

e?V ?V

X

X
e?(e)
??
+
dk (e)?k ?
??k
1 + e?(e) e?E

?(e ?
/ Ck ) h?(e), ?k i

e?V ?V

X
e?(e)
?
?(e ?
/ Ck ) h?(e), ?k i .
?(e)
1+e
e?E

For fixed C \ Ci we note that solving argmaxCi l? (G; C \ Ci ) can be expressed as pseudo-boolean
optimization in a pairwise graphical model [4], i.e., it can be written as
X
Ck = argmax
E(x,y) (?(x ? C), ?(y ? C)).
(7)
C

(x,y)?V ?V

In words, we want edges with high weight
P(under ?k ) to appear in Ck , and edges with low weight to
appear outside of Ck . Defining ok (e) = Ck ?C\Ci dk (e) h?(e), ?k i the energy Ee of (eq. 7) is
Ee (0, 0) = Ee (0, 1) = Ee (1, 0)
Ee (1, 1)

=

?

ok (e) ? ?k h?(e), ?k i ? log(1 + eok (e)??k h?(e),?k i ),
? log(1 + eok (e)??k h?(e),?k i ),

=

?

ok (e) + h?(e), ?k i ? log(1 + eok (e)+h?(e),?k i ),
? log(1 + eok (e)+h?(e),?k i ),

e?E
e?
/E

e?E
.
e?
/E

By expressing the problem in this form we can draw upon existing work on pseudo-boolean optimization. We use the publicly-available ?QPBO? software described in [22], which is able to
accurately approximate problems of the form shown in (eq. 7). We solve (eq. 7) for each Ck in a
random order.
The two optimization steps of (eq. 5) and (eq. 6) are repeated until convergence, i.e., until C t+1 = C t .
PK P|?k |
We regularize (eq. 4) using the `1 norm, i.e., ?(?) = k=1 i=1
|?ki |, which leads to sparse (and
readily interpretable) parameters. Since ego-networks are naturally relatively small, our algorithm
can readily handle problems at the scale required. In the case of Facebook, the average ego-network
has around 190 nodes [24], while the largest network we encountered has 4,964 nodes. Note that
since the method is unsupervised, inference is performed independently for each ego-network. This
means that our method could be run on the full Facebook graph (for example), as circles are independently detected for each user, and the ego-networks typically contain only hundreds of nodes.
Hyperparameter estimation. To choose the optimal number of circles, we choose K so as to
minimize an approximation to the Bayesian Information Criterion (BIC) [2, 8, 25],
? = argmin BIC (K; ?K )
K

(8)

K

where ?K is the set of parameters predicted for a particular number of communities K, and
BIC (K; ?K ) ' ?2l?K (G; C) + |?K | log |E|.

(9)

The regularization parameter ? ? {0, 1, 10, 100} was determined using leave-one-out cross validation, though in our experience did not significantly impact performance.

4

Dataset Description

Our goal is to evaluate our unsupervised method on ground-truth data. We expended significant time,
effort, and resources to obtain high quality hand-labeled data.2 We were able to obtain ego-networks
and ground-truth from three major social networking sites: Facebook, Google+, and Twitter.
From Facebook we obtained profile and network data from 10 ego-networks, consisting of 193 circles and 4,039 users. To do so we developed our own Facebook application and conducted a survey
of ten users, who were asked to manually identify all the circles to which their friends belonged. On
average, users identified 19 circles in their ego-networks, with an average circle size of 22 friends.
Examples of such circles include students of common universities, sports teams, relatives, etc.
2

http://snap.stanford.edu/data/

4

?rst name

Alan

last name

Turing

position
company
name

work

type
name

education

type
?rst name

Dilly

last name

Knox

position
company
position

work

education

company
name
type

Cryptanalyst
GC&CS
Cambridge
College

1 ? ?x,y

Princeton
Graduate School
Cryptanalyst
GC&CS
Cryptanalyst
Royal Navy

0

1 ? ?x,y

Cambridge
College

203first name : Dilly
607last name : Knox
607first name : Alan
6 7
607last name : Turing
6 7
617work : position : Cryptanalyst
6 7
7
=6
617work : location : GC &CS
607work : location : Royal Navy
6 7
617education : name : Cambridge
6 7
617education : type : College
4 5
0 education : name : Princeton
0 education : type : Graduate School
2 3
0 first name
607last name
6 7
617work : position
=6 7
617work : location
415education : name
1 education : type

Figure 2: Feature construction. Profiles are tree-structured, and we construct features by comparing paths in those trees. Examples of trees for two users x (blue) and y (pink) are shown at
left. Two schemes for constructing feature vectors from these profiles are shown at right: (1) (top
right) we construct binary indicators measuring the difference between leaves in the two trees, e.g.
?work?position?Cryptanalyst? appears in both trees. (2) (bottom right) we sum over the leaf nodes
in the first scheme, maintaining the fact that the two users worked at the same institution, but discarding the identity of that institution.
For the other two datasets we obtained publicly accessible data. From Google+ we obtained data
from 133 ego-networks, consisting of 479 circles and 106,674 users. The 133 ego-networks represent all 133 Google+ users who had shared at least two circles, and whose network information
was publicly accessible at the time of our crawl. The Google+ circles are quite different to those
from Facebook, in the sense that their creators have chosen to release them publicly, and because
Google+ is a directed network (note that our model can very naturally be applied to both to directed
and undirected networks). For example, one circle contains candidates from the 2012 republican
primary, who presumably do not follow their followers, nor each other. Finally, from Twitter we
obtained data from 1,000 ego-networks, consisting of 4,869 circles (or ?lists? [10, 19, 27, 31]) and
81,362 users. The ego-networks we obtained range in size from 10 to 4,964 nodes.
Taken together our data contains 1,143 different ego-networks, 5,541 circles, and 192,075 users.
The size differences between these datasets simply reflects the availability of data from each of the
three sources. Our Facebook data is fully labeled, in the sense that we obtain every circle that a
user considers to be a cohesive community, whereas our Google+ and Twitter data is only partially
labeled, in the sense that we only have access to public circles. We design our evaluation procedure
in Section 6 so that partial labels cause no issues.

5

Constructing Features from User Profiles

Profile information in all of our datasets can be represented as a tree where each level encodes
increasingly specific information (Figure 2, left). From Google+ we collect data from six categories
(gender, last name, job titles, institutions, universities, and places lived). From Facebook we collect
data from 26 categories, including hometowns, birthdays, colleagues, political affiliations, etc. For
Twitter, many choices exist as proxies for user profiles; we simply collect data from two categories,
namely the set of hashtags and mentions used by each user during two-weeks? worth of tweets.
?Categories? correspond to parents of leaf nodes in a profile tree, as shown in Figure 2.
We first describe a difference vector to encode the relationship between two profiles. A non-technical
description is given in Figure 2. Suppose that users v ? V each have an associated profile tree Tv ,
and that l ? Tv is a leaf in that tree. We define the difference vector ?x,y between two users x and y
as a binary indicator encoding the profile aspects where users x and y differ (Figure 2, top right):
?x,y [l] = ?((l ? Tx ) 6= (l ? Ty )).
(10)
Note that feature descriptors are defined per ego-network: while many thousands of high schools
(for example) exist among all Facebook users, only a small number appear among any particular
user?s friends.
Although the above difference vector has the advantage that it encodes profile information at a fine
granularity, it has the disadvantage that it is high-dimensional (up to 4,122 dimensions in the data
5

we considered). One way to address this is to form difference vectors based on the parents of leaf
nodes: this way, we encode what profile categories two users have in common, but disregard specific
values (Figure 2, bottom right). For example, we encode how many hashtags two users tweeted in
common, but discard which hashtags they tweeted:
P
0
?x,y
[p] = l?children(p) ?x,y [l].
(11)
This scheme has the advantage that it requires a constant number of dimensions, regardless of the
size of the ego-network (26 for Facebook, 6 for Google+, 2 for Twitter, as described above).
0
Based on the difference vectors ?x,y (and ?x,y
) we now describe how to construct edge features
?(x, y). The first property we wish to model is that members of circles should have common relationships with each other:
?1 (x, y) = (1; ??x,y ).
(12)
The second property we wish to model is that members of circles should have common relationships
to the ego of the ego-network. In this case, we consider the profile tree Tu from the ego user u. We
then define our features in terms of that user:


?2 (x, y) = (1; ??x,u ? ?y,u )
(13)

(|?x,u ? ?y,u | is taken elementwise). These two parameterizations allow us to assess which mechanism better captures users? subjective definition of a circle. In both cases, we include a constant feature (?1?), which controls the probability that edges form within circles, or equivalently it measures
the extent to which circles are made up of friends. Importantly, this allows us to predict memberships
even for users who have no profile information, simply due to their patterns of connectivity.
0
, we define
Similarly, for the ?compressed? difference vector ?x,y
 0

0
0 
? ?y,u
).
? 1 (x, y) = (1; ??x,y
), ? 2 (x, y) = (1; ??x,u

(14)

To summarize, we have identified four ways of representing the compatibility between different
aspects of profiles for two users. We considered two ways of constructing a difference vector (?x,y
0
) and two ways of capturing the compatibility of a pair of profiles (?(x, y) vs. ?(x, y)).
vs. ?x,y

6

Experiments

Although our method is unsupervised, we can evaluate it on ground-truth data by examining the
maximum-likelihood assignments of the latent circles C = {C1 . . . CK } after convergence. Our
goal is that for a properly regularized model, the latent variables will align closely with the human
labeled ground-truth circles C? = {C?1 . . . C?K? }.
Evaluation metrics. To measure the alignment between a predicted circle C and a ground-truth
? we compute the Balanced Error Rate (BER) between the two circles [7], BER(C, C)
? =
circle
 C,

?
?
|C\
C|
|
C\C|
1
. This measure assigns equal importance to false positives and false negatives,
?
2
|C| + |C|
so that trivial or random predictions incur an error of 0.5 on average. Such a measure is preferable to
the 0/1 loss (for example), which assigns extremely low error to trivial predictions. We also report
the F1 score, which we find produces qualitatively similar results.
Aligning predicted and ground-truth circles. Since we do not know the correspondence between
? we compute the optimal match via linear assignment by maximizing:
circles in C and C,
1 X
max
(1 ? BER(C, f (C))),
(15)
?
f :C?C |f |
C?dom(f )

? That is, if the number of predicted circles |C|
where f is a (partial) correspondence between C and C.
? then every circle C ? C must have a match C? ? C,
?
is less than the number of ground-truth circles |C|,
?
but if |C| > |C|, we do not incur a penalty for additional predictions that could have been circles
but were not included in the ground-truth. We use established techniques to estimate the number of
? = |C|, nor can any
circles, so that none of the baselines suffers a disadvantage by mispredicting K
method predict the ?trivial? solution of returning the powerset of all users. We note that removing the
bijectivity requirement (i.e., forcing all circles to be aligned by allowing multiple predicted circles
to match a single groundtruth circle or vice versa) lead to qualitatively similar results.
6

Accuracy (1 - BER)
Accuracy (F1 score)

Accuracy on detected communities (1 - Balanced Error Rate, higher is better)

1.0

multi-assignment clustering (Streich, Frank, et al.)
low-rank embedding (Yoshida)
block-LDA (Balasubramanyan and Cohen)

.84
.77
.72

.72

.70

.70

our model (friend-to-friend features ?1 , eq. 12)
our model (friend-to-user features ?2 , eq. 13)
our model (compressed features ? 1 , eq. 14)

0.5

our model (compressed features ? 2 , eq. 14)

Facebook

Twitter

Google+

Accuracy on detected communities (F1 score, higher is better)

1.0

multi-assignment clustering (Streich, Frank, et al.)
low-rank embedding (Yoshida)
block-LDA (Balasubramanyan and Cohen)

.59
.40

.38

.38

.34

.34

our model (friend-to-friend features ?1 , eq. 12)
our model (friend-to-user features ?2 , eq. 13)
our model (compressed features ? 1 , eq. 14)

0.0

our model (compressed features ? 2 , eq. 14)

Facebook

Google+

Twitter

Figure 3: Performance on Facebook, Google+, and Twitter, in terms of the Balanced Error Rate
(top), and the F1 score (bottom). Higher is better. Error bars show standard error. The improvement
of our best features ?1 compared to the nearest competitor are significant at the 1% level or better.

Baselines. We considered a wide number of baseline methods, including those that consider only
network structure, those that consider only profile information, and those that consider both. First
we experimented with Mixed Membership Stochastic Block Models [2], which consider only network information, and variants that also consider text attributes [5, 6, 13]. For each node, mixedmembership models predict a stochastic vector encoding partial circle memberships, which we
threshold to generate ?hard? assignments. We also considered Block-LDA [3], where we generate
?documents? by treating aspects of user profiles as words in a bag-of-words model.
Secondly, we experimented with classical clustering algorithms, such as K-means and Hierarchical
Clustering [9], that form clusters based only on node profiles, but ignore the network. Conversely we
considered Link Clustering [1] and Clique Percolation [21], which use network information, but ignore profiles. We also considered the Low-Rank Embedding approach of [30], where node attributes
and edge information are projected into a feature space where classical clustering techniques can
be applied. Finally we considered Multi-Assignment Clustering [23], which is promising in that it
predicts hard assignments to multiple clusters, though it does so without using the network.
Of the eight baselines highlighted above we report the three whose overall performance was the best,
namely Block-LDA [3] (which slightly outperformed mixed membership stochastic block models
[2]), Low-Rank Embedding [30], and Multi-Assignment Clustering [23].
Performance on Facebook, Google+, and Twitter Data. Figure 3 shows results on our Facebook,
Google+, and Twitter data. Circles were aligned as described in (eq. 15), with the number of circles
? determined as described in Section 3. For non-probabilistic baselines, we chose K
? so as to
K
maximize the modularity, as described in [20]. In terms of absolute performance our best model
?1 achieves BER scores of 0.84 on Facebook, 0.72 on Google+ and 0.70 on Twitter (F1 scores are
0.59, 0.38, and 0.34, respectively). The lower F1 scores on Google+ and Twitter are explained by the
fact that many circles have not been maintained since they were initially created: we achieve high
recall (we recover the friends in each circle), but at low precision (we recover additional friends who
appeared after the circle was created).
Comparing our method to baselines we notice that we outperform all baselines on all datasets by a
statistically significant margin. Compared to the nearest competitors, our best performing features
?1 improve on the BER by 43% on Facebook, 26% on Google+, and 16% on Twitter (improvements
in terms of the F1 score are similar). Regarding the performance of the baseline methods, we
note that good performance seems to depend critically on predicting hard memberships to multiple
circles, using a combination of node and edge information; none of the baselines exhibit precisely
this combination, a shortcoming our model addresses.
Both of the features we propose (friend-to-friend features ?1 and friend-to-user features ?2 ) perform
similarly, revealing that both schemes ultimately encode similar information, which is not surprising,
7

studied the same degree
speak the same languages

feature index for ?i1

Americans

weight ?4,i

1

feature index for ?1i
weight ?2,i

weight ?1,i

feature index for ?1i

1

Germans
who went to school in 1997

1

1
studied the same degree

feature index for ?i1

1
same level of education

feature index for ?i1

college educated people
working at a particular institute

feature index for ?1i

feature index for ?1i
weight ?4,i

living in S.F. or Stanford

1

weight ?3,i

people with PhDs

weight ?3,i

1

weight ?2,i

weight ?1,i

Figure 4: Three detected circles on a small ego-network from Facebook, compared to three groundtruth circles (BER ' 0.81). Blue nodes: true positives. Grey: true negatives. Red: false positives.
Yellow: false negatives. Our method correctly identifies the largest circle (left), a sub-circle contained within it (center), and a third circle that significantly overlaps with it (right).

1

worked for the same employer
at the same time

feature index for ?i1

Figure 5: Parameter vectors of four communities for a particular Facebook user. The top four plots
show ?complete? features ?1 , while the bottom four plots show ?compressed? features ? 1 (in both
cases, BER ' 0.78). For example the former features encode the fact that members of a particular
community tend to speak German, while the latter features encode the fact that they speak the same
language. (Personally identifiable annotations have been suppressed.)
since users and their friends have similar profiles. Using the ?compressed? features ? 1 and ? 2 does
not significantly impact performance, which is promising since they have far lower dimension than
the full features; what this reveals is that it is sufficient to model categories of attributes that users
have in common (e.g. same school, same town), rather than the attribute values themselves.
We found that all algorithms perform significantly better on Facebook than on Google+ or Twitter.
There are a few explanations: Firstly, our Facebook data is complete, in the sense that survey participants manually labeled every circle in their ego-networks, whereas in other datasets we only observe
publicly-visible circles, which may not be up-to-date. Secondly, the 26 profile categories available
from Facebook are more informative than the 6 categories from Google+, or the tweet-based profiles
we build from Twitter. A more basic difference lies in the nature of the networks themselves: edges
in Facebook encode mutual ties, whereas edges in Google+ and Twitter encode follower relationships, which changes the role that circles serve [27]. The latter two points explain why algorithms
that use either edge or profile information in isolation are unlikely to perform well on this data.
Qualitative analysis. Finally we examine the output of our model in greater detail. Figure 4 shows
results of our method on an example ego-network from Facebook. Different colors indicate true-,
false- positives and negatives. Our method is correctly able to identify overlapping circles as well
as sub-circles (circles within circles). Figure 5 shows parameter vectors learned for four circles for
a particular Facebook user. Positive weights indicate properties that users in a particular circle have
in common. Notice how the model naturally learns the social dimensions that lead to a social circle.
Moreover, the first parameter that corresponds to a constant feature ?1? has the highest weight; this
reveals that membership to the same community provides the strongest signal that edges will form,
while profile data provides a weaker (but still relevant) signal.
Acknowledgements. This research has been supported in part by NSF IIS-1016909, CNS-1010921,
IIS-1159679, DARPA XDATA, DARPA GRAPHS, Albert Yu & Mary Bechmann Foundation, Boeing, Allyes, Samsung, Intel, Alfred P. Sloan Fellowship and the Microsoft Faculty Fellowship.

8

References
[1] Y.-Y. Ahn, J. Bagrow, and S. Lehmann. Link communities reveal multiscale complexity in networks.
Nature, 2010.
[2] E. Airoldi, D. Blei, S. Fienberg, and E. Xing. Mixed membership stochastic blockmodels. JMLR, 2008.
[3] R. Balasubramanyan and W. Cohen. Block-LDA: Jointly modeling entity-annotated text and entity-entity
links. In SDM, 2011.
[4] E. Boros and P. Hammer. Pseudo-boolean optimization. Discrete Applied Mathematics, 2002.
[5] J. Chang and D. Blei. Relational topic models for document networks. In AIStats, 2009.
[6] J. Chang, J. Boyd-Graber, and D. Blei. Connections between the lines: augmenting social networks with
text. In KDD, 2009.
[7] Y. Chen and C. Lin. Combining SVMs with various feature selection strategies. Springer, 2006.
[8] M. Handcock, A. Raftery, and J. Tantrum. Model-based clustering for social networks. Journal of the
Royal Statistical Society Series A, 2007.
[9] S. Johnson. Hierarchical clustering schemes. Psychometrika, 1967.
[10] D. Kim, Y. Jo, L.-C. Moon, and A. Oh. Analysis of twitter lists as a potential source for discovering latent
characteristics of users. In CHI, 2010.
[11] P. Krivitsky, M. Handcock, A. Raftery, and P. Hoff. Representing degree distributions, clustering, and
homophily in social networks with latent cluster random effects models. Social Networks, 2009.
[12] P. Lazarsfeld and R. Merton. Friendship as a social process: A substantive and methodological analysis.
In Freedom and Control in Modern Society. 1954.
[13] Y. Liu, A. Niculescu-Mizil, and W. Gryc. Topic-link LDA: joint models of topic and author community.
In ICML, 2009.
[14] D. MacKay. Information Theory, Inference and Learning Algorithms. Cambrdige University Press, 2003.
[15] J. McAuley and J. Leskovec. Discovering social circles in ego networks. arXiv:1210.8182, 2012.
[16] M. McPherson. An ecology of affiliation. American Sociological Review, 1983.
[17] A. Menon and C. Elkan. Link prediction via matrix factorization. In ECML/PKDD, 2011.
[18] A. Mislove, B. Viswanath, K. Gummadi, and P. Druschel. You are who you know: Inferring user profiles
in online social networks. In WSDM, 2010.
[19] P. Nasirifard and C. Hayes. Tadvise: A twitter assistant based on twitter lists. In SocInfo, 2011.
[20] M. Newman. Modularity and community structure in networks. PNAS, 2006.
[21] G. Palla, I. Derenyi, I. Farkas, and T. Vicsek. Uncovering the overlapping community structure of complex
networks in nature and society. Nature, 2005.
[22] C. Rother, V. Kolmogorov, V. Lempitsky, and M. Szummer. Optimizing binary MRFs via extended roof
duality. In CVPR, 2007.
[23] A. Streich, M. Frank, D. Basin, and J. Buhmann. Multi-assignment clustering for boolean data. JMLR,
2012.
[24] J. Ugander, B. Karrer, L. Backstrom, and C. Marlow. The anatomy of the Facebook social graph. preprint,
2011.
[25] C. Volinsky and A. Raftery. Bayesian information criterion for censored survival models. Biometrics,
2000.
[26] D. Vu, A. Asuncion, D. Hunter, and P. Smyth. Dynamic egocentric models for citation networks. In
ICML, 2011.
[27] S. Wu, J. Hofman, W. Mason, and D. Watts. Who says what to whom on twitter. In WWW, 2011.
[28] J. Yang and J. Leskovec. Community-affiliation graph model for overlapping community detection. In
ICDM, 2012.
[29] J. Yang and J. Leskovec. Defining and evaluating network communities based on ground-truth. In ICDM,
2012.
[30] T. Yoshida. Toward finding hidden communities based on user profiles. In ICDM Workshops, 2010.
[31] J. Zhao. Examining the evolution of networks based on lists in twitter. In IMSAA, 2011.

9


----------------------------------------------------------------

title: 5116-a-latent-source-model-for-nonparametric-time-series-classification.pdf

A Latent Source Model for
Nonparametric Time Series Classification
George H. Chen
MIT
georgehc@mit.edu

Stanislav Nikolov
Twitter
snikolov@twitter.com

Devavrat Shah
MIT
devavrat@mit.edu

Abstract
For classifying time series, a nearest-neighbor approach is widely used in practice
with performance often competitive with or better than more elaborate methods
such as neural networks, decision trees, and support vector machines. We develop
theoretical justification for the effectiveness of nearest-neighbor-like classification of time series. Our guiding hypothesis is that in many applications, such as
forecasting which topics will become trends on Twitter, there aren?t actually that
many prototypical time series to begin with, relative to the number of time series
we have access to, e.g., topics become trends on Twitter only in a few distinct manners whereas we can collect massive amounts of Twitter data. To operationalize
this hypothesis, we propose a latent source model for time series, which naturally
leads to a ?weighted majority voting? classification rule that can be approximated
by a nearest-neighbor classifier. We establish nonasymptotic performance guarantees of both weighted majority voting and nearest-neighbor classification under
our model accounting for how much of the time series we observe and the model
complexity. Experimental results on synthetic data show weighted majority voting
achieving the same misclassification rate as nearest-neighbor classification while
observing less of the time series. We then use weighted majority to forecast which
news topics on Twitter become trends, where we are able to detect such ?trending
topics? in advance of Twitter 79% of the time, with a mean early advantage of 1
hour and 26 minutes, a true positive rate of 95%, and a false positive rate of 4%.

1

Introduction

Recent years have seen an explosion in the availability of time series data related to virtually every
human endeavor ? data that demands to be analyzed and turned into valuable insights. A key
recurring task in mining this data is being able to classify a time series. As a running example used
throughout this paper, consider a time series that tracks how much activity there is for a particular
news topic on Twitter. Given this time series up to present time, we ask ?will this news topic go
viral?? Borrowing Twitter?s terminology, we label the time series a ?trend? and call its corresponding
news topic a trending topic if the news topic goes viral; otherwise, the time series has label ?not
trend?. We seek to forecast whether a news topic will become a trend before it is declared a trend (or
not) by Twitter, amounting to a binary classification problem. Importantly, we skirt the discussion
of what makes a topic considered trending as this is irrelevant to our mathematical development.1
Furthermore, we remark that handling the case where a single time series can have different labels
at different times is beyond the scope of this paper.
1
While it is not public knowledge how Twitter defines a topic to be a trending topic, Twitter does provide
information for which topics are trending topics. We take these labels to be ground truth, effectively treating
how a topic goes viral to be a black box supplied by Twitter.

1

Numerous standard classification methods have been tailored to classify time series, yet a simple
nearest-neighbor approach is hard to beat in terms of classification performance on a variety of
datasets [20], with results competitive to or better than various other more elaborate methods such
as neural networks [15], decision trees [16], and support vector machines [19]. More recently,
researchers have examined which distance to use with nearest-neighbor classification [2, 7, 18] or
how to boost classification performance by applying different transformations to the time series
before using nearest-neighbor classification [1]. These existing results are mostly experimental,
lacking theoretical justification for both when nearest-neighbor-like time series classifiers should be
expected to perform well and how well.
If we don?t confine ourselves to classifying time series, then as the amount of data tends to infinity,
nearest-neighbor classification has been shown to achieve a probability of error that is at worst
twice the Bayes error rate, and when considering the nearest k neighbors with k allowed to grow
with the amount of data, then the error rate approaches the Bayes error rate [5]. However, rather
than examining the asymptotic case where the amount of data goes to infinity, we instead pursue
nonasymptotic performance guarantees in terms of how large of a training dataset we have and how
much we observe of the time series to be classified. To arrive at these nonasymptotic guarantees, we
impose a low-complexity structure on time series.
Our contributions. We present a model for which nearest-neighbor-like classification performs well
by operationalizing the following hypothesis: In many time series applications, there are only a small
number of prototypical time series relative to the number of time series we can collect. For example,
posts on Twitter are generated by humans, who are often behaviorally predictable in aggregate. This
suggests that topics they post about only become trends on Twitter in a few distinct manners, yet we
have at our disposal enormous volumes of Twitter data. In this context, we present a novel latent
source model: time series are generated from a small collection of m unknown latent sources, each
having one of two labels, say ?trend? or ?not trend?. Our model?s maximum a posteriori (MAP) time
series classifier can be approximated by weighted majority voting, which compares the time series
to be classified with each of the time series in the labeled training data. Each training time series
casts a weighted vote in favor of its ground truth label, with the weight depending on how similar
the time series being classified is to the training example. The final classification is ?trend? or ?not
trend? depending on which label has the higher overall vote. The voting is nonparametric in that it
does not learn parameters for a model and is driven entirely by the training data. The unknown latent
sources are never estimated; the training data serve as a proxy for these latent sources. Weighted
majority voting itself can be approximated by a nearest-neighbor classifier, which we also analyze.
Under our model, we show sufficient conditions so that if we have n = ?(m log m ) time series in
our training data, then weighted majority voting and nearest-neighbor classification correctly classify a new time series with probability at least 1
after observing its first ?(log m ) time steps. As
our analysis accounts for how much of the time series we observe, our results readily apply to the
?online? setting in which a time series is to be classified while it streams in (as is the case for forecasting trending topics) as well as the ?offline? setting where we have access to the entire time series.
Also, while our analysis yields matching error upper bounds for the two classifiers, experimental results on synthetic data suggests that weighted majority voting outperforms nearest-neighbor classification early on when we observe very little of the time series to be classified. Meanwhile, a specific
instantiation of our model leads to a spherical Gaussian mixture model, where the latent sources are
Gaussian mixture components. We show that existing performance guarantees on learning spherical
Gaussian mixture models [6, 10, 17] require more stringent conditions than what our results need,
suggesting that learning the latent sources is overkill if the goal is classification.
Lastly, we apply weighted majority voting to forecasting trending topics on Twitter. We emphasize
that our goal is precognition of trends: predicting whether a topic is going to be a trend before it
is actually declared to be a trend by Twitter or, in theory, any other third party that we can collect
ground truth labels from. Existing work that identify trends on Twitter [3, 4, 13] instead, as part
of their trend detection, define models for what trends are, which we do not do, nor do we assume
we have access to such definitions. (The same could be said of previous work on novel document
detection on Twitter [11, 12].) In our experiments, weighted majority voting is able to predict
whether a topic will be a trend in advance of Twitter 79% of the time, with a mean early advantage
of 1 hour and 26 minutes, a true positive rate of 95%, and a false positive rate of 4%. We empirically
find that the Twitter activity of a news topic that becomes a trend tends to follow one of a finite
number of patterns, which could be thought of as latent sources.
2

Outline. Weighted majority voting and nearest-neighbor classification for time series are presented in Section 2. We provide our latent source model and theoretical performance guarantees
of weighted majority voting and nearest-neighbor classification under this model in Section 3. Experimental results for synthetic data and forecasting trending topics on Twitter are in Section 4.

2

Weighted Majority Voting and Nearest-Neighbor Classification

Given a time-series2 s : Z ! R, we want to classify it as having either label +1 (?trend?) or 1
(?not trend?). To do so, we have access to labeled training data R+ and R , which denote the sets
of all training time series with labels +1 and 1 respectively.
Weighted majority voting. Each positively-labeled example r 2 R+ casts a weighted vote
(T )
e d (r,s) for whether time series s has label +1, where d(T ) (r, s) is some measure of similarity between the two time series r and s, superscript (T ) indicates that we are only allowed to look
at the first T time steps (i.e., time steps 1, 2, . . . , T ) of s (but we?re allowed to look outside of these
time steps for the training time series r), and constant
0 is a scaling parameter that determines
the ?sphere of influence? of each example. Similarly, each negatively-labeled example in R also
casts a weighted vote for whether time series s has label 1.
The similarity measure d(T ) (r, s) could, for example, be squared Euclidean distance: d(T ) (r, s) =
PT
s(t))2 , kr sk2T . However, this similarity measure only looks at the first T time
t=1 (r(t)
steps of training time series r. Since time series in our training data are known, we need not restrict
our attention to their first T time steps. Thus, we use the following similarity measure:
d(T ) (r, s) =

2{

min

max ,...,0,...,

max }

T
X

(r(t + )

t=1

s(t))2 =

2{

min

max ,...,0,...,

max }

kr ?

sk2T ,

(1)
where we minimize over integer time shifts with a pre-specified maximum allowed shift max 0.
Here, we have used q? to denote time series q advanced by time steps, i.e., (q? )(t) = q(t+ ).
Finally, we sum up all of the weighted +1 votes and then all of the weighted 1 votes. The label
with the majority of overall weighted votes is declared as the label for s:
(
P
P
d(T ) (r,s)
d(T ) (r,s)
,
(T
)
r2R e
b (s; ) = +1 if r2R+ e
L
(2)
1 otherwise.
Using a larger time window size T corresponds to waiting longer before we make a prediction.
We need to trade off how long we wait and how accurate we want our prediction. Note that knearest-neighbor classification corresponds to only considering the k nearest neighbors of s among
all training time series; all other votes are set to 0. With k = 1, we obtain the following classifier:
Nearest-neighbor classifier. Let rb = arg minr2R+ [R d(T ) (r, s) be the nearest neighbor of s.
Then we declare the label for s to be:
?
+1 if rb 2 R+ ,
(T )
b
LN N (s) =
(3)
1 if rb 2 R .

3

A Latent Source Model and Theoretical Guarantees

We assume there to be m unknown latent sources (time series) that generate observed time series.
Let V denote the set of all such latent sources; each latent source v : Z ! R in V has a true label
+1 or 1. Let V+ ? V be the set of latent sources with label +1, and V ? V be the set of those
with label 1. The observed time series are generated from latent sources as follows:

2

1. Sample latent source V from V uniformly at random.3 Let L 2 {?1} be the label of V .

We index time using Z for notationally convenience but will assume time series to start at time step 1.
While we keep the sampling uniform for clarity of presentation, our theoretical guarantees can easily be
extended to the case where the sampling is not uniform. The only change is that the number of training data
needed will be larger by a factor of m?1min , where ?min is the smallest probability of a particular latent source
occurring.
3

3

activity

+1
{1
+1

{1
+1
{1

time

Figure 1: Example of latent sources superimposed, where each latent source is shifted vertically in
amplitude such that every other latent source has label +1 and the rest have label 1.
2. Sample integer time shift uniformly from {0, 1, . . . , max }.
3. Output time series S : Z ! R to be latent source V advanced by time steps, followed
by adding noise signal E : Z ! R, i.e., S(t) = V (t + ) + E(t). The label associated
with the generated time series S is the same as that of V , i.e., L. Entries of noise E are
i.i.d. zero-mean sub-Gaussian with parameter , which means that for any time index t,
?1
?
2 2
E[exp( E(t))] ? exp
for all 2 R.
(4)
2
The family of sub-Gaussian distributions includes a variety of distributions, such as a zeromean Gaussian with standard deviation and a uniform distribution over [ , ].
The above generative process defines our latent source model. Importantly, we make no assumptions
about the structure of the latent sources. For instance, the latent sources could be tiled as shown in
Figure 1, where they are evenly separated vertically and alternate between the two different classes
+1 and 1. With a parametric model like a k-component Gaussian mixture model, estimating
these latent sources could be problematic. For example, if we take any two adjacent latent sources
with label +1 and cluster them, then this cluster could be confused with the latent source having
label 1 that is sandwiched in between. Noise only complicates estimating the latent sources. In
this example, the k-component Gaussian mixture model needed for label +1 would require k to be
the exact number of latent sources with label +1, which is unknown. In general, the number of
samples we need from a Gaussian mixture mixture model to estimate the mixture component means
is exponential in the number of mixture components [14]. As we discuss next, for classification,
we sidestep learning the latent sources altogether, instead using training data as a proxy for latent
sources. At the end of this section, we compare our sample complexity for classification versus
some existing sample complexities for learning Gaussian mixture models.
Classification. If we knew the latent sources and if noise entries E(t) were i.i.d. N (0, 21 ) across t,
then the maximum a posteriori (MAP) estimate for label L given an observed time series S = s is
(
(T )
+1 if ?MAP (s; ) 1,
(T )
b
LMAP (s; ) =
(5)
1 otherwise,
where

(T )
?MAP (s;

and D+ , {0, . . . ,

max }.

P

), P

v+ 2V+

v 2V

P

P

+ 2D+

2D+

exp
exp

kv+ ?

kv ?

+

sk2T
sk2T

,

(6)

However, we do not know the latent sources, nor do we know if the noise is i.i.d. Gaussian. We
assume that we have access to training data as given in Section 2. We make a further assumption
that the training data were sampled from the latent source model and that we have n different training
time series. Denote D , {
max , . . . , 0, . . . , max }. Then we approximate the MAP classifier by
using training data as a proxy for the latent sources. Specifically, we take ratio (6), replace the inner
sum by a minimum in the exponent, replace V+ and V by R+ and R , and replace D+ by D to
obtain the ratio:
P
min + 2D kr+ ? + sk2T
r 2R exp
(T )
? (s; ) , P + +
.
(7)
min 2D kr ?
sk2T
r 2R exp
4

(T )

Plugging ?(T ) in place of ?MAP in classification rule (5) yields the weighted majority voting rule (2).
Note that weighted majority voting could be interpreted as a smoothed nearest-neighbor approximation whereby we only consider the time-shifted version of each example time series that is closest
to the observed time series s. If we didn?t replace the summations over time shifts with minimums
in the exponent, then we have a kernel density estimate in the numerator and in the denominator
[9, Chapter 7] (where the kernel is Gaussian) and our main theoretical result for weighted majority
voting to follow would still hold using the same proof.4
Lastly, applications may call for trading off true and false positive rates. We can do this by generalizing decision rule (5) to declare the label of s to be +1 if ?(T ) (s, ) ? and vary parameter ? > 0.
The resulting decision rule, which we refer to as generalized weighted majority voting, is thus:
?
+1 if ?(T ) (s, ) ?,
(T )
b
L? (s; ) =
(8)
1 otherwise,
where setting ? = 1 recovers the usual weighted majority voting (2). This modification to the
classifier can be thought of as adjusting the priors on the relative sizes of the two classes. Our
theoretical results to follow actually cover this more general case rather than only that of ? = 1.

Theoretical guarantees. We now present the main theoretical results of this paper which identify
sufficient conditions under which generalized weighted majority voting (8) and nearest-neighbor
classification (3) can classify a time series correctly with high probability, accounting for the size of
the training dataset and how much we observe of the time series to be classified. First, we define the
?gap? between R+ and R restricted to time length T and with maximum time shift max as:
G(T ) (R+ , R ,

max )

,

min

r+ 2R+ ,r 2R ,
2D
+,

kr+ ?

+

r ?

k2T .

(9)

This quantity measures how far apart the two different classes are if we only look at length-T chunks
of each time series and allow all shifts of at most max time steps in either direction.
Our first main result is stated below. We defer proofs to the longer version of this paper.
Theorem 1. (Performance guarantee for generalized weighted majority voting) Let m+ = |V+ | be
the number of latent sources with label +1, and m = |V | = m m+ be the number of latent
sources with label 1. For any > 1, under the latent source model with n > m log m time series
in the training data, the probability of misclassifying time series S with label L using generalized
b (T ) (?; ) satisfies the bound
weighted majority voting L
?
(T )

b (S; ) 6= L)
P(L
?
? ?m
m ?
+
?
+
(2
m
?m

max

+ 1)n exp

(

4

2 2

)G(T ) (R+ , R ,

max )

+1

+m

. (10)

An immediate consequence is that given error tolerance 2 (0, 1) and with choice 2 (0, 4 1 2 ),
then upper bound (10) is at most (by having each of the two terms on the right-hand side be ? 2 )
if n > m log 2m (i.e., = 1 + log 2 / log m), and
G(T ) (R+ , R ,

+
log( ?m
m +

m
?m

) + log(2

max +
2 2

1) + log n + log

2

.
(11)
4
This means that if we have access to a large enough pool of labeled time series, i.e., the pool has
?(m log m ) time series, then we can subsample n = ?(m log m ) of them to use as training data.
Then with choice = 8 1 2 , generalized weighted majority voting (8) correctly classifies a new time
series S with probability at least 1
if
? ?
?
? ?m
m ?
m?
+
G(T ) (R+ , R , max ) = ? 2 log
+
+ log(2 max + 1) + log
.
(12)
m
?m
max )

Thus, the gap between sets R+ and R needs to grow logarithmic in the number of latent sources m
in order for weighted majority voting to classify correctly with high probability. Assuming that the
4
We use a minimum rather a summation over time shifts to make the method more similar to existing time
series classification work (e.g., [20]), which minimize over time warpings rather than simple shifts.

5

original unknown latent sources are separated (otherwise, there is no hope to distinguish between
the classes using any classifier) and the gap in the training data grows as G(T ) (R+ , R , max ) =
?( 2 T ) (otherwise, the closest two training time series from opposite classes are within noise of
each other), then observing the first T = ?(log(? + ?1 ) + log(2 max + 1) + log m ) time steps from
the time series is sufficient to classify it correctly with probability at least 1
.
A similar result holds for the nearest-neighbor classifier (3).
Theorem 2. (Performance guarantee for nearest-neighbor classification) For any > 1, under
the latent source model with n > m log m time series in the training data, the probability of
b (T ) (?) satisfies the
misclassifying time series S with label L using the nearest-neighbor classifier L
NN
bound
?
?
1
b (T ) (S) 6= L) ? (2 max + 1)n exp
P(L
G(T ) (R+ , R , max ) + m +1 .
(13)
NN
16 2

Our generalized weighted majority voting bound (10) with ? = 1 (corresponding to regular weighted
majority voting) and = 8 1 2 matches our nearest-neighbor classification bound, suggesting that
the two methods have similar behavior when the gap grows with T . In practice, we find weighted
majority voting to outperform nearest-neighbor classification when T is small, and then as T grows
large, the two methods exhibit similar performance in agreement with our theoretical analysis. For
small T , it could still be fairly likely that the nearest neighbor found has the wrong label, dooming
the nearest-neighbor classifier to failure. Weighted majority voting, on the other hand, can recover
from this situation as there may be enough correctly labeled training time series close by that contribute to a higher overall vote for the correct class. This robustness of weighted majority voting
makes it favorable in the online setting where we want to make a prediction as early as possible.
Sample complexity of learning the latent sources. If we can estimate the latent sources accurately,
then we could plug these estimates in place of the true latent sources in the MAP classifier and
achieve classification performance close to optimal. If we restrict the noise to be Gaussian and
assume max = 0, then the latent source model corresponds to a spherical Gaussian mixture model.
We could learn such a model using Dasgupta and Schulman?s modified EM algorithm [6]. Their
theoretical guarantee depends on the true separation between the closest two latent
p sources, namely
(T )?
0 2
(T )?
2
0
0
G
, minv,v 2V s.t. v6=v kv v k2 , which needs to satisfy G
T . Then with n =
2
?(max{1, G(TT)? }m log m ), G(T )? = ?( 2 log m
),
and
"
?
?
?
?
?
4 2
4 2
T
m
T
T = ? max 1, (T )? 2 log
max 1, (T )? 2
,
(14)
(G
)
(G
)
p
their algorithm achieves, with probability at least 1
, an additive " T error (in Euclidean
distance) close to optimal in estimating every latent source. In contrast, our result is in terms of gap
G(T ) (R+ , R , max ) that depends not on the true separation between two latent sources but instead
on the minimum observed separation in the training data between two time series of opposite labels.
In fact, our gap, in their setting, grows as ?( 2 T ) even when their gap G(T )? grows sublinear in
pT .
m
2
(T )?
2
In particular, while their result cannot handle the regime where O( log ) ? G
?
T,
ours can, using n = ?(m log m ) training time series and observing the first T = ?(log m ) time
steps to classify a time series correctly with probability at least 1
; see the longer version of this
paper for details.
Vempala and Wang [17] have a spectral method for learning Gaussian mixture models that can hane 3 m2 ) training data,
dle smaller G(T )? than Dasgupta and Schulman?s approach but requires n = ?(T
2
where we?ve hidden the dependence on
and other variables of interest for clarity of presentation.
Hsu and Kakade [10] have a moment-based estimator that doesn?t have a gap condition but, under a
different non-degeneracy condition, requires substantially more samples for our problem setup, i.e.,
n = ?((m14 + T m11 )/"2 ) to achieve an " approximation of the mixture components. These results
need substantially more training data than what we?ve shown is sufficient for classification.
To fit a Gaussian mixture model to massive training datasets, in practice, using all the training data
could be prohibitively expensive. In such scenarios, one could instead non-uniformly subsample
O(T m3 /"2 ) time series from the training data using the procedure given in [8] and then feed the
resulting smaller dataset, referred to as an (m, ")-coreset, to the EM algorithm for learning the latent
sources. This procedure still requires more training time series than needed for classification and
lacks a guarantee that the estimated latent sources will be close to the true latent sources.
6

Classification error rate on test data

Classification error rate on test data

0.6
Weighted majority voting
Nearest?neighbor classifier
Oracle MAP classifier

0.5
0.4
0.3
0.2
0.1
0

0

50

100
T

150

200

0.25
Weighted majority voting
Nearest?neighbor classifier
Oracle MAP classifier

0.2
0.15
0.1
0.05
0
1

2

3

4

5

6

7

8

?

(a)

(b)

activity

Figure 2: Results on synthetic data. (a) Classification error rate vs. number of initial time steps T
used; training set size: n = m log m where = 8. (b) Classification error rate at T = 100 vs. .
All experiments were repeated 20 times with newly generated latent sources, training data, and test
data each time. Error bars denote one standard deviation above and below the mean value.

time

Figure 3: How news topics become trends on Twitter. The top left shows some time series of activity
leading up to a news topic becoming trending. These time series superimposed look like clutter, but
we can separate them into different clusters, as shown in the next five plots. Each cluster represents
a ?way? that a news topic becomes trending.

4

Experimental Results

Synthetic data. We generate m = 200 latent sources, where each latent source is constructed by
first sampling i.i.d. N (0, 100) entries per time step and then applying a 1D Gaussian smoothing
filter with scale parameter 30. Half of the latent sources are labeled +1 and the other half 1. Then
n = m log m training time series are sampled as per the latent source model where the noise added
is i.i.d. N (0, 1) and max = 100. We similarly generate 1000 time series to use as test data. We
set = 1/8 for weighted majority voting. For = 8, we compare the classification error rates on
test data for weighted majority voting, nearest-neighbor classification, and the MAP classifier with
oracle access to the true latent sources as shown in Figure 2(a). We see that weighted majority voting
outperforms nearest-neighbor classification but as T grows large, the two methods? performances
converge to that of the MAP classifier. Fixing T = 100, we then compare the classification error
rates of the three methods using varying amounts of training data, as shown in Figure 2(b); the
oracle MAP classifier is also shown but does not actually depend on training data. We see that as
increases, both weighted majority voting and nearest-neighbor classification steadily improve in
performance.
Forecasting trending topics on twitter. We provide only an overview of our Twitter results here,
deferring full details to the longer version of this paper. We sampled 500 examples of trends at
random from a list of June 2012 news trends, and 500 examples of non-trends based on phrases
appearing in user posts during the same month. As we do not know how Twitter chooses what
phrases are considered as candidate phrases for trending topics, it?s unclear what the size of the
7

(a)

(b)

(c)

Figure 4: Results on Twitter data. (a) Weighted majority voting achieves a low error rate (FPR
of 4%, TPR of 95%) and detects trending topics in advance of Twitter 79% of the time, with a mean
of 1.43 hours when it does; parameters: = 10, T = 115, Tsmooth = 80, h = 7. (b) Envelope of
all ROC curves shows the tradeoff between TPR and FPR. (c) Distribution of detection times for
?aggressive? (top), ?conservative? (bottom) and ?in-between? (center) parameter settings.
non-trend category is in comparison to the size of the trend category. Thus, for simplicity, we
intentionally control for the class sizes by setting them equal. In practice, one could still expressly
assemble the training data to have pre-specified class sizes and then tune ? for generalized weighted
majority voting (8). In our experiments, we use the usual weighted majority voting (2) (i.e., ? = 1)
to classify time series, where max is set to the maximum possible (we consider all shifts).
Per topic, we created its time series based on a pre-processed version of the raw rate of how often
the topic was shared, i.e., its Tweet rate. We empirically found that how news topics become trends
tends to follow a finite number of patterns; a few examples of these patterns are shown in Figure 3.
We randomly divided the set of trends and non-trends into into two halves, one to use as training
data and one to use as test data. We applied weighted majority voting, sweeping over , T , and
data pre-processing parameters. As shown in Figure 4(a), one choice of parameters allows us to
detect trending topics in advance of Twitter 79% of the time, and when we do, we detect them an
average of 1.43 hours earlier. Furthermore, we achieve a true positive rate (TPR) of 95% and a false
positive rate (FPR) of 4%. Naturally, there are tradeoffs between TPR, FPR, and how early we make
a prediction (i.e., how small T is). As shown in Figure 4(c), an ?aggressive? parameter setting yields
early detection and high TPR but high FPR, and a ?conservative? parameter setting yields low FPR
but late detection and low TPR. An ?in-between? setting can strike the right balance.
Acknowledgements. This work was supported in part by the Army Research Office under MURI
Award 58153-MA-MUR. GHC was supported by an NDSEG fellowship.

8

References
[1] Anthony Bagnall, Luke Davis, Jon Hills, and Jason Lines. Transformation based ensembles for time
series classification. In Proceedings of the 12th SIAM International Conference on Data Mining, pages
307?319, 2012.
[2] Gustavo E.A.P.A. Batista, Xiaoyue Wang, and Eamonn J. Keogh. A complexity-invariant distance measure for time series. In Proceedings of the 11th SIAM International Conference on Data Mining, pages
699?710, 2011.
[3] Hila Becker, Mor Naaman, and Luis Gravano. Beyond trending topics: Real-world event identification
on Twitter. In Proceedings of the Fifth International Conference on Weblogs and Social Media, 2011.
[4] Mario Cataldi, Luigi Di Caro, and Claudio Schifanella. Emerging topic detection on twitter based on
temporal and social terms evaluation. In Proceedings of the 10th International Workshop on Multimedia
Data Mining, 2010.
[5] Thomas M. Cover and Peter E. Hart. Nearest neighbor pattern classification. IEEE Transactions on
Information Theory, 13(1):21?27, 1967.
[6] Sanjoy Dasgupta and Leonard Schulman. A probabilistic analysis of EM for mixtures of separated,
spherical gaussians. Journal of Machine Learning Research, 8:203?226, 2007.
[7] Hui Ding, Goce Trajcevski, Peter Scheuermann, Xiaoyue Wang, and Eamonn Keogh. Querying and mining of time series data: experimental comparison of representations and distance measures. Proceedings
of the VLDB Endowment, 1(2):1542?1552, 2008.
[8] Dan Feldman, Matthew Faulkner, and Andreas Krause. Scalable training of mixture models via coresets.
In Advances in Neural Information Processing Systems 24, 2011.
[9] Keinosuke Fukunaga. Introduction to statistical pattern recognition (2nd ed.). Academic Press Professional, Inc., 1990.
[10] Daniel Hsu and Sham M. Kakade. Learning mixtures of spherical gaussians: Moment methods and
spectral decompositions, 2013. arXiv:1206.5766.
[11] Shiva Prasad Kasiviswanathan, Prem Melville, Arindam Banerjee, and Vikas Sindhwani. Emerging topic
detection using dictionary learning. In Proceedings of the 20th ACM Conference on Information and
Knowledge Management, pages 745?754, 2011.
[12] Shiva Prasad Kasiviswanathan, Huahua Wang, Arindam Banerjee, and Prem Melville. Online l1dictionary learning with application to novel document detection. In Advances in Neural Information
Processing Systems 25, pages 2267?2275, 2012.
[13] Michael Mathioudakis and Nick Koudas. Twittermonitor: trend detection over the Twitter stream. In
Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data, 2010.
[14] Ankur Moitra and Gregory Valiant. Settling the polynomial learnability of mixtures of gaussians. In 51st
Annual IEEE Symposium on Foundations of Computer Science, pages 93?102, 2010.
[15] Alex Nanopoulos, Rob Alcock, and Yannis Manolopoulos. Feature-based classification of time-series
data. International Journal of Computer Research, 10, 2001.
[16] Juan J. Rodr??guez and Carlos J. Alonso. Interval and dynamic time warping-based decision trees. In
Proceedings of the 2004 ACM Symposium on Applied Computing, 2004.
[17] Santosh Vempala and Grant Wang. A spectral algorithm for learning mixture models. Journal of Computer and System Sciences, 68(4):841?860, 2004.
[18] Kilian Q. Weinberger and Lawrence K. Saul. Distance metric learning for large margin nearest neighbor
classification. Journal of Machine Learning Research, 10:207?244, 2009.
[19] Yi Wu and Edward Y. Chang. Distance-function design and fusion for sequence data. In Proceedings of
the 2004 ACM International Conference on Information and Knowledge Management, 2004.
[20] Xiaopeng Xi, Eamonn J. Keogh, Christian R. Shelton, Li Wei, and Chotirat Ann Ratanamahatana. Fast
time series classification using numerosity reduction. In Proceedings of the 23rd International Conference
on Machine Learning, 2006.

9


----------------------------------------------------------------

