query sentence: Neural networks
---------------------------------------------------------------------
title: 232-analog-neural-networks-of-limited-precision-i-computing-with-multilinear-threshold-functions.pdf

702

Obradovic and Pclrberry

Analog Neural Networks of Limited Precision I:
Computing with Multilinear Threshold Functions
(Preliminary Version)

Zoran Obradovic and Ian Parberry
Department of Computer Science.
Penn State University.
University Park. Pa. 16802.

ABSTRACT
Experimental evidence has shown analog neural networks to be ex~mely fault-tolerant; in particular. their performance does not appear to be significantly impaired when precision is limited. Analog
neurons with limited precision essentially compute k-ary weighted
multilinear threshold functions. which divide R" into k regions with
k-l hyperplanes. The behaviour of k-ary neural networks is investigated. There is no canonical set of threshold values for k>3.
although they exist for binary and ternary neural networks. The
weights can be made integers of only 0 ?z +k ) log (z +k ? bits. where
z is the number of processors. without increasing hardware or running time. The weights can be made ?1 while increasing running
time by a constant multiple and hardware by a small polynomial in z
and k. Binary neurons can be used if the running time is allowed to
increase by a larger constant multiple and the hardware is allowed to
increase by a slightly larger polynomial in z and k. Any symmetric
k-ary function can be computed in constant depth and size
(n k - 1/(k-2)!). and any k-ary function can be computed in constant
depth and size 0 (nk"). The alternating neural networks of Olafsson
and Abu-Mostafa. and the quantized neural networks of Fleisher are
closely related to this model.

o

Analog Neural Networks of Limited Precision I

1 INTRODUCTION
Neural networks are typically circuits constructed from processing units which compute simple functions of the form f(Wl> ... ,wlI):RII-+S where SeR, wieR for 1~~,
and
II

f (Wl> ... ,WII)(Xl, .?. ,xlI)=g (LWi X;)
i=1

for some output function g :R-+S. There are two choices for the set S which are
currently popular in the literature. The first is the discrete model, with S=B (where B
denotes the Boolean set (0,1)). In this case, g is typically a linear threshold function
g (x)= 1 iff x~. and f is called a weighted linear threshold function. The second is
the analog model, with S=[O,I] (where [0,1] denotes (re RI~~I}). In this case. g
is typically a monotone increasing function, such as the sigmoid function
g (x)=(1 +c -% 1 for some constant c e R. The analog neural network model is popular
because it is easy to construct processors with the required characteristics using a few
transistors. The digital model is popular because its behaviour is easy to analyze.

r

Experimental evidence indicates that analog neural networks can produce accurate
computations when the precision of their components is limited. Consider what actually happens to the analog model when the precision is limited. Suppose the neurons
can take on k distinct excitation values (for example, by restricting the number of digits in their binary or decimal expansions). Then S is isomorphic to Zk={O, ... ,k-l}.
We will show that g is essentially the multilinear threshold function
g (hloh2 ....,hk-l):R-+Zk defined by

Here and throughout this paper, we will assume that hl~h2~ ... ~hk-1> and for convenience define ho=-oo and h/c=oo. We will call f a k-ary weighted multilinear threshold
function when g is a multilinear threshold function.
We will study neural networks constructed from k-ary multilinear threshold functions.
We will call these k-ary neural networks, in order to distinguish them from the standard 2-ary or binary neural network. We are particularly concerned with the resources
of time, size (number of processors), and weight (sum of all the weights) of k-ary
neural networks when used in accordance with the classical computational paradigm.
The reader is referred to (parberry, 1990) for similar results on binary neural networks.
A companion paper (Obradovic & Parberry, 1989b) deals with learning on k-ary neural networks. A more detailed version of this paper appears in (Obradovic & Parberry,
1989a).

2 A K-ARY NEURAL NETWORK MODEL
A k-ary neural network is a weighted graph M =(V ,E ,W ,h), where V is a set of processors and E cVxV is a set of connections between processors. Function
w:VxV -+R assign weights to interconnections and h:V -+Rk - assign a set of k-l
thresholds to each of the processors. We assume that if (u ,v) eE, W (u ,v )=0. The
size of M is defined to be the number of processors, and the weight of M is

703

704

Obradovic and Parberry

The processors of a k-ary neural network are relatively limited in computing power.
A k-ary function is a function f :Z:~Z". Let F; denote the set of all n-input k-ary
functions. Define e::R,,+Ir;-l~F; by e:(w l .....w".h It .???h''_l):R;~Z,,. where

.

e;(w It ???? w" .h h???.h,,-l)(X 1o... ,%.. )=i iff hi ~~Wi xi <h; +1?
i=1

The set of k-ary weighted multilinear threshold functions is the union. over all n e N.
of the range of e;. Each processor of a k-ary neural network can compute a k-ary
weighted multilinear threshold function of its inputs.
Each processor can be in one of k states, 0 through k-l. Initially. the input processors of M are placed into states which encode the input If processor v was updated
during interval t, its state at time t -1 was i and output was j. then at time t its state
will be j. A k-ary neural network computes by having the processors change state until a stable configuration is reached. The output of M are the states of the output processors after a stable state has been reached. A neural network M 2 is said to be f (t )equivalent to M 1 iff for all inputs x. for every computation of M 1 on input x which
terminates in time t there is a computation of M 2 on input x which terminates in time
f (t) with the same output. A neural network M 2 is said to be equivalent to M 1 iff it
is t -equivalent to it.

3 ANALOG NEURAL NETWORKS
Let f be a function with range [0.1]. Any limited-precision device which purports to
compute f must actually compute some function with range the k rational values

R"={ilk-llieZ,,,~<k} (for some keN). This is sufficient for all practical purposes
provided k is large enough. Since R" is isomorphic to Z". we will formally define
the limited precision variant of f to be the function f" :X ~Z" defined by
f,,(x)=round(j (x).(k-l?, where round:R~N is the natural rounding function defined
by round(x)=n iff n-o.5~<n-tO.5.

Theorem 3.1 : Letf(Wlo ... ,w.. ):R"~[O,I] where WieR for

1~~.

be defined by

.
f (w1O.?.,W,,)(X 10 .?? ,x.. )=g (LWiXi)
i=l

where g:R~[O,I] is monotone increasing and invertible. Then f(Wlo ... ,W.. )":R"~Z,,
is a k-ary weighted multilinear threshold function.
Proof: It is easy to verify that f(Wlo ...?W")"=S;(Wl' ... ,w",hl, ...?h,,_l)' where
hi =g-1?2i-l)/2(k-l?. 0
Thus we see that analog neural networks with limited precision are essentially k-ary
neural networks.

Analog Neural Networks of Limited Precision I

4 CANONICAL THRESHOLDS
Binary neural networks have the advantage that all thresholds can be taken equal to
zero (see. for example. Theorem 4.3.1 of Parberry, 1990). A similar result holds for
ternary neural networks.
Theorem 4.1 : For every n-input ternary weighted multilinear threshold function there
is an equivalent (n +I)-input ternary weighted multilinear threshold function with
threshold values equal to zero and one.
Proof: Suppose W=(W1o ??? ,WII )E R", hloh2E R. Without loss of generality assume
h l<h 2.
Define W=(Wl ?...?wlI+l)e RII+I by wj=wjl(hrh 1) for I~!0t, and
wlI +I=-h I/(h2-h 1). It can be demonstrated by a simple case analysis that for all
x =(x 1, ??? ,xll)e

Z;.

8;(w,h l,hz)(x )=8;+I(W ,0,I)(x l,... ,xll ,1).

o
The choice of threshold values in Theorem 4.1 was arbitrary. Unfortunately there is
no canonical set of thresholds for k >3.
Theorem 4.2 : For every k>3, n~2, m~. h 1o ??? ,hk - 1E R. there exists an n-input k-ary
weighted multilinear threshold function

such that for all (n +m )-input k-ary weighted multilinear threshold functions

8 k"+m("
WI.???

)?zm+1I
.WII+m. h 10???. hk-l'
k
~Z k
A

Proof (Sketch): Suppose that t I ?.. . .tk-l e R is a canonical set of thresholds. and w.t.o.g.
assume n =2. Let h =(h 1o ??? ,hk - 1), where h l=h z=2. h j=4, hi =5 for 4Si <k. and
f=8i(1,I.h).
By hypothesis there exist wlo ????wm+2 and y=(ylo ...?ym)eRm such that for all xeZi,

f (x )=8r+2(w 1.? .. ,Wm+2,t 1, ??? ,tk-l)(X ,y).
m

Let S= I:Wi+2Yi. Since f (1.0)=0. f (0.1)=0, f (2,1)=2, f (1,2)=2. it follows that
;=1

2(Wl+Wz+S )<tl+t 3.
Since f (2,0)=2, f (1.1 )=2. and f (0.2)=2, it follows that

(1)

70S

706

Obradovic and Pdrberry

Wl+W2+S~2?

(2)

2t2<ll+13.

(3)

Inequalities (1) and (2) imply that

By similar arguments from g=S;(1,l,l.3.3.4 ?...?4) we can conclude that
(4)

But (4) contradicts (3). 0

S NETWORKS OF BOUNDED WEIGHT
Although our model allows each weight to take on an infinite number of possible
values. there are only a finite number of threshold functions (since there are only a
finite number of k-ary functions) with a fixed number of inputs. Thus the number of
n -input threshold functions is bounded above by some function in n and k. In fact.
something stronger can be shown. All weights can be made integral. and
o ((n +k) log (n +k? bits are sufficient to describe each one.
Theorem 5.1 : For every k-ary neural network M 1 of size z there exists an equivalent
k-ary neural network M2 of size z and weight ((k_l)/2)Z(z+I)(z+k)'2+0(1) with integer
weights.
Proof (Sketch): It is sufficient to prove that for every weighted threshold function
f:(Wlt ...?wll.hh ...?h"-I):Z:~Z,, for some neN. there is an equivalent we1f.hted threshold function g:(w~ ?...? w:.hi ?...? h;-d such that Iwtl~((k-l)/2)I(n+l)'" )12+0(1) for
l~i~. By extending the techniques used by Muroga. Toda and Takasu (1961) in the
binary case. we see that the weights are bounded above by the maximum determinant
of a matrix of dimension n +k -lover Z". 0
Thus if k is bounded above by a polynomial in n. we are guaranteed of being able to
describe the weights using a polynomial number of bits.

6 THRESHOLD CIRCUITS
A k-ary neural network with weights drawn from {?1} is said to have unit weights. A
unit-weight directed acyclic k-ary neural network is called a k-ary threshold circuit.
A k-ary threshold circuit can be divided into layers. with each layer receiving inputs
only from the layers above it. The depth of a k-ary threshold circuit is defined to be
the number of layers. The weight is equal to the number of edges. which is bounded
above by the square of the size. Despite the apparent handicap of limited weights. kary threshold circuits are surprisingly powerful.
Much interest has focussed on the computation of symmetric functions by neural networks. motivated by the fact that the visual system appears to be able to recognize objects regardless of their position on the retina A function f :Z:~Z" is called symmetric if its output remains the same no matter how the input is permuted.

Analog Neural Networks of Limited Precision I

Theorem 6.1 : Any symmetric k-ary function on n inputs can be computed by a k-ary
threshold circuit of depth 6 and size (n+1)k-l/(k-2)!+ o (kn).
Proof: Omitted. 0
It has been noted many times that neural networks can compute any Boolean function
in constant depth. The same is true of k-ary neural networks, although both results
appear to require exponential size for many interesting functions.

Theorem 6.2 : Any k-ary function of n inputs can be computed by a k-ary threshold
circuit with size (2n+1)k"+k+1 and depth 4.
Proof: Similar to that for k=2 (see Chandra et. al., 1984; Parberry, 1990). 0
The interesting problem remaining is to determine which functions require exponential
size to achieve constant depth, and which can be computed in polynomial size and
constant depth. We will now consider the problem of adding integers represented in
k-ary notation.

Theorem 6.3 : The sum of two k-ary integers of size n can be computed by a k-ary
threshold circuit with size 0 (n 2) and depth 5.
Proof: First compute the carry of x and y in 'luadratic size and depth 3 using the standard elementary school algorithm. Then the it position of the result can be computed
from the i tit position of the operands and a carry propagated in that position in constant size and depth 2. 0
Theorem 6.4 : The sum of n k-~ integers of size n can be computed by a k-ary
threshold circuit with size 0 (n 3+kn ) and constant depth.
Proof: Similar to the proof for k=2 using Theorem 6.3 (see Chandra et. al., 1984; Parberry, 1990). 0
Theorem 6.S : For every k-ary neural network M 1 of size z there exists an 0 (t)equivalent unit-weight k-ary neural network M2 of size o ((z+k)410g3(z+k?.
Proof: By Theorem 5.1 we can bound all weights to have size 0 ((z+k)log(z+k? in
binary notation. By Theorem 6.4 we can replace every processor with non-unit
weights by a threshold circuit of size o ((z+k)310g3(z+k? and constant depth. 0
Theorem 6.5 implies that we can assume unit weights by increasing the size by a polynomial and the running time by only a constant multiple provided the number of
logic levels is bounded above by a polynomial in the size of the network. The
number of thresholds can also be reduced to one if the size is increased by a larger
polynomial:

Theorem 6.6 : For every k-ary neural network M 1 of size z there exists an 0 (t )equivalent unit-weight binary neural network M 2 of size 0 (z 4k 4)(log z + log k)3
which outputs the binary encoding of the required result
Proof: Similar to the proof of Theorem 6.5. 0
This result is primarily of theoretical interest. Binary neural networks appear simpler,
and hence more desirable than analog neural networks. However, analog neural networks are actually more desirable since they are easier to build. With this in mind,
Theorem 6.6 simply serves as a limit to the functions that an analog neural network

707

708

Obradovic and Parberry

can be expected to compute efficiently. We are more concerned with constructing a
model of the computational abilities of neural networks, rather than a model of their
implementation details.

7 NONMONOTONE MULTILINEAR NEURAL NETWORKS
Olafsson and Abu-Mostafa (1988) study
f(Wlt ... ,wl):R"-+B for w;ER, 1~~, where

f

information

capacity

of functions

II
(Wlt.. ??WII)(X1 ?... , xlI)=g (~W;X;)
;=1

and g is the alternating threshold function g (h loh2.....hk-1):R-+B for some monotone
increasing h;ER, 1~<k, defined by g(x)=O if h2i~<h2i+1 for some ~5:nI2. We
will call f an alternating weighted multilinear threshold function, and a neural network constructed from functions of this form alternating multilinear neural networks.
Alternating multilinear neural networks are closely related to k-ary neural networks:
Theorem 7.1 : For every k-ary neural network of size z and weight w there is an
equivalent alternating multilinear neural network of size z log k and weight
(k -l)w log (k -1) which produces the output of the former in binary notation.
Proof (Sketch): Each k-ary gate is replaced by log k gates which together essentially
perform a "binary search" to determine each bit of the k-ary gate. Weights which increase exponentially are used to provide the correct output value. 0
Theorem 7.2 : For every alternating multilinear neural network of size z and weight
w there is a 3t-equivalent k-ary neural network of size 4z and weight w+4z.
Proof (Sketch): Without loss of generality. assume k is odd. Each alternating gate is
replaced by a k-ary gate with identical weights and thresholds. The output of this gate
goes with weight one to a k-ary gate with thresholds 1,3,S ?... ,k-1 and with weight
minus one to a k-ary gate with thresholds -(k-1), ... ,-3,-1. The output of these gates
goes to a binary gate with threshold k. 0
Both k-ary and alternating multilinear neural networks are a special case of nonmonotone multilinear neural networks, where g :R-+R is the defined by g (x )=Ci iff
hi~<h;+lt for some monotone increasing h;ER, 1~<k, and co, ... ,Ck-1EZk. Nonmonotone neural networks correspond to analog neural networks whose output function is not necessarily monotone nondecreasing. Many of the result of this paper, including Theorems 5.1, 6.5, and 6.6, also apply to nonmonotone neural networks. The
size, weight and running time of many of the upper-bounds can also be improved by a
small amount by using nonmonotone neural networks instead of k-ary ones. The details are left to the interested reader.

8 MUL TILINEAR HOPFIELD NETWORKS
A multilinear version of the Hopfield network called the quantized neural network has
been studied by Fleisher (1987). Using the terminology of (parberry, 1990), a quantized neural network is a simple symmetric k-ary neural network (that is, its interconnection pattern is an undirected graph without self-loops) with the additional property
that all processors have an identical set of thresholds. Although the latter assumption

Analog Neural Networks of Limited Precision I

is reasonable for binary neural networks (see, for example, Theorem 4.3.1 of Parberry,
1990), and ternary neural networks (Theorem 4.1), it is not necessarily so for k-ary
neural networks with k>3 (Theorem 4.2). However, it is easy to extend Fleisher's
main result to give the following:
Theorem 8.1 : Any productive sequential computation of a simple symmetric k-ary
neural network will converge.

9 CONCLUSION
It has been shown that analog neural networks with limited precision are essentially
k-ary neural networks. If k is limited to a polynomial, then polynomial size, constant
depth k-ary neural networks are equivalent to polynomial size, constant depth binary
neural networks. Nonetheless, the savings in time (at most a constant multiple) and
hardware (at most a polynomial) arising from using k-ary neural networks rather than
binary ones can be quite significant. We do not suggest that one should actually construct binary or k-ary neural networks. Analog neural networks can be constructed by
exploiting the analog behaviour of transistors, rather than using extra hardware to inhibit it Rather, we suggest that k-ary neural networks are a tool for reasoning about the
behaviour of analog neural networks.
Acknowledgements
The financial support of the Air Force Office of Scientific Research, Air Force S ysterns Command, DSAF, under grant numbers AFOSR 87-0400 and AFOSR 89-0168
and NSF grant CCR-8801659 to Ian Parberry is gratefully acknowledged.
References
Chandra A. K., Stockmeyer L. J. and Vishkin D., (1984) "Constant depth reducibility,"
SIAM 1. Comput., vol. 13, no. 2, pp. 423-439.
Fleisher M., (1987) "The Hopfield model with multi-level neurons," Proc. IEEE
Conference on Neural Information Processing Systems, pp. 278-289, Denver, CO.
Muroga S., Toda 1. and Takasu S., (1961) "Theory of majority decision elements," 1.
Franklin Inst., vol. 271., pp. 376-418.
Obradovic Z. and Parberry 1., (1989a) "Analog neural networks of limited precision I:
Computing with multilinear threshold functions (preliminary version)," Technical Report CS-89-14, Dept of Computer Science, Penn. State Dniv.
Obradovic Z. and Parberry I., (1989b) "Analog neural networks of limited precision II:
Learning with multilinear threshold functions (preliminary version)," Technical Report
CS-89-15, Dept. of Computer Science, Penn. State Dniv.
Olafsson S. and Abu-Mostafa Y. S., (1988) "The capacity of multilevel threshold functions," IEEE Trans. Pattern Analysis and Machine Intelligence, vol. 10, no. 2, pp.
277-281.
Parberry I., (To Appear in 1990) "A Primer on the Complexity Theory of Neural Networks," in A Sourcebook of Formal Methods in Artificial Intelligence, ed. R. Banerji,
North-Holland.

709


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 516-neural-network-routing-for-random-multistage-interconnection-networks.pdf

Neural Network Routing for Random Multistage
Interconnection Networks

Mark W. Goudreau
Princeton University
and
NEe Research Institute, Inc.
4 Independence Way
Princeton, NJ 08540

c. Lee Giles
NEC Research Institute, Inc.
4 Independence Way
Princeton, NJ 08540

Abstract
A routing scheme that uses a neural network has been developed that can
aid in establishing point-to-point communication routes through multistage interconnection networks (MINs). The neural network is a network
of the type that was examined by Hopfield (Hopfield, 1984 and 1985).
In this work, the problem of establishing routes through random MINs
(RMINs) in a shared-memory, distributed computing system is addressed.
The performance of the neural network routing scheme is compared to two
more traditional approaches - exhaustive search routing and greedy routing. The results suggest that a neural network router may be competitive
for certain RMIN s.

1

INTRODUCTION

A neural network has been developed that can aid in establishing point-topoint communication routes through multistage interconnection networks (MINs)
(Goudreau and Giles, 1991). Such interconnection networks have been widely studied (Huang, 1984; Siegel, 1990). The routing problem is of great interest due to
its broad applicability. Although the neural network routing scheme can accommodate many types of communication systems, this work concentrates on its use in a
shared-memory, distributed computing system.
Neural networks have sometimes been used to solve certain interconnection network
722

Neural Network Routing for Random Multistage Interconnection Networks

Input
Ports

Output
Ports

Interconnection
Network

Control Bits
-

: Logic1
I
L.: _ _ _ _ _

Neural
Network
_ _ ....
_-_-:--r-_~_

-

:1

Interconnection
Logic2:
Network
I
Controller
I

___'--_-_-_

-_-J:.J

Externa Control
Figure 1: The communication system with a neural network router. The input
ports (processors) are on the left, while the output ports (memory modules) are on
the right.

problems, such as finding legal routes (Brown, 1989; Hakim and Meadows, 1990)
and increasing the throughput of an interconnection network (Brown and Liu, 1990;
Marrakchi and Troudet, 1989). The neural network router that is the subject of
this work, however, differs significantly from these other routers and is specially
designed to handle parallel processing systems that have MINs with random interstage connections. Such random MINs are called RMINs. RMINs tend to have
greater fault-tolerance than regular MINs.
The problem is to allow a set of processors to access a set of memory modules
through the RMIN. A picture of the communication system with the neural network
router is shown in Figure 1. The are m processors and n memory modules. The
system is assumed to be synchronous. At the beginning of a message cycle, some
set of processors may desire to access some set of memory modules. It is the
job of the router to establish as many of these desired connections as possible in
a non-conflicting manner. Obtaining the optimal solution is not critical. Stymied
processors may attempt communication again during the subsequent message cycle.
It is the combination of speed and the quality of the solution that is important.
The object of this work was to discover if the neural network router could be competitive with other types of routers in terms of quality of solution, speed, and resource

723

724

Goudreau and Giles

RMIN2
RMINI
2

1

1
2

3

3
4
5
6

4

5
6

7
8

RMIN3
1

1

2

3

4

1

2
3

2
3

4

4

3

6

7
8

5

7
8
9

10

Figure 2: Three random multistage interconnection networks. The blocks that are
shown are crossbar switches, for which each input may be connected to each output.

utilization. To this end, the neural
other schemes for routing in RMINs
routing. So far, the results of this
router may indeed be a practicable
too large.

2

network routing scheme was compared to two
- namely, exhaustive search routing and greedy
investigation suggest that the neural network
alternative for routing in RMINs that are not

EXHAUSTIVE SEARCH ROUTING

The exhaustive search routing method is optimal in terms of the ability of the router
to find the best solution. There are many ways to implement such a router. One
approach is described here.
For a given interconnection network, every route from each input to each output
was stored in a database. (The RMIN s that were used as test cases in this paper
always had at least one route from each processor to each memory module.) When
a new message cycle began and a new message set was presented to the router,
the router would search through the database for a combination of routes for the
message set that had no conflicts. A conflict was said to occur if more than one
route in the set of routes used a single bus in the interconnection network. In the
case where every combination of routes for the message set had a conflict, the router
would find a combination of routes that could establish the largest possible number
of desired connections.

If there are k possible routes for each message, this algorithm needs a memory of
size 8( mnk) and, in the worst case, takes exponential time with respect to the size

Neural Network Routing for Random Multistage Interconnection Networks

of the message set. Consequently, it is an impractical approach for most RMINs,
but it provides a convenient upper bound for the performance of other routers.

3

GREEDY ROUTING

When greedy routing is applied, message connections are established one at a time.
Once a route is established in a given message cycle, it may not be removed. Greedy
routing does not always provide the optimal routing solution.
The greedy routing algorithm that was used required the same route database as
the exhaustive search router did. However, it selects a combination of routes in
the following manner. When a new message set is present, the router chooses one
desired message and looks at the first route on that message's list of routes. The
router then establishes that route. Next, the router examines a second message
(assuming a second desired message was requested) and sees if one of the routes
in the second message's route list can be established without conflicting with the
already established first message. If such a route does exist, the router establishes
that route and moves on to the next desired message.
In the worst case, the speed of the greedy router is quadratic with respect to the
size of the message set.

4

NEURAL NETWORK ROUTING

The focal point of the neural network router is a neural network of the type that
was examined by Hopfield (Hopfield, 1984 and 1985). The problem of establishing
a set of non-conflicting routes can be reduced to a constraint satisfaction problem.
The structure of the neural network router is completely determined by the RMIN.
When a new set of routes is desired, only certain bias currents in the network change.
The neural network routing scheme also has certain fault-tolerant properties that
will not be described here.
The neural network calculates the routes by converging to a legal routing array. A
legal routing array is 3-dimensional. Therefore, each element of the routing array
will have three indices. If element ai,i,k is equal to 1 then message i is routed
through output port k of stage j. We say ai,;,k and a',m,n are in the same row if
i = I and k = n. They are in the same column if i = I and j = m. Finally, they are
in the same rod if j = m and k = n.
A legal routing array will satisfy the following three constraints:
1. one and only one element in each column is equal to 1.

2. the elements in successive columns that are equal to 1 represent output ports
that can be connected in the interconnection network.
3. no more than one element in each rod is equal to 1.
The first restriction ensures that each message will be routed through one and
only one output port at each stage of the interconnection network. The second
restriction ensures that each message will be routed through a legal path in the

725

726

Goudreau and Giles

interconnection network. The third restriction ensures that any resource contention
in the interconnection network is resolved. In other words, only one message can
use a certain output port at a certain stage in the interconnection network. When
all three of these constraints are met, the routing array will provide a legal route
for each message in the message set.
Like the routing array, the neural network router will naturally have a 3-dimensional
structure. Each ai,j,k of a routing array is represented by the output voltage of a
neuron, V'i,j,k' At the beginning of a message cycle, the neurons have a random
output voltage. If the neural network settles in one of the global minima, the
problem will have been solved.
A continuous time mode network was chosen. It was simulated digitally. The neural
network has N neurons. The input to neuron i is Ui, its input bias current is Ii, and
its output is Vi. The input Ui is converted to the output Vi by a sigmoid function,
g(z). Neuron i influences neuron j by a connection represented by 7ji. Similarly,
neuron j affects neuron i through connection Iij. In order for the Liapunov function
(Equation 5) to be constructed, Iij must equal7ji. We further assume that Iii = O.
For the synchronous updating model, there is also a time constant, denoted by T.
The equations which describe the output of a neuron i are:
duo
LN T... v,. + L?
-'
J
,
dt = --' +
U?

(1)

~

T

.

J=

1

T=RC

(2)

V; = g(Uj)

(3)

1

(4)

g(z) = 1 + e-X

The equations above force the neural net into stable states that are the local minima
of this approximate energy equation
iNN

E = -

2L

N

2: Iij Vi V; - L V'i Ii

i=1j=1

(5)

i=l

For the neural network, the weights (Iii's) are set, as are the bias currents (Ii'S).
It is the output voltages (V'i's) that vary to to minimize E.

Let M be the number of messages in a message set, let S be the number of stages
in the RMIN, and let P be the number of ports per stage (P may be a function
of the stage number). Below are the energy functions that implement the three
constraints discussed above:
A M 8-1 P
P
(6)
E1 = 2'
Vm",p(-Vm",p +
Vm,3,i)
B

E2

2: L 2:

2:

m=1 1=1 p=l

i=1

8-1 P

M

M

= 2' 2: 2: 2: Vm,I,p( - Vm,3,p + L
,=1 p=1 m=1

i=1

V'i,3,p)

(7)

Neural Network Routing for Random Multistage Interconnection Networks

C
Ea =

"2

M

S-l P

P

2: 2: 2:( -2Vm",p + Vm",p(-Vm",p + 2: Vm",i))
m=l

,=1 p=l

f. ~]; tt
+ &,(
M

[S-l P

D

(8)

i=l
P

d(s, p, i)Vm,,-l,p Vm",i

(9)

d( 1, (JIm, j)Vm,IJ + d( S, j, Pm )Vm,S -IJ )]

A, B, C, and D are arbitrary positive constants. l El and Ea handle the first
constraint in the routing array. E4 deals with the second constraint. E2 ensures the
third. From the equation for E4, the function d(sl,pl,p2) represents the "distance"
between output port pI from stage sl - 1 and output port p2 from stage s1. If pI
can connect to p2 through stage sl, then this distance may be set to zero. If pI
and p2 are not connected through stage sl, then the distance may be set to one.
Also, am is the source address of message m, while f3m is the destination address
of message m.

The entire energy function is:

(10)
Solving for the connection and bias current values as shown in Equation 5 results
in the following equations:

(11)
-B031 ,,2 0pl,p2(1 - Oml,m2)
-D8m1,m2[031+1,,2d(s2,pl,p2) + 8,1,,2+1 d(sl,p2,pl)]

=

1m ",p C - D[8"ld(l, am,p) + o"s-ld(S,p,f3m)]
8i,j is a Kronecker delta (8j,j = 1 when i = j, and 0 otherwise).

(12)

Essentially, this approach is promising because the neural network is acting as a
parallel computer. The hope is that the neural network will generate solutions much
faster than conventional approaches for routing in RMINs.
The neural network that is used here has the standard problem - namely, a global
minimum is not always reached. But this is not a serious difficulty. Typically,
when the globally minimal energy is not reached by the neural network, some of
the desired routes will have been calculated while others will not have. Even a
locally minimal solution may partially solve the routing problem. Consequently,
this would seem to be a particularly encouraging type of application for this type
of neural network. For this application, the traditional problem of not reaching
the global minimum may not hurt the system's performance very much, while the
expected speed of the neural network in calculating the solution will be a great
asset.
IFor the simulations, T = 1.0, A
0, and D were chosen empirically.

= 0 = D = 3.0, and B = 6.0.

These values for A, B,

727

728

Goudreau and Giles

Table 1: Routing results for the RMINs shown in Figure 2. The
calculated due to their computational complexity.
RMIN1

M
1
2
3
4
5
6
7
8

RMIN2

* entries were not

RMIN3

Eel

Egr

Enn

Eel

Egr

Enn

Eel

Egr

Enn

1.00
1.86
2.54
3.08
3.53
3.89
4.16
4.33

1.00
1.83
2.48
2.98
3.38
3.67
3.91
4.10

1.00
1.87
2.51
2.98
3.24
3.45
3.66
3.78

1.00
1.97
2.91
3.80
4.65
5.44
6.17
6.86

1.00
1.97
2.91
3.79
4.62
5.39
6.13
6.82

1.00
1.98
2.93
3.80
4.61
5.36
6.13
6.80

1.00
1.99
2.99
3.94

1.00
1.88
2.71
3.49
4.22
4.90
5.52
6.10

1.00
1.94
2.87
3.72
4.54
5.23
5.80
6.06

*
*
*
*

The neural network router uses a large number of neurons. If there are m input
ports, and m output ports for each stage of the RMIN, an upper bound on the
number of neurons needed is m 2 S. Often, however, the number of neurons actually
required is much smaller than this upper bound.
It has been shown empirically that neural networks of the type used here can con-

verge to a solution in essentially constant time. For example, this claim is made for
the neural network described in (Takefuji and Lee, 1991), which is a slight variation
of the model used here.

5

SIMULATION RESULTS

Figure 2 shows three RMINs that were examined. The routing results for the three
routing schemes are shown in Table 1. Eel represents the expected number of
messages to be routed using exhaustive search routing. Egr is for greedy routing
while Enn is for neural network routing. These values are functions of the size
of the message set, M. Only message sets that did not have obvious conflicts
were examined. For example, no message set could have two processors trying to
communicate to the same memory module. The table shows that, for at least these
three RMINs, the three routing schemes produce solutions that are of similar virtue.
In some cases, the neural network router appears to outperform the supposedly
optimal exhaustive search router. That is because the Eel and Egr values were
calculated by testing every message set of size M, while Enn was calculated by
testing 1,000 randomly generated message sets of size M. For the neural network
router to appear to perform best, it must have gotten message sets that were easier
to route than average.
In general, the performance of the neural network router degenerates as the size of
the RMIN increases. It is felt that the neural network router in its present form will
not scale well for large RMINs. This is because other work has shown that large
neural networks of the type used here have difficulty converging to a valid solution
(Hopfield, 1985).

Neural Network Routing for Random Multistage Interconnection Networks

6

CONCLUSIONS

The results show that there is not much difference, in terms of quality of solution, for
the three routing methodologies working on these relatively small sample RMINs.
The exhaustive search approach is clearly not a practical approach since it is too
time consuming. But when considering the asymptotic analyses for these three
methodologies one should keep in mind the performance degradation of the greedy
router and the neural network router as the size of the RMIN increases.
Greedy routing and neural network routing would appear to be valid approaches
for RMINs of moderate size. But since asymptotic analysis has a very limited
significance here, the best way to compare the speeds of these two routing schemes
would be to build actual implementations.
Since the neural network router essentially calculates the routes in parallel, it can
reasonably be hoped that a fast, analog implementation for the neural network
router may find solutions faster than the exhaustive search router and even the
greedy router. Thus, the neural network router may be a viable alternative for
RMIN s that are not too large.
References

Brown, T. X., (1989), "Neural networks for switching," IEEE Commun. Mag., Vol.
27, pp. 72-81, Nov. 1989.
Brown, T. X. and Liu, K. H., (1990), "Neural network design of a banyan network
controller," IEEE J. on Selected Areas of Comm., pp. 1428-1438, Oct. 1990.
Goudreau, M. W. and Giles, C. L., (1991), "Neural network routing for multiple
stage interconnection networks," Proc. IJCNN 91, Vol. II, p. A-885, July 1991.
Hakim, N. Z. and Meadows, H. E., (1990), "A neural network approach to the setup
of the Benes switch," in Infocom 90, pp. 397-402.
Hopfield, J. J., (1984), "Neurons with graded response have collective computational
properties like those of two-state neurons," Proc. Natl. Acad. Sci. USA, Vol. 81,
pp. 3088-3092, May 1984.
Hopfield, J. J ., (1985), "Neural computation on decisions in optimization problems,"
Bioi. Cybern., Vol. 52, pp. 141-152, 1985.
Huang, K. and Briggs, F. A., (1984), Computer Architecture and Parallel Processing,
McGraw-Hill, New York, 1984.
Marrakchi, A. M. and Troudet, T., (1989), "A neural net arbitrator for large crossbar packet-switches," IEEE Trans. on Cire. and Sys., Vol. 36, pp. 1039-1041, July
1989.
Siegel, H. J., (1990), Interconnection Networks for Large Scale Parallel Processing,
McGraw-Hill, New York, 1990.
Takefuji, Y. and Lee, K. C., (1991), "An artificial hysteresis binary neuron: a model
suppressing the oscillatory behaviors of neural dynamics", Biological Cybernetics,
Vol. 64, pp. 353-356, 1991.

729


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1193-a-new-approach-to-hybrid-hmmann-speech-recognition-using-mutual-information-neural-networks.pdf

A New Approach to Hybrid HMMJANN Speech
Recognition Using Mutual Information Neural
Networks
G. Rigoll,

c.

Neukirchen

Gerhard-Mercator-University Duisburg
Faculty of Electrical Engineering
Department of Computer Science
Bismarckstr. 90, Duisburg, Germany

ABSTRACT
This paper presents a new approach to speech recognition with hybrid
HMM/ANN technology. While the standard approach to hybrid
HMMIANN systems is based on the use of neural networks as
posterior probability estimators, the new approach is based on the use
of mutual information neural networks trained with a special learning
algorithm in order to maximize the mutual information between the
input classes of the network and its resulting sequence of firing output
neurons during training. It is shown in this paper that such a neural
network is an optimal neural vector quantizer for a discrete hidden
Markov model system trained on Maximum Likelihood principles.
One of the main advantages of this approach is the fact, that such
neural networks can be easily combined with HMM's of any
complexity with context-dependent capabilities. It is shown that the
resulting hybrid system achieves very high recognition rates, which
are now already on the same level as the best conventional HMM
systems with continuous parameters, and the capabilities of the
mutual information neural networks are not yet entirely exploited.

1 INTRODUCTION
Hybrid HMM/ANN systems deal with the optimal combination of artificial neural
networks (ANN) and hidden Markov models (HMM). Especially in the area of automatic
speech recognition, it has been shown that hybrid approaches can lead to very powerful
and efficient systems, combining the discriminative capabilities of neural networks and
the superior dynamic time warping abilities of HMM's. The most popular hybrid
approach is described in (Hochberg, 1995) and replaces the component modeling the
emission probabilities of the HMM by a neural net. This is possible, because it is shown

Mutual In/ormation Neural Networks/or Hybrid HMMIANN Speech Recognition

773

in (Bourlard, 1994) that neural networks can be trained so that the output of the m-th
neuron approximates the posterior probability p(QmIX). In this paper, an alternative
method for constructing a hybrid system is presented. It is based on the use of discrete
HMM's which are combined with a neural vector quantizer (VQ) in order to form a hybrid
system. Each speech feature vector is presented to the neural network, which generates a
firing neuron in its output layer. This neuron is processed as VQ label by the HMM's.
There are the following arguments for this alternative hybrid approach:
? The neural vector quantizer has to be trained on a special information theory criterion,
based on the mutual information between network input and resulting neuron firing
sequence. It will be shown that such a network is the optimal acoustic processor for a
discrete HMM system, resulting in a profound mathematical theory for this approach.
? Resulting from this theory, a formula can be derived which jointly describes the
behavior of the HMM and the neural acoustic processor. In that way, both systems can
be described in a unified manner and both major components of the hybrid system can
be trained using a unified learning criterion.
? The above mentioned theoretical background leads to the development of new neural
network paradigms using novel training algorithms that have not been used before in
other areas of neurocomputing, and therefore represent major challenges and issues in
learning and training for neural systems.
? The neural networks can be easily combined with any HMM system of arbitrary
complexity. This leads to the combination of optimally trained neural networks with
very powerful HMM's, having all features useful for speech recognition, e.g. triphones,
function words, crossword triphones, etc .. Context-dependency, which is very desirable
but relatively difficult to realize with a pure neural approach, can be left to the HMM's.
? The resulting hybrid system has still the basic structure of a discrete system, and
therefore has all the effective features associated with discrete systems, e.g. quick and
easy training as well as recognition procedures, real-time capabilities, etc ..
? The work presented in this paper has been also successfully implemented for a
demanding speech recognition problem, the 1000 word speaker-independent continuous
Resource Management speech recognition task. For this task, the hybrid system
produces one of the best recognition results obtained by any speech recognition system.
In the following section, the theoretical foundations of the hybrid approach are briefly
explained. A unified probabilistic model for the combined HMMIANN system is derived,
describing the interaction of the neural and the HMM component. Furthermore, it is
shown that the optimal neural acoustic processor can be obtained from a special
information theoretic network training algorithm.

2 INFORMATION THEORY PRINCIPLES FOR NEURAL
NETWORK TRAINING
We are considering now a neural network of arbitrary topology used as neural vector
quantizer for a discrete HMM system. If K patterns are presented to the hybrid system
during training, the feature vectors resulting from these patterns using any feature
extraction method can be denoted as x(k), k=l.. .K. If these feature vectors are presented to
the input layer of a neural network, the network will generate one firing neuron for each
presentation. Hence, all K presentations will generate a stream of firing neurons with
length K resulting from the output layer of the neural net. This label stream is denoted as
Y=y(l) ... y(K). The label stream Y will be presented to the HMM's, which calculate the
probability that this stream has been observed while a pattern of a certain class has been
presented to the system. It is assumed, that M different classes Q m are active in the

G. Rigoll and C. Neukirchen

774

system, e.g. the words or phonemes in speech recognition. Each feature vector ~(k) will
belong to one of these classes. The class Om, to which feature vector ~(k) belongs is
denoted as Q(k). The major training issue for the neural network can be now formulated
as follows : How should the weights of the network be trained, so that the network
produces a stream of firing neurons that can be used by the discrete HMM's in an optimal
way? It is known that HMM's are usually trained with information theory methods which
mostly rely on the Maximum Likelihood (ML) principle. If the parameters of the hybrid
system (i.e. transition and emission probabilities and network weights) are summarized in
the vector !!, the probability P!!(x(k)IQ(k? denotes the probability of the pattern X at
discrete time k, under the assumption that it has been generated by the model representing
class O(k), with parameter set !!. The ML principle will then try to maximize the joint
probability of all presented training patterns ~(k), according to the following Maximum
Likelihood function:
fl* = arg max
~

{~ i

log P!! (K(k) I Q(k?j
(1)

k=1

where !!* is the optimal parameter vector maximizing this equation. Our goal is to feed
the feature vector ~ into a neural network and to present the neural network output to the
Markov model. Therefore, one has to introduce the neural network output in a suitable
manner into the above formula. If the vector ~ is presented to the network input layer, and
we assume that there is a chance that any neuron Yn, n=1...N (with network output layer
size N) can fire with a certain probability, then the output probability p(~IQ) in (1) can
be written as:
N
N
p(KIQ) =
p(x ,Y n IQ) =
p(y n IQ) . p(x Iy n,Q)
(2)
n=1
n=1
Now, the combination of the neural component with the HMM can be made more
obvious: In (2), typically the probability P(YnIQ) will be described by the Markov model,
in terms of the emission probabilities of the HMM . For instance, in continuous
parameter HMM's, these probabilities are interpreted as weights for Gaussian mixtures. In
the case of semi-continuous systems or discrete HMM's, these probabilities will serve as
discrete emission probabilities of the codebook labels. The probability p(xIYn,Q)
describes the acoustic processor of the system and is characterizing the relation between
the vector ~ as input to the acoustic processor and the label Yn, which can be considered
as the n-th output component of the acoustic processor. This n-th output component may
characterize e.g. the n-th Gaussian mixture component in continuous parameter HMM's,
or the generation of the n-th label of a vector quantizer in a discrete system. This
probability is often considered as independent of the class 0 and can then be expressed as
p(xIYn). It is exactly this probability, that can be modeled efficiently by our neural
network. In this case, the vector X serves as input to the neural network and Yn
characterizes the n-th neuron in the output layer of the network. Using Bayes law, this
probability can be written as:
P(YnIK) ' pW
p(xl Yn) =
p(y n)

I

I

(3)

yielding for (2):

(4)
Using again Bayes law to express

Mutual Information Neural Networks for Hybrid HMMIANN Speech Recognition

775

(5)

one obtains from (4):
p(K)
N
p(KI.Q)= -(.Q) . L p(.Qly n ) ?p(ynlo!J
p
n=1
(6)
We have now modified the class-dependent probability of the feature vector X in a way
that allows the incorporation of the probability P(YnIX). This probability allows a better
characterization of the behavior of the neural network, because it describes the probability
of the various neurons Yn, if the vector X is presented to the network input. Therefore,
these probabilities give a good description of the input/output behavior of the neural
network. Eq. (6) can therefore be considered as probabilistic model for the hybrid system,
where the neural acoustic processor is characterized by its input/output behavior. Two
cases can be now distinguished: In the first case, the neural network is assumed to be a
probabilistic paradigm, where each neuron fires with a certain probability, if an input
vector is presented. In this case all neurons contribute to the information forwarded to the
HMM's. As already mentioned, in this paper, the second possible case is considered,
namely that only one neuron in the output layer fires and will be fed as observed label to
the HMM. In this case, we have a deterministic decision, and the probability P(YnIX)
describes what neuron Yn* fires if vector X is presented to the input layer. Therefore, this
probability reduces to
(7)

Then, (6) yields:
(8)

Now, the class-dependent probability p(Xln) is expressed through the probability
p(nIYn*), involving directly the firing neuron Yn*, when feature vector X is presented.
One has now to turn back to (1), recalling the fact, that this equation describes the fact
that the Markov models are trained with the ML criterion. It should also be recalled, that
the entire sequence of feature vectors, x(k), k=l...K, results in a label stream of firing
neurons Yn*(k), k=l...K, where Yn*(k) is the firing neuron if the k-th vector x(k) is
presented to the neural network. Now, (8) can be substituted into (1) for each presentation
k, yielding the modified ML criterion:

1( =

arg;ax {

::1
K

p(x(k))
}
log P(Q (k)) . p(.Q(k) I Y n*,k))

~ arg;ax {~, log p(x (k)) - ~109P(Q(k)) + ~IOg p(Q(k) IYn.(k))}

(9)

Usually, in a continuous parameter system, the probability p(x) can be expressed as:
N

p(K)

=

LP(K,ly n) . p(y n)
n=1

(10)

and is therefore dependent of the parameter vector ft, because in this case, p(xIYn) can be
interpreted as the probability provided by the Gaussian distributions, and the parameters of

G. Rigoll and C. Neukirchen

776

the Gaussians will depend on ft. As just mentioned before, in a discrete system, only one
firing neuron Yn* survives, resulting in the fact that only the n*-th member remains in
the sum in (10). This would correspond to only one "firing Gaussian" in the continuous
case, leading to the following expression for p(x):
p(K)

= p(x Iy nJ? p(y nJ = p(K,y nJ = p(y n"lx)

. p(x)

(11)

Considering now the fact, that the acoustic processor is not represented by a Gaussian but
instead by a vector quantizer, where the probability P(Yn*IX) of the firing neuron is equal
to 1, then (11) reduces to p(~) =p(x) and it becomes obvious that this probability is not
affected by any distribution that depends on the parameter vector ft. This would be
different, if P(Yn*IX) in (11) would not have binary characteristics as in (7), but would be
computed by a continuous function which in this case would depend on the parameter
vector ft. Thus, without consideration of p(X), the remaining expression to be maximized
in (9) reduces to:

,r( =arg;ax

[~ ~IOg p(.Q( k)) +

= arg max [-

!

1

log p(.Q( k) I Y n?(k))

(12)

E {log p(.o)} + E {log p(.o I y n")}]

fJ..
These expectations of logarithmic probabilities are also defined as entropies. Therefore,
(9) can be also written as
fl." = arg max {H (.0) - H(.o I Y)}

fJ..

(13)

This equation can be interpreted as follows: The term on the right side of (13) is also
known as the mutual information I(n,Y~ between the probabilistic variables nand Y,
i.e. :
1(.0, Y) =H(.o) - H (.01 Y) =H (Y) - H(YI.o)
(14)
Therefore, the final information theory-based training criterion for the neural network can
be formulated as follows: The synaptic weights of the neural network should be chosen as
to maximize the mutual information between the string representing the classes of the
vectors presented to the network input layer during training and the string representing the
resulting sequence of firing neurons in the output layer of the neural network. This can be
also expressed as the Maximum Mutual Information (MMI) criterion for neural network
training. This concludes the proof that MMI neural networks are indeed optimal acoustic
processors for HMM's trained with maximum likelihood principles.

3 REALIZATION OF MMI TRAINING ALGORITHMS FOR
NEURAL NETWORKS
Training the synaptic weights of a neural network in order to achieve mutual information
maximization is not easy. Two different algorithms have been developed for this task and
can only be briefly outlined in this paper. A detailed description can be found in (Rigoll,
1994) and (Neukirchen, 1996). The first experiments used a single-layer neural network
with Euclidean distance as propagation function. The first implementation of the MMI
training paradigm has been realized in (Rigoll, 1994) and is based on a self-organizing
procedure, starting with initial weights derived from k-means clustering of the training
vectors, followed by an iterative procedure to modify the weights. The mutual
information increases in a self-organizing way from a low value at the start to a much
higher value after several iteration cycles. The second implementation has been realized

Mutual Information Neural Networks for Hybrid HMMIANN Speech Recognition

777

recently and is described in detail in (Neukirchen, 1996). It is based on the idea of using
gradient methods for finding the MMI value. This technique has not been used before,
because the maximum search for finding the firing neuron in the output layer has
prevented the calculation of derivatives. This maximum search can be approximated using
the softmax function, denoted as sn for the n-th neuron. It can be computed from the
activations Zl of all neurons as:
z IT

Sn=e n

N

""

/ ?..Je

ZI

IT

/=1
(15)
where a small value for parameter T approximates a crisp maximum selection. Since the
string n in (14) is always fixed during training and independent of the parameters in ft,
only the function H(nIY) has to be minimized. This function can also be expressed as

M

H(!2 I Y)

=-

N

L L

p(y n,!2 m ) ?logp(!2 m I Y n)

m=1 n=1

m=1 n=1

(16)

A derivative with respect to a weight Wlj of the neural network yields:
aH (!21 Y)
JW/j

=
(17)

As shown in (Neukirchen, 1996), all the required terms in (17) can be computed
effectively and it is possible to realize a gradient descend method in order to maximize the
mutual information of the training data. The great advantage of this method is the fact
that it is now possible to generalize this algorithm for use in all popular neural network
architectures, including multilayer and recurrent neural networks.

4 RESULTS FOR THE HYBRID SYSTEM
The new hybrid system has been developed and extensively tested using the Resource
Management 1000 word speaker-independent continuous speech recognition task. First, a
baseline discrete HMM system has been built up with all well-known features of a
context-dependent HMM system. The performance of that baseline system is shown in
column 2 of Table 1. The 1st column shows the performance of the hybrid system with
the neural vector quantizer. This network has some special features not mentioned in the
previous sections, e.g. it uses multiple frame input and has been trained on contextdependent classes. That means that the mutual information between the stream of firing
neurons and the corresponding input stream of triphones has been maximized. In this
way, the firing behavior of the network becomes sensitive to context-dependent units.
Therefore, this network may be the only existing context-dependent acoustic processor,
carrying the principle of triphone modeling from the HMM structure to the acoustic front
end. It can be seen, that a substantially higher recognition performance is obtained with
the hybrid system, that compares well with the leading continuous system (HTK, in
column 3). It is expected, that the system will be further improved in the near future
through various additional features, including full exploitation of multilayer neural VQ's

778

G. Rigoll and C. Neukirchen

and several conventional HMM improvements, e.g. the use of crossword triphones.
Recent results on the larger Wall Street Journal (WSJ) database have shown a 10.5% error
rate for the hybrid system compared to a 13.4% error rate for a standard discrete system,
using the 5k vocabulary test with bigram language model of perplexity 110. This error
rate can be further reduced to 8.9% using crossword triphones and 6.6% with a trigram
language model. This rate compares already quite favorably with the best continuous
systems for the same task. It should be noted that this hybrid WSJ system is still in its
initial stage and the neural component is not yet as sophisticated as in the RM system.

5 CONCLUSION
A new neural network paradigm and the resulting hybrid HMMIANN speech recognition
system have been presented in this paper. The new approach performs already very well
and is still perfectible. It gains its good performance from the following facts: (1) The use
of information theory-based training algorithms for the neural vector quantizer, which can
be shown to be optimal for the hybrid approach. (2) The possibility of introducing
context-dependency not only to the HMM's, but also to the neural quantizer. (3) The fact
that this hybrid approach allows the combination of an optimal neural acoustic processor
with the most advanced context-dependent HMM system. We will continue to further
implement various possible improvements for our hybrid speech recognition system.

REFERENCES
Rigoll, G. (1994) Maximum Mutual Information Neural Networks for Hybrid
Connectionist-HMM Speech Recognition Systems, IEEE Transactions on Speech and
Audio Processing, Vol. 2, No.1, Special Issue on Neural Networks for Speech
Processing, pp. 175-184
Neukirchen, C. & Rigoll, G. (1996) Training of MMI Neural Networks as Vector
Quantizers, Internal Report, Gerhard-Mercator-University Duisburg, Faculty of Electrical
Engineering, available via http://www.fb9-tLuni-duisburg.de/veroeffentl.html
Bourlard, H. & Morgan, N. (1994) Connectionist Speech Recognition: A Hybrid
Approach, Kluwer Academic Publishers
Hochberg, M., Renals, S., Robinson, A., Cook, G. (1995) Recent Improvements to the
ABBOT Large Vocabulary CSR System, in Proc. IEEE-ICASSP, Detroit, pp. 69-72
Rigoll, G., Neukirchen, c., Rottland, J. (1996) A New Hybrid System Based on MMINeural Networks for the RM Speech Recognition Task, in Proc. IEEE-ICASSP, Atlanta
Table 1: Comparison of recognition rates for different speech recognition systems
RM SI word recognition rate with word pair grammar: correctness (accuracy)
test set

hybrid MMI-NN
system

baseline k-means
VQ system

continuous pdf system
(HTK)

Feb.'89

96,3 %

(95,6 %)

94,3 % (93,6 %)

96,0 % (95,5 %)

Oct.'89

95,4 %

(94,5 %)

93,5 % (92,0 %)

95,4% (94,9 %)

Feb.'91

96,7 %

(95,9 %)

94,4% (93,5 %)

96,6% (96,0 %)

Sep.'92

93,9 %

(92,5 %)

90,7 % (88,9 %)

93,6 % (92,6 %)

average

95,6 %

(94,6 %)

93,2 % (92,0 %)

95,4% (94,7 %)


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1162-experiments-with-neural-networks-for-real-time-implementation-of-control.pdf

Experiments with Neural Networks for Real
Time Implementation of Control
P. K. Campbell, M. Dale, H. L. Ferra and A. Kowalczyk
Telstra Research Laboratories
770 Blackburn Road Clayton, Vic. 3168, Australia
{p.campbell, m.dale, h.ferra, a.kowalczyk}@trl.oz.au

Abstract
This paper describes a neural network based controller for allocating
capacity in a telecommunications network. This system was proposed in
order to overcome a "real time" response constraint. Two basic
architectures are evaluated: 1) a feedforward network-heuristic and; 2) a
feedforward network-recurrent network. These architectures are
compared against a linear programming (LP) optimiser as a benchmark.
This LP optimiser was also used as a teacher to label the data samples
for the feedforward neural network training algorithm. It is found that
the systems are able to provide a traffic throughput of 99% and 95%,
respectively, of the throughput obtained by the linear programming
solution. Once trained, the neural network based solutions are found in a
fraction of the time required by the LP optimiser.

1 Introduction
Among the many virtues of neural networks are their efficiency, in terms of both execution
time and required memory for storing a structure, and their practical ability to approximate
complex functions. A typical drawback is the usually "data hungry" training algorithm.
However, if training data can be computer generated off line, then this problem may be
overcome. In many applications the algorithm used to generate the solution may be
impractical to implement in real time. In such cases a neural network substitute can
become crucial for the feasibility of the project. This paper presents preliminary results for
a non-linear optimization problem using a neural network. The application in question is
that of capacity allocation in an optical communications network. The work in this area is
continuing and so far we have only explored a few possibilities.

2 Application: Bandwidth Allocation in SDH Networks
Synchronous Digital Hierarchy (SDH) is a new standard for digital transmission over
optical fibres [3] adopted for Australia and Europe equivalent to the SONET
(Synchronous Optical NETwork) standard in North America. The architecture of the
particular SDH network researched in this paper is shown in Figure 1 (a).
1)

Nodes at the periphery of the SDH network are switches that handle individual
calls.

P. CAMPBELL, M. DALE, H. L. FERRA, A. KOWALCZYK

974

2) Each switch concentrates traffic for another switch into a number of streams.
3)

Each stream is then transferred to a Digital Cross-Connect (DXC) for switching and
transmission to its destination by allocating to it one of several alternative virtual
paths.

The task at hand is the dynamic allocation of capacities to these virtual paths in order to
maximize SDH network throughput.
This is a non-linear optimization task since the virtual path capacities and the constraints,
i.e. the physical limit on capacity of links between DXC's, are quantized, and the objective
function (Erlang blocking) depends in a highly non-linear fashion on the allocated
capacities and demands. Such tasks can be solved 'optimally' with the use of classical
linear programming techniques [5], but such an approach is time-consuming - for large
SDH networks the task could even require hours to complete.
One of the major features of an SDH network is that it can be remotely reconfigured using
software controls. Reconfiguration of the SDH network can become necessary when
traffic demands vary, or when failures occur in the DXC's or the links connecting them.
Reconfiguration in the case of failure must be extremely fast, with a need for restoration
times under 60 ms [1].
(b)
output: path
capacities
synaptic weights
(22302)
hidden units:
'AND' gates
(l10)

thresholds
(738,67 used)
input

o

link
capacities

DXC (Digital
Cross-Connect)

?

offered
traffic

Switch

Figure 1
(a) Example of an Inter-City SDH/SONET Network Topology used in experiments.
(b) Example of an architecture of the mask perceptron generated in experiments.

In our particular case, there are three virtual paths allocated between any pair of switches,
each using a different set of links between DXC's of the SDH network. Calls from one
switch to another can be sent along any of the virtual paths, leading to 126 paths in total (7
switches to 6 other switches, each with 3 paths).
The path capacities are normally set to give a predefined throughput. This is known as the
"steady state". If links in the SDH network become partially damaged or completely cut,
the operation of the SDH network moves away from the steady state and the path
capacities must be reconfigured to satisfy the traffic demands subject to the following
constraints:
(i) Capacities have integer values (between 0 and 64 with each unit corresponding to a
2 Mb/s stream, or 30 Erlangs),
(ii) The total capacity of all virtual paths through anyone link of the SDH network

Experiments with Neural Networks for Real Time Implementation of Control

975

cannot exceed the physical capacity of that link.
The neural network training data consisted of 13 link capacities and 42 traffic demand
values, representing situations in which the operation of one or more links is degraded
(completely or partially). The output data consisted of 126 integer values representing the
difference between the steady state path capacities and the final allocated path capacities.

3 Previous Work
The problem of optimal SDH network reconfiguration has been researched already. In
particular Gopal et. al. proposed a heuristic greedy search algorithm [4] to solve this nonlinear integer programming problem. Herzberg in [5] reformulated this non-linear integer
optimization problem as a linear programming (LP) task, Herzberg and Bye in [6]
investigated application of a simplex algorithm to solve the LP problem, whilst Bye [2]
considered an application of a Hopfield neural network for this task, and finally Leckie [8]
used another set of AI inspired heuristics to solve the optimization task.
All of these approaches have practical deficiencies; the linear programming is slow, while
the heuristic approaches are relatively inaccurate and the Hopfield neural network method
(simulated on a serial computer) suffers from both problems.
In a previous paper Campbell et al. [10] investigated application of a mask perceptron to
the problem of reconfiguration for a "toy" SDH network. The work presented here
expands on the work in that paper, with the idea of using a second stage mask perceptron
in a recurrent mode to reduce link violationslunderutilizations.

4 The Neural Controller Architecture
Instead of using the neural network to solve the optimization task, e.g. as a substitute for
the simplex algorithm, it is taught to replicate the optimal LP solution provided by it.
We decided to use a two stage approach in our experiments. For the first stage we
developed a feedforward network able to produce an approximate solution. More
precisely, we used a collection of 2000 random examples for which the linear
programming solution of capacity allocations had been pre-computed to develop a
feedforward neural network able to approximate these solutions.
Then, for a new example, such an "approximate" neural network solution was rounded to
the nearest integer, to satisfy constraint (i), and used to seed the second stage providing
refinement and enforcement of constraint (ii).
For the second stage experiments we initially used a heuristic module based on the Gopal
et al. approach [4]. The heuristic firstly reduces the capacities assigned to all paths which
cause a physical capacity violation on any links, then subsequently increases the capacities
assigned to paths across links which are being under-utilized.
We also investigated an approach for the second stage which uses another feedforward
neural network. The teaching signal for the second stage neural network is the difference
between the outputs from the first stage neural network alone and the combined first stage
neural networkiheuristic solution. This time the input data consisted of 13 link usage
values (either a link violation or underutilization) and 42 values representing the amount
of traffic lost per path for the current capacity allocations. The second stage neural
network had 126 outputs representing the correction to the first stage neural network's
outputs.
The second stage neural network is run in a recurrent mode, adjusting by small steps the
currently allocated link capacities, thereby attempting to iteratively move closer to the
combined neural-heuristic solution by removing the link violations and under-utilizations
left behind by the first stage network.
The setup used during simulation is shown in Figure 2. For each particular instance tested
the network was initialised with the solution from the first stage neural network. The
offered traffic (demand) and the available maximum link capacities were used to
determine the extent of any link violations or underutilizations as well as the amount of
lost traffic (demand satisfaction). This data formed the initial input to the second stage
network. The outputs of the neural network were then used to check the quality of the

976

P. CAMPBELL, M. DALE, H. L. FERRA, A. KOWALCZYK

solution, and iteration continued until either no link violations occurred or a preset
maximum number of iterations had been performed.
offered traffic
link capacities

computation of
constraint-demand
satisfaction

[........ ~ ........-. ....
-----~(+)

!

solution (t-l)

solution (t)
correction (t)

!

I!
initialization:
solution (0)
from stage 1

demand satisfaction (t-l
42 inputs
link capacities
violation!underutilization (t-l)

13 inputs

Figure 2. Recurrent Network used for second stage experiments.
When computing the constraint satisfaction the outputs of the neural network where
combined and rounded to give integer link violations/under-utilizations. This means that
in many cases small corrections made by the network are discarded and no further
improvement is possible. In order to overcome this we introduced a scheme whereby
errors (link violations/under-utilizations) are occasionally amplified to allow the network a
chance of removing them. This scheme works as follows :
1) an instance is iterated until it has either no link violations or until 10 iterations have
been performed;
2) if any link violations are still present then the size of the errors are multiplied by an
amplification factor (> 1);
3)

a further maximum of 10 iterations are performed;

4) if subsequently link violations persist then the amplification factor is increased;
the procedure repeats until either all link violations are removed or the amplification factor
reaches some fixed value.

S Description of Neural Networks Generated
The first stage feedforward neural network is a mask perceptron [7], c.f. Figure 1 (b). Each
input is passed through a number of arbitrarily chosen binary threshold units. There were a
total of 738 thresholds for the 55 inputs. The task for the mask perceptron training
algorithm [7] is to select a set of useful thresholds and hidden units out of thousands of
possibilities and then to set weights to minimize the mean-square-error on the training set.
The mask perceptron training algorithm automatically selected 67 of these units for direct
connection to the output units and a further 110 hidden units ("AND" gates) whose

Experiments with Neural Networks for Real Time Implementation of Control

977

outputs are again connected to the neural network outputs, giving 22,302 connections in
all.
Such neural networks are very rapid to simulate since the only operations required are
comparison and additions.
For the recurrent network used in the second stage we also used a mask perceptron. The
training algori thIn used for the recurrent network was the same as for the first stage, in
particular note that no gradual adaptation was employed. The inputs to the network are
passed through 589 arbitrarily chosen binary threshold units. Of these 35 were selected by
the training algorithm for direct connection to the output units via 4410 weighted links.

6 Results
The results are presented in Table 1 and Figure 3. The values in the table represent the
traffic throughput of the SDH network, for the respective methods, as a percentage of the
throughput determined by the LP solution. Both the neural networks were trained using
2000 instances and tested against a different set of 2000 instances. However for the
recurrent network approximately 20% of these cases still had link violations after
simulation so the values in Table 1 are for the 80% of valid solutions obtained from either
the training or test set.
Solution type
Feedforward Net/Heuristic
Feedforward Net/Recurrent Net
Gopal-S
Gopal-O

Training
99.08%
94.93% (*)
96.38%
85.63%

Test
98 .90%,

94.76%(*)
96.20%
85.43%

(*) these numbers are for the 1635 training and 1608 test instances (out of 2000) for which the
recurrent network achieved a solution with no link violations after simulation as described in
Section 3.

Table 1. Efficiency of solutions measured by average fraction of the ' optimal'
throughput of the LP solution
As a comparison we implemented two solely heuristic algorithms. We refer to these as
Gopal-S and Gopal-O. Both employ the same scheme described earlier for the Gopal et al.
heuristic. The difference between the two is that Gopal-S uses the steady state solution as
an initial starting point to determine virtual path capacities for a degraded network,
whereas Gopal-O starts from a point where all path capacities are initially set to zero.
Referring to Figure 3, link capacity ratio denotes the total link capacity of the degraded
SDH network relative to the total link capacity of the steady state SDH network. A low
value of link capacity ratio indicates a heavily degraded network. The traffic throughput
ratio denotes the ratio between the throughput obtained by the method in question, and the
throughput of the steady state solution.
Each dot in the graphs in Figure 3 represents one of the 2000 test set cases. It is clear from
the figure that the neural network/heuristic approach is able to find better solutions for
heavily degraded networks than each of the other approaches. Overall the clustering of
dots for the neural network/heuristic combination is tighter (in the y-direction) and closer
to 1.00 than for any of the other methods. The results for the recurrent network are very
encouraging being qUalitatively quite close to those for the Gopal-S algorithm.
All experiments were run on a SPARCStation 20. The neural network training took a few
minutes. During simulation the neural network took an average of 9 ms per test case with
a further 36.5 ms for the heuristic, for a total of 45.5 ms. On average the Gopal-S
algorithm required 55.3 ms and the Gopal-O algorithm required 43.7 ms per test case. The
recurrent network solution required an average of 55.9 ms per test case. The optimal
solutions calculated using the linear programming algorithm took between 2 and 60
seconds per case on a SPARCStation 10.

978

P. CAMPBELL, M. DALE, H. L. FERRA, A. KOWALCZYK

Neural Network/Heuristic

Recurrent Neural Network

1.00

.2

~

0.95

8.

0.90

.r:

0>

is

0 .85

.!.!
~

0 .80

.c
t~

?? , _ ._0 ?? _ ? ?? ? ? ? ?? : ? ? ?? :.'???

0.60

0 .10

0 .80

0.90

0.70 0.50

1.00

link Capacity Ratio

1.00

ra
cr
~
.r:

0 .95

6

0.85

,g

0 .80

0 .90

"

" - -' - "~':'

.2
r.;

..... ...~ ...... -... --- -.. ..

0 .95

cr
~ 0.90
.r:

0>

0>

5

0.85

.~

0 .80

.ct~

~

~

1.00

1.00

? ? ? :? ? :? ?:,,~i~ffI~
.-. -,.

0.60 0 .70 0 .80 0.90
Link Capacity Ratio

Gopal-O

Gopal-S

.ct-

_ ?? ? ? ? _????????

0.75
0.70 0 .50

.2

:.~'?? : ? ???? :. '0""

~

0 .75
0.70 0.50

0.60

0.70

0.80

0 .90

link Capacity Ratio

1.00

0 .75

0.70 0.50

0.60 0.70 0.80 0 .90
Link Capacily Ratio

100

Figure 3. Experimental results for the Inter-City SDH network (Fig. 1) on the
independent test set of 2000 random cases. On the x axis we have the ratio
between the total link capacity of the degraded SDH network and the steady state
SDH network. On the y axis we have the ratio between the throughput obtained
by the method in question, and the throughput of the steady state solution.
Fig 3. (a) shows results for the neural network combined with the heuristic
second stage. Fig 3. (b) shows results for the recurrent neural network second
stage. Fig 3. (c) shows results for the heuristic only, initialised by the steady state
(Gopal-S) and Fig 3. (d) has the results for the heuristic initialised by zero
(Gopal-O).

7 Discussion and Conclusions
The combined neural network/heuristic approach performs very well across the whole
range of degrees of SDH network degradation tested. The results obtained in this paper are
consistent with those found in [10]. The average accuracy of -99% and fast solution
generation times ? ffJ ms) highlight this approach as a possible candidate for
implementation in a real system, especially when one considers the easily achievable
speed increase available from parallelizing the neural network. The mask perceptron used
in these experiments is well suited for simulation on a DSP (or other hardware) : the
operations required are only comparisons, calculation of logical "AND" and the
summation of synaptic weights (no multiplications or any non-linear transfonnations are
required).
The interesting thing to note is the relatively good perfonnance of the recurrent network,
namely that it is able to handle over 80% of cases achieving very good perfonnance when
compared against the neural network/heuristic solution (95% of the quality of the teacher).
One thing to bear in mind is that the heuristic approach is highly tuned to producing a
solution which satisfies the constraints, changing the capacity of one link at a time until
the desired goal is achieved. On the other hand the recurrent network is generic and does
not target the constraints in such a specific manner, making quite crude global changes in

Experiments with Neural Networks for Real Time Implementation of Control

979

one hit, and yet is still able to achieve a reasonable level of performance. While the speed
for the recurrent network was lower on average than for the heuristic solution in our
experiments, this is not a major problem since many improvements are still possible and
the results reported here are only preliminary, but serve to show what is possible. It is
planned to continue the SOH network experiment in the future; with more investigation on
the recurrent network for the second stage and also more complex SDH architectures.

Acknowledgments
The research and development reported here has the active support of various sections and
individuals within the Telstra Research Laboratories (TRL), especially Dr. C. Leckie, Mr.
P. Sember, Dr. M. Herzberg, Mr. A. Herschtal and Dr. L. Campbell. The permission of the
Managing Director, Research and Information Technology, Telstra, to publish this paper is
acknowledged.
The research and development reported here has the active support of various sections and
individuals within the Telstra Research Laboratories (TRL), especially Dr. C. Leckie and
Mr. P. Sember who were responsible for the creation and trialling of the programs
designed to produce the testing and training data.
The SOH application was possible due to co-operation of a number of our colleagues in
TRL, in particular Dr. L. Campbell (who suggested this particular application), Dr. M.
Herzberg and Mr. A. Herschtal.
The permission of the Managing Director, Research and Information Technology, Telstra,
to publish this paper is acknowledged.

References
[1]
[2]

[3]
[4]

[5]

[6]
[7]

[8]

[9]

[10]

E. Booker, Cross-connect at a Crossroads, Telephony, Vol. 215, 1988, pp. 63-65.
S. Bye, A Connectionist Approach to SDH Bandwidth Management, Proceedings
of the 19th International Conference on Artificial Neural Networks (ICANN-93),
Brighton Conference Centre, UK, 1993, pp. 286-290.
R. Gillan, Advanced Network Architectures Exploiting the Synchronous Digital
Hierarchy, Telecommunications Journal of Australia 39, 1989, pp. 39-42.
G. Gopal, C. Kim and A. Weinrib, Algorithms for Reconfigurable Networks,
Proceedings of the 13th International Teletraffic Congress (ITC-13), Copenhagen,
Denmark, 1991, pp. 341-347.
M. Herzberg, Network Bandwidth Management - A New Direction in Network
Management, Proceedings of the 6th Australian Teletraffic Research Seminar,
Wollongong, Australia, pp. 218-225.
M. Herzberg and S. Bye, Bandwidth Management in Reconfigurable Networks,
Australian Telecommunications Research 27, 1993, pp 57-70.
A. Kowalczyk and H.L. Ferra, Developing Higher Order Networks with
Empirically Selected Units, IEEE Transactions on Neural Networks, pp. 698-711,
1994.
C. Leckie, A Connectionist Approach to Telecommunication Network
Optimisation, in Complex Systems: Mechanism of Adaptation, R.J. Stonier and
X.H. Yu, eds., lOS Press, Amsterdam, 1994.
M. Schwartz, Telecommunications Networks, Addison-Wesley, Readings,
Massachusetts, 1987.
p. Campbell, H.L. Ferra, A. Kowalczyk, C. Leckie and P. Sember, Neural Networks
in Real Time Decision Making, Proceedings of the International Workshop on
Applications of Neural Networks to Telecommunications 2 (IWANNT-95), Ed. J
Alspector et. al. Lawrence Erlbaum Associates, New Jersey, 1995, pp. 273-280.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1968-not-bounding-the-true-error.pdf

(Not) Bounding the True Error

John Langford
Department of Computer Science
Carnegie-Mellon University
Pittsburgh, PA 15213
jcl+@cs.cmu.edu

Rich Caruana
Department of Computer Science
Cornell University
Ithaca, NY 14853
caruana@cs.cornell.edu

Abstract
We present a new approach to bounding the true error rate of a continuous
valued classifier based upon PAC-Bayes bounds. The method first constructs a distribution over classifiers by determining how sensitive each
parameter in the model is to noise. The true error rate of the stochastic
classifier found with the sensitivity analysis can then be tightly bounded
using a PAC-Bayes bound. In this paper we
demonstrate
the method on

 order of magnitude
artificial neural networks with results of a
improvement vs. the best deterministic neural net bounds.

1 Introduction
In machine learning it is important to know the true error rate a classifier will achieve on
future test cases. Estimating this error rate can be suprisingly difficult. For example, all
known bounds on the true error rate of artificial neural networks tend to be extremely loose
and often result in the meaningless bound of ?always err? (error rate = 1.0).
In this paper, we do not bound the true error rate of a neural network. Instead, we bound
the true error rate of a distribution over neural networks which we create by analysing one
neural network. (Hence, the title.) This approach proves to be much more fruitful than
trying to bound the true error rate of an individual network. The best current approaches
[1][2] often require 	 , 		 , or more examples before producing a nontrivial bound on
the true error rate. We produce nontrivial bounds on the true error rate of a stochastic neural
network with less than 
	 examples. A stochastic neural network is a neural network
where each weight 
 is perturbed by a gaussian with variance  every time it is evaluated.
Our approach uses the PAC-Bayes bound [5]. The approach can be thought of as a
redivision of the work between the experimenter and the theoretician: we make the experimenter work harder so that the theoretician?s true error bound becomes much tighter. This
?extra work? on the part of the experimenter is significant, but tractable, and the resulting
bounds are much tighter.
An alternative viewpoint is that the classification problem is finding a hypothesis with
a low upper bound on the future error rate. We present a post-processing phase for neural
networks which results in a classifier with a much lower upper bound on the future error
rate. The post-processing can be used with any artificial neural net trained with any optimization method; it does not require the learning procedure be modified, re-run, or even
that the threshold function be differentiable. In fact, this post-processing step can easily be
adapted to other learning algorithms.
David MacKay [4] has done significant work to make approximate Bayesian learning
tractable with a neural network. Our work here is complimentary rather than competitive.
We exhibit a technique which will likely give nontrivial true error rate bounds for Bayesian

neural networks regardless of approximation or prior modeling errors. Verification of this
statement is work in progress.
The post-processing step finds a ?large? distribution over classifiers, which has a small
average empirical error rate. Given the average empirical error rate, it is straightforward
to apply the PAC-Bayes bound in order to find a bound on the average true error rate. We
find this large distribution over classifiers by performing a simple noise sensitivy analysis
on the learned model. The noise model allows us to generate a distribution of classifiers
with a known, small, average empirical error rate. In this paper we refer to the distribution
of neural nets that results from this noise analysis as a stochastic neural net model.
Why do we expect the PAC-Bayes bound to be a significant improvement over standard
covering number and VC bound approaches? There exist learning problems for which
the difference between the lower bound and the PAC-Bayes upper bound are tight up to
where is the number of training examples. This is superior to the guarantees
which can be made for typical covering number bounds where the gap is, at best, known
up to an (asymptotic) constant. The guarantee that PAC-Bayes bounds are sometimes quite
tight encourages us to apply them here.
The next sections will:
1. Describe the bounds we will compare.
2. Describe our algorithm for constructing a distribution over neural networks.
3. Present experimental results.

 	 




2 Theoretical setup

    
 
 * +,-.#"/
0) '  )

We will work in the standard supervised batch learning setting. This setting starts with the
over
assumption that all examples are drawn from some fixed (unknown) distribution,
   and the,input
(input, output) pairs,
. The output is drawn from the space
space is arbitrary. The goal of machine learning is to use a sample set of pairs to find
a classifier, , which maps the input space to the output space and has a small true error,
. Since the distribution is unknown, the true error rate is not
observable. However, we can observe the empirical error rate,

.

Now that the basic quantities of interest are defined, we will first present a modern neural network bound, then specialize the PAC-Bayes bound to a stochastic neural network. A
stochastic neural network is simply a neural network where each weight in the neural network is drawn from some distribution whenever it is used. We will describe our technique
for constructing the distribution of the stochastic neural network.



 !#"%$& 
() ' 
31 2 54 1 
 6) ' 





2.1 Neural Network bound
We will compare a specialization of the best current neural network true error rate bound
[2] with our approach. The neural network bound is described in terms of the following
parameters:
.
1. A margin, 
2. An arbitrary function (unrelated to the neural network sigmoid function) defined by
 if  ,
 if  , and linear in between.
3.  , an upper bound on the sum of the magnitude of the weights in the th layer of
the neural network
4.  , a Lipschitz constant which holds for the th layer of the neural network. A
Lipschitz constant is a bound on the magnitude of the derivative.
5. , the size of the input space.
With these parameters defined, we get the following bound.
Theorem 2.1 (2 layer feed-forward Neural Network true error bound)

@

798:7
;<=
 ) 
:7 ;<=
 )

B


?>

A

C

EGF

D"$ (HJI	K  L>9M5NPQSO R T8UWVYX[Z

A

;

where

1
R 8  ) [2

;

 

 Q 

Q

	









 1B 1B @ 1@























Proof: Given in [2]. 

The theorem is actually only given up to a universal constant. ? ? might be the right
choice, but this is just an educated guess. The neural network true error bound above is
(perhaps) the tightest known bound for general feed-forward neural networks and so it is
the natural bound to compare with.
This 2 layer feed-forward bound is not easily applied in a tight manner because we can?t
calculate a priori what our weight bound  should be. This can be patched up using the
!#"
principle of structural risk minimization. In particular, we can state the bound for
where $ is some non-negative integer and
 is a constant. If the $ th bound holds with
probability % '" &  , then all bounds will hold simultaneously with probability 
, since

@



>

)



(

"

41
$



Applying this approach to the values of both

EF

Z

)

+*

@ 1

,

@ 1)



and

@

 , we get the following theorem:

Theorem 2.2 (2 layer feed-forward Neural Network true error bound)

#"$  HJI	K  L>3QM NO R T8    V X9Z
  
1
 Q 
where R 8<   )  2 ;
 1B 1B 
Q
Proof: Apply the union bound to all possible values of and as discussed above.
)   and report the value of the tightest applicable bound
In practice, we will use )
for all  .
/$ 0

".-

	




1$ 0












768</9 =



"23-

54

 :;







$

2

0



>

$ .0

2.2 Stochastic Neural Network bound
Our approach will start with a simple refinement [3] of the original PAC-Bayes bound [5].
We will first specialize this bound to stochastic neural networks and then show that the use
of this bound in conjunction with a post-processing algorithm results in a much tighter true
error rate upper bound.
First, we will need to define some parameters of the theorem.
1.

is a distribution over the hypotheses which can be found in an example depen?
dent manner.

2.

@
is a distribution over the hypotheses which is chosen a priori?without dependence on the examples.

   ) D  is the true error rate of the stochastic hypothesis which, in
any evaluation, draws a hypothesis  from , and outputs 
 .
 * +, is the average empirical error rate of the same stochastic
4.  *  )
hypothesis.
3.

BA

+CD
E

BA

FCG
HE

A

?

A

Now, we are ready to state the theorem.

EF



KL 

N


#"$
K KL  * + , 

   V X Z
where KL 
 )  N C   is the Kullback-Leibler divergence between the distributions and and KL  * 
 *  and a coin of bias   .  is the KL divergence between a coin of bias
Theorem 2.3 (PAC-Bayes Relative Entropy Bound) For all priors, @ ,
A

?

HA

?

O


SR 
UT

/?NIOI @

@

JII

P WX V Y
J
ZA

[A

IOI

A

HA

M?NIOI @

LK

QP

&

Proof: Given in [3]. 
We need to specialize this theorem for application to a stochastic neural network with a
choice of the ?prior?. Our ?prior? will be zero on all neural net structures other than the
one we train and a multidimensional isotropic gaussian on the values of the weights in our
neural network. The multidimensional gaussian will have a mean of  and a variance in
each dimension of  . This choice is made for convenience and happens to work.
The optimal value of is unknown and dependent on the learning problem so we will
wish to parameterize it in an example dependent manner. We can do this using the same
 "
trick as for the original neural net bound. Use a sequence of bounds where
for

and some constants and $ a nonnegative number. For the $ th bound set
% &  . Now,
"

the union bound will imply that all bounds hold simultaneously with probability at least
 .
Now, assuming that our ?posterior? ? is also defined by a multidimensional gaussian
with the mean and variance in each dimension defined by   and   , we can specialize to
the following corollary:
Corollary 2.4 (Stochastic Neural Network bound) Let 0 be the number of weights in a
neural net,   be the th weight and   be the variance of the th weight. Then, we have

R

R

)
R
Z

Z

#"$

 F

A
A





 1 N   
1


N
	




2




4
  

K KL   * +,    9M5NPO
X Z

  

?

A

JII

HA

K



9

-

P













9



P





"

&

"

(1)

Proof: Analytic calculation of the KL divergence between two multidimensional Gaussians and the union bound applied for each value of $ . 
We will choose
>  and  > as reasonable default values.
One more step is necessary in order to apply this bound. The essential difficulty is
evaluting A
. This quantity is observable although calculating it to high precision is
difficult. We will avoid the need for a direct evaluation by a monte carlo evaluation and
A 
a bound on the tail of the monte carlo evaluation. Let A
be the
observed rate of failure of a random hypotheses drawn according to ? and applied to a
random training example. Then, the following simple bound holds:
Theorem 2.5 (Sample Convergence Bound) For all distributions, ? , for all sample sets ,

 * 

)

-)

*  +,  #"  / 
 ) ' 



#"
A



E

KL



 *    * +,  N   
V X[Z
A

IOI

HA

P

K

&

where is the number of evaluations of the stochastic hypothesis.
Proof: This is simply an application of the Chernoff bound for the tail of a Binomial
where a ?head? occurs when an error is observed and the bias is A
. 
In order to calculate a bound on the expected true error rate, we will first bound the expected
empirical error rate ZA
with confidence & then bound the expected true error rate A
 . Since the total probability of failure is only
with confidence & , using our bound on A
 . In practice, we will use

& 
&
our bound will hold with probability 
	
evaluations

of the empirical error rate of the stochastic neural network.

 * +,

) Z

 * +,

 * +,

Z

 )

 

2.3 Distribution Construction algorithm
One critical step is missing in the description: How do we calculate the multidimensional
gaussian, ? ? The variance of the posterior gaussian needs to be dependent on each weight
in order to achieve a tight bound since we want any ?meaningless? weights to not contribute
significantly to the overall sample complexity. We use a simple greedy algorithm to find
the appropriate variance in each dimension.
1. Train a neural net on the examples
2. For every weight,  , search for the variance,   , which reduces the empirical
accuracy
of the stochastic neural network by some fixed target percentage (we use
  ) while holding all other weights fixed.



0.8

1

0.6
0.5
error

10
error

0.7

SNN bound
NN bound
SNN Train error
NN Train error
SNN Test error
NN Test error

100

0.4
0.3
0.2

0.1

0.1
0.01

0
10000
pattern presentations

100000

10000

100000

pattern presentations

Figure 1: Plot of measured errors and error bounds for the neural network (NN) and the
stochastic neural network (SNN) on the synthetic problem. The training set has 100 cases
and the reduction in empirical error is 5%. Note that a true error bound of ?100? (visible
in the graph on the left) implies that at least  more examples are required in order to
make a nonvacuous bound. The graph on the right expands the vertical scale by excluding
the poor true error bound that has error above 100. The curves for NN and SNN are qualitatively similar on the train and test sets. As expected, the SNN consistently performs 5%
worse than the NN on the train set (easier to see in the graph on the right). Surprisingly,
the SNN performs worse than the NN by less than 5% on the test sets. Both NN and SNN
exhibit overfitting after about 6000-12000 pattern presentations (600-1200 epochs). The
shape of the SNN bound roughly mimics the shape of the empirically measured true error
(this is more visible in the graph on the right) and thus might be useful for indicating where
the net begins overfitting.
3. The stochastic neural network defined by 	

  will generally have a too-large
empirical error. Therefore, we calculate a global multiplier  such that the
stochastic neural network defined by   

  decreases the empirical accuracy
by only the same  (absolute error rate) used in Step 2.
4. Then, we evaluate the empirical error rate of the resulting stochastic neural net
by repeatedly drawing samples from the stochastic neural network. In the work
reported here we use  samples.

3 Experimental Results
How well can we bound the true error rate of a stochastic neural network? The answer is
much better than we can bound the true error rate of a neural network.
We use two datasets to empirically evaluate the quality of the new bound. The first is a
synthetic dataset which has 25 input dimensions and one output dimension. Most of these
dimensions are useless?simply random numbers drawn from a  !"
#$ Gaussian. One of
the 25 input dimensions is dependent on the label. First, the label % is drawn uniformly
from &
#  , then the special dimension is drawn from a  !%'
#$ Gaussian. Note that this
learning problem can not be solved perfectly because some examples will be drawn from
the tails where the gaussians overlap. The ?ideal? neural net to use in solving this synthetic
problem is a single node perceptron. We will instead use a 2 layer neural net with 2 hidden
nodes using the sigmoid transfer function. This overly complex neural net will result in the
potential for significant overfitting which makes the bound prediction problem interesting.
It is also somewhat more ?realistic? if the neural net structure does not exactly match the
learning problem.
The second dataset is the ADULT problem from the UCI Machine Learning Repository. We use a 2 layer neural net with 2 hidden units for this problem as well because
preliminary experiments showed that nets this small can overfit the ADULT dataset if the
training sample is small.
To keep things challenging, we use just (*)+ examples in our experiments. As

0.5
0.4
error

10
error

0.6

SNN bound
NN bound
SNN Train error
NN Train error
SNN Test error
NN Test error

100

1

0.3
0.2

0.1
0.1
0.01

0
10000

100000

10000

pattern presentations

100000
pattern presentations

Figure 2: Plot of measured errors and error bounds for the neural network (NN) and the
stochastic neural network (SNN) on the UCI ADULT dataset. These graphs show the
results obtained using a 1% reduction in empirical error instead of the 5% reduction used
in Figure 1. The training sample size for this problem is 200 cases. NN and SNN exhibit
overfitting after approximately 12000 pattern presentations (600 epochs). As in Figure 1, a
true error bound of ?100? implies that at least   more examples are required in order to
make a nonvacuous bound. The graph on the right expands the vertical scale by excluding
the poor true error bound.
we will see in Figures 1 and 2, constructing a nonvacuous bound for a continuous hypothesis space with only 	 ) examples is quite difficult. The conventional bounds are
hopelessly loose.
Figure 1 shows the results for the synthetic problem. For this problem we use 100
training cases and a 5% reduction in empirical error. The results for the ADULT problem
are presented in Figure 2. For this problem we use 200 training cases and a 1% reduction
in empirical error. Experiments performed on these problems using somewhat smaller and
larger training samples yielded similar results. The choice of reduction in empirical error
is somewhat arbitrary. We see qualitatively similar results if we switch to a 1% reduction
for the synthetic problem and a 5% reduction for the ADULT problem.
There are several things worth noting about the results in the two figures.
1. The SNN upper bounds are 2-3 orders of magnitude lower than the NN upper
bounds. While not as tight as might be desired, the SNN upper bounds are orders
of magnitude better and are not vacuous.
2. The SNNs perform somewhat better than expected. In particular, on the synthetic
problem the SNN true error rate is at most  worse than the true error rate of
the NN (true error rates are estimated using large test sets). This is suprising
considering that we fixed the difference in empirical error rates at  for the
synthetic problem. Similarly, on the ADULT problem we observe that the true
error rates between the SNN and NN typically is only about 0.5%, about half of
the target difference of 1%. This is good because it suggests that we do not lose
as much accuracy as might be expected when creating the SNN.
3. On both test problems, the shape of the SNN bound is somewhat similar to the
shape of the true error rate. In particular, the local minima in the SNN bound
occur roughly where the local minima in the true error rates occur. The SNN
bound may weakly predict the overfitting points of the SNN and NN nets.
The comparison between the neural network bound and the stochastic neural network
bound is not quite ?fair? due to the form of the bound. In particular, the stochastic neural
network bound can never return a value greater than ?always err?. This implies that when
the bound is near the value of ? ?, it is difficult to judge how rapidly extra examples will
improve the stochastic neural network bound. We can judge the sample complexity of
the stochastic bound by plotting the value of the numerator in equation 1. Figure 3 plots
the complexity versus the number of pattern presentations in training. In this figure, we


Complexity

100

Complexity

10

1
10000

100000

pattern presentations
Figure 3: We plot the ?complexity? of the stochastic network model (numerator of equation
1) vs. training epoch. Note that the complexity increases with more training as expected
and stays below 
	 , implying nonvacuous bounds on a training set of size  .
observe the expected result: the ?complexity? (numerator of equation 1) increases with
more training and is significantly less than the number of examples (100).
The stochastic bound is a radical improvement on the neural network bound but it is not
yet a perfectly tight bound. Given that we do not have a perfectly tight bound, one important consideration arises: does the minimum of the stochastic bound predict the minimum
of the true error rate (as predicted by a large holdout dataset). In particular, can we use
the stochastic bound to determine when we should cease training? The stochastic bound
depends upon (1) the complexity which increases with training time and (2) the training error which decreases with training time. This dependence results in a minima which occurs
at approximately 12000 pattern presentations for both of our test problems. The point of
minimal true error (for the stochastic and deterministic neural networks) occurs at approximately 6000 pattern presentations for the synthetic problem, and at about 18000 pattern
presentations for the ADULT problem, indicating that the stochastic bound weakly predicts
the point of minimum error. The neural network bound has no such minimum.
Is the choice of 1-5% increased empirical error optimal? In general, the ?optimal?
choice of the extra error rate depends upon the learning problem. Since the stochastic
neural network bound (corollary 2.4) holds for all multidimensional gaussian distributions,
we are free to optimize the choice of distribution in anyway we desire. Figure 4 shows the

resulting bound for different choices of posterior ? . The bound has a minimum at > 
extra error indicating that our initial choices of  >   and >  are in the right ballpark, and
>  may be unnecessarily large. Larger differences in empirical error rate such as >  are
easier to obtain reliably with fewer samples from the stochastic neural net, but we have not
had difficulty using as few as 100 samples from the SNN with as small as a 1% increase in
empirical error. Also note that the complexity always decreases with increasing entropy in
the distribution of our stochastic neural net. The existence of a minimum in Figure 4 is the
?right? behaviour: the increased empirical error rate is significant in the calculation of the
true error bound.







4 Conclusion
We have applied a PAC-Bayes bound for the true error rate of a stochastic
network.
  neural
The stochastic neural network bound results in a radically tighter (
orders of mag-

true error bound or complexity

100

Stochastic NN bound
Complexity

10

1

0.1
0

0.02

0.04
0.06
extra training error

0.08

0.1

Figure 4: Plot of the stochastic neural net (SNN) bound for ?posterior? distributions chosen
according to the extra empirical error they introduce.
nitude) bound on the true error rate of a classifier while increasing the empirical and true
error rates only a small amount.
Although,
stochastic neural net bound is not completely tight, it is not vacuous with
 	theexamples
just 
and the minima of the bound weakly predicts the point where
overtraining occurs.
The results with two datasets (one synthetic and one from UCI) are extremely
promising?the bounds are orders of magnitude better. Our next step will be to test the
method on more datasets using a greater variety of net architectures to insure that the
bounds remain tight. In addition, there remain many opportunities for improving the application of the bound. For example, it is possible that shifting the weights when finding a
maximum acceptable variance will result in a tighter bound. Also, we have not taken into
account symmetries within the network which would allow for a tighter bound calculation.

References
[1] Peter Bartlett, ?The Sample Complexity of Pattern Classification with Neural Networks: The Size of the Weights is More Important than the Size of the Network?,
IEEE Transactions on Information Theory, Vol. 44, No. 2, March 1998.
[2] V. Koltchinskii and D. Panchenko, ?Empirical Margin Distributions and
Bounding the Generalization Error of Combined Classifiers?, preprint,
http://citeseer.nj.nec.com/386416.html
[3] John Langford and Matthias Seeger, ?Bounds for Averaging Classifiers.? CMU tech
report, 2001.
[4] David MacKay, ?Probable Networks and Plausible Predictions - A Review of Practical
Bayesian Methods for Supervised Neural Networks?, ??
[5] David McAllester, ?Some PAC-Bayes bounds?, COLT 1999.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 211-a-large-scale-neural-network-which-recognizes-handwritten-kanji-characters.pdf

A Large-Scale Neural Network

A LARGE-SCALE NEURAL NETWORK
WHICH RECOGNIZES HANDWRITTEN
KANJI CHARACTERS
Yoshihiro Mori
Kazuki Joe
ATR Auditory and Visual Perception Research Laboratories
Sanpeidani Inuidani Seika-cho Soraku-gun Kyoto 619-02 Japan

ABSTRACT
We propose a new way to construct a large-scale neural network for
3.000 handwritten Kanji characters recognition. This neural network
consists of 3 parts: a collection of small-scale networks which are
trained individually on a small number of Kanji characters; a network
which integrates the output from the small-scale networks, and a
process to facilitate the integration of these neworks. The recognition
rate of the total system is comparable with those of the small-scale
networks. Our results indicate that the proposed method is effective for
constructing a large-scale network without loss of recognition
performance.

1 INTRODUCTION
Neural networks have been applied to recognition tasks in many fields. with good results
[Denker, 1988][Mori,1988][Weideman, 1989]. They have performed better than
conventional methods. However these networks currently operate with only a few
categories, about 20 to 30. The Japanese writing system at present is composed of about
3,000 characters. For a network to recognize this many characters, it must be given a
large number of categories while maintaining its level of performance.
To train small-scale neural networks is not a difficult task. Therefore. exploring methods
for integrating these small-scale neural networks is important to construct a large-scale
network. If such methods could integrate small-scale networks without loss of the
performance, the scale of neural networks would be extended dramatically. In this paper,
we propose such a method for constructing a large-scale network whose object is to
recognize 3,000 handwritten Kanji characters, and report the result of a part of this
network. This method is not limited to systems for character recognition, and can be
applied to any system which recognizes many categories.

2 STRATEGIES FOR A LARGE-SCALE NETWORK
Knowing the current recognition and generalization capacity of a neural network. we
realized that constructing a large-scale monolithic network would not be efficient or

415

416

Mori and Joe
effective. Instead, from the start we decided on a building blocks approach
[Mori,1988] [Waibel,1988]. There are two strategies to mix many small-scale networks.

2.1 Selective Neural Network (SNN)
In this strategy, a large-scale neural network is made from many small-scale networks
which are trained individually on a small number of categories, and a network (SNN)
which selects the appropriate small-scale network (Fig. I). The advantage of this strategy
is that the information passed to a selected small-scale networks is always appropriate for
that network. Therefore, training these small-scale networks is very easy. But on the
other hand, increasing the number of categories will substantially increase the training
time of the SNN, and may make it harder for the SNN to retain high perfonnance.
Furthennore, the error rate of the SNN will limit the perfonnance of the whole system.

2.2 Integrative Neural Network (INN)
In this strategy, a large-scale neural network is made from many small-scale networks
which are trained individually on a small number of categories. and a network (INN)
which integrates the output from these small-scale networks(Fig. 2). The advantage of
this strategy is that every small-scale network gets information and contributes to finding
the right answer. Therefore, it is possible to use the knowledge distributed among each
small-scale network. But in some respects. various devices are needed to make the
integration easier.
The common advantage with both strategies just mentioned is that the size of each neural
network is relatively small, and it does not take a long time to train these networks. Each
small-scale networks is considered an independent part of the whole system. Therefore,
retraining these networks (to improve the performance of the whole system) will not take
too long.
~__....
O,utput

Sub
Net
1

? ?
Neural Network
(Selection Type)

':1U:U/W:::::::/:::/E::::::::.

: : Suspending
/ Network

(:::::{::::::::::::::::.:::::::: ~

Fig. 1 SNN Strategy

A Large-Scale Neural Network

Output
Neural Network
(Integration Type)

? ?
Fig. 2 INN Strategy

3 STRUCTURE OF LARGE-SCALE NETWORK
The whole system is constructed using three kinds of neural networks. The ftrst one,
called a SubNet, is an ordinary three layered feed forward type neural network trained
using the Back Propagation learning algorithm. The second kind of network is called a
SuperNet. This neural network makes its decision by integrating the outputs from all the
SubNets. This network is also a 3-layered feed-forward net, but is larger than the Subnets.
The last network, which we call an OtherFilter, is devised to improve the integration of
the S uperNet. This OtherFilter network was designed using the L VQ algorithm
[Khonen,1988]. There are also some changes made in the BP learning algorithm
especially for pattern recognition [Joe,1989].
We decided that, based on the time it takes for learning, there should be 9 categories in
each small-scale network. The 3,000 characters are separated into these small groups
through the K-means clustering method, which allows similar characters to be grouped
together. The separation occurs in two stages. First, 11 groups of 270 characters each are
formed, then each group is separated into 30 smaller units. In this way, 330 groups of 9
characters each are obtained. We choose the INN strategy to use distributed knowledge to
full advantage. The 9-character units are SubNets, which are integrated in 2 stages. First
30 SubNets are integrated by a higher level network SuperNet. Altogether, 11 SuperNets
are needed to recognize all 3,000 characters. SuperNets are in turn integrated by a higher
level network, the HyperNet. More precisely, the role and structure of these kinds of
networks are as follows:

3.1 SubNet
A feature vector extracted from handwritten patterns is used as the input (described in
Section 4.1). The number of units in the output layer is the same as the number of
categories to be recognized by the SubNet. In short, the role of a SubNet is to output the
similarity between the input pattern and the categories allotted to the SubNet. (Fig. 3)

3.2 SuperNet
The outputs from each SubNet fIltered by the OtherFilter network are used as the input to

417

418

Mori and Joe

the SuperNet. The number of units in an output layer is the same as the number of
SubNets belonging to a SuperNet. In shortt the role of SuperNet is to select the SubNet
which covers the category corresponding to the input patterns. (Fig. 5)

Output

Horizontal

+45?diagonal

Vertical

Original Pattern

Fig. 3 S ubNet

3.3 OtherFIIter
45(9x5) reference vectors are assigned to each SubNet. LVQ is used to adapt these
reference vectors t so that each input vector has a reference of the correct SubNet as its
closest reference vector. The
OtherFilter method is to frrst measure
the distance between all the reference
d
vectors and one input vector. The
mean distance and normal deviation of
distance are calculated. The distance
between a S ubNet and an input vector
is defmed to be the smallest distance
of that SubNet's reference vectors to
? References
the input vector .

?

?

XInput Vector

Fig4. Shape of OtherFilter

?

f(xo}=l 1(1+ e (x n-M+2d)/Cd) (1)
Xn : The Distance of Nth SubNet
M : The Mean of Xn
d : The Variance of Xn
C : Constant

A Large-Scale Neural Network

This distance modified by equation (1) is multiplied by the outputs of the SubNet. and fed
into the SuperNet. The outputs of SubNets whose distance is greater than the mean
distance are suppressed. and the outputs of SubNets whose distance is smaller than the
mean distance are amplified. In this way. the outputs of SubNets are modified to improve
the integration of the higher level SuperNet. (Fig. 5)

HyperNet 1
SuperNet 11
SubNet 330
OtherFilter 12

Other-Filter

FigS. Outline of the Whole System

4 RECOGNITION EXPERIMENT
4.1 TRAINING PATTERN
The training samples for this network were chosen from a database of about 3000 Kanji
characters [Saito 1985]. For each character. there are 200 handwritten samples from
different writers. 100 are used as training samples. and the remaining 100 are used to test
recognition accuracy of the trained network. All samples in the database consist of 64 by
63 dots.

419

420

Mori and Joe

JlQ
~
~~

~

.J-~

~~lJ
~~

~ ~
~

,~

~~

~
~~
-V'#f)

~

~

.orfffi

~~

J..~

~i2

O~

~

DI~J

o/N{

Fig. 6 Examples of training pattern

4.2 LDCD FEATURE
If we were to use this pattern as the input to our neural net, the number of units required
in the input layer would be too large for the computational abilities of current computers.
Therefore, a feature vector extracted from the handwritten patterns is used as the input. In
the "LDCD feature" [Hagita 1983], there are 256 dimensions computing a line segment
length along four directions: horizontal, vertical, and two diagonals in the 8 by 8 squares
into which the handwritten samples are divided.

t"
:61

o

horizontal
component

Fig 7. LDCD Feature
4.3 RECOGNITION RESULTS
In the work reported here, one SuperNet, 30 SubNets and one OtherFilter were
constructed for recognition experiments. SubNets were trained until the recognition of
training samples reaches at least 99%. With these SubNets, the mean recognition rate of
test patterns was 92%. This recognition rate is higher than that of conventional methods.
A SuperNet which integrates the output modified by OtherFilter from 30 trained SubNets

A Large-Scale Neural Network

was then constructed. The number of units in the input layer of the SuperNet was 270.
This SuperNet was trained until the performance of training samples becomes at least
93%. With this SuperNet, the recognition rate of test patterns was 74%, though that of
OtherFilter was 72%. The recognition rate of a system without the OtherFilter of test
patterns was 55%.

5 CONCLUSION
We have here proposed a new way of constructing a large-scale neural network for the
recognition of 3,000 handwritten Kanji characters. With this method, a system
recognizing 270 Kanji characters was constructed. This system will become a part of a
system recognizing 3,000 Kanji characters. Only a modest training time was necessary
owing to the modular nature of the system. Moreover, this modularity means that only a
modest re-training time is necessary for retraining an erroneous neural network in the
whole system. The overall system performance can be improved by retraining just that
neural network, and there is no need to retrain the whole system. However, the
performance of the OtherFilter is not satisfactory. We intend to improve the OtherFilter,
and build a large-scale network for the recognition of 3,000 handwritten Kanji characters
by the method reported here.

Acknowledgments
We are grateful to Dr. Yodogawa for his support and encouragement. Special thanks to
Dr. Sei Miyake for the ideas he provided in our many discussions. The authors would like
to acknowledge, with thanks, the help of Erik McDermott for his valuable assistance in
writing this paper in English.

References
[Denier, 1988]
l.S.Denker, W.R.Gardner, H.P. Graf, D.Henderson, R.E. Howard,
W.Hubbard, L.DJackel. H.S.Baird, I.Guyon : "Neural Network Recognizer for HandWritten ZIP Code Digits", NEURAL INFORMATION PROCESSING SYSTEMS 1.
pp.323-331, Morgan Kaufmann. 1988
[Mori,1988]
Y.Mori. K.Yokosawa : "Neural Networks that Learn to Discriminate
Similar Kanji Characters". NEURAL INFORMATION PROCESSING SYSTEMS 1,
pp.332-339, Morgan Kaufmann. 1988
[Weideman.1989]W.E.Weideman. M.T.Manry. H.C.Yau ; tI A COMPARISON OF A
NEAREST NEIGHBOR CLASSIFIER AND A NEURAL NETWORK FOR NUMERIC
HANDPRINT CHARACTER RECOGNITION". UCNN89(Washington), VoLl, pp.117120, June 1989

421

422

Mori and Joe

Alex Waibel, "Consonant Recognition by Modular Construction of
[Waibel, 1988]
Large Phonemic Time-Delay Neural Networks", NEURAL INFORMATION
PROCESSING SYSTEMS 1, pp.215-223, Morgan Kaufmann, 1988
[Joo,1989]
KJoo, Y.Mori, S.Miyake : "Simulation of a Large-Scale Neural
Networks on a Parallel Computer", 4th Hypercube Concurrent Computers,1989
[Khonen,1988] T.Kohonen, G.Barna, R.Chrisley : "Statistical Pattern Recognition
with Neural Networks", IEEE, Proc.of ICNN, YoU, pp.61-68, July 1988
[Saito,1985]
T.Saito, H.Yamada, K.Yamamoto : "On the Data Base ETL9 of
Handprinted Characters in 1IS Chinese Characters and Its Analysis", J68-D, 4, 757-764,
1985
[Hagita,1983]
N.Hagita, S.Naito, I.Masuda : "Recognition of Handprinted Chinese
Characters by Global and Local Direction Contributivity Density-Feature", J66-D, 6,
722-729,1983


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 5954-convolutional-networks-on-graphs-for-learning-molecular-fingerprints.pdf

Convolutional Networks on Graphs
for Learning Molecular Fingerprints

David Duvenaud? , Dougal Maclaurin?, Jorge Aguilera-Iparraguirre
Rafael G?omez-Bombarelli, Timothy Hirzel, Al?an Aspuru-Guzik, Ryan P. Adams
Harvard University

Abstract
We introduce a convolutional neural network that operates directly on graphs.
These networks allow end-to-end learning of prediction pipelines whose inputs
are graphs of arbitrary size and shape. The architecture we present generalizes
standard molecular feature extraction methods based on circular fingerprints. We
show that these data-driven features are more interpretable, and have better predictive performance on a variety of tasks.

1

Introduction

Recent work in materials design used neural networks to predict the properties of novel molecules
by generalizing from examples. One difficulty with this task is that the input to the predictor, a
molecule, can be of arbitrary size and shape. Currently, most machine learning pipelines can only
handle inputs of a fixed size. The current state of the art is to use off-the-shelf fingerprint software
to compute fixed-dimensional feature vectors, and use those features as inputs to a fully-connected
deep neural network or other standard machine learning method. This formula was followed by
[28, 3, 19]. During training, the molecular fingerprint vectors were treated as fixed.
In this paper, we replace the bottom layer of this stack ? the function that computes molecular
fingerprint vectors ? with a differentiable neural network whose input is a graph representing the
original molecule. In this graph, vertices represent individual atoms and edges represent bonds. The
lower layers of this network is convolutional in the sense that the same local filter is applied to each
atom and its neighborhood. After several such layers, a global pooling step combines features from
all the atoms in the molecule.
These neural graph fingerprints offer several advantages over fixed fingerprints:
? Predictive performance. By using data adapting to the task at hand, machine-optimized
fingerprints can provide substantially better predictive performance than fixed fingerprints.
We show that neural graph fingerprints match or beat the predictive performance of standard fingerprints on solubility, drug efficacy, and organic photovoltaic efficiency datasets.
? Parsimony. Fixed fingerprints must be extremely large to encode all possible substructures
without overlap. For example, [28] used a fingerprint vector of size 43,000, after having
removed rarely-occurring features. Differentiable fingerprints can be optimized to encode
only relevant features, reducing downstream computation and regularization requirements.
? Interpretability. Standard fingerprints encode each possible fragment completely distinctly, with no notion of similarity between fragments. In contrast, each feature of a neural
graph fingerprint can be activated by similar but distinct molecular fragments, making the
feature representation more meaningful.
?

Equal contribution.

1

Figure 1: Left: A visual representation of the computational graph of both standard circular fingerprints and neural graph fingerprints. First, a graph is constructed matching the topology of the
molecule being fingerprinted, in which nodes represent atoms, and edges represent bonds. At each
layer, information flows between neighbors in the graph. Finally, each node in the graph turns on
one bit in the fixed-length fingerprint vector. Right: A more detailed sketch including the bond
information used in each operation.

2

Circular fingerprints

The state of the art in molecular fingerprints are extended-connectivity circular fingerprints
(ECFP) [21]. Circular fingerprints [6] are a refinement of the Morgan algorithm [17], designed
to encode which substructures are present in a molecule in a way that is invariant to atom-relabeling.
Circular fingerprints generate each layer?s features by applying a fixed hash function to the concatenated features of the neighborhood in the previous layer. The results of these hashes are then treated
as integer indices, where a 1 is written to the fingerprint vector at the index given by the feature
vector at each node in the graph. Figure 1(left) shows a sketch of this computational architecture.
Ignoring collisions, each index of the fingerprint denotes the presence of a particular substructure.
The size of the substructures represented by each index depends on the depth of the network. Thus
the number of layers is referred to as the ?radius? of the fingerprints.
Circular fingerprints are analogous to convolutional networks in that they apply the same operation
locally everywhere, and combine information in a global pooling step.

3

Creating a differentiable fingerprint

The space of possible network architectures is large. In the spirit of starting from a known-good configuration, we designed a differentiable generalization of circular fingerprints. This section describes
our replacement of each discrete operation in circular fingerprints with a differentiable analog.
Hashing The purpose of the hash functions applied at each layer of circular fingerprints is to
combine information about each atom and its neighboring substructures. This ensures that any
change in a fragment, no matter how small, will lead to a different fingerprint index being activated.
We replace the hash operation with a single layer of a neural network. Using a smooth function
allows the activations to be similar when the local molecular structure varies in unimportant ways.
Indexing Circular fingerprints use an indexing operation to combine all the nodes? feature vectors
into a single fingerprint of the whole molecule. Each node sets a single bit of the fingerprint to one,
at an index determined by the hash of its feature vector. This pooling-like operation converts an
arbitrary-sized graph into a fixed-sized vector. For small molecules and a large fingerprint length,
the fingerprints are always sparse. We use the softmax operation as a differentiable analog of
indexing. In essence, each atom is asked to classify itself as belonging to a single category. The sum
of all these classification label vectors produces the final fingerprint. This operation is analogous to
the pooling operation in standard convolutional neural networks.
2

Algorithm 1 Circular fingerprints
1: Input: molecule, radius R, fingerprint
length S
2: Initialize: fingerprint vector f ? 0S
3: for each atom a in molecule
4:
ra ? g(a)
. lookup atom features
5: for L = 1 to R
. for each layer
6:
for each atom a in molecule
7:
r1 . . . rN = neighbors(a)
8:
v ? [ra , r1 , . . . , rN ] . concatenate
9:
ra ? hash(v)
. hash function
10:
i ? mod(ra , S) . convert to index
11:
fi ? 1
. Write 1 at index
12: Return: binary vector f

Algorithm 2 Neural graph fingerprints
1: Input: molecule, radius R, hidden weights
5
H11 . . . HR
, output weights W1 . . . WR
2: Initialize: fingerprint vector f ? 0S
3: for each atom a in molecule
4:
ra ? g(a)
. lookup atom features
5: for L = 1 to R
. for each layer
6:
for each atom a in molecule
7:
r1 . . . rN =Pneighbors(a)
8:
v ? ra + N
. sum
i=1 ri
9:
ra ? ?(vHLN )
. smooth function
10:
i ? softmax(ra WL )
. sparsify
11:
f ?f +i
. add to fingerprint
12: Return: real-valued vector f

Figure 2: Pseudocode of circular fingerprints (left) and neural graph fingerprints (right). Differences
are highlighted in blue. Every non-differentiable operation is replaced with a differentiable analog.
Canonicalization Circular fingerprints are identical regardless of the ordering of atoms in each
neighborhood. This invariance is achieved by sorting the neighboring atoms according to their
features, and bond features. We experimented with this sorting scheme, and also with applying the
local feature transform on all possible permutations of the local neighborhood. An alternative to
canonicalization is to apply a permutation-invariant function, such as summation. In the interests of
simplicity and scalability, we chose summation.
Circular fingerprints can be interpreted as a special case of neural graph fingerprints having large
random weights. This is because, in the limit of large input weights, tanh nonlinearities approach
step functions, which when concatenated form a simple hash function. Also, in the limit of large
input weights, the softmax operator approaches a one-hot-coded argmax operator, which is analogous to an indexing operation.
Algorithms 1 and 2 summarize these two algorithms and highlight their differences. Given a fingerprint length L, and F features at each layer, the parameters of neural graph fingerprints consist of
a separate output weight matrix of size F ? L for each layer, as well as a set of hidden-to-hidden
weight matrices of size F ? F at each layer, one for each possible number of bonds an atom can
have (up to 5 in organic molecules).

4

Experiments

We ran two experiments to demonstrate that neural fingerprints with large random weights behave
similarly to circular fingerprints. First, we examined whether distances between circular fingerprints
were similar to distances between neural fingerprint-based distances. Figure 3 (left) shows a scatterplot of pairwise distances between circular vs. neural fingerprints. Fingerprints had length 2048,
and were calculated on pairs of molecules from the solubility dataset [4]. Distance was measured
using a continuous generalization of the Tanimoto (a.k.a. Jaccard) similarity measure, given by
.X
X
distance(x, y) = 1 ?
min(xi , yi )
max(xi , yi )
(1)
There is a correlation of r = 0.823 between the distances. The line of points on the right of the plot
shows that for some pairs of molecules, binary ECFP fingerprints have exactly zero overlap.
Second, we examined the predictive performance of neural fingerprints with large random weights
vs. that of circular fingerprints. Figure 3 (right) shows average predictive performance on the solubility dataset, using linear regression on top of fingerprints. The performances of both methods
follow similar curves. In contrast, the performance of neural fingerprints with small random weights
follows a different curve, and is substantially better. This suggests that even with random weights,
the relatively smooth activation of neural fingerprints helps generalization performance.
3

2.0
1.8

0.9

RMSE (log Mol/L)

Neural fingerprint distances

Neural vs Circular distances, r =0:823
1.0

0.8
0.7
0.6
0.5
0.5

Circular fingerprints
Random conv with large parameters
Random conv with small parameters

1.6
1.4
1.2
1.0
0.8
0

0.6
0.7
0.8
0.9
1.0
Circular fingerprint distances

1

2
3
4
Fingerprint radius

5

6

Figure 3: Left: Comparison of pairwise distances between molecules, measured using circular fingerprints and neural graph fingerprints with large random weights. Right: Predictive performance
of circular fingerprints (red), neural graph fingerprints with fixed large random weights (green) and
neural graph fingerprints with fixed small random weights (blue). The performance of neural graph
fingerprints with large random weights closely matches the performance of circular fingerprints.
4.1

Examining learned features

To demonstrate that neural graph fingerprints are interpretable, we show substructures which most
activate individual features in a fingerprint vector. Each feature of a circular fingerprint vector can
each only be activated by a single fragment of a single radius, except for accidental collisions.
In contrast, neural graph fingerprint features can be activated by variations of the same structure,
making them more interpretable, and allowing shorter feature vectors.
Solubility features Figure 4 shows the fragments that maximally activate the most predictive features of a fingerprint. The fingerprint network was trained as inputs to a linear model predicting
solubility, as measured in [4]. The feature shown in the top row has a positive predictive relationship
with solubility, and is most activated by fragments containing a hydrophilic R-OH group, a standard
indicator of solubility. The feature shown in the bottom row, strongly predictive of insolubility, is
activated by non-polar repeated ring structures.
Fragments most
activated by
pro-solubility
feature

O

OH

O
NH
O

OH

OH

Fragments most
activated by
anti-solubility
feature

Figure 4: Examining fingerprints optimized for predicting solubility. Shown here are representative
examples of molecular fragments (highlighted in blue) which most activate different features of the
fingerprint. Top row: The feature most predictive of solubility. Bottom row: The feature most
predictive of insolubility.

4

Toxicity features We trained the same model architecture to predict toxicity, as measured in two
different datasets in [26]. Figure 5 shows fragments which maximally activate the feature most
predictive of toxicity, in two separate datasets.
Fragments most
activated by
toxicity feature
on SR-MMP
dataset
Fragments most
activated by
toxicity feature
on NR-AHR
dataset
Figure 5: Visualizing fingerprints optimized for predicting toxicity. Shown here are representative
samples of molecular fragments (highlighted in red) which most activate the feature most predictive
of toxicity. Top row: the most predictive feature identifies groups containing a sulphur atom attached
to an aromatic ring. Bottom row: the most predictive feature identifies fused aromatic rings, also
known as polycyclic aromatic hydrocarbons, a well-known carcinogen.
[27] constructed similar visualizations, but in a semi-manual way: to determine which toxic fragments activated a given neuron, they searched over a hand-made list of toxic substructures and chose
the one most correlated with a given neuron. In contrast, our visualizations are generated automatically, without the need to restrict the range of possible answers beforehand.
4.2

Predictive Performance

We ran several experiments to compare the predictive performance of neural graph fingerprints to
that of the standard state-of-the-art setup: circular fingerprints fed into a fully-connected neural
network.
Experimental setup Our pipeline takes as input the SMILES [30] string encoding of each
molecule, which is then converted into a graph using RDKit [20]. We also used RDKit to produce
the extended circular fingerprints used in the baseline. Hydrogen atoms were treated implicitly.
In our convolutional networks, the initial atom and bond features were chosen to be similar to those
used by ECFP: Initial atom features concatenated a one-hot encoding of the atom?s element, its
degree, the number of attached hydrogen atoms, and the implicit valence, and an aromaticity indicator. The bond features were a concatenation of whether the bond type was single, double, triple,
or aromatic, whether the bond was conjugated, and whether the bond was part of a ring.
Training and Architecture Training used batch normalization [11]. We also experimented with
tanh vs relu activation functions for both the neural fingerprint network layers and the fullyconnected network layers. relu had a slight but consistent performance advantage on the validation set. We also experimented with dropconnect [29], a variant of dropout in which weights are
randomly set to zero instead of hidden units, but found that it led to worse validation error in general. Each experiment optimized for 10000 minibatches of size 100 using the Adam algorithm [13],
a variant of RMSprop that includes momentum.
Hyperparameter Optimization To optimize hyperparameters, we used random search. The hyperparameters of all methods were optimized using 50 trials for each cross-validation fold. The
following hyperparameters were optimized: log learning rate, log of the initial weight scale, the log
L2 penalty, fingerprint length, fingerprint depth (up to 6), and the size of the hidden layer in the
fully-connected network. Additionally, the size of the hidden feature vector in the convolutional
neural fingerprint networks was optimized.
5

Dataset
Units
Predict mean
Circular FPs + linear layer
Circular FPs + neural net
Neural FPs + linear layer
Neural FPs + neural net

Solubility [4]
log Mol/L

Drug efficacy [5]
EC50 in nM

Photovoltaic efficiency [8]
percent

4.29 ? 0.40
1.71 ? 0.13
1.40 ? 0.13
0.77 ? 0.11
0.52 ? 0.07

1.47 ? 0.07
1.13 ? 0.03
1.36 ? 0.10
1.15 ? 0.02
1.16 ? 0.03

6.40 ? 0.09
2.63 ? 0.09
2.00 ? 0.09
2.58 ? 0.18
1.43 ? 0.09

Table 1: Mean predictive accuracy of neural fingerprints compared to standard circular fingerprints.

Datasets We compared the performance of standard circular fingerprints against neural graph fingerprints on a variety of domains:
? Solubility: The aqueous solubility of 1144 molecules as measured by [4].
? Drug efficacy: The half-maximal effective concentration (EC50 ) in vitro of 10,000
molecules against a sulfide-resistant strain of P. falciparum, the parasite that causes malaria,
as measured by [5].
? Organic photovoltaic efficiency: The Harvard Clean Energy Project [8] uses expensive
DFT simulations to estimate the photovoltaic efficiency of organic molecules. We used a
subset of 20,000 molecules from this dataset.
Predictive accuracy We compared the performance of circular fingerprints and neural graph fingerprints under two conditions: In the first condition, predictions were made by a linear layer using
the fingerprints as input. In the second condition, predictions were made by a one-hidden-layer
neural network using the fingerprints as input. In all settings, all differentiable parameters in the
composed models were optimized simultaneously. Results are summarized in Table 4.2.
In all experiments, the neural graph fingerprints matched or beat the accuracy of circular fingerprints,
and the methods with a neural network on top of the fingerprints typically outperformed the linear
layers.
Software Automatic differentiation (AD) software packages such as Theano [1] significantly
speed up development time by providing gradients automatically, but can only handle limited control
structures and indexing. Since we required relatively complex control flow and indexing in order
to implement variants of Algorithm 2, we used a more flexible automatic differentiation package
for Python called Autograd (github.com/HIPS/autograd). This package handles standard
Numpy [18] code, and can differentiate code containing while loops, branches, and indexing.
Code for computing neural fingerprints and producing visualizations is available at
github.com/HIPS/neural-fingerprint.

5

Limitations

Computational cost Neural fingerprints have the same asymptotic complexity in the number of
atoms and the depth of the network as circular fingerprints, but have additional terms due to the
matrix multiplies necessary to transform the feature vector at each step. To be precise, computing
the neural fingerprint of depth R, fingerprint length L of a molecule with N atoms using a molecular
convolutional net having F features at each layer costs O(RN F L + RN F 2 ). In practice, training
neural networks on top of circular fingerprints usually took several minutes, while training both the
fingerprints and the network on top took on the order of an hour on the larger datasets.
Limited computation at each layer How complicated should we make the function that goes
from one layer of the network to the next? In this paper we chose the simplest feasible architecture:
a single layer of a neural network. However, it may be fruitful to apply multiple layers of nonlinearities between each message-passing step (as in [22]), or to make information preservation easier by
adapting the Long Short-Term Memory [10] architecture to pass information upwards.
6

Limited information propagation across the graph The local message-passing architecture developed in this paper scales well in the size of the graph (due to the low degree of organic molecules),
but its ability to propagate information across the graph is limited by the depth of the network. This
may be appropriate for small graphs such as those representing the small organic molecules used in
this paper. However, in the worst case, it can take a depth N2 network to distinguish between graphs
of size N . To avoid this problem, [2] proposed a hierarchical clustering of graph substructures. A
tree-structured network could examine the structure of the entire graph using only log(N ) layers,
but would require learning to parse molecules. Techniques from natural language processing [25]
might be fruitfully adapted to this domain.
Inability to distinguish stereoisomers Special bookkeeping is required to distinguish between
stereoisomers, including enantomers (mirror images of molecules) and cis/trans isomers (rotation
around double bonds). Most circular fingerprint implementations have the option to make these
distinctions. Neural fingerprints could be extended to be sensitive to stereoisomers, but this remains
a task for future work.

6

Related work

This work is similar in spirit to the neural Turing machine [7], in the sense that we take an existing
discrete computational architecture, and make each part differentiable in order to do gradient-based
optimization.
Neural nets for quantitative structure-activity relationship (QSAR) The modern standard for
predicting properties of novel molecules is to compose circular fingerprints with fully-connected
neural networks or other regression methods. [3] used circular fingerprints as inputs to an ensemble
of neural networks, Gaussian processes, and random forests. [19] used circular fingerprints (of depth
2) as inputs to a multitask neural network, showing that multiple tasks helped performance.
Neural graph fingerprints The most closely related work is [15], who build a neural network
having graph-valued inputs. Their approach is to remove all cycles and build the graph into a tree
structure, choosing one atom to be the root. A recursive neural network [23, 24] is then run from
the leaves to the root to produce a fixed-size representation. Because a graph having N nodes
has N possible roots, all N possible graphs are constructed. The final descriptor is a sum of the
representations computed by all distinct graphs. There are as many distinct graphs as there are
atoms in the network. The computational cost of this method thus grows as O(F 2 N 2 ), where F
is the size of the feature vector and N is the number of atoms, making it less suitable for large
molecules.
Convolutional neural networks Convolutional neural networks have been used to model images,
speech, and time series [14]. However, standard convolutional architectures use a fixed computational graph, making them difficult to apply to objects of varying size or structure, such as molecules.
More recently, [12] and others have developed a convolutional neural network architecture for modeling sentences of varying length.
Neural networks on fixed graphs [2] introduce convolutional networks on graphs in the regime
where the graph structure is fixed, and each training example differs only in having different features
at the vertices of the same graph. In contrast, our networks address the situation where each training
input is a different graph.
Neural networks on input-dependent graphs [22] propose a neural network model for graphs
having an interesting training procedure. The forward pass consists of running a message-passing
scheme to equilibrium, a fact which allows the reverse-mode gradient to be computed without storing
the entire forward computation. They apply their network to predicting mutagenesis of molecular
compounds as well as web page rankings. [16] also propose a neural network model for graphs
with a learning scheme whose inner loop optimizes not the training loss, but rather the correlation
between each newly-proposed vector and the training error residual. They apply their model to a
dataset of boiling points of 150 molecular compounds. Our paper builds on these ideas, with the
7

following differences: Our method replaces their complex training algorithms with simple gradientbased optimization, generalizes existing circular fingerprint computations, and applies these networks in the context of modern QSAR pipelines which use neural networks on top of the fingerprints
to increase model capacity.
Unrolled inference algorithms [9] and others have noted that iterative inference procedures
sometimes resemble the feedforward computation of a recurrent neural network. One natural extension of these ideas is to parameterize each inference step, and train a neural network to approximately
match the output of exact inference using only a small number of iterations. The neural fingerprint,
when viewed in this light, resembles an unrolled message-passing algorithm on the original graph.

7

Conclusion

We generalized existing hand-crafted molecular features to allow their optimization for diverse tasks.
By making each operation in the feature pipeline differentiable, we can use standard neural-network
training methods to scalably optimize the parameters of these neural molecular fingerprints end-toend. We demonstrated the interpretability and predictive performance of these new fingerprints.
Data-driven features have already replaced hand-crafted features in speech recognition, machine
vision, and natural-language processing. Carrying out the same task for virtual screening, drug
design, and materials design is a natural next step.
Acknowledgments
We thank Edward Pyzer-Knapp, Jennifer Wei, and Samsung Advanced Institute of Technology for
their support. This work was partially funded by NSF IIS-1421780.

References
[1] Fr?ed?eric Bastien, Pascal Lamblin, Razvan Pascanu, James Bergstra, Ian J. Goodfellow, Arnaud
Bergeron, Nicolas Bouchard, and Yoshua Bengio. Theano: new features and speed improvements. Deep Learning and Unsupervised Feature Learning NIPS 2012 Workshop, 2012.
[2] Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral networks and locally
connected networks on graphs. arXiv preprint arXiv:1312.6203, 2013.
[3] George E. Dahl, Navdeep Jaitly, and Ruslan Salakhutdinov. Multi-task neural networks for
QSAR predictions. arXiv preprint arXiv:1406.1231, 2014.
[4] John S. Delaney. ESOL: Estimating aqueous solubility directly from molecular structure. Journal of Chemical Information and Computer Sciences, 44(3):1000?1005, 2004.
[5] Francisco-Javier Gamo, Laura M Sanz, Jaume Vidal, Cristina de Cozar, Emilio Alvarez,
Jose-Luis Lavandera, Dana E Vanderwall, Darren VS Green, Vinod Kumar, Samiul Hasan,
et al. Thousands of chemical starting points for antimalarial lead identification. Nature,
465(7296):305?310, 2010.
[6] Robert C. Glem, Andreas Bender, Catrin H. Arnby, Lars Carlsson, Scott Boyer, and James
Smith. Circular fingerprints: flexible molecular descriptors with applications from physical
chemistry to ADME. IDrugs: the investigational drugs journal, 9(3):199?204, 2006.
[7] Alex Graves, Greg Wayne, and Ivo Danihelka. Neural Turing machines. arXiv preprint
arXiv:1410.5401, 2014.
[8] Johannes Hachmann, Roberto Olivares-Amaya, Sule Atahan-Evrenk, Carlos Amador-Bedolla,
Roel S S?anchez-Carrera, Aryeh Gold-Parker, Leslie Vogt, Anna M Brockway, and Al?an
Aspuru-Guzik. The Harvard clean energy project: large-scale computational screening and
design of organic photovoltaics on the world community grid. The Journal of Physical Chemistry Letters, 2(17):2241?2251, 2011.
[9] John R Hershey, Jonathan Le Roux, and Felix Weninger. Deep unfolding: Model-based inspiration of novel deep architectures. arXiv preprint arXiv:1409.2574, 2014.
8

[10] Sepp Hochreiter and J?urgen Schmidhuber. Long short-term memory. Neural computation,
9(8):1735?1780, 1997.
[11] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training
by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.
[12] Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. A convolutional neural network
for modelling sentences. Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, June 2014.
[13] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint
arXiv:1412.6980, 2014.
[14] Yann LeCun and Yoshua Bengio. Convolutional networks for images, speech, and time series.
The handbook of brain theory and neural networks, 3361, 1995.
[15] Alessandro Lusci, Gianluca Pollastri, and Pierre Baldi. Deep architectures and deep learning
in chemoinformatics: the prediction of aqueous solubility for drug-like molecules. Journal of
chemical information and modeling, 53(7):1563?1575, 2013.
[16] Alessio Micheli. Neural network for graphs: A contextual constructive approach. Neural
Networks, IEEE Transactions on, 20(3):498?511, 2009.
[17] H.L. Morgan. The generation of a unique machine description for chemical structure. Journal
of Chemical Documentation, 5(2):107?113, 1965.
[18] Travis E Oliphant. Python for scientific computing. Computing in Science & Engineering,
9(3):10?20, 2007.
[19] Bharath Ramsundar, Steven Kearnes, Patrick Riley, Dale Webster, David Konerding, and Vijay
Pande. Massively multitask networks for drug discovery. arXiv:1502.02072, 2015.
[20] RDKit: Open-source cheminformatics. www.rdkit.org. [accessed 11-April-2013].
[21] David Rogers and Mathew Hahn. Extended-connectivity fingerprints. Journal of Chemical
Information and Modeling, 50(5):742?754, 2010.
[22] F. Scarselli, M. Gori, Ah Chung Tsoi, M. Hagenbuchner, and G. Monfardini. The graph neural
network model. Neural Networks, IEEE Transactions on, 20(1):61?80, Jan 2009.
[23] Richard Socher, Eric H Huang, Jeffrey Pennin, Christopher D Manning, and Andrew Y Ng.
Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In Advances
in Neural Information Processing Systems, pages 801?809, 2011.
[24] Richard Socher, Jeffrey Pennington, Eric H Huang, Andrew Y Ng, and Christopher D Manning. Semi-supervised recursive autoencoders for predicting sentiment distributions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages
151?161. Association for Computational Linguistics, 2011.
[25] Kai Sheng Tai, Richard Socher, and Christopher D Manning.
Improved semantic
representations from tree-structured long short-term memory networks. arXiv preprint
arXiv:1503.00075, 2015.
[26] Tox21 Challenge. National center for advancing translational sciences. http://tripod.
nih.gov/tox21/challenge, 2014. [Online; accessed 2-June-2015].
[27] Thomas Unterthiner, Andreas Mayr, G?unter Klambauer, and Sepp Hochreiter. Toxicity prediction using deep learning. arXiv preprint arXiv:1503.01445, 2015.
[28] Thomas Unterthiner, Andreas Mayr, G u? nter Klambauer, Marvin Steijaert, J?org Wenger, Hugo
Ceulemans, and Sepp Hochreiter. Deep learning as an opportunity in virtual screening. In
Advances in Neural Information Processing Systems, 2014.
[29] Li Wan, Matthew Zeiler, Sixin Zhang, Yann L. Cun, and Rob Fergus. Regularization of neural
networks using dropconnect. In International Conference on Machine Learning, 2013.
[30] David Weininger. SMILES, a chemical language and information system. Journal of chemical
information and computer sciences, 28(1):31?36, 1988.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 40-neural-networks-for-template-matching-application-to-real-time-classification-of-the-action-potentials-of-real-neurons.pdf

103

NEURAL NETWORKS FOR TEMPLATE MATCHING:
APPLICATION TO REAL-TIME CLASSIFICATION
OF THE ACTION POTENTIALS OF REAL NEURONS
Yiu-fai Wongt, Jashojiban Banikt and James M. Bower!
tDivision of Engineering and Applied Science
!Division of Biology
California Institute of Technology
Pasadena, CA 91125

ABSTRACT
Much experimental study of real neural networks relies on the proper classification of
extracellulary sampled neural signals (i .e. action potentials) recorded from the brains of experimental animals. In most neurophysiology laboratories this classification task is simplified
by limiting investigations to single, electrically well-isolated neurons recorded one at a time.
However, for those interested in sampling the activities of many single neurons simultaneously,
waveform classification becomes a serious concern. In this paper we describe and constrast
three approaches to this problem each designed not only to recognize isolated neural events,
but also to separately classify temporally overlapping events in real time. First we present two
formulations of waveform classification using a neural network template matching approach.
These two formulations are then compared to a simple template matching implementation.
Analysis with real neural signals reveals that simple template matching is a better solution to
this problem than either neural network approach.

INTRODUCTION
For many years, neurobiologists have been studying the nervous system by
using single electrodes to serially sample the electrical activity of single neurons in the brain. However, as physiologists and theorists have become more
aware of the complex, nonlinear dynamics of these networks, it has become
apparent that serial sampling strategies may not provide all the information
necessary to understand functional organization. In addition, it will likely be
necessary to develop new techniques which sample the activities of multiple
neurons simultaneouslyl. Over the last several years, we have developed two
different methods to acquire multineuron data. Our initial design involved
the placement of many tiny micro electrodes individually in a tightly packed
pseudo-floating configuration within the brain 2 . More recently we have been
developing a more sophisticated approach which utilizes recent advances in
silicon technology to fabricate multi-ported silicon based electrodes (Fig. 1) .
Using these electrodes we expect to be able to readily record the activity patterns of larger number of neurons.
As research in multi-single neuron recording techniques continue, it has become very clear that whatever technique is used to acquire neural signals from
many brain locations, the technical difficulties associated with sampling, data
compressing, storing, analyzing and interpreting these signals largely dwarf the
development of the sampling device itself. In this report we specifically consider
the need to assure that neural action potentials (also known as "spikes") on
each of many parallel recording channels are correctly classified, which is just
one aspect of the problem of post-processing multi-single neuron data. With
more traditional single electrode/single neuron recordings, this task usually in? American Institute or Physics 1988

104

volves passing analog signals through a Schmidt trigger whose output indicates
the occurence of an event to a computer, at the same time as it triggers an
oscilloscope sweep of the analog data. The experimenter visually monitors the
oscilloscope to verify the accuracy of the discrimination as a well-discriminated
signal from a single neuron will overlap on successive oscilloscope traces (Fig.
Ic). Obviously this approach is impractical when large numbers of channels
are recorded at the same time. Instead, it is necessary to automate this classification procedure. In this paper we will describe and contrast three approaches
we have developed to do this .

Traces
on upper
layer

~

'a.
E

IV

1~
0

Traces

4

2
Ume (msec)

on lower
layer

C. ,

&.

Recording s~e

b.

75sq.jllT1

Fig. 1. Silicon probe being developed in our lababoratory for multi-single unit recording
in cerebellar cortex. a) a complete probe; b) surface view of one recording tip; c) several
superimposed neuronal action potentials recorded from such a silicon electrode ill cerebellar
cortex.

While our principal design objective is the assurance that neural waveforms
are adequately discriminated on multiple channels, technically the overall objective of this research project is to sample from as many single neurons as
possible. Therefore, it is a natural extention of our effort to develop a neural
waveform classification scheme robust enough to allow us to distinguish activities arising from more than one neuron per recording site. To do this, however,
we now not only have to determine that a particular signal is neural in origin,
but also from which of several possible neurons it arose (see Fig. 2a). While
in general signals from different neurons have different waveforms aiding in
the classification, neurons recorded on the same channel firing simultaneously
or nearly simultaneously will produce novel combination waveforms (Fig. 2b)
which also need to be classified. It is this last complication which particularly

105

bedevils previous efforts to classify neural signals (For review see 5, also see
3-4). In summary, then, our objective was to design a circuit that would:
1. distinguish different waveforms even though neuronal discharges tend
to be quite similar in shape (Fig. 2a);
2. recognize the same waveform even though unavoidable movements
such as animal respiration often result in periodic changes in the amplitude
of a recorded signal by moving the brain relative to the tip of the electrode;
3. be considerably robust to recording noise which variably corrupts all
neural recordings (Fig. 2);
4. resolve overlapping waveforms, which are likely to be particularly interesting events from a neurobiological point of view;
5. provide real-time performance allowing the experimenter to detect
problems with discrimination and monitor the progress of the experiment;
6. be implementable in hardware due to the need to classify neural signals on many channels simultaneously. Simply duplicating a software-based
algorithm for each channel will not work, but rather, multiple, small, independent, and programmable hardware devices need to be constructed.

I
b.

50 Jl.V

signal recorded

c.

electrode
a.

Fig. 2. a) Schematic diagram of an electrode recording from two neuronal cell bodies b) An
actual multi-neuron recording. Note the similarities in the two waveforms and the overlapping
event. c) and d) Synthesized data with different noise levels for testing classificat.ion algorithms
(c : 0.3 NSR ; d: 1.1 NSR) .

106

METHODS
The problem of detecting and classifying multiple neural signals on single voltage records involves two steps. First, the waveforms that are present
in a particular signal must be identified and the templates be generated;
second, these waveforms must be detected and classified in ongoing data
records. To accomplish the first step we have modified the principal component analysis procedure described by Abeles and Goldstein 3 to automatically extract templates of the distinct waveforms found in an initial sample of the digitized analog data. This will not be discussed further as it is
the means of accomplishing the second step which concerns us here. Specifically, in this paper we compare three new approaches to ongoing waveform classification which deal explicitly with overlapping spikes and variably meet other design criteria outlined above. These approaches consist of
a modified template matching scheme, and two applied neural network implementations. We will first consider the neural network approaches. On
a point of nomenclature, to avoid confusion in what follows, the real neurons whose signals we want to classify will be referred to as "neurons" while
computing elements in the applied neural networks will be called "Hopons."

Neural Network Approach - Overall, the problem of classifying neural
waveforms can best be seen as an optimization problem in the presence of
noise. Much recent work on neural-type network algorithms has demonstrated
that these networks work quite well on problems of this sort 6- 8 . In particular,
in a recent paper Hopfield and Tank describe an A/D converter network and
suggest how to map the problem of template matching into a similar context 8 .
The energy functional for the network they propose has the form:
- 1

E = - 2 ~~
'" '" T.I] v..v.
I]
1

]

- '"
~ VI

II

(1)

1

where Tij = connectivity between Hopon i and Hopon y', V; = voltage output
of Hopon i, Ii = input current to Hopon i and each Hopon has a sigmoid
input-output characteristic V = g(u) = 1/(1 + exp( -au)).
If the equation of motion is set to be:

du;fdt

=

-oE/oV =

L

T;jVj

+ Ii

(la)

j

then we see that dE/dt = -(I:iTijVj + Ii)dV/dt = - (du/dt)(dV/dt) =
-g'{u)(du/dt)2 :s: O. Hence E will go to to a minimum which, in a network
constructed as described below, will correspond to a proposed solution to a
particular waveform classification problem.

Template Matching using a Hopfield-type Neural Net - We have
taken the following approach to template matching using a neural network. For
simplicity, we initially restricted the classification problem to one involving two
waveforms and have accordingly constructed a neural network made up of two
groups of Hopons, each concerned with discriminating one or the other waveform. The classification procedure works as follows: first, a Schmidt trigger

107

is used to detect the presence of a voltage on the signal channel above a set
threshold . When this threshold is crossed, implying the presence of a possible
neural signal, 2 msecs of data around the crossing are stored in a buffer (40
samples at 20 KHz). Note that biophysical limitations assure that a single real
neuron cannot discharge more than once in this time period, so only one waveform of a particular type can occur in this data sample. Also, action potentials
are of the order of 1 msec in duration, so the 2 msec window will include the full
signal for single or overlapped waveforms. In the next step (explained later)
the data values are correlated and passed into a Hopfield network designed to
minimize the mean-square error between the actual data and the linear combination of different delays of the templates. Each Hopon in the set of Hopons
concerned with one waveform represents a particular temporal delay in the
occurrence of that waveform in the buffer. To express the network in terms of
an energy function formulation: Let x(t) = input waveform amplitude in the
tth time bin, Sj(t) = amplitude of the ph template, Vjk denote if Sj(t - k)(J?th
template delayed by k time bins)is present in the input waveform. Then the
appropriate energy function is:

(2)

The first term is designed to minimize the mean-square error and specifies
the best match. Since V E [0,1]' the second term is minimized only when each
Vjk assumes values 0 or 1. It also sets the diagonal elements Tij to o. The
third term creates mutual inhibition among the processing nodes evaluating
the same neuronal signal, which as described above can only occur once per
sample.
Expanding and simplifying expression (2), the connection matrix is :

(3a)
and the input current

(3b)
As it can be seen, the inputs are the correlations between the actual data and
the various delays of the templates subtracting a constant term.

Modified Hopfield Network - As documented in more detail in Fig.
3-4, the above full Hopfield-type network works well for temporally isolated
spikes at moderate noise levels, but for overlapping spikes it has a local minima
problem. This is more severe with more than two waveforms in the network.

108

Further, we need to build our network in hardware and the full Hopfield network is difficult to implement with current technology (see below) . For these
reasons, we developed a modified neural network approach which significantly
reduces the necessary hardware complexity and also has improved performance.
To understand how this works, let us look at the information contained in the
quantities Tij and Iij (eq. 3a and 3b ) and make some use of them. These
quantities have to be calculated at a pre-processing stage before being loaded
into the Hopfield network. If after calculating these quantities, we can quickly
rule out a large number of possible template combinations, then we can significantly reduce the size of the problem and thus use a much smaller (and
hence more efficient) neural network to find the optimal solution. To make the
derivation simple, we define slightly modified versions of 1';j and Iij (eq. 4a
and 4b) for two-template case.

Iij

= L x(t) [~SI(t - i) + ~S2(t - j)] t

~L

si(t - i) -

t

~ L s~(t -

j)

(4b)

t

In the case of overlaping spikes the 1';j'S are the cross-correlations between SI (t)
and S2(t) with different delays and Ii;'s are the cross-correlations between input
x(t) and weighted combination of SI(t) and S2(t). Now if x(t) = SI(t - i) +
S2(t - J') (i.e. the overlap of the first template with i time bin delay and the
second template with j time bin delay), then I:::.ij = l1';j - Iijl = O. However
in the presence of noise, I:::. ij will not be identically zero, but will equal to the
noise, and if I:::.ij > l:::.1';j (where l:::.1';j = l1';j - 1';'j.1 for i =f: i' and j =f: l) this
simple algorithm may make unacceptable errors. A solution to this problem
for overlapping spikes will be described below, but now let us consider the
problem of classifying non-overlapping spikes. In this case, we can compare
the input cross-correlation with the auto-correlations (eq. 4c and 4d).

T! = Lsi(t - i); T!, = Ls~(t - i)

(4c)

t

(4d)
So for non-overlapping cases, if x(t) = SI(t - i), then I:::.~ = IT: - 1:1 = O. If
x(t) = S2(t - i), then 1:::.:' = IT:' - 1:'1 = o.
In the absence of noise, then the minimum of I:::. ij , 1:::.: and I:::.? represents the
correct classification. However, in the presence of noise, none of these quantities
will be identically zero, but will equal the noise in the input x(t) which will
give rise to unacceptible errors. Our solution to this noise related. problem is
to choose a few minima (three have chosen in our case) instead of one. For
each minimum there is either a known corresponding linear combination of
templates for overlapping cases or a simple template for non-overlapping cases.
A three neuron Hopfield-type network is then programmed so that each neuron
corresponds to each of the cases. The input x(t) is fed to this tiny network to
resolve whatever confusion remains after the first step of "cross-correlation"
comparisons. (Note: Simple template matching as described below can also be
used in the place of the tiny Hopfield type network.)

109

Simple Template Matching ~ To evaluate the performances of these
neural network approaches, we decided to implement a simple template matching scheme, which we will now describe. However, as documented below, this
approach turned out to be the most accurate and require the least complex
hardware of any of the three approaches. The first step is, again, to fill a buffer
with data based on the detection of a possible neural signal. Then we calculate
the difference between the recorded waveform and all possible combinations of
the two previously identified templates. Formally, this consists of calculating
the distances between the input x(m) and all possible cases generated by all
the combinations of the two templates.
d,j =

L

Ix(t) - {Sl(t - i)

+ S2(t - Jonl

t

d~

=

L
t

Ix(t) - Sl(t - i)l;

d~'

= L Ix(t) - S2(t - i)1
t

dmin = min(dij,d~,dn
dm,n gives the best fit of all possible combinations of templates to the actual
voltage signal.
TESTING PROCEDURES
To compare the performance of each of the three approaches, we devised a
common set of test data using the following procedures. First, we used the principal component method of Abeles and Goldstein 3 to generate two templates
from a digitized analog record of neural activity recorded in the cerebellum
of the rat. The two actual spike waveform templates we decided to use had
a peak-to-peak ratio of 1.375. From a second set of analog recordings made
from a site in the cerebellum in which no action potential events were evident,
we determined the spectral characteristics of the recording noise. These two
components derived from real neural recordings were then digitally combined,
the objective being to construct realistic records, while also knowing absolutely
what the correct solution to the template matching problem was for each occurring spike. As shown in Fig. 2c and 2d, data sets corresponding to different
noise to signal ratios were constructed. We also carried out simulations with
the amplitudes of the templates themselves varied in the synthesized records to
simulate waveform changes due to brain movements often seen in real recordings. In addition to two waveform test sets, we also constructed three waveform
sets by generating a third template that was the average of the first two templates. To further quantify the comparisons of the three diffferent approaches
described above we considered non-overlapping and overlapping spikes separately. To quantify the performance of the three different approaches, two
standards for classification were devised. In the first and hardest case, to be
judged a correct classification, the precise order and timing of two waveforms
had to be reconstructed. In the second and looser scheme, classification was
judged correct if the order of two waveforms was correct but timing was allowed to vary by ?lOO Jlsecs(i.e. ?2 time bins) which for most neurobiological
applications is probably sufficient resolution . Figs. 3-4 compare the performance results for the three approaches to waveform classification implemented
as digital simulations.

110

PERFORMANCE COMPARISON
Two templates - non-overlapping waveforms: As shown in Fig. 3a, at
low noise-to-signal ratios (NSRs below .2) each of the three approaches were
comparable in performance reaching close to 100% accuracy for each criterion.
As the ratio was increased, however the neural network implementations did
less and less well with respect to the simple template matching algorithm with
the full Hopfield type network doing considerably worse than the modified
network. In the range of NSR most often found in real data (.2 - .4) simple
template matching performed considerably better than either of the neural
network approaches. Also it is to be noted that simple template matching
gives an estimate of the goodness of fit betwwen the waveform and the closest
template which could be used to identify events that should not be classified
(e.g. signals due to noise).
a.

.

b.

,

..
c.

,.

..

. ..

..

..

1.1

noise level: 3a/peak amplitude

.,

,

?

//

\,

.
,

.

1.1

,.-.-..-----------.

/

,
,,

,,

I

,,

,:

.

.

.

noise level: 3a/peak amplitude

I

I

I

:'
I

,I

\,'
-14

-12

-tli

-I

-2

12

degrees of overlap
light line - absolute criteria
heavy line - less stringent criteria

simple template matching
Hopfield network
modified Hopfield network

Fig. 3. Comparisons of the three approaches detecting two non-overlapping (a), and overlapping (b) waveforms, c) compares the performances of the neural network approaches for
different degrees of waveform overlap.

Two' templates - overlapping waveforms: Fig. 3b and 3c compare performances when waveforms overlapped. In Fig. 3b the serious local minima problem encountered in the full neural network is demonstrated as is the improved
performance of the modified network. Again, overall performance in physi-

111

ological ranges of noise is clearly best for simple template matching. When
the noise level is low, the modified approach is the bet ter of the two neural
networks due to the reliability of the correlation number which reflects the
resemblence between the input data and the template. When the noise level
is high, errors in the correlation numbers may exclude the right combination
from the smaller network. In this case its performance is actually a little worse
than the larger Hopfield network. Fig. 3c documents in detail which degrees
of overlap produce the most trouble for the neural network approaches at average NSR levels found in real neural data. It can be seen that for the neural
networks, the most serious problem is encountered when the delays between
the two waveforms are small enough that the resulting waveform looks like the
larger waveform with some perturbation.
Three templates - overlapping and non-overlapping: In Fig. 4 are shown
the comparisons between the full Hopfield network approach and the simple
template matching approach. For nonoverlapping waveforms, the performance
of these two approaches is much more comparable than for the two waveform
case (Fig. 4a), although simple template matching is still the optimal method.
In the overlapping waveform condition, however, the neural network approach
fails badly (Fig. 4b and 4c). For this particular application and implementation, the neural network approach does not scale well.
b.

a.
~

!:!...

.

o ..
v

~

..

.

28

.2

c.
~

......'"
o
V

~

.

1. 1

.S

.2

noise level: 3a /peak amplitude

..
..

.4

..

.S

.. I

noise level: 3a /peak amplitude

Hopfield network
simple template matching
light line - absolute criteria
heavy line - less stringent criteria
a = variance of the noise

50

2.

.2

.6

.8

1. ?

noise level: 3a /peak amplitude
Fig. 4. Comparisons of performance for three waveforms. a) nonoverlapping waveforms; b)
two waveforms overlapping; c) three waveforms overlapping.

HARDWARE COMPARISONS
As described earlier, an important design requi~ement for this work was the
ability to <letect neural signals in analog records in real-time originating from

112

many simultaneously active sampling electrodes. Because it is not feasible to
run the algorithms in a computer in real time for all the channels simultaneously, it is necessary to design and build dedicated hardware for each channel.
To do this, we have decided to design VLSI implementations of our circuitry.
In this regard, it is well recognized that large modifiable neural networks need
very elaborate hardware implementations. Let us consider, for example, implementing hard wares for a two-template case for comparisons. Let n = no.
of neurons per template (one neuron for each delay of the template), m =
no. of iterations to reach the stable state (in simulating the discretized differential equation, with step size = 0.05), [ = no. of samples in a template
tj(m). Then, the number of connections in the full Hopfield network will be
4n 2 ? The total no. of synaptic calculations = 4mn 2 ? So, for two templates
and n = 16, m = 100,4mn 2 = 102,400. Thus building the full Hopfield-type
network digitally requires a system too large to be put in a single VLSI chip
which will work in real time. If we want to build an analog system, we need
to have many (O{ 4n 2 )) easily modifiable synapses. As yet this technology is
not available for nets of this size. The modified Hopfield-type network on the
other hand is less technically demanding . To do the preprocessing to obtain
the minimum values we have to do about n 2 = 256 additions to find all possible
Iijs and require 256 subtractions and comparisons to find three minima. The
costs associated with doing input cross-correlations are the same as for the full
neural network (i.e. 2nl = 768(l = 24) mUltiplications). The saving with the
modified approach is that the network used is small and fast (120 multiplications and 120 additions to construct the modifiable synapses, no. of synaptic
calculations = 90 with m = 10, n = 3).
In contrast to the neural networks, simple temrlate matching is simple
indeed. For example, it must perform about n 2 [ + n = 10,496 additions and
n 2 = 256 comparisons to find the minimum d ij . Additions are considerably less
costly in time and hardware than multiplications. In fact, because this method
needs only addition operations, our preliminary design work suggests it can be
built on a single chip and will be able to do the two-template classification
in as little as 20 microseconds. This actually raises the possibility that with
switching and buffering one chip might be able to service more than one channel
in essentially real time.

CONCLUSIONS
Template matching using a full Hopfield-type neural network is found to
be robust to noise and changes in signal waveform for the two neural waveform
classification problem. However, for a three-waveform case, the network does
not perform well. Further, the network requires many modifiable connections
and therefore results in an elaborate hardware implementation. The overall
performance of the modified neural network approach is better than the full
~Iopfield network approach. The computation has been reduced largly and
the hardware requirements are considerably less demanding demonstrating the
value of designing a specific network to a specified problem. However, even the
modified neural network performs less well than a simple template-matching
algorithm which also has the simplest hardware implementation. Using the
simple template matching algorithm, our simulations suggest it will be possible to build a two or three waveform classifier on a single VLSI chip using
CMOS technology that works in real time with excellent error characteristics.
Further, such a chip will be able to accurately classify variably overlapping

113

neural signals.

REFERENCES
[1] G. L. Gerstein, M. J. Bloom, 1. E. Espinosa, S. Evanczuk & M. R. Turner,
IEEE Trans. Sys. Cyb. Man., SMC-13, 668(1983).
2 J. M. Bower & R . Llinas, Soc. Neurosci. Abst.,~, 607(1983).
3 M. Abeles & M. H. Goldstein, Proc. IEEE, 65, 762(1977).
4 W. M. Roberts & D. K. Hartline, Brain Res., 94, 141(1976).
5 E. M. Schmidt, J. of Neurosci. Methods, 12, 95(1984).
6 J. J. Hopfield, Proc. Natl. Acad. Sci. (USA), 81, 3088(1984).
7 J. J. Hopfield & D. W. Tank, BioI. Cybern., 52, 141(1985).
8 D. W. Tank & J. J. Hopfield, IEEE Trans. Circuits Syst., CAS-33,
533(1986).

ACKNOWLEDGEMENTS
We would like to acknowledge the contribution of Dr. Mark Nelson to the intellectual
development of these projects and the able assistance of Herb Adams, Mike Walshe and John
Powers in designing and constructing support equipment. This work was supported by NIH
grant NS22205, the Whitaker Foundation and the Joseph Drown Foundation.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 503-refining-pid-controllers-using-neural-networks.pdf

Refining PIn Controllers using Neural Networks

Gary M. Scott
Department of Chemical Engineering
1415 Johnson Drive
University of Wisconsin
Madison, WI 53706

Jude W. Shavlik
Department of Computer Sciences
1210 W. Dayton Street
University of Wisconsin
Madison, WI 53706

W. Harmon Ray
Department of Chemical Engineering
1415 Johnson Drive
University of Wisconsin
Madison, WI 53706

Abstract
The KBANN approach uses neural networks to refine knowledge that can
be written in the form of simple propositional rules. We extend this idea
further by presenting the MANNCON algorithm by which the mathematical
equations governing a PID controller determine the topology and initial
weights of a network, which is further trained using backpropagation. We
apply this method to the task of controlling the outflow and temperature
of a water tank, producing statistically-significant gains in accuracy over
both a standard neural network approach and a non-learning PID controller. Furthermore, using the PID knowledge to initialize the weights of
the network produces statistically less variation in testset accuracy when
compared to networks initialized with small random numbers.

1

INTRODUCTION

Research into the design of neural networks for process control has largely ignored
existing knowledge about the task at hand. One form this knowledge (often called
the "domain theory") can take is embodied in traditional controller paradigms. The

555

556

Scott, Shavlik, and Ray

recently-developed KBANN (Knowledge-Based Artificial Neural Networks) approach
(Towell et al., 1990) addresses this issue for tasks for which a domain theory (written
using simple propositional rules) is available. The basis of this approach is to use
the existing knowledge to determine an appropriate network topology and initial
weights, such that the network begins its learning process at a "good" starting
point.
This paper describes the MANNCON (Multivariable Artificial Neural Network Control) algorithm, a method of using a traditional controller paradigm to determine
the topology and initial weights of a network . The used of a PID controller in this
way eliminates network-design problems such as the choice of network topology
(i.e., the number of hidden units) and reduces the sensitivity of the network to the
initial values of the weights. Furthermore, the initial configuration of the network
is closer to its final state than it would normally be in a randomly-configured network. Thus, the MANNCON networks perform better and more consistently than
the standard, randomly-initialized three-layer approach.
The task we examine here is learning to control a Multiple-Input, Multiple-Output
(MIMO) system. There are a number of reasons to investigate this task using neural networks. One, it usually involves nonlinear input-output relationships, which
matches the nonlinear nature of neural networks. Two, there have been a number
of successful applications of neural networks to this task (Bhat & McAvoy, 1990;
Jordan & Jacobs, 1990; Miller et al., 1990). Finally, there are a number of existing
controller paradigms which can be used to determine the topology and the initial
weights of the network.

2

CONTROLLER NETWORKS

The MANNCON algorithm uses a Proportional-Integral-Derivative (PID) controller
(Stephanopoulos, 1984), one of the simplest of the traditional feedback controller
schemes, as the basis for the construction and initialization of a neural network controller. The basic idea of PID control is that the control action u (a vector) should
be proportional to the error, the integral of the error over time, and the temporal
derivative of the error. Several tuning parameters determine the contribution of
these various components. Figure 1 depicts the resulting network topology based
on the PID controller paradigm. The first layer of the network, that from Y$P (desired process output or setpoint) and Y(n-l) (actual process output of the past time
step), calculates the simple error (e). A simple vector difference,
e=Y$p-Y

accomplishes this. The second layer, that between e, e(n-l), and e, calculates the
actual error to be passed to the PID mechanism. In effect, this layer acts as a
steady-state pre-compensator (Ray, 1981), where

e = GIe
and produces the current error and the error signals at the past two time steps.
This compensator is a constant matrix, G I , with values such that interactions at a
steady state between the various control loops are eliminated. The final layer , that
between e and u(n) (controller output/plant input), calculates the controller action

Refining PID Controllers using Neural Networks

Fd
Td
den) Water

Tank

F
T
Yen)

WCO
WHO
WCI
WHI
WC2
WH2

Y(n-I)
t:(n-I)

Figure 1:

MANNCON network showing weights that are initialized using
Ziegler-Nichols tuning parameters.

based on the velocity form of the discrete PID controller:
UC(n)

= UC(n-l) + WCOCI(n) + WCICI(n-l) + WC2 CI(n-2)

where Wca, wCb and WC2 are constants determined by the tuning parameters of the
controller for that loop. A similar set of equations and constants (WHO, WHI, WH2)
exist for the other controller loop.
Figure 2 shows a schematic of the water tank (Ray, 1981) that the network controls. This figure also shows the controller variables (Fc and FH), the tank output
variables (F(h) and T), and the disturbance variables (Fd and Td). The controller
cannot measure the disturbances, which represent noise in the system.
MANN CON initializes the weights of Figure 1 's network with va.lues that mimic
the behavior of a PID controller tuned with Ziegler-Nichols (Z-N) parameters
(Stephanopoulos, 1984) at a particular operating condition. Using the KBANN
approach (Towell et al., 1990), it adds weights to the network such that all units
in a layer are connected to all units in all subsequent layers, and initializes these
weights to small random numbers several orders of magnitude smaller than the
weights determined by the PID parameters. We scaled the inputs and outputs of
the network to be in the range [0,1].

Initializing the weights of the network in the manner given above assumes that the
activation functions of the units in the network are linear, that is,

557

558

Scott, Shavlik, and Ray

Cold Stream
Fe
Hot Stream (at TH)

~
T
F

Dis t urban ce
Fd,Td
I-

= Temperature
= Flow Rate

h

II

l-

Output
F(h), T

I I

Figure 2: Stirred mixing tank requiring outflow and temperature control.

Table 1: Topology and initialization of networks.
Network
1. Standard neural network
2. MANNCON network I
3. MANNCON network II

Topology
3-layer (14 hidden units)
PID topology
PID topology

Weight Initialization
random
random
Z-N tuning

The strength of neural networks, however, lie in their having nonlinear (typically
sigmoidal) activation functions. For this reason, the MANNCON system initially sets
the weights (and the biases of the units) so that the linear response dictated by the
PID initialization is approximated by a sigmoid over the output range of the unit.
For units that have outputs in the range [-1,1]' the activation function becomes
2

1 + exp( -2.31 L
where

Wji

_ 1
WjiOi)

are the linear weights described above.

Once MANNCON configures and initializes the weights of the network, it uses a set
of training examples and backpropagation to improve the accuracy of the network.
The weights initialized with PID information, as well as those initialized with small
random numbers, change during backpropagation training.

3

EXPERIMENTAL DETAILS

We compared the performance of three networks that differed in their topology
and/or their method of initialization. Table 1 summarizes the network topology
and weight initialization method for each network. In this table, "PID topology"
is the network structure shown in Figure 1. "Random" weight initialization sets

Refining PID Controllers using Neural Networks

Table 2: Range and average duration of setpoints for experiments.
Experiment
1
2

3

Training Set
[0.1,0.9]
22 instances
[0.1,0.9]
22 instances
[0.4,0.6]
22 instances

Testing Set
[0.1,0.9]
22 instances
[0.1,0.9]
80 instances
[0.1,0.9]
80 instances

all weights to small random numbers centered around zero. We also compare these
networks to a (non-learning) PID controller.
We trained the networks using backpropagation over a randomly-determined schedule of setpoint YsP and disturbance d changes that did not repeat. The setpoints,
which represent the desired output values that the controller is to maintain, are the
temperature and outflow of the tank. The disturbances, which represent noise, are
the inflow rate and temperature of a disturbance stream. The magnitudes of the
setpoints and the disturbances formed a Gaussian distribution centered at 0.5. The
number of training examples between changes in the setpoints and disturbances
were exponentially distributed.
We performed three experiments in which the characteristics of the training and/or
testing set differed. Table 2 summarizes the range of the setpoints as well as their
average duration for each data set in the experiments. As can be seen, in Experiment
1, the training set and testing sets were qualitatively similar; in Experiment 2, the
test set was of longer duration setpoints; and in Experiment 3, the training set was
restricted to a subrange of the testing set. We periodically interrupted training and
tested the network . Results are averaged over 10 runs (Scott, 1991).
We used the error at the output of the tank (y in Figure 1) to determine the network
error (at u) by propagating the error backward through the plant (Psaltis et al.,
1988). In this method, the error signal at the input to the tank is given by

8u i

?Yi
= f '( netui ) ~
~ 8y j OUi
J

where 8yj represents the simple error at the output of the water tank and 8ui is the
error signal at the input of the tank . Since we used a model of the process and not a
real tank, we can calculate the partial derivatives from the process model equations.

4

RESULTS

Figure 3 compares the performance of the three networks for Experiment 1. As can
be seen, the MANNCON networks show an increase in correctness over the standard
neural network approach. Statistical analysis of the errors using a t-test show
that they differ significantly at the 99.5% confidence level. Furthermore, while the
difference in performance between MANNCON network I and MANNCON network II is

559

560

Scott, Shavlik, and Ray
l~---------------------------------------------,

1 = Standard neural network
2 = MANNCON network I
3 = MANN CON network II
4 = PID controller (non-learning)

10000

15000

20000

25000

30000

Training Instances
Figure 3: Mean square error of networks on the testset as a function of
the number of training instances presented for Experiment 1.
not significant, the difference in the variance of the testing error over different runs
is significant (99.5% confidence level). Finally, the MANNCON networks perform
significantly better (99.95% confidence level) than the non-learning PID controller.
The performance of the standard neural network represents the best of several trials
with a varying number of hidden units ranging from 2 to 20.
A second observation from Figure 3 is that the MANNCON networks learned much
more quickly than the standard neural-network approach. The MANNCON networks
required significantly fewer training instances to reach a performance level within
5% of its final error rate. For each of the experiments, Table 3 summarizes the
final mean error, as well as the number of training instances required to achieve a
performance within 5% of this value.

In Experiments 2 and 3 we again see a significant gain in correctness of the

MAN-

NCON networks over both the standard neural network approach (99.95% confidence
level) as well as the non-learning PID controller (99.95% confidence level). In these
experiments, the MANNCON network initialized with Z-N tuning also learned significantly quicker (99.95% confidence level) than the standard neural network.

5

FUTURE WORK

One question is whether the introduction of extra hidden units into the network
would improve the performance by giving the network "room" to learn concepts
that are outside the given domain theory. The addition of extra hidden units as
well as the removal of unneeded units is an area with much ongoing research.

Refining PID Controllers using Neural Networks

l.

2.
3.
4.
5.
l.

2.
3.
4.
5.
l.

2.
3.
4.
5.

Table 3: Comparison of network performance.
I Mean Square Error I Training Instances
Method
Experiment 1
25,200 ? 2, 260
Standard neural network
0.0103 ? 0.0004
5,000 ? 3,340
MANN CON network I
0.0090 ? 0.0006
MANN CON network II
640? 200
0.0086 ? 0.0001
PID control (Z-N tuning) 0.0109
0.0190
Fixed control action
Experiment 2
14,400 ? 3, 150
Standard neural network
0.0118 ? 0.00158
12 , 000 ? 3,690
MANN CON network I
0.0040 ? 0.00014
2,080? 300
0.0038 ? 0.00006
MANN CON network II
PID control (Z-N tuning) 0.0045
Fixed con trol action
0.0181
Experiment 3
0.0112 ? 0.00013
25,200 ? 2, 360
Standard neural network
25,000 ? 1, 550
MANN CON network I
0.0039 ? 0.00008
9,400 ? 1,180
MANN CON network II
0.0036 ? 0.00006
PID control (Z-N tuning) 0.0045
Fixed control action
0.0181

The "?" indicates that the true value lies within these bounds at a 95%
confidence level. The values given for fixed control action (5) represent
the errors resulting from fixing the control actions at a level that produces
outputs of [0.5,0.5) at steady state.

"Ringing" (rapid changes in controller actions) occurred in some of the trained
networks . A future enhancement of this approach would be to create a network
architecture that prevented this ringing, perhaps by limiting the changes in the
controller actions to some relatively small values.
Another important goal of this approach is the application of it to other real-world
processes. The water tank in this project, while illustrative of the approach , was
quite simple. Much more difficult problems (such as those containing significant
time delays) exist and should be explored.
There are several other controller paradigms that could be used as a basis for network construction and initialization. There are several different digital controllers,
such as Deadbeat or Dahlin's (Stephanopoulos, 1984), that could be used in place
of the digital PID controller used in this project. Dynamic Matrix Control (DMC)
(Pratt et al., 1980) and Internal Model Control (IMC) (Garcia & Morari, 1982) are
also candidates for consideration for this approach.
Finally, neural networks are generally considered to be "black boxes," in that their
inner workings are completely uninterpretable. Since the neural networks in this
approach are initialized with information, it may be possible to interpret the weights
of the network and extract useful information from the trained network.

561

562

Scott, Shavlik, and Ray

6

CONCLUSIONS

We have described the MANNCON algorithm, which uses the information from a
PID controller to determine a relevant network topology without resorting to trialand-error methods. In addition, the algorithm, through initialization of the weights
with prior knowledge, gives the backpropagtion algorithm an appropriate direction
in which to continue learning. Finally, we have shown that using the MANNCON
algorithm significantly improves the performance of the trained network in the following ways:
? Improved mean testset accuracy
? Less variability between runs
? Faster rate of learning
? Better generalization and extrapolation ability
Acknowledgements

This material based upon work partially supported under a National Science Foundation Graduate Fellowship (to Scott), Office of Naval Research Grant N00014-90J-1941, and National Science Foundation Grants IRI-9002413 and CPT-8715051.
References

Bhat, N. & McAvoy, T. J. (1990). Use of neural nets for dynamic modeling and
control of chemical process systems. Computers and Chemical Engineering, 14,
573-583.
Garcia, C. E. & Morari, M. (1982). Internal model control: 1. A unifying review
and some new results. I&EC Process Design & Development, 21, 308-323.
Jordan, M. I. & Jacobs, R. A. (1990). Learning to control an unstable system
with forward modeling. In Advances in Neural Information Processing Systems
(Vol. 2, pp. 325- 331). San Mateo, CA: Morgan Kaufmann.
Miller, W. T., Sutton, R. S., & Werbos, P. J. (Eds.)(1990). Neural networks for
control. Cambridge, MA : MIT Press.
Pratt, D. M., Ramaker, B. L., & Cutler, C. R. (1980) . Dynamic matrix control
method. Patent 4,349,869, Shell Oil Company.
Psaltis, D., Sideris, A., & Yamamura, A. A. (1988). A multilayered neural network
controller. IEEE Control Systems Magazine, 8, 17- 21.
Ray, W . H. (1981). Advanced process control. New York: McGraw-Hill, Inc.
Scott, G. M. (1991). Refining PID controllers using neural networks. Master's
project, University of Wisconsin, Department of Computer Sciences.
Stephanopoulos, G. (1984). Chemical process control: An introduction to theory
and practice. Englewood Cliffs, NJ: Prentice Hall, Inc.
Towell, G., Shavlik, J., & Noordewier, M. (1990). Refinement of approximate domain theories by knowledge-base neural networks. In Eighth National Conference on Aritificial Intelligence (pp. 861-866). Menlo Park, CA: AAAI Press .


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 822-bounds-on-the-complexity-of-recurrent-neural-network-implementations-of-finite-state-machines.pdf

Bounds on the complexity of recurrent
neural network implementations of finite
state machines

Bill G. Horne
NEC Research Institute
4 Independence Way
Princeton, NJ 08540

Don R. Hush
EECE Department
University of New Mexico
Albuquerque, NM 87131

Abstract
In this paper the efficiency of recurrent neural network implementations of m-state finite state machines will be explored. Specifically,
it will be shown that the node complexity for the unrestricted case
can be bounded above by 0 ( fo) . It will also be shown that the
node complexity is 0 (y'm log m) when the weights and thresholds
are restricted to the set {-I, I}, and 0 (m) when the fan-in is restricted to two. Matching lower bounds will be provided for each
of these upper bounds assuming that the state of the FSM can be
encoded in a subset of the nodes of size rlog m1.

1

Introduction

The topic of this paper is understanding how efficiently neural networks scale to
large problems. Although there are many ways to measure efficiency, we shall be
concerned with node complexity, which as its name implies, is a calculation of the
required number of nodes. Node complexity is a useful measure of efficiency since
the amount of resources required to implement or even simulate a recurrent neural
network is typically related to the number of nodes. Node complexity can also
be related to the efficiency of learning algorithms for these networks and perhaps
to their generalization ability as well. We shall focus on the node complexity of
recurrent neural network implementations of finite state machines (FSMs) when
the nodes of the network are restricted to threshold logic units.

359

360

Home and Hush

In the 1960s it was shown that recurrent neural networks are capable of implementing arbitrary FSMs. The first result in this area was due to Minsky [7], who
showed that m-state FSMs can be implemented in a fully connected recurrent neural network. Although circuit complexity was not the focus of his investigation it
turns out that his construction, yields 0 (m) nodes. This construction was also
guaranteed to use weight values limited to the set {I, 2}. Since a recurrent neural
network with k hard-limiting nodes is capable of representing as many as 2k states,
one might wonder if an m-state FSM could be implemented by a network with
log m nodes. However, it was shown in [1] that the node complexity for a standard

((m

fully connected network is n
log m)1/3). They were also able to improve upon
Minsky's result by providing a construction which is guaranteed to yield no more
than 0 (m 3/ 4 ) nodes. In the same paper lower bounds on node complexity were investigated as the network was subject to restrictions on the possible range of weight
values and the fan-in and fan-out of the nodes in the network. Their investigation
was limited to fully connected recurrent neural networks and they discovered that
the node complexity for the case where the weights are restricted to a finite size set
is n (y'm log m) . Alternatively, if the nodes in the network were restricted to have a
constant fan-in then the node complexity becomes n (m) . However, they left open
the question of how tight these bounds are and if they apply to variations on the
basic architecture. Other recent work includes investigation of the node complexity
for networks with continuous valued nonlinearities [14]. However, it can also be
shown that when continuous nonlinearities are used, recurrent neural networks are
far more powerful than FSMs; in fact, they are Turing equivalent [13].
In this paper we improve the upper bound on the node complexity for the unrestricted case to 0 (yIm). We also provide upper bounds that match the lower
bounds above for various restrictions. Specifically, we show that a node complexity
of 0 ( y'm log m) can be achieved if the weights are restricted to the set {-I, I} , and
that the node complexity is 0 (m) for the case when the fan-in of each node in the
network is restricted to two. Finally, we explore the possibility that implementing
finite state machines in more complex models might yield a lower node complexity.
Specifically, we explore the node complexity of a general recurrent neural network
topology, that is capable of simulating a variety of popular recurrent neural network architectures. Except for the unrestricted case, we will show that the node
complexity is no different for this architecture than for the fully connected case if
the number of feedback variables is limited to rlog m1, i.e. if the state of the FSM
is encoded optimally in a subset of the nodes. We leave it as an open question if a
sparser encoding can lead to a more efficient implementation.

2
2.1

Background
Finite State Machines

FSMs may be defined in several ways. In this paper we shall be concerned with
Mealy machines, although our approach can easily be extended to other formulations
to yield equivalent results.

Bounds on the Complexity of Recurrent Neural Network Implementations

Definition 1 A Mealy machine is a quintuple M = (Q, qo, E, d, <1?, where Q is a
finite set of states; qo is the initial state ; E is the input alphabet; d is the output
alphabet; and <I> : Q x E Q x d is the combined transition and output function.

o

=

Throughout this paper both the input and output alphabets will be binary (i.e. E
d
{a, I}) . In general, the number of states, m
IQI, may be arbitrary. Since any
element of Q can be encoded as a binary vector whose minimum length is pog m 1,
the function <I> can be implemented as a boolean logic function of the form

=

=

<I> :

{a, l} pogm1+l _

{a, l} pogm1+l .

(1)

The number, N M , of different minimal FSMs with m states will be used to determine
lower bounds on the number of gates required to implement an arbitrary FSM in a
recurrent neural network. It can easily be shown that (2m)m :S NM [5]. However,
it will be convenient to reexpress N M in terms of n = flog m 1+ 1 as follows

(2)
2.2

Recurrent Neural Networks

The fundamental processing unit in the models we wish to consider is the perceptron,
which is a biased, linearly weighted sum of its inputs followed by a hard-limiting
nonlinearity whose output is zero if its input is negative and one otherwise. The
fan-in of the perceptron is defined to be the number of non-zero weights. When the
values of Xi are binary (as they are in this paper) , the perceptron is often referred
to as a threshold logic unit (TL U).
A count of the number of different partially specified threshold logic functions, which
are threshold logic functions whose values are only defined over v vertices of the
unit hypercube, will be needed to develop lower bounds on the node complexity
required to implement an arbitrary logic function . It has been shown that this
number, denoted L~, is [15]
L~:S

2v n
-,-.
n.

(3)

As pointed out in [10], many of the most popular discrete-time recurrent neural
network models can be implemented as a feedforward network whose outputs are
fed back recurrently through a set of unit time delays. In the most generic version of
this architecture, the feed forward section is lower triangular, meaning the [th node is
the only node in layer I and receives input from all nodes in previous layers (including
the input layer). A lower triangular network of k threshold logic elements is the
most general topology possible for a feedforward network since all other feedforward
networks can be viewed as a special case of this network with the appropriate weights
set equal to zero. The most direct implementation of this model is the architecture
proposed in [11] . However, many recurrent neural network architectures can be cast
into this framework. For example, fully connected networks [3] fit this model when
the the feedforward network is simply a single layer of nodes. Even models which
appear very different [2, 9] can be cast into this framework.

361

362

Home and Hush

3

The unrestricted case

The unrestricted case is the most general, and thus explores the inherent power of
recurrent neural networks. The unrestricted case is also important because it serves
as a baseline from which one can evaluate the effect of various restrictions on the
node complexity.
In order to derive an upper bound on the node complexity of recurrent neural
network implementations of FSMs we shall utilize the following lemma, due to
Lupanov [6]. The proof of this lemma involves a construction that is extremely
complex and beyond the scope of this paper.
Lemma 1 (Lupanov, 1973) Arbitrary boolean logic functions with x inputs and
y outputs can be implemented in a network of perceptrons with a node complexity
of

o(

J ~~:g y) .
x

o
Theorem 1 Multilayer recurrent neural networks can implement FSMs having m
states with a node complexity of 0 (.Jffi) .
0
Proof: Since an m-state FSM can be implemented in a recurrent neural network
in which the multilayer network performs a mapping of the form in equation (1),
then using n = m = flog m1+ 1, and applying Lemma 1 gives an upper bound of
O(.Jffi).
Q.E.D.
Theorem 2 Multilayer recurrent neural networks can implement FSMs having m
states with a node complexity of n (fo) if the number of unit time delays is flog m1.

o

Proof: In order to prove the theorem we derive an expression for the maximum
number of functions that a k-node recurrent neural network can compute and compare that against the minimum number of finite state machines. Then we solve for
k in terms of the number of states of the FSM.

Specifically, we wish to manipulate the inequality
2(n-l)2 n -

2

< n!
-

( k- 1 )

n- 1
(a)

krr-l 2n(n+i~+1
.
(n + z)!
,=0
(b)

where the left hand side is given in equation (2), (a) represents the total number of
ways to choose the outputs and feedback variables of the network, and (b) represents the total number of logic functions computable by the feed forward section of
the network, which is lower triangular. Part (a) is found by simple combinatorial
arguments and noting that the last node in the network must be used as either
an output or feedback node. Part (b) is obtained by the following argument: If
the state is optimally encoded in flog m1 nodes, then only flog m1 variables need

Bounds on the Complexity of Recurrent Neural Network Implementations

to be fed back. Together with the external input this gives n = rlog m1 + 1 local
inputs to the feedforward network. Repeated application of (3) with v 2n yields
expression (b).

=

Following a series of algebraic manipulations it can easily be shown that there exists
a constant c such that
n2n < ck 2n.
Since n = flog ml

4

+ 1 it follows that k = f2 (fo).

Q.E.D.

Restriction on weights and thresholds

All threshold logic functions can be implemented with perceptrons whose weight
and threshold values are integers. It is well known that there are threshold logic
functions of n variables that require a perceptron with weights whose maximum
magnitude is f2(2n) and O( nn/2) [8]. This implies that if a perceptron is to be
implemented digitally, the number of bits required to represent each weight and
threshold in the worst case will be a super linear function of the fan-in. This is
generally undesirable ; it would be far better to require only a logarithmic number
of bits per weight, or even better, a constant number of bits per weight. We will be
primarily be interested in the most extreme case where the weights are limited to
values from the set {-I , I}.
In order to derive the node complexity for networks with weight restrictions, we
shall utilize the following lemma, proved in [4].
Lemma 2 Arbitrary boolean logic functions with x inputs and y outputs can be
implemented in a network ofperceptrons whose weights and thresholds are restricted
to the set {-I, I} with a node complexity of e (Jy2 x ) .
0

This lemma is not difficult to prove , however it is beyond the scope of this paper.
The basic idea involves using a decomposition of logic functions proposed in [12].
Specifically, a boolean function f may always be decomposed into a disjunction of
2 r terms of the form XIX2. ' . Xr fi(X r +1 , .. . , x n ) , one for each conjunction of the
first r variables, where Xj represents either a complemented or uncomplemented
version of the input variable Xj and each Ii is a logic function of the last n - r
variables. This expression can be implemented directly in a neural network. With
negligible number of additional nodes, the construction can be implemented in such
a way that all weights are either -lor 1. Finally, the variable r is optimized to
yield the minimum number of nodes in the network.
Theorem 3 Multilayer recurrent neural networks that have nodes whose weights
and thresholds are restricted to the set {-I , I} can implement FSMs having m
states with a node complexity of 0 (Jm log m) .
0
Proof: Since an m-state FSM can be implemented in a recurrent neural network
in which the multilayer network performs a mapping of the form in equation (1),
then using n = m = flog m1+ 1, and applying Lemma 2 gives an upper bound of
o (Jmlogm) .
Q.E.D.

363

364

Home and Hush

Theorem 4 Multilayer recurrent neural networks that have nodes whose weights
and thresholds are restricted to a set of size IWI can implement FSMs having m

states with a node complexity of n (

if the number of unit time delays is

flogml.

0

Proof: The proof is similar to the proof of Theorem 2 which gave a lower bound
for the node complexity required in an arbitrary network of threshold logic units.
Here, the inequality we wish to manipulate is given by
k-l

k- 1

n-I

)

II IWln+i+

1.

i=O

(b)

(a)

where the left hand side and (a) are computed as before and (b) represents the
maximum number of ways to configure the nodes in the network when there are
only IWI choices for each weight and threshold. Following a series of algebraic
manipulations it can be shown that there exists a constant c such that
n2n ::; ck 2 log IWI.

Since n

= pog m1+ 1 it follows that k = n (

Clearly, for W

5

mlogm)
loglWI
.

Q.E.D.

= {-I, I} this lower bound matches the upper bound in Theorem 3.

Restriction on fan-in

A limit on the fan-in of a perceptron is another important practical restriction.
In the networks discussed so far each node has an unlimited fan-in. In fact, in
the constructions described above, many nodes receive inputs from a polynomial
number of nodes (in terms of m) in a previous layer. In practice it is not possible
to build devices that have such a large connectivity. Restricting the fan-in to 2, is
the most severe restriction, and will be of primary interest in this paper.
Once again, in order to derive the node complexity for restricted fan-in, we shall
utilize the following lemma, proved in [4].
Lemma 3 Arbitrary boolean logic functions with x inputs and y outputs can be
implemented in a network of perceptrons restricted to fan-in 2 with a node complexityof
y2X )
e ( x + logy .

o
This proof of this lemma is very similar to the proof of Lemma 2. Here Shannon's
decomposition is used with r = 2 to recursively decompose the logic function into
a set of trees, until each tree has depth d. Then, all possible functions of the last
n - d variables are implemented in an inverted tree-like structure, which feeds into
the bottom of the trees. Finally, d is optimized to yield the minimum number of
nodes.

Bounds on the Complexity of Recurrent Neural Network Implementations

Theorem 5 Multilayer recurrent neural networks that have nodes whose fan-in is
restricted to two can implement FSMs having m states with a node complexity of

Oem)

0

Proof: Since an m-state FSM can be implemented in a recurrent neural network
in which the multilayer network performs a mapping of the form in equation (1),
then using n = m = rlog m1+ 1, and applying Lemma 3 gives an upper bound of
o (m).
Q.E.D.
Theorem 6 Multilayer recurrent neural networks that have nodes whose fan-in is
restricted to two can implement FSMs having m states with a node complexity of
n (m) if the number of unit time delays is rlog m1.
0
Proof: Once again the proof is similar to Theorem 2, which gave a lower bound
for the node complexity required in an arbitrary network of threshold logic units.
Here, the inequality we need to solve for is given by
2(n-1)2'-'

:s n! ( ~:= ~

) D. 14 (

n

t

i )

,----_V~----A~----_V~----~

(a)

(b)

where the left hand side and (a) are computed as before and (b) represents the maximum number of ways to configure the nodes in the network. The term ( n

t

i )

is used since a node in the ith layer has n + i possible inputs from which two are
chosen. The constant 14 represents the fourteen possible threshold logic functions
of two variables. Following a series of algebraic manipulations it can be shown that
there exists a constant c such that
~

ck logk

Since n = rlog m1 + 1 it follows that k =

n (m) .

n2n

6

Q.E.D.

Summary

In summary, we provide new bounds on the node complexity of implementing FSMs
with recurrent neural networks. These upper bounds match lower bounds developed in [1] for fully connected recurrent networks when the size of the weight set
or the fan-in of each node is finite. Although one might speculate that more complex networks might yield more efficient constructions, we showed that these lower
bounds do not change for restrictions on weights or fan-in, at least when the state
of the FSM is encoded optimally in a subset of flog m1 nodes. When the network
is unrestricted, this lower bound matches our upper bound. We leave it as an open
question if a sparser encoding of the state variables can lead to a more efficient
implementation.
One interesting aspect of this study is that there is really not much difference
in efficiency when the network is totally unrestricted and when there are severe
restrictions placed on the weights. Assuming that our bounds are tight, then there

365

366

Home and Hush

is only a y'log m penalty for restricting the weights to either -1 or 1. To get some
idea for how marginal this difference is consider that for a finite state machine with
18 x 10 18 states, y'log m is only eight!
m

=

A more detailed version of this paper can be found in [5].

References
[1] N. Alon, A.K. Dewdney, and T.J. Ott . Efficient simulation of finite automata
by neural nets. JACM, 38(2):495-514, 1991.
[2] A.D. Back and A.C. Tsoi. FIR and I1R synapses, a new neural network architecture for time series modeling. Neural Computation, 3(3):375-385, 1991.
[3] J.J. Hopfield. Neural networks and physical systems with emergent collective
computational abilities. Proc. Nat. Acad. Sci., 79:2554-2558, 1982.
[4] B.G. Horne and D.R. Hush. On the node complexity of neural networks. Technical Report EECE 93-003, Dept. EECE, U. New Mexico, 1993.
[5] B.G. Horne and D.R. Hush. Bounds on the complexity of recurrent neural
network implementations of finite state machines. Technical Report EECE
94-001, Dept. EECE, U. New Mexico, 1994.
[6] O.B. Lupanov . The synthesis of circuits from threshold elements. Problemy
Kibernetiki, 26:109-140, 1973.
[7] M. Minsky. Computation: Finite and infinite machines. Prentice-Hall, 1967.
[8] S. Muroga. Threshold Logic and Its Applications. Wiley, 1971.
[9] K.S. Narendra and K. Parthasarathy. Identification and control of dynamical
systems using neural networks. IEEE Trans. on Neural Networks, 1:4-27, 1990.
[10] O. Nerrand et al. Neural networks and nonlinear adaptive filtering: Unifying
concepts and new algorithms. Neural Computation, 5(2):165-199, 1993.
[11] A.J. Robinson and F. Fallside. Static and dynamic error propagation networks
with application to speech coding. In D.Z. Anderson, editor, Neural Information Processing Systems, pages 632-641, 1988.
[12] C. Shannon. The synthesis of two-terminal switching circuits. Bell Sys. Tech.
1., 28:59-98, 1949.
[13] H. Siegelmann and E.D. Sontag. Neural networks are universal computing
devices. Technical Report SYCON-91-08, Rutgers Ctr. for Sys. and Cont.,
1991.
[14] H.T. Siegelmann, E.D. Sontag, and C.L. Giles. The complexity of language
recognition by neural networks. In Proc. IFIP 12th World Compo Cong., pages
329-335, 1992.
[15] R.O. Winder. Bounds on threshold gate realizability. IEEE Trans. on Elect.
Comp., EC-12:561-564, 1963.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

