query sentence: Storing potentiation of synaptic strengths
---------------------------------------------------------------------
title: 100-storing-covariance-by-the-associative-long-term-potentiation-and-depression-of-synaptic-strengths-in-the-hippocampus.pdf

394

STORING COVARIANCE BY THE ASSOCIATIVE
LONG?TERM POTENTIATION AND DEPRESSION
OF SYNAPTIC STRENGTHS IN THE HIPPOCAMPUS
Patric K. Stanton? and Terrence J. Sejnowski t
Department of Biophysics
Johns Hopkins University
Baltimore, MD 21218
ABSTRACT

In modeling studies or memory based on neural networks, both the selective
enhancement and depression or synaptic strengths are required ror effident storage
or inrormation (Sejnowski, 1977a,b; Kohonen, 1984; Bienenstock et aI, 1982;
Sejnowski and Tesauro, 1989). We have tested this assumption in the hippocampus,
a cortical structure or the brain that is involved in long-term memory. A brier,
high-frequency activation or excitatory synapses in the hippocampus produces an
increase in synaptic strength known as long-term potentiation, or LTP (BUss and
Lomo, 1973), that can last ror many days. LTP is known to be Hebbian since it
requires the simultaneous release or neurotransmitter from presynaptic terminals
coupled with postsynaptic depolarization (Kelso et al, 1986; Malinow and Miller,
1986; Gustatrson et al, 1987). However, a mechanism ror the persistent reduction or
synaptic strength that could balance LTP has not yet been demonstrated. We studied the associative interactions between separate inputs onto the same dendritic
trees or hippocampal pyramidal cells or field CAl, and round that a low-frequency
input which, by itselr, does not persistently change synaptic strength, can either
increase (associative LTP) or decrease in strength (associative long-term depression
or LTD) depending upon whether it is positively or negatively correlated in time
with a second, high-frequency bursting input. LTP or synaptic strength is Hebbian,
and LTD is anti-Hebbian since it is elicited by pairing presynaptic firing with postsynaptic hyperpolarization sufficient to block postsynaptic activity. Thus, associative LTP and associative LTO are capable or storing inrormation contained in the
covariance between separate, converging hippocampal inputs?

?Present address: Dep~ents of NeW'Oscience and Neurology, Albert Einstein College
of Medicine, 1410 Pelham Parkway South, Bronx, NY 10461 USA.
tPresent address: Computational Neurobiology Laboratory, The Salk Institute, P.O. Box
85800, San Diego, CA 92138 USA.

Storing Covariance by Synaptic Strengths in the Hippocampus

INTRODUCTION
Associative LTP can be produced in some hippocampal neuroos when lowfrequency. (Weak) and high-frequency (Strong) inputs to the same cells are simultaneously activated (Levy and Steward, 1979; Levy and Steward, 1983; Barrionuevo and
Brown, 1983). When stimulated alone, a weak input does not have a long-lasting effect
on synaptic strength; however, when paired with stimulation of a separate strong input
sufficient to produce homo synaptic LTP of that pathway, the weak pathway is associatively potentiated. Neural network modeling studies have predicted that, in addition to
this Hebbian form of plasticity, synaptic strength should be weakened when weak and
strong inputs are anti-correlated (Sejnowski, 1977a,b; Kohonen, 1984; Bienenstock et al,
1982; Sejnowski and Tesauro, 1989). Evidence for heterosynaptic depression in the hippocampus has been found for inputs that are inactive (Levy and Steward, 1979; Lynch et
al, 1977) or weakly active (Levy and Steward, 1983) during the stimulation of a strong
input, but this depression did not depend on any pattern of weak input activity and was
not typically as long-lasting as LTP.
Therefore, we searched for conditions under which stimulation of a hippocampal
pathway, rather than its inactivity, could produce either long-term depression or potentiation of synaptic strengths, depending on the pattern of stimulation. The stimulus paradigm that we used, illustrated in Fig. I, is based on the finding that bursts of stimuli at 5
Hz are optimal in eliciting LTP in the hippocampus (Larson and Lynch, 1986). A highfrequency burst (S'IRONG) stimulus was applied to Schaffer collateral axons and a lowfrequency (WEAK) stimulus given to a separate subicular input coming from the opposite side of the recording site, but terminating on dendrites of the same population of CAl
pyramidal neurons. Due to the rhythmic nature of the strong input bursts, each weak
input shock could be either superimposed on the middle of each burst of the strong input
(IN PHASE), or placed symmetrically between bursts (OUT OF PHASE).

RESULTS
Extracellular evoked field potentials were recorded from the apical dendritic and
somatic layers of CAl pyramidal cells. The weak stimulus train was first applied alone
and did not itself induce long-lasting changes. The strong site was then stimulated alone,
which elicited homosynaptic LTP of the strong pathway but did not significantly alter
amplitude of responses to the weak input. When weak and strong inputs were activated
IN PHASE, there was an associative LTP of the weak input synapses, as shown in Fig.
2a. Both the synaptic excitatory post-synaptic potential (e.p.s.p.) (Ae.p.s.p. = +49.8 ?
7.8%, n=20) and population action potential (&Pike = +65.4 ? 16.0%, n=14) were
significantly enhanced for at least 60 min up to 180 min following stimulation.
In contrast, when weak and strong inputs were applied OUT OF PHASE, they elicited an associative long-term depression (LTO) of the weak input synapses, as shown in
Fig. 2b. There was a marked reduction in the population spike (-46.5 ? 11.4%, n=10)
with smaller decreases in the e.p.s.p. (-13.8 ? 3.5%, n=13). Note that the stimulus patterns applied to each input were identical in these two experiments, and only the relative

395

396

Stanton and Sejnowski

phase of the weak and strong stimuli was altered. With these stimulus patterns. synaptic
strength could be repeatedly enhanced and depressed in a single slice. as illustrated in Fig
2c. As a control experiment to determine whether information concerning covariance
between the inputs was actually a determinant of plasticity. we combined the in phase
and out of phase conditions, giving both the weak input shocks superimposed on the
bursts plus those between the bursts. for a net frequency of 10 Hz. This pattern. which
resulted in zero covariance between weak and strong inputs. produced no net change in
weak input synaptic strength measmed by extracellular evoked potentials. Thus. the assoa

b
A.SSOCIA.TIVE STIMULUS PA.RA.DIGMS
POSJTIVE.LY CORKELA TED ? "IN PHASE"

~K~~ _I~__~I____~I____~I_
SI1IONG,NJO\IT

. u.Jj1l 11l. -1---1&1111.....
11 ---1&1
111.....
11 ---,I~IIII

NEGATIVELY CORRELATED? 'our OF PHASE"
W[AKIN'lTf

STIONG 'N''''

~I

11111

--,-;

11111

11111

Figure 1. Hippocampal slice preparation and stimulus paradigms. a: The in vitro hippocampal slice showing recording sites in CAl pyramidal cell somatic (stratum pyramidale) and dendritic (stratum radiatum) layers. and stimulus sites activating Schaffer collateral (STRONG) and commissural (WEAK) afferents. Hippocampal slices (400 Jlm
thick) were incubated in an interface slice chamber at 34-35 0 C. Extracellular (1-5 M!l
resistance, 2M NaCI filled) and intracellular (70-120 M 2M K-acetate filled) recording electrodes. and bipolar glass-insulated platinum wire stimulating electrodes (50 Jlm
tip diameter). were prepared by standard methods (Mody et al, 1988). b: Stimulus paradigms used. Strong input stimuli (STRONG INPUT) were four trains of 100 Hz bursts.
Each burst had 5 stimuli and the interburst interval was 200 msec. Each train lasted 2
seconds for a total of 50 stimuli. Weak input stimuli (WEAK INPUT) were four trains of
shocks at 5 Hz frequency. each train lasting for 2 seconds. When these inputs were IN
PHASE. the weak single shocks were superimposed on the middle of each burst of the
strong input. When the weak input was OUT OF PHASE. the single shocks were placed
symmetrically between the bursts.

n.

Storing Covariance by Synaptic Strengths in the Hippocampus

ciative LTP and LTD mechanisms appear to be balanced in a manner ideal for the
storage of temporal covariance relations.
The simultaneous depolarization of the postsynaptic membrane and activation of
glutamate receptors of the N-methyl-D-aspartate (NMDA) subtype appears to be necessary for LTP induction (Collingridge et ai, 1983; Harris et al, 1984; Wigstrom and Gustaffson, 1984). The SJ?read of current from strong to weak synapses in the dendritic tree,
d

ASSOCIATIVE

LON(;.TE~

I'OTENTIATION

LONG-TE~

DE,/tESSION

-

!!Ll!!!!.

b

ASSOCIATIVE

I

11111

?

11111.
I

c

e...

I

I

I

I

Figure 2. mustration of associative long-term potentiation (LTP) and associative longterm depression (LTD) using extracellular recordings. a: Associative LTP of evoked
excitatory postsynaptic potentials (e.p.s.p.'s) and population action potential responses in
the weak inpuL Test responses are shown before (Pre) and 30 min after (post) application of weak stimuli in phase with the coactive strong input. b: Associative LTD of
evoked e.p.s.p.'s and population spike responses in the weak input. Test responses are
shown before (Pre) and 30 min after (post) application of weak stimuli out of phase with
the coactive strong input. c: Time course of the changes in population spike amplitude
observed at each input for a typical experiment. Test responses from the strong input (S,
open circles), show that the high-frequency bursts (5 pulses/l00 Hz, 200 msec interburst
interval as in Fig. 1) elicited synapse-specific LTP independent of other input activity.
Test responses from the weak input (W. filled circles) show that stimulation of the weak
pathway out of phase with the strong one produced associative LTD (Assoc LTD) of this
input. Associative LTP (Assoc LTP) of the same pathway was then elicited following in
phase stimulation. Amplitude and duration of associative LTD or LTP could be increased
by stimulating input pathways with more trains of shocks.

397

398

Stanton and Sejnowski

coupled with release of glutamate from the weak inputs, could account for the ability of
the strong pathway to associatively potentiate a weak one (Kelso et al, 1986; Malinow
and Miller, 1986; Gustaffson et al, 1987). Consistent with this hypothesis, we find that
the NMDA receptor antagonist 2-amino-S-phosphonovaleric acid (APS, 10 J.1M) blocks
induction of associative LTP in CAl pyramidal neurons (data not shown, n=S). In contrast, the application of APS to the bathing solution at this same concentration had no
significant effect on associative LTD (data not shown, n=6). Thus, the induction of LTD
seems to involve cellular mechanisms different from associative LTP.
The conditions necessary for LTD induction were explored in another series of
experiments using intracellular recordings from CAl pyramidal neurons made using
standard techniques (Mody et al, 1988). Induction of associative LTP (Fig 3; WEAK
S+W IN PHASE) produced an increase in amplitude of the single cell evoked e.p.s.p. and
a lowered action potential threshold in the weak pathway, as reported previously (Barrionuevo and Brown, 1983). Conversely, the induction of associative LTD (Fig. 3;
WEAK S+W OUT OF PHASE) was accompanied by a long-lasting reduction of e.p.s.p.
amplitude and reduced ability to elicit action potential firing. As in control extracellular
experiments, the weak input alone produced no long-lasting alterations in intracellular
e.p.s.p.'s or firing properties, while the strong input alone yielded specific increases of
the strong pathway e.p.s.p. without altering e.p.s.p. 's elicited by weak input stimulation.

PRE

30 min POST
S+W OUT OF PHASE

30 min POST
S+W IN PHASE

Figure 3. Demonstration of associative LTP and LTD using intracellular recordings from
a CAl pyramidal neuron. Intracellular e.p.s.p.'s prior to repetitive stimulation (pre), 30
min after out of phase stimulation (S+W OUT OF PHASE), and 30 min after subsequent in phase stimuli (S+W IN PHASE). The strong input (Schaffer collateral side,
lower traces) exhibited LTP of the evoked e.p.s.p. independent of weak input activity.
Out of phase stimulation of the weak (Subicular side, upper traces) pathway produced a
marked, persistent reduction in e.p.s.p. amplitude. In the same cell, subsequent in phase
stimuli resulted in associative LTP of the weak input that reversed the LTD and enhanced
amplitude of the e.p.s.p. past the original baseline. (RMP = -62 mY, RN = 30 MO)

Storing Covariance by Synaptic Strengths in the Hippocampus

A weak stimulus that is out of phase with a strong one anives when the postsynaptic neuron is hyperpolarized as a consequence of inhibitory postsynaptic potentials and
afterhyperpolarization from mechanisms intrinsic to pyramidal neurons. This suggests
that postsynaptic hyperpolarization coupled with presynaptic activation may trigger L'ID.
To test this hypothesis, we injected current with intracellular microelectrodes to hyperpolarize or depolarize the cell while stimulating a synaptic input. Pairing the injection of
depolarizing current with the weak input led to LTP of those synapses (Fig. 4a; STIM;

a

PRE

? ?IDPOST
S'I1M ? DEPOL

~l"V
lS.,.c

r
," i

COI'ITROL

-Jj

b

I

--" \

"----

(W.c:ULVllj

PRE

lOlIIin POST
STlM ? HYPERPOL

Figure 4. Pairing of postsynaptic hyperpolarization with stimulation of synapses on CAl
hippocampal pyramidal neurons produces L'ID specific to the activated pathway, while
pairing of postsynaptic depolarization with synaptic stimulation produces synapsespecific LTP. a: Intracellular evoked e.p.s.p.'s are shown at stimulated (STIM) and
unstimulated (CONTROL) pathway synapses before (Pre) and 30 min after (post) pairing a 20 mY depolarization (constant current +2.0 nA) with 5 Hz synaptic stimulation.
The stimulated pathway exhibited associative LTP of the e.p.s.p., while the control,
unstimulated input showed no change in synaptic strength. (RMP = -65 mY; RN = 35
Mfl) b: Intracellular e.p.s.p. 's are shown evoked at stimulated and control pathway
synapses before (Pre) and 30 min after (post) pairing a 20 mV hyperpolarization (constant current -1.0 nA) with 5 Hz synaptic stimulation. The input (STIM) activated during
the hyperpolarization showed associative LTD of synaptic evoked e.p.s.p.'s, while
synaptic strength of the silent input (CONTROL) was unaltered. (RMP =-62 mV; RN =
38M!l)

399

400

Stanton and Sejnowski

+64.0 -9.7%, n=4), while a control input inactive during the stimulation did not change
(CONTROL), as reported previously (Kelso et al, 1986; Malinow and Miller, 1986; Gustaffson et al, 1987). Conversely, prolonged hyperpolarizing current injection paired with
the same low-frequency stimuli led to induction of LTD in the stimulated pathway (Fig.
4b; STIM; -40.3 ? 6.3%, n=6). but not in the unstimulated pathway (CONTROL). The
application of either depolarizing current, hyperpolarizing current, or the weak 5 Hz
synaptic stimulation alone did not induce long-term alterations in synaptic strengths.
Thus. hyperpolarization and simultaneous presynaptic activity supply sufficient conditions for the induction of LTD in CAl pyramidal neurons.

CONCLUSIONS
These experiments identify a novel fono of anti-Hebbian synaptic plasticity in the
hippocampus and confirm predictions made from modeling studies of information storage
in neural networks. Unlike previous reports of synaptic depression in the hippocampus,
the plasticity is associative, long-lasting, and is produced when presynaptic activity
occurs while the postsynaptic membrane is hyperpolarized. In combination with Hebbian
mechanisms also present at hippocampal synapses. associative LTP and associative LTD
may allow neurons in the hippocampus to compute and store covariance between inputs
(Sejnowski, 1977a,b; Stanton and Sejnowski. 1989). These finding make temporal as
well as spatial context an important feature of memory mechanisms in the hippocampus.
Elsewhere in the brain, the receptive field properties of cells in cat visual cortex
can be altered by visual experience paired with iontophoretic excitation or depression of
cellular activity (Fregnac et al, 1988; Greuel et al, 1988). In particular, the chronic hyperpolarization of neurons in visual cortex coupled with presynaptic transmitter release leads
to a long-teno depression of the active. but not inactive, inputs from the lateral geniculate
nucleus (Reiter and Stryker, 1988). Thus. both Hebbian and anti-Hebbian mechanisms
found in the hippocampus seem to also be present in other brain areas, and covariance of
firing patterns between converging inputs a likely key to understanding higher cognitive
function.
This research was supported by grants from the National Science Foundation and
the Office of Naval research to TJS. We thank Drs. Charles Stevens and Richard Morris
for discussions about related experiments.

Rererences
Bienenstock, E., Cooper. LN. and Munro. P. Theory for the development of neuron
selectivity: orientation specificity and binocular interaction in visual cortex. J. Neurosci. 2. 32-48 (1982).
Barrionuevo, G. and Brown, T.H. Associative long-teno potentiation in hippocampal
slices. Proc. Nat. Acad. Sci. (USA) 80, 7347-7351 (1983).
Bliss. T.V.P. and Lomo, T. Long-lasting potentiation of synaptic ttansmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path. J.
Physiol. (Lond.) 232. 331-356 (1973).

Storing Covariance by Synaptic Strengths in the Hippocampus

Collingridge, GL., Kehl, SJ. and McLennan, H. Excitatory amino acids in synaptic
transmission in the Schaffer collateral-commissural pathway of the rat hippocampus. J.
Physiol. (Lond.) 334, 33-46 (1983).
Fregnac, Y., Shulz, D., Thorpe, S. and Bienenstock, E. A cellular analogue of visual cortical plasticity. Nature (Lond.) 333, 367-370 (1988).
Greuel. J.M.. Luhmann. H.J. and Singer. W. Pharmacological induction of usedependent receptive field modifications in visual cortex. Science 242,74-77 (1988).
Gustafsson, B., Wigstrom, H., Abraham, W.C. and Huang. Y.Y. Long-term potentiation
in the hippocampus using depolarizing current pulses as the conditioning stimulus to
single volley synaptic potentials. J. Neurosci. 7, 774-780 (1987).
Harris. E.W., Ganong, A.H. and Cotman, C.W. Long-term potentiation in the hippocampus involves activation of N-metbyl-D-aspartate receptors. Brain Res. 323, 132137 (1984).
Kelso, S.R.. Ganong, A.H. and Brown, T.H. Hebbian synapses in hippocampus. Proc.
Natl. Acad. Sci. USA 83, 5326-5330 (1986).
Kohonen. T. Self-Organization and Associative Memory. (Springer-Verlag. Heidelberg,
1984).
Larson. J. and Lynch. G. Synaptic potentiation in hippocampus by patterned stimulation
involves two events. Science 232, 985-988 (1986).
Levy. W.B. and Steward, O. Synapses as associative memory elements in the hippocampal formation. Brain Res. 175,233-245 (1979).
Levy. W.B. and Steward, O. Temporal contiguity requirements for long-term associative
potentiation/depression in the hippocampus. Neuroscience 8, 791-797 (1983).
Lynch. G.S., Dunwiddie. T. and Gribkoff. V. Heterosynaptic depression: a postsynaptic
correlate oflong-term potentiation. Nature (Lond.) 266. 737-739 (1977).
Malinow. R. and Miller, J.P. Postsynaptic hyperpolarization during conditioning reversibly blocks induction of long-term potentiation Nature (Lond.)32.0. 529-530 (1986).
Mody. I.. Stanton. PK. and Heinemann. U. Activation of N-methyl-D-aspartate
(NMDA) receptors parallels changes in cellular and synaptic properties of dentate
gyrus granule cells after kindling. J. Neurophysiol. 59. 1033-1054 (1988).
Reiter, H.O. and Stryker, M.P. Neural plasticity without postsynaptic action potentials:
Less-active inputs become dominant when kitten visual cortical cells are pharmacologically inhibited. Proc. Natl. Acad. Sci. USA 85, 3623-3627 (1988).
Sejnowski, T J. and Tesauro, G. Building network learning algorithms from Hebbian
synapses, in: Brain Organization and Memory JL. McGaugh, N.M. Weinberger, and
G. Lynch, Eds. (Oxford Univ. Press, New York, in press).
Sejnowski, TJ. Storing covariance with nonlinearly interacting neurons. J. Math. Biology 4, 303-321 (1977).
Sejnowski, T. J. Statistical constraints on synaptic plasticity. J. Theor. Biology 69, 385389 (1977).
Stanton, P.K. and Sejnowski, TJ. Associative long-term depression in the hippocampus:
Evidence for anti-Hebbian synaptic plasticity. Nature (Lond.), in review.
Wigstrom, H. and Gustafsson, B. A possible correlate of the postsynaptic condition for
long-lasting potentiation in the guinea pig hippocampus in vitro. Neurosci. Lett. 44,
327?332 (1984).

401


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4871-correlations-strike-back-again-the-case-of-associative-memory-retrieval.pdf

Correlations strike back (again): the case of
associative memory retrieval

Cristina Savin1
cs664@cam.ac.uk

Peter Dayan2
dayan@gatsby.ucl.ac.uk

M?at?e Lengyel1
m.lengyel@eng.cam.ac.uk
1

Computational & Biological Learning Lab, Dept. Engineering, University of Cambridge, UK
2
Gatsby Computational Neuroscience Unit, University College London, UK

Abstract
It has long been recognised that statistical dependencies in neuronal activity need
to be taken into account when decoding stimuli encoded in a neural population.
Less studied, though equally pernicious, is the need to take account of dependencies between synaptic weights when decoding patterns previously encoded in an
auto-associative memory. We show that activity-dependent learning generically
produces such correlations, and failing to take them into account in the dynamics
of memory retrieval leads to catastrophically poor recall. We derive optimal network dynamics for recall in the face of synaptic correlations caused by a range of
synaptic plasticity rules. These dynamics involve well-studied circuit motifs, such
as forms of feedback inhibition and experimentally observed dendritic nonlinearities. We therefore show how addressing the problem of synaptic correlations leads
to a novel functional account of key biophysical features of the neural substrate.

1

Introduction

Auto-associative memories have a venerable history in computational neuroscience. However, it is
only rather recently that the statistical revolution in the wider field has provided theoretical traction
for this problem [1]. The idea is to see memory storage as a form of lossy compression ? information
on the item being stored is mapped into a set of synaptic changes ? with the neural dynamics during
retrieval representing a biological analog of a corresponding decompression algorithm. This implies
there should be a tight, and indeed testable, link between the learning rule used for encoding and the
neural dynamics used for retrieval [2].
One issue that has been either ignored or trivialized in these treatments of recall is correlations
among the synapses [1?4] ? beyond the perfect (anti-)correlations emerging between reciprocal
synapses with precisely (anti-)symmetric learning rules [5]. There is ample experimental data for
the existence of such correlations: for example, in rat visual cortex, synaptic connections tend to
cluster together in the form of overrepresented patterns, or motifs, with reciprocal connections being
much more common than expected by chance, and the strengths of the connections to and from
each neuron being correlated [6]. The study of neural coding has indicated that it is essential to
treat correlations in neural activity appropriately in order to extract stimulus information well [7?
9]. Similarly, it becomes pressing to examine the nature of correlations among synaptic weights in
auto-associative memories, the consequences for retrieval of ignoring them, and methods by which
they might be accommodated.
1

Here, we consider several well-known learning rules, from simple additive ones to bounded synapses
with metaplasticity, and show that, with a few significant exceptions, they induce correlations between synapses that share a pre- or a post-synaptic partner. To assess the importance of these dependencies for recall, we adopt the strategy of comparing the performance of decoders which either
do or do not take them into account [10], showing that they do indeed have an important effect on
efficient retrieval. Finally, we show that approximately optimal retrieval involves particular forms
of nonlinear interactions between different neuronal inputs, as observed experimentally [11].

2

General problem formulation

We consider a network of N binary neurons that enjoy all-to-all connectivity.1 As is conventional,
and indeed plausibly underpinned by neuromodulatory interactions [12], we assume that network
dynamics do not play a role during storage (with stimuli being imposed as patterns of activity on the
neurons), and that learning does not occur during retrieval.
To isolate the effects of different plasticity rules on synaptic correlations from other sources of
correlations, we assume that the patterns of activity inducing the synaptic changes have no particular
structure, i.e. their distribution factorizes. For further simplicity, we take these activity patterns to
be binary with pattern density f , i.e. a prior over patterns defined as:
Y
Pstore (x) =
Pstore (xi )
Pstore (xi ) = f xi ? (1 ? f )1?xi
(1)
i

During recall, the network is presented with a cue, x
?, which is a noisy or partial version of one
of the originally stored patterns. Network dynamics should complete this partial pattern, using the
information in the weights W (and the cue). We start by considering arbitrary dynamics; later we
impose the critical constraint for biological realisability that they be strictly local, i.e. the activity of
neuron i should depend exclusively on inputs through incoming synapses Wi,? .
Since information storage by synaptic plasticity is lossy, recall is inherently a probabilistic inference
problem [1, 13] (Fig. 1a), requiring estimation of the posterior over patterns, given the information
in the weights and the recall cue:
? ) ? Pstore (x) ? Pnoise (?
P (x|W, x
x|x) ? P(W|x)

(2)

This formulation has formed the foundation of recent work on constructing efficient autoassociative
recall dynamics for a range of different learning rules [2?4]. In this paper, we focus on the last term
P(W|x), which expresses the probability of obtaining W as the synaptic weight matrix when x is
stored along with T ? 1 random patterns (sampled from the prior, Eq. 1). Critically, this is where
we diverge from previous analyses that assumed this distribution was factorised, or only trivially
correlated due to reciprocal synapses being precisely (anti-)symmetric [1, 2, 4]. In contrast, we
explicitly study the emergence and effects of non-trivial correlations in the synaptic weight matrixdistribtion, because almost all synaptic plasticity rules induce statistical dependencies between the
synaptic weights of each neuron (Fig. 1a, d).
The inference problem expressed by Eq. 2 can be translated into neural dynamics in several ways
? dynamics could be deterministic, attractor-like, converging to the most likely pattern (a MAP
estimate) of the distribution of x [2], or to a mean-field approximate solution [3]; alternatively, the
dynamics could be stochastic, with the activity over time representing samples from the posterior,
and hence implicitly capturing the uncertainty associated with the answer [4]. We consider the latter.
Since we estimate performance by average errors, the optimal response is the mean of the posterior,
which can be estimated by integrating the activity of the network during retrieval.
We start by analysing the class of additive learning rules, to get a sense for the effect of correlations on retrieval. Later, we focus on multi-state synapses, for which learning rules are described
by transition probabilities between the states [14]. These have been used to capture a variety of
important biological constraints such as bounds on synaptic strengths and metaplasticity, i.e. the
fact that synaptic changes induced by a certain activity pattern depend on the history of activity at
the synapse [15]. The two classes of learning rule are radically different; so if synaptic correlations
matter during retrieval in both cases, then the conclusion likely applies in general.
1
Complete connectivity simplifies the computation of the parameters for the optimal dynamics for cascadelike learning rules considered in the following, but is not necessary for the theory.

2

1

covariance rule
simple Hebb rule
cortical data (Song 2005)

0.5
0

d

e
error (%)

1

corr

c

error (%)

b
corr

a

0.5
0

10 control
exact (considering correlations)
simple (ignoring correlations)

5
0

25

30

50

100

50

100

N

20
10 control
0

25

N

Figure 1: Memory recall as inference and additive learning rules. a. Top: Synaptic weights,
W, arise by storing the target pattern x together with T ?1 other patterns, {x(t) }t=1...T?1 . During
? , is a noisy version of the target pattern. The task of recall is to infer x given W
recall, the cue, x
and x
? (by marginalising out {x(t) }). Bottom: The activity of neuron i across the stored patterns is
a source of shared variability between synapses connecting it to neurons j and k. b-c. Covariance
rule: patterns of synaptic correlations and recall performance for retrieval dynamics ignoring or
considering synaptic correlations; T = 5. d-e. Same for the simple Hebbian learning rule. The
control is an optimal decoder that ignores W.

3

Additive learning rules

Local additive learning rules assume that synaptic changes induced by different activity patterns
combine additively; such that storing a sequence of T patterns from Pstore (x), results in weights
P
(t)
(t)
Wij = t ?(xi , xj ), with function ?(xi , xj ) describing the change in synaptic strength induced
by presynaptic activity xj and postsynaptic activity xi . We consider a generalized Hebbian form for
this function, with ? (xi , xj ) = (xi ? ?)(xj ? ?). This class includes, for example, the covariance
rule (? = ? = f ), classically used in Hopfield networks, or simple Hebbian learning (? = ? = 0).
As synaptic changes are deterministic, the only source of uncertainty in the distribution P(W|x)
is the identity of the other stored patterns. To estimate this, let us first consider the distribution of
the weights after storing one random pattern from Pstore (x). The mean ? and covariance C of the
weight change induced by this event can be computed as:2
Z
Z

? = Pstore (x)?| (x)dx,
C = Pstore (x) ?| (x) ? ?| (x)T dx ? ? ? ?T
(3)
Since the rule is additive and the patterns are independent, the mean and covariance scale linearly
with the number of intervening patterns. Hence, the distribution over possible weight values at
recall, given that pattern x is stored along with T ? 1 other, random, patterns has mean ?W =
?(x) + (T ? 1) ? ?, and covariance CW = (T ? 1) ? C. Most importantly, because the rule is
additive, in the limit of many stored patterns (and in practice even for modest values of T ), the
distribution P(W|x) approaches a multivariate Gaussian that is characterized completely by these
two quantities; moreover, its covariance is independent of x.
For retrieval dynamics based on Gibbs sampling, the key quantity is the log-odds ratio


P(xi = 1|x?i , W, x
?)
(4)
Ii = log
P(xi = 0|x?i , W, x
?)
for neuron i, which could be represented by the total current entering the unit. This would translate
into a probability of firing given by the sigmoid activation function f (Ii ) = 1/(1 + e?Ii ).
The total current entering a neuron is a sum of two terms: one term from the external input of the
form c1 ? x
?i + c2 (with constants c1 and c2 determined by parameters f and r [16]), and one term
from the recurrent input, of the form:

T
 
T



1
(0)
(0)
(1)
(1)
Iirec =
(5)
W| ? ?W
C?1 W| ? ?W ? W| ? ?W
C?1 W| ? ?W
2(T ?1)
2
For notational convenience, we use a column-vector form of the matrix of weight changes ?, and the
weight matrix W, marked by subscript | .

3

(0/1)

where ?W = ?| (x(0/1) )+(T?1)? and x(0/1) is the vector of activities obtained from x in which
the activity of neuron i is set to 0, or 1, respectively.
It is easy to see that for the covariance rule, ? (xi , xj ) = (xi ? f )(xj ? f ), synapses sharing
a single pre- or post-synaptic partner happen to be uncorrelated (Fig. 1b). Moreover, as for any
(anti-)symmetric additive learning rule, reciprocal connections are perfectly correlated (Wij = Wji ).
The (non-degenerate part of the) covariance matrix in this case becomes diagonal, and the total
current in optimal retrieval reduces to simple linear dynamics :
Ii =

1
2
(T ? 1) ?W

X

Wij xj ?

j

|

{z

}

recurrent input


X
(1 ? 2f )2 X
1 ? 2f
Wij ? f 2
xj ? f
2
2
j
j
| {z }
{z
}
| {z }
|
feedback inhibition

homeostatic term

(6)

constant

2
where ?W
is the variance of a synaptic weight resulting from storing a single pattern. This term
includes a contribution from recurrent excitatory input, dynamic feedback inhibition (proportional
to the total population activity) and a homeostatic term that reduces neuronal excitability as function
of the net strength of its synapses (a proxy for average current the neuron expects to receive) [17].
Reassuringly, the optimal decoder for the covariance rule recovers a form for the input current that is
closely related to classic Hopfield-like [5] dynamics (with external field [1, 18]): feedback inhibition
is needed only when the stored patterns are not balanced (f 6= 0.5); for the balanced case, the
homeostatic term can be integrated in the recurrent current, by rewriting neural activities as spins.
In sum, for the covariance rule, synapses are fortuitously uncorrelated (except for symmetric pairs
which are perfectly correlated), and thus simple, classical linear recall dynamics suffice (Fig. 1c).

The covariance rule is, however, the exception rather than the rule. For example, for simple Hebbian
learning, ? (xi , xj ) = xi ?xj , synapses sharing a pre- or post-synaptic partner are correlated (Fig. 1d)
and so the covariance matrix C is no longer diagonal. Interestingly, the final expression of the
recurrent current to a neuron remains strictly local (because of additivity and symmetry), and very
similar to Eq. 6, but feedback inhibition becomes a non-linear function of the total activity in the
network [16]. In this case, synaptic correlations have a dramatic effect: using the optimal non-linear
dynamics ensures high performance, but trying to retrieve information using a decoder that assumes
synaptic independence (and thus uses linear dynamics) yields extremely poor performance, which
is even worse than the obvious control of relying only on the information in the recall cue and the
prior over patterns (Fig. 1e).
For the generalized Hebbian case, ? (xi , xj ) = (xi ??)(xj ??) with ? 6= ?, the optimal decoder becomes even more complex, with the total current including additional terms accounting for pairwise
correlations between any two synapses that have neuron i as a pre- or post-synaptic partner [16].
Hence, retrieval is no longer strictly local3 and a biological implementation will require approximating the contribution of non-local terms as a function of locally available information, as we discuss
in detail for palimpsest learning below.

4

Palimpsest learning rules

Though additive learning rules are attractive for their analytical tractability, they ignore several important aspects of synaptic plasticity, e.g. they assume that synapses can grow without bound. We
investigate the effects of bounded weights by considering another class of learning rules, which assumes synaptic efficacies can only take binary values, with stochastic transitions between the two
underpinned by paired cascades of latent internal states [14] (Fig. 2). These learning rules, though
very simple, capture an important aspect of memory ? the fact that memory is leaky, and information
about the past is overwritten by newly stored items (usually referred to as the palimpsest property).
Additionally, such rules can account for experimentally observed synaptic metaplasticity [15].
3
For additive learning rules, the current to neuron i always depends only on synapses local to a neuron, but
these can also include outgoing synapses of which the weight, W?i , should not influence its dynamics. We refer
to such dynamics as ?semi-local?. For other learning rules, the optimal current to neuron i may depend on all
connections in the network, including Wjk with j, k 6= i (?non-local? dynamics).

4

R1

D P

post

R2

R3

c

- -

0
1

D
P

P D
D P
0 1
pre

0.4

cortex data (Song 2005)

d

correlated synapses

20
10

0.2
0

0

0.4

20

error (%)

b

correlation coefficient

a

0.2
0
0.6

pseudostorage

10
0
20

0.3

*

10

0

exact approx

0

simple
dynamics

*

corr-dependent
dynamics

Figure 2: Palimpsest learning. a. The cascade model. Colored circles are latent states (V ) that
belong to two different synaptic weights (W ), arrows are state transitions (blue: depression, red:
potentiation) b. Different variants of mapping pre- and post-synaptic activations to depression (D)
and potentiation (P): R1?postsynaptically gated, R2?presynaptically gated, R3?XOR rule. c. Correlation structure induced by these learning rules. c. Retrieval performance for each rule.
Learning rule
Learning is stochastic and local, with changes in the state of a synapse Vij being determined only by
the activation of the pre- and post-synaptic neurons, xj and xi . In general, one could define separate
transition matrices for each activity pattern, M(xi , xj ), describing the probability of a synaptic state
transitioning between any two states Vij to Vij0 following an activity pattern, (xi , xj ). For simplicity,
we define only two such matrices, for potentiation, M+ , and depression, M? , respectively, and then
map different activity patterns to these events. In particular, we assume Fusi?s cascade model [14]4
and three possible mappings (Fig. 2b [16]): 1) a postsynaptically gated learning rule, where changes
occur only when the postsynaptic neuron is active, with co-activation of pre- and post- neuron leading to potentiation, and to depression otherwise5 ; 2) a presynaptically gated learning rule, typically
assumed when analysing cascades[20, 21]; and 3) an XOR-like learning rule which assumes potentiation occurs whenever the pre- and post- synaptic activity levels are the same, with depression
otherwise. The last rule, proposed by Ref. 22, was specifically designed to eliminate correlations
between synapses, and can be viewed as a version of the classic covariance rule fashioned for binary
synapses.
Estimating the mean and covariance of synaptic weights
At the level of a single synapse, the presentation of a sequence of uncorrelated patterns from
Pstore (x) corresponds to a Markov random walk, P
defined by a transition matrix M, which averages over possible neural activity patterns: M = xi ,xj Pstore (xi ) ? Pstore (xj ) ? M(xi , xj ). The
distribution over synaptic states t steps after the initial encoding can be calculated by starting from
the stationary distribution of the weights ? V 0 (assuming a large number of other patterns have previously been stored; formally, this is the eigenvector of M corresponding to eigenvalue ? = 1), then
storing the pattern (xi , xj ), and finally t ? 1 other patterns from the prior:
t?1

? V (xi , xj , t) = M

? M(xi , xj ) ? ? V 0 ,

(7)

?lV

with the distribution over states given as a column vector,
= P(Vij = l|xi , xj ), l ? {1 . . . 2n},
where n is the depth of the cascade. Lastly, the distribution over weights, P(Wij |xi , xj ), can be
derived as ? W = MV ?W ? ? V , where MV ?W is a deterministic map from states to observed
weights (Fig. 2a).
As in the additive case, the states of synapses sharing a pre- or post- synaptic partner will be correlated (Figs. 1a, 2c). The degree of correlations for different synaptic configurations can be estimated
by generalising the above procedure to computing the joint distribution of the states of pairs of
synapses, which we represent as a matrix ?. E.g. for a pair of synapses sharing a postsynaptic
partner (Figs. 1b, d, and 2c), element (u, v) is ?uv = P(Vpost,pre1 = u, Vpost,pre2 = v). Hence, the
presentation of an activity pattern (xpre1 , xpre2 , xpost ) induces changes in the corresponding pair of
4

Other models, e.g. serial [19], could be used as well without qualitatively affecting the results.
One could argue that this is the most biologically relevant as plasticity is often NMDA-receptor dependent,
and hence it requires postsynaptic depolarisation for any effect to occur.
5

5

incoming synapses to neuron post as ?(1) = M(xpost , xpre1 ) ? ?(0) ? M(xpost , xpre2 )T , where ?(0)
is the stationary distribution corresponding to storing an infinite number of triplets from the pattern
distribution [16].
Replacing ? V with ? (which is now a function of the triplet (xpre1 , xpre2 , xpost )), and the multiplication by M with the slightly more complicated operator above, we can estimate the evolution of
the joint distribution over synaptic states in a manner very similar to Eq. 7:
X
? i ) ? ?(t?1) ? M(x
? i )T ,
Pstore (xi ) ? M(x
(8)
?(t) =
xi
P
? i) =
where M(x
xj Pstore (xj )M(xi , xj ). Also as above, the final joint distribution over states
can be mapped into a joint distribution over synaptic weights as MV ?W ? ?(t) ? MT
V ?W . This
approach can be naturally extended to all other correlated pairs of synapses [16].
The structure of correlations for different synaptic pairs varies significantly as a function of the
learning rule (Fig. 2c), with the overall degree of correlations depending on a range of factors.
Correlations tend to decrease with cascade depth and pattern sparsity. The first two variants of the
learning rule considered are not symmetric, and so induce different patterns of correlations than the
additive rules above. The XOR rule is similar to the covariance rule, but the reciprocal connections
are no longer perfectly correlated (due to metaplasticity), which means that it is no longer possible
to factorize P(W|x). Hence, assuming independence at decoding seems bound to introduce errors.
Approximately optimal retrieval when synapses are independent
If we ignore synaptic correlations, the evidence from the weights factorizes, P(W|x) =
Q
3
i,j P(Wij |xi , xj ), and so the exact dynamics would be semi-local . We can further approximate
the contribution of the outgoing weights by its mean, which recovers the same simple dynamics
derived for the additive case:


X
X
X
P(xi = 1|x?i , W, x
?)
Ii = log
= c1
Wij xj + c2
Wij + c3
xj + c4 x?i + c5 (9)
j
j
j
P(xi = 0|x?i , W, x
?)
The parameters c. depend on the prior over x, the noise model, the parameters of the learning rule
and t. Again, the optimal decoder is similar to previously derived attractor dynamics; in particular,
for stochastic binary synapses with presynaptically gated learning the optimal dynamics require
dynamic inhibition only for sparse patterns, and no homeostatic term, as used in [21] .
To validate these dynamics, we remove synaptic correlations by a pseudo-storage procedure in which
synapses are allowed to evolve independently according to transition matrix M, rather than changing
as actual intermediate patterns are stored. The dynamics work well in this case, as expected (Fig. 2d,
blue bars). However, when storing actual patterns drawn from the prior, performance becomes extremely poor, and often worse than the control (Fig. 2d, gray bars). Moreover, performance worsens
as the network size increases (not shown). Hence, ignoring correlations is highly detrimental for this
class of learning rules too.
Approximately optimal retrieval when synapses are correlated
To accommodate synaptic correlations, we approximate P(W|x) with a maximum entropy distribution with the same marginals and covariance structure, ignoring the higher order moments.6
Specifically, we assume the evidence from the weights has the functional form:
X

1X
1
exp
kij (x, t) ? Wij +
J(ij)(kl) (x, t) ? Wij Wkl
(10)
P(W|x, t) =
ij
ijkl
Z(x, t)
2
We use the TAP mean-field method [23] to find parameters k and J and the partition function, Z,
for each possible activity pattern x, given the mean and covariance for the synaptic weights matrix,
computed above7 [16].
6
This is just a generalisation of the simple dynamics which assume a first order max entropy model; moreover, the resulting weight distribution is a binary analog of the multivariate normal used in the additive case,
allowing the two to be directly compared.
7
Here, we ask whether it is possible to accommodate correlations in appropriate neural dynamics at all,
ignoring the issue of how the optimal values for the parameters of the network dynamics would come about.

6

a

b

no corr
corr

5

0.05

0.5

0.01

0
0

0

0

?5
?10

?0.05

d

12

6

0
?2

0

2

4

6

8

10

number of coactive inputs

12

10

20

0

10

0

10

20

e

10
5
0
?5
?10

?0.01

20

0

2

4

6

8

10

12

number of coactive inputs

normalized EPSP

0

TIP

20

MIDDLE

10

postsynaptic current

c

postsynaptic current

0

BASE

?0.5

1.0
0.8
0.6
0.4
0.2
0.0

0

1

2 3 4 5 6
number of inputs

7

Figure 3: Implications for neural dynamics. a. R1: parameters for Iirec ; linear modulation by
network activity, nb . b. R2: nonlinear modulation of pairwise term by network activity (cf. middle
panel in a); other parameters have
P linear dependences on nb . c. R1: Total current as
Pfunction of
number of coactivated inputs, j Wij xj ; lines: different levels of neural excitability j Wij , line
widths scale with frequency of occurrence in a sample run. d. Same for R2. e. Nonlinear integration
in dendrites, reproduced from [11], cf. curves in c.
Exact retrieval dynamics based on Eq. 10, but not respecting locality constraints, work substantially
better in the presence of synaptic correlations, for all rules (Fig. 2d, yellow bars). It is important to
note that for the XOR rule, which was supposed to be the closest analog to the covariance rule and
hence afford simple recall dynamics [22], error rates stay above control, suggesting that it is actually
a case in which even dependencies beyond 2nd-order correlation would need to be considered.
As in the additive case, exact recall dynamics are biologically implausible, as the total current to
the neuron depends on the full weight matrix. It is possible to approximate the dynamics using
strictly local information by replacing the nonlocal term by its mean, which, however,
is no longer a
P
constant, but rather a linear function of the total activity in the network, nb = j6=i xj [16]. Under
this approximation, the current from recurrent connections corresponding to the evidence from the
weights becomes:
 X

P(W|x(1) )
1X
4
J4
=
k
(x)Wij Wik ? Z 4
(11)
(x)W
+
Iirec = log
ij
ij
jk (ij)(ik)
j
2
P(W|x(0) )
where i is the index of the neuron to be updated, and x(0/1) activity vector has the to-be-updated
neuron?s activity set to 1 or 0, respectively, and all other components given by the
 current network

4
4
state. The functions kij
(x) = kij (x(1) )?kij (x(0) ), J(ij)(kl)
(x) = J(ij)(kl) x(1) ?J(ij)(kl) x(0) ,


and Z 4 = log Z x(1) ? log Z x(0) depend on the local activity at the indexed synapses,
modulated by the number of active neurons in the network, nb . This approximation is again consistent with our previous analysis, i.e. in the absence of synaptic correlations, the complex dynamics
recover the simple case presented before. Importantly, this approximation also does about as well as
exact dynamics (Fig. 2d, red bars).
For post-synaptically gated learning, comparing the parameters of the dynamics in the case of independent versus correlated synapses (Fig. 3a) reveals a modest modulation of the recurrent input by
the total activity. More importantly, the net current to the postsynaptic P
neuron depends non-linearly
(formally, quadratically) on the number of co-active inputs, nW 1 = j xj Wij , (Fig. 3c), which
is reminiscent of experimentally observed dendritic non-linearities [11] (Fig. 3e). Conversely, for
the presynaptically gated learning rule, approximately optimal dynamics predict a non-monotonic
modulation of activity by lateral inhibition (Fig. 3b), but linear neural integration (Fig. 3d).8 Lastly,
retrieval based on the XOR rule has the same form as the simple dynamics derived for the factorized
case [16]. However, the total current has to be rescaled to compensate for the correlations introduced
by reciprocal connections.
8
The difference between the two rules emerges exclusively because of the constraint of strict locality of the
approximation, since the exact form of the dynamics is essentially the same for the two.

7

additive
cascade

RULE
covariance
simple Hebbian
generalized Hebbian
presyn. gated
postsyn. gated
XOR

EXACT DYNAMICS
strictly local, linear
strictly local, nonlinear
semi-local, nonlinear
nonlocal, nonlinear
nonlocal, nonlinear
beyond correlations

NEURAL IMPLEMENTATION
linear feedback inh., homeostasis
nonlinear feedback inh.
nonlinear feedback inh.
nonlinear feedback inh., linear dendritic integr.
linear feedback inh., non-linear dendritic integr.
?

Table 1: Results summary: circuit adaptations against correlations for different learning rules.

5

Discussion

Statistical dependencies between synaptic efficacies are a natural consequence of activity dependent
synaptic plasticity, and yet their implications for network function have been unexplored. Here, in
the context of an auto-associative memory network, we investigated the patterns of synaptic correlations induced by several well-known learning rules and their consequent effects on retrieval. We
showed that most rules considered do indeed induce synaptic correlations and that failing to take
them into account greatly damages recall. One fortuitous exception is the covariance rule, for which
there are no synaptic correlations. This might explain why the bulk of classical treatments of autoassociative memories, using the covariance rule, could achieve satisfying capacity levels despite
overlooking the issue of synaptic correlations [5, 24, 25].
In general, taking correlations into account optimally during recall requires dynamics in which there
are non-local interactions between neurons. However, we derived approximations that perform well
and are biologically realisable without such non-locality (Table 1). Examples include the modulation of neural responses by the total activity of the population, which could be mediated by feedback
inhibition, and specific dendritic nonlinearities. In particular, for the post-synaptically gated learning rule, which may be viewed as an abstract model of hippocampal NMDA receptor-dependent
plasticity, our model predicts a form of non-linear mapping of recurrent inputs into postsynaptic
currents which is similar to experimentally observed dendritic integration in cortical pyramidal cells
[11]. In general, the tight coupling between the synaptic plasticity used for encoding (manifested
in patterns of synaptic correlations) and circuit dynamics offers an important route for experimental
validation [2].
None of the rules governing synaptic plasticity that we considered perfectly reproduced the pattern
of correlations in [6]; and indeed, exactly which rule applies in what region of the brain under which
neuromodulatory influences is unclear. Furthermore, results in [6] concern the neocortex rather
than the hippocampus, which is a more common target for models of auto-associative memory.
Nonetheless, our analysis has shown that synaptic correlations matter for a range of very different
learning rules that span the spectrum of empirical observations.
Another strategy to handle the negative effects of synaptic correlations is to weaken or eliminate
them. For instance, in the palimpsest synaptic model [14], the deeper the cascade, the weaker the
correlations, and so metaplasticity may have the beneficial effect of making recall easier. Another,
popular, idea is to use very sparse patterns [21], although this reduces the information content of
each one. More speculatively, one might imagine a process of off-line synaptic pruning or recoding,
in which strong correlations are removed or the weights adjusted so that simple recall methods will
work.
Here, we focused on second-order correlations. However, for plasticity rules such as XOR, we
showed that this does not suffice. Rather, higher-order correlations would need to be considered,
and thus, presumably higher-order interactions between neurons approximated. Finally, we know
from work on neural coding of sensory stimuli that there are regimes in which correlations either
help or hurt the informational quality of the code, assuming that decoding takes them into account.
Given our results, it becomes important to look at the relative quality of different plasticity rules,
assuming realizable decoding ? it is not clear whether rules that strive to eliminate correlations will
be bested by ones that do not.
Acknowledgments This work was supported by the Wellcome Trust (CS, ML), the Gatsby Charitable Foundation (PD), and the European Union Seventh Framework Programme (FP7/2007?2013)
under grant agreement no. 269921 (BrainScaleS) (ML).
8

References
1. Sommer, F.T. & Dayan, P. Bayesian retrieval in associative memories with storage errors. IEEE transactions on neural networks 9, 705?713 (1998).
2. Lengyel, M., Kwag, J., Paulsen, O. & Dayan, P. Matching storage and recall: hippocampal spike timingdependent plasticity and phase response curves. Nature Neuroscience 8, 1677?1683 (2005).
3. Lengyel, M. & Dayan, P. Uncertainty, phase and oscillatory hippocampal recall. Advances in Neural
Information Processing (2007).
4. Savin, C., Dayan, P. & Lengyel, M. Two is better than one: distinct roles for familiarity and recollection in
retrieving palimpsest memories. in Advances in Neural Information Processing Systems, 24 (MIT Press,
Cambridge, MA, 2011).
5. Hopfield, J.J. Neural networks and physical systems with emergent collective computational abilities.
Proc. Natl. Acad. Sci. USA 76, 2554?2558 (1982).
6. Song, S., Sj?ostr?om, P.J., Reigl, M., Nelson, S. & Chklovskii, D.B. Highly nonrandom features of synaptic
connectivity in local cortical circuits. PLoS biology 3, e68 (2005).
7. Dayan, P. & Abbott, L. Theoretical Neuroscience (MIT Press, 2001).
8. Averbeck, B.B., Latham, P.E. & Pouget, A. Neural correlations, population coding and computation.
Nature Reviews Neuroscience 7, 358?366 (2006).
9. Pillow, J.W. et al. Spatio-temporal correlations and visual signalling in a complete neuronal population.
Nature 454, 995?999 (2008).
10. Latham, P.E. & Nirenberg, S. Synergy, redundancy, and independence in population codes, revisited.
Journal of Neuroscience 25, 5195?5206 (2005).
11. Branco, T. & H?ausser, M. Synaptic integration gradients in single cortical pyramidal cell dendrites. Neuron
69, 885?892 (2011).
12. Hasselmo, M.E. & Bower, J.M. Acetylcholine and memory. Trends Neurosci. 16, 218?222 (1993).
13. MacKay, D.J.C. Maximum entropy connections: neural networks. in Maximum Entropy and Bayesian
Methods, Laramie, 1990 (eds. Grandy, Jr, W.T. & Schick, L.H.) 237?244 (Kluwer, Dordrecht, The Netherlands, 1991).
14. Fusi, S., Drew, P.J. & Abbott, L.F. Cascade models of synaptically stored memories. Neuron 45, 599?611
(2005).
15. Abraham, W.C. Metaplasticity: tuning synapses and networks for plasticity. Nature Reviews Neuroscience
9, 387 (2008).
16. For details, see Supplementary Information.
17. Zhang, W. & Linden, D. The other side of the engram: experience-driven changes in neuronal intrinsic
excitability. Nature Reviews Neuroscience (2003).
18. Engel, A., Englisch, H. & Sch?utte, A. Improved retrieval in neural networks with external fields. Europhysics Letters (EPL) 8, 393?397 (1989).
19. Leibold, C. & Kempter, R. Sparseness constrains the prolongation of memory lifetime via synaptic metaplasticity. Cerebral cortex (New York, N.Y. : 1991) 18, 67?77 (2008).
20. Amit, Y. & Huang, Y. Precise capacity analysis in binary networks with multiple coding level inputs.
Neural computation 22, 660?688 (2010).
21. Huang, Y. & Amit, Y. Capacity analysis in multi-state synaptic models: a retrieval probability perspective.
Journal of computational neuroscience (2011).
22. Dayan Rubin, B. & Fusi, S. Long memory lifetimes require complex synapses and limited sparseness.
Frontiers in Computational Neuroscience (2007).
23. Thouless, D.J., Anderson, P.W. & Palmer, R.G. Solution of ?Solvable model of a spin glass?. Philosophical
Magazine 35, 593?601 (1977).
24. Amit, D., Gutfreund, H. & Sompolinsky, H. Storing infinite numbers of patterns in a spin-glass model of
neural networks. Phys Rev Lett 55, 1530?1533 (1985).
25. Treves, A. & Rolls, E.T. What determines the capacity of autoassociative memories in the brain? Network
2, 371?397 (1991).

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4872-a-memory-frontier-for-complex-synapses.pdf

A memory frontier for complex synapses

Subhaneil Lahiri and Surya Ganguli
Department of Applied Physics, Stanford University, Stanford CA
sulahiri@stanford.edu, sganguli@stanford.edu

Abstract
An incredible gulf separates theoretical models of synapses, often described solely
by a single scalar value denoting the size of a postsynaptic potential, from the
immense complexity of molecular signaling pathways underlying real synapses.
To understand the functional contribution of such molecular complexity to learning and memory, it is essential to expand our theoretical conception of a synapse
from a single scalar to an entire dynamical system with many internal molecular
functional states. Moreover, theoretical considerations alone demand such an expansion; network models with scalar synapses assuming finite numbers of distinguishable synaptic strengths have strikingly limited memory capacity. This raises
the fundamental question, how does synaptic complexity give rise to memory? To
address this, we develop new mathematical theorems elucidating the relationship
between the structural organization and memory properties of complex synapses
that are themselves molecular networks. Moreover, in proving such theorems, we
uncover a framework, based on first passage time theory, to impose an order on
the internal states of complex synaptic models, thereby simplifying the relationship between synaptic structure and function.

1

Introduction

It is widely thought that our very ability to remember the past over long time scales depends crucially
on our ability to modify synapses in our brain in an experience dependent manner. Classical models
of synaptic plasticity model synaptic efficacy as an analog scalar value, denoting the size of a postsynaptic potential injected into one neuron from another. Theoretical work has shown that such
models have a reasonable, extensive memory capacity, in which the number of long term associations
that can be stored by a neuron is proportional its number of afferent synapses [1?3]. However,
recent experimental work has shown that many synapses are more digital than analog; they cannot
robustly assume an infinite continuum of analog values, but rather can only take on a finite number
of distinguishable strengths, a number than can be as small as two [4?6] (though see [7]). This
one simple modification leads to a catastrophe in memory capacity: classical models with digital
synapses, when operating in a palimpset mode in which the ongoing storage of new memories can
overwrite previous memories, have a memory capacity proportional to the logarithm of the number
of synapses [8, 9]. Intuitively, when synapses are digital, the storage of a new memory can flip
a population of synaptic switches, thereby rapidly erasing previous memories stored in the same
synaptic population. This result indicates that the dominant theoretical basis for the storage of long
term memories in modifiable synaptic switches is flawed.
Recent work [10?12] has suggested that a way out of this logarithmic catastrophe is to expand our
theoretical conception of a synapse from a single scalar value to an entire stochastic dynamical system in its own right. This conceptual expansion is further necessitated by the experimental reality
that synapses contain within them immensely complex molecular signaling pathways, with many internal molecular functional states (e.g. see [4, 13, 14]). While externally, synaptic efficacy could be
digital, candidate patterns of electrical activity leading to potentiation or depression could yield transitions between these internal molecular states without necessarily inducing an associated change in
1

synaptic efficacy. This form of synaptic change, known as metaplasticity [15, 16], can allow the
probability of synaptic potentiation or depression to acquire a rich dependence on the history of
prior changes in efficacy, thereby potentially improving memory capacity.
Theoretical studies of complex, metaplastic synapses have focused on analyzing the memory performance of a limited number of very specific molecular dynamical systems, characterized by a
number of internal states in which potentiation and depression each induce a specific set of allowable transitions between states (e.g. see Figure 1 below). While these models can vastly outperform
simple binary synaptic switches, these analyses leave open several deep and important questions.
For example, how does the structure of a synaptic dynamical system determine its memory performance? What are the fundamental limits of memory performance over the space of all possible
synaptic dynamical systems? What is the structural organization of synaptic dynamical systems that
achieve these limits? Moreover, from an experimental perspective, it is unlikely that all synapses
can be described by a single canonical synaptic model; just like the case of neurons, there is an
incredible diversity of molecular networks underlying synapses both across species and across brain
regions within a single organism [17]. In order to elucidate the functional contribution of this diverse molecular complexity to learning and memory, it is essential to move beyond the analysis of
specific models and instead develop a general theory of learning and memory for complex synapses.
Moreover, such a general theory of complex synapses could aid in development of novel artificial
memory storage devices.
Here we initiate such a general theory by proving upper bounds on the memory curve associated with
any synaptic dynamical system, within the well established ideal observer framework of [10, 11, 18].
Along the way we develop principles based on first passage time theory to order the structure of
synaptic dynamical systems and relate this structure to memory performance. We summarize our
main results in the discussion section.

2

Overall framework: synaptic models and their memory curves

In this section, we describe the class of models of synaptic plasticity that we are studying and how
we quantify their memory performance. In the subsequent sections, we will find upper bounds on
this performance.
We use a well established formalism for the study of learning and memory with complex synapses
(see [10, 11, 18]). In this approach, electrical patterns of activity corresponding to candidate potentiating and depressing plasticity events occur randomly and independently at all synapses at a
Poisson rate r. These events reflect possible synaptic changes due to either spontaneous network
activity, or the storage of new memories. We let f pot and f dep denote the fraction of these events that
are candidate potentiating or depressing events respectively. Furthermore, we assume our synaptic
model has M internal molecular functional states, and that a candidate potentiating (depotentiating) event induces a stochastic transition in the internal state described by an M ? M discrete time
Markov transition matrix Mpot (Mdep ). In this framework, the states of different synapses will be
independent, and the entire synaptic population can be fully described by the probability distribution
across these states, which we will indicate with the row-vector p(t). Thus the i?th component of
p(t) denotes the fraction of the synaptic population in state i. Furthermore, each state i has its own
synaptic weight, wi , which we take, in the worst case scenario, to be restricted to two values. After
shifting and scaling these two values, we can assume they are ?1, without loss of generality.
We also employ an ?ideal observer? approach to the memory readout, where the synaptic weights
are read directly. This provides an upper bound on the quality of any readout using neural activity.
For any single memory, stored at time t = 0, we assume there will be an ideal pattern of synaptic
weights across a population of N synapses, the N -element vector w
~ ideal , that is +1 at all synapses
that experience a candidate potentiation event, and ?1 at all synapses that experience a candidate
depression event at the time of memory storage. We assume that any pattern of synaptic weights
close to w
~ ideal is sufficient to recall the memory. However, the actual pattern of synaptic weights at
some later time, t, will change to w(t)
~
due to further modifications from the storage of subsequent
memories. We can use the overlap between these, w
~ ideal ? w(t),
~
as a measure of the quality of the
memory. As t ? ?, the system will return to its steady state distribution which will be uncorrelated
2

Cascade model

(b)

Serial model

(c)

?1

10

SNR

(a)

?2

10

Cascade
Serial

?3

10

?1

10

0

10

1

10
Time

2

10

3

10

Figure 1: Models of complex synapses. (a) The cascade model of [10], showing transitions between
states of high/low synaptic weight (red/blue circles) due to potentiation/depression (solid red/dashed
blue arrows). (b) The serial model of [12]. (c) The memory curves of these two models, showing
the decay of the signal-to-noise ratio (to be defined in ?2) as subsequent memories are stored.
with the memory stored at t = 0. The probability distribution of the quantity w
~ ideal ? w(?)
~
can be
used as a ?null model? for comparison.
The extent to which the memory has been stored is described by a signal-to-noise ratio (SNR)
[10, 11]:
hw
~ ideal ? w(t)i
~
? hw
~ ideal ? w(?)i
~
p
SNR(t) =
.
(1)
Var(w
~ ideal ? w(?))
~
?
The noise in the denominator is essentially N . There is a correction when potentiation and depression are imbalanced, but this will not affect the upper bounds that we will discuss below and
will be ignored in the subsequent formulae.
A simple average memory curve can be derived as follows. All of the preceding plasticity events,
prior to t = 0, will put the population of synapses in its steady-state distribution, p? . The memory we are tracking at t = 0 will change the internal state distribution to p? Mpot (or p? Mdep )
in those synapses that experience a candidate potentiation (or depression) event. As the potentiating/depressing nature of the subsequent memories is independent of w
~ ideal , we can average over all
sequences, resulting in the evolution of the probability distribution:
dp(t)
= rp(t)WF ,
where WF = f pot Mpot + f dep Mdep ? I.
(2)
dt
Here WF is a continuous time transition matrix that models the process of forgetting the memory
stored at time t = 0 due to random candidate potentiation/depression events occurring at each
synapse due to the storage of subsequent memories. Its stationary distribution is p? .
This results in the following SNR
?


F
(3)
SNR(t) = N 2f pot f dep p? Mpot ? Mdep ertW w.
A detailed derivation of this formula can be found in the supplementary material. We will frequently
refer to this function as the memory curve. It can be thought of as the excess fraction of synapses
(relative to equilibrium) that maintain their ideal synaptic strength at time t, as dictated by the stored
memory at time t = 0.
Much of the previous work on these types of complex synaptic models has focused on understanding
the memory curves of specific models, or choices of Mpot/dep . Two examples of these models are
shown in Figure 1. We see that they have different memory properties. The serial model performs
relatively well at one particular timescale, but it performs poorly at other times. The cascade model
does not perform quite as well at that time, but it maintains its performance over a wider range of
timescales.
In this work, rather than analyzing specific models, we take a different approach, in order to obtain
a more general theory. We consider the entire space of these models and find upper bounds on the
memory capacity of any of them. The space of models with a fixed number of internal states M is
parameterized by the pair of M ? M discrete time stochastic transition matrices Mpot and Mdep , in
addition to f pot/dep . The parameters must satisfy the following constraints:
Mpot/dep
? [0, 1],
ij
X

Mpot/dep
ij

= 1,

f pot/dep ? [0, 1],
f pot + f dep = 1,

j

p? WF = 0,
X
p?
i = 1.
i

3

wi = ?1,
(4)

and f pot/dep follow automatically from the other constraints.
The upper bounds on Mpot/dep
ij
The critical question is: what do these constraints imply about the space of achievable memory
curves in (3)? To answer this question, especially for limits on achievable memory at finite times, it
will be useful to employ the eigenmode decomposition:
X
WF =
?qa ua va , va ub = ?ab , WF ua = ?qa ua , va WF = ?qa va .
(5)
a

Here qa are the negative of the eigenvalues of the forgetting process WF , ua are the right (column)
eigenvectors and va are the left (row) eigenvectors. This decomposition allows us to write the
memory curve as a sum of exponentials,
? X
SNR(t) = N
Ia e?rt/?a ,
(6)
a

where Ia = (2f pot f dep )p? (Mpot ? Mdep )ua va w and ?a = 1/qa . We can then ask the question:
what are the constraints on these quantities, namely eigenmode initial SNR?s, Ia , and time constants,
?a , implied by the constraints in (4)? We will derive some of these constraints in the next section.

3

Upper bounds on achievable memory capacity

In the previous section, in (3) we have described an analytic expression for a memory curve as a
function of the structure of a synaptic dynamical system, described by the pair of stochastic transition
matrices Mpot/dep . Since the performance measure for memory is an entire memory curve, and not
just a single number, there is no universal scalar notion of optimal memory in the space of synaptic
dynamical systems. Instead there are tradeoffs between storing proximal and distal memories; often
attempts to increase memory at late (early) times by changing Mpot/dep , incurs a performance loss
in memory at early (late) times in specific models considered so far [10?12]. Thus our end goal,
achieved in ?4, is to derive an envelope memory curve in the SNR-time plane, or a curve that forms
an upper-bound on the entire memory curve of any model. In order to achieve this goal, in this
section, we must first derive upper bounds, over the space of all possible synaptic models, on two
different scalar functions of the memory curve: its initial SNR, and the area under the memory curve.
In the process of upper-bounding the area, we will develop an essential framework to organize the
structure of synaptic dynamical systems based on first passage time theory.
3.1

Bounding initial SNR

We now give an upper bound on the initial SNR,
?


SNR(0) = N 2f pot f dep p? Mpot ? Mdep w,

(7)

over all possible models and also find the class of models that saturate this bound. A useful quantity
is the equilibrium probability flux between two disjoint sets of states, A and B:
XX
F
?AB =
rp?
(8)
i Wij .
i?A j?B

The initial SNR is closely related to the flux from the states with wi = ?1 to those with wj = +1
(see supplementary material):
?
4 N ??+
SNR(0) ?
.
(9)
r
This inequality becomes an equality if potentiation never decreases the synaptic weight and depression never increases it, which should be a property of any sensible model.
To maximize this flux, potentiation from a weak state must be guaranteed to end in a strong state,
and depression must do the reverse. An example of such a model is shown in Figure 2(a,b). These
models have a property known as ?lumpability? (see [19, ?6.3] for the discrete time version and
[20, 21] for continuous time). They are completely equivalent (i.e. have the same memory curve) as
a two state model with transition probabilities equal to 1, as shown in Figure 2(c).
4

(a)

(b)

(c)

1
1

Figure 2: Synaptic models that maximize initial SNR. (a) For potentiation, all transitions starting
from a weak state lead to a strong state, and the probabilities for all transitions leaving a given weak
state sum to 1. (a) Depression is similar to potentiation, but with strong and weak interchanged.
(c) The equivalent two state model, with transition probabilities under potentiation and depression
equal to one.
This two state model has the equilibrium distribution p? = (f dep , f pot ) and its flux is given by
??+ = rf pot f dep . This is maximized when f pot = f dep = 12 , leading to the upper bound:
?
SNR(0) ? N .
(10)
We note that while this model has high initial SNR, it also has very fast memory decay ? with a
timescale ? ? 1r . As the synapse is very plastic, the initial memory is encoded very easily, but
the subsequent memories also overwrite it rapidly. This is one example of the tradeoff between
optimizing memory at early versus late times.
3.2

Imposing order on internal states through first passage times

Our goal of understanding the relationship between structure and function in the space of all possible
synaptic models is complicated by the fact that this space contains many different possible network
topologies, encoded in the nonzero matrix elements of Mpot/dep . To systematically analyze this
entire space, we develop an important organizing principle using the theory of first passage times
in the stochastic process of forgetting, described by WF . The mean first passage time matrix, Tij ,
is defined as the average time it takes to reach state j for the first time, starting from state i. The
diagonal elements are defined to be zero.
A remarkable theorem we will exploit is that the quantity
X
??
Tij p?
j ,

(11)

j

known as Kemeny?s constant (see [19, ?4.4]), is independent of the starting state i. Intuitively, (11)
states that the average time it takes to reach any state, weighted by its equilibrium probability, is
independent of the starting state, implying a hidden constancy inherent in any stochastic process.
In the context of complex synapses, we can define the partial sums
X
X
?i+ =
Tij p?
?i? =
Tij p?
j ,
j .
j?+

(12)

j??

These can be thought of as the average time it takes to reach the strong/weak states respectively.
Using these definitions, we can then impose an order on the states by arranging them in order of
decreasing ?i+ or increasing ?i? . Because ?i+ + ?i? = ? is independent of i, the two orderings are
the same. In this order, which depends sensitively on the structure of Mpot/dep , states later (to the
right in figures below) can be considered to be more potentiated than states earlier (to the left in
figures below), despite the fact that they have the same synaptic efficacy. In essence, in this order, a
state is considered to be more potentiated if the average time it takes to reach all the strong efficacy
states is shorter. We will see that synaptic models that optimize various measures of memory have
an exceedingly simple structure when, and only when, their states are arranged in this order.1
1
Note that we do not need to worry about the order of the ?i? changing during the optimization: necessary
conditions for a maximum only require that there is no infinitesimal perturbation that increases the area. Therefore we need only consider an infinitesimal neighborhood of the model, in which the order will not change.

5

(a)

(b)

(c)

Figure 3: Perturbations that increase the area. (a) Perturbations that increase elements of Mpot
above the diagonal and decrease the corresponding elements of Mdep . It can no longer be used
when Mdep is lower triangular, i.e. depression must move synapses to ?more depressed? states. (b)
Perturbations that decrease elements of Mpot below the diagonal and increase the corresponding
elements of Mdep . It can no longer be used when Mpot is upper triangular, i.e. potentiation must
move synapses to ?more potentiated? states. (c) Perturbation that decreases ?shortcut? transitions
and increases the bypassed ?direct? transitions. It can no longer be used when there are only nearestneighbor ?direct? transitions.
3.3

Bounding area

Now consider the area under the memory curve:
Z ?
A=
dt SNR(t).

(13)

0

We will find an upper bound on this quantity as well as the model that saturates this bound.
First passage time theory introduced in the previous section becomes useful because the area has a
simple expression in terms of quantities introduced in (12) (see supplementary material):


X
?

pot
dep
A = N (4f pot f dep )
p?
?i+ ? ?j+
M
?
M
i
ij
ij
ij

?
=

N (4f

pot dep

f

)

X




dep
p?
?j? ? ?i? .
Mpot
i
ij ? Mij

(14)

ij

With the states in the order described above, we can find perturbations of Mpot/dep that will always
increase the area, whilst leaving the equilibrium distribution, p? , unchanged. Some of these perturbations are shown in Figure 3, see supplementary material for details. For example, in Figure 3(a),
for two states i on the left and j on the right, with j being more ?potentiated? than i (i.e. ?i+ > ?j+ ),
dep
we have proven that increasing Mpot
ij and decreasing Mij leads to an increase in area. The only
thing that can prevent these perturbations from increasing the area is when they require the decrease
of a matrix element that has already been set to 0. This determines the topology (non-zero transition
probabilities) of the model with maximal area. It is of the form shown in Figure 4(c),with potentiation moving one step to the right and depression moving one step to the left. Any other topology
would allow some class of perturbations (e.g. in Figure 3) to further increase the area.
As these perturbations do not change the equilibrium distribution, this means that the area of any
model is bounded by that of a linear chain with the same equilibrium distribution. The area of
a linear chain model can be expressed directly in terms of its equilibrium state distribution, p? ,
yielding the following upper bound on the area of any model with the same p? (see supplementary
material):


?
?
?
?


X
X
X

2
N
2 N X?
?
? ?

?
k?
jp?
p
w
=
k
?
jp
A?
(15)
k
j
k
j  pk ,

r
r

j
j
k
k 
P
where we chose wk = sgn[k ? j jp?
j ]. We can then maximize this by pushing all of the equilibrium distribution symmetrically to the two end states. This can be done by reducing the transition
probabilities out of these states, as in Figure 4(c). This makes it very difficult to exit these states
once they have been entered. The resulting area is
?
N (M ? 1)
.
(16)
A?
r
This analytical result is similar to a numerical result found in [18] under a slightly different information theoretic measure of memory performance.
6

The ?sticky? end states result in very slow decay of memory, but they also make it difficult to encode
the memory in the first place, since a small fraction of synapses are able to change synaptic efficacy
during the storage of a new memory. Thus models that maximize area optimize memory at late
times, at the expense of early times.

4

Memory curve envelope

Now we will look at the implications of the upper bounds found in the previous section for the SNR
at finite times. As argued in (6), the memory curve can be written in the form
? X
SNR(t) = N
Ia e?rt/?a .
(17)
a

The upper bounds on the initial SNR, (10), and the area, (16), imply the following constraints on the
parameters {Ia , ?a }:
X
X
Ia ? 1,
Ia ?a ? M ? 1.
(18)
a

a

We are not claiming that these are a complete set of constraints: not every set {Ia , ?a } that satisfies
these inequalities will actually be achievable by a synaptic model. However, any set that violates
either inequality will definitely not be achievable.
Now we can pick some fixed time, t0 , and maximize the SNR at that time wrt. the parameters
{Ia , ?a }, subject to the constraints above. This always results in a single nonzero Ia ; in essence,
optimizing memory at a single time requires a single exponential. The resulting optimal memory
curve, along with the achieved memory at the chosen time, depends on t0 as follows:
?
?
M ?1
t0 ?
=? SNR(t) = N e?rt/(M ?1)
=? SNR(t0 ) = N e?rt0 /(M ?1) ,
r
?
?
(19)
M ?1
N (M ? 1)e?t/t0
N (M ? 1)
t0 ?
=? SNR(t) =
=? SNR(t0 ) =
.
r
rt0
ert0
Both the initial SNR bound and the area bound are saturated at early times. At late times, only
the area bound is saturated. The function SNR(t0 ), the green curve in Figure 4(a), above forms a
memory curve envelope with late-time power-law decay ? t?1
0 . No synaptic model can have an
SNR that is greater than this at any time. We can use this to find an upper bound on the memory
lifetime, ? (), by finding the point at which the envelope crosses :
?
N (M ? 1)
,
(20)
? () ?
er
where we assume N > (e)2 . Intriguingly, both the lifetime and memory envelope expand linearly
with the number of internal states M , and increase as the square root of the number of synapses N .
This leaves the question of whether this bound is achievable. At any time, can we find a model
whose memory curve touches the envelope? The red curves in Figure 4(a) show the closest we
have come to the envelope with actual models, by repeated numerical optimization of SNR(t0 ) over
Mpot/dep with random initialization and by hand designed models.
We see that at early, but not late times, there is a gap between the upper bound that we can prove
and what we can achieve with actual models. There may be other models we haven?t found that
could beat the ones we have, and come closer to our proven envelope. However, we suspect that the
area constraint is not the bottleneck for optimizing memory at times less than O( M
r ). We believe
there is some other constraint that prevents models from approaching the envelope, and currently are
exploring several mathematical conjectures for the precise form of this constraint in order to obtain
a potentially tighter envelope. Nevertheless, we have proven rigorously that no model?s memory
curve can ever exceed this envelope, and that it is at least tight for late times, longer than O( M
r ),
where models of the form in Figure 4(c)can come close to the envelope.

5

Discussion

We have initiated the development of a general theory of learning and memory with complex
synapses, allowing for an exploration of the entire space of complex synaptic models, rather than
7

(a)

(b)

1

10

0

10
SNR

envelope
numerical search
hand designed
?1

10

(c)

?

Area bound active
Initial SNR bound active

?

?2

10 ?1
10

0

10

1

10
Time

2

10

3

10

Figure 4: The memory curve envelope for N = 100, M = 12. (a) An upper bound on the SNR
at any time is shown in green. The red dashed curve shows the result of numerical optimization of
synaptic models with random initialization. The solid red curve shows the highest SNR we have
found with hand designed models. At early times these models are of the form shown in (b) with
different numbers of states, and all transition probabilities equal to 1. At late times they are of the
form shown in (c) with different values of ?. The model shown in (c) also saturates the area bound
(16) in the limit ? ? 0.
analyzing individual models one at a time. In doing so, we have obtained several new mathematical results delineating the functional limits of memory achievable by synaptic complexity, and the
structural characterization of synaptic dynamical systems that achieve these limits. In particular,
operating within the ideal observer framework of [10, 11, 18], we have shown that for a population
?
of N synapses with M internal states, (a) the initial SNR of any synaptic model cannot exceed N ,
and any model that achieves this bound is equivalent to a binary synapse, (b) the area under the
memory curve of any model cannot exceed that of a linear chain model with the same
? equilibrium
distribution, (c) both the area and memory lifetime of any model cannot exceed O( N M ), and the
model that achieves this limit has a linear chain topology with only nearest neighbor transitions, (d)
we have derived an envelope memory curve in the SNR-time plane that cannot be exceeded by the
memory curve of any model, and models that approach this envelope for times greater ?
than O( M
r )
are linear chain models, and (e) this late-time envelope is a power-law proportional to O( N M /rt),
indicating that synaptic complexity can strongly enhance the limits of achievable memory.
This theoretical study opens up several avenues for further inquiry. In particular, the tightness of our
envelope for early times, less than O( M
r ), remains an open question, and we are currently pursuing
several conjectures. We have also derived memory constrained envelopes, by asking in the space
of models that achieve a given SNR at a given time, what is the maximal SNR achievable at other
times. If these two times are beyond a threshold separation, optimal constrained models require
two exponentials. It would be interesting to systematically analyze the space of models that achieve
good memory at multiple times, and understand their structural organization, and how they give rise
to multiple exponentials, leading to power law memory decays.
Finally, it would be interesting to design physiological experiments in order to perform optimal
systems identification of potential Markovian dynamical systems hiding within biological synapses,
given measurements of pre and post-synaptic spike trains along with changes in post-synaptic potentials. Then given our theory, we could match this measured synaptic model to optimal models to
understand for which timescales of memory, if any, biological synaptic dynamics may be tuned.
In summary, we hope that a deeper theoretical understanding of the functional role of synaptic
complexity, initiated here, will help advance our understanding of the neurobiology of learning and
memory, aid in the design of engineered memory circuits, and lead to new mathematical theorems
about stochastic processes.
Acknowledgements
We thank Sloan, Genenetech, Burroughs-Wellcome, and Swartz foundations for support. We thank
Larry Abbott, Marcus Benna, Stefano Fusi, Jascha Sohl-Dickstein and David Sussillo for useful
discussions.
8

References
[1] J. J. Hopfield, ?Neural networks and physical systems with emergent collective computational
abilities,? Proc. Natl. Acad. Sci. U.S.A. 79 (1982) no. 8, 2554?2558.
[2] D. J. Amit, H. Gutfreund, and H. Sompolinsky, ?Spin-glass models of neural networks,? Phys.
Rev. A 32 (Aug, 1985) 1007?1018.
[3] E. Gardner, ?The space of interactions in neural network models,? Journal of Physics A:
Mathematical and General 21 (1988) no. 1, 257.
[4] T. V. P. Bliss and G. L. Collingridge, ?A synaptic model of memory: long-term potentiation in
the hippocampus,? Nature 361 (Jan, 1993) 31?39.
[5] C. C. H. Petersen, R. C. Malenka, R. A. Nicoll, and J. J. Hopfield, ?All-or-none potentiation at
CA3-CA1 synapses,? Proc. Natl. Acad. Sci. U.S.A. 95 (1998) no. 8, 4732?4737.
[6] D. H. O?Connor, G. M. Wittenberg, and S. S.-H. Wang, ?Graded bidirectional synaptic
plasticity is composed of switch-like unitary events,? Proc. Natl. Acad. Sci. U.S.A. 102 (2005)
no. 27, 9679?9684.
[7] R. Enoki, Y. ling Hu, D. Hamilton, and A. Fine, ?Expression of Long-Term Plasticity at
Individual Synapses in Hippocampus Is Graded, Bidirectional, and Mainly Presynaptic:
Optical Quantal Analysis,? Neuron 62 (2009) no. 2, 242 ? 253.
[8] D. J. Amit and S. Fusi, ?Constraints on learning in dynamic synapses,? Network:
Computation in Neural Systems 3 (1992) no. 4, 443?464.
[9] D. J. Amit and S. Fusi, ?Learning in neural networks with material synapses,? Neural
Computation 6 (1994) no. 5, 957?982.
[10] S. Fusi, P. J. Drew, and L. F. Abbott, ?Cascade models of synaptically stored memories,?
Neuron 45 (Feb, 2005) 599?611.
[11] S. Fusi and L. F. Abbott, ?Limits on the memory storage capacity of bounded synapses,? Nat.
Neurosci. 10 (Apr, 2007) 485?493.
[12] C. Leibold and R. Kempter, ?Sparseness Constrains the Prolongation of Memory Lifetime via
Synaptic Metaplasticity,? Cerebral Cortex 18 (2008) no. 1, 67?77.
[13] D. S. Bredt and R. A. Nicoll, ?AMPA Receptor Trafficking at Excitatory Synapses,? Neuron
40 (2003) no. 2, 361 ? 379.
[14] M. P. Coba, A. J. Pocklington, M. O. Collins, M. V. Kopanitsa, R. T. Uren, S. Swamy, M. D.
Croning, J. S. Choudhary, and S. G. Grant, ?Neurotransmitters drive combinatorial multistate
postsynaptic density networks,? Sci Signal 2 (2009) no. 68, ra19.
[15] W. C. Abraham and M. F. Bear, ?Metaplasticity: the plasticity of synaptic plasticity,? Trends
in Neurosciences 19 (1996) no. 4, 126 ? 130.
[16] J. M. Montgomery and D. V. Madison, ?State-Dependent Heterogeneity in Synaptic
Depression between Pyramidal Cell Pairs,? Neuron 33 (2002) no. 5, 765 ? 777.
[17] R. D. Emes and S. G. Grant, ?Evolution of Synapse Complexity and Diversity,? Annual
Review of Neuroscience 35 (2012) no. 1, 111?131.
[18] A. B. Barrett and M. C. van Rossum, ?Optimal learning rules for discrete synapses,? PLoS
Comput. Biol. 4 (Nov, 2008) e1000230.
[19] J. Kemeny and J. Snell, Finite markov chains. Springer, 1960.
[20] C. Burke and M. Rosenblatt, ?A Markovian function of a Markov chain,? The Annals of
Mathematical Statistics 29 (1958) no. 4, 1112?1122.
[21] F. Ball and G. F. Yeo, ?Lumpability and Marginalisability for Continuous-Time Markov
Chains,? Journal of Applied Probability 30 (1993) no. 3, 518?528.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1620-temporally-asymmetric-hebbian-learning-spike-liming-and-neural-response-variability.pdf

Temporally Asymmetric Hebbian Learning,
Spike Timing and Neuronal Response Variability

L.F. Abbott and Sen Song
Volen Center and Department of Biology
Brandeis University
Waltham MA 02454

Abstract
Recent experimental data indicate that the strengthening or weakening of
synaptic connections between neurons depends on the relative timing of
pre- and postsynaptic action potentials. A Hebbian synaptic modification
rule based on these data leads to a stable state in which the excitatory and
inhibitory inputs to a neuron are balanced, producing an irregular pattern
of firing. It has been proposed that neurons in vivo operate in such a
mode.

1 Introduction
Hebbian modification of network interconnections plays a central role in the study of learning in neural networks (Rumelhart and McClelland, 1986; Hertz et al., 1991). Most work
on Hebbian learning involves network models in which the activities of the individual units
are represented by continuous variables. A Hebbian learning rule, in this context, is specified by describing how network weights change as a function of the activities of the units
that transmit and receive signals across a given network connection. While analyses of
Hebbian learning along these lines have provided important results, direct application of
these ideas to neuroscience is hindered by the fact that real neurons cannot be adequately
described by continuous activity variables such as firing rates. Instead, the inputs and outputs of neurons are sequences of action potentials or spikes. All the information conveyed
by one neuron to another over any appreciable distance is carried by the temporal patterns
of action potential sequences. Rules by which synaptic connections between real neurons
are modified in a Hebbian manner should properly be expressed as functions of the relative
timing of the action potentials fired by the input (presynaptic) and output (postsynaptic)
neurons. Until recently, little information has been available about the exact dependence of
synaptic modification on pre- and postsynaptic spike timing (see however, Levy and Steward, 1983; Gustafsson et ai., 1987). New experimental results (Markram et at., 1997; Bell
et al., 1997; Debanne et at., 1998; Zhang et at., 1998; Bi and Poo, 1999) have changed

L. F Abbott and S. Song

70

this situation dramatically, and these allow us to study Hebbian learning in a manner that
is much more realistic and relevant to biological neural networks. The results may find
application in artificial neural networks as well.

2

Temporally Asymmetric LTP and LTD

The biological substrate for Hebbian learning in neuroscience is provided by long-term
potentiation (LTP) and long-term depression (LTD) of the synaptic connections between
neurons (see for example, Malenka and Nicoll, 1993). LTP is a long-lasting strengthening of synaptic efficacy associated with paired pre- and postsynaptic activity. LTD is
a long-lasting weakening of synaptic strength. In recent experiments on neocortical slices
(Markram et aI., 1997), hippocampal cells in culture (Bi and Poo, 1999), and in vivo studies
of tadpole tectum (Zhang et aI., 1998), induction of LTP required that presynaptic action
potentials preceded postsynaptic firing by no more than about 20 ms. Maximal LTP occurred when presynaptic spikes preceded postsynaptic action potentials by less than a few
milliseconds. If presynaptic spikes followed postsynaptic action potentials, long-term depression rather than potentiation resulted. These results are summarized schematically in
Figure 1.

Figure 1: A model of the change in synaptic strength 6..g produced by paired pre- and postsynaptic
spikes occurring at times tpre and tpost respectively. Positive changes correspond to LTP and negative
to LTD. There is an abrupt transition at tpre - tpost = O. The units for 6..g are arbitrary in this figure,
but data indicate a maximum change of approximately 0.5 % per spike pair.
The curve in Figure 1 is a caricature used to model the weight changes arising from pairings
of pre- and postsynaptic action potentials separated by various intervals of time. This curve
resembles the data from all three preparations discussed above, but a couple of assumptions have been made in its construction. The data indicate that there is a rapid transition
from LTP to LTD depending on whether the time difference between pre- and postsynaptic
spiking is positive or negative, but the existing data cannot resolve exactly what happens
at the transition point. We have assumed that there is a discontinuous jump from LTP to
LTD at this point. In addition, we assume that the area under the LTP side of the curve is
slightly less than the area under the LTD side. In Figure 1, this diffetence is imposed by
making the magnitude of LTD slightly greater than the magnitude of LTP, while both sides
of the curve have equal exponential fall-offs away from zero time difference. Alternately,
we could have given the LTD side a slower exponential fall-off and equal amplitude. The
data do not support either assumption unambiguously, nor do they indicate which area is
larger. The assumption that the area under the LTD side of the curve is larger than that under the LTP side is critical if the resulting synaptic modification rule is to be stable against
uncontrolled growth of synaptic strengths.
Hebb (1949) postulated that a synapse should be strengthened when the presynaptic neuron
is frequently involved in making the postsynaptic neuron fire an action potential. Causality
is an important element in Hebb's statement; synaptic potentiation should occur only if
there is a causal relationship between the pre- and postsynaptic spiking. The LTPILTD rule
summarized in Figure 1 imposes causality through a tight timing requirement. The narrow

71

Hebbian Learning and Response Variability

windows for LTP and LTD seen in the data, and the abrupt transition from potentiation to
depression near zero separation between pre- and postsynaptic spike times impose a strict
causality condition for LTP induction.

3

Response Variability

What are the implications of the synaptic modification rule summarized in Figure I? To address this question, we introduce another topic that has been discussed extensively within
the computational neuroscience community in recent years, the origin of response variability (Softky and Koch, 1992 & 1994; Shadlen and Newsome, 1994 & 1998; Tsodyks
and Sejnowski, 1995; Amit and BruneI, 1997; Troyer and Miller, 1997a & b; Bugmann
et aI., 1997; van Vreeswijk and Sompolinsky, 1996 & 1998). Neurons can respond to
multiple synaptic inputs in two different modes of operation. Figure 2 shows membrane
potentials of a model neuron receiving 1000 excitatory and 200 inhibitory synaptic inputs.
Each input consists of an independent Poisson spike train driving a synaptic conductance.
The integrate-and-fire model neuron used in this example integrates these synaptic conductances as a simple capacitor-resistor circuit. To generate action potentials in this model,
we monitor the membrane potential and compare it to a threshold voltage. Whenever the
membrane potential reaches the threshold an action potential is "pasted" onto the membrane potential trace and the membrane potential is reset to a prescribed value.

B

A

-50

-58

250

500

750

1000

:> -20
E

~

>

500

750

1000

_-20

>

-40

-60

250

~

V

r-

50

100

t (ms)

150

200

E.

-40

>

-60

"Y'-'~"'h.llNM,~j~~"~"250

500

750

1000

t (ms)

Figure 2: Regular and irregular firing modes of a model integrate-and-fire neuron. Upper panels
show the model with action potentials deactivated, and the dashed lines show the action potential
threshold. The lower figures show the model with action potentials activated. A) In the regular firing
mode, the average membrane potential without spikes is above threshold and the firing pattern is fast
and regular (note the different time scale in the lower panel). B) In the irregular firing mode, the
average membrane potential without spikes is below threshold and the firing pattern is slower and
irregular.
Figures 2A and 2B illustrate the two modes of operation. The upper panels of Figure 2 show
the membrane potential with the action potential generation mechanism of the model turned
off, and the lower panels show the membrane potential and spike sequences that result when
the action potential generation is turned on. In Figure 2A, the effect of the excitatory inputs
is strong enough relative to that of the inhibitory inputs so that the average membrane
potential, when action potential generation is blocked, is above the spike threshold of the
model. When the action potential mechanism is turned back on (lower panel of Figure
2A), this produces a fairly regular pattern of action potentials at a relatively high rate.
The total synaptic input attempts to charge the neuron above the threshold, but every time
the potential reaches the threshold it gets reset and starts charging again. In this regular

L. F Abbott and S. Song

72

firing mode of operation, the timing of the action potentials is determined primarily by the
charging rate of the cell, which is controlled by its membrane time constant. Since this does
not vary as a function of time, the firing pattern is regular despite the fact that the synaptic
input is varying.
Figure 2B shows the other mode of operation that produces an irregular firing pattern. In
the irregular firing mode, the average membrane is more hyperpolarized than the threshold
for action potential generation (upper panel of Figure 2B). In this mode, action potentials
are only generated when there is a fluctuation in the total synaptic current strong enough to
make the membrane potential cross the threshold. This results in slower and more irregular
firing (lower panel of Figure 2B). The irregular firing mode has a number of interesting
features (Shadlen and Newsome, 1994 & 1998; Tsodyks and Sejnowski, 1995; Amit and
Brunei, 1997; Troyer and Miller, 1997a & b; Bugmann et aI., 1997; van Vreeswijk and
Sompolinsky, 1996 & 1998). First, it generates irregular firing patterns that are far closer
to the firing patterns seen in vivo than the patterns produced in the regular firing mode.
Second, responses to changes in the synaptic input are much more rapid in this mode, being
limited only by the synaptic rise time rather than the membrane time constant. Finally, the
timing of action potentials in the irregular firing mode is related to the timing of fluctuations
in the synaptic input rather than being determined primarily by the membrane time constant
of the cell.
B

A
~ 1.
(I)

I'"

1

(I)

~

11l
!!? 0.8

?20

?10

0

10

20

tpre -Ipost (ms)

Figure 3: Histograms indicating the relative probability of finding pre- and postsynaptic spikes
separated by the indicated time interval. A) Regular firing mode. The probability is essentiaIly flat
and at the chance level of one. B) Irregular firing mode. There is an excess of presynaptic spike
shortly before a postsynaptic spike.
An important difference between the regular and irregular firing modes is illustrated in the
cross-correlograms shown in Figure 3 (Troyer and Miller, 1997b; Bugmann et al. 1997).
These indicate the probability that an action potential fired by the postsynaptic neuron is
preceded or followed by an presynaptic spike separated by various intervals. The histogram
has been normalized so its value for pairings that are due solely to chance is one. The
histogram when the model is in the regular firing mode (Figure 3A) takes a value close to
one for almost all input-output spike time differences. This is a reflection of the fact that the
timing of individual action potentials in the regular firing mode is relatively independent
of the timing of the presynaptic inputs. In contrast, the histogram for a model neuron in
the irregular firing mode (Figure 3B) shows a much larger excess of presynaptic spikes
occurring shortly before the postsynaptic neuron fires. This excess reflects the fluctuations
in the total synaptic input that push the membrane potential up to the threshold and produce
a spike in the irregular firing mode. It indicates that, in this mode, there is a tight temporal
correlation between the timing of such fluctuations and output spikes.
For a neuron to operate in the irregular firing mode, there must be an appropriate balance
between the strength of its excitatory and inhibitory inputs. The excitatory input must be
weak enough, relative to the inhibitory input, so that the average membrane potential in the
absence of spikes is below the action potential threshold to avoid regular firing. However,
excitatory input must be sufficiently strong to keep the average potential close enough to

73

Hebbian Learning and Response Variability

the threshold so that fluctuations can reach it and cause the cell to fire. How is this balance
achieved?

4

Asymmetric LTPILTD Leads to an Irregular Firing State

A comparison of the LTPILTD synaptic modification rule illustrated in Figure 1, and the
presynaptic/postsynaptic timing histogram shown in Figure 3, reveals that a temporally
asymmetric synaptic modification rule based on the curve in Figure 1 can automatically
generate the balance of excitation and inhibition needed to produce an irregular firing state.
Suppose that we start a neuron model in a regular firing mode by giving it relatively strong
excitatory synaptic strengths. We then apply the LTPILTD rule of Figure 1 to the excitatory
synapse while holding the inhibitory synapse at constant values. Recall that Figure 1 has
been adjusted so that the area under the LTD part of the curve is greater than that under the
LTP part. This means that if there is an equal probability of a presynaptic spike to either
precede or follow a postsynaptic spike the net effect will be a weakening of the excitatory
synapses. This is exactly what happens in the regular firing mode, where the relationship
between the timing of pre- and postsynaptic spikes is approximately random (Figure 3A).
As the LTPILTD rule weakens the excitatory synapses, the average membrane potential
drops and the neuron enters the irregular firing mode. In the irregular firing mode, there is
a higher probability for a presynaptic spike to precede than to follow a postsynaptic spike
(Figure 3B). This compensates for the fact that the rule we use produces more LTD than
LTP. Equilibrium will be reached when the asymmetry of the LTPILTD modification curve
of Figure 1 is matched by the asymmetry of the presynaptic/postsynaptic timing histogram
of Figure 3B. The equilibrium state corresponds to a balanced, irregular firing mode of
operation, and it is automatically produced by the temporally asymmetric learning rule.
Figure 4A shows a transition from a regular to an irregular firing state mediated by the temporally asymmetric LTPILTD modification rule. The irregularity of the postsynaptic spike
train has been quantified by plotting the coefficient of variation (CV), the standard deviation over the mean of the interspike intervals, of the model neuron as a function of time.
Initially, the neuron was in a regular firing state with a low CV value. After the synaptic
modification rule reached an equilibrium state, the CV took a value near one indicating that
the neuron has been transformed into an irregular firing mode. The solid curve in Figure 4B
shows that temporally asymmetric LTPILTD can robustly generate irregular output firing
for a wide range of input firing rates.

A

B
1.0

1.2

?

?

.~

0.8

.~

1.0

.~

0.6

.~

0.8

(5

~
'0

~

8

(5 0.6

c

0"

~
Qi

0.2

8

0.0-'------.- - , -- - . - ----,
.0
20
30
40

time steps

04

2

o.

".
~

.......... .

0 0 + - - , - --..,.----,--5
,0
15
20

-;
"
25

input rate (Hz)

Figure 4: Coefficient of variation (CV) of the output spike train of the model neuron. A) Transition from a regular to an irregular firing state as temporally asymmetric LTPILTD modifies synaptic
strengths. The units of time in this plot 'are arbitrary because they depend on the magnitude of LTP
and LTD used in the model. B) Equilibrium CV values as a function of the firing rates of excitatory
inputs to the model neuron, The solid curve gives the results when temporally asymmetric LTP/LTD
is active, The dashed curve shows the results if the synaptic strengths that arose for 5 Hz inputs are
left unmodified.

74

L. F Abbott and S. Song

5 Discussion
Temporally asymmetric LTPILTD provides a Hebbian-type learning rule with interesting
properties (Kempter et aI., 1998). In the past, temporally asymmetric Hebbian learning
rules have been studied and applied to problems of temporal sequence generation (Manai
and Levy, 1993), navigation (Blum and Abbott, 1996; Gerstner and Abbott, 1997), motor
learning (Abbott and Blum, 1996), and detection of spike synchrony (Gerstner et al., 1996).
In these studies, two different LTPILTD window sizes were assumed: either of order 100 ms
(Manai and Levy, 1993; Blum and Abbott, 1996; Gerstner and Abbott, 1997; (Abbott and
Blum, 1996) or around 1 ms (Gerstner et aI., 1996). The new data (Markram et al., 1997;
Bell et aI., 1997; Zhang et al., 1998; Bi and Poo, 1999) give a window size of order 10
ms. For alms window size, temporally asymmetric LTPILTD is sensitive to precise spike
timing. When the window size is of order 100 ms, changes in stimuli or motor actions on a
behavioral level become relevant for LTP and LTD. A window size of 10 ms, as supported
by the recent data, suggests that LTP and LTD are sensitive to firing correlations relevant
to neuronal circuitry, such as input-output correlations, which vary over this time scale.
Temporally asymmetric LTPILTD has some interesting properties that distinguish it from
Hebbian learning rules based on correlations or covariances in pre- and postsynaptic rates.
We have found that the rule used here is not sensitive to input firing rates or to variability
in input rates. If we split the excitatory inputs of the model into two groups and give these
two input sets different rates, we see no difference in the distribution of synaptic strengths
arising from the learning rule. Similarly, if one group is given a steady firing rate and
the other group has firing rates that vary in time, no difference in synaptic strengths is
apparent. The most effective way to induce LTP in a set of inputs is to synchronize some of
their spikes. Inputs with synchronized spikes are slightly more effective at firing the neuron
than un synchronized spikes. This means that such inputs will preceded postsynaptic spikes
more frequently and thus will get stronger. This suggests that spike synchrony may be a
signal that marks a set of inputs for learning. Even when this synchrony has no particular
functional effect, so that it has little impact on the firing pattern of the postsynaptic neuron,
it can lead to dramatic shifts in synaptic strength. Thus, spike synchronization may be a
mechanism for inducing LTP and LTD .

Acknowledgments
Research supported by the National Science Foundation (DMS-9503261), the Sloan Center for Theoretical Neurobiology at Brandeis University, a Howard Hughes Predoctoral
Fellowship, and the W.M. Keck Foundation.

References
Abbott, LF & Blum, KI (1996) Functional significance of long-term potentiation for sequence learning and prediction. Cerebral Cortex 6:406-416.
Amit, DJ & BruneI N (1997) Global spontaneous activity and local structured (learned)
delay activity in cortex. Cerebral Cortex 7:237-252.
Bell ce, Han VZ, Sugawara Y & Grant K (1997) Synaptic plasticity in a cerebellum-like
structure depends on temporal order. Nature 387:278-281.
Bi G-q & Poo M-m (1999) Activity-induced synaptic modifications in hippocampal culture:
dependence on spike timing, synaptic strength and cell type. J. Neurophysiol. (in press).
Blum, KI & Abbott, LF (1996) A model of spatial map formation in the hippocampus of
the rat. Neural Compo 8:85-93.
Bugmann, G, Christodoulou, C & and Taylor, JG (1997) Role of temporal integration and
fluctuation detection in the highly irregular firing of a leaky integrator neuron model
with partial reset. Neural Compu . 9:985-1000.

Hebbian Learning and Response Variability

75

Debanne D, Gahwiler BH, Thompson SM (1998) Long-term synaptic plasticity between
pairs of individual CA3 pyramidal cells in rat hippocampal slices. J. Physiol. 507:237247.
Gerstner, W & Abbott, LF (1997) Learning navigational maps through potentiation and
modulation of hippocampal place cells. J. Computational Neurosci. 4:79-94.
Gerstner W, Kempter R, van Hemmen JL & Wagner, H (1996) A neural learning rule for
sub-millisecond temporal coding. Nature 383:76-78.
Gustafsson B, Wigstrom H, Abraham WC & Huang Y-Y (1987) Long-term potentiation
in the hippocampus using depolarizing current pulses as the conditioning stimulus to
single volley synaptic potentials. J. Neurosci. 7:774-780.
Hebb, DO (1949) The Organization of Behavior: A Neuropsychological Theory. New
York:Wiley.
Hertz, JA, Palmer, RG & Krogh, A (1991) Introduction to the Theory of Neural Computation. New York:Addison-Wesley.
Kempter R, Gerstner W & van Hemmen JL (1999) Hebbian learning and spiking neurons.
(submitted).
Levy WB & Steward 0 (1983) Temporal contiguity requirements for long-term associative
potentiation/depression in the hippocampus. Neurosci. 8:791-797.
Malenka, RC & Nicoll, RA (1993) MBDA-receptor-dependent synaptic plasticity: Multiple forms and mechanisms. Trends Neurosci. 16:521-527.
Minai, AA & Levy, WB (1993) Sequence learning in a single trial. INNS World Congress
on Neural Networks 11:505-508.
Markram H, Lubke J, Frotscher M & Sakrnann B (1997) Regulation of synaptic efficacy
by coincidence of postsynaptic APs and EPSPs. Science 275:213-215.
Rumelhart, DE & McClelland, JL, editors (1986) Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volumes I & II. Cambridge, MA:MIT Press.
Shadlen, MN & Newsome, WT (1994) Noise, neural codes and cortical organization. Current Opinion in Neurobiology 4:569-579.
Shadlen, MN & Newsome, WT (1998) The Variable Discharge of Cortical Neurons: Implications for Connectivity, Computation, and Information Coding. Journal of Neuroscience 18:3870-3896.
Softky, WR & Koch, C (1992) Cortical cells should spike regularly but do not. Neural
Computation 4:643-646.
Softky, WR & Koch, C (1994) The highly irregular firing of cortical cells is inconsistent
with temporal integration of random EPSPs. Journal of Neuroscience 13:334-350.
Troyer, 1W & Miller, KD (1997a) Physiological gain leads to high lSI variability in a
simple model of a cortical regular spiking cell. Neural Compo 9:971-983:
Troyer, 1W & Miller, KD (1997b) Integrate-and-fire neurons matched to physiological
F-I curves yield high input sensitivity and wide dynamic range. Computational Neuroscience, Trends in Research. 1M Boser, ed. New York:Plenum, pp. 197-20l.
Tsodyks, M & Sejnowski, TJ (1995) Rapid switching in balanced cortical network models.
Network 6: 1-14.
van Vreeswijk, C & Sompolinsky, H (1996) Chaos in neuronal networks with balanced
excitatory and inhibitory activity. Science 274: 1724-1726.
van Vreeswijk, C & Sompolinsky, H (1998) Chaotic balanced state in a model of cortical
circuits. Neural Compo 10:1321-1327.
Zhang LI, Tao, HW, Holt CE, Harris WA & Poo M-m (1998) A critical window for cooperation and competition among developing retinotectal synapses. Nature 395:37-44.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4364-two-is-better-than-one-distinct-roles-for-familiarity-and-recollection-in-retrieving-palimpsest-memories.pdf

Two is better than one: distinct roles for familiarity
and recollection in retrieving palimpsest memories

Cristina Savin1
cs664@cam.ac.uk

Peter Dayan2
dayan@gatsby.ucl.ac.uk

M?at?e Lengyel1
m.lengyel@eng.cam.ac.uk
1

Computational & Biological Learning Lab, Dept. of Engineering, University of Cambridge, UK
2
Gatsby Computational Neuroscience Unit, University College London, UK

Abstract
Storing a new pattern in a palimpsest memory system comes at the cost of interfering with the memory traces of previously stored items. Knowing the age of
a pattern thus becomes critical for recalling it faithfully. This implies that there
should be a tight coupling between estimates of age, as a form of familiarity, and
the neural dynamics of recollection, something which current theories omit. Using a normative model of autoassociative memory, we show that a dual memory
system, consisting of two interacting modules for familiarity and recollection, has
best performance for both recollection and recognition. This finding provides a
new window onto actively contentious psychological and neural aspects of recognition memory.

1

Introduction

Episodic memory such as that in the hippocampus acts like a palimpsest ? each new entity to be
stored is overlaid on top of its predecessors, and, in turn, is submerged by its successors. This implies
both anterograde interference (existing memories hinder the processing of new ones) and retrograde
interference (new memories overwrite information about old ones). Both pose important challenges
for the storage and retrieval of information in neural circuits. Some aspects of these challenges have
been addressed in two theoretical frameworks ? one focusing on anterograde interference through the
interaction of novelty and storage [1]; the other on retrograde interference in individual synapses [2].
However, neither fully considered the critical issue of retrieval from palimpsests; this is our focus.
First, [1] made the critical observation that autoassociative memories only work if normal recall
dynamics are suppressed on presentation of new patterns that need to be stored. Otherwise, rather
than memorizing the new pattern, the memory associated with the existing pattern that most closely
matches the new input will be strengthened. This suggests that it is critical to have a mechanism for
assessing pattern novelty or, conversely, familiarity, a function that is often ascribed to neocortical
areas surrounding the hippocampus.
Second, [2] considered the palimpsest problem of overwriting information in synapses whose efficacies have limited dynamic ranges. They pointed out that this can be at least partially addressed
through allowing multiple internal states (for instance forming a cascade) for each observable synaptic efficacy level. However, although [2] provide an attractive formalism for analyzing and optimizing synaptic storage, a retrieval mechanism associated with this storage is missing.
1

a

b

potentiation
depression

Figure 1: a. The cascade model. Internal states of a synapse (circles) can express one of two different
efficacies (W, columns). Transitions between states are stochastic and can either be potentiating,
or depressing, depending on pre- and postsynaptic activities. Probabilities of transitions between
states expressing the same efficacy p and between states expressing different efficacies, q, decrease
geometrically with cascade depth. b. Generative model for the autoassociative memory task. The
? is a noisy version of one of the stored patterns x. Upon storing pattern x synaptic states
recall cue x
changed from V0 (sampled from the stationary distribution of synaptic dynamics) to V1 . Recall
occurs after the presentation of t ? 1 intervening patterns, when synapses are in states Vt , with
? are observed at recall.
corresponding synaptic efficacies Wt . Only Wt and x
Although these pieces of work might seem completely unrelated, we show here that they are closely
linked via retrieval. The critical fact about recall from memory, in general, is to know how the information should appear at the time of retrieval. In the case of a palimpsest, the trace of a memory
in the synaptic efficacies depends critically on the age of the memory, i.e., its relative familiarity.
This suggests a central role for novelty (or familiarity) signals during recollection. Indeed, we show
retrieval is substantially worse when familiarity is not explicitly represented than when it is.
Dual system models for recognition memory are the topic of a heated debate [3, 4]. Our results
could provide a computational rationale for them, showing that separating a perirhinal-like network
(involved in familiarity) from a hippocampal-like network can be beneficial even when the only
task is recollection. We also show that the task of recognition can also be best accomplished by
combining the outputs of both networks, as suggested experimentally [4].

2

Storage in a palimpsest memory

We consider the task of autoassociative recall of binary patterns from a palimpsest memory. Specifically, the neural circuit consists of N binary neurons that enjoy all-to-all connectivity. During
storage, network activity is clamped to the presented pattern x, inducing changes in the synapses?
?internal? states V and corresponding observed binary efficacies W (Fig. 1a).
At recall, we seek to retrieve a pattern x that was originally stored, given a noisy cue x
? and the
current weight matrix W. This weight matrix is assumed to result from storing x on top of the
stationary distribution of the synaptic efficacies coming from the large number of patterns that had
been previously stored, and then subsequently storing a sequence of t ? 1 other intervening patterns
with the same statistics on top of x (Fig. 1b).
In more detail, a pattern to be stored has density f , and is drawn from the distribution:
Y
Y
Pstore (x) =
Pstore (xi ) =
f xi ? (1 ? f )1?xi
i

i

(1)

The recall cue is a noisy version of the original pattern, modeled using a binary symmetric channel:
Pnoise (?
x|x) =

Y
i

Pnoise (x?i |xi )

Pnoise (x?i |xi ) = (1 ? r)xi ? r


1?xi x?i

where r defines the level of input noise.
2

(2)
? rxi ? (1 ? r)


1?xi 1?x?i

(3)

The recall time t is assumed to come from a geometric distribution with mean t?:

t?1
1
1
Precall (t) = ? 1 ?
t?
t?

(4)

The synaptic learning rule is local and stochastic, with the probability of an event actually leading
to state changes determined by the current state of the synapse Vij and the activity at the pre- and
post-synaptic neurons, xi and xj . Hence, learning is specified through a set of transition matrices
M (xi , xj ), with M (xi , xj )l0 l = P(Vij0 = l0 |Vij = l, xi , xj ). For convenience, we adopted the cascade model [2] (Fig. 1a), which assumes that the probability of potentiation and depression decays
n?1
with cascade depth i as a geometric progression, qi? = ?i?1 , with qn? = ?1?? to compensate for
i

?
boundary effects. The transition between metastates is given by p?
i = ?? 1?? , with the correction
f
factors ?+ = 1?f
f and ?? = 1?f ensuring that different metastates are equally occupied for different pattern sparseness values f [2]. Furthermore, we assume synaptic changes occur only when the
postsynaptic neuron is active, leading to potentiation if the presynaptic neuron is also active and to
depression otherwise. The specific form of the learning rule could influence the memory span of the
network, but we expect it not to change the results below qualitatively.

The evolution of the distribution over synaptic states after encoding can be described by a Markov
process, with a transition matrix M given as the averageP
change in synaptic states expected after
storing an arbitrary pattern from the prior Pstore (x), M = xi ,xj Pstore (xi )?Pstore (xj )?M(xi , xj ).
Additionally, we define the column vectors ? V (xi , xj ) and ? W (xi , xj ) for the distribution of the
synaptic states and observable efficacies, respectively, when one of the patterns stored was (xi , xj ),
such that ?lW (xi , xj ) = P(Wij = l|xi , xj ) and ?lV (xi , xj ) = P(Vij = l|xi , xj ). Given these
definitions, we can express the final distribution over synaptic states as:

X
t?1
? V (xi , xj ) =
Precall (t) ? M
? M(xi , xj ) ? ? ?
(5)
t

where we start from the stationary distribution ? ? (the eigenvector of M for eigenvalue 1), encode
pattern (xi , xj ) and then t ? 1 additional patterns from the same distribution. The corresponding
weight distribution is ? W (xi , xj ) = T ? ? V (xi , xj ), where T is a 2 ? 2n matrix defining the
deterministic mapping from synaptic states to observable efficacies.
The fact that the recency of the pattern to be recalled, t, appears in equation 5 implies that pattern age
will strongly influence information retrieval. In the following, we consider two possible solutions
to this problem. We first show the limitations of recall dynamics that involve a single, monolithic
module which averages over t. We then prove the benefits of a dual system with two qualitatively
different modules, one of which explicitly represents an estimate of pattern age.

3
3.1

A single module recollection system
Optimal retrieval dynamics

Since information storage by synaptic plasticity is lossy, the recollection task described above is a
probabilistic inference problem [5,6]. Essentially, neural dynamics should represent (aspects of) the
posterior over stored patterns, P (x|?
x, W), that expresses the probability of any pattern x being the
? , and the synaptic efficacies W.
correct response for the recall query given a noisy recall cue, x
In more detail, the posterior over possible stored patterns can be computed as:
? ) ? Pstore (x) ? Pnoise (?
P (x|W, x
x|x) ? P(W|x)

(6)
1

where
we assume that evidence from the weights factorizes over synapses , P (W|x) =
Q
P
(W
ij |xi , xj ).
ij
1
This assumption is never exactly true in practice, as synapses that share a pre- or post- synaptic partner are
bound to be correlated. Here, we assume the intervening patterns cause independent weight changes and ignore
the effects of such correlations.

3

Previous Bayesian recall dynamics derivations assumed learning rules for which the contribution of
each pattern to the final weight were the same, irrespective of the order of pattern presentation [5,6].
By contrast, the Markov chain behaviour of our synaptic learning rule forces us to explicitly consider
pattern age. Furthermore, as pattern age is unknown at recall, we need to integrate over all possible t
values (Eq. 5). This integral (which is technically a sum, for discrete t) can be computed analytically
using the eigenvalue decomposition of the transition matrix M. Alternatively, if the value of t is
known during recall, the prior is replaced by a delta function, Precall (t) = ?(t ? t? ).
There are several possible ways of representing the posterior in Eq.6 through neural dynamics without reifying t. For consistency, we assume neural states to be binary, with network activity at each
step representing a sample from the posterior [7, 8]. An advantage of this approach is that the full
posterior is represented in the network dynamics, such that higher decision modules can not only
extract the ?best? pattern (for the mean squared error cost function considered here, this would be
the mean of the posterior) but also estimate the uncertainty of this solution. Nevertheless, other
representations, for example representing the parameters of a mean-field approximation to the true
posterior [5, 9, 10], would also be possible and similarly informative about uncertainty.
In particular, we use Gibbs sampling, as it allows for neurally plausible recall dynamics [7]. This
results in asynchronous updates, in which the activity of a neuron xi changes stochastically as a
function of its input cue x
?i , the activity of all other neurons, x\i , and neighbouring synapses, Wi,?
and W?,i . Specifically, the Gibbs sampler results in a sigmoid transfer function, with the total current
to the neuron given by the log-odds ratio:
Iirec

=

log

P(xi = 1|x\i , W, x
?i )
= Iirec,in + Iirec,out + a?
xi + b
P(xi = 0|x\i , W, x
?i )

(7)

in/out

defining the evidence from the incoming and outgoing synapses of neuron i,
with the terms Irec
and the constants a and b determined by the prior over patterns and the noise model.2 The terms
describing the contribution from recurrent interactions, have a similar shape:
X

in
in
in
Iirec,in =
cin
(8)
1 ? Wij xj + c2 ? Wij + c3 ? xj + c4
j

Iirec,out

=

X

out
out
out
cout
1 ? Wji xj + c2 ? Wji + c3 ? xj + c4



(9)

j
in/out

The parameters ck
, uniquely determined by the learning rule and the priors for x and t, rescale
the contribution of the evidence from the weights as a function of pattern age (see supplementary
text). Furthermore, these constants translate into a unique signal, giving a sort of ?sufficient statistic? for the expected memory strength. NoteP
that the optimal dynamics include two homeostatic
P
processes, corresponding to global inhibition, j xj , and neuronal excitability regulation, j Wij ,
that stabilize network activity during recall.
3.2

Limitations

Beside the effects of assuming a factorized weight distribution, the neural dynamics derived above
should be the best we can do given the available data (i.e. recall cue and synaptic weights). How
well does the network fare in practice?
Performance is as expected when pattern age is assumed known: as the available information from
the weights decreases, so does performance, finally converging to control levels, defined by the retrieval performance of a network without plastic recurrent connections, i.e. when inference uses only
the recall cue and the prior over stored patterns (Fig. 2a, green). When t is unknown, performance
also deteriorates with increasing pattern age, however this time beneath control levels (Fig. 2a, blue).
Intuitively, one can see that relying on the prior over t is similar to assuming t fixed to a value close
2
out
Real neurons can only receive information from their presynaptic partners, so cannot estimate Irec
. We
therefore ran simulations without this term in the dynamics and found that although it did decrease recall performance, this decrease was similar to that obtained by randomly pruning half of the connections in the network
and keeping this term in the dynamics (not shown). This indicated that performance is mostly determined by
the number of available synapses used for inference, and not so much by the direction of those synapses. Hence,
in the following we use both terms and leave the systematic study of connectivity for future work.

4

40

t known
t unknown
control

30

b

20

10

control

5

10
0
0

15
error (%)

error (%)

a

50

t

100

150

0

t known

single module
dual system
Gibbs tempered
transitions

Figure 2: a. Recall performance for a single module memory system. b. Average recollection error
comparison for the single and dual memory system. Black lines mark control performance, when
ignoring the information from the synaptic weights.

to the mean of this prior. When the pattern that was actually presented is older than this estimate, the
resulting memory signal is weaker than expected, suggesting that the initial pattern was very sparse
(since a pair of inactive elements does not induce any synaptic changes according to our learning
rule). However, less reasonable is the fact that averaging over the prior distribution of recall times t
(Eq. 4), performance is worse than this control (Fig. 2b).
One possible reason for this failure is that the sampling procedure used for inference might not work
in certain cases. Since Gibbs samplers are known to mix poorly when the shape of the posterior is
complex (with strong correlations, as in frustrated Ising models), perhaps our neural dynamics are
unable to sample the desired distribution effectively. We confirmed this hypothesis by implementing
a more sophisticated sampling procedure using tempered transitions [11] (details in supplementary
text). Indeed, with tempered transitions performance becomes significantly better than control, even
for the cases where Gibbs sampling fails (Fig. 2b). Unfortunately, there has yet to be a convincing
suggestion as to how tempering dynamics (or in fact any other sampling algorithm that works well
with correlated posteriors) can be represented neurally since, for example, they require a global
acceptance decision to be taken at the end of each temperature cycle.
It is worth noting that with more complex synaptic dynamics (e.g. deeper cascades) simple Gibbs
sampling works reasonably well (data not shown), probably because the posterior is smoother and
hence easier to sample.

4

A dual memory system

An alternative to implicitly marginalizing over the age of the pattern throughout the inference process is to estimate it at the same time as performing recollection. This suggests the use of dual
modules that together estimate the joint posterior P (x, t|?
x, W), with sampling proceeding in a
loop: the familiarity module generates a sample from the posterior over the age of the currently esti? , W); and the recollection module uses this estimated age to compute a new
mated pattern, P(t|x, x
sample from the distribution over possible stored patterns given the age, P (x|?
x, W, t) (Fig. 3a).
The module that computes familiarity can also be seen as a palimpsest, with each pattern overlaying,
and being overlaid by, its predecessors and successors. Formally, it needs to compute the probability
? , W), as the system continues to implement a Gibbs sampler with t as an additional dimenP(t|x, x
sion. As a separate module, the neural network estimating familiarity cannot however access the
weights W of the recollection module. A biologically plausible approximation is to assume that
the familiarity module uses a separate set of weights, which we call Wfam . Also, it is clear from
? conditioned on x, thus the conditioning on x
? can be dropped when
Fig. 1b that t is independent of x
computing the posterior over t, that is, external input need only feed directly into the recollection
but not the familiarity module (Fig. 3a).
In particular, we assume a feedforward network structure in the familiarity module, with each neuron
receiving the output of the recollection module as inputs through synapses Wfam . These synaptic
5

b

cue

familiarity

recollection

activation

0.05

0

1

100

neuron index

familiarity signal

a

10 1

10 0

10 ?1

200

0

50

t

100

150

Figure 3: a. An overview of the dual memory system. The familiarity network has a feedforward
structure, with the activity of individual neurons estimating the probability of the true pattern age
being a certain value t, see example in inset. The estimated pattern age translates into a familiarity
signal, which scales the contribution of the recurrent inputs in the network dynamics. b. Dependence
of the familiarity signal on the estimated pattern age.
weights change according to the same cascade rule used for recollection.3 For simplicity, we assume
that the familiarity neurons are always activated during encoding, so that synapses can change state
(either by potentiation or depression) with every storage event.
Concretely, the familiarity module consists of Nfam neurons, each corresponding to a certain pattern
age in the range 1?Nfam (the last unit codes for t ? Nfam ). This forms a localist code for familiarity.
The total input to a neuron is given by the log-posterior Iifam = log P(t = i|x, Wfam ) which
translates into a simple linear activation function:
X

fam
fam
fam
fam
Iifam =
cfam
+ cfam
+ log P(t) ? log(Z)
(10)
1,i Wij xj + c2,i Wij
3,i xj + c4,i
j
in/out
before (albeit different for each neuron
where the constants cfam
k,i are similar to parameters c
because of their tuning to different values of t), and Z is the unknown partition function.

As mentioned above, we treat the activity of the familiarity module as a sample from the posterior
over age t. This representation requires lateral competition between different units such that only one
can become active at each step. Dynamics of this sort can be implemented using a softmax operator,
Ii
P(xfam
= 1) = Pe eIj (thus rendering the evaluation of the partition function Z unnecessary), and
i
j

are a common feature of a range of neural models [12, 13].
Critically, this familiarity module is not just a convenient theoretical construct associated with retrieval. First, as we mentioned before, the assessment of novelty actually plays a key part in memory
storage ? in making the decision as to whether a pattern that is presented is novel, and so should
be stored, or familiar, and so should have its details be recalled. This venerable suggestion [1] has
played a central part in the understanding of structure-function relationships in the hippocampus.
The graded familiarity module that we have suggested is an obvious extension of this idea; the use
for retrieval is new. Second, it is in general accord with substantial data on the role of perirhinal cortex and the activity of neurons in this structure [3]. Recency neurons would be associated with small
values of t; novelty neurons with large or effectively infinite values of t [14], although perirhinal
cortex appears to adopt a population coding strategy for age, rather than just one-of-n.
The recollection module has the same dynamics as before, with constants ci computed assuming t
fixed to the output of the familiarity module. Thus we predict that familiarity multiplicatively modulates recurrent interactions in the recollection module during recall. Since there is a deterministic
mapping between t and this modulatory factor (Fig. 3b), it can be computed using a linear unit pooling the outputs of all the neurons in the familiarity module, with weights given by the corresponding
values for cfam
(t).
i
3
There is nothing to say that the learning rule that optimizes the recollection network?s ability to recall
patterns should be equally appropriate for assessing familiarity. Hence, the familiarity module could have their
own learning rule, optimized for its specific task.

6

b
novel

40

c

0.9

1

0.7

0.9

*

*

100

50

30
0.5

20

0.3

10
0

familiar
0

0.04

0.08

0.12

0.1

hits

familiarity: estimated t

a

0.8

0

0.7

100

d

fam

rec

*

90

0.6
0.5

both

80
0

0.2

recollection: average entropy

0.4

0.6

false alarms

0.8

1

fam

rec

Figure 4: a. Decision boundaries for the recognition module. b. Corresponding ROC curve. c.
Performance comparison when the decision layer uses signals from the familiarity module, the recollection module, or both. d. Same comparison, when data is restricted to recent stimuli. Note that
difference between fam and rec became significant compared to c.
In order to compare single and dual module systems fairly, the computational resources employed by
each should be the same. We therefore reduced the overall connectivity in the dual system such that
the two have the same total number of synapses. Moreover, since elements of Wfam are correlated,
the effective number of connections is in fact somewhat lower in the dual system. Regardless, the
dual memory system performs significantly better than the single module system (Fig. 2b).

5

Recognition memory

We have so far considered familiarity merely as an instrument for effective recollection. However,
there are many practical and experimental tasks in which it is sufficient to make a binary decision
about whether a pattern is novel or familiar rather than recalling it in all its gory detail. It is these
tasks that have been used to elucidate the role of perirhinal cortex in recognition memory.
In the dual module system, information about recognition is available from both the familiarity
module (patterns judged to have young ages are recognized) and the recollection module (patterns
recalled with higher certainty are recognized). We therefore construct an additional decision module
which takes the outputs of the familiarity and recollection modules and maps them into a binary
behavioral response (familiar vs. novel).
Specifically, we use the average of the entropies associated with the activities of neurons in the
recollection module and the mean estimate of t from the familiarity module. Since the palimpsest
property implicitly assumes that all patterns have been presented at some point, we define a pattern to
be familiar if its age is less than a fixed threshold tth . We train the decision module using a Gaussian
process classifier4 [15], which yields as outcome the probability of a hit, P(familiar|t? , x? ), shown
in Fig. 4a. The shape of the resulting discriminator, that it is not parallel to either axis, suggests that
the output of both modules is needed for successful recognition, as suggested experimentally [4,16].
The fact that a classifier trained using only one of the two dimensions cannot match the recognition
performance of that using both confirms this observation (Fig. 4c).
Moreover, the ROC curve produced by the classifier, plotting hit rates against false alarms as relative
losses are varied, has a similar shape to those obtained for human behavioral data: it has a so-called
?curvi-linear? character because of the apparent intersect at a finite hit probability for 0 false alarm
rate [17] (Fig. 4b). Lastly, as recognition is known to rely more on familiarity for relatively recent
patterns [18], we estimate recognition performance for recent patterns, which we define as having
age t ? t2th . To determine the contribution of each module in recognition outcomes in this case, we
estimate performance of classifiers trained on single input dimensions for this test data. Consistent
with experimental data, our analysis reveals that the familiarity signal gives a more reliable estimate
of novelty, compared to the recollection output for relatively recent items (Fig. 4d).
4
The specific classifier was chosen as it allows for an easy estimation of the ROC curves. Future work
should explore analytical decision rules.

7

6

Conclusions and discussion

Knowing the age of a pattern is critical for retrieval from palimpsest memories, a consideration
that has so far eluded theoretical inquiry. We showed that a memory system could either treat this
information implicitly, by marginalizing over all possible ages, or it could estimate age explicitly as
a form of familiarity. In principle, both solutions should have similar performance, given the same
resources. In practice, however, a system involving dual modules is significantly better.
In our model, the posterior over possible stored patterns was represented in neural activities via
samples. We showed that a complex, biologically-questionable sampling procedure would be necessary for the implicit, single module, system. Instead, a dual memory system with two functionally
distinct but closely interacting modules, yielded the best performance both for efficient recollection
and for recognition. Importantly, though Gibbs sampling and tempered transitions provide a useful framework for understanding the performance differences between different memory systems,
the presented results are not restricted to a sampling-based implementation. Since age and identity
are tightly correlated, a mean field solution that use factorized distributions [5] shows very similar behavior (see supplementary text). Similarly, the specific details of the familiarity module are
not critical for these effects, which should be apparent for any alternative implementation correctly
estimating pattern age.
Representing pattern age, t, explicitly essentially amounts to implementing an auxiliary variable for
sampling the space of possible patterns, x more efficiently. Such auxiliary variable methods are
widely used to increase sampling efficiency when other, simpler methods fail [19]. Moreover, since
t in our case specifically modulates the correlated components of the posterior it can be seen as a
?temperature? parameter, and so we can understand the advantages brought about by the dual system
as due to implementing a form of ?simulated tempering? ? a class of methods known to help mixing
in strongly correlated posteriors.
Our proposal provides a powerful new window onto the contentious debate about the neural mechanisms of recognition and recall. The rationale for our familiarity network was improving recollection; however, the form of the network was motivated by the substantial experimental data [14] on
recognition, and indeed standard models of perirhinal cortex activity [20]. These, for instance, also
rely on some form of inhibition to mediate interactions between different familiarity neurons. Nevertheless, our model is the first to link the computational function of familiarity networks to recall;
it is distinct also in that it considers palimpsest synapses, as previous models use purely additive
learning rules [20]. Although we only considered pattern age as the basis of familiarity here, the
principle of the interaction between familiarity and recollection remains the same in an extended
setting, when familiarity characterizes the expected strength of the memory trace more completely,
including the effects of retention interval, number of repetitions, and spacing between repetitions.
Future work with the extended model should allow us to address familiarity, novelty, and recency
neurons in the perirhinal cortex, and indeed provide a foundation for new thinking about this region.
In our model familiarity interacts with recollection by multiplicatively (or divisively) modulating the
contribution of recurrent inputs in the recollection module. Neurally, this effect could be mediated
by shunting inhibition via specific classes of hippocampal interneurons which target the dendritic
segment corresponding to recurrent connections, thus rescaling the relative contribution of external versus recurrent inputs [21]. Whether pathways reaching CA3 from perirhinal cortex through
entorhinal cortex preserve a sufficient amount of input specificity of feed-forward inhibition is unknown.
Our theory predicts important systems-level aspects of memory from synaptic-level constraints. In
particular, by optimizing our dual system solely for memory recall we also predicted non-trivial
ROC curves for recognition that are in at least broad qualitative agreement with experiments. Future
work will be needed to explore whether the ROC curves in our model show similar dissociations in
response to specific lesions of the two modules to those found in recent experiments [22,23] and the
relation to other recognition memory models [24].
Acknowledgements
This work was supported by the Wellcome Trust (CS, ML) and the Gatsby Charitable Foundation
(PD).
8

References
[1] Hasselmo, M.E. The role of acetylcholine in learning and memory. Current opinion in neurobiology 16, 710?715 (2006).
[2] Fusi, S., Drew, P.J. & Abbott, L.F. Cascade models of synaptically stored memories. Neuron
45, 599?611 (2005).
[3] Brown, M.W. & Aggleton, J.P. Recognition memory: What are the roles of the perirhinal
cortex and hippocampus? Nature Reviews Neuroscience 2, 51?61 (2001).
[4] Wixted, J.T. & Squire, L.R. The medial temporal lobe and the attributes of memory. Trends in
Cognitive Sciences 15, 210?217 (2011).
[5] Sommer, F.T. & Dayan, P. Bayesian retrieval in associative memories with storage errors.
IEEE transactions on neural networks 9, 705?713 (1998).
[6] Lengyel, M., Kwag, J., Paulsen, O. & Dayan, P. Matching storage and recall: hippocampal
spike timing-dependent plasticity and phase response curves. Nature Neuroscience 8, 1677?
1683 (2005).
[7] Ackley, D., Hinton, G. & Sejnowski, T. A learning algorithm for Boltzmann machines. Cognitive Science 9, 147?169 (1995).
[8] Fiser, J., Berkes, P., Orb?an, G. & Lengyel, M. Statistically optimal perception and learning:
from behavior to neural representations. Trends in Cognitive Sciences 14, 119?130 (2010).
[9] Hinton, G. Deterministic Boltzmann learning performs steepest descent in weight-space.
Neural Computation 1, 143?150 (1990).
[10] Lengyel, M. & Dayan, P. Uncertainty, phase and oscillatory hippocampal recall. Advances in
Neural Information Processing (2007).
[11] Neal, R.M. Sampling from multimodal distributions using tempered transitions. Statistics and
Computing 6, 353?366 (1996).
[12] Fukai, T. & Tanaka, S. A simple neural network exhibiting selective activation of neuronal
ensembles: from winner-take-all to winners-share-all. Neural computation 9, 77?97 (1997).
[13] Bogacz, R. & Gurney, K. The basal ganglia and cortex implement optimal decision making
between alternative actions. Neural computation 19, 442?477 (2007).
[14] Xiang, J.Z. & Brown, M.W. Differential neuronal encoding of novelty, familiarity and recency
in regions of the anterior temporal lobe. Neuropharmacology 37, 657?676 (1998).
[15] Rasmussen, C.E. & Williams, C.K.I. Gaussian Processes for Machine Learning (MIT Press,
2006).
[16] Warburton, E.C. & Brown, M.W. Findings from animals concerning when interactions between perirhinal cortex, hippocampus and medial prefrontal cortex are necessary for recognition memory. Neuropsychologia 48, 2262?2272 (2010).
[17] Yonelinas, A.P. Components of episodic memory: the contribution of recollection and familiarity. Philosophical Transactions of the Royal Society B: Biological Sciences 356, 1363?1374
(2001).
[18] Yonelinas, A. The nature of recollection and familiarity: A review of 30 years of research.
Journal of memory and language 46, 441?517 (2002).
[19] Iba, Y. Extended ensemble Monte Carlo. Int. J. Mod. Phys 12, 653?656 (2001).
[20] Bogacz, R. Comparison of computational models of familiarity discrimination in the perirhinal
cortex. Hippocampus (2003).
[21] Mitchell, S. Shunting inhibition modulates neuronal gain during synaptic excitation. Neuron
(2003).
[22] Fortin, N.J., Wright, S.P. & Eichenbaum, H. Recollection-like memory retrieval in rats is
dependent on the hippocampus. Nature 431, 188?191 (2004).
[23] Cowell, R., Winters, B., Bussey, T. & Saksida, L. Paradoxical false memory for objects after
brain damage. Science (2010).
[24] Norman, K. & O?Reilly, R. Modeling hippocampal and neocortical contributions to recognition
memory: A complementary-learning-systems approach. Psychological Review (2003).

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 353-self-organization-of-hebbian-synapses-in-hippocampal-neurons.pdf

Self-organization of Hebbian Synapses
in Hippocampal Neurons

Thomas H. Brown,t Zachary F. Mainen,t Anthony M. Zador,t and Brenda J. Claiborne?

t Department of Psychology

? Division of Life Sciences

Yale University

University of Texas

New Haven, cr 06511

San Antonio, TX 78285

ABSTRACT
We are exploring the significance of biological complexity for neuronal
computation. Here we demonstrate that Hebbian synapses in realistically-modeled hippocampal pyramidal cells may give rise to two novel
forms of self-organization in response to structured synaptic input. First,
on the basis of the electrotonic relationships between synaptic contacts,
a cell may become tuned to a small subset of its input space. Second, the
same mechanisms may produce clusters of potentiated synapses across
the space of the dendrites. The latter type of self-organization may be
functionally significant in the presence of nonlinear dendritic conductances.

1 INTRODUCTION
Long-term potentiation (LTP) is an experimentally observed form of synaptic plasticity
that has been interpreted as an instance of a Hebbian modification (Kelso et al, 1986;
Brown et al, 1990). The induction ofLTP requires synchronous presynaptic activity and
postsynaptic depolarization (Kelso et al, 1986). We have previously developed a detailed
biophysical model of the LTP observed at synapses onto hippocampal region CAl pyrami-

39

40

Brown, Mainen, Zador, and Claiborne

Figure 1: Two-dimensional projection of a reconstructed hippocampal CAl pyramidal cell.

dal neurons (Zador et al, 1990). The synapses at which this form of LTP occurs are distributed across an extensive dendritic arbor (Fig. 1). During synaptic stimulation, the
membrane voltage at each synapse is different. In this way, a biological neuron differs

from the processing elements typically used in neural network models, where the postsynaptic activity can be represented by a single state variable. We have developed an electrotonic model based on an anatomically reconstructed neuron. We have used this model to
explore how the spatial distribution of inputs and the temporal relationships of their activation affect synaptic potentiation.

2 THE NEURONAL MODEL
Standard compartmental modeling techniques were used to represent the electrical structure of hippocampal CAl pyramidal cells.
2.1 MORPHOLOGY AND ELECTRICAL PARAMETERS

Morphometric data were obtained from three-dimensional reconstructions (Brown et al.,
1991) of hippocampal neurons (Fig. 1). A correction factor was applied to the membrane
area based on an estimate for spine density of 2/llm. The original measurements divided
a single neuron into 3000-4000 cylinders with an average length of 5.5 J.1m. For simulation
purposes, this structure was collapsed into 300-400 compartments, preserving the connectivity pattern and changes in process diameter. Electrical constants were Rm = 70 ID-cm 2,
em= 1 JlF'lcrrll, Ri = 200 n-cm (Spruston & Johnston 1990). The membrane was electrically passive. Synaptic currents were modeled as the sum of fast AMPA and slow NMDA
conductances on the head of a two-compartment spine (Zador et al., 1990). The AMPA
conductance was represented by an alpha function (Jack et al., 1975) with time constant of
1.5 msec (Brown and Johnston, 1983). The NMDA conductance was represented by a
more complicated function with two time constants and a voltage dependence due to voltage-sensitive channel blocking by Mg2+ ions (see Zador et aI., 1990; Brown et al. 1991).
The initial peak conductances, gAMPA and gNMDA' were set to 0.5 and 0.1 nS respectively.

Self-organization of Hebbian Synapses in Hippocampal Neurons
2.2 SIMULATION AND SYNAPTIC MODIFICATION

Simulations were run on a Sun 4/330 workstation using a customized version of NEURON.
a simulator developed by Michael Hines (Hines. 1989). Prior to a simulation. 5 patterns of
40 synapses were selected at random from a pool of synapses distributed unifonnly over
the apical and basal dendrites. Simulations were divided into trials of 100 msec. At the
beginning of each trial a particular pattern of synapses was activated synchronously (3
stimuli at intervals of 3 msec). The sequential presentation of all 5 selected patterns
constituted an epoch. An entire simulation consisted of 20 presentation epochs. Over the
course of each trial. membrane potential was computed at each location in the dendritic
tree. and these voltages were used to compute weight changes .!\Wij according to the
Hebbian algorithm described below. After each trial. the actual peak AMPA conductances
(gAMPA. hereafter denoted g$1J were scaled by the sigmoidal function
gmax

(1)

where 0' detennines the steepness of the sigmoid. and gfM% was set to 1.0 nS.
The rule for synaptic modification was based on a biophysical interpretation (Kairiss et aI .?
1991; Brown et aI .? 1991) of a generalized bilinear fonn of Hebbian algorithm (Brown et
aI.? 1990):

(2)
where a. ~. and 'Y are functionals.l) is a constant. a.(t) represents postsynaptic activity and
a .(t) represents presynaptic activity. This equation specifies an interactive fonn of synaptic
ehhancement combined with three noninteractive forms of synaptic depression, all of
which have possible neurobiological analogs (Brown et aI. 1990). The interactive tenn was
derived from a biophysical model of LTP induction in a spine (Zador et aI'21990). A simplified version of this model was used to compute the concentration of Ca +-bound calmodulin. [CaM-C84]. It has been suggested that CaM-C84 may trigger protein kinases
responsible for LTP induction. In general [CaM-C8.4] was a nonlinear function of subsynaptic voltage (Zador et al .? 1990).
The biophysical mechanisms underlying synaptic depression are less well understood. The
constant l) represents a passive decay process and was generally set to zero. The functional
~ represents heterosynaptic depression based on postsynaptic activity. In these simulations, ~ was proportional the amount of depolarization of the subsynaptic membrane from
resting potential (V$111 - V ). The functional 'Y represents homosynaptic depression based
on presynaptic activity. Were. 'Y was proportional to the AMPA conductance. which can
be considered a measure of exclusively presynaptic activity because it is insensitive to
postsynaptic voltage. The three activity-dependent tenns were integrated over the period
of the trial in order to obtain a measure of weight change. Reinterpreting a. ~. and 'Yas constants. the equation is thus:
.!\Wij

=

f
"ial

[a [CamCa 4] -

~ (V.rYII- V,..,,)

- 'YgAMPA -l)] dt.

(3)

41

42

Brown, Mainen, Zador, and Claiborne
-40

-40

-40

-60

-60

-80 IL.-_ _ __

o

............ .

-====

-801.:..':_'

o

tOO

50

: ....... .

:...

m.sec

50

tOO

m.sec

................................................

....

. ...... .... .. -............ ......

-80~~~~~~~~~~~~~~~~~~

o

5

10

15

20

epochs
Figure 2: Interactions among Hebbian synapses produce differing global effects ("winning" and
"losing" patterns) on the basis of the spatial distribution of synapses. The PSP (always measured
at the soma) due to two different patterns of 40 synapses are plotted as a function of the presentation
epoch. Initially, pattern 1 (solid line) evoked a slightly greater PSP than pattern 2 (dotted line; inset, top right). Mter 20 epochs these responses were reversed: thePSP due to pattern 1 was depressed while the PSP due to pattern 2 was potentiated (inset, top left).

3 RESULTS
Analysis of the simulations revealed self-organization in the form of differential modification of synaptic strengths (Mainen et al. 1990). Two aspects of the self-organization phenomena were distinguished. In some simulations, a form of pattern selection was observed
in which clear "winners" and "losers" emerged. In other simulations, the average synaptic
efficacy remained about the same, but spatial heterogeneities~lustering~f synaptic
strength developed. Different measures were used to assess these phenomena.
3.1 PATTERNSELECTION

The change in the peak postsynaptic potential recorded at the soma (P SP) provided one useful measure of pattern selection. In many simulations, pattern selection resulted in a
marked potentiation of the PSP due to some patterns and a depression of the PSP due to
others. The PSP can be regarded as an indirect measure of the functional consequence of
self-organization. In the simulation illustrated in Fig. 2, patterns of 40 synapses produced
an average PSP of 15 mV before learning. After learning, responses ranged from 10% to
150% of this amount Underlying.pattern selection was a ch8!!ge in the average peak synaptic conductance for the patterng8YIIO).1 The initial value of g8YII was .!he same for all patterns, and its final value was bounded by eq. 1. In many simulations, g8YII approached the
upper bound for some patterns and the lower bound for other patterns (Fig. 3). In this way,
the neuron became selectively tuned to a subset of its original set of inputs. The specificity

Self-organization of Hebbian Synapses in Hippocampal Neurons
1.0

!

....... ..... .....

............................

0.5/?????????????????????????

~

~

o

5

10

15

20

epochs
Figure 3. The mean synaptic conductance gSy"of two patterns is plotted as a function of the presentation epoch. Both patterns began with iaenucal total synaptic strength (40 synapses with gs,r& =
0.5 nS). Synaptic conductances were constrained to the range [0.0, 1.0] nS. Mter twenty epochs,
gSY" of pattern 1 (solid line) approached the minimum ofO.OnS while gsy" of pattern 2 (dotted line)
approached the maximum of 1.0 nS.

of this tuning was dependent on the parameter values of the neuronal model, learning rule,
and stimulus set.
3.2 CLUSTER FORMAnON

Heterogeneity in the spatial distribution of strengthened and weakened synapses was often
observed. After learning, spatial clusters of synapses with similar conductances formed.
These spatial heterogeneities can be illustrated in several ways. In one convenient method
(see Brown et al., 1991), synapses are represented as colored points superimposed on a rendition of the neuronal morphology as illustrated in Fig. 1. By COlor-coding gsyn for each
synapse in a pattern, correlations in synaptic strength across dendritic space are immediately apparent. In a second method, better suited to the monochrome graphics available in the
present text, the evolution of the variance of gsyn is plotted as a function of time (Fig. 4).
In the simulation illustrated here, the increase in variance was due to the formation of a single, relatively large cluster of strengthened synapses. Within other parameter regimes, multiple clusters of smaller size were formed.

4

DISCUSSION

The important differences between synaptic modifications in the biophysically-modeled
neuron and those in simple processing elements arise from voltage gradients present in the
realistic model (Brown et aI., 1991; Kairiss et al., 1990). In standard processing elements,

g

1 Although SJ" and the somatic PSP were generally correlated, the relationship between the two is
not linear, as was often evident in simulations (compare initial trials in Figs. 2 and 3).

43

44

Brown, Mainen, Zador, and Claiborne
1.0

--_.-._--.-.----_._._.--_.

til

b

o. 0

"'""""'-----'--'--"---'~.............-'--~--'---''__'_...........__'

L-..-...........

o

5

10

15

20

epochs
Figure 4: Synaptic heterogeneity is indicated by increases in the variance (02) of the set of synaptic
conductances for each pattern. The variances of the peak synaptic conductances. (g'l,J of 4 patterns
are plotted as ajy)lction of the epoch. The variance of all 4 patterns approached the theoretical
maximum of JO.5. In this parameter regime, the variance was due to the potentiation of a single
large cluster of synapes combined with the depression of other synapses.

a single state variable represents postsynaptic activity. In contrast, the critical subsynaptic
voltages which represent postsynaptic activity in the neuron are correlated but are not strictly equal. The structure and electrical properties of the cell interact with its synaptic input
to detennine the precise spatiotemporal pattern of membrane voltage. Thus, the voltage at
any synapse depends strongly on its electrotonic relationships to other active synapses. The
way in which this local depolarization affects the nature of self-organization depends on the
specific mechanisms of the synaptic modification rule. We have modeled a pair of opposing voltage-dependent mechanisms. An interactive potentiation mechanism (the functional
ex) promotes cooperativity between spatially proximal synapses with temporally correlated
activity. A heterosynaptic depression mechanism (the functional P), which is independent
of presynaptic activity, promotes competition among spatially proximal synapses.
Through mechanisms such as these, the specific electrotonic structure of a neuron predetennines a complex set of interactions between any given spatial distribution of synaptic
inputs. We have shown that these higher-order interactions can give rise to self-organization with at least two interesting effects.
4.1 SPARSE REPRESENTATION

The phenomenon of pattern selection demonstrates how Hebbian self-organization may
naturally tune neurons to respond to a subset of their input space. This tuning mechanism
might allow a large field of neurons to develop a sparse coding of the activity in a set of
input fibers, since each neuron would respond to a particular small portion of the input
space. Sparse coding may be advantageous to associative learning and other types of neural
computation (Kanerva, 1988).

Self-organization of Hebbian Synapses in Hippocampal Neurons

4.2 CLUSTERING AND NONLINEAR COMPUTATION
The fonnation of clusters of strengthened synapses illustrates a property of Hebbian selforganization whose functional significance might only be appreciated in the presence of
nonlinear (voltage-dependent) dendritic conductances. We have examined the self-organization process in an electrically passive neuron. Under these conditions, the presence of
clustering within patterns has little effect on the observed output. In fact, it is known that
hippocampal cells of the type modeled possess a variety of spatially heterogeneous nonlinear dendritic conductances (Jones et al., 1989). The computational role of such nonlinearities is just beginning to be explored. It is possible that interactions between synaptic
clustering and nonlinear membrane patches may significantly affect both the perfonnance
of dendritic computations and the process of self-organization itself.
Acknowledgments
This research was supported by grants from the Office of Naval Research, the Defense Advanced Research Projects Agency, and the Air Force Office of Scientific Research.
References
Brown, T .H. and Johnston, D. (1983) Voltage-clamp analysis of mossy fiber synaptic input
to hippocampal neurons. J. Neurophysiol. SO: 487-507.
Brown, T.H., Kairiss, E.W. and Keenan, C.L. (1990) Hebbian synapses: biophysical mechanisms and algorithms. Annu. Rev. Neurosci. 13: 475-512.
Brown, T.H., Zador, A.M., Mainen, Z.F. and Claiborne, BJ. (1991) Hebbian modifications
in hippocampal neurons. In J. Davis and M. Baudry (eds.), LTP: A Debate of Current Issues (Cambridge, MA: MIT Press).
Hines, M. (1989) A program for simulation of nerve equations with branching geometries.
Int. J. Bio-Med Comp 24: 55-68.
Jack, J., Noble, A. and Tsien, R.W. (1975) Electrical Current Flow in Excitable Membranes (London: Oxford Univ. Press).
Jones, O.T., Kunze, D.L and Angelides, KJ. (1989) Localization and mobility ofw-conotoxin-sensitive Ca2+ channels in hippocampal CAl neurons. Science 244: 1189-1193.
Kairiss, E.W., Mainen, Z.F., Claiborne, BJ. and Brown, T.H. (1991) Dendritic control of
hebbian compuations. In F. Eeckman (ed.), Analysis and Modeling of Neural Systems
(Boston, MA: Kluwer Academic Publishers).
Kanerva, P. (1988) Sparse distributed memory. (Cambridge, MA: MIT Press).
Kelso, S.R., Ganong, Brown, T.H. (1986) Hebbian synapses in hippocampus. Proc. Natl.
Acad. Sci. USA 83: 5326-5330.
Mainen, Z.M., Zador, A.M., Claiborne, B. and Brown, T.H. (1990) Hebbian synapses induce feature mosaics in hippocampal dendrites. Soc. Neurosci. Abstr. 16: 492.
Spruston, N. and Johnston, D. (1990) Whole-cell patch clamp analysis of the passive membrane properties of hippocampal neurons. Soc. N eurosci. Abstr. 16: 1297.
Zador, A., Koch, C. and Brown, T.H. (1990) Biophysical model of a hebbian synapse.
Proc. Natl. Acad. Sci. USA 87: 6718-6722.

45


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 526-oscillatory-model-of-short-term-memory.pdf

Oscillatory Model of Short Term Memory

David Horn
School of Physics and Astronomy
Raymond and Beverly Sackler
Faculty of Exact Sciences
Tel-Aviv University
Tel Aviv 69978, Israel

Marius U sher*
Dept. of Applied Mathematics
and Computer Science
Weizmann Institute of Science
Rehovot 76100, Israel

Abstract
We investigate a model in which excitatory neurons have dynamical thresholds which display both fatigue and potentiation. The fatigue property
leads to oscillatory behavior. It is responsible for the ability of the model
to perform segmentation, i.e., decompose a mixed input into staggered
oscillations of the activities of the cell-assemblies (memories) affected by
it. Potentiation is responsible for sustaining these staggered oscillations
after the input is turned off, i.e. the system serves as a model for short
term memory. It has a limited STM capacity, reminiscent of the magical
number 7 ? 2.

1

Introduction

The limited capacity (7 ? 2) of the short term memory (STM) has been a subject
of major interest in the psychological and physiological literature. It seems quite
natural to assume that the limited capacity is due to the special dynamical nature
of STM. Recently, Crick and Koch (1990) suggested that the working memory
is functionally related to the binding process, and is obtained via synchronized
oscillations of neural populations. The capacity limitation of STM may then result
from the competition between oscillations representing items in STM. In the model
which we investigate this is indeed the case.
?Present address: Division of Biology, 216-76, Caltech, Pasadena CA 91125.

125

126

Horn and Usher

Models of oscillating neural networks can perform various tasks:

1. Phase-locking and synchronization in response to global coherence in the stimuli, such as similarity of orientation and continuity (Kamen et al. 1989; Sompolinsyet al. 1990; Konig & Schillen 1991).
2. Segmentation of incoherent stimuli in low level vision via desynchronization,
using oscillator networks with delayed connections (Schillen & Konig 1991).
3. Segmentation according to semantic content, i.e., separate an input of mixed information into its components which are known memories of the system (Wang
et al. 1990, Horn and Usher 1991). In these models the memories are represented by competing cell a.'3semblies. The input, which affects a subset of these
assemblies, induces staggered oscillations of their activities. This works as long
as the number of memories in the input is small, of the order of 5.
4. Binding, i.e., connecting correctly different attributes of the same object which
appear in the mixed input (Horn et al. 1991). Binding can be interpreted as
matching the phases of oscillations representing attributes of the same object
in two different networks which are coupled in a way which does not assume
any relation between the attributes.
To these we add here the important task of
5. STM, i.e., keeping information about segmentation or binding after the input
is turned off.
In order to qualify as models for STM, the staggered oscillations have to prevail
after the input stimuli disappear. Unfortunately, this does not hold for the models
quot.ed above. Once the input disappears, either the network's activity dies out,
or oscillations of assemblies not included in the original input are turned on. In
other words, the oscillations have no inertia, and thus they do not persist after the
disappearance of the sensory input. Our purpose is to present a model of competing neural assemblies which, upon receiving a mixed input develops oscillations
which prevail after the st.imulus disappears. In order to achieve this, the biological
mechanism of post tetanic potentiation will be used.

2

Dynaillics of Short Ternl Potentiation

It was shown that following a t.etanus of electrophysiological stimulation temporary
modifications in the synaptic strengths, mostly non Hebbian, are observed (Crick
and Koch, 1990; Zucker, 1989). The time scale of these synaptic modifications
ranges between 50 111S to several minutes. A detailed description of the processes
responsible for this mechanism was given by Zucker (1989), exhibiting a rather complex behavior. In the following we will use a simplified version of these mechanisms
involving two processes with different time scales. We assume that following a prolonged activation of a synapse, the synaptic strength exhibits depression on a short
time scale, but recovers and becomes slightly enhanced on a longer time scale. As
illustrated in Fig 1 of Zucker (1989), this captures most of the dynamics of Short
Term Potentiation. The fact that these mechanisms are non Hebbian implies that
all synapses associated with a presynaptic cell are affected, and thus the unit of
change is the presynaptic cell (Crick & Koch 1990).

Oscillatory Model of Shorr Term Memory

Our previous oscillatory neural networks were based on the assumption that, in
addition to the customary properties of the formal neuron, its threshold increases
when the neuron keeps firing, thus exhibiting adaptation or fatigue (Horn & Usher
1989). Motivated by the STP findings we add a new component offacilitaion, which
takes place on a longer time scale than fatigue. We denote the dynamical threshold
by the continuous variable r which is chosen as a sum of two components, I and p,
representing fatigue and potentiation,
(1)

= all - a2p?

r

Their dynamics is governed by the equations

,dl/dt =

m

+ (l/CI

,dp/dt =

1)1

-

m

+ (1/c2 -

l)p

(2)

where m describes the average neuron activity (firing rate) on a time scale which
is large compared to the refractory period. The time constants of the fatigue and
potentiation components, Tj = c,c:' l are chosen so that TI < T2. As a result the
neuron displays fatigue on a short time scale, but recovers and becomes slightly
enhanced (potentiated) on a longer time scale. This is clearly seen in Fig. 1, which
shows the behavior when the activity m of the corresponding neuron is clamped at
1 for some time (due to sensory input) and quenched to zero afterwards.

3

_. -.
,,-

2

\

/

\f

I

\

r

\

1

,
"

.....
"-

.-.- . -. -.-

0
\
'\
'\
'\

-1

-2

""
0

.........

p. . . .
.......

....- ..-

./

.......

.......
./

40

20

60

100

80

time
Figure 1: Behavior of the dynamic threshold r and its fatigue

I and potentiation

p components, when the neuron activity m is clamped as shown. Time scale is

arbitrary. The parameters are

CI

= 1.2 C2 =

1.05

al

= 4 a2 = 1 .

We observe here that the threshold increases during the cell's activation, being
driven to its asymptotic value al c1-I.
After the release of the stimulus the dyCl
namic threshold decreases (i.e . the neuron recovers) and turns negative (signifying

127

128

Horn and Usher

potentiation). The parameters were chosen so that asymptotically the threshold
reaches zero, i.e. no permanent effect is left. In our model we will assume a similar
behavior for the excitatory cell-assemblies which carry the memories in our system.

3

The Model

Our basic model (Horn & Usher 1990) is composed of two kinds of neurons which
are assumed to have excitatory and inhibitory synapses exclusively. Memory patterns are carried by excitatory neurons only. Furthermore, we make the simplifying
assumption that the patterns do not overlap with one another, i.e. the model is
composed of disjoint Hebbian cell-assemblies of excitatory neurons which affect one
another through their interaction with a single assembly of inhibitory neurons.
Let us denote by mS'(t) the fraction of cell-assembly number Il which fires at time t,
and by m I (t) the fraction of active inhibitory neurons. We will refer to mS' as the
activity of the Ilth memory pattern. There are P different memories in the model,
and their activities obey the following differential equations

= -mS' + FT(AmS' -

Bm I - f}S' + is')
dmI/dt == -m I + FT(CM - Dm I - f}I)

(3)

M= LmS'
S'

(4)

dmS' /dt
where

f}S' and f}I are the thresholds of all excitatory and inhibitory neurons correspondingly
and is' represents the input into cell assembly Il. The four parameters ABC and
D are all positive and represent the different couplings between the neurons. This
system is an attractor neural network. In the absence of input and dynamical
thresholds it is a dissipative system which flows into fixed points determined by the
memOrIes.
This system is a generalization of the E-I model of Wilson and Cowan (1972) in
which we have introduced competing memory patterns. The latter make it into an
attractor neural network. Wilson and Cowan have shown that a pair of excitatory
and inhibitory assemblies, when properly connected, will form an oscillator. We
induce oscillations in a different way, keeping the option of having the network
behave either as an attractor neural network or as an oscillating one: we turn the
thresholds of the excitatory neurons into dynamic variables, which are defined by

f}S' = f}t;

+ brS' .

The dynamics of the new variables rS' are chosen to follow equations (1) and (2)
where all elements, r f p and m refer to the same cell-assembly 1-'. To understand
the effects of this change let us first limit ourselves to the fatigue component only,
1 and a2 = 0 in Eq. 1. Imagine a situation in which the system would flow
i.e. a1
into a fixed point mS'
1. rS' will then increase until it reaches the value cI/( C1 -1).
This means that the argument of the FT function in the equation for mS' decreases
by 9 = bCI/(Cl - 1) . If this overcomes the effect of the other terms the amplitude
mS' decreases and the system moves out of the attractor and falls into the basin
of a different center of attraction. This process can continue indefinitely creating

=

=

Oscillatory Model of Short Term Memory

an oscillatory network which moves from one memory to another. Envisage now
turning on a p/lo component leading to an r/lo behavior of the type depicted in Fig.
1. Its effect will evidently be the same as the input i/lo in Eq. (3) during the time
in which it is active. In other words, it will help to reactivate the cell-assembly /-l,
thus carrying the information that this memory was active before. Therefore, its
role in our system is to serve as the inertia component necessary for creating the
effect of STM.

4

Seglnentation and Short Term Memory

In this section we will present. results of numerical investigations of our model. The
parameters used in the following are A = C = D = 1 B = 1.10t; = 0.075 OJ =
-0.55 T = 0.05 b = 0.2 I = 2.5 and the values of ai and Ci of Fig. 1. We let n of the
P memories have a constant input of the form
i/lo

=i

/-l

= 1"

.. , n

=0

i/lo

/-l = n

+ 1,?,?, P.

(5)

An example of the result. of a system with P = 10 and n = 4 is shown in Fig. 2.

1.0 ,...

0.8

-

U1

\l.)
.....
o+J
.....
:>
.....
o+J

CJ

CO

I

,
,.,,11/
" 11? ,\ ,I ""
I
'\'
:
I
I
"
I
. ? '.
I ? .f ??
..
,

'I::

II,?::

0.6 - ,',."

. ",

,. . ., ,I,?:.
0.4 I - / '"t ? I l" r'::
.

.,

tr1

0.2

~

0.0

,

"

;
?

I

t ~

I.

oj

I,!.

I

"

::
"

.'
..
.'

,

1,1 ?

I ~r \

':

"

'

I ~

,\ ,I~I.\.
'.\1J\ ."\.1\t:.).,~~.: \ '.. 1.\,

::

.:

,

A :.

.,11::
I,

-

I

I

I

\<

., I ,'.
"1 1<

. I:

~

1 I

?

I, ::..
,,::
II
"
,.1,::
"~"

,.

'I, "

"

"

,.,,::

I,

'.

I.

\ ..

, ,I I' ,
.
" ' , \,1 I: :
I"

"

,

,,' I:: " :: '\/ I: .
',~~: I~I~"~'

Il'l

~.

"\.;~.'" ?

11,\.t
I, ~

~'" _'

',J\..J ~ '_'l

' ,

?

.A.

---------C>

4

3
2

1

a
a

25

75

50

100

125

time
Figure 2: Result.s of our model for P = 10 memories and n = 4 inputs. The first
frame displays the activities m of the four relevant cell-assemblies, and the second
frame represents their l' values. The arrow indicates the duration of the mixed
input.

129

130

Horn and Usher

Here we display the activities of the cell-assemblies that receive the constant input
and their corresponding average thresholds. While the signal of the mixed input
is on (denoted by an arrow along the time scale) we see how the phenomenon of
segmentation develops. The same staggered oscillation of the four cell-assemblies
which received an input is sustained after the signal is turned off. This indicates that
the system functions as a STM. Note that no synaptic connections were changed
and, once the system will receive a new input its behavior will be revised. However,
as long as it is left alone, it will continue to activate the cell-assemblies affected by
the original input.
We were able to obtain good results only for low n values, n ::; 4. As n is increased
we have difficulties wit.h both segmentation and STM. By modifying slightly the
paradigm we were able to feed 5 different inputs in a STM, as shown in Fig. 3.
This required presenting them at different times, as indicated by the 5 arrows on this
figure. In other words, t.his system does not perform segmentation but it continues
to work as a STM. Note, however, that the order of the different activities is no
longer maintained after the stimuli are turned off.

1.0

.-.-

I

0.8

tZl
tl)

~

.-

>

~

C)

ttl

0.6

.

....

II

, I ? l\
I ,? ?
?
?? ???
,:? ???.
I I

I

0.4

:

\:

0.2

.

:"':

? ;i
,

?:
-;

. /1 .
'1. ,I
I I ,I
., . ,
II
?? ..

.'

1

.'.

I' ::

;; :~

,?

0.0

o
o

25

75

50

100

125

time
Figure 3: Result.s for 5 inputs which are fed in consecutively at the times indicated
by the short arrows. The model functions as STM without segmentation.

Oscillatory Model of Short Term Memory

5

Discussion.

Psychological experiments show that subjects can repeat a sequence of verbal items
in perfect order a.'l long as their number is small (7 ? 2). The items may be numbers
or let.ters but can also be combinations of the latter such as words or recognizable
dates or acronyms. This proves that STM makes use of the encoded material in the
long term memory (Miller 1956). This relation between the two different kinds of
memOt'y lies in the basis of our model. Long term memory is represented by excitatory cell assemblies . Incorporating threshold fatigue into the model, it acquires the
capability of performing temporal segmentation of external input. Adding to the
threshold post tetanic potentiation, the model becomes capable of maintaining the
segmented information in the form of staggered oscillations. This is the property
which we view as responsible for STM.
Both segmentation and STM have very limited capacities. This seems to follow
from t.he oscillatory nature of the system which we use to model these functions.
In contrast with long term memory, whose capacity can be increased endlessly by
adding neurons and synaptic connections, we find here that only a few items can
be st.ored in t.he dynamic fashion of staggered oscillations, irrespective of the size
of the system. Vve regard this result as very significant, in view of the fact that
the same holds for the limited psychological ability of attention and STM. It may
indicate t.hat the oscillatory model contains the key to the understanding of these
psychological findings.
In order to validate the hypothesis that STM is based on oscillatory correlations
between firing rates of neurons, some more experimental neurobiological and psychophysical research is required. While no conclusive results were yet obtained from
recordings of t.he cortical activity in the monkey, some positive support has been obtained in psychophysical experiments. Preliminary results show that an oscillatory
component can be found in the percentage of correct responses in STM matching
experiments (Usher & Sagi 1991).
Our mathematical model is based on many specific assumptions. We believe that
our main results are characteristic of a class of such models which can be obtained
by changing various elements in our system. The main point is that dynamical
storage of information can be achieved through staggered oscillations of memory
activit.ies. Moreover, to sustain them in the absence of an external input, a potentiation capability ha.'l to be present. A model which contains both should be able
to accomodate STM in t.he fashion which we have demonstrated.
A cknowledgenlent s

M. Usher is the recipient of a Dov Biegun post-doctoral fellowship. We wish to
thank S. Popescu for helpful discussions.
References

Crick,F. & Koch,C. 1990. Towards a neurobiological theory of consciousness. Seminars in the Neurosciences 2, 263-275.

131

132

Horn and Usher

Horn,D., Sagi,D. & Usher,M. 1991. Segmentation, binding and illusory conjunctions. Neural Compo 3, 509-524.
Horn,D. & Usher ,M. 1989. Neural networks with dynamical thresholds, Phys. Rev.
A 40, 1036-1044.
Horn,D. & Usher,M. 1990. Excitatory-inhibitory networks with dynamical thresholds, Int. 1. NeuralSyst. 1, 249-257.
Horn,D. & Usher ,M. 1991. Parallel Activation of Memories is an Oscillatory Neural
Network. Neural Compo 3, 31-43.
Kammen,D.M., Holmes,P.J. & Koch C. 1990. Origin of oscillations in visual cortex:
Feedback versus local coupling. In Models of Brain Function, M.Cotterill ed., pp
273-284. Cambridge University Press.
Konig,P. & Schillen,T.B. 1991. Stimulus-dependent assembly formation of oscillatory responses: I. Synchronization, Neural Compo 3, 155-166.
Miller,G. 1956. The magical number seven plus minus two. Psych. Rev., 63,81-97.
Sompolinsky,H., Golomb,D. & Kleinfeld,D. 1990. Global processing of visual stimuli
in a neural network of coupled oscillators. Proc. Natl. Acad. of Sci. USA, 87,
7200-7204.
Schillen,T.B. & Konig,P. 1991. Stimulus-dependent assembly formation of oscillatory responses: I. Synchronization, Neural Compo 3, 155-166.
Wang,D., Buhmann,J. & von der Malsburg,C. 1990. Pattern segmentation in associative memory. Neural Compo 2, 94-106.
Wilson,H .R. & Cowan,J .D. 1972. Excitatory and inhibitory interactions in localized
populations of model neurons. Biophys. 1. 12, 1-24.
Usher,M. & Sa.gi D. 1991, in preparation.
Zucker ,R.S. 1989. Short-term synaptic plasticity. Ann. Rev. Neurosci. 12, 13-31.

PART III

SPEECH


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1658-spike-based-learning-rules-and-stabilization-of-persistent-neural-activity.pdf

Spike-based learning rules and stabilization of
persistent neural activity

Xiaohui Xie and H. Sebastian Seung
Dept. of Brain & Cog. Sci., MIT, Cambridge, MA 02139
{xhxie, seung}@mit.edu

Abstract
We analyze the conditions under which synaptic learning rules based
on action potential timing can be approximated by learning rules based
on firing rates. In particular, we consider a form of plasticity in which
synapses depress when a presynaptic spike is followed by a postsynaptic
spike, and potentiate with the opposite temporal ordering. Such differential anti-Hebbian plasticity can be approximated under certain conditions
by a learning rule that depends on the time derivative of the postsynaptic
firing rate. Such a learning rule acts to stabilize persistent neural activity
patterns in recurrent neural networks.

1 INTRODUCTION
Recent
experiments
have
demonstrated types of synaptic
~re 11111111111 111111111111111111
plasticity that depend on the
post 11111111111 11111111? ?11.
A
temporal ordering of presynaptic and postsynaptic spiking. At
B 0L-.i
cortical [ I] and hippocampal[2]
t .:oLl____
o
synapses, long-term potenti1000
2000
tpost - tpre
time (ms)
ation is induced by repeated
pairing of a presynaptic spike
Figure I: (A) Pairing function for differential Heband a succeeding postsynaptic
bian learning. The change in synaptic strength is plotspike, while long-term deprested
versus the time difference between postsynaptic
sion results when the order
and
presynaptic spikes. (B) Pairing function for difis reversed. The dependence
ferential anti-Hebbian learning. (C) Differential antiof the change in synaptic
Hebbian learning is driven by changes in firing rates.
strength on the difference
The
synaptic learning rule of Eq. (l) is applied to two
l:!..t = tpost - tpre between
Poisson spike trains. The synaptic strength remains
postsynaptic and presynaptic
roughly constant in time, except when the postsynapspike times has been measured
tic rate changes.
quantitatively.
This pairing
function, sketched in Figure
lA, has positive and negative lobes correspond to potentiation and depression. and a
width of tens of milliseconds. We will refer to synaptic plasticity associated with this
pairing function as differential Hebbian plasticity-Hebbian because the conditions for

o~i=~=::====:

_:3/_-----'

?

\:;J
__~

X Xie and H. S. Seung

200

potentiation are as predicted by Hebb[3], and differential because it is driven by the
difference between the opposing processes of potentiation and depression.
The pairing function of Figure IA is not characteristic of all synapses. For example, an
opposite temporal dependence has been observed at electrosensory lobe synapses of electric fish[4]. As shown in Figure IB, these synapses depress when a presynaptic spike is
followed by a postsynaptic one, and potentiate when the order is reversed. We will refer to
this as differential anti-Hebbian plasticity.
According to these experiments, the maximum ranges of the differential Hebbian and antiHebbian pairing functions are roughly 20 and 40 ms, respectively. This is fairly short, and
seems more compatible with descriptions of neural activity based on spike timing rather
than instantaneous firing rates[5, 6]. In fact, we will show that there are some conditions
under which spike-based learning rules can be approximated by rate-based learning rules.
Other people have also studied the relationship between spike-based and rate-based learning rules[7, 8].
The pairing functions of Figures IA and IB lead to rate-based learning rules like those
traditionally used in neural networks, except that they depend on temporal derivatives of
firing rates as well as firing rates themselves. We will argue that the differential antiHebbian learning rule of Figure IB could be a general mechanism for tuning the strength
of positive feedback in networks that maintain a short-term memory of an analog variable
in persistent neural activity. A number of recurrent network models have been proposed
to explain memory-related neural activity in motor [9] and prefrontal [ 10] cortical areas,
as well as the head direction system [11] and oculomotor integrator[ 12, 13, 14]. All of
these models require precise tuning of synaptic strengths in order to maintain continuously
variable levels of persistent activity. As a simple illustration of tuning by differential antiHebbian learning, a model of persistent activity maintained by an integrate-and-fire neuron
with an excitatory autapse is studied.

2 SPIKE-BASED LEARNING RULE
Pairing functions like those of Figure 1 have been measured using repeated pairing of a
single presynaptic spike with a single postsynaptic spike. Quantitative measurements of
synaptic changes due to more complex patterns of spiking activity have not yet been done.
We will assume a simple model in which the synaptic change due to arbitrary spike trains is
the sum of contributions from all possible pairings of presynaptic with postsynaptic spikes.
The model is unlikely to be an exact description of real synapses, but could turn out to be
approximately valid.
We will write the spike train of the ith neuron as a series of Dirac delta functions, Si (t) =
<5(t - Tr), where Tr is the nth spike time of the ith neuron. The synaptic weight from
neuron j to i at time t is denoted by W ij (t). Then the change in synaptic weight induced
by presynaptic spikes occurring in the time interval [0, Tj is modeled as

Ln

Wij(T

+ >.)

- Wij(>')

= [T dtj

io

foo dti f(ti - tj)Si(ti) Sj(tj)

(1)

-00

Each presynaptic spike is paired with all postsynaptic spikes produced before and after.
For each pairing, the synaptic weight is changed by an amount depending on the pairing
function f. The pairing function is assumed to be nonzero inside the interval [-T, Tj, and
zero outside. We will refer to T as the pairing range.
According to our model, each presynaptic spike results in induction of plasticity only after
a latency>.. Accordingly, the arguments T + >. and >. of W ij on the left hand side of the
equation are shifted relative to the limits T and 0 of the integral on the right hand side. We

201

Spike-based Learning and Stabilization ofPersistent Neural Activity

will assume that the latency>. is greater than the pairing range T, so that Wi} at any time is
only influenced by presynaptic and postsynaptic spikes that happened before that time, and
therefore the learning rule is causal.

3

RELATION TO RATE-BASED LEARNING RULES

The learning rule of Eq. (1) is driven by correlations between presynaptic and postsynaptic
activities. This dependence can be made explicit by making the change of variables u =
ti - t j in Eq. (I), which yields

Wij(T

+ >.) -

W ij (>.)

= iTT duf(u)Cij(u)

(2)

where we have defined the cross-correlation

Cij(u)

= !aT dt Si(t + u) Sj(t)

.

(3)

and made use of the fact that f vanishes outside the interval [-T, T]. Our immediate goal
is to relate Eq. (2) to learning rules that are based on the cross-correlation between firing
rates,

Crre(u)

= !aT dt Vi(t + u) Vj(t)

(4)

There are a number of ways of defining instantaneous firing rates. Sometimes they are
computed by averaging over repeated presentations of a stimulus. In other situations, they
are defined by temporal filtering of spike trains. The following discussion is general, and
should apply to these and other definitions of firing rates.
The "rate correlation" is commonly subtracted from the total correlation to obtain the "spike
correlation" C:r ke = Cij - Cijate. To derive a rate-based approximation to the learning
rule (2), we rewrite it as

Wij(T

+ >.) -

Wij(>')

= iTT du f(u)Cijate(u) + iTT du f(u)C:r ke (u)

(5)

and simply neglect the second term. Shortly we will discuss the conditions under which
this is a good approximation. But first we derive another form for the first term by applying
the approximation Vi(t + u) ~ Vi(t) + UVi(t) to obtain

j

T

-T

duf(u)Crre(u)

~

iT

dt[fiovi(t)

+ 131Vi(t)]VJ (t)

(6)

0

where we define
(7)

This approximation is good when firing rates vary slowly compared to the pairing range
T . The learning rule depends on the postsynaptic rate through fio Vi + 131 Vi . When the
first term dominates the second, then the learning rule is the conventional one based on
correlations between firing rates, and the sign of fio determines whether the rule is Hebbian
or anti-Hebbian.
In the remainder of the paper, we will discuss the more novel case where 130 = O. This
holds for the pairing functions shown in Figures lA and IB, which have positive and negative lobes with areas that exactly cancel in the definition of 130. Then the dependence on

X Xie and H. S. Seung

202

postsynaptic activity is purely on the time derivative of the firing rate. Differential Hebbian
learning corresponds to /31 > 0 (Figure IA), while differential anti-Hebbian learning leads
to /31 < 0 (Figure IB). To summarize the /30 = 0 case, the synaptic changes due to rate
correlations are approximated by
W ij ex: -ViVj

(diff. anti-Hebbian)

(8)

for slowly varying rates. These formulas imply that a constant postsynaptic firing rate
causes no net change in synaptic strength. Instead, changes in rate are required to induce
synaptic plasticity.
To illustrate this point, Figure lC shows the result of applying differential anti-Hebbian
learning to two spike trains. The presynaptic spike train was generated by a 50 Hz Poisson
process, while the postsynaptic spike train was generated by an inhomogeneous Poisson
process with rate that shifted from 50 Hz to 200 Hz at 1 sec. Before and after the shift,
the synaptic strength fluctuates but remains roughly constant. But the upward shift in firing
rate causes a downward shift in synaptic strength, in accord with the sign of the differential
anti-Hebbian rule in Eq. (8).
The rate-based approximation works well for this example, because the second term of Eq.
(5) is not so important. Let us return to the issue of the general conditions under which
Pike (u) are
this term can be neglected. With Poisson spike trains, the spike correlations
zero in the limit T -7 00, but for finite T they fluctuate about zero. The integr~l over u in
the second term of (5) dampens these fluctuations. The amount of dampening depends on
the pairing range T, which sets the limits of integration. In Figure 1C we used a relatively
long pairing range of 100 ms, which made the fluctuations small even for small T. On the
other hand, if T were short, the fluctuations would be small only for large T_ Averaging
over large T is relevant when the amplitUde of f is small, so that the rate of learning is
slow. In this case, it takes a long time for significant synaptic changes to accumulate, so
that plasticity is effectively driven by integrating over long time periods T in Eq. (l).

C:

In the brain, nonvanishing spike correlations are sometimes observed even in the T -7 00
limit, unlike with Poisson spike trains. These correlations are often roughly symmetric
about zero, in which case they should produce little plasticity if the pairing functions are
antisymmetric as in Figures lA and lB. On the other hand, if the spike correlations are
asymmetric, they could lead to substantial effects[6].

4

EFFECTS ON RECURRENT NETWORK DYNAMICS

The learning rules of Eq. (8) depend on both presynaptic and postsynaptic rates, like learning rules conventionally used in neural networks. They have the special feature that they
depend on time derivatives, which has computational consequences for recurrent neural
networks of the form
Xi

+ Xi

=

L Wiju(Xj) + bi

(9)

j

Such classical neural network equations can be derived from more biophysically realistic
models using the method of averaging[ 15] or a mean field approximation[ 16]. The firing
rate of neuron j is conventionally identified with Vj = u(Xj).

v;

The cost function E( {Xi}; {Wij}) = ~ Li
quantifies the amount of drift in firing rate at
the point Xl , ... , X N in the state space of the network. If we consider Vi to be a function of
Xi and W ij defined by (9), then the gradient ofthe cost function with respect to W ij is given
by BE / BWij = U' (Xi)ViVj. Assuming that U is a monotonically increasing function so that
u' (xd > 0, it follows that the differential Hebbian update of (8) increases the cost function,

Spike-based Learning and Stabilization ofPersistent Neural Activity

203

and hence increases the magnitude of the drift velocity. In contrast, the differential antiHebbian update decreases the drift velocity. This suggests that the differential anti-Hebbian
update could be useful for creating fixed points of the network dynamics (9).

5

PERSISTENT ACTIVITY IN A SPIKING AUTAPSE MODEL

The preceding arguments about drift velocity were based on approximate rate-based descriptions of learning and network dynamics. It is important to implement spike-based
learning in a spiking network dynamics, to check that our approximations are valid.
Therefore we have numerically simulated the simple recurrent circuit of
integrate-and-fire neurons shown in Figure 2. The core of the circuit is the
"memory neuron," which makes an excitatory autapse onto itself. It also receives
synaptic input from three input neurons:
a tonic neuron, an excitatory burst neuron, and an inhibitory burst neuron. It is
known that this circuit can store a shortterm memory of an analog variable in
persistent activity, if the strengths of the
autapse and tonic synapse are precisely
INHIBITORY BURST
tuned[ 17]. Here we show that this tun?
ing can be accomplished by the spikebased learning rule of Eq. (1), with a dFigure 2: Circuit diagram for autapse model
ifferential anti-Hebbian pairing function
like that of Figure 1B.
The memory neuron is described by the equations

C
m

dr
Tsyn

dt

dV
dt

=

(10)
(1)

+r
n

where V is the membrane potential. When V reaches V'thres, a spike is considered to have
occurred, and V is reset to Vreset. Each spike at time Tn causes a jump in the synaptic
activation r of size CY.r/Tsyn, after which r decays exponentially with time constant Tsyn
until the next spike.
The synaptic conductances of the memory neuron are given by
(12)

The term W r is recurrent excitation from the autapse, where W is the strength of the autapse. The synaptic activations ro, r +, and r _ of the tonic, excitatory burst, and inhibitory
burst neurons are governed by equations like (10) and (1), with a few differences. These
neurons have no synaptic input; their firing patterns are instead determined by applied currents lapp,o, lapp,+ and lapp,_. The tonic neuron has a constant applied current, which
makes it fire repetitively at roughly 20 Hz (Figure 3). For the excitatory and inhibitory
burst neurons the applied current is normally zero, except for brief 100 ms current pulses
that cause bursts of action potentials.
As shown in Figure 3, if the synaptic strengths W and Wo are arbitrarily set before learning,
the burst neurons cause only transient changes in the firing rate of the memory neuron.
After applying the spike-based learning rule (1) to tune both W and W o, the memory

X Xie and H. S. Seung

204

111111111111 I

~IIIIIIIII

I

IUIIIIIIII I

/untuned
111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111

I

I~

____~I~____~______=-_____
I

"

tuned

1IIIIIIIIIIIIIIIIIIIIIIIIIIINIIIIII'.tl

I

1 sec
1111111111'"111111111111111111111111111

Figure 3: Untuned and tuned autapse activity. The middle three traces are the membrane
potentials of the three input neurons in Figure 2 (spikes are drawn at the reset times of
the integrate-and-fire neurons). Before learning, the activity of the memory neuron is not
persistent, as shown in the top trace. After the spike-based learning rule (1) is applied to
the synaptic weights Wand W o, then the burst inputs cause persistent changes in activity.
em = 1 nF, gL = 0.025 J-lS, VL = -70 mY, VE = 0 mY, VI = -70 mY, vthres = -52
mY, Vr eset = -59 mY, a s = 1, Tsyn = 100 ms, Iapp,o = 0.5203 nA, I app ,? = 0 or 0.95
nA, Ts yn ,O = 100 ms, Tsyn,+ = Ts yn,- = 5 ms, W+ = 0.1, W_ = 0.05.

neuron is able to maintain persistent activity. During the interburst intervals (from A after
one burst until A before the next), we made synaptic changes using the differential antiHebbian pairing function f(t) = -Asin(7l'tjT) for spike time differences in the range
[-T, T] with A = 1.5 X 10- 4 and T=A=120 ms. The resulting increase in persistence time
can be seen in Figure 4A, along with the values of the synaptic weights versus time.
To quantify the performance of the system at maintaining persistent activity, we determined
the relationship between dv / dt and v using a long sequence of interburst intervals, where v
was defined as the reciprocal of the interspike interval. If Wand Wo are fixed at optimally
tuned values, there is still a residual drift, as shown in Figure 4B. But if these parameters are
allowed to adapt continuously, even after good tuning has been achieved, then the residual
drift is even smaller in magnitude. This is because the learning rule tweaks the synaptic
weights during each interburst interval, reducing the drift for that particular firing rate.
Autapse learning is driven by the autocorrelation of the spike train, rather than a crosscorrelation. The peak in the autocorrelogram at zero lag has no effect, since the pairing
function is zero at the origin. Since the autocorrelation is zero for small time lags, we used
a fairly large pairing range in our simulations. In a recurrent network of many neurons, a
shorter pairing range would suffice, as the cross-correlation does not vanish near zero.

6 DISCUSSION
We have shown that differential anti-Hebbian learning can tune a recurrent circuit to maintain persistent neural activity. This behavior can be understood by reducing the spike-based
learning rule (l) to the rate-based learning rules ofEqs. (6) and (8). The rate-based approximations are good if two conditions are satisfied. First, the pairing range must be large, or
the rate of learning must be slow. Second, spike synchrony must be weak, or have little
effect on learning due to the shape of the pairing function.
The differential anti-Hebbian pairing function results in a learning rule that uses -Vi as a
negative feedback signal to reduce the amount of drift in firing rate, as illustrated by our
simulations of an integrate-and-fire neuron with an excitatory autapse. More generally,
the learning rule could be relevant for tuning the strength of positive feedback in networks that maintain a short-term memory of an analog variable in persistent neural activity.

Spike-based Learning and Stabilization of Persistent Neural Activity
A

250

B

c '

200

0.395

~150

W

WO

0.16

0385

~

i!

0

?100

""

0.12

10

20

"me Is)

I

6

I

4

1

5

10

15

tlme(s)

20

.~~

2

1~
:I:

~r?

0

~-2

~~!

50

00

205

25

~~~

-4f

-at
-8'

20

40

60

rate (Hzl

'0
80

i
100

Figure 4: Tuning the autapse. (A) The persistence time of activity increases as the weights Wand Wo are tuned. Each transition is driven by pseudorandom bursts of input (B)
Systematic relationship between drift dv/dt in firing rate and v, as measured from a long
sequence of interburst intervals. If the weights are continuously fine-tuned ('*') the drift is
less than with fixed well-tuned weights ('0').
For example, the learning rule could be used to improve the robustness of the oculomotor
integrator[12, 13, 14] and head direction system[l1] to mistuning of parameters. In deriving the differential forms of the learning rules in (8), we assumed that the areas under the
positive and negative lobes of the pairing function are equal, so that the integral defining
130 vanishes. In reality, this cancellation might not be exact. Then the ratio of 131 and 130
would limit the persistence time that can be achieved by the learning rule.
Both the oculomotor integrator and the head direction system are also able to integrate
vestibular inputs to produce changes in activity patterns. The problem of finding generalizations of the present learning rules that train networks to integrate is still open .

References
[1] H. Markram, J. Lubke, M. Frotscher, and B. Sakmann. Science, 275(5297):213-5, 1997.
[2] G. Q. Bi and M. M. Poo. 1 Neurosci, 18(24):10464-72,1998.
[3] D. O . Hebb. Organization of behavior. Wiley, New York, 1949.
[4] C. C. Bell, V. Z. Han, Y. Sugawara, and K. Grant. Nature , 387(6630):278-81 , 1997.
[5]

w. Gerstner, R . Kempter, 1. L. van Hemmen, and H. Wagner.

Nature, 383(6595):76-81, 1996.

[6] L. F. Abbott and S. Song. Adv. Neural Info. Proc. Syst., 11, 1999.
[7] P. D. Roberts . 1. Comput. Neurosci., 7:235-246, 1999.
[8] R. Kempter, W. Gerstner, and J. L. van Hemmen. Phys. Rev. E, 59(4):4498-4514, 1999.
[9] A. P. Georgopoulos, M. Taira, and A. Lukashin. Science, 260:47-52, 1993.
[10] M. Camperi and X. J. Wang. 1 Comput Neurosci, 5(4):383-405, 1998.
[11] K. Zhang. 1. Neurosci., 16:2112-2126, 1996.
[12] S. C. Cannon, D. A. Robinson, and S. Shamma. Bio!. Cybern., 49:127-136,1983.
[13] H. S. Seung. Proc. Nat!. A cad. Sci. USA, 93:13339-13344, 1996.
[14] H. S. Seung, D. D. Lee, B. Y. Reis, and D. W. Tank. Neuron, 2000.
[15] B. Ermentrout. Neural Comput., 6:679-695, 1994.
[16] O. Shriki, D. Hansel, and H. Sompolinsky. Soc. Neurosci. Abstr., 24:143, 1998.
[17] H. S. Seung, D. D. Lee, B. Y. Reis, and D. W. Tank. 1. Comput. Neurosci., 2000.

III
THEORY

PART


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4690-towards-a-learning-theoretic-analysis-of-spike-timing-dependent-plasticity.pdf

Towards a learning-theoretic analysis of
spike-timing dependent plasticity
David Balduzzi
MPI for Intelligent Systems, T?ubingen, Germany
ETH Zurich, Switzerland
david.balduzzi@inf.ethz.ch
Michel Besserve
MPI for Intelligent Systems and MPI for Biological Cybernetics
T?ubingen, Germany
michel.besserve@tuebingen.mpg.de

Abstract
This paper suggests a learning-theoretic perspective on how synaptic plasticity
benefits global brain functioning. We introduce a model, the selectron, that (i)
arises as the fast time constant limit of leaky integrate-and-fire neurons equipped
with spiking timing dependent plasticity (STDP) and (ii) is amenable to theoretical
analysis. We show that the selectron encodes reward estimates into spikes and that
an error bound on spikes is controlled by a spiking margin and the sum of synaptic
weights. Moreover, the efficacy of spikes (their usefulness to other reward maximizing selectrons) also depends on total synaptic strength. Finally, based on our
analysis, we propose a regularized version of STDP, and show the regularization
improves the robustness of neuronal learning when faced with multiple stimuli.

1

Introduction

Finding principles underlying learning in neural networks is an important problem for both artificial
and biological networks. An elegant suggestion is that global objective functions may be optimized
during learning [1]. For biological networks however, the currently known neural plasticity mechanisms use a very restricted set of data ? largely consisting of spikes and diffuse neuromodulatory
signals. How a global optimization procedure could be implemented at the neuronal (cellular) level
is thus a difficult problem.
A successful approach to this question has been Rosenblatt?s perceptron [2] and its extension to
multilayer perceptrons via backpropagation [3]. Similarly, (restricted) Boltzmann machines, constructed from simple stochastic units, have provided a remarkably powerful approach to organizing
distributed optimization across many layers [4]. By contrast, although there has been significant
progress in developing and understanding more biologically realistic models of neuronal learning [5?10], these do not match the performance of simpler, more analytically and computationally
tractable models in learning tasks.
Overview. This paper constructs a bridge from biologically realistic to analytically tractable models. The selectron is a model derived from leaky integrate and fire neurons equipped with spiketiming dependent plasticity that is amenable to learning-theoretic analysis. Our aim is to extract
some of the principles implicit in STDP by thoroughly investigating a limit case.
Section ?2 introduces the selectron. We state a constrained reward maximization problem which
implies that selectrons encode empirical reward estimates into spikes. Our first result, section ?3,
1

is that the selectron arises as the fast time constant limit of well-established models of neuronal
spiking and plasticity, suggesting that cortical neurons may also be encoding reward estimates into
their spiketrains.
Two important questions immediately arise. First, what guarantees can be provided on spikes being
reliable predictors of global (neuromodulatory) outcomes? Second, what guarantees can be provided
on the usefulness of spikes to other neurons? Sections ?4 and ?5 answer these questions by providing
an upper bound on a suitably defined 0/1 loss and a lower bound on the efficacy of a selectron?s
spikes, measured in terms of its contribution to the expected reward of a downstream selectron.
Both bounds are controlled by the sum of synaptic weights kwk1 , thereby justifying the constraint
introduced in ?2. Finally, motivated by our analysis, ?6 introduces a regularized STDP rule and
shows that it learns more robustly than classical STDP. ?7 concludes the paper. Proofs of theorems
are provided in the supplementary material.
Related work. Spike-timing dependent plasticity and its implications for the neural code have
been intensively studied in recent years. The work closest in spirit to our own is Seung?s ?hedonistic?
synapses, which seek to increase average reward [6]. Our work provides guarantees on the finite
sample behavior of a discrete-time analog of hedonistic neurons. Another related line of research
derives from the information bottleneck method [9, 11] which provides an alternate constraint to the
one considered here. An information-theoretic perspective on synaptic homeostasis and metabolic
cost, complementing the results in this paper, can be found in [12, 13]. Simulations combining
synaptic renormalization with burst-STDP can be found in [14].
Important aspects of plasticity that we have not considered here are properties specific to continuoustime models, such as STDP?s behavior as a temporal filter [15], and also issues related to convergence [8, 10].
The learning-theoretic properties of neural networks have been intensively studied, mostly focusing
on perceptrons, see for example [16]. A non-biologically motivated ?large-margin? analog of the
perceptron was proposed in [17].

2

The selectron

We introduce the selectron, which can be considered a biologically motivated adaptation of the
perceptron, see ?3. The mechanism governing whether or not the selectron spikes is a Heaviside
function acting on a weighted sum of synaptic inputs; our contribution is to propose a new reward
function and corresponding learning rule.
Let us establish some notation. Let X denote the set of N -dimensional {0, 1}-valued vectors forming synaptic inputs to a selectron, and Y = {0, 1} the set of outputs. A selectron spikes according
to
?
1 if z > 0
y = fw (x) := H (w| x #) , where H(z) :=
(1)
0 else
is the Heaviside function and w is a [0, 1] ? R valued N -vector specifying the selectron?s synaptic
weights. Let P (x) denote the probability of input x arising.
To model the neuromodulatory system we introduce random variable ? : X ! { 1, 0, +1}, where
positive values correspond to desirable outcomes, negative to undesirable and zero to neutral. Let
P (?|x) denote the probability of the release of neuromodulatory signal subsequent to input x.
Definition 1. Define reward function
R(x, fw , ?) =

?(x)
|{z}

neuromodulators

? (w| x #) ? fw (x) =
| {z } | {z }
margin

selectivity

?

?(x) ? (w| x
0

#)

if y = 1
else.

(2)

The reward consists in three components. The first term is the neuromodulatory signal, which acts as
a supervisor. The second term is the total current w| x minus the threshold #. It is analogous to the
margin in support vector machines or boosting algorithms, see section ?4 for a precise formulation.
2

The third term gates rewards according to whether or not the selectron spikes. The reward is thus
selected1 : neuromodulatory signals are ignored by the selectron?s reward function when it does not
spike, enabling specialization.
Constrained reward maximization. The selectron solves the following optimization problem:
bn :=
maximize: R
w

n
X
i=1

?(x(i) ) ? (w| x(i)

#) ? fw (x(i) )

(3)

subject to: kwk1 ? ! for some ! > 0.

Remark 1 (spikes encode rewards).
Optimization problem (3) ensures that selectrons spike for inputs that, on the basis of their empirical
sample, reliably lead to neuromodulatory rewards. Thus, spikes encode expectations about rewards.
The constraint is motivated by the discussion after Theorem 1 and the analysis in ?4 and ?5. We
postpone discussion of how to impose the constraint to ?6, and focus on reward maximization here.
The reward maximization problem cannot be solved analytically in general. However, it is possible
to use an iterative approach. Although fw (x) is not continuous, the reward function is a continuous
function of w and is differentiable everywhere except for the ?corner? where w| x # = 0. We
therefore apply gradient ascent by computing the derivative of (3) with respect to synaptic weights
to obtain online learning rule
?
? ? ?(x) if xj = 1 and y = 1
wj = ? ? ?(x) ? xj ? fw (x) =
(4)
0
else
where update factor ? controls the learning rate.
The learning rule is selective: regardless of the neuromodulatory signal, synapse wjk is updated
only if there is both an input xj = 1 and output spike y = fw (x) = 1.
The selectron is not guaranteed to find a global optimum. It is prone to initial condition dependent
local optima because rewards depend on output spikes in learning rule (4). Although this is an
undesirable property for an isolated learner, it is less important, and perhaps even advantageous, in
large populations where it encourages specialization.
Remark 2 (unsupervised setting).
Define the unsupervised setting by ?(x) = 1 for all x. The reward function reduces to R(x, fw ) =
(w| x #) ? fw (x). Without the constraint synapses will saturate. Imposing the constraint yields a
more interesting solution where the selectron finds a weight vector summing to ! which balances (i)
frequent spikes and (ii) high margins.
Theorem 1 (Controlling the frequency of spikes).
Assuming synaptic inputs are i.i.d. Bernoulli variables with P (spike) = p, then
?
?2
?
?
? ! ?2
kwk1
P fw (x) = 1 ? p ?
?p?
.
#
#
The Bernoulli regime is the discrete-time analog of the homogeneous Poisson setting used to prove
convergence of reward-modulated STDP in [8]. Interestingly, in this setting the constraint provides
a lever for controlling (lower bounding) rewards per spike
n

o
reward per spike =

b
R
P (fw (x) = 1)

c1 ?

b
R
.
!2

If inputs are not Bernoulli i.i.d., then P (y = 1) and ! still covary, although the precise relationship is
more difficult to quantify. Although i.i.d. inputs are unrealistic, note that recent neurophysiological
evidence suggests neuronal firing ? even of nearby neurons ? is uncorrelated [18].
1

The name ?selectron? was chosen to emphasize this selective aspect.

3

3

Relation to leaky integrate-and-fire neurons equipped with STDP

The literature contains an enormous variety of neuronal models, which vary dramatically in sophistication and the extent to which they incorporate the the details of the underlying biochemical
processes. Similarly, there is a large menagerie of models of synaptic plasticity [19]. We consider
two well-established models: Gerstner?s Spike Response Model (SRM) which generalizes leaky
integrate-and-fire neurons [20] and the original spike-timing dependent plasticity learning rule proposed by Song et al [5], and show that the selectron arises in the fast time constant limit of the two
models.
First let us recall the SRM. Suppose neuron nk last outputted a spike at time tk and receives input
spikes at times tj from neuron nj . Neuron nk spikes or according to the Heaviside function applied
to the membrane potential Mw :
X
fw (t) = H (Mw (t) #) where Mw (t) = ?(t tk ) +
wjk ? ?(t tj ) at time t tk .
tj ?t

Input and output spikes add
? ?t t?
?t t?
j
j
?(t tj ) = K e ?m
e ?s
and ?(t

?
?
?
tk t
tk ) = # K 1 e ? m

? ?t t?
k
K2 e ?m

e

?

tk t
?s

??

to the membrane potential for tj ? t and tk ? t respectively. Here ?m and ?s are the membrane and
synapse time constants.
The original STDP update rule [5] is
wjk =

8
<
:

?+ ? e

?t

? ?e

j tk
?+

?t

?

k tj
?

?

if tj ? tk
else

(5)

where ?+ and ? are time constants. STDP potentiates input synapses that spike prior to output
spikes and depotentiates input synapses that spike subsequent to output spikes.
Theorem 2 (the selectron is the fast time constant limit of SRM + STDP).
In the fast time constant limit, lim?? ! 0, the SRM transforms into a selectron with
?
?
X
fw (t) = H Mw (t) #
where Mw =
wjk ? tk (t).
{j|tj

tk }

Moreover, STDP transforms into learning rule (4) in the unsupervised setting with ?(x) = 1 for all
x. Finally, STDP arises as gradient ascent on a reward function whose limit is the unsupervised
setting of reward function (2).
Theorem 2 shows that STDP implicitly maximizes a time-discounted analog of the reward function
in (3). We expect many models of reward-modulated synaptic plasticity to be analytically tractable
in the fast time constant limit. An important property shared by STDP and the selectron is that
synaptic (de)potentiation is gated by output spikes, see ?A.1 for a comparison with the perceptron
which does not gate synaptic learning

4

An error bound

Maximizing reward function (3) implies that selectrons encode reward estimates into their spikes.
Indeed, it recursively justifies incorporating spikes into the reward function via the margin (w| x
#), which only makes sense if upstream spikes predict reward. However, in a large system where
estimates pile on top of each other there is a tendency to overfit, leading to poor generalizations [21].
It is therefore crucial to provide guarantees on the quality of spikes as estimators.
Boosting algorithms, where the outputs of many weak learners are aggregated into a classifier [22],
are remarkably resistant to overfitting as the number of learners increases [23]. Cortical learning may
be analogous to boosting: individual neurons have access to a tiny fraction of the total brain state,
and so are weak learners; and in the fast time constant limit, neurons are essentially aggregators.
4

We sharpen the analogy using the selectron. As a first step towards understanding how the cortex
combats overfitting, we adapt a theorem developed to explain the effectiveness of boosting [24]. The
goal is to show how the margin and constraint on synaptic weights improve error bounds.
Definition 2. A selectron incurs a 0/1 loss if a spike is followed by negative neuromodulatory
feedback
?
1 if y = 1 and ?(x) = 1
l(x, fw , ?) =
=
(6)
fw (x)??(x)
0 else.

The 0/1 loss fails to take the estimates (spikes) of other selectrons into account and is difficult to
optimize, so we also introduce the hinge loss:
?
?
?
x if x 0
h? (x, fw , ?) := ? (w| x #) ? ?(x) ? fw (x), where (x)+ :=
(7)
0 else.
+
Note that l ? h? for all ? 1. Parameter ? controls the saturation point, beyond which the size of
the margin makes no difference to h? .

An alternate 0/1 loss2 penalizes a selectron if it (i) fires when it shouldn?t, i.e. when ?(x) = 1
or (ii) does not fire when it should, i.e. when ?(x) = 1. However, since the cortex contains
many neurons and spiking is metabolically expensive [25], we propose a conservative loss that only
penalizes errors of commission (?first, do no harm?) and does not penalize specialization.
Theorem 3 (spike error bound).
Suppose each selectron has ? N synapses. For any selectron nk , let S k = {nk } [ {nj : nj ! nk }
denote a 2-layer feedforward subnetwork. For all ? 1, with probability at least 1
,
p
?
? 1 X ? (i)
8(N + 1) log(n + 1) + 1
p
E l(x, fw , ?) ?
h x , fw , ?(x(i) ) +! ? 2B ?
n
n
|
{z
}
|
{z
}
i
|
{z
}
hinge loss
0/1 loss
+ 2B ?

capacity term

s

2 log 2
n
| {z }

where B = ? + !

#.

confidence term

Remark 3 (theoretical justification for maximizing margin and constraining kwk1 ).
The theorem shows how subsets of distributed systems can avoid overfitting. First, it demonstrates
the importance of maximizing the margin (i.e. the empirical reward). Second, it shows the capacity
term depends on the number of synapses N and the constraint ! on synaptic weights, rather than
the capacity of S k ? which can be very large.
The hinge loss is difficult to optimize directly since gating with output spikes fw (x) renders it
discontinuous. However, in the Bernoulli regime, Theorem 1 implies the bound in Theorem 3 can
be rewritten as
?
?
!2
E l(x, fw , ?) ? p? 2
#

bn x(i) , fw , ?(x(i) ) + ! ? capacity term + confidence term
R

(8)

and so ! again provides the lever required to control the 0/1 loss. The constraint kwk1 ? ! is best
imposed offline, see ?6.

5

A bound on the efficacy of inter-neuronal communication

Even if a neuron?s spikes perfectly predict positive neuromodulatory signals, the spikes only matter
to the extent they affect other neurons in cortex. Spikes are produced for neurons by neurons. It is
therefore crucial to provide guarantees on the usefulness of spikes.
In this section we quantify the effect of one selectron?s spikes on another selectron?s expected reward. We demonstrate a lower bound on efficacy and discuss its consequences.
2

See ?A.5 for an error bound.

5

Definition 3. The efficacy of spikes from selectron nj on selectron nk is
Rk
E[Rk |xj = 1]
:=
xj
1

E[Rk |xj = 0]
,
0

i.e. the expected contribution of spikes from selectron nj to selectron nk ?s expected reward, relative
to not spiking. The notation is intended to suggest an analogy with differentiation ? the infinitesimal
difference made by spikes on a single synapse.
Efficacy is zero if E[Rk |xj = 1] = E[Rk |xj = 0]. In other words, if spikes from nj make no
difference to the expected reward of nk .
The following theorem relies on the assumption that the average contribution of neuromodulators is
higher after nj spikes than after it does not spike (i.e. upstream spikes predict reward), see ?A.6 for
precise statement. When the assumption is false the synapse wjk should be pruned.
Theorem 4 (spike efficacy bound).
Let pj := E[Y j ] denote the frequency of spikes from neuron nj . The efficacy of nj ?s spikes on nk is
lower bounded by
h
i
h
i
j k
j |
k
j |
2E
Y
Y
?
(wC
)
x
#
E
Y
?
(wC
)
x
#
k
j k
R
wj ? E[Y Y ]
c2 ?
+
(9)
xj
pj
pj (1 pj )
1 pj
|{z}
|
{z
}
|
{z
} |
{z
}
efficacy

wj -weighted co-spike frequency

co-spike frequency

nk spike frequency

where c2 is described in ?A.6 and wijC := wi if i 6= j and 0 if i = j.

The efficacy guarantee is interpreted as follows. First, the guarantee improves as co-spiking by nj
and nk increases. However, the denominators imply that increasing the frequency of nj ?s spikes
worsens the guarantee, insofar as nj is not correlated with nk . Similarly, from the third term,
increasing nk ?s spikes worsens the guarantee if they do not correlate with nj .
An immediate corollary of Theorem 4 is that Hebbian learning rules, such as STDP and the selectron
learning rule (4), improve the efficacy of spikes. However, it also shows that naively increasing the
frequency of spikes carries a cost. Neurons therefore face a tradeoff. In fact, in the Bernoulli regime,
Theorem 1 implies (9) can be rewritten as
h
i p ? ! 2 ? (! #)
Rk
wj
2
c2 ?
? E[Y j Y k ] +
E Y j Y k ? (wjC )| x #
,
(10)
xj
p
p(1 p)
(1 p)#2
so the constraint ! on synaptic strength can be used as a lever to improve guarantees on efficacy.
Remark 4 (efficacy improved by pruning weak synapses).
The 1st term in (9) suggests that pruning weak synapses increases the efficacy of spikes, and so may
aid learning in populations of selectrons or neurons.

6

Experiments

Cortical neurons are constantly exposed to different input patterns as organisms engage in different
activities. It is therefore important that what neurons learn is robust to changing inputs [26, 27]. In
this section, as proof of principle, we investigate a simple tweak of classical STDP involving offline
regularization. We show that it improves robustness when neurons are exposed to more than one
pattern.
Observe that regularizing optimization problem (3) yields
maximize:
w

learning rule:

n
X

R x(i) , fw , ?(x(i) )

i=1

2

wj = ? ? ?(x) ? xj ? fw (x)

(kwk1

!)2

? kwk1

(11)
! ? wj

(12)

incorporates synaptic renormalization directly into the update. However, (12) requires continuously
re-evaluating the sum of synaptic weights. We therefore decouple learning into an online reward
maximization phase and an offline regularization phase which resets the synaptic weights.
6

A similar decoupling may occur in cortex. It has recently been proposed that a function of NREM
sleep may be to regulate synaptic weights [28]. Indeed, neurophysiological evidence suggests that
average cortical firing rates increase during wakefulness and decrease during sleep, possibly reflecting synaptic strengths [29, 30]. Experimental evidence also points to a net increase in dendritic
spines (synapses) during waking and a net decrease during sleep [31].
Setup. We trained a neuron on a random input pattern for 10s to 87% accuracy with regularized
STDP. See ?A.7 for details on the structure of inputs. We then performed 700 trials (350 classical
and 350 regularized) exposing the neuron to a new pattern for 20 seconds and observed performance
under classical and regularized STDP.
SRM neurons with classical STDP. We used Gerstner?s SRM model, recall ?3, with parameters
chosen to exactly coincide with [32]: ?m = 10, ?s = 2.5, K = 2.2, K1 = 2, K2 = 4 and
# = 14 #synapses. STDP was implemented via (5) with parameters ?+ = 0.03125, ?+ = 16.8,
? = 0.85?+ and ? = 33.7 also taken from [32]. Synaptic weights were clipped to fall in [0, 1].
Regularized STDP consists of a small tweak of classical STDP in the online phase, and an additional offline regularization phase:
? Online. In the online phase, reduce the depotentiation bias from 0.85?+ in the classical
implementation to ? = 0.75?+ .
? Offline. In the offline phase, modify synapses once per second according to
?
? 32 wj ? (! s) if ! < s
wj =
(13)
? (! s)
else,
where s is output spikes per second, ! = 5Hz is the target rate and update factor
The offline update rule is firing rate, and not spike, dependent.

= 0.6.

Classical STDP has a depotentiation bias to prevent runaway potentiation feedback loops leading to
seizures [5]. Since synapses are frequently renormalized offline we incorporate a weak exploratory
(potentiation) bias during the online phase which helps avoid local minima.3 This is in line with
experimental evidence showing increased cortical activity during waking [30].
Since computing the sum of synaptic weights is non-physiological, we draw on Theorem 1 and
use the neuron?s firing rate when responding to uncorrelated inputs as a proxy for kwk1 . Thus,
in the offline phase, synapses receive inputs generated as in the online phase but without repeated
patterns. Note that (12) has a larger pruning effect on stronger synapses, discouraging specialization.
Motivated by Remark 4, we introduce bias ( 32 wj ) in the offline phase to ensure weaker synapses
are downscaled more than strong synapses. For example, a synapse with wi = 0.5 is downscaled
by twice as much as a synapse with weight wj = 1.0.
Regularized STDP alternates between 2 seconds online and 4 seconds offline, which suffices to
renormalize synaptic strengths. The frequency of the offline phase could be reduced by decreasing the update factors ?? , presenting stimuli less frequently (than 7 times per second), or adding
inhibitory neurons to the system.
Results. A summary of results is presented in the table below: accuracy quantifies the fraction
of spikes that co-occur with each pattern. Regularized STDP outperforms classical STDP on both
patterns on average. It should be noted that regularized neurons were not only online for 20 seconds
but also offline ? and exposed to Poisson noise ? for 40 seconds. Interestingly, exposure to Poisson
noise improves performance.
Algorithm

Accuracy
Pattern 1 Pattern 2

Classical

54%

39%

Regularized

59%

48%

3
The input stream contains a repeated pattern, so there is a potentiation bias in practice even though the net
integral of STDP in the online phase is negative.

7

TRIALS

0

60
30
0

100

100

80

80

ACCURACY ON #1

TRIALS

ACCURACY ON #1

160
100

60
40
20
0

20 40 60 80
ACCURACY ON #2

100 0

60
40
20
0

80 140
TRIALS

(a) Classical STDP

20 40 60 80
ACCURACY ON #2

100 0

40 70
TRIALS

(b) Regularized STDP

Figure 1: Accuracy after 20 seconds of exposure to a novel pattern.
Fig. 1 provides a more detailed analysis. Each panel shows a 2D-histogram (darker shades of gray
correspond to more trials) plotting accuracies on both patterns simultaneously, and two 1D histograms plotting accuracies on the two patterns separately. The 1D histogram for regularized STDP
shows a unimodal distribution for pattern #2, with most of the mass over accuracies of 50-90%. For
pattern #1, which has been ?unlearned? for twice as long as the training period, most of the mass is
over accuracies of 50% to 90%, with a significant fraction ?unlearnt?. By contrast, classical STDP
exhibits extremely brittle behavior. It completely unlearns the original pattern in about half the trials,
and also fails to learn the new pattern in most of the trials.
Thus, as suggested by our analysis, introducing a regularization both improves the robustness of
STDP and enables an exploratory bias by preventing runaway feedback leading to epileptic seizures.

7

Discussion

The selectron provides a bridge between a particular model of spiking neurons ? the Spike Response Model [20] with the original spike-timing dependent plasticity rule [5] ? and models that
are amenable to learning-theoretic analysis. Our hope is that the selectron and related models lead
to an improved understanding of the principles underlying learning in cortex. It remains to be seen
whether other STDP-based models also have tractable discrete-time analogs.
The selectron is an interesting model in its own right: it embeds reward estimates into spikes and
maximizes a margin that improves error bounds. It imposes a constraint on synaptic weights that:
concentrates rewards/spike, tightens error bounds and improves guarantees on spiking efficacy. Although the analysis does not apply directly to continuous-time models, experiments show that a
tweak inspired by our analysis improves the performance of a more realistic model. An important avenue for future research is investigating the role of feedback in cortex, specifically NMDA
synapses, which may have interesting learning-theoretic implications.
Acknowledgements. We thank Timoth?ee Masquelier for generously sharing his source code [32]
and Samory Kpotufe for useful discussions.

References
[1] Friston K, Kilner J, Harrison L: A free energy principle for the brain. J. Phys. Paris 2006, 100:70?87.
[2] Rosenblatt F: The perceptron: a probabilistic model for information storage and organization in the
brain. Psychol Rev 1958, 65(6):386?408.
[3] Rumelhart DE, Hinton GE, Williams RJ: Learning representations by back-propagating errors. Nature 1986, 323:533?536.
[4] Hinton G, Osindero S, Teh YW: A Fast Learning Algorithm for Deep Belief Nets. Neural Computation
2006, 18:1527?1554.

8

[5] Song S, Miller KD, Abbott LF: Competitive Hebbian learning through spike-timing-dependent
synaptic plasticity. Nature Neuroscience 2000, 3(9).
[6] Seung HS: Learning in Spiking Neural Networks by Reinforcement of Stochastic Synaptic Transmission. Neuron 2003, 40(1063-1073).
[7] Bohte SM, Mozer MC: Reducing spike train variability: A computational theory of spike-timing
dependent plasticity. In Advances in Neural Information Processing Systems (NIPS) 2005.
[8] Legenstein R, Maass W: A criterion for the convergence of learning with spike timing dependent
plasticity. In Advances in Neural Information Processing Systems (NIPS) 2006.
[9] Buesing L, Maass W: Simplified rules and theoretical analysis for information bottleneck optimization and PCA with spiking neurons. In Adv in Neural Information Processing Systems (NIPS) 2007.
[10] Legenstein R, Pecevski D, Maass W: Theoretical analysis of learning with reward-modulated spiketiming-dependent plasticity. In Advances in Neural Information Processing Systems (NIPS) 2008.
[11] Tishby N, Pereira F, Bialek W: The information bottleneck method. In Proc. of the 37-th Annual Allerton Conference on Communication, Control and Computing. Edited by Hajek B, Sreenivas R 1999.
[12] Balduzzi D, Tononi G: What can neurons do for their brain? Communicate selectivity with spikes.
To appear in Theory in Biosciences 2012.
[13] Balduzzi D, Ortega PA, Besserve M: Metabolic cost as an organizing principle for cooperative learning. Under review, 2012.
[14] Nere A, Olcese U, Balduzzi D, Tononi G: A neuromorphic architecture for object recognition and
motion anticipation using burst-STDP. PLoS One 2012, 7(5):e36958.
[15] Schmiedt J, Albers C, Pawelzik K: Spike timing-dependent plasticity as dynamic filter. In Advances
in Neural Information Processing Systems (NIPS) 2010.
[16] Anthony M, Bartlett PL: Neural Network Learning: Theoretical Foundations. Cambridge Univ Press
1999.
[17] Freund Y, Schapire RE: Large Margin Classification Using the Perceptron Algorithm. Machine Learning 1999, 37(3):277?296.
[18] Ecker AS, Berens P, Keliris GA, Bethge M, Logothetis NK, Tolias AS: Decorrelated neuronal firing in
cortical microcircuits. Science 2010, 327(5965):584?7.
[19] Dan Y, Poo MM: Spike timing-dependent plasticity of neural circuits. Neuron 2004, 44:23?30.
[20] Gerstner W: Time structure of the activity in neural network models. Phys. Rev. E 1995, 51:738?758.
[21] Geman S, Bienenstock E, Doursat R: Neural Networks and the Bias/Variance Dilemma. Neural Comp
1992, 4:1?58.
[22] Freund Y, Schapire RE: Experiments with a New Boosting Algorithm. In Machine Learning: Proceedings of the Thirteenth International Conference 1996.
[23] Schapire RE, Freund Y, Bartlett P, Lee WS: Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods. The Annals of Statistics 1998, 26(5).
[24] Boucheron S, Bousquet O, Lugosi G: Theory of classification: A survey of some recent advances.
ESAIM: PS 2005, 9:323?375.
[25] Hasenstaub A, Otte S, Callaway E, Sejnowski TJ: Metabolic cost as a unifying principle governing
neuronal biophysics. Proc Natl Acad Sci U S A 2010, 107(27):12329?34.
[26] Fusi S, Drew P, Abbott L: Cascade Models of Synaptically Stored Memories. Neuron 2005, 45:599?
611.
[27] Fusi S, Abbott L: Limits on the memory storage capacity of bounded synapses. Nature Neuroscience
2007, 10(4):485?493.
[28] Tononi G, Cirelli C: Sleep function and synaptic homeostasis. Sleep Med Rev 2006, 10:49?62.
[29] Vyazovskiy VV, Cirelli C, Pfister-Genskow M, Faraguna U, Tononi G: Molecular and electrophysiological evidence for net synaptic potentiation in wake and depression in sleep. Nat Neurosci 2008,
11(2):200?8.
[30] Vyazovskiy VV, Olcese U, Lazimy Y, Faraguna U, Esser SK, Williams JC, Cirelli C, Tononi G: Cortical
firing and sleep homeostasis. Neuron 2009, 63(6):865?78.
[31] Maret S, Faraguna U, Nelson AB, Cirelli C, Tononi G: Sleep and waking modulate spine turnover in
the adolescent mouse cortex. Nat Neurosci 2011, 14(11):1418?1420.
[32] Masquelier T, Guyonneau, R and Thorpe SJ: Competitive STDP-Based Spike Pattern Learning. Neural
Computation 2009, 21(5):1259?1276.
[33] Roelfsema PR, van Ooyen A: Attention-gated reinforcement learning of internal representations for
classification. Neural Comput 2005, 17(10):2176?2214.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1972-self-regulation-mechanism-of-temporally-asymmetric-hebbian-plasticity.pdf

Self-regulation Mechanism of Temporally
Asymmetric Hebbian Plasticity

Narihisa Matsumoto
Graduate School of Science and Engineering
Saitama University:
RIKEN Brain Science Institute
Saitama 351-0198, Japan
xmatumo@brain.riken.go.jp

Masato Okada
RIKEN Brain Science Institute
Saitama 351-0198, Japan
okada@brain.riken.go.jp

Abstract
Recent biological experimental findings have shown that the synaptic plasticity depends on the relative timing of the pre- and postsynaptic spikes which determines whether Long Term Potentiation
(LTP) occurs or Long Term Depression (LTD) does. The synaptic
plasticity has been called ?Temporally Asymmetric Hebbian plasticity (TAH)?. Many authors have numerically shown that spatiotemporal patterns can be stored in neural networks. However, the
mathematical mechanism for storage of the spatio-temporal patterns is still unknown, especially the effects of LTD. In this paper,
we employ a simple neural network model and show that interference of LTP and LTD disappears in a sparse coding scheme.
On the other hand, it is known that the covariance learning is indispensable for storing sparse patterns. We also show that TAH
qualitatively has the same effect as the covariance learning when
spatio-temporal patterns are embedded in the network.

1

Introduction

Recent biological experimental findings have indicated that the synaptic plasticity
depends on the relative timing of the pre- and post- synaptic spikes which determines whether Long Term Potentiation (LTP) occurs or Long Term Depression
(LTD) does [1, 2, 3]. LTP occurs when a presynaptic firing precedes a postsynaptic
one by no more than about 20ms. In contrast, LTD occurs when a presynaptic
firing follows a postsynaptic one. A rapid transition occurs between LTP and LTD
within a time difference of a few ms. Such a learning rule is called ?Temporally
Asymmetric Hebbian learning (TAH)? [4, 5] or ?Spike Timing Dependent synaptic
Plasticity (STDP)? [6]. Many authors have numerically shown that spatio-temporal
patterns can be stored in neural networks [6, 7, 8, 9, 10, 11]. Song et al. discussed
the variablity of spike generation about the network consisting of spiking neurons
using TAH [6]. They found that the condition that the area of LTD was slightly
larger than that of LTP was indispensable of the stability. Namely, the balance of
LTP and LTD is crucial. Yoshioka also discussed the associative memory network

consisting of spiking neurons using TAH [11]. He found that the area of LTP was
needed to be equal to that of LTD for stable retrieval. Munro and Hernandez numerically showed that a network can retrieve spatio-temporal patterns even in a
noisy environment owing to LTD [9]. However, they did not discuss the reason why
TAH was effective in terms of the storage and retrieval of the spatio-temporal patterns. Since TAH has not only the effect of LTP but that of LTD, the interference
of LTP and LTD may prevent retrieval of the patterns. To investigate this unknown
mathematical mechanism for retrieval, we employ an associative memory network
consisting of binary neurons. To simplify the dynamics of internal potential enables
us to analyze the details of the retrieval process. We use a learning rule that is
the similar formulation in the previous works. We show the mechanism that the
spatio-temporal patterns can be retrieved in this network.
There are many works concerned with associative memory networks that store
spatio-temporal patterns by the covariance learning [12, 13]. Many biological findings imply that sparse coding schemes may be used in the brain [14]. It is wellknown that the covariance learning is indispensable when the sparse patterns are
embedded in a network as attractors [15, 16]. The information on the firing rate
for the stored patterns is not indispensable for TAH, although it is indispensable
for the covariance learning. We theoretically show that TAH qualitatively has the
same effect as the covariance learning when the spatio-temporal patterns are embedded in the network. This means that the difference in spike times induces LTP
or LTD, and the effect of the firing rate information can be canceled out by this
spike time difference. We conclude that this is the reason why TAH doesn?t require
the information on the firing rate for the stored patterns.

2

Model

We investigate a network consisting of N binary neurons that are connected mutually. In this paper, we consider the case of N ? ?. We use a neuronal model with
binary state, {0, 1}. We also use discrete time steps and the following synchronous
updating rule,
ui (t) =

N
X

Jij xj (t),

(1)

j=1

xi (t + 1) = ?(ui (t) ? ?),

1, u ? 0
?(u) =
0, u < 0,

(2)
(3)

where xi (t) is the state of the i-th neuron at time t, ui (t) its internal potential,
and ? a uniform threshold. If the i-th neuron fires at time t, its state is xi (t) = 1;
otherwise, xi (t) = 0. The specific value of the threshold is discussed later. Jij is
the synaptic weight from the j-th neuron to the i-th neuron. Each element ?i? of
?
the ?-th memory pattern ?? = (?1? , ?2? , ? ? ?, ? N
) is generated independently by,
?

Prob[?i? = 1] = 1 ? Prob[?i? = 0] = f.
E[?i?]

(4)

The expectation of ? is
= f, and thus, f can be considered as the mean firing
rate of the memory pattern. The memory pattern is ?sparse? when f ? 0, and
this coding scheme is called ?sparse coding?. The synaptic weight Jij follows the
synaptic plasticity that depends on the difference in spike times between the i-th
(post-) and j-th (pre-) neurons. The difference determines whether LTP occurs or
LTD does. Such a learning rule is called ?Temporally Asymmetric Hebbian learning
(TAH)? or ?Spike Timing Dependent synaptic Plasticity (STDP)?. This biological

(a)

60
40

1

LTP

LTP

20

?Jij

Change in EPSP amplitude(%)

experimental finding indicates that LTP or LTD is induced when the difference in
the pre- and post-synaptic spike times falls within about 20ms [3] (Figure 1(a)).
We define that one time step in equations (1)?(3) corresponds to 20ms in Figure
1(a), and a time duration within 20ms is ignored (Figure 1(b)). Figure 1(b) shows
that LTP occurs when the j-th neuron fires one time step before the i-th neuron
does, ?i?+1 = ?j? = 1, and that LTD occurs when the j-th neuron fires one time step
after the i-th neuron does, ?i??1 = ?j? = 1. The previous work indicates the blance
of LTP and LTD is significant [6]. Therefore, we define that the area of LTP is the

0

0

-20

LTD

LTD

-40

-1

-60
-100 -80 -60 -40 -20

0

20

40

tpre - tpost (ms)

60

80 100

(b)

-2

-1

0

1

2

tj - ti

Figure 1: Temporally Asymmetric Hebbian plasticity. (a): The result of biological
finding [3] and (b): the learning rule in our model. LTP occurs when the j-th
neuron fires one time step before the i-th one. On the contrary, LTD occurs when
the j-th neuron fires one time step after the i-th one. Synaptic weight Jij is followed
by this rule.
same as that of LTD, and that the amplitude of LTP is also the same as that of
LTD. On the basis of these definitions, we employ the following learning rule,
p
X
1
(? ?+1 ?j? ? ?i??1 ?j? ).
Jij =
N f(1 ? f) ?=1 i

(5)

The number of memory patterns is p = ?N where ? is defined as the ?loading
rate?. There is a critical value ?C of loading rate. If the loading rate is larger than
?C , the pattern sequence becomes unstable. ?C is called the ?storage capacity?.
The previous works have shown that the learning method of equation (5) can store
spatio-temporal patterns, that is, pattern sequences [9, 10]. We show that p memory
patterns are retrieved periodically like ?1 ? ? 2 ? ? ? ? ? ? p ? ? 1 ? ? ? ?. In other
words, ?1 is retrieved at t = 1, ?2 at t = 2, and ? 1 at t = p + 1.
Here, we discuss the value of threshold ?. It is well-known that the threshold
value should be controlled according to the progress of the retrieval process timedependently [15, 16]. One candidate algorithm for controlling the threshold value
is to maintain the mean firing rate of the network at that of memory pattern, f, as
follows,
N
N
1 X
1 X
xi (t) =
?(ui (t) ? ?(t)).
(6)
f =
N
N
i=1

i=1

It is known that the obtained threshold value is nearly optimal, since it approximately gives a maximal storage capacity value [16].

3

Theory

Many neural network models that store and retrieve sequential patterns by TAH
have been discussed by many authors [7, 8, 9, 10]. They have numerically shown that

TAH is effective for storing pattern sequences. For example, Munro and Hernandez
showed that their model could retrieve a stored pattern sequence even in a noisy
environment [9]. However, the previous works have not mentioned the reason why
TAH is effective. Exploring such a mechanism is the main purpose of our paper.
Here, we discuss the mechanism that the network learned by TAH can store and
retrieve sequential patterns. Before providing details of the retrieval process, we
discuss a simple situation where the number of memory patterns is very small
relative to the number of neurons, i.e., p ? O(1). Let the state at time t be the
same as the t-th memory pattern: x(t) = ?t . Then, the internal potential u i (t) of
the equation (1) is given by,
ui (t) = ?it+1 ? ?it?1 .

(7)

ui (t) depends on two independent random variables, ?it+1 and ?it?1 , according to the
equation (4). The first term ?it+1 of the equation (7) is a signal term for the recall of
the pattern ?t+1 , which is designed to be retrieved at time t+1, and the second term
?it?1 can interfere in retrieval of ?t+1 . According to the equation (7), ui (t) takes a
value of 0, ?1 or +1. ? it?1 = 1 means that the interference of LTD exists. If the
threshold ?(t) is set between 0 and +1, ?it+1 = 0 isn?t influenced by the interference
of ?it?1 = 1. When ?it+1 = 1 and ?it?1 = 1, the interference does influence the
retrieval of ? t+1 . We consider the probability distribution of the internal potential
ui (t) to examine how the interference of LTD influences the retrieval of ?t+1 . The
probability of ? it+1 = 1 and ?it?1 = 1 is f 2 , that of ?it+1 = 1 and ?it?1 = 0 is f ? f 2 ,
that of ?it+1 = 0 and ?it?1 = 1 is f ? f 2 , and that of ?it+1 = 0 and ?it?1 = 0 is
(1 ? f)2 . Then the probability distribution of u i (t) is given by this equation
Prob(ui (t)) = (f ?f 2 )?(ui (t)?1)+(1?2f +2f 2 )?(ui (t))+(f ?f 2 )?(ui (t)+1). (8)

Since the threshold ?(t) is set between 0 and +1, the state xi (t + 1) is 1 with
probability f ? f 2 and 0 with 1 ? f + f 2 . The overlap between the state x(t + 1)
and the memory pattern ? t+1 is given by,
N

mt+1 (t + 1) =

X
1
(? t+1 ? f)xi (t + 1) = 1 ? f.
N f(1 ? f) i=1 i

(9)

In a sparse limit, f ? 0, the probability of ? it+1 = 1 and ?it?1 = 1 approaches 0.
This means that the interference of LTD disappears in a sparse limit, and the model
can retrieve the next pattern ?t+1 . Then the overlap mt+1 (t + 1) approaches 1.
Next, we discuss whether the information on the firing rate is indispensable for
TAH or not. To investigate this, we consider the case that the number of memory
patterns is extensively large, i.e., p ? O(N ). Using the equation (9), the internal
potential ui (t) of the i-th neuron at time t is represented as,
ui (t) = (?it+1 ? ?it?1 )mt (t) + zi (t),
p
X
zi (t) =
(?i?+1 ? ?i??1 )m? (t).

(10)
(11)

?6=t

zi (t) is called the ?cross-talk noise?, which represents contributions from non-target
patterns excluding ?t?1 and prevents the target pattern ?t+1 from being retrieved.
This disappeared in the finite loading case, p ? O(1).

It is well-known that the covariance learning is indispensable when the sparse patterns are embedded in a network as attractors [15, 16]. Under sparse coding schemes,

unless the covariance learning is employed, the cross-talk noise does diverge in the
large N limit. Consequently, the patterns can not be stored. The information on
the firing rate for the stored patterns is not indispensable for TAH, although it is
indispensable for the covariance learning. We use the method of the ?statistical
neurodynamics? [17, 18] to examine whether the variance of cross-talk noise diverges or not. If a pattern sequence can be stored, the cross-talk noise is obeyed
by a Gaussian distribution with mean 0 and time-dependent variance ? 2 (t). Otherwise, ?2 (t) diverges. Since ?2 (t) is changing over time, it is necessary to control
a threshold at an appropriate value at each time step [15, 16]. According to the
statistical neurodynamics, we obtain the recursive equations for the overlap mt (t)
between the network state x(t) and the target pattern ?t and the variance ?2 (t).
The details of the derivation will be shown elsewhere. Here, we show the recursive
equations for mt (t) and ? 2 (t),
1 ? 2f
1?f
f
mt (t) =
erf(?0 ) ?
erf(?1 ) + erf(?2 ),
(12)
2
2
2
t
a
X
Y
? 2 (t) =
C
?q(t
?
a)
U 2 (t ? b + 1),
(13)
2(a+1) (a+1)
a=0

b=1

2
2
2
1
U (t) = ?
{(1 ? 2f + 2f 2 )e??0 + f(1 ? f)(e??1 + e??2 )},
(14)
2??(t ? 1)

1
1 ? (1 ? 2f + 2f 2 )erf(?0 ) ? f(1 ? f)(erf(?1 ) + erf(?2 )) ,
(15)
q(t) =
2 Z
y
2
b!
, a! = a ? (a ? 1) ? ? ? ? ? 1,
erf(y) = ?
exp (?u2 )du, b Ca =
? 0
a!(b ? a)!
?(t ? 1)
?mt?1 (t ? 1) + ?(t ? 1)
mt?1 (t ? 1) + ?(t ? 1)
?
?
?0 = ?
, ?1 =
, ?2 =
.
2?(t ? 1)
2?(t ? 1)
2?(t ? 1)
These equations reveal that the variance ?2 (t) of cross-talk noise does not diverge
as long as a pattern sequence can be retrieved. This result means that TAH qualitatively has the same effect as the covariance learning.

Next, we discuss the mechanism that the variance of cross-talk noise does not diverge. Let us consider the equation (5). Synaptic weight Jij from j-th neuron to
i-th neuron is also derived as follows,
p
p
X
X
1
1
Jij =
(?i?+1 ?j? ? ?i??1 ?j? ) =
(? ? ? ??1 ? ?i? ?j?+1 )
N f(1 ? f) ?=1
N f(1 ? f) ?=1 i j
=

p
n
o
X
1
?i? (?j??1 ? f) ? (?j?+1 ? f)
N f(1 ? f) ?=1

(16)

This equation implies that TAH has the information on the firing rate of the memory
patterns when spatio-temporal patterns are embedded in a network. Therefore,
the variance of cross-talk noise doesn?t diverge, and this is another factor for the
network learned by TAH to store and retrieve a pattern sequence. We conclude
that the difference in spike times induces LTP or LTD, and the effect of the firing
rate information can be canceled out by this spike times difference.

4

Results

We investigate the property of our model and examine the following two conditions:
a fixed threshold and a time-dependent threshold, using the statistical neurodynamics and computer simulations.

overlap (solid), activity/f (dashed)

Figure 2 shows
how the overlap mt (t) and the mean firing rate of the network,
P
1
x?(t) = N i xi (t), depend on the loading rate ? when the mean firing rate of
the memory pattern is f = 0.1 and the threshold is ? = 0.52, where the storage
capacity is maximum with respect to the threshold ?. The stored pattern sequence
can be retrieved when the initial overlap m1 (1) is greater than the critical value
mC . The lower line indicates how the critical initial overlap m C depends on the
loading rate ?. In other words, the lower line represents the basin of attraction
for the retrieved sequence. The upper line denotes a steady value of overlap mt (t)
when the pattern sequence is retrieved. mt (t) is obtained by setting the initial
state to the first memory pattern: x(1) = ?1 . In this case, the storage capacity is
?C = 0.27. The dashed line shows a steady value of the normalized mean firing rate
of network, x?(t)/f, for the pattern sequence. The data points and error bars indicate
the results of the computer simulations with 5000 neurons: N = 5000. The former
indicates mean values and the latter does variances in 10 trials. Since the results
1.2
1
0.8
0.6
0.4
0.2
0
0

0.05

0.1

0.15

0.2

0.25

0.3

loading rate

Figure 2 !!The critical overlap (the lower line) and the
overlap at the stationary state (the upper line). The
dashed line shows the mean firing rate of the network
divided firing rate which is 0.1. The threshold is 0.52
and the number of neurons is 5000. The data points and
error bars show the means and variances, respectively, in
10 trials of computer simulations. The storage capacity
is 0.27.

of the computer simulations coincide with those of the statistical neurodynamics,
hereafter, we show the results only of the statistical neurodynamics.

overlap (solid), activity/f (dashed)

Next, we examine the threshold control scheme in the equation (6), where the
threshold is controlled to maintain the mean firing rate of the network at f. q(t)
PN
2
in equation (15) is equal to the mean firing rate because q(t) = N1
i=1 (xi (t)) =
P
N
1
i=1 xi (t) under the condition xi (t) = {0, 1}. Thus, the threshold is adjusted to
N
satisfy the following equation,

1
f = q(t) =
1 ? (1 ? 2f + 2f 2 )erf(?0 ) ? f(1 ? f)(erf(?1 ) + erf(?2 )) .
(17)
2
Figure 3 shows the overlap mt (t) as a function of loading rate ? with f = 0.1. The
storage capacity is ?C = 0.234. The basin of attraction becomes larger than that
of the fixed threshold condition, ? = 0.52 (Figure 2). Thus, the network becomes
robust against noise. This means that even if the initial state x(1) is different from
the first memory pattern ?1 , that is, the state includes a lot of noise, the pattern
sequence can be retrieved.
1.2
1
0.8
0.6
0.4
0.2
0

0

0.05

0.1

0.15

0.2

loading rate

0.25

0.3

Figure 3 !!The critical overlap (the lower line) and the
overlap at the stationary state (the upper line) when
the threshold is changing over time to maintain mean
firing rate of the network at f. The dashed line shows
the mean firing rates of the network divided firing rate
which is 0.1. The basin of attraction become larger than
that of the fixed threshold condition: Figure 2.

Finally, we discuss how the storage capacity depends on the firing rate f of the
1
memory pattern. It is known that the storage capacity diverges as f | log
f | in a
sparse limit, f ? 0 [19, 20]. Therefore, we investigate the asymptotic property

of the storage capacity in a sparse limit. Figure 4 shows how the storage capacity
depends on the firing rate where the threshold is controlled to maintain the network
1
activity at f (symbol ?). The storage capacity diverges as f | log
f | in a sparse limit.
0.03
0.025

Figure 4 !! The storage capacity as a function of f in
the case of maintaining activity at f (symbol ?). Ths
1
storage capacity diverges as f | log
in a sparse limit.
f|

?C f

0.02
0.015
0.01
0.005
0 0

0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45

1/|log f|

5

Discussion

Using a simple neural network model, we have discussed the mechanism that TAH
enables the network to store and retrieve a pattern sequence. First, we showed that
the interference of LTP and LTD disappeared in a sparse coding scheme. This is
a factor to enable the network to store and retrieve a pattern sequence. Next, we
showed the mechanism that TAH qualitatively had the same effect as the covariance
learning by analyzing the stability of the stored pattern sequence and the retrieval
process by means of the statistical neurodynamics. Consequently, the variance of
cross-talk noise didn?t diverge, and this is another factor for the network learned by
TAH to store and retrieve a pattern sequence. We conclude that the difference in
spike times induces LTP or LTD, and the effect of the firing rate information can
be canceled out by this spike times difference. We investigated the property of our
model. To improve the retrieval property of the basin of attraction, we introduced
a threshold control algorithm where a threshold value was adjusted to maintain the
mean firing rate of the network at that of a memory pattern. As a result, we found
that this scheme enlarged the basin of attraction, and that the network became
1
robust against noise. We also found that the loading rate diverged as f | log
f | in a
sparse limit, f ? 0.

Here, we compare the storage capacity of our model with that of the model using
the covariance learning (Figure 5). The dynamical equations of the model using the
covariance learning is derived by Kitano and Aoyagi [13]. We calculate the storage
capacity ?COV
from their dynamical equations and compare these of our model,
C
?TCAH , by the ratio of ? TCAH /?COV
. The threshold control method is the same as
C
in this paper. As f decreases, the ratio of storage capacities approaches 0.5. The
contribution of LTD reduces the storage capacity of our model to half. Therefore,
in terms of the storage capacity, the covariance learning is better than TAH. But, as
we discussed previously, the information of the firing rate is indispensable in TAH.
In biological systems, to get the information of the firing rate is difficult.
0.52
0.5

/ ?COV
?TAH
C
C

0.48

Figure 5 !! The comparison of the storage capacity of
our model with that of the model using the covariance
learning. As f decreases, the ratio of storage capacity
approaches 0.5.

0.46
0.44
0.42
0.4
0.38
0.36
0.34
-10

-9

-8

-7

-6

-5

-4

-3

-2

-1

log10f

References
[1] G. Q. Bi and M. M. Poo. Synaptic modifications in cultured hippocampal
neurons: Dependence on spike timing, synaptic strength, and postsynaptic cell

type. The Journal of Neuroscience, 18:10464?10472, 1998.
[2] H. Markram, J. L?
ubke, M. Frotscher, and B. Sakmann. Regulation of synaptic
efficacy by coincidence of postsynaptic aps and epsps. Science, 275:213?215,
1997.
[3] L. I. Zhang, H. W. Tao, C. E. Holt, W. A. Harris, and M. M. Poo. A critical window for cooperation and competition among developing retinotectal
synapses. Nature, 395:37?44, 1998.
[4] L. F. Abbott and S. Song. Temporally asymmetric hebbian learning, spike
timing and neuronal response variability. In Advances in Neural Information
Processing Systems 11, pages 69?75. MIT Press, 1999.
[5] J. Rubin, D. D. Lee, and H. Sompolinsky. Equilibrium properties of temporally
asymmetric hebbian plasticity. Physical Review Letters, 86:364?367, 2001.
[6] S. Song, K. D. Miller, and L. F. Abbott. Competitive hebbian learning through
spike-timing-dependent synaptic plasticity. Nature Neuroscience, 3:919?926,
2000.
[7] W. Gerstner, R. Kempter, J. L. van Hemmen, and H. Wagner. A neuronal
learning rule for sub-millisecond temporal coding. Nature, 383:76?78, 1996.
[8] R. Kempter, W. Gerstner, and J. L. van Hemmen. Hebbian learning and
spiking neurons. Physical Review E, 59:4498?4514, 1999.
[9] P. Munro and G. Hernandez. LTD facilitates learning in a noisy environment.
In Advances in Neural Information Processing Systems 12, pages 150?156. MIT
Press, 2000.
[10] R. P. N. Rao and T. J. Sejnowski. Predictive sequence learning in recurrent
neocortical circuits. In Advances in Neural Information Processing Systems 12,
pages 164?170. MIT Press, 2000.
[11] M. Yoshioka. to be published in Physical Review E, 2001.
[12] G. Chechik, I. Meilijson, and E. Ruppin. Effective learning requires neuronal
remodeling of hebbian synapses. In Advances in Neural Information Processing
Systems 11, pages 96?102. MIT Press, 1999.
[13] K. Kitano and T. Aoyagi. Retrieval dynamics of neural networks for sparsely
coded sequential patterns. Journal of Physics A: Mathematical and General,
31:L613?L620, 1998.
[14] M. Miyashita. Neuronal correlate of visual associative long-term memory in
the primate temporal cortex. Nature, 335:817?820, 1988.
[15] S. Amari. Characteristics of sparsely encoded associative memory. Neural
Networks, 2:1007?1018, 1989.
[16] M. Okada. Notions of associative memory and sparse coding. Neural Networks,
9:1429?1458, 1996.
[17] S. Amari and K. Maginu. Statistical neurodynamics of various versions of
correlation associative memory. Neural Networks, 1:63?73, 1988.
[18] M. Okada. A hierarchy of macrodynamical equations for associative memory.
Neural Networks, 8:833?838, 1995.
[19] M. V. Tsodyks and M. V. Feigle?man. The enhanced strage capacity in neural
networks with low activity level. Europhysics Letters, 6:101?105, 1988.
[20] C. J. Perez-Vicente and D. J. Amit. Optimized network for sparsely coded
patterns. Journal of Physics A: Mathematical and General, 22:559?569, 1989.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

