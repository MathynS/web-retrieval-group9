query sentence: Storing potentiation of synaptic strengths
---------------------------------------------------------------------
title: 100-storing-covariance-by-the-associative-long-term-potentiation-and-depression-of-synaptic-strengths-in-the-hippocampus.pdf

394

STORING COVARIANCE BY THE ASSOCIATIVE
LONG?TERM POTENTIATION AND DEPRESSION
OF SYNAPTIC STRENGTHS IN THE HIPPOCAMPUS
Patric K. Stanton? and Terrence J. Sejnowski t
Department of Biophysics
Johns Hopkins University
Baltimore, MD 21218
ABSTRACT

In modeling studies or memory based on neural networks, both the selective
enhancement and depression or synaptic strengths are required ror effident storage
or inrormation (Sejnowski, 1977a,b; Kohonen, 1984; Bienenstock et aI, 1982;
Sejnowski and Tesauro, 1989). We have tested this assumption in the hippocampus,
a cortical structure or the brain that is involved in long-term memory. A brier,
high-frequency activation or excitatory synapses in the hippocampus produces an
increase in synaptic strength known as long-term potentiation, or LTP (BUss and
Lomo, 1973), that can last ror many days. LTP is known to be Hebbian since it
requires the simultaneous release or neurotransmitter from presynaptic terminals
coupled with postsynaptic depolarization (Kelso et al, 1986; Malinow and Miller,
1986; Gustatrson et al, 1987). However, a mechanism ror the persistent reduction or
synaptic strength that could balance LTP has not yet been demonstrated. We studied the associative interactions between separate inputs onto the same dendritic
trees or hippocampal pyramidal cells or field CAl, and round that a low-frequency
input which, by itselr, does not persistently change synaptic strength, can either
increase (associative LTP) or decrease in strength (associative long-term depression
or LTD) depending upon whether it is positively or negatively correlated in time
with a second, high-frequency bursting input. LTP or synaptic strength is Hebbian,
and LTD is anti-Hebbian since it is elicited by pairing presynaptic firing with postsynaptic hyperpolarization sufficient to block postsynaptic activity. Thus, associative LTP and associative LTO are capable or storing inrormation contained in the
covariance between separate, converging hippocampal inputs?

?Present address: Dep~ents of NeW'Oscience and Neurology, Albert Einstein College
of Medicine, 1410 Pelham Parkway South, Bronx, NY 10461 USA.
tPresent address: Computational Neurobiology Laboratory, The Salk Institute, P.O. Box
85800, San Diego, CA 92138 USA.

Storing Covariance by Synaptic Strengths in the Hippocampus

INTRODUCTION
Associative LTP can be produced in some hippocampal neuroos when lowfrequency. (Weak) and high-frequency (Strong) inputs to the same cells are simultaneously activated (Levy and Steward, 1979; Levy and Steward, 1983; Barrionuevo and
Brown, 1983). When stimulated alone, a weak input does not have a long-lasting effect
on synaptic strength; however, when paired with stimulation of a separate strong input
sufficient to produce homo synaptic LTP of that pathway, the weak pathway is associatively potentiated. Neural network modeling studies have predicted that, in addition to
this Hebbian form of plasticity, synaptic strength should be weakened when weak and
strong inputs are anti-correlated (Sejnowski, 1977a,b; Kohonen, 1984; Bienenstock et al,
1982; Sejnowski and Tesauro, 1989). Evidence for heterosynaptic depression in the hippocampus has been found for inputs that are inactive (Levy and Steward, 1979; Lynch et
al, 1977) or weakly active (Levy and Steward, 1983) during the stimulation of a strong
input, but this depression did not depend on any pattern of weak input activity and was
not typically as long-lasting as LTP.
Therefore, we searched for conditions under which stimulation of a hippocampal
pathway, rather than its inactivity, could produce either long-term depression or potentiation of synaptic strengths, depending on the pattern of stimulation. The stimulus paradigm that we used, illustrated in Fig. I, is based on the finding that bursts of stimuli at 5
Hz are optimal in eliciting LTP in the hippocampus (Larson and Lynch, 1986). A highfrequency burst (S'IRONG) stimulus was applied to Schaffer collateral axons and a lowfrequency (WEAK) stimulus given to a separate subicular input coming from the opposite side of the recording site, but terminating on dendrites of the same population of CAl
pyramidal neurons. Due to the rhythmic nature of the strong input bursts, each weak
input shock could be either superimposed on the middle of each burst of the strong input
(IN PHASE), or placed symmetrically between bursts (OUT OF PHASE).

RESULTS
Extracellular evoked field potentials were recorded from the apical dendritic and
somatic layers of CAl pyramidal cells. The weak stimulus train was first applied alone
and did not itself induce long-lasting changes. The strong site was then stimulated alone,
which elicited homosynaptic LTP of the strong pathway but did not significantly alter
amplitude of responses to the weak input. When weak and strong inputs were activated
IN PHASE, there was an associative LTP of the weak input synapses, as shown in Fig.
2a. Both the synaptic excitatory post-synaptic potential (e.p.s.p.) (Ae.p.s.p. = +49.8 ?
7.8%, n=20) and population action potential (&Pike = +65.4 ? 16.0%, n=14) were
significantly enhanced for at least 60 min up to 180 min following stimulation.
In contrast, when weak and strong inputs were applied OUT OF PHASE, they elicited an associative long-term depression (LTO) of the weak input synapses, as shown in
Fig. 2b. There was a marked reduction in the population spike (-46.5 ? 11.4%, n=10)
with smaller decreases in the e.p.s.p. (-13.8 ? 3.5%, n=13). Note that the stimulus patterns applied to each input were identical in these two experiments, and only the relative

395

396

Stanton and Sejnowski

phase of the weak and strong stimuli was altered. With these stimulus patterns. synaptic
strength could be repeatedly enhanced and depressed in a single slice. as illustrated in Fig
2c. As a control experiment to determine whether information concerning covariance
between the inputs was actually a determinant of plasticity. we combined the in phase
and out of phase conditions, giving both the weak input shocks superimposed on the
bursts plus those between the bursts. for a net frequency of 10 Hz. This pattern. which
resulted in zero covariance between weak and strong inputs. produced no net change in
weak input synaptic strength measmed by extracellular evoked potentials. Thus. the assoa

b
A.SSOCIA.TIVE STIMULUS PA.RA.DIGMS
POSJTIVE.LY CORKELA TED ? "IN PHASE"

~K~~ _I~__~I____~I____~I_
SI1IONG,NJO\IT

. u.Jj1l 11l. -1---1&1111.....
11 ---1&1
111.....
11 ---,I~IIII

NEGATIVELY CORRELATED? 'our OF PHASE"
W[AKIN'lTf

STIONG 'N''''

~I

11111

--,-;

11111

11111

Figure 1. Hippocampal slice preparation and stimulus paradigms. a: The in vitro hippocampal slice showing recording sites in CAl pyramidal cell somatic (stratum pyramidale) and dendritic (stratum radiatum) layers. and stimulus sites activating Schaffer collateral (STRONG) and commissural (WEAK) afferents. Hippocampal slices (400 Jlm
thick) were incubated in an interface slice chamber at 34-35 0 C. Extracellular (1-5 M!l
resistance, 2M NaCI filled) and intracellular (70-120 M 2M K-acetate filled) recording electrodes. and bipolar glass-insulated platinum wire stimulating electrodes (50 Jlm
tip diameter). were prepared by standard methods (Mody et al, 1988). b: Stimulus paradigms used. Strong input stimuli (STRONG INPUT) were four trains of 100 Hz bursts.
Each burst had 5 stimuli and the interburst interval was 200 msec. Each train lasted 2
seconds for a total of 50 stimuli. Weak input stimuli (WEAK INPUT) were four trains of
shocks at 5 Hz frequency. each train lasting for 2 seconds. When these inputs were IN
PHASE. the weak single shocks were superimposed on the middle of each burst of the
strong input. When the weak input was OUT OF PHASE. the single shocks were placed
symmetrically between the bursts.

n.

Storing Covariance by Synaptic Strengths in the Hippocampus

ciative LTP and LTD mechanisms appear to be balanced in a manner ideal for the
storage of temporal covariance relations.
The simultaneous depolarization of the postsynaptic membrane and activation of
glutamate receptors of the N-methyl-D-aspartate (NMDA) subtype appears to be necessary for LTP induction (Collingridge et ai, 1983; Harris et al, 1984; Wigstrom and Gustaffson, 1984). The SJ?read of current from strong to weak synapses in the dendritic tree,
d

ASSOCIATIVE

LON(;.TE~

I'OTENTIATION

LONG-TE~

DE,/tESSION

-

!!Ll!!!!.

b

ASSOCIATIVE

I

11111

?

11111.
I

c

e...

I

I

I

I

Figure 2. mustration of associative long-term potentiation (LTP) and associative longterm depression (LTD) using extracellular recordings. a: Associative LTP of evoked
excitatory postsynaptic potentials (e.p.s.p.'s) and population action potential responses in
the weak inpuL Test responses are shown before (Pre) and 30 min after (post) application of weak stimuli in phase with the coactive strong input. b: Associative LTD of
evoked e.p.s.p.'s and population spike responses in the weak input. Test responses are
shown before (Pre) and 30 min after (post) application of weak stimuli out of phase with
the coactive strong input. c: Time course of the changes in population spike amplitude
observed at each input for a typical experiment. Test responses from the strong input (S,
open circles), show that the high-frequency bursts (5 pulses/l00 Hz, 200 msec interburst
interval as in Fig. 1) elicited synapse-specific LTP independent of other input activity.
Test responses from the weak input (W. filled circles) show that stimulation of the weak
pathway out of phase with the strong one produced associative LTD (Assoc LTD) of this
input. Associative LTP (Assoc LTP) of the same pathway was then elicited following in
phase stimulation. Amplitude and duration of associative LTD or LTP could be increased
by stimulating input pathways with more trains of shocks.

397

398

Stanton and Sejnowski

coupled with release of glutamate from the weak inputs, could account for the ability of
the strong pathway to associatively potentiate a weak one (Kelso et al, 1986; Malinow
and Miller, 1986; Gustaffson et al, 1987). Consistent with this hypothesis, we find that
the NMDA receptor antagonist 2-amino-S-phosphonovaleric acid (APS, 10 J.1M) blocks
induction of associative LTP in CAl pyramidal neurons (data not shown, n=S). In contrast, the application of APS to the bathing solution at this same concentration had no
significant effect on associative LTD (data not shown, n=6). Thus, the induction of LTD
seems to involve cellular mechanisms different from associative LTP.
The conditions necessary for LTD induction were explored in another series of
experiments using intracellular recordings from CAl pyramidal neurons made using
standard techniques (Mody et al, 1988). Induction of associative LTP (Fig 3; WEAK
S+W IN PHASE) produced an increase in amplitude of the single cell evoked e.p.s.p. and
a lowered action potential threshold in the weak pathway, as reported previously (Barrionuevo and Brown, 1983). Conversely, the induction of associative LTD (Fig. 3;
WEAK S+W OUT OF PHASE) was accompanied by a long-lasting reduction of e.p.s.p.
amplitude and reduced ability to elicit action potential firing. As in control extracellular
experiments, the weak input alone produced no long-lasting alterations in intracellular
e.p.s.p.'s or firing properties, while the strong input alone yielded specific increases of
the strong pathway e.p.s.p. without altering e.p.s.p. 's elicited by weak input stimulation.

PRE

30 min POST
S+W OUT OF PHASE

30 min POST
S+W IN PHASE

Figure 3. Demonstration of associative LTP and LTD using intracellular recordings from
a CAl pyramidal neuron. Intracellular e.p.s.p.'s prior to repetitive stimulation (pre), 30
min after out of phase stimulation (S+W OUT OF PHASE), and 30 min after subsequent in phase stimuli (S+W IN PHASE). The strong input (Schaffer collateral side,
lower traces) exhibited LTP of the evoked e.p.s.p. independent of weak input activity.
Out of phase stimulation of the weak (Subicular side, upper traces) pathway produced a
marked, persistent reduction in e.p.s.p. amplitude. In the same cell, subsequent in phase
stimuli resulted in associative LTP of the weak input that reversed the LTD and enhanced
amplitude of the e.p.s.p. past the original baseline. (RMP = -62 mY, RN = 30 MO)

Storing Covariance by Synaptic Strengths in the Hippocampus

A weak stimulus that is out of phase with a strong one anives when the postsynaptic neuron is hyperpolarized as a consequence of inhibitory postsynaptic potentials and
afterhyperpolarization from mechanisms intrinsic to pyramidal neurons. This suggests
that postsynaptic hyperpolarization coupled with presynaptic activation may trigger L'ID.
To test this hypothesis, we injected current with intracellular microelectrodes to hyperpolarize or depolarize the cell while stimulating a synaptic input. Pairing the injection of
depolarizing current with the weak input led to LTP of those synapses (Fig. 4a; STIM;

a

PRE

? ?IDPOST
S'I1M ? DEPOL

~l"V
lS.,.c

r
," i

COI'ITROL

-Jj

b

I

--" \

"----

(W.c:ULVllj

PRE

lOlIIin POST
STlM ? HYPERPOL

Figure 4. Pairing of postsynaptic hyperpolarization with stimulation of synapses on CAl
hippocampal pyramidal neurons produces L'ID specific to the activated pathway, while
pairing of postsynaptic depolarization with synaptic stimulation produces synapsespecific LTP. a: Intracellular evoked e.p.s.p.'s are shown at stimulated (STIM) and
unstimulated (CONTROL) pathway synapses before (Pre) and 30 min after (post) pairing a 20 mY depolarization (constant current +2.0 nA) with 5 Hz synaptic stimulation.
The stimulated pathway exhibited associative LTP of the e.p.s.p., while the control,
unstimulated input showed no change in synaptic strength. (RMP = -65 mY; RN = 35
Mfl) b: Intracellular e.p.s.p. 's are shown evoked at stimulated and control pathway
synapses before (Pre) and 30 min after (post) pairing a 20 mV hyperpolarization (constant current -1.0 nA) with 5 Hz synaptic stimulation. The input (STIM) activated during
the hyperpolarization showed associative LTD of synaptic evoked e.p.s.p.'s, while
synaptic strength of the silent input (CONTROL) was unaltered. (RMP =-62 mV; RN =
38M!l)

399

400

Stanton and Sejnowski

+64.0 -9.7%, n=4), while a control input inactive during the stimulation did not change
(CONTROL), as reported previously (Kelso et al, 1986; Malinow and Miller, 1986; Gustaffson et al, 1987). Conversely, prolonged hyperpolarizing current injection paired with
the same low-frequency stimuli led to induction of LTD in the stimulated pathway (Fig.
4b; STIM; -40.3 ? 6.3%, n=6). but not in the unstimulated pathway (CONTROL). The
application of either depolarizing current, hyperpolarizing current, or the weak 5 Hz
synaptic stimulation alone did not induce long-term alterations in synaptic strengths.
Thus. hyperpolarization and simultaneous presynaptic activity supply sufficient conditions for the induction of LTD in CAl pyramidal neurons.

CONCLUSIONS
These experiments identify a novel fono of anti-Hebbian synaptic plasticity in the
hippocampus and confirm predictions made from modeling studies of information storage
in neural networks. Unlike previous reports of synaptic depression in the hippocampus,
the plasticity is associative, long-lasting, and is produced when presynaptic activity
occurs while the postsynaptic membrane is hyperpolarized. In combination with Hebbian
mechanisms also present at hippocampal synapses. associative LTP and associative LTD
may allow neurons in the hippocampus to compute and store covariance between inputs
(Sejnowski, 1977a,b; Stanton and Sejnowski. 1989). These finding make temporal as
well as spatial context an important feature of memory mechanisms in the hippocampus.
Elsewhere in the brain, the receptive field properties of cells in cat visual cortex
can be altered by visual experience paired with iontophoretic excitation or depression of
cellular activity (Fregnac et al, 1988; Greuel et al, 1988). In particular, the chronic hyperpolarization of neurons in visual cortex coupled with presynaptic transmitter release leads
to a long-teno depression of the active. but not inactive, inputs from the lateral geniculate
nucleus (Reiter and Stryker, 1988). Thus. both Hebbian and anti-Hebbian mechanisms
found in the hippocampus seem to also be present in other brain areas, and covariance of
firing patterns between converging inputs a likely key to understanding higher cognitive
function.
This research was supported by grants from the National Science Foundation and
the Office of Naval research to TJS. We thank Drs. Charles Stevens and Richard Morris
for discussions about related experiments.

Rererences
Bienenstock, E., Cooper. LN. and Munro. P. Theory for the development of neuron
selectivity: orientation specificity and binocular interaction in visual cortex. J. Neurosci. 2. 32-48 (1982).
Barrionuevo, G. and Brown, T.H. Associative long-teno potentiation in hippocampal
slices. Proc. Nat. Acad. Sci. (USA) 80, 7347-7351 (1983).
Bliss. T.V.P. and Lomo, T. Long-lasting potentiation of synaptic ttansmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path. J.
Physiol. (Lond.) 232. 331-356 (1973).

Storing Covariance by Synaptic Strengths in the Hippocampus

Collingridge, GL., Kehl, SJ. and McLennan, H. Excitatory amino acids in synaptic
transmission in the Schaffer collateral-commissural pathway of the rat hippocampus. J.
Physiol. (Lond.) 334, 33-46 (1983).
Fregnac, Y., Shulz, D., Thorpe, S. and Bienenstock, E. A cellular analogue of visual cortical plasticity. Nature (Lond.) 333, 367-370 (1988).
Greuel. J.M.. Luhmann. H.J. and Singer. W. Pharmacological induction of usedependent receptive field modifications in visual cortex. Science 242,74-77 (1988).
Gustafsson, B., Wigstrom, H., Abraham, W.C. and Huang. Y.Y. Long-term potentiation
in the hippocampus using depolarizing current pulses as the conditioning stimulus to
single volley synaptic potentials. J. Neurosci. 7, 774-780 (1987).
Harris. E.W., Ganong, A.H. and Cotman, C.W. Long-term potentiation in the hippocampus involves activation of N-metbyl-D-aspartate receptors. Brain Res. 323, 132137 (1984).
Kelso, S.R.. Ganong, A.H. and Brown, T.H. Hebbian synapses in hippocampus. Proc.
Natl. Acad. Sci. USA 83, 5326-5330 (1986).
Kohonen. T. Self-Organization and Associative Memory. (Springer-Verlag. Heidelberg,
1984).
Larson. J. and Lynch. G. Synaptic potentiation in hippocampus by patterned stimulation
involves two events. Science 232, 985-988 (1986).
Levy. W.B. and Steward, O. Synapses as associative memory elements in the hippocampal formation. Brain Res. 175,233-245 (1979).
Levy. W.B. and Steward, O. Temporal contiguity requirements for long-term associative
potentiation/depression in the hippocampus. Neuroscience 8, 791-797 (1983).
Lynch. G.S., Dunwiddie. T. and Gribkoff. V. Heterosynaptic depression: a postsynaptic
correlate oflong-term potentiation. Nature (Lond.) 266. 737-739 (1977).
Malinow. R. and Miller, J.P. Postsynaptic hyperpolarization during conditioning reversibly blocks induction of long-term potentiation Nature (Lond.)32.0. 529-530 (1986).
Mody. I.. Stanton. PK. and Heinemann. U. Activation of N-methyl-D-aspartate
(NMDA) receptors parallels changes in cellular and synaptic properties of dentate
gyrus granule cells after kindling. J. Neurophysiol. 59. 1033-1054 (1988).
Reiter, H.O. and Stryker, M.P. Neural plasticity without postsynaptic action potentials:
Less-active inputs become dominant when kitten visual cortical cells are pharmacologically inhibited. Proc. Natl. Acad. Sci. USA 85, 3623-3627 (1988).
Sejnowski, T J. and Tesauro, G. Building network learning algorithms from Hebbian
synapses, in: Brain Organization and Memory JL. McGaugh, N.M. Weinberger, and
G. Lynch, Eds. (Oxford Univ. Press, New York, in press).
Sejnowski, TJ. Storing covariance with nonlinearly interacting neurons. J. Math. Biology 4, 303-321 (1977).
Sejnowski, T. J. Statistical constraints on synaptic plasticity. J. Theor. Biology 69, 385389 (1977).
Stanton, P.K. and Sejnowski, TJ. Associative long-term depression in the hippocampus:
Evidence for anti-Hebbian synaptic plasticity. Nature (Lond.), in review.
Wigstrom, H. and Gustafsson, B. A possible correlate of the postsynaptic condition for
long-lasting potentiation in the guinea pig hippocampus in vitro. Neurosci. Lett. 44,
327?332 (1984).

401


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 2190-spike-timing-dependent-plasticity-in-the-address-domain.pdf

Spike Timing-Dependent Plasticity
in the Address Domain
R. Jacob Vogelstein1 , Francesco Tenore2 , Ralf Philipp2 , Miriam S. Adlerstein2 ,
David H. Goldberg2 and Gert Cauwenberghs2
1
Department of Biomedical Engineering
2
Department of Electrical and Computer Engineering
Johns Hopkins University, Baltimore, MD 21218
{jvogelst,fra,rphilipp,mir,goldberg,gert}@jhu.edu

Abstract
Address-event representation (AER), originally proposed as a means
to communicate sparse neural events between neuromorphic chips, has
proven efficient in implementing large-scale networks with arbitrary,
configurable synaptic connectivity. In this work, we further extend the
functionality of AER to implement arbitrary, configurable synaptic plasticity in the address domain. As proof of concept, we implement a biologically inspired form of spike timing-dependent plasticity (STDP)
based on relative timing of events in an AER framework. Experimental results from an analog VLSI integrate-and-fire network demonstrate
address domain learning in a task that requires neurons to group correlated inputs.

1 Introduction
It has been suggested that the brain?s impressive functionality results from massively parallel processing using simple and efficient computational elements [1]. Developments in
neuromorphic engineering and address-event representation (AER) have provided an infrastructure suitable for emulating large-scale neural systems in silicon, e.g., [2, 3]. Although an integral part of neuromorphic engineering since its inception [1], only recently
have implemented systems begun to incorporate adaptation and learning with biological
models of synaptic plasticity.
A variety of learning rules have been realized in neuromorphic hardware [4, 5]. These systems usually employ circuitry incorporated into the individual cells, imposing constraints
on the nature of inputs and outputs of the implemented algorithm. While well-suited to
small assemblies of neurons, these architectures are not easily scalable to networks of hundreds or thousands of neurons. Algorithms based both on continuous-valued ?intracellular?
signals and discrete spiking events have been realized in this way, and while analog computations may be performed better at the cellular level, we argue that it is advantageous
to implement spike-based learning rules in the address domain. AER-based systems are
inherently scalable, and because the encoding and decoding of events is performed at the
periphery, learning algorithms can be arbitrarily complex without increasing the size of
repeating neural units. Furthermore, AER makes no assumptions about the signals repre-

1
2

Data bus
3 0 2 1

3

time

Decoder

0

Receiver
Encoder

Sender

0
1
2
3

REQ

REQ

ACK

ACK

Figure 1: Address-event representation. Sender events are encoded into an address, sent
over the bus, and decoded. Handshaking signals REQ and ACK are required to ensure that
only one cell pair is communicating at a time. Note that the time axis goes from right to
left.
sented as spikes, so learning can address any measure of cellular activity. This flexibility
can be exploited to achieve learning mechanisms with high degrees of biological realism.
Much previous work has focused on rate-based Hebbian learning (e.g., [6]), but recently,
the possibility of modifying synapses based on the timing of action potentials has been
explored in both the neuroscience [7, 8] and neuromorphic engineering disciplines [9]?[11].
This latter hypothesis gives rise to the possibility of learning based on causality, as opposed
to mere correlation. We propose that AER-based neuromorphic systems are ideally suited
to implement learning rules founded on this notion of spike-timing dependent plasticity
(STDP). In the following sections, we describe an implementation of one biologicallyplausible STDP learning rule and demonstrate that table-based synaptic connectivity can be
extended to table-based synaptic plasticity in a scalable and reconfigurable neuromorphic
AER architecture.

2 Address-domain architecture
Address-event representation is a communication protocol that uses time-multiplexing to
emulate extensive connectivity [12] (Fig. 1). In an AER system, one array of neurons encodes its activity in the form of spikes that are transmitted to another array of neurons. The
?brute force? approach to communicating these signals would be to use one wire for each
pair of neurons, requiring N wires for N cell pairs. However, an AER system identifies
the location of a spiking cell and encodes this as an address, which is then sent across a
shared data bus. The receiving array decodes the address and routes it to the appropriate
cell, reconstructing the sender?s activity. Handshaking signals REQ and ACK are required
to ensure that only one cell pair is using the data bus at a time. This scheme reduces the required number of wires from N to ? log2 N . Two pieces of information uniquely identify
a spike: its location, which is explicitly encoded as an address, and the time that it occurs,
which need not be explicitly encoded because the events are communicated in real-time.
The encoded spike is called an address-event.
In its original formulation, AER implements a one-to-one connection topology, which is
appropriate for emulating the optic and auditory nerves [12, 13]. To create more complex
neural circuits, convergent and divergent connectivity is required. Several authors have
discussed and implemented methods of enhancing the connectivity of AER systems to
this end [14]?[16]. These methods call for a memory-based projective field mapping that
enables routing an address-event to multiple receiver locations.
The enhanced AER system employed in this paper is based on that of [17], which en-

Sender address
Synapse index
Receiver address
Weight polarity
Weight magnitude

1
2

3
-1
8
4

(a)

0
1

1
0
1
1
-

3
1
8
4
-

REQ
POL

0
1

Encoder

0

0
0
2
2
-

Decoder

??Receiver??

??Sender??

0 0
1
2
1 0
1
2
2 0
1
2

2
EG
Integrate-and-fire array

2

Look-up table

(b)

Figure 2: Enhanced AER for implementing complex neural networks. (a) Example neural
network. The connections are labeled with their weight values. (b) The network in (a) is
mapped to the AER framework by means of a look-up table.
ables continuous-valued synaptic weights by means of graded (probabilistic or deterministic) transmission of address-events. This architecture employs a look-up table (LUT), an
integrate-and-fire address-event transceiver (IFAT), and some additional support circuitry.
Fig. 2 shows how an example two-layer network can be mapped to the AER framework.
Each row in the table corresponds to a single synaptic connection?it contains information
about the sender location, the receiver location, the connection polarity (excitatory or inhibitory), and the connection magnitude. When a spike is sent to the system, the sender
address is used as an index into the LUT and a signal activates the event generator (EG)
circuit. The EG scrolls through all the table entries corresponding to synaptic connections
from the sending neuron. For each synapse, the receiver address and the spike polarity
are sent to the IFAT, and the EG initiates as many spikes as are specified in the weight
magnitude field.
Events received by the IFAT are temporally and spatially integrated by analog circuitry.
Each integrate-and-fire cell receives excitatory and inhibitory inputs that increment or
decrement the potential stored on an internal capacitance. When this potential exceeds
a given threshold, the cell generates an output event and broadcasts its address to the AE
arbiter. The physical location of neurons in the array is inconsequential as connections are
routed through the LUT, which is implemented in random-access memory (RAM) outside
of the chip.
An interesting feature of the IFAT is that it is insensitive to the timescale over which events
occur. Because internal potentials are not subject to decay, the cells? activities are only
sensitive to the order of the events. Effects of leakage current in real neurons are emulated
by regularly sending inhibitory events to all of the cells in the array. Modulating the timing
of the ?global decay events? allows us to dynamically warp the time axis.
We have designed and implemented a prototype system that uses the IFAT infrastructure
to implement massively connected, reconfigurable neural networks. An example setup is
described in detail in [17], and is illustrated in Fig. 3. It consists of a custom VLSI IFAT
chip with a 1024-neuron array, a RAM that stores the look-up table, and a microcontroller
unit (MCU) that realizes the event generator.
As discussed in [18, p. 91], a synaptic weight w can be expressed as the combined effect

Weight polarity

RAM

DATA

RAM

Receiver address

ADDRESS

Sender
address

Weight polarity
DATA

ADDRESS

Sender
address

Receiver address

POL

POL

IN

IN

OUT

OUT

IN

MCU

Synapse
index

Weight
magnitude

MCU

Weight
magnitude

PC board

PC board

(a)

OUT

IFAT

IFAT
Synapse
index

OUT

(b)

Figure 3: Hardware implementation of enhanced AER. The elements are an integrate-andfire array transceiver (IFAT) chip, a random-access memory (RAM) look-up table, and a
microcontroller unit (MCU). (a) Feedforward mode. Input events are routed by the RAM
look-up table, and integrated by the IFAT chip. (b) Recurrent mode. Events emitted by the
IFAT are sent to the look-up table, where they are routed back to the IFAT. This makes
virtual connections between IFAT cells.
of three physical mechanisms:
w = npq
(1)
where n is the number of quantal neurotransmitter sites, p is the probability of synaptic
release per site, and q is the measure of the postsynaptic effect of the synapse. Many early
neural network models held n and p constant and attributed all of the variability in the
weight to q. Our architecture is capable of varying all three components: n by sending
multiple events to the same receiver location, p by probabilistically routing the events (as
in [17]), and q by varying the size of the potential increments and decrements in the IFAT
cells. In the experiments described in this paper, the transmission of address-events is
deterministic, and the weight is controlled by varying the number of events per synapse,
corresponding to a variation in n.

3 Address-domain learning
The AER architecture lends itself to implementations of synaptic plasticity, since information about presynaptic and postsynaptic activity is readily available and the contents of the
synaptic weight fields in RAM are easily modifiable ?on the fly.? As in biological systems,
synapses can be dynamically created and pruned by inserting or deleting entries in the LUT.
Like address domain connectivity, the advantage of address domain plasticity is that the
constituents of the implemented learning rule are not constrained to be local in space or
time. Various forms of learning algorithms can be mapped onto the same architecture by
reconfiguring the MCU interfacing the IFAT and the LUT.
Basic forms of Hebbian learning can be implemented with no overhead in the address domain. When a presynaptic event, routed by the LUT through the IFAT, elicits a postsynaptic
event, the synaptic strength between the two neurons is simply updated by incrementing the
data field of the LUT entry at the active address location. A similar strategy can be adopted
for other learning rules of the incremental outer-product type, such as delta-rule or backpropagation supervised learning.
Non-local learning rules require control of the LUT address space to implement spatial
and/or temporal dependencies. Most interesting from a biological perspective are forms of

?+
?w

Presynaptic Queue
x1x3 x2 x1 x3 x3 x1 x2 x1

t

x1

?w(tpre ? tpost)
??+

x2

Presynaptic

??
tpre ? tpost

x3
Postsynaptic

Presynaptic

presynaptic

Postsynaptic

postsynaptic

x2
y

x
y1
y2
y2 y1

y1

y1 y2 y2

Postsynaptic Queue

?w

t

y1 y2

?w
???

(a)

(b)

Figure 4: Spike timing-dependent plasticity (STDP) in the address domain. (a) Synaptic
updates ?w as a function of the relative timing of presynaptic and postsynaptic events, with
asymmetric windows of anti-causal and causal regimes ? ? > ?+ . (b) Address-domain
implementation using presynaptic (top) and postsynaptic (bottom) event queues of window
lengths ?+ and ?? .
spike timing-dependent plasticity (STDP).

4 Spike timing-dependent plasticity
Learning rules based on STDP specify changes in synaptic strength depending on the time
interval between each pair of presynaptic and postsynaptic events. ?Causal? postsynaptic
events that succeed presynaptic action potentials (APs) by a short duration of time potentiate the synaptic strength, while ?anti-causal? presynaptic events succeeding postsynaptic
APs by a short duration depress the synaptic strength. The amount of strengthening or
weakening is dependent on the exact time of the event within the causal or anti-causal
regime, as illustrated in Fig. 4 (a). The weight update has the form
(
??[?? ? (tpre ? tpost )]
0 ? tpre ? tpost ? ??
?[?+ + (tpre ? tpost )]
??+ ? tpre ? tpost ? 0
?w =
(2)
0
otherwise
where tpre and tpost denote time stamps of presynaptic and postsynaptic events.
For stable learning, the time windows of causal and anti-causal regimes ? + and ?? are
subject to the constraint ?+ < ?? . For more general functional forms of STDP ?w(t pre ?
tpost ), the area under the synaptic modification curve in the anti-causal regime must be
greater than that in the causal regime to ensure convergence of the synaptic strengths [7].
The STDP synaptic modification rule (2) is implemented in the address domain by augmenting the AER architecture with two event queues, one each for presynaptic and postsynaptic events, shown in Figure 4 (b). Each time a presynaptic event is generated, the
sender?s address is entered into a queue with an associated value of ? + . All values in the
queue are decremented every time a global decay event is observed, marking one unit of
time T . A postsynaptic event triggers a sequence of synaptic updates by iterating backwards through the queue to find the causal spikes, in turn locating the synaptic strength entries in the LUT corresponding to the sender addresses and synaptic index, and increasing

x1
x2
x3
x4
x5
y
x16
x17
x18
x19
x20

Figure 5: Pictorial representation of our experimental neural network, with actual spike
train data sent from the workstation to the first layer. All cells are identical, but x 18 . . . x20
(shaded) receive correlated inputs. Activity becomes more sparse in the hidden and output
layers as the IFAT integrates spatiotemporally. Note that connections are virtual, specified
in the RAM look-up-table.

the synaptic strengths in the LUT according to the values stored in the queue. Anti-causal
events require an equivalent set of operations, matching each incoming presynaptic spike
with a second queue of postsynaptic events. In this case, entries in the queue are initialized
with a value of ?? and decremented after every interval of time T between decay events,
corresponding to the decrease in strength to be applied at the presynaptic/postsynaptic pair.
We have chosen a particularly simple form of the synaptic modification function (2) as
proof of principle in the experiments. More general functions can be implemented by a
table that maps time bins in the history of the queue to specified values of ?w(nT ), with
positive values of n indexing the postsynaptic queue, and negative values indexing the
presynaptic queue.

5 Experimental results
We have implemented a Hebbian spike timing-based learning rule on a network of 21 neurons using the IFAT system (Fig. 5). Each of the 20 neurons in the input layer is driven by
an externally supplied, randomly generated list of events. Sufficiently high levels of input
cause these neurons to produce spikes that subsequently drive the output layer. All events
are communicated over the address-event bus and are monitored by a workstation communicating with the MCU and RAM. As shown in [7], temporally asymmetric Hebbian
learning using STDP is useful for detecting correlations between inputs. We have proved
that this can be accomplished in hardware in the address domain by presenting the network
with stimulus patterns containing a set of correlated inputs and a set of uncorrelated inputs:
neurons x1 . . . x17 are all stimulated independently with a probability of 0.05 per unit of
time, while neurons x18 . . . x20 have the same likelihood of stimulation but are always activated together. Thus, over a sufficiently long period of time each neuron in the input layer
will receive the same amount of activation, but the correlated group will fire synchronous
spikes more frequently than any other combination of neurons.
In the implemented learning rule (2), causal activity results in synaptic strengthening and
anti-causal activity results in synaptic weakening. As described in Section 4, for an anticausal regime ?? larger than the causal regime ?+ , random activity results in overall weak-

35

35
Maximum Strength = 31

30

30

25

25

Synaptic Strength

Synaptic Strength

Maximum Strength = 31

20
15
10
5
0

20
15
10
5

1

20
Synapse Address

(a)

0

1

20
Synapse Address

(b)

Figure 6: Experimental synaptic strengths in the second layer, recorded from the IFAT
system after the presentation of 200,000 input events. (a) Typical experimental run. (b)
Average (+SE) over 20 experimental runs.
ening of a synapse. All synapses connecting the input and output layers are equally likely
to be active during an anti-causal regime. However, the increase in average contribution
to the postsynaptic membrane potential for the correlated group of neurons renders this
population slightly more likely to be active during the causal regime than any single member of the uncorrelated group. Therefore, the synaptic strengths for this group of neurons
will increase with respect to the uncorrelated group, further augmenting their likelihood
of causing a postsynaptic spike. Over time, this positive feedback results in a random but
stable distribution of synaptic strengths in which the correlated neurons? synapses form
the strongest connections and the remaining neurons are distributed around an equilibrium
value for weak connections.
In the experiments, we have chosen ?+ = 3 and ?? = 6. An example of a typical distribution of synaptic strengths recorded after 200,000 events have been processed by the
input layer is shown in Fig. 6 (a). For the data shown, synapses driving the input layer were
fixed at the maximum strength (+31), the rate of decay was ?4 per unit of time, and the
plastic synapses between the input and output layers were all initialized to +8. Because
the events sent from the workstation to the input layer are randomly generated, fluctuations
in the strengths of individual synapses occur consistently throughout the operation of the
system. Thus, the final distribution of synaptic weights is different each time, but a pattern
can be clearly discerned from the average value of synaptic weights after 20 separate trials
of 200,000 events each, as shown in Fig. 6 (b).
The system is robust to changes in various parameters of the spike timing-based learning
algorithm as well as to modifications in the number of correlated, uncorrelated, and total
neurons (data not shown). It also converges to a similar distribution regardless of the initial
values of the synaptic strengths (with the constraint that the net activity must be larger than
the rate of decay of the voltage stored on the membrane capacitance of the output neuron).

6 Conclusion
We have demonstrated that the address domain provides an efficient representation to implement synaptic plasticity that depends on the relative timing of events. Unlike dedicated
hardware implementations of learning functions embedded into the connectivity, the address domain implementation allows for learning rules with interactions that are not constrained in space and time. Experimental results verified this for temporally-antisymmetric
Hebbian learning, but the framework can be extended to general learning rules, including
reward-based schemes [10].

The IFAT architecture can be augmented to include sensory input, physical nearestneighbor connectivity between neurons, and more realistic biological models of neural
computation. Additionally, integrating the RAM and IFAT into a single chip will allow for
increased computational bandwidth. Unlike a purely digital implementation or software
emulation, the AER framework preserves the continuous nature of the timing of events.

References
[1] C. Mead, Analog VLSI and Neural Systems. Reading, Massachusetts: Addison-Wesley, 1989.
[2] S. R. Deiss, R. J. Douglas, and A. M. Whatley, ?A pulse-coded communications infrastructure
for neuromorphic systems,? in Pulsed Neural Networks (W. Maas and C. M. Bishop, eds.),
pp. 157?178, Cambridge, MA: MIT Press, 1999.
[3] K. Boahen, ?A retinomorphic chip with parallel pathways: Encoding INCREASING, ON,
DECREASING, and OFF visual signals,? Analog Integrated Circuits and Signal Processing,
vol. 30, pp. 121?135, February 2002.
[4] G. Cauwenberghs and M. A. Bayoumi, eds., Learning on Silicon: Adaptive VLSI Neural Systems. Norwell, MA: Kluwer Academic, 1999.
[5] M. A. Jabri, R. J. Coggins, and B. G. Flower, Adaptive analog VLSI neural systems. London:
Chapman & Hall, 1996.
[6] T. J. Sejnowski, ?Storing covariance with nonlinearly interacting neurons,? Journal of Mathematical Biology, vol. 4, pp. 303?321, 1977.
[7] S. Song, K. D. Miller, and L. F. Abbott, ?Competitive Hebbian learning through spike-timingdependent synaptic plasticity,? Nature Neuroscience, vol. 3, no. 9, pp. 919?926, 2000.
[8] M. C. W. van Rossum, G. Q. Bi, and G. G. Turrigiano, ?Stable Hebbian learning from spike
timing-dependent plasticity,? Journal of Neuroscience, vol. 20, no. 23, pp. 8812?8821, 2000.
[9] P. Hafliger and M. Mahowald, ?Spike based normalizing Hebbian learning in an analog VLSI artificial neuron,? in Learning On Silicon (G. Cauwenberghs and M. A. Bayoumi, eds.), pp. 131?
142, Norwell, MA: Kluwer Academic, 1999.
[10] T. Lehmann and R. Woodburn, ?Biologically-inspired on-chip learning in pulsed neural networks,? Analog Integrated Circuits and Signal Processing, vol. 18, no. 2-3, pp. 117?131, 1999.
[11] A. Bofill, A. F. Murray, and D. P. Thompson, ?Circuits for VLSI implementation of temporallyasymmetric Hebbian learning,? in Advances in Neural Information Processing Systems 14
(T. Dietterich, S. Becker, and Z. Ghahramani, eds.), Cambridge, MA: MIT Press, 2002.
[12] M. Mahowald, An analog VLSI system for stereoscopic vision. Boston: Kluwer Academic
Publishers, 1994.
[13] J. Lazzaro, J. Wawrzynek, M. Mahowald, M. Sivilotti, and D. Gillespie, ?Silicon auditory processors as computer peripherals,? IEEE Trans. Neural Networks, vol. 4, no. 3, pp. 523?528,
1993.
[14] K. A. Boahen, ?Point-to-point connectivity between neuromorphic chips using address events,?
IEEE Trans. Circuits and Systems?II: Analog and Digital Signal Processing, vol. 47, no. 5,
pp. 416?434, 2000.
[15] C. M. Higgins and C. Koch, ?Multi-chip neuromorphic motion processing,? in Proceedings
20th Anniversary Conference on Advanced Research in VLSI (D. Wills and S. DeWeerth, eds.),
(Los Alamitos, CA), pp. 309?323, IEEE Computer Society, 1999.
[16] S.-C. Liu, J. Kramer, G. Indiveri, T. Delbr?uck, and R. Douglas, ?Orientation-selective aVLSI
spiking neurons,? in Advances in Neural Information Processing Systems 14 (T. Dietterich,
S. Becker, and Z. Ghahramani, eds.), Cambridge, MA: MIT Press, 2002.
[17] D. H. Goldberg, G. Cauwenberghs, and A. G. Andreou, ?Probabilistic synaptic weighting in a
reconfigurable network of VLSI integrate-and-fire neurons,? Neural Networks, vol. 14, no. 6/7,
pp. 781?793, 2001.
[18] C. Koch, Biophysics of Computation: Information Processing in Single Neurons. New York:
Oxford University Press, 1999.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1554-neuronal-regulation-implements-efficient-synaptic-pruning.pdf

Neuronal Regulation Implements
Efficient Synaptic Pruning

Gal Chechik and Isaac Meilijson
School of Mathematical Sciences
Tel Aviv University, Tel Aviv 69978, Israel
ggal@math.tau.ac.il isaco@math.tau.ac.il
Eytan Ruppin
Schools of Medicine and Mathematical Sciences
Tel Aviv University, Tel Aviv 69978, Israel
ruppin@math.tau.ac.il

Abstract
Human and animal studies show that mammalian brain undergoes
massive synaptic pruning during childhood , removing about half of
the synapses until puberty. We have previously shown that maintaining network memory performance while synapses are deleted,
requires that synapses are properly modified and pruned, removing the weaker synapses. We now show that neuronal regulation , a
mechanism recently observed to maintain the average neuronal input field , results in weight-dependent synaptic modification . Under
the correct range of the degradation dimension and synaptic upper bound, neuronal regulation removes the weaker synapses and
judiciously modifies the remaining synapses . It implements near
optimal synaptic modification, and maintains the memory performance of a network undergoing massive synaptic pruning. Thus ,
this paper shows that in addition to the known effects of Hebbian
changes, neuronal regulation may play an important role in the
self-organization of brain networks during development .

1

Introduction

This paper studies one of the fundamental puzzles in brain development: the massive synaptic pruning observed in mammals during childhood , removing more than
half of the synapses until puberty (see [1] for review) . This phenomenon is observed in various areas of the brain both in animal studies and human studies. How
can the brain function after such massive synaptic elimination? what could be the
computational advantage of such a seemingly wasteful developmental strategy? In

G. Chechik. I. Meilijson and E. Ruppin

98

previous work [2], we have shown that synaptic overgrowth followed by judicial
pruning along development improves the performance of an associative memory
network with limited synaptic resources, thus suggesting a new computational explanation for synaptic pruning in childhood. The optimal pruning strategy was
found to require that synapses are deleted according to their efficacy, removing the
weaker synapses first.
But is there a mechanism that can implement these theoretically-derived synaptic
pruning strategies in a biologically plausible manner? To answer this question , we
focus here on studying the role of neuronal regulation (NR) , a mechanism operating
to maintain the homeostasis of the neuron 's membrane potential. NR has been recently identified experimentally by [3], who showed that neurons both up-regulate
and down-regulate the efficacy of their incoming excitatory synapses in a multiplicative manner, maintaining their membrane potential around a baseline level.
Independently, [4] have studied NR theoretically, showing that it can efficiently
maintain the memory performance of networks undergoing synaptic degradation .
Both [3] and [4] have hypothesized that NR may lead to synaptic pruning during
development.
In this paper we show that this hypothesis is both computationally feasible and
biologically plausible by studying the modification of synaptic values resulting from
the operation of NR. Our work thus gives a possible account for the way brain
networks maintain their performance while undergoing massive synaptic pruning.

2

The Model

NR-driven synaptic modification (NRSM) results from two concomitant processes:
synaptic degradation (which is the inevitable consequence of synaptic turnover
[5]) , and neuronal regulation (NR) operating to compensate for the degradation.
We therefore model NRSM by a sequence of degradation-strengthening steps. At
each time step, synaptic degradation stochastically reduces the synaptic strength
W t (W t > 0) to W't+l by
W't+l = W t - (wtt'1]t; 1] "" N(J..{/ , (1"1/)
(1)

where 1] is noise term with positive mean and the power a defines the degradation
dimension parameter chosen in the range [0,1] . Neuronal regulation is modeled by
letting the post-synaptic neuron multiplicatively strengthen all its synapses by a
common factor to restore its original input field
W t +1 = W'tH li~
(2)

Ii

where If is the input field of neuron i at time t. The excitatory synaptic efficacies are
assumed to have a viability lower bound B- below which a synapse degenerates and
vanishes, and a soft upper bound B+ beyond which a synapse is strongly degraded
reflecting their maximal efficacy. To study of the above process in a network, a
model incorporating a segregation between inhibitory and excitatory neurons (i.e.
obeying Dale's law) is required . To generate this essential segregation, we modify
the standard low-activity associative memory model proposed by [6] by adding a
small positive term to the synaptic learning rule. In this model, M memories
are stored in an excitatory N -neuron network forming attractors of the network
dynamics. The synaptic efficacy Wij between the jth (pre-synaptic) neuron and
the ith (post-synaptic) neuron is
M

Wij

=

I: [(er - p)(ej - p) + a] , 1 ~ i i= j

~

N

(3)

99

Neuronal Regulation Implements Efficient Synaptic Prnning

where {e'}~=l are {O, I} memory patterns with coding level p (fraction of firing
neurons), and a is some positive constant 1. The updating rule for the state Xf of
the ith neuron at time t is
N

xI+1

= (J(Jf),

If

N

= ~ L9(Wij)Xj - ~ L
j=l

xj -

T,

(J(J)

= 1 + sign(J)

(4)

2

j=l

where T is the neuronal threshold, and I is the inhibition strength. 9 is a general
modification function over the excitatory synapses, which is either derived explicitly
(See Section 4), or determined implicitly by the operation of NRSM. If 9 is linear
and I = Mathe model reduces to the original model described by [6]. The overlap
mil (or similarity) between the network 's activity pattern X and the memory ~II
serves to measure memory performance (retrieval acuity), and is defined as mil

~
3

Ef=l (~j -

=

p)Xj.

N euronally Regulated Synaptic Modification

NRSM was studied by simulating the degradation-strengthening sequence in a network in which memory patterns were stored according to Eq.3. Figure la plots a
typical distribution of synaptic values as traced along a sequence of degradationstrengthening steps (Eq. 1,2) . As evident, the synaptic values diverge: some of the
weights are strengthened and lie close to the upper synaptic bounds, while the other
synapses degenerate and vanish. Using probabilistic considerations, it can be shown
that the synaptic distribution converge to a meta-stable state where it remains for
long waiting times. Figure Ib describes the metastable synaptic distribution as
calculated for different 0 values .
Evolving distribution of synaptic efficacies
a. Simulation results
b. Numerical results
10000
CJ)

Q)
CJ)

c..

1.0

/1, 5000
r
r
r
I

I

I

r

\1000

I

0.8

ctl

c::
>CJ)

r

1400

-....

I

_._. Alpha=O.O
- - - Alpha=O.5
Alpha=O.9

~.6
'(j)

c::
~0.4

0

I

i
i

Q)

.0

E

0.2

:::l

c::

0.0

/

/

..

//

0

Figure 1: Distribution of synaptic strengths following a degradation-strengthening
process. a) Synaptic distribution after 0,200 , 400, 1000 and 5000 degradationstrengthening steps of a 400 neurons network with 1000 stored memory patterns.
0=0.8, p = 0.1, B- = 10- 5 , B+ = 18 and T/ '" N(0.05, 0.05). Qualitatively similar
results were obtained for a wide range of simulation parameters. b) The synaptic
distribution of the remaining synapses at the meta-stable state was calculated as
the main eigen vector of the transition probability matrix.
the weights are normally distributed with expectation M a > 0 and standard deviation O(VM) , the probability of a negative synapse vanishes as M goes to infinity (and
is negligible already for several dozens of memories in the parameters' range used here).
1 As

G. Chechik, I Meilijson and E. Ruppin

100

a. NRSM functions at the
Metastable state
, 20

b. NRSM and
random deletion

i ----r--- --j::=::::==

1.0

r-:-~-~---_r__-_-~---,

~-?-v~?.M,~

r~

,

\
\
\

\
\

~

\
\

c

'"
E

.g
Q)

a...

0 .5

\

\
\
\
\

\
\

NR modification
- - - Random deletion

\
\
\

,,

' ......

0 .0 '---''-------'''--.......''"'''-...?...-~--------,'
0.0
4 .0
8.0
,2.0

Original synaptic strength

0 .0 '---- ' - -- - ',--~----"~.,.~
--~
, 0.9
0 .8
0.7
0.6
0.5

- ''--~
04
0 .3

Network's Connectivity

Figure 2: a) NRSM functions at the metastable state for different a values. Results were obtained in a 400-neurons network after performing 5000 degradationstrengthening steps. Parameter values are as in Figure 1, except B+
12. b)
Performance of NR modification and random deletion. The retrieval acuity of 200
memories stored in a network of 800 neurons is portrayed as a function of network
connectivity, as the network undergoes continuous pruning until NR reaches the
metastable state. a = 0, B+ = 7.5, p = 0.1, rna = 0.80, a = 0.01, T = 0.35,
B- = 10- 5 and TJ"'" N(O.OI, 0.01).

=

To further investigate which synapses are strengthened and which are pruned, we
study the resulting synaptic modification function. Figure 2a plots the value of
synaptic efficacy at the metastable state as a function of the initial synaptic efficacy, for different values of the degradation dimension a. As observed, a sigmoidal
dependency is obtained, where the slope of the sigmoid s.trongly depends on the
degradatiori dimension. In the two limit cases, additive degradation (a = 0) results
in a step function at the metastable state, while multiplicative degradation (a = 1)
results in random diffusion of the synaptic weights toward a memory less mean value.
Different values of a and B+ result in different levels of synaptic pruning: When
the synaptic upper bound B+ is high, the surviving synapses assume high values,
leading to massive pruning to maintain the neuronal input field, which in turn reduces network 's performance. Low B+ values lead to high connectivity, but limit
synapses to a small set of possible values, again reducing memory performance. Our
simulations show that optimal memory retrieval is obtained for B+ values that lead
to deletion levels of 40% - 60%, in which NR indeed maintains the network performance. Figure 2b traces the average retrieval acuity of a network throughout the
operation of NR, versus a network subject to random deletion at the same pruning
levels. While the retrieval of a randomly pruned network collapses already at low
deletion levels of about 20%, a network undergoing NR performs well even in high
deletion levels.

4

Optimal Modification In Excitatory-Inhibitory Networks

To obtain a a comparative yardstick to evaluate the efficiency of NR as a selective
pruning mechanism, we derive optimal modification functions maximizing memory
performance in our excitatory-inhibitory model and compare them to the NRSM
functions.

101

Neuronal Regulation Implements Efficient Synaptic Pruning

We study general synaptic modification functions, which prune some of the synapses
and possibly modify the rest, while satisfying global constraints on synapses such
as the number or total strength of the synapses. These constraints reflect the
observation that synaptic activity is strongly correlated with energy consumption
in the brain [7], and synaptic resources may hence be inherently limited in the adult
brain.
We evaluate the impact of these functions on the network's retrieval performance,
by deriving their effect on the signal to noise ratio (SIN) of the neuron's input field
(Eqs. 3,4)' known to be the primary determinant of retrieval capacity ([8]). This
analysis, conducted in a similar manner to [2] yields

where z'" N(O, 1) and 9 is the modification function of Eq. 4 but is now explicitly
applied to the synapses. To derive optimal synaptic modification functions with
limited synaptic resources, we consider 9 functions that zero all synapses except
those in some set A, and keep the integral

i

l(z)?(z)dz

k

= 0, 1, ...

;

= OVz ~ A

g(z)

(6)

limited. We then maximize the SIN under this constraint using the Lagrange
method. Our results show that without any synaptic constraints the optimal function is the identity function, that is, the original Hebbian rule is optimal. When
the number of synapses is restricted (k = 0), the optimal modification function is a
linear function for all the remaining synapses
a

g(W)

= aW -J.ta+b

-

L z2?(z)dz

where { b
(Ta

J z?(z )dz

L ?(z)dz)

A

(1-

E(W)
V(W)

(7)

for any deletion set A. To find the synapses that should be deleted, we have numerically searched for a deletion set maximizing SIN while limiting g(W) to positive
values (as required by the segregation between excitatory and inhibitory neurons).
The results show, that weak synapses pruning, a modification strategy that removes the weakest synapses and modifies the rest according to Eq. 7, is optimal
at deletion levels above 50% . For lower deletion levels, the above 9 function fails
to satisfy the positivity constraint for any set A. When the positivity constraint is
ignored, SIN is maximized if the weights closest to the mean are deleted and the
remaining synapses are modified according to Eq 7. We name this strategy mean
synapses pruning. Figure 3 plots the memory capacity under weak-synapses
pruning (compared with random deletion and mean-synaptic pruning) showing that
pruning the weak synapses performs at least near optimally for lower deletion levels
as well. Even more interesting, under the correct parameter values weak-synapses
pruning results in a modification function that has a similar form to the NR-driven
modification function studied in the previous Section: both strategies remove the
weakest synapses and linearly modify the remaining synapses in a similar manner.
In the case of limited overall synaptic strength (k > 0 in Eq. 6), the optimal 9
satisfies
z - 2"Y1 [g(z) - E(g(z))] - "Y2kg(z)k-1 = 0
(8)
and thus for k = 1 and k = 2 the optimal modification function is again linear. For
k > 2 a sublinear modification function is optimal, where 9 is a function of zl/(k-1),

G. Chechik, I. Meilijson and E. Ruppin

102

Capacity of different synaptic modification functions g(w)
a. Analysis results
b. Simulations results
1oo0r---~----~--~----~---'

=---==-.......,::...:.... _.-.-........
800

800

.~600

~6oo

?I

?I

?I 400

?1400

(.)

c..
(.)

200

(.)

c..
(.)

200

'..... .........

.... ....

.

..... .... ..

'" '" '"

'".
'".
'"'" ,.,
'"'" .,

'",,.,.

"

'\.

,.

1\

\

Figure 3: Comparison between performance of different modification strategies as a
function of the deletion level (percentage of synapses pruned). Capacity is measured
as the number of patterns that can be stored in the network (N = 2000) and be
recalled almost correctly (rn > 0.95) from a degraded pattern (rna = 0.80).
and is thus unbounded for all k. Therefore, in our model, bounds on the synaptic
efficacies are not dictated by the optimization process. Their computational advantage arises from their effect on preserving memory capacity in face of ongoing
synaptic pruning.

5

Discussion

By studying NR-driven synaptic modification in the framework of associative memory networks, we show that NR prunes the weaker synapses and modifies the remaining synapses in a sigmoidal manner. The critical variables that govern the
pruning process are the degradation dimension and the upper synaptic bound. Our
results show that in the correct range of these parameters, NR implements
a near optimal strategy, maximizing memory capacity in the sparse connectivity levels observed in the brain.
A fundamental requirement of central nervous system development is that the system should continuously function, while undergoing major structural and functional developmental changes. It has been proposed that a major functional role
of neuronal down-regulation during early infancy is to maintain neuronal activity
at its baseline levels while facing continuous increase in the number and efficacy
of synapses [3]. Focusing on up-regulation, our work shows that NR has another
important interesting effect: that of modifying and pruning synapses in a continuously optimal manner. Neuronally regulated synaptic modifications may play the
same role also in the peripheral nervous system: It was recently shown that in the
neuro-muscular junction the muscle regulates its incoming synapses in a way similar to NR [9]. Our analysis suggests this process may be the underlying cause for
the finding that synapses in the neuro-muscular junction are either strengthened or
pruned according to their initial efficacy [10].
The significance of our work goes beyond understanding synaptic organization and
remodeling in the associative memory models studied in this paper. Our analysis
bears relevance to two other fundamental paradigms: Hetero Associative memory
and self organizing maps, sharing the same basic synaptic structure of storing as-

Neuronal Regulation Implements Efficient Synaptic Pruning

103

sociations between sets of patterns via a Hebbian learning rule.
Combining the investigation of a biologically identified mechanism with the analytic study of performance optimization in neural network models, this paper shows
the biologically plausible and beneficial role of weight dependent synaptic pruning.
Thus, in addition to the known effects of Hebbian learning, neuronal regulation may
play an important role in the self-organization of brain networks during development .

References
[1] G.M. Innocenti. Exuberant development of connections and its possible permissive role in cortical evolution. Trends Neurosci, 18:397-402, 1995.
[2] G. Chechik, I. Meilijson, and E. Ruppin. Synaptic pruning during development:
A computational account. Neural Computation. In press., 1998.
[3] G.G. Turrigano, K. Leslie, N. Desai, and S.B. Nelson . Activity dependent scaling of quantal amplitude in neocoritcal pyramidal neurons. Nature,
391(6670):892-896,1998.
[4] D. Horn, N. Levy, and E. Ruppin. Synaptic maintenance via neuronal regulation. Neural Computation, 10(1):1- 18,1998.
[5] J .R. Wolff, R. Laskawi, W.B. Spatz, and M. Missler. Structural dynamics of
synapses and synaptic components. Behavioral Brain Research, 66(1-2):13- 20,
1995.
[6] M.V . Tsodyks and M. Feigel'man. Enhanced storage capacity in neural networks with low activity level. Europhys. Lett., 6:101- 105,1988.
[7] Per E. Roland. Brain Activation. Willey-Liss, 1993 .
[8] I. Meilijson and E. Ruppin. Optimal firing in sparsely-connected low-activity
attractor networks. Biological cybernetics, 74:479-485, 1996.
[9] G .W . Davis and C .S. Goodman. Synapse-specific control of synaptic efficacy
at the terminals of a single neuron. Nature, 392(6671):82- 86, 1998.
[10] H. Colman, J . Nabekura, and J. W. Lichtman. Alterations in synaptic strength
preceding axon withdrawal. Science, 275(5298):356-361, 1997.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 972-a-model-of-the-hippocampus-combining-self-organization-and-associative-memory-function.pdf

A model of the hippocampus combining selforganization and associative memory function.
Michael E. Hasselmo, Eric Schnell
Joshua Berke and Edi Barkai

Dept. of Psychology, Harvard University
33 Kirkland St., Cambridge, MA 02138
hasselmo@katla.harvard.edu

Abstract
A model of the hippocampus is presented which forms rapid self-organized representations of input arriving via the perforant path, performs
recall of previous associations in region CA3, and performs comparison
of this recall with afferent input in region CA 1. This comparison drives
feedback regulation of cholinergic modulation to set appropriate
dynamics for learning of new representations in region CA3 and CA 1.
The network responds to novel patterns with increased cholinergic modulation, allowing storage of new self-organized representations, but
responds to familiar patterns with a decrease in acetylcholine, allowing
recall based on previous representations. This requires selectivity of the
cholinergic suppression of synaptic transmission in stratum radiatum of
regions CA3 and CAl, which has been demonstrated experimentally.

1

INTRODUCTION

A number of models of hippocampal function have been developed (Burgess et aI., 1994;
Myers and Gluck, 1994; Touretzky et al., 1994), but remarkably few simulations have
addressed hippocampal function within the constraints provided by physiological and anatomical data. Theories of the function of specific subregions of the hippocampal formation often do not address physiological mechanisms for changing dynamics between
learning of novel stimuli and recall of familiar stimuli. For example, the afferent input to
the hippocampus has been proposed to form orthogonal representations of entorhinal
activity (Marr, 1971; McNaughton and Morris, 1987; Eichenbaum and Buckingham,
1990), but simulations have not addressed the problem of when these representations

78

Michael E. Hasselmo. Eric Schnell. Joshua Berke. Edi Barkai

should remain stable, and when they should be altered. In addition, models of autoassociative memory function in region CA3 (Marr, 1971; McNaughton and Morris, 1987;
Levy, 1989; Eichenbaum and Buckingham, 1990) and heteroassociative memory function
at the Schaffer collaterals projecting from region CA3 to CAl (Levy, 1989; McNaughton,
1991) require very different activation dynamics during learning versus recall.
Acetylcholine may set appropriate dynamics for storing new information in the cortex
(Hasselmo et aI., 1992, 1993; Hasselmo, 1993, 1994; Hasselmo and Bower, 1993). Acetylcholine has been shown to selectively suppress synaptic transmission at intrinsic but
not afferent fiber synapses (Hasselmo and Bower, 1992), to suppress the neuronal adaptation of cortical pyramidal cells (Hasselmo et aI., 1994; Barkai and Hasselmo, 1994), and
to enhance long-term potentiation of synaptic potentials (Hasselmo, 1994b). Models
show that suppression of synaptic transmission during learning prevents recall of previously stored information from interfering with the storage of new information (Hasselmo
et al., 1992, 1993; Hasselmo, 1993, 1994a), while cholinergic enhancement of synaptic
modification enhances the rate of learning (Hasselmo, 1994b).
Feedback regulation of cholinergic modulation may set the appropriate level of cholinergic modulation dependent upon the novelty or familiarity of a particular input pattern.
We have explored possible mechanisms for the feedback regulation of cholinergic modulation in simulations of region CAl (Hasselmo and Schnell, 1994) and region CA3. Here
we show that self-regulated learning and recall of self-organized representations can be
obtained in a network simulation of the hippocampal formation. This model utilizes selective cholinergic suppression of synaptic transmission in stratum radiatum of region CA3,
which has been demonstrated in brain slice preparations of the hippocampus.

2

METHODS

2.1. SIMPLIFIED REPRESENTA nON OF HIPPOCAMPAL NEURONS.

In place of the sigmoid input-output functions used in many models, this model uses a
simple representation in which the output of a neuron is not explicitly constrained, but the
total network activity is regulated by feedback from inhibitory interneurons and adaptation due to intracellular calcium concentration. Separate variables represent pyramidal
cell membrane potential a, intracellular calcium concentration c, and the membrane potential of inhibitory interneurons h:

l1a i = Ai -l1 ai - J..l.C +

L Wijg(aj - e) - Hikg(h k - e h)
j

I1c?I = 'Vg(a
.i?
I
I1hk

e )- Qc
C

= IWkjg(aj-eo)-l1hk- IHk/g(h/-e)
j

where A = afferent input, "

/

=passive decay of membrane potential, Il =strength of cal-

A Model of Hippocampus

79

cium-dependent potassium current (proportional to intracellular calcium), Wij = excitatory
recurrent synapses (longitudinal association path tenninating in stratum radiatum), gO is a
threshold linear function proportional to the amount by which membrane potential
exceeds an output threshold 00 or threshold for calcium current Oc' 'Y = strength of voltagedependent calcium current, n = diffusion constant of calcium, Wki = excitatory synapses
inhibitory interneurons, Hilc = inhibitory synapses from interneurons to pyramidal cells,
Hk}= inhibitory synapses between interneurons. This representation gives neurons adaptation characteristics similar to those observed with intracellular recording (Barkai and Hasselmo, 1994), including a prominent afterhyperpolarization potential (see Figure 1).

An

B

.... ..
~

....J

'N~JJL

C

lO

\..--14

Figure 1. Comparison of pyramidal cell model with experimental data.
In Figure I, A shows the membrane potential of a modeled pyramidal cell in response to
simulated current injection. Output of this model is a continuous variable proportional to
how much membrane potential exceeds threshold. This is analogous to the reciprocal of
interspike interval in real neuronal recordings. Note that the model displays adaptation
during current injection and afterhyperpolarization afterwards, due to the calcium-dependent potassium current. B shows the intracellularly recorded membrane potential in a pirifonn cortex pyramidal cell, demonstrating adaptation of firing frequency due to
activation of calcium-dependent potassium current. The firing rate falls off in a manner
similar to the smooth decrease in firing rate in the simplified representation. C shows an
intracellular recording illustrating long-tenn afterhyperpolarization caused by calcium
influx induced by spiking of the neuron during current injection.
2.2. NETWORK CONNECTIVITY

A schematic representation of the network simulation of the hippocampal fonnation is
shown in Figure 2. The anatomy of the hippocampal fonnation is summarized on the left
in A, and the function of these different subregions in the model is shown on the right in
B. Each of the subregions in the model contained a population of excitatory neurons with
a single inhibitory interneuron mediating feedback inhibition and keeping excitatory
activity bounded. Thus, the local activation dynamics in each region follow the equations
presented above. The connectivity of the network is further summarized in Figure 3 in the
Results section. A learning rule of the Hebbian type was utilized at all synaptic connections, with the exception of the mossy fibers from the dentate gyrus to region CA3, and the
connections to and from the medial septum. Self-organization of perforant path synapses
was obtained through decay of synapses with only pre or post-synaptic activity, and
growth of synapses with combined activity. Associative memory function at synapses

80

Michael E. Hasse/mo, Eric Schnell, Joshua Berke, Edi Barkai

arising from region CA3 was obtained through synaptic modification during cholinergic
suppression of synaptic transmission.

B

Entorhinal cortex

""""""""""

??

?
???

: Self-organized
: representation
: r-----..L.\

?

~

Comparison

.L-______~~.-----~~~--~~

Feedback regulation of
cholinergic modulation

Regulation of
learning dynamics

Figure 2. Schematic representation of hippocampal circuitry
and the corresponding function of connections in the model.

2.3. CHOLINERGIC MODULAnON
The total output from region CAl determined the level of cholinergic modulation within
both region CA3 and CAl, with increased output causing decreased modulation. This is
consistent with experimental evidence suggesting that activity in region CAl and region
CA3 can inhibit activity in the medial septum, and thereby downregulate cholinergic modulation. This effect was obtained in the model by excitatory connections from region CAl
to an inhibitory interneuron in the medial septum, which suppressed the activity of a cholinergic neuron providing modulation to the full network. When levels of cholinergic
modulation were high, there was strong suppression of synaptic transmission at the excitatory recurrent synapses in CA3 and the Schaffer collaterals projecting from region CA3 to
CAL This prevented the spread of activity due to previous learning from interfering with
self-organization. When levels of cholinergic modulation were decreased, the strength of
synaptic transmission was increased, allowing associative recall to dominate. Cholinergic
modulation also increased the rate of synaptic modification and depolarized neurons.

2.4. TESTS OF SELF-REGULATED LEARNING AND RECALL
Simulations of the full hippocampal network evaluated the response to the sequential presentation of a series of highly overlapping activity patterns in the entorhinal cortex. Recall
was tested with interspersed presentation of degraded versions of previously presented
activity patterns. For effective recall, the pattern of activity in entorhinal cortex layer IV
evoked by degraded patterns matched the pattern evoked by the full learned version of
these patterns. The function of the full network is illustrated in Figure 3. In simulations

A Model of Hippocampus

81

focused on region CA3, activity patterns were induced sequentially in region CA3, representing afferent input from the entorhinal cortex. Different levels of external activation of
the cholinergic neuron resulted in different levels of learning of new overlapping patterns.
These results are illustrated in Figure 4.

2.5. BRAIN SLICE EXPERIMENTS
The effects in the simulations of region CA3 depended upon the cholinergic suppression
of synaptic transmission in stratum radiatum of this region The cholinergic suppression of
glutamatergic synaptic transmission in region CA3 was tested in brain slice preparations
by analysis of the influence of the cholinergic agonist carbachol on the size of field potentials elicited by stimulation of stratum radiatum. These experiments used techniques similar to previously published work in region CAl (Hasselmo and Schnell, 1994).

3 RESULTS
In the full hippocampal simulation, input of an unfamiliar pattern to entorhinal cortex
layer II resulted in high levels of acetylcholine. This allowed rapid self-organization of
the perforant path input to the dentate gyrus and region CAl. Cholinergic suppression of
synaptic transmission in region CAl prevented recall from interfering with self-organization. Instead, recurrent collaterals in region CA3 stored an autoassociative representation
of the input from the dentate gyrus to region CA3, and connections from CA3 to CA 1
stored associations between the pattern of activity in CA3 and the associated self-organized representation in region CAl.
identity
" self-org "matrix ~
,auto-"
,,~>
M assoc
u .....
?
?
'at)
u
u
c >.
--I.~ ?
c
?
c
?
:.a.?:i
Self-org ~
iden~ity
.9
hetero.9 hetero8
matrix
~
assoc
~ assoc
C!

~

~

?

~

111111 I "T I' , If
,r
2 I I I II
n
I I
ld II
r I" I 'I"'"'I II , , ,
Q)2dl' r II' I I ' l l I
~ 311111 I' I I I n
"

j

4

3d
4d
ld

2d

n,n

II
II
II

'f
I I II I n
I
II I
I
,
,
II
,
I
1I
'I

I

'I

.. ,
II f'l't?
U i
I I Itt

~

I.Ll

r"

U
I

"
H
,
I
I
U
I I 1 II r

~'

,,

1

,

'(
( U.

"

I I

I

1'1 I I
I I I n
I"'" , 'I II I II

1 I ' ,I

I

l 11 I J1
't III I'

?"

'I . .

I

I

, I I II
I II ? .1
l " I II
I III I I

W.

Jl 1

lU

Neuron #
Figure 3. Activity in each subregion of the full network simulation of the hippocampal
formation during presentation of a sequence of activity patterns in entorhinal cortex.

82

Michael E. Hasselmo, Eric Schnell, Joshua Berke, Edi Barkai

In Figure 3. width of the lines represents the activity of each neuron at a particular time
step. As seen here. the network forms a self-organized representation of each new pattern
consisting of active neurons in the dentate gyrus and region CAL At the same time. an
association is formed between the self-organized representation in region CAl and the
same afferent input pattern presented to entorhinal cortex layer IV. Four overlapping patterns (1-4) are presented sequentially. each of which results in learning of a separate selforganized representation in the dentate gyrus and region CAl. with an association formed
between this representation and the full input pattern in entorhinal cortex.
The recall characteristics of the network are apparent when degraded versions of the afferent input patterns are presented in the sequence (ld-4d). This degraded afferent input
weakly activates the same representations previously formed in the dentate gyrus. Recurrent excitation in region CA3 enhances this activity. giving robust recall of the full version
of this pattern. This activity then reaches CA 1. where it causes strong activation if it
matches the pattern of afferent input from the entorhinal cortex. Strong activation in
region CAl decreases cholinergic modulation. preventing formation of a new representation and allowing recall to dominate. Strong activation of the representation stored in
region CAl then activates the full representation of the pattern in entorhinal cortex layer
IV. Thus. the network can accurately recall each of many highly overlapping patterns.
The effect of cholinergic modulation on the level of learning or recall can be seen more
clearly in a simulation of auto-associative memory function in region CA3 as shown in
Figure 4. Each box shows the response of the network to sequential presentation of full
and degraded versions of two highly overlapping input patterns. The width of the black
traces represents the activity of each of 10 CA3 pyramidal cells during each simulation
step. In the top row. level of cholinergic modulation (ACh) is plotted. In A. external activation of the cholinergic neuron is absent. so there is no cholinergic suppression of synaptic transmission. In this case. the first pattern is learned and recalled properly. but
subsequent presentation of a second overlapping pattern results only in recall of the previously learned pattern. In B. with greater cholinergic suppression. recall is suppressed sufficiently to allow learning of a combination of the two input patterns. Finally. in C. strong
cholinergic suppression prevents recall. allowing learning of the new overlapping pattern
to dominate over the previously stored pattern.

A

Stored
patterns

???

??
??

?
?

-.gN.g
N

-

ACh
Inhib
Q\

.- .--.

ACh input = 0.0

..... ......

,11",,11.

.....

B

ACh input

=0.15

C

__
ACh input

=0.3

...11'_..,.......,.. ......

111 ... 111...... 11 . . . ."'... 11 ? ?111 ??,

'

I ? ? " '? ? _ _

'111"

.';::
~

~

?'. _"11.. ? .'.? .
.,~

. ",.

.u. . . . .... ,

0

. . . . . . . . . . 111. . . .... .

N

Figure 4. Increased cholinergic suppression of synaptic transmission in region CA3
causes greater learning of new aspects of afferent input patterns.

A Model of Hippocampus

83

Extracellular recording in brain slice preparations of hippocampal region CA3 have demonstrated that perfusion of the cholinergic agonist carbachol strongly suppresses synaptic
potentials recorded in stratum radiatum, as shown in Figure 5. In contrast, suppression of
synaptic transmission at the afferent fiber synapses arising from entorhinal cortex is much
weaker. At a concentration of 20J..tM, carbachol suppressed synaptic potentials in stratum
radiatum on average by 54.4% (n=5). Synaptic potentials elicited in stratum lacunosum
were more weakly suppressed, with an average suppression of28%.

Control

Carbachol
(20JlM)

Wash

Figure 5. Cholinergic suppression of synaptic transmission in stratum radiatum of CA3.

4

DISCUSSION

In this model of the hippocampus, self-organization at perforant path synapses forms compressed representations of specific patterns of cortical activity associated with events in
the environment. Feedback regulation of cholinergic modulation sets appropriate dynamics for learning in response to novel stimuli, allowing predominance of self-organization,
and appropriate dynamics for recall in response to familiar stimuli, allowing predominance of associative memory function. This combination of self-organization and associative memory function may also occur in neocortical structures. The selective cholinergic
suppression of feedback and intrinsic synapses has been proposed to allow self-organization of feedforward synapses while feedback synapses mediate storage of associations
between higher level representations and activity in primary cortical areas (Hasselmo,
1994b). This previous proposal could provide a physiological justification for a similar
mechanism utilized in recent models (Dayan et al., 1995). Detailed modeling of cholinergic effects in the hippocampus provides a theoretical framework for linking the considerable behavioral evidence for a role of acetylcholine in memory function (Hagan and
Morris, 1989) to the neurophysiological evidence for the effects of acetylcholine within
cortical structures (Hasselmo and Bower, 1992; 1993; Hasselmo, 1994a, 1994b).

Acknowledgements
This work supported by a pilot grant from the Massachusetts Alzheimer's Disease
Research Center and by an NIMH FIRST award MH52732-01.

References
Barkai E, Hasselmo ME (1994) Modulation of the input/output function of rat piriform
cortex pyramidal cells. J. Neurophysiol. 72: 644-658.

84

Michael E. Hasselmo, Eric Schnell, Joshua Berke, Edi Barkai

Barkai E, Bergman RE, Horwitz G, Hasselmo ME (1994) Modulation of associative memory function in a biophysical simulation of rat pirifonn cortex. J. Neurophysiol. 72:659677.
Burgess N, Reece M, O'Keefe J (1994) A model of hippocampal function. Neural Networks 7: 1065-1081.
Dayan P, Hinton GE, Neal RM and Zemel RS (1995) The Helmholtz machine. Neural
computation in press.
Eichenbaum, H. and Buckingham, J. (1990) Studies on hippocampal processing: experiment, theory and model. In: Learning and computational neuroscience: foundations of
adaptive networks, M. Gabriel and J. Moore, eds., Cambridge, MA: MIT Press.
Hagan, JJ and Morris, RGM (1989) The cholinergic hypothesis of memory: A review of
animal experiments. In Psychopharmacology of the Aging Nervous System, L.L. Iversen,
S.D. Iversen and S.H. Snyder, eds. New York: Plenum Press, p. 237-324.
Hasselmo, M.E. (1993) Acetylcholine and learning in a cortical associative memory. Neural Compo 5: 22-34.
Hasselmo ME (1994a) Runaway synaptic modification in models of cortex: Implications
for Alzheimer's disease. Neural Networks 7: 13-40.
Hasselmo ME (1994b) Neuromodulation and cortical function. Behav. Brain Res. in press
Hasselmo ME, Anderson, BP and Bower, JM (1992) Cholinergic modulation of cortical
associative memory function. J. Neurophysiol. 67(5): 1230-1246.
Hasselmo ME, Bower JM (1992) Cholinergic suppression specific to intrinsic not afferent
fiber synapses in rat pirifonn (olfactory) cortex. J. Neurophysiol. 67(5): 1222-1229.
Hasselmo ME, Bower JM (1993) Acetylcholine and memory. Trends Neurosci 16:218222.
Hasselmo ME, Barkai E, Horwitz G, Bergman RE (1993) Modulation of neuronal adaptation and cortical associative memory function. In: Computation and Neural Systems II
(Eeckman F, Bower JM, ed). Norwell, MA: Kluwer Academic Publishers.
Hasselmo ME, Schnell E (1994) Laminar selectivity of the cholinergic suppression of synaptic transmission in rat hippocampal region CAl: Computational modeling and brain
slice physiology. J. Neurosci. 14: 3898-3914.
Levy WB (1989) A computational approach to hippocampal function. In: Computational
models of learning in simple neural systems (Hawkins RD, Bower GH, ed), pp. 243-305.
Orlando, FL: Academic Press.
Myers CE and Gluck M (1994) Context, conditioning and hippocampal rerepresentation
in animal learning. Behav. Neurosci. 108: 835-847.
Marr 0 (1971) Simple memory: A theory for archicortex. Phil. Trans. Roy. Soc. B
B262:23-81
McNaughton BL (1991) Associative pattern completion in hippocampal circuits: New
evidence and new questions. Brain Res. Rev. 16:193-220.
McNaughton BL, Morris RGM (1987) Hippocampal synaptic enhancement and infonnation storage within a distributed memory system. Trends Neurosci. 10:408-415.
Touretzky OS, Wan HS and Redish AD (1994) Neural representation of space in rats and
robots. In Zurada JM and Marks RJ (eds) Computational Intelligence: Imitating life.
IEEE Press.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4871-correlations-strike-back-again-the-case-of-associative-memory-retrieval.pdf

Correlations strike back (again): the case of
associative memory retrieval

Cristina Savin1
cs664@cam.ac.uk

Peter Dayan2
dayan@gatsby.ucl.ac.uk

M?at?e Lengyel1
m.lengyel@eng.cam.ac.uk
1

Computational & Biological Learning Lab, Dept. Engineering, University of Cambridge, UK
2
Gatsby Computational Neuroscience Unit, University College London, UK

Abstract
It has long been recognised that statistical dependencies in neuronal activity need
to be taken into account when decoding stimuli encoded in a neural population.
Less studied, though equally pernicious, is the need to take account of dependencies between synaptic weights when decoding patterns previously encoded in an
auto-associative memory. We show that activity-dependent learning generically
produces such correlations, and failing to take them into account in the dynamics
of memory retrieval leads to catastrophically poor recall. We derive optimal network dynamics for recall in the face of synaptic correlations caused by a range of
synaptic plasticity rules. These dynamics involve well-studied circuit motifs, such
as forms of feedback inhibition and experimentally observed dendritic nonlinearities. We therefore show how addressing the problem of synaptic correlations leads
to a novel functional account of key biophysical features of the neural substrate.

1

Introduction

Auto-associative memories have a venerable history in computational neuroscience. However, it is
only rather recently that the statistical revolution in the wider field has provided theoretical traction
for this problem [1]. The idea is to see memory storage as a form of lossy compression ? information
on the item being stored is mapped into a set of synaptic changes ? with the neural dynamics during
retrieval representing a biological analog of a corresponding decompression algorithm. This implies
there should be a tight, and indeed testable, link between the learning rule used for encoding and the
neural dynamics used for retrieval [2].
One issue that has been either ignored or trivialized in these treatments of recall is correlations
among the synapses [1?4] ? beyond the perfect (anti-)correlations emerging between reciprocal
synapses with precisely (anti-)symmetric learning rules [5]. There is ample experimental data for
the existence of such correlations: for example, in rat visual cortex, synaptic connections tend to
cluster together in the form of overrepresented patterns, or motifs, with reciprocal connections being
much more common than expected by chance, and the strengths of the connections to and from
each neuron being correlated [6]. The study of neural coding has indicated that it is essential to
treat correlations in neural activity appropriately in order to extract stimulus information well [7?
9]. Similarly, it becomes pressing to examine the nature of correlations among synaptic weights in
auto-associative memories, the consequences for retrieval of ignoring them, and methods by which
they might be accommodated.
1

Here, we consider several well-known learning rules, from simple additive ones to bounded synapses
with metaplasticity, and show that, with a few significant exceptions, they induce correlations between synapses that share a pre- or a post-synaptic partner. To assess the importance of these dependencies for recall, we adopt the strategy of comparing the performance of decoders which either
do or do not take them into account [10], showing that they do indeed have an important effect on
efficient retrieval. Finally, we show that approximately optimal retrieval involves particular forms
of nonlinear interactions between different neuronal inputs, as observed experimentally [11].

2

General problem formulation

We consider a network of N binary neurons that enjoy all-to-all connectivity.1 As is conventional,
and indeed plausibly underpinned by neuromodulatory interactions [12], we assume that network
dynamics do not play a role during storage (with stimuli being imposed as patterns of activity on the
neurons), and that learning does not occur during retrieval.
To isolate the effects of different plasticity rules on synaptic correlations from other sources of
correlations, we assume that the patterns of activity inducing the synaptic changes have no particular
structure, i.e. their distribution factorizes. For further simplicity, we take these activity patterns to
be binary with pattern density f , i.e. a prior over patterns defined as:
Y
Pstore (x) =
Pstore (xi )
Pstore (xi ) = f xi ? (1 ? f )1?xi
(1)
i

During recall, the network is presented with a cue, x
?, which is a noisy or partial version of one
of the originally stored patterns. Network dynamics should complete this partial pattern, using the
information in the weights W (and the cue). We start by considering arbitrary dynamics; later we
impose the critical constraint for biological realisability that they be strictly local, i.e. the activity of
neuron i should depend exclusively on inputs through incoming synapses Wi,? .
Since information storage by synaptic plasticity is lossy, recall is inherently a probabilistic inference
problem [1, 13] (Fig. 1a), requiring estimation of the posterior over patterns, given the information
in the weights and the recall cue:
? ) ? Pstore (x) ? Pnoise (?
P (x|W, x
x|x) ? P(W|x)

(2)

This formulation has formed the foundation of recent work on constructing efficient autoassociative
recall dynamics for a range of different learning rules [2?4]. In this paper, we focus on the last term
P(W|x), which expresses the probability of obtaining W as the synaptic weight matrix when x is
stored along with T ? 1 random patterns (sampled from the prior, Eq. 1). Critically, this is where
we diverge from previous analyses that assumed this distribution was factorised, or only trivially
correlated due to reciprocal synapses being precisely (anti-)symmetric [1, 2, 4]. In contrast, we
explicitly study the emergence and effects of non-trivial correlations in the synaptic weight matrixdistribtion, because almost all synaptic plasticity rules induce statistical dependencies between the
synaptic weights of each neuron (Fig. 1a, d).
The inference problem expressed by Eq. 2 can be translated into neural dynamics in several ways
? dynamics could be deterministic, attractor-like, converging to the most likely pattern (a MAP
estimate) of the distribution of x [2], or to a mean-field approximate solution [3]; alternatively, the
dynamics could be stochastic, with the activity over time representing samples from the posterior,
and hence implicitly capturing the uncertainty associated with the answer [4]. We consider the latter.
Since we estimate performance by average errors, the optimal response is the mean of the posterior,
which can be estimated by integrating the activity of the network during retrieval.
We start by analysing the class of additive learning rules, to get a sense for the effect of correlations on retrieval. Later, we focus on multi-state synapses, for which learning rules are described
by transition probabilities between the states [14]. These have been used to capture a variety of
important biological constraints such as bounds on synaptic strengths and metaplasticity, i.e. the
fact that synaptic changes induced by a certain activity pattern depend on the history of activity at
the synapse [15]. The two classes of learning rule are radically different; so if synaptic correlations
matter during retrieval in both cases, then the conclusion likely applies in general.
1
Complete connectivity simplifies the computation of the parameters for the optimal dynamics for cascadelike learning rules considered in the following, but is not necessary for the theory.

2

1

covariance rule
simple Hebb rule
cortical data (Song 2005)

0.5
0

d

e
error (%)

1

corr

c

error (%)

b
corr

a

0.5
0

10 control
exact (considering correlations)
simple (ignoring correlations)

5
0

25

30

50

100

50

100

N

20
10 control
0

25

N

Figure 1: Memory recall as inference and additive learning rules. a. Top: Synaptic weights,
W, arise by storing the target pattern x together with T ?1 other patterns, {x(t) }t=1...T?1 . During
? , is a noisy version of the target pattern. The task of recall is to infer x given W
recall, the cue, x
and x
? (by marginalising out {x(t) }). Bottom: The activity of neuron i across the stored patterns is
a source of shared variability between synapses connecting it to neurons j and k. b-c. Covariance
rule: patterns of synaptic correlations and recall performance for retrieval dynamics ignoring or
considering synaptic correlations; T = 5. d-e. Same for the simple Hebbian learning rule. The
control is an optimal decoder that ignores W.

3

Additive learning rules

Local additive learning rules assume that synaptic changes induced by different activity patterns
combine additively; such that storing a sequence of T patterns from Pstore (x), results in weights
P
(t)
(t)
Wij = t ?(xi , xj ), with function ?(xi , xj ) describing the change in synaptic strength induced
by presynaptic activity xj and postsynaptic activity xi . We consider a generalized Hebbian form for
this function, with ? (xi , xj ) = (xi ? ?)(xj ? ?). This class includes, for example, the covariance
rule (? = ? = f ), classically used in Hopfield networks, or simple Hebbian learning (? = ? = 0).
As synaptic changes are deterministic, the only source of uncertainty in the distribution P(W|x)
is the identity of the other stored patterns. To estimate this, let us first consider the distribution of
the weights after storing one random pattern from Pstore (x). The mean ? and covariance C of the
weight change induced by this event can be computed as:2
Z
Z

? = Pstore (x)?| (x)dx,
C = Pstore (x) ?| (x) ? ?| (x)T dx ? ? ? ?T
(3)
Since the rule is additive and the patterns are independent, the mean and covariance scale linearly
with the number of intervening patterns. Hence, the distribution over possible weight values at
recall, given that pattern x is stored along with T ? 1 other, random, patterns has mean ?W =
?(x) + (T ? 1) ? ?, and covariance CW = (T ? 1) ? C. Most importantly, because the rule is
additive, in the limit of many stored patterns (and in practice even for modest values of T ), the
distribution P(W|x) approaches a multivariate Gaussian that is characterized completely by these
two quantities; moreover, its covariance is independent of x.
For retrieval dynamics based on Gibbs sampling, the key quantity is the log-odds ratio


P(xi = 1|x?i , W, x
?)
(4)
Ii = log
P(xi = 0|x?i , W, x
?)
for neuron i, which could be represented by the total current entering the unit. This would translate
into a probability of firing given by the sigmoid activation function f (Ii ) = 1/(1 + e?Ii ).
The total current entering a neuron is a sum of two terms: one term from the external input of the
form c1 ? x
?i + c2 (with constants c1 and c2 determined by parameters f and r [16]), and one term
from the recurrent input, of the form:

T
 
T



1
(0)
(0)
(1)
(1)
Iirec =
(5)
W| ? ?W
C?1 W| ? ?W ? W| ? ?W
C?1 W| ? ?W
2(T ?1)
2
For notational convenience, we use a column-vector form of the matrix of weight changes ?, and the
weight matrix W, marked by subscript | .

3

(0/1)

where ?W = ?| (x(0/1) )+(T?1)? and x(0/1) is the vector of activities obtained from x in which
the activity of neuron i is set to 0, or 1, respectively.
It is easy to see that for the covariance rule, ? (xi , xj ) = (xi ? f )(xj ? f ), synapses sharing
a single pre- or post-synaptic partner happen to be uncorrelated (Fig. 1b). Moreover, as for any
(anti-)symmetric additive learning rule, reciprocal connections are perfectly correlated (Wij = Wji ).
The (non-degenerate part of the) covariance matrix in this case becomes diagonal, and the total
current in optimal retrieval reduces to simple linear dynamics :
Ii =

1
2
(T ? 1) ?W

X

Wij xj ?

j

|

{z

}

recurrent input


X
(1 ? 2f )2 X
1 ? 2f
Wij ? f 2
xj ? f
2
2
j
j
| {z }
{z
}
| {z }
|
feedback inhibition

homeostatic term

(6)

constant

2
where ?W
is the variance of a synaptic weight resulting from storing a single pattern. This term
includes a contribution from recurrent excitatory input, dynamic feedback inhibition (proportional
to the total population activity) and a homeostatic term that reduces neuronal excitability as function
of the net strength of its synapses (a proxy for average current the neuron expects to receive) [17].
Reassuringly, the optimal decoder for the covariance rule recovers a form for the input current that is
closely related to classic Hopfield-like [5] dynamics (with external field [1, 18]): feedback inhibition
is needed only when the stored patterns are not balanced (f 6= 0.5); for the balanced case, the
homeostatic term can be integrated in the recurrent current, by rewriting neural activities as spins.
In sum, for the covariance rule, synapses are fortuitously uncorrelated (except for symmetric pairs
which are perfectly correlated), and thus simple, classical linear recall dynamics suffice (Fig. 1c).

The covariance rule is, however, the exception rather than the rule. For example, for simple Hebbian
learning, ? (xi , xj ) = xi ?xj , synapses sharing a pre- or post-synaptic partner are correlated (Fig. 1d)
and so the covariance matrix C is no longer diagonal. Interestingly, the final expression of the
recurrent current to a neuron remains strictly local (because of additivity and symmetry), and very
similar to Eq. 6, but feedback inhibition becomes a non-linear function of the total activity in the
network [16]. In this case, synaptic correlations have a dramatic effect: using the optimal non-linear
dynamics ensures high performance, but trying to retrieve information using a decoder that assumes
synaptic independence (and thus uses linear dynamics) yields extremely poor performance, which
is even worse than the obvious control of relying only on the information in the recall cue and the
prior over patterns (Fig. 1e).
For the generalized Hebbian case, ? (xi , xj ) = (xi ??)(xj ??) with ? 6= ?, the optimal decoder becomes even more complex, with the total current including additional terms accounting for pairwise
correlations between any two synapses that have neuron i as a pre- or post-synaptic partner [16].
Hence, retrieval is no longer strictly local3 and a biological implementation will require approximating the contribution of non-local terms as a function of locally available information, as we discuss
in detail for palimpsest learning below.

4

Palimpsest learning rules

Though additive learning rules are attractive for their analytical tractability, they ignore several important aspects of synaptic plasticity, e.g. they assume that synapses can grow without bound. We
investigate the effects of bounded weights by considering another class of learning rules, which assumes synaptic efficacies can only take binary values, with stochastic transitions between the two
underpinned by paired cascades of latent internal states [14] (Fig. 2). These learning rules, though
very simple, capture an important aspect of memory ? the fact that memory is leaky, and information
about the past is overwritten by newly stored items (usually referred to as the palimpsest property).
Additionally, such rules can account for experimentally observed synaptic metaplasticity [15].
3
For additive learning rules, the current to neuron i always depends only on synapses local to a neuron, but
these can also include outgoing synapses of which the weight, W?i , should not influence its dynamics. We refer
to such dynamics as ?semi-local?. For other learning rules, the optimal current to neuron i may depend on all
connections in the network, including Wjk with j, k 6= i (?non-local? dynamics).

4

R1

D P

post

R2

R3

c

- -

0
1

D
P

P D
D P
0 1
pre

0.4

cortex data (Song 2005)

d

correlated synapses

20
10

0.2
0

0

0.4

20

error (%)

b

correlation coefficient

a

0.2
0
0.6

pseudostorage

10
0
20

0.3

*

10

0

exact approx

0

simple
dynamics

*

corr-dependent
dynamics

Figure 2: Palimpsest learning. a. The cascade model. Colored circles are latent states (V ) that
belong to two different synaptic weights (W ), arrows are state transitions (blue: depression, red:
potentiation) b. Different variants of mapping pre- and post-synaptic activations to depression (D)
and potentiation (P): R1?postsynaptically gated, R2?presynaptically gated, R3?XOR rule. c. Correlation structure induced by these learning rules. c. Retrieval performance for each rule.
Learning rule
Learning is stochastic and local, with changes in the state of a synapse Vij being determined only by
the activation of the pre- and post-synaptic neurons, xj and xi . In general, one could define separate
transition matrices for each activity pattern, M(xi , xj ), describing the probability of a synaptic state
transitioning between any two states Vij to Vij0 following an activity pattern, (xi , xj ). For simplicity,
we define only two such matrices, for potentiation, M+ , and depression, M? , respectively, and then
map different activity patterns to these events. In particular, we assume Fusi?s cascade model [14]4
and three possible mappings (Fig. 2b [16]): 1) a postsynaptically gated learning rule, where changes
occur only when the postsynaptic neuron is active, with co-activation of pre- and post- neuron leading to potentiation, and to depression otherwise5 ; 2) a presynaptically gated learning rule, typically
assumed when analysing cascades[20, 21]; and 3) an XOR-like learning rule which assumes potentiation occurs whenever the pre- and post- synaptic activity levels are the same, with depression
otherwise. The last rule, proposed by Ref. 22, was specifically designed to eliminate correlations
between synapses, and can be viewed as a version of the classic covariance rule fashioned for binary
synapses.
Estimating the mean and covariance of synaptic weights
At the level of a single synapse, the presentation of a sequence of uncorrelated patterns from
Pstore (x) corresponds to a Markov random walk, P
defined by a transition matrix M, which averages over possible neural activity patterns: M = xi ,xj Pstore (xi ) ? Pstore (xj ) ? M(xi , xj ). The
distribution over synaptic states t steps after the initial encoding can be calculated by starting from
the stationary distribution of the weights ? V 0 (assuming a large number of other patterns have previously been stored; formally, this is the eigenvector of M corresponding to eigenvalue ? = 1), then
storing the pattern (xi , xj ), and finally t ? 1 other patterns from the prior:
t?1

? V (xi , xj , t) = M

? M(xi , xj ) ? ? V 0 ,

(7)

?lV

with the distribution over states given as a column vector,
= P(Vij = l|xi , xj ), l ? {1 . . . 2n},
where n is the depth of the cascade. Lastly, the distribution over weights, P(Wij |xi , xj ), can be
derived as ? W = MV ?W ? ? V , where MV ?W is a deterministic map from states to observed
weights (Fig. 2a).
As in the additive case, the states of synapses sharing a pre- or post- synaptic partner will be correlated (Figs. 1a, 2c). The degree of correlations for different synaptic configurations can be estimated
by generalising the above procedure to computing the joint distribution of the states of pairs of
synapses, which we represent as a matrix ?. E.g. for a pair of synapses sharing a postsynaptic
partner (Figs. 1b, d, and 2c), element (u, v) is ?uv = P(Vpost,pre1 = u, Vpost,pre2 = v). Hence, the
presentation of an activity pattern (xpre1 , xpre2 , xpost ) induces changes in the corresponding pair of
4

Other models, e.g. serial [19], could be used as well without qualitatively affecting the results.
One could argue that this is the most biologically relevant as plasticity is often NMDA-receptor dependent,
and hence it requires postsynaptic depolarisation for any effect to occur.
5

5

incoming synapses to neuron post as ?(1) = M(xpost , xpre1 ) ? ?(0) ? M(xpost , xpre2 )T , where ?(0)
is the stationary distribution corresponding to storing an infinite number of triplets from the pattern
distribution [16].
Replacing ? V with ? (which is now a function of the triplet (xpre1 , xpre2 , xpost )), and the multiplication by M with the slightly more complicated operator above, we can estimate the evolution of
the joint distribution over synaptic states in a manner very similar to Eq. 7:
X
? i ) ? ?(t?1) ? M(x
? i )T ,
Pstore (xi ) ? M(x
(8)
?(t) =
xi
P
? i) =
where M(x
xj Pstore (xj )M(xi , xj ). Also as above, the final joint distribution over states
can be mapped into a joint distribution over synaptic weights as MV ?W ? ?(t) ? MT
V ?W . This
approach can be naturally extended to all other correlated pairs of synapses [16].
The structure of correlations for different synaptic pairs varies significantly as a function of the
learning rule (Fig. 2c), with the overall degree of correlations depending on a range of factors.
Correlations tend to decrease with cascade depth and pattern sparsity. The first two variants of the
learning rule considered are not symmetric, and so induce different patterns of correlations than the
additive rules above. The XOR rule is similar to the covariance rule, but the reciprocal connections
are no longer perfectly correlated (due to metaplasticity), which means that it is no longer possible
to factorize P(W|x). Hence, assuming independence at decoding seems bound to introduce errors.
Approximately optimal retrieval when synapses are independent
If we ignore synaptic correlations, the evidence from the weights factorizes, P(W|x) =
Q
3
i,j P(Wij |xi , xj ), and so the exact dynamics would be semi-local . We can further approximate
the contribution of the outgoing weights by its mean, which recovers the same simple dynamics
derived for the additive case:


X
X
X
P(xi = 1|x?i , W, x
?)
Ii = log
= c1
Wij xj + c2
Wij + c3
xj + c4 x?i + c5 (9)
j
j
j
P(xi = 0|x?i , W, x
?)
The parameters c. depend on the prior over x, the noise model, the parameters of the learning rule
and t. Again, the optimal decoder is similar to previously derived attractor dynamics; in particular,
for stochastic binary synapses with presynaptically gated learning the optimal dynamics require
dynamic inhibition only for sparse patterns, and no homeostatic term, as used in [21] .
To validate these dynamics, we remove synaptic correlations by a pseudo-storage procedure in which
synapses are allowed to evolve independently according to transition matrix M, rather than changing
as actual intermediate patterns are stored. The dynamics work well in this case, as expected (Fig. 2d,
blue bars). However, when storing actual patterns drawn from the prior, performance becomes extremely poor, and often worse than the control (Fig. 2d, gray bars). Moreover, performance worsens
as the network size increases (not shown). Hence, ignoring correlations is highly detrimental for this
class of learning rules too.
Approximately optimal retrieval when synapses are correlated
To accommodate synaptic correlations, we approximate P(W|x) with a maximum entropy distribution with the same marginals and covariance structure, ignoring the higher order moments.6
Specifically, we assume the evidence from the weights has the functional form:
X

1X
1
exp
kij (x, t) ? Wij +
J(ij)(kl) (x, t) ? Wij Wkl
(10)
P(W|x, t) =
ij
ijkl
Z(x, t)
2
We use the TAP mean-field method [23] to find parameters k and J and the partition function, Z,
for each possible activity pattern x, given the mean and covariance for the synaptic weights matrix,
computed above7 [16].
6
This is just a generalisation of the simple dynamics which assume a first order max entropy model; moreover, the resulting weight distribution is a binary analog of the multivariate normal used in the additive case,
allowing the two to be directly compared.
7
Here, we ask whether it is possible to accommodate correlations in appropriate neural dynamics at all,
ignoring the issue of how the optimal values for the parameters of the network dynamics would come about.

6

a

b

no corr
corr

5

0.05

0.5

0.01

0
0

0

0

?5
?10

?0.05

d

12

6

0
?2

0

2

4

6

8

10

number of coactive inputs

12

10

20

0

10

0

10

20

e

10
5
0
?5
?10

?0.01

20

0

2

4

6

8

10

12

number of coactive inputs

normalized EPSP

0

TIP

20

MIDDLE

10

postsynaptic current

c

postsynaptic current

0

BASE

?0.5

1.0
0.8
0.6
0.4
0.2
0.0

0

1

2 3 4 5 6
number of inputs

7

Figure 3: Implications for neural dynamics. a. R1: parameters for Iirec ; linear modulation by
network activity, nb . b. R2: nonlinear modulation of pairwise term by network activity (cf. middle
panel in a); other parameters have
P linear dependences on nb . c. R1: Total current as
Pfunction of
number of coactivated inputs, j Wij xj ; lines: different levels of neural excitability j Wij , line
widths scale with frequency of occurrence in a sample run. d. Same for R2. e. Nonlinear integration
in dendrites, reproduced from [11], cf. curves in c.
Exact retrieval dynamics based on Eq. 10, but not respecting locality constraints, work substantially
better in the presence of synaptic correlations, for all rules (Fig. 2d, yellow bars). It is important to
note that for the XOR rule, which was supposed to be the closest analog to the covariance rule and
hence afford simple recall dynamics [22], error rates stay above control, suggesting that it is actually
a case in which even dependencies beyond 2nd-order correlation would need to be considered.
As in the additive case, exact recall dynamics are biologically implausible, as the total current to
the neuron depends on the full weight matrix. It is possible to approximate the dynamics using
strictly local information by replacing the nonlocal term by its mean, which, however,
is no longer a
P
constant, but rather a linear function of the total activity in the network, nb = j6=i xj [16]. Under
this approximation, the current from recurrent connections corresponding to the evidence from the
weights becomes:
 X

P(W|x(1) )
1X
4
J4
=
k
(x)Wij Wik ? Z 4
(11)
(x)W
+
Iirec = log
ij
ij
jk (ij)(ik)
j
2
P(W|x(0) )
where i is the index of the neuron to be updated, and x(0/1) activity vector has the to-be-updated
neuron?s activity set to 1 or 0, respectively, and all other components given by the
 current network

4
4
state. The functions kij
(x) = kij (x(1) )?kij (x(0) ), J(ij)(kl)
(x) = J(ij)(kl) x(1) ?J(ij)(kl) x(0) ,


and Z 4 = log Z x(1) ? log Z x(0) depend on the local activity at the indexed synapses,
modulated by the number of active neurons in the network, nb . This approximation is again consistent with our previous analysis, i.e. in the absence of synaptic correlations, the complex dynamics
recover the simple case presented before. Importantly, this approximation also does about as well as
exact dynamics (Fig. 2d, red bars).
For post-synaptically gated learning, comparing the parameters of the dynamics in the case of independent versus correlated synapses (Fig. 3a) reveals a modest modulation of the recurrent input by
the total activity. More importantly, the net current to the postsynaptic P
neuron depends non-linearly
(formally, quadratically) on the number of co-active inputs, nW 1 = j xj Wij , (Fig. 3c), which
is reminiscent of experimentally observed dendritic non-linearities [11] (Fig. 3e). Conversely, for
the presynaptically gated learning rule, approximately optimal dynamics predict a non-monotonic
modulation of activity by lateral inhibition (Fig. 3b), but linear neural integration (Fig. 3d).8 Lastly,
retrieval based on the XOR rule has the same form as the simple dynamics derived for the factorized
case [16]. However, the total current has to be rescaled to compensate for the correlations introduced
by reciprocal connections.
8
The difference between the two rules emerges exclusively because of the constraint of strict locality of the
approximation, since the exact form of the dynamics is essentially the same for the two.

7

additive
cascade

RULE
covariance
simple Hebbian
generalized Hebbian
presyn. gated
postsyn. gated
XOR

EXACT DYNAMICS
strictly local, linear
strictly local, nonlinear
semi-local, nonlinear
nonlocal, nonlinear
nonlocal, nonlinear
beyond correlations

NEURAL IMPLEMENTATION
linear feedback inh., homeostasis
nonlinear feedback inh.
nonlinear feedback inh.
nonlinear feedback inh., linear dendritic integr.
linear feedback inh., non-linear dendritic integr.
?

Table 1: Results summary: circuit adaptations against correlations for different learning rules.

5

Discussion

Statistical dependencies between synaptic efficacies are a natural consequence of activity dependent
synaptic plasticity, and yet their implications for network function have been unexplored. Here, in
the context of an auto-associative memory network, we investigated the patterns of synaptic correlations induced by several well-known learning rules and their consequent effects on retrieval. We
showed that most rules considered do indeed induce synaptic correlations and that failing to take
them into account greatly damages recall. One fortuitous exception is the covariance rule, for which
there are no synaptic correlations. This might explain why the bulk of classical treatments of autoassociative memories, using the covariance rule, could achieve satisfying capacity levels despite
overlooking the issue of synaptic correlations [5, 24, 25].
In general, taking correlations into account optimally during recall requires dynamics in which there
are non-local interactions between neurons. However, we derived approximations that perform well
and are biologically realisable without such non-locality (Table 1). Examples include the modulation of neural responses by the total activity of the population, which could be mediated by feedback
inhibition, and specific dendritic nonlinearities. In particular, for the post-synaptically gated learning rule, which may be viewed as an abstract model of hippocampal NMDA receptor-dependent
plasticity, our model predicts a form of non-linear mapping of recurrent inputs into postsynaptic
currents which is similar to experimentally observed dendritic integration in cortical pyramidal cells
[11]. In general, the tight coupling between the synaptic plasticity used for encoding (manifested
in patterns of synaptic correlations) and circuit dynamics offers an important route for experimental
validation [2].
None of the rules governing synaptic plasticity that we considered perfectly reproduced the pattern
of correlations in [6]; and indeed, exactly which rule applies in what region of the brain under which
neuromodulatory influences is unclear. Furthermore, results in [6] concern the neocortex rather
than the hippocampus, which is a more common target for models of auto-associative memory.
Nonetheless, our analysis has shown that synaptic correlations matter for a range of very different
learning rules that span the spectrum of empirical observations.
Another strategy to handle the negative effects of synaptic correlations is to weaken or eliminate
them. For instance, in the palimpsest synaptic model [14], the deeper the cascade, the weaker the
correlations, and so metaplasticity may have the beneficial effect of making recall easier. Another,
popular, idea is to use very sparse patterns [21], although this reduces the information content of
each one. More speculatively, one might imagine a process of off-line synaptic pruning or recoding,
in which strong correlations are removed or the weights adjusted so that simple recall methods will
work.
Here, we focused on second-order correlations. However, for plasticity rules such as XOR, we
showed that this does not suffice. Rather, higher-order correlations would need to be considered,
and thus, presumably higher-order interactions between neurons approximated. Finally, we know
from work on neural coding of sensory stimuli that there are regimes in which correlations either
help or hurt the informational quality of the code, assuming that decoding takes them into account.
Given our results, it becomes important to look at the relative quality of different plasticity rules,
assuming realizable decoding ? it is not clear whether rules that strive to eliminate correlations will
be bested by ones that do not.
Acknowledgments This work was supported by the Wellcome Trust (CS, ML), the Gatsby Charitable Foundation (PD), and the European Union Seventh Framework Programme (FP7/2007?2013)
under grant agreement no. 269921 (BrainScaleS) (ML).
8

References
1. Sommer, F.T. & Dayan, P. Bayesian retrieval in associative memories with storage errors. IEEE transactions on neural networks 9, 705?713 (1998).
2. Lengyel, M., Kwag, J., Paulsen, O. & Dayan, P. Matching storage and recall: hippocampal spike timingdependent plasticity and phase response curves. Nature Neuroscience 8, 1677?1683 (2005).
3. Lengyel, M. & Dayan, P. Uncertainty, phase and oscillatory hippocampal recall. Advances in Neural
Information Processing (2007).
4. Savin, C., Dayan, P. & Lengyel, M. Two is better than one: distinct roles for familiarity and recollection in
retrieving palimpsest memories. in Advances in Neural Information Processing Systems, 24 (MIT Press,
Cambridge, MA, 2011).
5. Hopfield, J.J. Neural networks and physical systems with emergent collective computational abilities.
Proc. Natl. Acad. Sci. USA 76, 2554?2558 (1982).
6. Song, S., Sj?ostr?om, P.J., Reigl, M., Nelson, S. & Chklovskii, D.B. Highly nonrandom features of synaptic
connectivity in local cortical circuits. PLoS biology 3, e68 (2005).
7. Dayan, P. & Abbott, L. Theoretical Neuroscience (MIT Press, 2001).
8. Averbeck, B.B., Latham, P.E. & Pouget, A. Neural correlations, population coding and computation.
Nature Reviews Neuroscience 7, 358?366 (2006).
9. Pillow, J.W. et al. Spatio-temporal correlations and visual signalling in a complete neuronal population.
Nature 454, 995?999 (2008).
10. Latham, P.E. & Nirenberg, S. Synergy, redundancy, and independence in population codes, revisited.
Journal of Neuroscience 25, 5195?5206 (2005).
11. Branco, T. & H?ausser, M. Synaptic integration gradients in single cortical pyramidal cell dendrites. Neuron
69, 885?892 (2011).
12. Hasselmo, M.E. & Bower, J.M. Acetylcholine and memory. Trends Neurosci. 16, 218?222 (1993).
13. MacKay, D.J.C. Maximum entropy connections: neural networks. in Maximum Entropy and Bayesian
Methods, Laramie, 1990 (eds. Grandy, Jr, W.T. & Schick, L.H.) 237?244 (Kluwer, Dordrecht, The Netherlands, 1991).
14. Fusi, S., Drew, P.J. & Abbott, L.F. Cascade models of synaptically stored memories. Neuron 45, 599?611
(2005).
15. Abraham, W.C. Metaplasticity: tuning synapses and networks for plasticity. Nature Reviews Neuroscience
9, 387 (2008).
16. For details, see Supplementary Information.
17. Zhang, W. & Linden, D. The other side of the engram: experience-driven changes in neuronal intrinsic
excitability. Nature Reviews Neuroscience (2003).
18. Engel, A., Englisch, H. & Sch?utte, A. Improved retrieval in neural networks with external fields. Europhysics Letters (EPL) 8, 393?397 (1989).
19. Leibold, C. & Kempter, R. Sparseness constrains the prolongation of memory lifetime via synaptic metaplasticity. Cerebral cortex (New York, N.Y. : 1991) 18, 67?77 (2008).
20. Amit, Y. & Huang, Y. Precise capacity analysis in binary networks with multiple coding level inputs.
Neural computation 22, 660?688 (2010).
21. Huang, Y. & Amit, Y. Capacity analysis in multi-state synaptic models: a retrieval probability perspective.
Journal of computational neuroscience (2011).
22. Dayan Rubin, B. & Fusi, S. Long memory lifetimes require complex synapses and limited sparseness.
Frontiers in Computational Neuroscience (2007).
23. Thouless, D.J., Anderson, P.W. & Palmer, R.G. Solution of ?Solvable model of a spin glass?. Philosophical
Magazine 35, 593?601 (1977).
24. Amit, D., Gutfreund, H. & Sompolinsky, H. Storing infinite numbers of patterns in a spin-glass model of
neural networks. Phys Rev Lett 55, 1530?1533 (1985).
25. Treves, A. & Rolls, E.T. What determines the capacity of autoassociative memories in the brain? Network
2, 371?397 (1991).

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4872-a-memory-frontier-for-complex-synapses.pdf

A memory frontier for complex synapses

Subhaneil Lahiri and Surya Ganguli
Department of Applied Physics, Stanford University, Stanford CA
sulahiri@stanford.edu, sganguli@stanford.edu

Abstract
An incredible gulf separates theoretical models of synapses, often described solely
by a single scalar value denoting the size of a postsynaptic potential, from the
immense complexity of molecular signaling pathways underlying real synapses.
To understand the functional contribution of such molecular complexity to learning and memory, it is essential to expand our theoretical conception of a synapse
from a single scalar to an entire dynamical system with many internal molecular
functional states. Moreover, theoretical considerations alone demand such an expansion; network models with scalar synapses assuming finite numbers of distinguishable synaptic strengths have strikingly limited memory capacity. This raises
the fundamental question, how does synaptic complexity give rise to memory? To
address this, we develop new mathematical theorems elucidating the relationship
between the structural organization and memory properties of complex synapses
that are themselves molecular networks. Moreover, in proving such theorems, we
uncover a framework, based on first passage time theory, to impose an order on
the internal states of complex synaptic models, thereby simplifying the relationship between synaptic structure and function.

1

Introduction

It is widely thought that our very ability to remember the past over long time scales depends crucially
on our ability to modify synapses in our brain in an experience dependent manner. Classical models
of synaptic plasticity model synaptic efficacy as an analog scalar value, denoting the size of a postsynaptic potential injected into one neuron from another. Theoretical work has shown that such
models have a reasonable, extensive memory capacity, in which the number of long term associations
that can be stored by a neuron is proportional its number of afferent synapses [1?3]. However,
recent experimental work has shown that many synapses are more digital than analog; they cannot
robustly assume an infinite continuum of analog values, but rather can only take on a finite number
of distinguishable strengths, a number than can be as small as two [4?6] (though see [7]). This
one simple modification leads to a catastrophe in memory capacity: classical models with digital
synapses, when operating in a palimpset mode in which the ongoing storage of new memories can
overwrite previous memories, have a memory capacity proportional to the logarithm of the number
of synapses [8, 9]. Intuitively, when synapses are digital, the storage of a new memory can flip
a population of synaptic switches, thereby rapidly erasing previous memories stored in the same
synaptic population. This result indicates that the dominant theoretical basis for the storage of long
term memories in modifiable synaptic switches is flawed.
Recent work [10?12] has suggested that a way out of this logarithmic catastrophe is to expand our
theoretical conception of a synapse from a single scalar value to an entire stochastic dynamical system in its own right. This conceptual expansion is further necessitated by the experimental reality
that synapses contain within them immensely complex molecular signaling pathways, with many internal molecular functional states (e.g. see [4, 13, 14]). While externally, synaptic efficacy could be
digital, candidate patterns of electrical activity leading to potentiation or depression could yield transitions between these internal molecular states without necessarily inducing an associated change in
1

synaptic efficacy. This form of synaptic change, known as metaplasticity [15, 16], can allow the
probability of synaptic potentiation or depression to acquire a rich dependence on the history of
prior changes in efficacy, thereby potentially improving memory capacity.
Theoretical studies of complex, metaplastic synapses have focused on analyzing the memory performance of a limited number of very specific molecular dynamical systems, characterized by a
number of internal states in which potentiation and depression each induce a specific set of allowable transitions between states (e.g. see Figure 1 below). While these models can vastly outperform
simple binary synaptic switches, these analyses leave open several deep and important questions.
For example, how does the structure of a synaptic dynamical system determine its memory performance? What are the fundamental limits of memory performance over the space of all possible
synaptic dynamical systems? What is the structural organization of synaptic dynamical systems that
achieve these limits? Moreover, from an experimental perspective, it is unlikely that all synapses
can be described by a single canonical synaptic model; just like the case of neurons, there is an
incredible diversity of molecular networks underlying synapses both across species and across brain
regions within a single organism [17]. In order to elucidate the functional contribution of this diverse molecular complexity to learning and memory, it is essential to move beyond the analysis of
specific models and instead develop a general theory of learning and memory for complex synapses.
Moreover, such a general theory of complex synapses could aid in development of novel artificial
memory storage devices.
Here we initiate such a general theory by proving upper bounds on the memory curve associated with
any synaptic dynamical system, within the well established ideal observer framework of [10, 11, 18].
Along the way we develop principles based on first passage time theory to order the structure of
synaptic dynamical systems and relate this structure to memory performance. We summarize our
main results in the discussion section.

2

Overall framework: synaptic models and their memory curves

In this section, we describe the class of models of synaptic plasticity that we are studying and how
we quantify their memory performance. In the subsequent sections, we will find upper bounds on
this performance.
We use a well established formalism for the study of learning and memory with complex synapses
(see [10, 11, 18]). In this approach, electrical patterns of activity corresponding to candidate potentiating and depressing plasticity events occur randomly and independently at all synapses at a
Poisson rate r. These events reflect possible synaptic changes due to either spontaneous network
activity, or the storage of new memories. We let f pot and f dep denote the fraction of these events that
are candidate potentiating or depressing events respectively. Furthermore, we assume our synaptic
model has M internal molecular functional states, and that a candidate potentiating (depotentiating) event induces a stochastic transition in the internal state described by an M ? M discrete time
Markov transition matrix Mpot (Mdep ). In this framework, the states of different synapses will be
independent, and the entire synaptic population can be fully described by the probability distribution
across these states, which we will indicate with the row-vector p(t). Thus the i?th component of
p(t) denotes the fraction of the synaptic population in state i. Furthermore, each state i has its own
synaptic weight, wi , which we take, in the worst case scenario, to be restricted to two values. After
shifting and scaling these two values, we can assume they are ?1, without loss of generality.
We also employ an ?ideal observer? approach to the memory readout, where the synaptic weights
are read directly. This provides an upper bound on the quality of any readout using neural activity.
For any single memory, stored at time t = 0, we assume there will be an ideal pattern of synaptic
weights across a population of N synapses, the N -element vector w
~ ideal , that is +1 at all synapses
that experience a candidate potentiation event, and ?1 at all synapses that experience a candidate
depression event at the time of memory storage. We assume that any pattern of synaptic weights
close to w
~ ideal is sufficient to recall the memory. However, the actual pattern of synaptic weights at
some later time, t, will change to w(t)
~
due to further modifications from the storage of subsequent
memories. We can use the overlap between these, w
~ ideal ? w(t),
~
as a measure of the quality of the
memory. As t ? ?, the system will return to its steady state distribution which will be uncorrelated
2

Cascade model

(b)

Serial model

(c)

?1

10

SNR

(a)

?2

10

Cascade
Serial

?3

10

?1

10

0

10

1

10
Time

2

10

3

10

Figure 1: Models of complex synapses. (a) The cascade model of [10], showing transitions between
states of high/low synaptic weight (red/blue circles) due to potentiation/depression (solid red/dashed
blue arrows). (b) The serial model of [12]. (c) The memory curves of these two models, showing
the decay of the signal-to-noise ratio (to be defined in ?2) as subsequent memories are stored.
with the memory stored at t = 0. The probability distribution of the quantity w
~ ideal ? w(?)
~
can be
used as a ?null model? for comparison.
The extent to which the memory has been stored is described by a signal-to-noise ratio (SNR)
[10, 11]:
hw
~ ideal ? w(t)i
~
? hw
~ ideal ? w(?)i
~
p
SNR(t) =
.
(1)
Var(w
~ ideal ? w(?))
~
?
The noise in the denominator is essentially N . There is a correction when potentiation and depression are imbalanced, but this will not affect the upper bounds that we will discuss below and
will be ignored in the subsequent formulae.
A simple average memory curve can be derived as follows. All of the preceding plasticity events,
prior to t = 0, will put the population of synapses in its steady-state distribution, p? . The memory we are tracking at t = 0 will change the internal state distribution to p? Mpot (or p? Mdep )
in those synapses that experience a candidate potentiation (or depression) event. As the potentiating/depressing nature of the subsequent memories is independent of w
~ ideal , we can average over all
sequences, resulting in the evolution of the probability distribution:
dp(t)
= rp(t)WF ,
where WF = f pot Mpot + f dep Mdep ? I.
(2)
dt
Here WF is a continuous time transition matrix that models the process of forgetting the memory
stored at time t = 0 due to random candidate potentiation/depression events occurring at each
synapse due to the storage of subsequent memories. Its stationary distribution is p? .
This results in the following SNR
?


F
(3)
SNR(t) = N 2f pot f dep p? Mpot ? Mdep ertW w.
A detailed derivation of this formula can be found in the supplementary material. We will frequently
refer to this function as the memory curve. It can be thought of as the excess fraction of synapses
(relative to equilibrium) that maintain their ideal synaptic strength at time t, as dictated by the stored
memory at time t = 0.
Much of the previous work on these types of complex synaptic models has focused on understanding
the memory curves of specific models, or choices of Mpot/dep . Two examples of these models are
shown in Figure 1. We see that they have different memory properties. The serial model performs
relatively well at one particular timescale, but it performs poorly at other times. The cascade model
does not perform quite as well at that time, but it maintains its performance over a wider range of
timescales.
In this work, rather than analyzing specific models, we take a different approach, in order to obtain
a more general theory. We consider the entire space of these models and find upper bounds on the
memory capacity of any of them. The space of models with a fixed number of internal states M is
parameterized by the pair of M ? M discrete time stochastic transition matrices Mpot and Mdep , in
addition to f pot/dep . The parameters must satisfy the following constraints:
Mpot/dep
? [0, 1],
ij
X

Mpot/dep
ij

= 1,

f pot/dep ? [0, 1],
f pot + f dep = 1,

j

p? WF = 0,
X
p?
i = 1.
i

3

wi = ?1,
(4)

and f pot/dep follow automatically from the other constraints.
The upper bounds on Mpot/dep
ij
The critical question is: what do these constraints imply about the space of achievable memory
curves in (3)? To answer this question, especially for limits on achievable memory at finite times, it
will be useful to employ the eigenmode decomposition:
X
WF =
?qa ua va , va ub = ?ab , WF ua = ?qa ua , va WF = ?qa va .
(5)
a

Here qa are the negative of the eigenvalues of the forgetting process WF , ua are the right (column)
eigenvectors and va are the left (row) eigenvectors. This decomposition allows us to write the
memory curve as a sum of exponentials,
? X
SNR(t) = N
Ia e?rt/?a ,
(6)
a

where Ia = (2f pot f dep )p? (Mpot ? Mdep )ua va w and ?a = 1/qa . We can then ask the question:
what are the constraints on these quantities, namely eigenmode initial SNR?s, Ia , and time constants,
?a , implied by the constraints in (4)? We will derive some of these constraints in the next section.

3

Upper bounds on achievable memory capacity

In the previous section, in (3) we have described an analytic expression for a memory curve as a
function of the structure of a synaptic dynamical system, described by the pair of stochastic transition
matrices Mpot/dep . Since the performance measure for memory is an entire memory curve, and not
just a single number, there is no universal scalar notion of optimal memory in the space of synaptic
dynamical systems. Instead there are tradeoffs between storing proximal and distal memories; often
attempts to increase memory at late (early) times by changing Mpot/dep , incurs a performance loss
in memory at early (late) times in specific models considered so far [10?12]. Thus our end goal,
achieved in ?4, is to derive an envelope memory curve in the SNR-time plane, or a curve that forms
an upper-bound on the entire memory curve of any model. In order to achieve this goal, in this
section, we must first derive upper bounds, over the space of all possible synaptic models, on two
different scalar functions of the memory curve: its initial SNR, and the area under the memory curve.
In the process of upper-bounding the area, we will develop an essential framework to organize the
structure of synaptic dynamical systems based on first passage time theory.
3.1

Bounding initial SNR

We now give an upper bound on the initial SNR,
?


SNR(0) = N 2f pot f dep p? Mpot ? Mdep w,

(7)

over all possible models and also find the class of models that saturate this bound. A useful quantity
is the equilibrium probability flux between two disjoint sets of states, A and B:
XX
F
?AB =
rp?
(8)
i Wij .
i?A j?B

The initial SNR is closely related to the flux from the states with wi = ?1 to those with wj = +1
(see supplementary material):
?
4 N ??+
SNR(0) ?
.
(9)
r
This inequality becomes an equality if potentiation never decreases the synaptic weight and depression never increases it, which should be a property of any sensible model.
To maximize this flux, potentiation from a weak state must be guaranteed to end in a strong state,
and depression must do the reverse. An example of such a model is shown in Figure 2(a,b). These
models have a property known as ?lumpability? (see [19, ?6.3] for the discrete time version and
[20, 21] for continuous time). They are completely equivalent (i.e. have the same memory curve) as
a two state model with transition probabilities equal to 1, as shown in Figure 2(c).
4

(a)

(b)

(c)

1
1

Figure 2: Synaptic models that maximize initial SNR. (a) For potentiation, all transitions starting
from a weak state lead to a strong state, and the probabilities for all transitions leaving a given weak
state sum to 1. (a) Depression is similar to potentiation, but with strong and weak interchanged.
(c) The equivalent two state model, with transition probabilities under potentiation and depression
equal to one.
This two state model has the equilibrium distribution p? = (f dep , f pot ) and its flux is given by
??+ = rf pot f dep . This is maximized when f pot = f dep = 12 , leading to the upper bound:
?
SNR(0) ? N .
(10)
We note that while this model has high initial SNR, it also has very fast memory decay ? with a
timescale ? ? 1r . As the synapse is very plastic, the initial memory is encoded very easily, but
the subsequent memories also overwrite it rapidly. This is one example of the tradeoff between
optimizing memory at early versus late times.
3.2

Imposing order on internal states through first passage times

Our goal of understanding the relationship between structure and function in the space of all possible
synaptic models is complicated by the fact that this space contains many different possible network
topologies, encoded in the nonzero matrix elements of Mpot/dep . To systematically analyze this
entire space, we develop an important organizing principle using the theory of first passage times
in the stochastic process of forgetting, described by WF . The mean first passage time matrix, Tij ,
is defined as the average time it takes to reach state j for the first time, starting from state i. The
diagonal elements are defined to be zero.
A remarkable theorem we will exploit is that the quantity
X
??
Tij p?
j ,

(11)

j

known as Kemeny?s constant (see [19, ?4.4]), is independent of the starting state i. Intuitively, (11)
states that the average time it takes to reach any state, weighted by its equilibrium probability, is
independent of the starting state, implying a hidden constancy inherent in any stochastic process.
In the context of complex synapses, we can define the partial sums
X
X
?i+ =
Tij p?
?i? =
Tij p?
j ,
j .
j?+

(12)

j??

These can be thought of as the average time it takes to reach the strong/weak states respectively.
Using these definitions, we can then impose an order on the states by arranging them in order of
decreasing ?i+ or increasing ?i? . Because ?i+ + ?i? = ? is independent of i, the two orderings are
the same. In this order, which depends sensitively on the structure of Mpot/dep , states later (to the
right in figures below) can be considered to be more potentiated than states earlier (to the left in
figures below), despite the fact that they have the same synaptic efficacy. In essence, in this order, a
state is considered to be more potentiated if the average time it takes to reach all the strong efficacy
states is shorter. We will see that synaptic models that optimize various measures of memory have
an exceedingly simple structure when, and only when, their states are arranged in this order.1
1
Note that we do not need to worry about the order of the ?i? changing during the optimization: necessary
conditions for a maximum only require that there is no infinitesimal perturbation that increases the area. Therefore we need only consider an infinitesimal neighborhood of the model, in which the order will not change.

5

(a)

(b)

(c)

Figure 3: Perturbations that increase the area. (a) Perturbations that increase elements of Mpot
above the diagonal and decrease the corresponding elements of Mdep . It can no longer be used
when Mdep is lower triangular, i.e. depression must move synapses to ?more depressed? states. (b)
Perturbations that decrease elements of Mpot below the diagonal and increase the corresponding
elements of Mdep . It can no longer be used when Mpot is upper triangular, i.e. potentiation must
move synapses to ?more potentiated? states. (c) Perturbation that decreases ?shortcut? transitions
and increases the bypassed ?direct? transitions. It can no longer be used when there are only nearestneighbor ?direct? transitions.
3.3

Bounding area

Now consider the area under the memory curve:
Z ?
A=
dt SNR(t).

(13)

0

We will find an upper bound on this quantity as well as the model that saturates this bound.
First passage time theory introduced in the previous section becomes useful because the area has a
simple expression in terms of quantities introduced in (12) (see supplementary material):


X
?

pot
dep
A = N (4f pot f dep )
p?
?i+ ? ?j+
M
?
M
i
ij
ij
ij

?
=

N (4f

pot dep

f

)

X




dep
p?
?j? ? ?i? .
Mpot
i
ij ? Mij

(14)

ij

With the states in the order described above, we can find perturbations of Mpot/dep that will always
increase the area, whilst leaving the equilibrium distribution, p? , unchanged. Some of these perturbations are shown in Figure 3, see supplementary material for details. For example, in Figure 3(a),
for two states i on the left and j on the right, with j being more ?potentiated? than i (i.e. ?i+ > ?j+ ),
dep
we have proven that increasing Mpot
ij and decreasing Mij leads to an increase in area. The only
thing that can prevent these perturbations from increasing the area is when they require the decrease
of a matrix element that has already been set to 0. This determines the topology (non-zero transition
probabilities) of the model with maximal area. It is of the form shown in Figure 4(c),with potentiation moving one step to the right and depression moving one step to the left. Any other topology
would allow some class of perturbations (e.g. in Figure 3) to further increase the area.
As these perturbations do not change the equilibrium distribution, this means that the area of any
model is bounded by that of a linear chain with the same equilibrium distribution. The area of
a linear chain model can be expressed directly in terms of its equilibrium state distribution, p? ,
yielding the following upper bound on the area of any model with the same p? (see supplementary
material):


?
?
?
?


X
X
X

2
N
2 N X?
?
? ?

?
k?
jp?
p
w
=
k
?
jp
A?
(15)
k
j
k
j  pk ,

r
r

j
j
k
k 
P
where we chose wk = sgn[k ? j jp?
j ]. We can then maximize this by pushing all of the equilibrium distribution symmetrically to the two end states. This can be done by reducing the transition
probabilities out of these states, as in Figure 4(c). This makes it very difficult to exit these states
once they have been entered. The resulting area is
?
N (M ? 1)
.
(16)
A?
r
This analytical result is similar to a numerical result found in [18] under a slightly different information theoretic measure of memory performance.
6

The ?sticky? end states result in very slow decay of memory, but they also make it difficult to encode
the memory in the first place, since a small fraction of synapses are able to change synaptic efficacy
during the storage of a new memory. Thus models that maximize area optimize memory at late
times, at the expense of early times.

4

Memory curve envelope

Now we will look at the implications of the upper bounds found in the previous section for the SNR
at finite times. As argued in (6), the memory curve can be written in the form
? X
SNR(t) = N
Ia e?rt/?a .
(17)
a

The upper bounds on the initial SNR, (10), and the area, (16), imply the following constraints on the
parameters {Ia , ?a }:
X
X
Ia ? 1,
Ia ?a ? M ? 1.
(18)
a

a

We are not claiming that these are a complete set of constraints: not every set {Ia , ?a } that satisfies
these inequalities will actually be achievable by a synaptic model. However, any set that violates
either inequality will definitely not be achievable.
Now we can pick some fixed time, t0 , and maximize the SNR at that time wrt. the parameters
{Ia , ?a }, subject to the constraints above. This always results in a single nonzero Ia ; in essence,
optimizing memory at a single time requires a single exponential. The resulting optimal memory
curve, along with the achieved memory at the chosen time, depends on t0 as follows:
?
?
M ?1
t0 ?
=? SNR(t) = N e?rt/(M ?1)
=? SNR(t0 ) = N e?rt0 /(M ?1) ,
r
?
?
(19)
M ?1
N (M ? 1)e?t/t0
N (M ? 1)
t0 ?
=? SNR(t) =
=? SNR(t0 ) =
.
r
rt0
ert0
Both the initial SNR bound and the area bound are saturated at early times. At late times, only
the area bound is saturated. The function SNR(t0 ), the green curve in Figure 4(a), above forms a
memory curve envelope with late-time power-law decay ? t?1
0 . No synaptic model can have an
SNR that is greater than this at any time. We can use this to find an upper bound on the memory
lifetime, ? (), by finding the point at which the envelope crosses :
?
N (M ? 1)
,
(20)
? () ?
er
where we assume N > (e)2 . Intriguingly, both the lifetime and memory envelope expand linearly
with the number of internal states M , and increase as the square root of the number of synapses N .
This leaves the question of whether this bound is achievable. At any time, can we find a model
whose memory curve touches the envelope? The red curves in Figure 4(a) show the closest we
have come to the envelope with actual models, by repeated numerical optimization of SNR(t0 ) over
Mpot/dep with random initialization and by hand designed models.
We see that at early, but not late times, there is a gap between the upper bound that we can prove
and what we can achieve with actual models. There may be other models we haven?t found that
could beat the ones we have, and come closer to our proven envelope. However, we suspect that the
area constraint is not the bottleneck for optimizing memory at times less than O( M
r ). We believe
there is some other constraint that prevents models from approaching the envelope, and currently are
exploring several mathematical conjectures for the precise form of this constraint in order to obtain
a potentially tighter envelope. Nevertheless, we have proven rigorously that no model?s memory
curve can ever exceed this envelope, and that it is at least tight for late times, longer than O( M
r ),
where models of the form in Figure 4(c)can come close to the envelope.

5

Discussion

We have initiated the development of a general theory of learning and memory with complex
synapses, allowing for an exploration of the entire space of complex synaptic models, rather than
7

(a)

(b)

1

10

0

10
SNR

envelope
numerical search
hand designed
?1

10

(c)

?

Area bound active
Initial SNR bound active

?

?2

10 ?1
10

0

10

1

10
Time

2

10

3

10

Figure 4: The memory curve envelope for N = 100, M = 12. (a) An upper bound on the SNR
at any time is shown in green. The red dashed curve shows the result of numerical optimization of
synaptic models with random initialization. The solid red curve shows the highest SNR we have
found with hand designed models. At early times these models are of the form shown in (b) with
different numbers of states, and all transition probabilities equal to 1. At late times they are of the
form shown in (c) with different values of ?. The model shown in (c) also saturates the area bound
(16) in the limit ? ? 0.
analyzing individual models one at a time. In doing so, we have obtained several new mathematical results delineating the functional limits of memory achievable by synaptic complexity, and the
structural characterization of synaptic dynamical systems that achieve these limits. In particular,
operating within the ideal observer framework of [10, 11, 18], we have shown that for a population
?
of N synapses with M internal states, (a) the initial SNR of any synaptic model cannot exceed N ,
and any model that achieves this bound is equivalent to a binary synapse, (b) the area under the
memory curve of any model cannot exceed that of a linear chain model with the same
? equilibrium
distribution, (c) both the area and memory lifetime of any model cannot exceed O( N M ), and the
model that achieves this limit has a linear chain topology with only nearest neighbor transitions, (d)
we have derived an envelope memory curve in the SNR-time plane that cannot be exceeded by the
memory curve of any model, and models that approach this envelope for times greater ?
than O( M
r )
are linear chain models, and (e) this late-time envelope is a power-law proportional to O( N M /rt),
indicating that synaptic complexity can strongly enhance the limits of achievable memory.
This theoretical study opens up several avenues for further inquiry. In particular, the tightness of our
envelope for early times, less than O( M
r ), remains an open question, and we are currently pursuing
several conjectures. We have also derived memory constrained envelopes, by asking in the space
of models that achieve a given SNR at a given time, what is the maximal SNR achievable at other
times. If these two times are beyond a threshold separation, optimal constrained models require
two exponentials. It would be interesting to systematically analyze the space of models that achieve
good memory at multiple times, and understand their structural organization, and how they give rise
to multiple exponentials, leading to power law memory decays.
Finally, it would be interesting to design physiological experiments in order to perform optimal
systems identification of potential Markovian dynamical systems hiding within biological synapses,
given measurements of pre and post-synaptic spike trains along with changes in post-synaptic potentials. Then given our theory, we could match this measured synaptic model to optimal models to
understand for which timescales of memory, if any, biological synaptic dynamics may be tuned.
In summary, we hope that a deeper theoretical understanding of the functional role of synaptic
complexity, initiated here, will help advance our understanding of the neurobiology of learning and
memory, aid in the design of engineered memory circuits, and lead to new mathematical theorems
about stochastic processes.
Acknowledgements
We thank Sloan, Genenetech, Burroughs-Wellcome, and Swartz foundations for support. We thank
Larry Abbott, Marcus Benna, Stefano Fusi, Jascha Sohl-Dickstein and David Sussillo for useful
discussions.
8

References
[1] J. J. Hopfield, ?Neural networks and physical systems with emergent collective computational
abilities,? Proc. Natl. Acad. Sci. U.S.A. 79 (1982) no. 8, 2554?2558.
[2] D. J. Amit, H. Gutfreund, and H. Sompolinsky, ?Spin-glass models of neural networks,? Phys.
Rev. A 32 (Aug, 1985) 1007?1018.
[3] E. Gardner, ?The space of interactions in neural network models,? Journal of Physics A:
Mathematical and General 21 (1988) no. 1, 257.
[4] T. V. P. Bliss and G. L. Collingridge, ?A synaptic model of memory: long-term potentiation in
the hippocampus,? Nature 361 (Jan, 1993) 31?39.
[5] C. C. H. Petersen, R. C. Malenka, R. A. Nicoll, and J. J. Hopfield, ?All-or-none potentiation at
CA3-CA1 synapses,? Proc. Natl. Acad. Sci. U.S.A. 95 (1998) no. 8, 4732?4737.
[6] D. H. O?Connor, G. M. Wittenberg, and S. S.-H. Wang, ?Graded bidirectional synaptic
plasticity is composed of switch-like unitary events,? Proc. Natl. Acad. Sci. U.S.A. 102 (2005)
no. 27, 9679?9684.
[7] R. Enoki, Y. ling Hu, D. Hamilton, and A. Fine, ?Expression of Long-Term Plasticity at
Individual Synapses in Hippocampus Is Graded, Bidirectional, and Mainly Presynaptic:
Optical Quantal Analysis,? Neuron 62 (2009) no. 2, 242 ? 253.
[8] D. J. Amit and S. Fusi, ?Constraints on learning in dynamic synapses,? Network:
Computation in Neural Systems 3 (1992) no. 4, 443?464.
[9] D. J. Amit and S. Fusi, ?Learning in neural networks with material synapses,? Neural
Computation 6 (1994) no. 5, 957?982.
[10] S. Fusi, P. J. Drew, and L. F. Abbott, ?Cascade models of synaptically stored memories,?
Neuron 45 (Feb, 2005) 599?611.
[11] S. Fusi and L. F. Abbott, ?Limits on the memory storage capacity of bounded synapses,? Nat.
Neurosci. 10 (Apr, 2007) 485?493.
[12] C. Leibold and R. Kempter, ?Sparseness Constrains the Prolongation of Memory Lifetime via
Synaptic Metaplasticity,? Cerebral Cortex 18 (2008) no. 1, 67?77.
[13] D. S. Bredt and R. A. Nicoll, ?AMPA Receptor Trafficking at Excitatory Synapses,? Neuron
40 (2003) no. 2, 361 ? 379.
[14] M. P. Coba, A. J. Pocklington, M. O. Collins, M. V. Kopanitsa, R. T. Uren, S. Swamy, M. D.
Croning, J. S. Choudhary, and S. G. Grant, ?Neurotransmitters drive combinatorial multistate
postsynaptic density networks,? Sci Signal 2 (2009) no. 68, ra19.
[15] W. C. Abraham and M. F. Bear, ?Metaplasticity: the plasticity of synaptic plasticity,? Trends
in Neurosciences 19 (1996) no. 4, 126 ? 130.
[16] J. M. Montgomery and D. V. Madison, ?State-Dependent Heterogeneity in Synaptic
Depression between Pyramidal Cell Pairs,? Neuron 33 (2002) no. 5, 765 ? 777.
[17] R. D. Emes and S. G. Grant, ?Evolution of Synapse Complexity and Diversity,? Annual
Review of Neuroscience 35 (2012) no. 1, 111?131.
[18] A. B. Barrett and M. C. van Rossum, ?Optimal learning rules for discrete synapses,? PLoS
Comput. Biol. 4 (Nov, 2008) e1000230.
[19] J. Kemeny and J. Snell, Finite markov chains. Springer, 1960.
[20] C. Burke and M. Rosenblatt, ?A Markovian function of a Markov chain,? The Annals of
Mathematical Statistics 29 (1958) no. 4, 1112?1122.
[21] F. Ball and G. F. Yeo, ?Lumpability and Marginalisability for Continuous-Time Markov
Chains,? Journal of Applied Probability 30 (1993) no. 3, 518?528.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 2765-representing-part-whole-relationships-in-recurrent-neural-networks.pdf

Representing Part-Whole Relationships in
Recurrent Neural Networks
Viren Jain2 , Valentin Zhigulin1,2 , and H. Sebastian Seung1,2
1
Howard Hughes Medical Institute and
2
Brain & Cog. Sci. Dept., MIT
viren@mit.edu, valentin@mit.edu, seung@mit.edu

Abstract
There is little consensus about the computational function of top-down
synaptic connections in the visual system. Here we explore the hypothesis that top-down connections, like bottom-up connections, reflect partwhole relationships. We analyze a recurrent network with bidirectional
synaptic interactions between a layer of neurons representing parts and a
layer of neurons representing wholes. Within each layer, there is lateral
inhibition. When the network detects a whole, it can rigorously enforce
part-whole relationships by ignoring parts that do not belong. The network can complete the whole by filling in missing parts. The network
can refuse to recognize a whole, if the activated parts do not conform to
a stored part-whole relationship. Parameter regimes in which these behaviors happen are identified using the theory of permitted and forbidden
sets [3, 4]. The network behaviors are illustrated by recreating Rumelhart
and McClelland?s ?interactive activation? model [7].
In neural network models of visual object recognition [2, 6, 8], patterns of synaptic connectivity often reflect part-whole relationships between the features that are represented
by neurons. For example, the connections of Figure 1 reflect the fact that feature B both
contains simpler features A1, A2, and A3, and is contained in more complex features C1,
C2, and C3. Such connectivity allows neurons to follow the rule that existence of the part
is evidence for existence of the whole. By combining synaptic input from multiple sources
of evidence for a feature, a neuron can ?decide? whether that feature is present. 1
The synapses shown in Figure 1 are purely bottom-up, directed from simple to complex
features. However, there are also top-down connections in the visual system, and there
is little consensus about their function. One possibility is that top-down connections also
reflect part-whole relationships. They allow feature detectors to make decisions using the
rule that existence of the whole is evidence for existence of its parts.
In this paper, we analyze the dynamics of a recurrent network in which part-whole relationships are stored as bidirectional synaptic interactions, rather than the unidirectional
interactions of Figure 1. The network has a number of interesting computational capabilities. When the network detects a whole, it can rigorously enforce part-whole relationships
1

Synaptic connectivity may reflect other relationships besides part-whole. For example, invariances can be implemented by connecting detectors of several instances of the same feature to the
same target, which is consequently an invariant detector of the feature.

C1

C2

C3

B
A1

A2

A3

Figure 1: The synaptic connections (arrows)
of neuron B represent part-whole relationships. Feature B both contains simpler features and is contained in more complex features. The synaptic interactions are drawn
one-way, as in most models of visual object
recognition. Existence of the part is regarded
as evidence for existence of the whole. This
paper makes the interactions bidirectional, allowing the existence of the whole to be evidence for the existence of its parts.

by ignoring parts that do not belong. The network can complete the whole by filling in
missing parts. The network can refuse to recognize a whole, if the activated parts do not
conform to a stored part-whole relationship. Parameter regimes in which these behaviors
happen are identified using the recently developed theory of permitted and forbidden sets
[3, 4].
Our model is closely related to the interactive activation model of word recognition, which
was proposed by McClelland and Rumelhart to explain the word superiority effect studied
by visual psychologists [7]. Here our concern is not to model a psychological effect, but to
characterize mathematically how computations involving part-whole relationships can be
carried out by a recurrent network.

1

Network model

Suppose that we are given a set of part-whole relationships specified by

1, if part i is contained in whole a
a
?i =
0, otherwise
We assume that every whole contains at least one part, and every part is contained in at
least one whole.
The stimulus drives a layer of neurons that detect parts. These neurons also interact with
a layer of neurons that detect wholes. We will refer to part-detectors as ?P-neurons? and
whole-detectors as ?W-neurons.?
The part-whole relationships are directly stored in the synaptic connections between P and
W neurons. If ?ia = 1, the ith neuron in the P layer and the ath neuron in the W layer have
an excitatory interaction of strength ?. If ?ia = 0, the neurons have an inhibitory interaction
of strength ?. Furthermore, the P-neurons inhibit each other with strength ?, and the Wneurons inhibit each other with strength ?. All of these interactions are symmetric, and all
activation functions are the rectification nonlinearity [z]+ = max{z, 0}.
Then the dynamics of the network takes the form
?
?+
X
X
X
W? a + Wa = ??
Pi ?ia ? ?
(1 ? ?ia )Pi ? ?
Wb ? ,
i

i

?+

?
P?i + Pi

= ??

(1)

b6=a

X
a

Wa ?ia ? ?

X
a

(1 ? ?ia )Wa ? ?

X
j6=i

Pj + B i ? .

(2)

where Bi is the input to the P layer from the stimulus. Figure 2 shows an example of a
network with two wholes. Each whole contains two parts. One of the parts is contained in
both wholes.
-?

Wa

excitation ?

-?

inhibition
P1

B1

-?

} W layer

Wb
-?

P2

-?

B2

P3

} P layer

B3

Figure 2: Model in example configuration: ? = {(1, 1, 0), (0, 1, 1)}.
When a stimulus is presented, it activates some of the P-neurons, which activate some of
the W-neurons. The network eventually converges to a stable steady state. We will assume
that ? > 1. In the Appendix, we prove that this leads to unconditional winner-take-all
behavior in the W layer. In other words, no more than one W-neuron can be active at a
stable steady state.
If a single W-neuron is active, then a whole has been detected. Potentially there are also
many P-neurons active, indicating detection of parts. This representation may have different properties, depending on the choice of parameters ?, ?, and ?. As discussed below,
these include rigorous enforcement of part-whole relationships, completion of wholes by
?filling in? missing parts, and non-recognition of parts that do not conform to a whole.

2

Enforcement of part-whole relationships

Suppose that a single W-neuron is active at a stable steady state, so that a whole has been
detected. Part-whole relationships are said to be enforced if the network always ignores
parts that are not contained in the detected whole, despite potentially strong bottom-up
evidence for them. It can be shown that enforcement follows from the inequality
? 2 + ? 2 + ? 2 + 2??? > 1.
(3)
which guarantees that neuron i in the P layer is inactive, if neuron a in the W layer is
active and ?ia = 0. When part-whole relations are enforced, prior knowledge about legal
combinations of parts strictly constrains what may be perceived. This result is proven in
the Appendix, and only an intuitive explanation is given here.
Enforcement is easiest to understand when there is interlayer inhibition (? > 0). In this
case, the active W-neuron directly inhibits the forbidden P-neurons. The case of ? = 0 is
more subtle. Then enforcement is mediated by lateral inhibition in the P layer. Excitatory
feedback from the W-neuron has the effect of counteracting the lateral inhibition between
the P-neurons that belong to the whole. As a result, these P-neurons become strongly
activated enough to inhibit the rest of the P layer.

3

Completion of wholes by filling in missing parts

If a W-neuron is active, it excites the P-neurons that belong to the whole. As a result, even
if one of these P-neurons receives no bottom-up input (Bi = 0), it is still active. We call

this phenomenon ?completion,? and it is guaranteed to happen when
p
(4)
?> ?
The network may thus ?imagine? parts that are consistent with the recognized whole, but
are not actually present in the stimulus. As with enforcement, this condition depends on
top-down connections.
?
In the special case ? = ?, the interlayer excitation between a W-neuron and its P-neurons
exactly cancels out the lateral inhibition between the P-neurons at a steady state. So the recurrent connections effectively vanish, letting the activity of the P-neurons be determined
by their feedforward inputs. When the interlayer excitation is stronger than this, the inequality (4) holds, and completion occurs.

4

Non-recognition of a whole

If there is no interlayer inhibition (? = 0), then a single W-neuron is always active, assuming that there is some activity in the P layer. To see this, suppose for the sake of contradiction that all the W-neurons are inactive. Then they receive no inhibition to counteract the
excitation from the P layer. This means some of them must be active, which contradicts our
assumption. This means that the network always recognizes a whole, even if the stimulus
is very different from any part-whole combination that is stored in the network.
However, if interlayer inhibition is sufficiently strong (large ?), the network may refuse
to recognize a whole. Neurons in the P layer are activated, but there is no activity in the
W layer. Formal conditions on ? can be derived, but are not given here because of space
limitations.
In case of non-recognition, constraints on the P-layer are not enforced. It is possible for the
network to detect a configuration of parts that is not consistent with any stored whole.

5

Example: Interactive Activation model

To illustrate the computational capabilities of our network, we use it to recreate the interactive activation (IA) model of McClelland and Rumelhart. Figure 3 shows numerical
simulations of a network containing three layers of neurons representing strokes, letters,
and words, respectively. There are 16 possible strokes in each of four letter positions. For
each stroke, there are two neurons, one signaling the presence of the stroke and the other
signaling its absence. Letter neurons represent each letter of the alphabet in each of four
positions. Word neurons represent each of 1200 common four letter words.
The letter and word layers correspond to the P and W layers that were introduced previously. There are bidirectional interactions between the letter and word layers, and lateral
inhibition within the layers. The letter neurons also receive input from the stroke neurons,
but this interaction is unidirectional.
Our network differs in two ways from the original IA model. First, all interactions involving
letter and word neurons are symmetric. In the original model, the interactions between the
letter and word layers were asymmetric. In particular, inhibitory connections only ran from
letter neurons to word neurons, and not vice versa. Second, the only nonlinearity in our
model is rectification. These two aspects allow us to apply the full machinery of the theory
of permitted and forbidden sets.
Figure 3 shows the result of presenting the stimulus ?MO M? for four different settings
of parameters. In each of the four cases, the word layer of the network converges to the
same result, detecting the word ?MOON?, which is the closest stored word to the stimulus.
However, the activity in the letter layer is different in the four cases.

input:

P layer

reconstruction

W layer

P layer

reconstruction

W layer

completion

noncompletion

enforcement

non-enforcement

Figure 3: Simulation of 4 different parameter regimes in a letter- word recognition network. Within
each panel, the middle column presents a feature- layer reconstruction based on the letter activity
shown in the left column. W layer activity is shown in the right column. The top row shows the
network state after 10 iterations of the dynamics. The bottom row shows the steady state.

In the left column, the parameters obey the inequality (3), so that part- whole relationships
are enforced. The activity of the letter layer is visualized by activating the strokes corresponding to each active letter neuron. The activated letters are part of the word ?MOON?.
In the top left, the inequality (4) is satisfied, so that the missing ?O? in the stimulus is filled
in. In the bottom left, completion does not occur.
In the simulations of the right column, parameters are such that part- whole relationships are
not enforced. Consequently, the word layer is
much more active. Bottom- up input provides
evidence for several other letters, which is not
suppressed. In the top right, the inequality (4) is
satisfied, so that the missing ?O? in the stimulus
is filled in. In the bottom right, the ?O? neuron
is not activated in the third position, so there is
no completion. However, some letter neurons
for the third position are activated, due to the
input from neurons that indicate the absence of
strokes.

input:

non-recognition event

multi-stability

Figure 4: Simulation of a non- recognition
event and example of multistability.

Figure 4 shows simulations for large ?, deep in
the enforcement regime where non- recognition is a possibility. From one initial condition,
the network converges to a state in which no W neurons are active, a non- recognition. From
another initial condition, the network detects the word ?NORM?. Deep in the enforcement
regime, the top- down feedback can be so strong that the network has multiple stable states,
many of which bear little resemblance to the stimulus at all. This is a problematic aspect
of this network. It can be prevented by setting parameters at the edge of the enforcement
regime.

6

Discussion

We have analyzed a recurrent network that performs computations involving part- whole
relationships. The network can fill in missing parts and suppress parts that do not belong.

These two computations are distinct and can be dissociated from each other, as shown in
Figure 3.
While these two computations can also be performed by associative memory models, they
are not typically dissociable in these models. For example, in the Hopfield model pattern
completion and noise suppression are both the result of recall of one of a finite number of
stereotyped activity patterns.
We believe that our model is more appropriate for perceptual systems, because its behavior
is piecewise linear, due its reliance on rectification nonlinearity. Therefore, analog aspects
of computation are able to coexist with the part-whole relationships. Furthermore, in our
model the stimulus is encoded in maintained synaptic input to the network, rather than as
an initial condition of the dynamics.

A

Appendix: Permitted and forbidden sets

Our mathematical results depend on the theory of permitted and forbidden sets [3, 4], which
is summarized briefly here. The theory isP
applicable to neural networks with rectification
nonlinearity, of the form x? i + xi = [bi + j Wij xj ]+ . Neuron i is said to be active when
xi > 0. For a network of N neurons, there are 2N possible sets of active neurons. For each
active set, consider the submatrix of Wij corresponding to the synapses between active
neurons. If all eigenvalues of this submatrix have real parts less than or equal to unity, then
the active set is said to be permitted. Otherwise the active set is said to be forbidden. A set
is permitted if and only if there exists an input vector b such that those neurons are active
at a stable steady state. Permitted sets can be regarded as memories stored in the synaptic
connections Wij . If Wij is a symmetric matrix, the nesting property holds: every subset of
a permitted set is permitted, and every superset of a forbidden set is forbidden.
The present model can be seen as a general method for storing permitted sets in a recurrent
network. This method introduces a neuron for each permitted set, relying on a unary or
?grandmother cell? representation. In contrast, Xie et al.[9] used lateral inhibition in a
single layer of neurons to store permitted sets. By introducing extra neurons, the present
model achieves superior storage capacity, much as unary models of associative memory [1]
surpass distributed models [5].
A.1

Unconditional winner-take-all in the W layer

The synapses between two W-neurons have strengths


0 ??
?? 0
The eigenvalues of this matrix are ??. Therefore two W-neurons constitute a forbidden set
if ? > 1. By the nesting property, it follows more than two W-neurons is also a forbidden
set, and that the W layer has the unconditional winner-take-all property.
A.2

Part-whole combinations as permitted sets

Theorem 1. Suppose that ? < 1. If ? 2 < ? + (1 ? ?)/k then any combination of k ? 1
parts consistent with a whole corresponds to a permitted set.
Proof. Consider k parts belonging to a whole. They are represented by one W-neuron and
k P-neurons, with synaptic connections given by the (k + 1) ? (k + 1) matrix


??(11T ? I) ?1
M=
,
(5)
?1T
0

where 1 is the k- dimensional vector whose elements are all equal to one. Two eigenvectors
of M are of the form (1T c), and have the same eigenvalues as the 2 ? 2 matrix


??(k ? 1) ?
?k
0
This matrix has eigenvalues less than one when ? 2 < ? + (1 ? ?)/k and ?(k ? 1) + 2 >
0. The other k ? 1 eigenvectors are of the form (dT , 0), where dT 1 = 0. These have
eigenvalues ?. Therefore all eigenvalues of W are less than one if the condition of the
theorem is satisfied.
A.3

Constraints on combining parts

Here, we derive conditions under which the network can enforce the constraint that steady state activity be confined to
parts that constitute a whole.
Theorem 2. Suppose that ? > 0 and ? 2 +? 2 +? 2 +2??? > 1
If a W- neuron is active, then only P- neurons corresponding to
parts contained in the relevant whole can be active at a stable
steady state.
Proof. Consider P- neurons Pi , Pj , and W- neuron Wa . Suppose that ?ia = 1 but ?ja = 0. As shown in Figure 5, the matrix
of connections is given by:
!
0 ?? ?
W = ?? 0 ??
(6)
? ?? 0

Wa
?

Pi

-?
-?

Pj

Figure 5: A set of
one W- neuron and two
P- neurons is forbidden
if one part belongs to
the whole and the other
does not.

This set is permitted if all eigenvalues of W ? I have negative
real parts. The characteristic equation of I ? W is ?3 + b1 ?2 +
b2 ? + b3 = 0, where b1 = 3, b2 = 3 ? ? 2 ? ? 2 ? ? 2 and
b3 = 1?2????? 2 ?? 2 ?? 2 . According to the Routh- Hurwitz theorem, all the eigenvalues
have negative real parts if and only if b1 > 0, b3 > 0 and b1 b2 > b3 . Clearly, the first
condition is always satisfied. The second condition is more restrictive than the third. It is
satisfied only when ? 2 + ? 2 + ? 2 + 2??? < 1. Hence, one of the eigenvalues has a positive
real part when this condition is broken, i.e., when ? 2 +? 2 +? 2 +2??? > 1. By the nesting
property, any larger set of P- neurons inconsistent with the W- neuron is also forbidden.
A.4

Completion of wholes
?
Theorem 3. If ? > ? and a single W- neuron a is active at a steady state, then Pi > 0
for all i such that ?ia = 1.
Proof. Suppose that the detected whole has k parts. At the steady state
Pi =

+
?ia 
Bi ? (? ? ? 2 )Ptot
1??

where
Ptot =

X
i

Pi =

k
X
1
Bi ?ia
1 ? ? + (? ? ? 2 )k i=1

(7)

A.5

Preventing runaway

If feedback loops cause the network activity to diverge, then the preceding analyses are not
relevant. Here we give a sufficient condition guaranteeing that runaway instability does not
happen. It is not a necessary condition. Interestingly, the condition implies the condition
of Theorem 1.
Theorem 4. Suppose that P and W obey the dynamics of Eqs. (1) and (2), and define the
objective function
!2
!2
1?? X 2 ? X
1?? X 2 ? X
E =
Wa +
Wa
+
Pi +
Pi
2
2
2
2
a
a
i
i
X
X
X
?
Bi Pi ? ?
Pi Wa ?ia + ?
(1 ? ?ia )Pi Wa .
(8)
i

ia

ia

Then E is a Lyapunov like function that, given ? > ? 2 ?
dynamics to a stable steady state.

1?? 2
N ?1 ,

ensures convergence of the

Proof. (sketch) Differentiation of E with respect to time shows that that E is nonincreasing
in the nonnegative orthant and constant only at steady states of the network dynamics. We
must also show that E is radially unbounded, which is true if the quadratic part of E is
copositive definite. Note thatP
the last term of E is lower-bounded by zero and the previous
term is upper bounded by ? ia Pi Wa . We assume ? > 1. Thus, we can use Cauchy?s
P
P
P
P
2
inequality, i Pi2 ? ( i Pi ) /N , and the fact that a Wa2 ? ( a Wa )2 for Wa ? 0, to
derive
!
X
X
X
X
1 X
1
?
?
+
?N
E?
(
(
Pi )2 ? 2?(
Wa )2 +
Wa
Pi ) ?
Bi Pi . (9)
2
N
a
a
i
i
i
If ? > ? 2 ?
unbounded.

1?? 2
N ?1 ,

the quadratic form in the inequality is positive definite and E is radially

References
[1] E. B. Baum, J. Moody, and F. Wilczek. Internal representations for associative memory. Biol.
Cybern., 59:217?228, 1988.
[2] K. Fukushima. Neocognitron: a self organizing neural network model for a mechanism of pattern
recognition unaffected by shift in position. Biol Cybern, 36(4):193?202, 1980.
[3] R.H. Hahnloser, R. Sarpeshkar, M.A. Mahowald, R.J. Douglas, and H.S. Seung. Digital selection
and analogue amplification coexist in a cortex-inspired silicon circuit. Nature, 405(6789):947?
51, Jun 22 2000.
[4] R.H. Hahnloser, H.S. Seung, and J.-J. Slotine. Permitted and forbidden sets in symmetric
threshold-linear networks. Neural Computation, 15:621?638, 2003.
[5] J.J. Hopfield. Neural networks and physical systems with emergent collective computational
abilities. Proc Natl Acad Sci U S A, 79(8):2554?8, Apr 1982.
[6] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel.
Backpropagation applied to handwritten zip code recognition. Neural Comput., 1:541?551, 1989.
[7] J. L. McClelland and D. E. Rumelhart. An interactive activation model of context effects in letter
perception: Part i. an account of basic findings. Psychological Review, 88(5):375?407, Sep 1981.
[8] M Riesenhuber and T Poggio. Hierarchical models of object recognition in cortex. Nat Neurosci,
2(11):1019?25, Nov 1999.
[9] X. Xie, R.H. Hahnloser, and H. S. Seung. Selectively grouping neurons in recurrent networks of
lateral inhibition. Neural Computation, 14:2627?2646, 2002.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 2331-neuromorphic-bisable-vlsi-synapses-with-spike-timing-dependent-plasticity.pdf

Neuromorphic Bistable VLSI Synapses with
Spike-Timing-Dependent Plasticity

Giacomo Indiveri
Institute of Neuroinformatics
University/ETH Zurich
CH-8057 Zurich, Switzerland
giacomo@ini.phys.ethz.ch

Abstract
We present analog neuromorphic circuits for implementing bistable synapses with spike-timing-dependent plasticity (STDP) properties. In these
types of synapses, the short-term dynamics of the synaptic efficacies are
governed by the relative timing of the pre- and post-synaptic spikes,
while on long time scales the efficacies tend asymptotically to either a
potentiated state or to a depressed one. We fabricated a prototype VLSI
chip containing a network of integrate and fire neurons interconnected
via bistable STDP synapses. Test results from this chip demonstrate the
synapse?s STDP learning properties, and its long-term bistable characteristics.

1 Introduction
Most artificial neural network algorithms based on Hebbian learning use correlations of
mean rate signals to increase the synaptic efficacies between connected neurons. To prevent uncontrolled growth of synaptic efficacies, these algorithms usually incorporate also
weight normalization constraints, that are often not biophysically realistic. Recently an
alternative class of competitive Hebbian learning algorithms has been proposed based on a
spike-timing-dependent plasticity (STDP) mechanism [1]. It has been argued that the STDP
mechanism can automatically, and in a biologically plausible way, balance the strengths of
synaptic efficacies, thus preserving the benefits of both weight normalization and correlation based learning rules [16]. In STDP the precise timing of spikes generated by the
neurons play an important role. If a pre-synaptic spike arrives at the synaptic terminal before a post-synaptic spike is emitted, within a critical time window, the synaptic efficacy
is increased. Conversely if the post-synaptic spike is emitted soon before the pre-synaptic
one arrives, the synaptic efficacy is decreased.
While mean rate Hebbian learning algorithms are difficult to implement using analog circuits, spike-based learning rules map directly onto VLSI [4, 6, 7]. In this paper we present
compact analog circuits that, combined with neuromorphic integrate and fire (I&F) neurons
and synaptic circuits with realistic dynamics [8, 12, 11] implement STDP learning for short
time scales and asymptotically tend to one of two possible states on long time scales. The
circuits required to implement STDP, are described in Section 2. The circuits that implement bistability are described in Section 3. The network of I&F neurons used to measure

the properties of the bistable STDP synapse is described in Section 4.
Long term storage of synaptic efficacies
The circuits that drive the synaptic efficacy to one of two possible states on long time scales,
were implemented in order to cope with the problem of long term storage of analog values
in CMOS technology. Conventional VLSI capacitors, the devices typically used as memory
elements, are not ideal, in that they slowly loose the charge they are supposed to store, due
to leakage currents. Several solutions have been proposed for long term storage of synaptic
efficacies in analog VLSI neural networks. One of the first suggestions was to use the same
method used for dynamic RAM: to periodically refresh the stored value. This involves
though discretization of the analog value to N discrete levels, a method for comparing the
measured voltage to the N levels, and a clocked circuit to periodically refresh the value
on the capacitor. An alternative solution is to use analog-to-digital (ADC) converters, an
off chip RAM and digital-to-analog converters (DAC), but this approach requires, next
to a discretization of the value to N states, bulky ADC and DAC circuits. A more recent
suggestion is the one of using floating gate devices [5]. These devices can store very precise
analog values for an indefinite amount of time using standard CMOS technology [13], but
for spike-based learning rules they would require a control circuit (and thus large area) per
synapse. To implement dense arrays of neurons with large numbers of dendritic inputs the
synaptic circuits should be as compact as possible.
Bistable synapses
An alternative approach that uses a very small amount of area per synapse is to use bistable
synapses. These types of synapses contain minimum feature-size circuits that locally compare the value of the synaptic efficacy stored on the capacitor with a fixed threshold voltage
and slowly drive that value either toward a high analog voltage or toward a low one, depending on the output of the comparator (see Section 3).
The assumption that on long time scales the synaptic efficacy can only assume two values
is not too severe, for networks of neurons with large numbers of synapses. It has been
argued that also biological synapses can be indeed discrete on long time-scales. These
assumptions are compatible with experimental data [3] and are supported by experimental
evidence [15]. Also from a theoretical perspective it has been shown that the performance
of associative networks is not necessarily degraded if the dynamic range of the synaptic
efficacy is reduced even to the extreme (two stable states), provided that the transitions
between stable states are stochastic [2].
Related work
Bistable VLSI synapses in networks of I&F neurons have already been proposed in [6], but
in those circuits, the synaptic efficacy is always clamped to either a high value or a low one,
also for short-term dynamics, as opposed to our case, in which the synaptic efficacy can
assume any analog value between the two. In [7] the authors propose a spike-based learning circuit, based on a modified version of Riccati?s equation [10], in which the synaptic
efficacy is a continuous analog voltage; but their synapses require many more transistors
than the solution we propose, and do not incorporate long-term bistability. More recently
Bofill and Murray proposed circuits for implementing STDP within a framework of pulsebased neural network circuits [4]. But, next to missing the long-term bistability properties,
their synaptic circuits require digital control signals that cannot be easily generated within
the framework of neuromorphic networks of I&F neurons [8, 12].

Vdd

Vdd

M3

M4

Vtp

M2

Vdd
M10

M5

/post

Vpot
Ipot

Vw0

Vd

M6

M7

Vp
Cw

Idep
Vdep

pre

M11

M8

M1

M12

M9

Vtd

Figure 1: Synaptic efficacy STDP circuit.

2 The STDP circuits
The circuit required to implement STDP in a network of I&F neurons is shown in Fig. 1.
This circuit increases or decreases the analog voltage Vw0 , depending on the relative timing
of the pulses pre and /post. The voltage Vw0 is then used to set the strength of synaptic
circuits with realistic dynamics, of the type described in [11]. The pre- and post-synaptic
pulses pre and /post are generated by compact, low power I&F neurons, of the type described in [9].
The circuit of Fig. 1 is fully symmetric: upon the arrival of a pre-synaptic pulse pre a
waveform Vpot (t) (for potentiating Vw0 ) is generated. Similarly, upon the arrival of a
post-synaptic pulse /post, a complementary waveform Vdep (t) (for depotentiating Vw0 )
is generated. Both waveforms have a sharp onset and decay linearly with time, at a rate set
respectively by Vtp and Vtd . The pre- and post-synaptic pulses are also used to switch on
two gates (M 8 and M 5), that allow the currents Idep and Ipot to flow, as long as the pulses
are high, either increasing or decreasing the weight. The bias voltages V p on transistor M 6
and Vd on M 7 set an upper bound for the maximum amount of current that can be injected
into or removed from the capacitor Cw . If transistors M 4?M 9 operate in the subthreshold
regime [13], we can compute the analytical expression of Ipot (t) and Idep (t):
Ipot (t) =
Idep (t) =

e

I0
? U? Vpot (t?tpre )
T

+e

? U? Vp

(1)

T

I0
? U? Vdep (t?tpost )

(2)
? ? V
e T
+ e UT d
where tpre and tpost are the times at which the pre-synaptic and post-synaptic spikes are
emitted, UT is the thermal voltage, and ? is the subthreshold slope factor [13]. The change
in synaptic efficacy is then:
(
I
(t
)
?Vw0 = potCppost ?tspk
if tpre < tpost
(3)
Idep (tpre )
?Vw0 = ? Cd ?tspk if tpost < tpre
where ?tspk is the pre- and post-synaptic spike width, Cp is the parasitic capacitance of
node Vpot and Cd the one of node Vdep (not shown in Fig. 1).
In Fig. 2(a) we plot experimental data showing how ?Vw0 changes as a function of ?t =
tpre ? tpost for different values of Vtd and Vtp . Similarly, in Fig. 2(b) we show plots

w0

0

?0.5

?V

?V

w0

(V)

0.5

(V)

0.5

?10

?5

0
? t (ms)

5

0

?0.5

10

?10

?5

(a)

0
? t (ms)

5

10

(b)

Figure 2: Changes in synaptic efficacy, as a function of the difference between pre- and
post-synaptic spike emission times ?t = tpre ?tpost . (a) Curves obtained for four different
values of Vpot (in the left quadrant) and four different values of Vdep (in the right quadrant).
(b) Typical STDP plot, obtained by setting Vp to 4.0V and Vd to 0.6V.
Vw0 (V)

1.5

0
0
5

2

3

4

5

0
0
5

1

2

3

4

5

0
0

1

2

3
Time (ms)

4

5

pre (V)

V

dep

(V)

1

Figure 3: Changes in Vw0 , in response to a sequence of pre-synaptic spikes (top trace). The
middle trace shows how the signal Vdep , triggered by the post-synaptic neuron, decreases
linearly with time. The bottom trace shows the series of digital pulses pre, generated with
every pre-synaptic spike.
of ?Vw0 versus ?t for three different values of Vp and three different values of Vd . As
there are four independent control biases, it is possible to set the maximum amplitude and
temporal window of influence independently for positive and negative changes in V w0 .
The data of Fig. 2 was obtained using a paired-pulse protocol similar to the one used in
physiological experiments [14]: one single pair of pre- and post-synaptic spikes was used
to measure each ?Vw0 data point, by systematically changing the delay tpre ? tpost and
by separating each stimulation session by a few hundreds of milliseconds (to allow the
signals to return to their resting steady-state). Unlike the biological experiments, in our
VLSI setup it is possible to evaluate the effect of multiple pulses on the synaptic efficacy,
for very long successive stimulation sessions, monitoring all the internal state variables
and signals involved in the process. In Fig. 3 we show the effect of multiple pre-synaptic
spikes, succeeding a post-synaptic one, plotting a trace of the voltage V w0 , together with the

Vhigh
M3

Vw0

?

Vthr

+

M4

M5

Vw0
M6

Vleak

M1

M2

Vlow

Figure 4: Bistability circuit. Depending on Vw0 ? Vthr , the comparator drives Vw0 to either
Vhigh or Vlow . The rate at which the circuit drives Vw0 toward the asymptote is controlled
by Vleak and imposed by transistors M 2 and M 4.
?internal? signal Vdep , generated by the post-synaptic spike, and the pulses pre, generated
by the per-synaptic neuron. Note how the change in Vw0 is a positive one, when the postsynaptic spike follows a pre-synaptic one, at t = 0.5ms, and is negative when a series
of pre-synaptic spikes follows the post-synaptic one. The effect of subsequent pre pulses
following the first post-/pre-synaptic pair is additive, and decreases with time as in Fig. 2.
As expected, the anti-causal relationship between pre- and post-synaptic neurons has the
net effect of decreasing the synaptic efficacy.

3 The bistability circuit
The bistability circuit, shown in Fig. 4, drives the voltage Vw0 toward one of two possible
states: Vhigh (if Vw0 > Vthr ), or Vlow (if Vw0 < Vthr ). The signal Vthr is a threshold
voltage that can be set externally. The circuit comprises a comparator, and a mixed-mode
analog-digital leakage circuit. The comparator is a five transistor transconductance amplifier [13] that can be designed using minimum feature-size transistors. The leakage circuit
contains two gates that act as digital switches (M 5, M 6) and four transistors that set the
two stable state asymptotes Vhigh and Vlow and that, together with the bias voltage Vleak ,
determine the rate at which Vw0 approaches the asymptotes. The bistability circuit drives
Vw0 in two different ways, depending on how large is the distance between the value of V w0
itself and the asymptote. If |Vw0 ?Vas | > 4UT the bistability circuit drives Vw0 toward Vas
linearly, where Vas represents either Vlow or Vhigh , depending on the sign of (Vw0 ? Vthr ):
(
leak
t if Vw0 > Vthr
Vw0 (t) = Vw0 (0) + IC
w
(4)
Ileak
Vw0 (t) = Vw0 (0) ? Cw t if Vw0 < Vthr
where Cw is the capacitor of Fig. 1 and
Ileak = I0 e

?Vleak ?Vlow
UT

As Vw0 gets close to the asymptote and |Vw0 ?Vas | < 4UT , transistors M 2 or M 4 of Fig. 4
go out of saturation and Vw0 begins to approach the asymptote exponentially:
(
I
? leak t
Vw0 (t) = Vhigh ? Vw0 (0)e Cw UT
if Vw0 > Vthr
(5)
Ileak
? Cw
t
UT
Vw0 (t) = Vlow + Vw0 (0)e
if Vw0 < Vthr
On long time scales the dynamics of Vw0 are governed by the bistability circuit, while on
short time-scales they are governed by the STDP circuits and the precise timing of pre- and

3

2

V

w0

(V)

2.5

1.5

1
0

2

4

6
Time (ms)

8

10

Figure 5: Synaptic efficacy bistability. Transition of Vw0 from below threshold to above
threshold (Vthr = 1.52V ), with leakage rate set by Vleak = 0.25V and pre- and postsynaptic neurons stimulated in a way to increase Vw0 .
I1

I2

M1

O1

M2

O2

Figure 6: Network of leaky I&F neurons with bistable STDP excitatory synapses and inhibitory synapses. The large circles symbolize I&F neurons, the small empty ones bistable
STDP excitatory synapses, and the small bars non-plastic inhibitory synapses. The arrows
in the circles indicate the possibility to inject current from an external source, to stimulate
the neurons.
post-synaptic spikes. If the STDP short-term dynamics drive Vw0 above threshold we say
that long-term potentiation (LTP) had been induced. And if the short-term dynamics drive
Vw0 below threshold, we say that long-term depression (LTD) has been induced.
In Fig. 5 we show how the synaptic efficacy Vw0 changes upon induction of LTP, while
stimulating the pre- and post-synaptic neurons with uniformly distributed spike trains. The
asymptote Vlow was set to zero, and Vhigh to 2.75V. The pre- and post-synaptic neurons
were injected with constant DC currents in a way to increase Vw0 , on average. As shown,
the two asymptotes Vlow and Vhigh act as two attractors, or stable equilibrium points,
whereas the threshold voltage Vthr acts as an unstable equilibrium point. If the synaptic efficacy is below threshold the short-term dynamics have to fight against the long-term
bistability effect, to increase Vw0 . But as soon as Vw0 crosses the threshold, the bistability
circuit switches, the effects of the short-term dynamics are reinforced by the asymptotic
drive, and Vw0 is quickly driven toward Vhigh .

4 A network of integrate and fire neurons
The prototype chip that we used to test the bistable STDP circuits presented in this paper,
contains a symmetric network of leaky I&F neurons [9] (see Fig. 6). The experimental data

w0

V

V

w0

(V)

4

(V)

4

4

6

8

10

0
0
2

2

4

6

8

10

0
0

2

4

6
Time (ms)

8

10

0
0
2

2

4

6

8

10

0
0
2

2

4

6

8

10

0
0

2

4

6
Time (ms)

8

10

pre (V)

pre (V)

post (V)

2

post (V)

0
0
2

(a)

(b)

Figure 7: Membrane potentials of pre- and post-synaptic neurons (bottom and middle traces
respectively) and synaptic efficacy values (top traces). (a) Changes in V w0 for low synaptic efficacy values (Vhigh = 2.1V) and no bistability leakage currents (Vleak = 0). (b)
Changes in Vw0 for high synaptic efficacy values (Vwh = 3.6V ) and with bistability asymptotic drive (Vleak = 0.25V).
of Figs. 2, 3, and 5 was obtained by injecting currents in the neurons labeled I1 and O1
and by measuring the signals from the excitatory synapse on O1. In Fig. 7 we show the
membrane potential of I1, O1, and the synaptic efficacy Vw0 of the corresponding synapse,
in two different conditions. Figure 7(a) shows the changes in Vw0 when both neurons are
stimulated but no asymptotic drive is used. As shown Vw0 strongly depends on the spike
patterns of the pre- and post-synaptic neurons. Figure 7(b) shows a scenario in which
only neuron I1 is stimulated, but in which the weight Vw0 is close to its high asymptote
(Vhigh = 3.6V) and in which there is a long-term asymptotic drive (Vleak = 0.25). Even
though the synaptic weight stays always in its potentiated state, the firing rate of O1 is not
as regular as the one of its efferent neuron. This is mainly due to the small variations of
Vw0 induced by the STDP circuit.

5 Discussion and future work
The STDP circuits presented here introduce a source of variability in the spike timing of the
I&F neurons that could be exploited for creating VLSI networks of neurons with stochastic
dynamics and for implementing spike-based stochastic learning mechanisms [2]. These
mechanisms rely on the variability of the input signals (e.g. of Poisson distributed spike
trains) and on their precise spike-timing in order to induce LTP or LTD only to a small
specific sub-set of the synapses stimulated. In future experiments we will characterize the
properties of the bistable STDP synapse in response to Poisson distributed spike trains, and
measure transition probabilities as functions of input statistics and circuit parameters.
We presented compact neuromorphic circuits for implementing bistable STDP synapses in
VLSI networks of I&F neurons, and showed data from a prototype chip. We demonstrated
how these types of synapses can either store their LTP or LTD state for long-term, or switch
state depending on the precise timing of the pre- and post-synaptic spikes. In the near
future, we plan to use the simple network of I&F neurons of Fig. 6, present on the prototype
chip, to analyze the effect of bistable STDP plasticity at a network level. On the long term,

we plan to design a larger chip with these circuits to implement a re-configurable network
of I&F neurons of O(100) neurons and O(1000) synapses, and use it as a real-time tool for
investigating the computational properties of competitive networks and selective attention
models.
Acknowledgments
I am grateful to Rodney Douglas and Kevan Martin for their support, and to Shih-Chii Liu
and Stefano Fusi for constructive comments on the manuscript. Some of the ideas that led
to the design and implementation of the circuits presented were inspired by the Telluride
Workshop on Neuromorphic Engineering (http://www.ini.unizh.ch/telluride).

References
[1] L. F. Abbott and S. Song. Asymmetric hebbian learning, spike liming and neural response
variability. In Advances in Neural Information Processing Systems, volume 11, pages 69?75,
1998.
[2] D. J. Amit and S. Fusi. Dynamic learning in neural networks with material synapses. Neural
Computation, 6:957, 1994.
[3] T. V. P. Bliss and G. L. Collingridge. A synaptic model of memory: Long term potentiation in
the hippocampus. Nature, 31:361, 1993.
[4] A. Bofill and A.F. Murray. Circuits for VLSI implementation of temporally asymmetric Hebbian learning. In T. G. Dietterich, S. Becker, and Z. Ghahramani, editors, Advances in Neural
Information processing systems, volume 14. MIT Press, Cambridge, MA, 2001.
[5] C. Diorio, P. Hasler, B.A. Minch, and C. Mead. A single-transistor silicon synapse. IEEE Trans.
Electron Devices, 43(11):1972?1980, 1996.
[6] S. Fusi, M. Annunziato, D. Badoni, A. Salamon, and D.J. Amit. Spike-driven synaptic plasticity: theory, simulation, VLSI implementation. Neural Computation, 12:2227?2258, 2000.
[7] P. H?afliger, M. Mahowald, and L. Watts. A spike based learning neuron in analog VLSI. In
M. C. Mozer, M. I. Jordan, and T. Petsche, editors, Advances in neuralinformation processing
systems, volume 9, pages 692?698. MIT Press, 1997.
[8] G. Indiveri. Modeling selective attention using a neuromorphic analog VLSI device. Neural
Computation, 12(12):2857?2880, December 2000.
[9] G. Indiveri. A low-power adaptive integrate-and-fire neuron circuit. In ISCAS 2003. The 2003
IEEE International Symposium on Circuits and Systems, 2003. IEEE, 2003.
[10] T. Kohonen. Self-Organization and Associative Memory. Springer Series in Information Sciences. Springer Verlag, 2nd edition, 1988.
[11] S.-C. Liu, M. Boegerhausen, and S. Pascal. Circuit model of short-term synaptic dynamics. In
Advances in Neural Information Processing Systems, volume 15, Cambridge, MA, December
2002. MIT Press.
[12] S.-C. Liu, J. Kramer, G. Indiveri, T. Delbruck, T. Burg, and R. Douglas. Orientation-selective
aVLSI spiking neurons. Neural Networks, 14(6/7):629?643, 2001. Special Issue on Spiking
Neurons in Neuroscience and Technology.
[13] S.-C. Liu, J. Kramer, G. Indiveri, T. Delbruck, and R. Douglas. Analog VLSI:Circuits and
Principles. MIT Press, 2002.
[14] H. Markram, J. L?ubke, M. Frotscher, and B. Sakmann. Regulation of synaptic efficacy by
coincidence of postsynaptic APs and EPSPs. Science, 275:213?215, 1997.
[15] C. C. H. Petersen, R. C. Malenka, R. A. Nicoll, and J. J. Hopfield. All-ornone potentiation at
CA3-CA1 synapses. Proc. Natl. Acad. Sci., 95:4732, 1998.
[16] S. Song, K. D. Miller, and L. F. Abbot. Competitive Hebbian learning through spike-timingdependent plasticity. Nature Neuroscience, 3(9):919?926, 2000.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 34-a-computer-simulation-of-olfactory-cortex-with-functional-implications-for-storage-and-retrieval-of-olfactory-information.pdf

114

A Computer Simulation of Olfactory Cortex With Functional Implications for
Storage and Retrieval of Olfactory Information
Matthew A. Wilson and James M. Bower
Computation and Neural Systems Program
Division of Biology, California Institute of Technology, Pasadena, CA 91125
ABSTRACT
Based on anatomical and physiological data, we have developed a computer simulation of piriform (olfactory) cortex which is capable of reproducing spatial and temporal patterns of actual
cortical activity under a variety of conditions. Using a simple Hebb-type learning rule in conjunction with the cortical dynamics which emerge from the anatomical and physiological organization of the model, the simulations are capable of establishing cortical representations for different input patterns. The basis of these representations lies in the interaction of sparsely distributed, highly divergent/convergent interconnections between modeled neurons. We have shown that
different representations can be stored with minimal interference. and that following learning
these representations are resistant to input degradation, allowing reconstruction of a representation following only a partial presentation of an original training stimulus. Further, we have
demonstrated that the degree of overlap of cortical representations for different stimuli can
also be modulated. For instance similar input patterns can be induced to generate distinct cortical
representations (discrimination). while dissimilar inputs can be induced to generate overlapping
representations (accommodation). Both features are presumably important in classifying olfactory stimuli.

INTRODUCTION
Piriform cortex is a primary olfactory cerebral cortical structure which receives
second order input from the olfactory receptors via the olfactory bulb (Fig. 1). It
is believed to play a significant role in the classification and storage of olfactory
information 1?2?3 . For several years we have been using computer simulations as a
tool for studying information processing within this cortex4?5. While we are ultimately interested in higher order functional questions, our fITst modeling objective
was to construct a computer simulation which contained sufficient neurobiological
detail to reproduce experimentally obtained cortical activity patterns. We believe
this first step is crucial both to establish correspondences between the model and
the cortex, and to assure that the model is capable of generating output that can
be compared to data from actual physiological experiments. In the current case,
having demonstrated that the behavior of the simulation at least approximates
that of the actual cortex4 (Fig. 3), we are now using the model to explore the
types of processing which could be carried out by this cortical structure. In particular, in this paper we will describe the ability of the simulated cortex to store and
recall cortical activity patterns generated by stimulus various conditions. We
believe this approach can be used to provide experimentally testable hypotheses
concerning the functional organization of this cortex which would have been difficult to deduce solely from neurophysiological or neuroanatomical data.
@ American Institute of Physics 1988

115

Olfactory
Receptors

l

Higher Cortical Areas 1'- Hippocampus

1

Piriform Cortex
Olfactory I+and Other
Bulb
Olfactory Structures

Entorhinal
Cortex

T
LOT
Fig. 1. Simplified block diagram of the olfactory system and closely related sbUctures.

MODEL DESCRIPTION

This model is largely instructed by the neurobiology of piriform cortex3. Axonal conduction velocities, time delays, and the general properties of neuronal integration and the major intrinsic neuronal connections approximate those currently
described in the actual cortex. However, the simulation reduces both the number
and complexity of the simulated neurons (see below). As additional infonnation
concerning the these or other important features of the cortex is obtained it will be
incorporated in the model. Bracketed numbers in the text refer to the relevent
mathematical expressions found in the appendix.
Neurons. The model contains three distinct populations of intrinsic cortical
neurons, and a fourth set of cells which simulate cortical input from the olfactory
bulb (Fig. 2). The intrinsic neurons consist of an excitatory population of pyramidal neurons (which are the principle neuronal type in this cortex), and two populations of inhibitory interneurons. In these simulations each population is modeled
as 100 neurons arranged in a 10x10 array (the actual piriform cortex of the rat
contains on the order of 106 neurons). The output of each modeled cell type consists of an all-or-none action potential which is generated when the membrane
potential of the cell crosses a threshold [2.3]. This output reaches other neurons
after a delay which is a function of the velocity of the fiber which connects them
and the cortical distance from the originating neuron to each target neuron [2.0,
2.4]. When an action potential arrives at a destination cell it triggers a conductance change in a particular ionic channel type in that cell which has a characteristic time course, amplitude, and waveform [2.0, 2.1]. The effect of this conductance
change on the transmembrane potential is to drive it towards the equilibrium
potential of that channel. Na+, CI-, and K+ channels are included in the model.
These channels are differentially activated by activity in synapses associated with
different cell types (see below).

116

LOT Afferent Fiber

r

Ceudelly Directed
A. .oelatlOn Fiber

Locel
....oclellon
Flbe,
locel FMdbeck InhlblUon
Roatrelly Directed

Caudally DlrectecI

..._llIlon Fiber

Aasoclllion Fiber

Fig. 2. Schematic diagram of piriform cortex showing an excitatory pyramidal cell and two
inhibitory intemeurons with their local interactions. Circles indicate sites of synaptic modifiability.

Connection Patterns. In the olfactory system, olfactory receptors project to the
olfactory bulb which, in turn, projects directly to the pirifonn cortex and other olfactory structures (Fig. 1). The input to the pirifonn cortex from the olfactory bulb is
delivered via a fiber bundle known as the lateral olfactory tract (LOT). This fiber
tract appears to make sparse, non-topographic, excitatory connections with pyramidal and feedforward inhibitory neurons across the extent of the cortex3,6. In the
model this input is simulated as 100 independent cells each of which make random connections (p=O.05) with pyramidal and feedforward inhibitory neurons
(Fig. 1 and 2).
In addition to the input connections from the olfactory bulb, there is also an
extensive set of connections between the neurons intrinsic to the cortex (Fig. 2).
For example, the association fiber system arises from pyramidal cells and makes
sparse, distributed excitatory connections with other pyramidal cells all across the
cortex7,8.9 ? In the model these connections are randomly distributed with 0.05
probability. In the model and in the actual cortex, pyramidal cells also make excitatory connections with nearby feedforward and feedback inhibitory cells. These
intemeurons, in turn, make reciprocal inhibitory connections with the group of
nearby pyramidal cells. The primary effect of the feedback inhibitory neurons is to
inhibit pyramidal cell firing through a CI- mediated current shunting mechanism lO?ll ?12. Feedforward intemeurons inhibit pyramidal cells via a long latency,
long duration, K+ mediated hyperpolarizing potential 12,13. Pyramidal cell axons
also constitute the primary output of both the model and the actual pirifonn cortex 7?14?

117

Synaptic Properties and Modification Rules. In the model, each synaptic connection has an associated weight which determines the peak amplitude of the conductance change induced in the postsynaptic cell following presynaptic activity
[2.0]. To study learning in the model, synaptic weights associated with some of
the fiber systems are modifiable in an activity-dependent fashion (Fig. 2). The
basic modification rule in each case is Hebb-like; i.e. change in synaptic strength
is proportional to presynaptic activity multiplied by the offset of the postsynaptic
membrane potential from a baseline potential. This baseline potential is set
slightly more positive than the CI- equilibrium potential associated with the shunting feedback inhibition. This means that synapses activated while a destination
cell is in a depolarized or excited state are strengthened, while those activated
during a period of inhibition are weakened. In the model, synapses which follow
this rule include the association fiber connections between excitatory pyramidal
neurons as well as the connections between inhibitory neurons and pyramidal neurons. Whether these synapses are modifiable in this way in the actual cortex is a
subject of active research in our lab. However, the model does mimic the actual
synaptic properties associated with the input pathway (LOT) which we have
shown to undergo a transient increase in synaptic strength following activation
which is independent of postsynaptic potential 15. This increase is not pennanent
and the synaptic strength subsequently returns to its baseline value.
Generation of Physiological Responses. Neurons in the model are represented
as fIrst-order "leaky" integrators with multiple, time-varying inputs [1.0]. During
simulation runs, membrane potentials and currents as well as the time of
occurence of action potentials are stored for comparison with actual data. An
explicit compartmental model (5 compartments) of the pyramidal cells is used to
generate the spatial current distributions used for calculation of field potentials
(evoked potentials, EEGs) [3.0,4.0].
Stimulus Characteristics. To compare the responses of the model to those of
the actual cortex, we mimicked actual experimental stimulation protocols in the
simulated cortex and contrasted the resulting intracellular and extracellular
records. For example, shock stimuli applied to the LOT are often used to elicit
characteristic cortical evoked potentials in vivo 16,17,18. In the model we simulated
this stimulus paradigm by simultaneously activating all 100 input fibers. Another
measure of cortical activity used most successfully by Freeman and colleagues
involves recording EEG activity from pirifonn cortex in behaving animals 19,20.
These odor-like responses were generated in the model through steady, random
stimulation of the input fibers.
To study learning in the model, once physiological measures were established,
it was required that we use more refined stimulation procedures. In the absence of
any specific infonnation about actual input activity patterns along the LOT, we
constructed each stimulus out of a randomly selected set of 10 out of the 100 input

118

fibers. Each stimulus episode consisted of a burst of activity in this subset of
fibers with a duration of 10 msec at 25 msec intervals to simulate the 40 Hz periodicity of the actual olfactory bulb input. This pattern of activity was repeated in
trials of 200 msec duration which roughly corresponds to the theta rhythm periodicity of bulbar activity and respiration 21 ?22 . Each trial was then presented 5 times
for a total exposure time of 1 second (cortical time). During this period the Hebbtype learning rule could be used to modify the connection weights in an activitydependent fashion.

Output Measure for Learning. Given that the sole output of the cortex is in the
fonn of action potentials generated by the pyramidal cells, the output measure of
the model was taken to be the vector of spike frequency for all pyramidal neurons
over a 200 msec trial, with each element of the vector corresponding to the firing
frequency of a single pyramidal cell. Figures 5 through 8 show the 10 by 10 array
of pyramidal cells. The size of the box placed at each cell position represents the
magnitude of the spike frequency for that cell. To evaluate learning effects, overlap
comparisons between response pairs were made by taking the nonnalized dot
product of their response vectors and expressing that value as a percent overlap
(Fig. 4).

Simulated

~\~f".-.-

lj
Fig. 3. Simulated physiological responses of the model compared with actual cortical responses. Upper: Simulated intracellular response of a single cell to paired stimulation of the input
system (LOn (left) compared with actual response (right) (Haberly & Bower: 84). Middle:
Simulated extracellular response recorded at the cortical surface to stimulation of the LOT
(left), compared with actual response (right) (Haberly:73b). Lower: Stimulated EEG
response recorted at the cortical surface to odor-like input (left), for actual EEG see Freeman
1978.

119

Computational Requirements. All simulations were carried out on a Sun
Microsystems 3/260 model microcomputer equipped with 8 Mbytes of memory and
a floating point accelerator. Average time for a 200 msec simulation was 3 cpu
minutes.
RESULTS
Physiological Responses
As described above, our initial modeling objective was to accurately simulate
a wide range of activity patterns recorded, by ourselves and others, in piriform
cortex using various physiological procedures. Comparisons between actual and
simulated records for several types of response are shown in figure 3. In general,
the model replicated known physiological responses quite well (Wilson et al in
preparation describes, in detail, the analysis of the physiological reSUlts). For
example in response to shock stimulation of the input pathway (LOT), the model
reproduces the principle characteristics of both the intracellular and locationdependent extracellular waveforms recorded in the actual cortex9,17,18 (Fig. 3).
100
Percent Overlap
with
Final Response
Pattern
60 0
Number of Trials

5

Fig. 4. Convergence of the cortical response during training with a single stimulus with synaptic
modification.

56% overlap

? ????? ??? ?? ? ? ?? ? ??
? ? ?? ? ? ? ? ?
? ??? ?? ? ??
?
? ? ???
?
?
?? ? ?? ? ? ? ? ? ?
Full Stimulus
50% Simulus
Before Training

80% overlap

??
??
? ????
?
?
?? ?? ? ? ??
??? ?? ?? ?? ?? ??
?? ? ?? ? ?
Full Stimulus
50% Simulus
After Training

Fig. S. Reconstruction of cortical response patterns with partially degraded stimuli. Left:
Response, before training, to the full stimulus (left) and to the same stimulus with 50% of the
input fibers inactivated (right). There is a 44% degradation in the response. Right: Response
after ttaining, to the full stimulus (left), and to the same stimulus with 50% of the input
fibers inactivated (right). As a result of ttaining, the degradation is now only 20%.

120

Trained on A

?? ?? ??
?
?????
? ??
?? ??? ?

Trained on B

?

?

? ?
?
???
?
?
?
?
? ??? ? ?

Retains A Response

?? ???
? ?? ?
?
? ??? ?
?? ?? ?

Fig. 6. Storage of multiple patterns. Left Response to stimulus A afler training. Middle:
Response to stimulus B afler training on A followed by training on B. Right: Response to
stimulus A after training on A followed by training on B. When compared with the original
response (left) there is an 85% congruence.

Further, in response to odor-like stimulation the model exhibits 40 Hz oscillations
which are characteristic of the EEG activity in olfactory cortex in awake, behaving
animals 19. Although beyond the scope of the present paper, the simulation also
duplicates epileptiform9 and damped oscillatory16 type activity seen in the cortex
under special stimulus or pharmacological conditions4 .
Learning
Having simulated characteristic physiological responses, we wished to
explore the capabilities of the model to store and recall information. Learning in
this case is defined as the development of a consistent representation in the activity of the cortex for a particular input pattern with repeated stimulation and synaptic modification. Figure 4 shows how the network converges, with training, on a
representation for a stimulus. Having demonstrated that, we studied three properties of learned responses - the reconstruction of trained cortical response patterns
with partially degraded stimuli, the simultaneous storage of separate stimulus
response patterns, and the modulation of cortical response patterns independent
of relative stimulus characteristics.
Reconstruction of Learned Cortical Response Patterns "with Partially Degraded Stimuli. We were interested in knowing what effect training would have on the
sensitivity of cortical responses to fluctuations in the input signal. First we presented the model with a random stimulus A for one trial (without synaptic modification). On the next trial the model was presented with a degraded version of A
in which half of the original 10 input fibers were inactivated. Comparison of the
responses to these two stimuli in the naive cortex showed a 44% variation. Next,
the model was trained on the full stimulus A for 1 second (with synaptic modification). Again, half of the input was removed and the model was presented with the
degraded stimulus for 1 trial (without synaptic modification). In this case the dif-

121

27% overlap

? ?
? ?? ?
? ?

?? ?
?

??

46% overlap

?

? ?? ?

Stimulus A
Stimulus B
Before Training

? ?
?? ???? ?
?
? ? ??

?

????

?? ? ??
?

Stimulus A
Stimulus B
After Training

Fig. 7. Results of merging cortical response patterns for dissimilar
stimulus A and stimulus B before training. Stimuli A and B do not
common but still have a 27% overlap in cortical response patterns.
lus A and stimulus B after training in the presence of a common
overlap in cortical response patterns is now 46%.

stimuli. Left: Response to
activate any input fibers in
Right: Response to stimumodulatory input E 1. The

ference between cortical responses was only 20% (Fig. 5) showing that training
increased the robustness of the response to degradation of the stimulus.
Storage of Two Patterns. The model was frrst trained on a random stimulus A
for 1 second. The response vector for this case was saved. Then, continuing with
the weights obtained during this training, the model was trained on a new nonoverlapping (Le. different input fibers activated) stimulus B. Both stimulus A and
stimulus B alone activated roughly 25% of the cortical pyramidal neurons with 25%
overlap between the two responses. Following the second training period we
assessed the amount of interference in recalling A introduced by training with B
by presenting stimulus A again for a single trial (without synaptic modification).
The variation between the response to A following additional training with B and
the initially saved reponse to A alone was less than 15% (Fig. 6) demonstrating
that learning B did not substantially interfere with the ability to recall A.
Modulation of Cortical Response Patterns.
It has been previously demonstrated that the stimulus evoked response of olfactory cortex can be modulated by
factors not directly tied to stimulus qualities, such as the behavioral state of the
animal 1,20,23. Accordingly we were interested in knowing whether the representations stored in the model could be modulated by the influence of such a "state"
input.
One potential role of a "state" input might be to merge the cortical response
patterns for dissimilar stimuli; an effect we refer to as accomodation. To test this
in the model, we presented it with a random input stimulus A for 1 trial. It was
then presented with a random input stimulus B (non-overlapping input fibers).
The amount of overlap in the cortical responses for these untrained cases was
27%. Next, the model was trained for 1 second on stimulus A in the presence of an
additional random "state" stimulus El (activity in a set of 10 input fibers distinct

122

77% overlap

45% overlap

~----------~

r--~------~

?
??
??
?
?
?
?
?
???
?? ?
?
?
? ?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?
?

?

?

?? ? ?

?

?

? ?? ??

Stimulus A
Stimulus B
Before Training

?

??

? ? ???

? ? ??

?
?
?

?
?

?

??

??

?

Stimulus A
Stimulus B
After Training

Fig. 8. Results of differentiating cortical response patterns for similar stimuli. Left:
Response to stimulus A and stimulus B before training. Stimuli A and B activate 75% of
their input fibers in common and have a 77% overlap in cortical response patterns. Right:
Respon~ to stimulus A and stimulus B after training A in the presence of modulatory input
El and training B with a different modulatory input E2. The overlap in cortical response patterns is now 45%.

from both A and B). The model was then trained on stimulus B in the presence of
the same "state" stimulus El. After training, the model was presented with stimulus A alone for 1 trial and stimulus B alone for 1 trial. Results showed that now.
even without the coincident E 1 input, the amount of overlap between A and B
responses was found to have increased to 46% (Fig 7). The role of El in this case
was to provide a common stimulus component during learning which reinforced
shared components of the responses to input stimuli A and B.
To test the ability of a state stimulus to induce differentiation of cortical
response patterns for similar stimuli, we presented the model with a random input
stimulus A for 1 trial, followed by 1 trial of a random input stimulus B (75% of the
input fibers overlapping), The amount of overlap in the cortical responses for these
untrained cases was 77%. Next, the model was trained for a period of 1 second on
stimulus A in the presence of an additional random "state" stimulus El (a set of
10 input fibers not overlapping either A or B). It was then trained on input stimulus B in the presence of a different random "state" stimulus E2 (10 input fibers not
overlapping either A, B, or El) After this training the model was presented with
stimulus A alone for 1 trial and stimulus B alone for 1 trial. The amount of overlap
was found to have decreased to 45% (Fig 8). In this situation EI and E2 provided
a differential signal during learning which reinforced distinct components of the
responses to input stimuli A and B.
DISCUSSION
PhYSiological Responses. Detailed discussion of the mechanisms underlying
the simulated patterns of physiological activity in the cortex is beyond the scope
of the current paper. However, the model has been of value in suggesting roles for

123

specific features of the cortex in generating physiologically recorded activity. For
example, while actual input to the cortex from the olfactory bulb is modulated into
40 Hz bursts24 , continuous stimulation of the model allowed us to demonstrate
the model's capability for intrinsic periodic activity independent of the complementary pattern of stimulation from the olfactory bulb. While a similar ability has
also been demonstrated by models of Freeman25 , by studying this oscillating
property in the model we were able to associate these oscillatory characteristics
with specific interactions of local and distant network properties (e.g. inhibitory
and excitatory time constants and trans-cortical axonal conduction velocities).
This result suggests underlying mechanisms for these oscillatory patterns which
may be somewhat different than those previously proposed.
Learning. The main subject of this paper is the examination of the learning
capabilities of the cortical model. In this model, the apparently sparse, highly distributed pattern of connectivity characteristic of piriform cortex is fundamental to
the way in which the model learns. Essentially, the highly distributed pattern of
connections allows the model to develop stimulus-specific cortical response patterns by extracting correlations from randomly distributed input and association
fiber activity. These correlations are, in effect, stored in the synaptic weights of
the association fiber and local inhibitory connections.
The model has also demonstrated robustness of a learned cortical response
against degradation of the input signal. A key to this property is the action of
sparsely distributed association fibers which provide reinforcment for previously
established patterns of cortical activity. This property arises from the modification
of synaptic weights due to correlations in activity between intra-cortical association fibers. As a result of this modification the activity of a subset of pyramidal
neurons driven by a degraded input drives the remaining neurons in the response.
In general, in the model, similar stimuli will map onto similar cortical responses and dissimilar stimuli will map onto dissimilar cortical responses. However, a
presumably important function of the cortex is not simply to store sensory information, but to represent incoming stimuli as a function of the absolute stimulus
qualities and the context in which the stimulus occurs. The fact that many of the
structures that piriform cortex projects to (and receives projections from) may be
involved in multimodal "state" generation14 is circumstantial evidence that such
modulation may occur. We have demonstrated in the model that such a modulatory input can modify the representations generated by pairs of stimuli so as to
push the representations of like stimuli apart and pull the representations of dissimilar stimuli together. It should be pointed out that this modulatory input was
not an "instructive" signal which explicitly directed the course of the representation, but rather a "state" signal which did not require a priori knowledge of the
representational structure. In the model, this modulatory phenomenon is a simple
consequence of the degree of overlap in the combined (odor stimulus + modulator)
stimulus. Both cases approached approximately 50% overlap in cortical responses
reflecting the approximately 50% overlap in the combined stimuli for both cases.

124

Of interest was the use of the model's reconstructive capabilities to maintain the
modulated response to each input stimulus even in the absence of the modulatory
input.
CA YEATS AND CONCLUSIONS
Our approach to studying this system involves using computer simulation to
investigate mechanisms of information processing which could be implemented
given what is known about biological constraints. The significance of results presented here lies primarily in the finding that the structure of the model and the
parameter settings which were appropriate for the reproduction of physiological
responses were also appropriate for the proper convergence of a simple, biologically plausible learning rule under various conditions. Of course, the model we
have developed is only an approximation to the actual cortex limited by our knowledge of its organization and the computing power available. For example, the
actual piriform cortex of the rat contains on the order of 106 cells (compared with
1()2 in the simulations) with a sparsity of connection on the order of p=O.OOI
(compared with p=0.05 in the simulations). Our continuing research effort will
include explorations of the scaling properties of the network.
Other assumptions made in the context of the current model include the
assumption that the representation of information in piriform cortex is in the form
of spatial distributions of rate-coded outputs. Information contained in the spatiotemporal patterns of activity was not analyzed, although preliminary observation
suggests that this may be of significance. In fact, the dynamics of the model itself
suggest that temporally encoded information in the input at various time scales
may be resolvable by the cortex. Additionally, the output of the cortex was
assumed to have spatial uniformity, Le. no differential weighting of information
was made on the basis of spatial location in the cortex. But again, observation of
the dynamics of the model, as well as the details of known anatomical distribution
patterns for axonal ?connections, indicate that this is a major oversimplification.
Preliminary evidence from the model would indicate that some form of hierarchical
structuring of information along rostraVcaudal lines may occur. For example it
may be that cells found in progressively more rostral locations would have
increasingly non-specific odor responses.
Further investigations of learning within the model will explore each of these
issues more fully, with attempts to correlate simulated findings with actual recordings from awake, behaving animals. At the same time, new data pertaining to the
structure of the cortex will be incorporated into the model as it emerges.
ACKNOWLEDGEMENTS
We wish to thank Dr. Lewis Haberly and Dr. Joshua Chover for their roles in
the development and continued support of the modeling effort. We also wish to
thank Dave Bilitch for his technical assistance. This work was supported by NIH
grant NS22205, NSF grant EET-8700064, the Lockheed Corporation, and a fellowship from the ARCS foundation.

125

APPENDIX
E,-V, (r) ]
-dV, = - 1 [",1: lik(r) + - - dl

c'" i=1

(1.0)

r,

SOl1UJric Inregrarion
(1.1)

n

l'u ..

=

number of input types

resting potential
r, ==membrane
leakage resistance

E,

V.(t) membrane potential of i th cell
lit (t ) .. current into cell i due to input type Ie
E t - equilibrium potential associated with input type Ie

c... = membrane capacitance
goJ:(t) .. conductance due to input type Ie in cell i

(2.0)

Spilce Propagation
and SynaptiC l"Pur

Aiji = (l-p:",")e -L., P. +

P:"'''

(2.2)

V) (r?T) , S)O..)=O for

A.=t .. r-ru,
(2.3)

otherwise

L'j = Ii - j

I~

nc61ls .. number of cells in the simulation
~ .. distance between adjacent cells

di = duration of conductance change due to input type Ie
Vi '" velocity of signals for input type Ie
Et = latency for input type Ie
Pt = spatial anenuation factor for input type Ie
P:"''' .. minimum spatial anenuation for input type Ie
ru, = refractory period

(2.4)

= threshold for cell j
distance from cell i to cell j
~')t = distribution of synaptic density for input type Ie
w'} = synaptic weight from cell j to cell i
goJ: (t) = conductance due to input type Ie in cell i
Ft (t) = conductance waveform for input type k
~J (I) = spike output of cell j at time t
U (t) = unit step function
T)

L,)

OK

(3.0)

Field Poren/ials

nc61ls

=number of cells in the simulation

nugs = number of segments in the companmental model
V (r) .. approximate extracellular field potential at cell j
I ... (r) membrane current for segment n in cell i

k

=

Zr/ec
1"

=depth of recording site

= depth of segment n

x .. x location of the jth cell
= extracellular resistance per unit length

R.

(4.0)

Dendriric Model
(4.1)

126

(4.2)

nc"",,, = number of different channels per segment
V" (r) membrane potential of nth segment
= membrane capacitance for segment n

c,:

=

r; = axial resistance for segment n
r:' - membrane resistance for segment n

=membrane current for segment n

/" = length of segment n
d" = diameter of segment n

R". = membrane resistivity
Rj

BPI< (r) = conductance of channel c in segment n
Ec = equilibrium potential associated with channel c
I:%(r) axial current between segment nil and n

=

l:'(r)

R.

e",

= intracellular resistiviry per unit length

=extracellular resistance per unit length
=capacitance per unit surface area

REFERENCES
1.
2.
3.
4.

W. J. Freeman, J. Neurophysiol., 23, 111 (1960).
T. Tanabe, M. lino, and S. F. Takagi, J. Neurophysiol., 38,1284 (1975).
L. B. Haberly, Chemical Senses, 10,219 (1985).
M. Wilson, J. M. Bower, J. Chover, and L. B. Haberly, Soc. Neuro. Abs., 11,
317 (1986).
5. M. Wilson and J. M. Bower, Soc. Neurosci. Abs., 12, 310 (1987).
6. M. Devor, J. Compo Neur., 166,31 (1976).
7. L. B. Haberly and 1. L. Price, J. Compo Neurol., 178, 711 (1978a).
8. L. B. Haberly and S. Presto, J. Compo Neur., 248, 464 (1986).
9. L. B. Haberly andJ. M. Bower, J. Neurophysiol., 51, 90 (1984).
10. M. A. Biedenbach and C. F. Stevens, J. Neurophysiol., 32, 193 (1969).
11. M. A. Biedenbach and C. F. Stevens, J. Neurophysiol., 32, 204 (1969).
12. M. Satou, K. Mori, Y. Tazawa, and S. F. Takagi, J. Neurophysiol., 48, 1157
(1982).
13. O. F. Tseng and L. B. Haberly, Soc. Neurosci. Abs. 12,667 (1986).
14. L. B. Luskin and J. L. Price, J. Compo Neur., 216, 264 (1983).
15. J. M. Bower and L. B. Haberly,L.B., Proc. Natl. Acad. Sci. USA, 83, 1115
(1985).
16. W. J. Freeman, J. Neurophysiol., 31, 1 (1968).
17. L. B. Haberly, J. Neurophysiol., 36, 762 (1973).
18. L. B. Haberly, J. Neurophysiol., 36, 775 (1973).
19. W. J. Freeman, Electroenceph. and Clin. Neurophysiol., 44, 586 (1978).
20. W.J. Freeman and W. Schneider, Psychophysiology, 19,44 (1982).
21. F. Macrides and S. L. Chorover, Science, 175,84 (1972).
22. F. Macrides, H. B. Eigenbaum, and W. B. Forbes, J. Neurosci., 2, 12, 1705
(1982).
23. P. D. MacLean, N. H. Horwitz, and F. Robinson, Yale J. BioI. Med., 25, 159
(1952).
24. E. D. Adrian, Electroenceph. and Clin. Neurophysiol., 2, 377 (1950).
25. W. J. Freeman, Exp. Neuro!., 10, 525 (1964).


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 3102-uncertainty-phase-and-oscillatory-hippocampal-recall.pdf

Uncertainty, phase and oscillatory hippocampal recall

M?at?e Lengyel and Peter Dayan
Gatsby Computational Neuroscience Unit
University College London
17 Queen Square, London WC1N 3AR, United Kingdom
{lmate,dayan}@gatsby.ucl.ac.uk

Abstract
Many neural areas, notably, the hippocampus, show structured, dynamical, population behavior such as coordinated oscillations. It has long been observed that
such oscillations provide a substrate for representing analog information in the
firing phases of neurons relative to the underlying population rhythm. However,
it has become increasingly clear that it is essential for neural populations to represent uncertainty about the information they capture, and the substantial recent
work on neural codes for uncertainty has omitted any analysis of oscillatory systems. Here, we observe that, since neurons in an oscillatory network need not only
fire once in each cycle (or even at all), uncertainty about the analog quantities each
neuron represents by its firing phase might naturally be reported through the degree of concentration of the spikes that it fires. We apply this theory to memory
in a model of oscillatory associative recall in hippocampal area CA3. Although
it is not well treated in the literature, representing and manipulating uncertainty
is fundamental to competent memory; our theory enables us to view CA3 as an
effective uncertainty-aware, retrieval system.

1

Introduction

In a network such as hippocampal area CA3 that shows prominent oscillations during memory retrieval and other functions [1], there are apparently three, somewhat separate, ways in which neurons
might represent information within a single cycle: they must choose how many spikes to fire; what
the mean phase of those spikes is; and how concentrated those spikes are about that mean. Most
groups working on the theory of spiking oscillatory networks have considered only the second of
these ? this is true, for instance, of Hopfield?s work on olfactory representations [2] and Yoshioka?s
[3] and Lengyel & Dayan?s work [4] on analog associative memories in CA3. Since neurons do really fire more or less than one spike per cycle, and furthermore in a way that can be informationally
rich [5, 6], this poses a key question as to what the other dimensions convey.
The number of spikes per cycle is an obvious analog of a conventional firing rate. Recent sophisticated models of firing rates of single neurons and neural populations treat them as representing
uncertainty about the quantities coded, partly driven by the strong psychophysical and computational evidence that uncertainty plays a key role in many aspects of neural processing [7, 8, 9].
Single neurons can convey the certainty of a binary proposition by firing more or less strongly
[10, 11]; a whole population can use firing rates to convey uncertainty about a collectively-coded
analog quantity [12].
However, if neurons can fire multiple spikes per cycle, then the degree to which the spikes are
concentrated around a mean phase is an additional channel for representing information. Concentration is not merely an abstract quantity; rather we can expect that the effect of the neuron on its
postsynaptic partners will be strongly influenced by the burstiness of the spikes, an effect apparent,
for instance, in the complex time-courses of short term synaptic dynamics. Here, we suggest that

concentration codes for the uncertainty about phase ? highly concentrated spiking represents high
certainty about the mean phase in the cycle.
One might wonder whether uncertainty is actually important for the cases of oscillatory processing
that have been identified. One key computation for spiking oscillatory networks is memory retrieval
[3, 4]. Although it is not often viewed this way, memory retrieval is a genuinely probabilistic task
[13, 14], with the complete answer to a retrieval query not being a single memory pattern, but rather
a distribution over memory patterns. This is because at the time of the query the memory device
only has access to incomplete information regarding the memory trace that needs to be recalled.
Most importantly, the way memory traces are stored in the synaptic weight matrix implies a data
lossy compression algorithm, and therefore the original patterns cannot be decompressed at retrieval
with absolute certainty.
In this paper, we first describe how oscillatory structures can use all three activity characteristics
at their disposal to represent two pieces of information and two forms of uncertainty (Section 2).
We then suggest that this representational scheme is appropriate as a model of uncertainty-aware
probabilistic recall in CA3. We derive the recurrent neural network dynamics that manipulate these
firing characteristics such that by the end of the retrieval process neurons represent a good approximation of the posterior distribution over memory patterns given the information in the recall cue
and in the synaptic weights between neurons (Section 3). We show in numerical simulations that the
derived dynamics lead to competent memory retrieval, supplemented by uncertainty signals that are
predictive of retrieval errors (Section 4).

2

Representation

Single cell The heart of our proposal is a suggestion for how to interpret the activity of a single
neuron in a single oscillatory cycle (such as a theta-cycle in the hippocampus) as representing a
probability distribution. This is a significant extension of standard work on single-neuron representations of probability [12]. We consider a distribution over two random variables, z ? {0, 1}, a
Bernoulli variable (for the case of memory, representing the participation of the neuron in the memory pattern), and x ? [0, T ), where T is the period of the underlying oscillation, a real valued phase
variable (representing an analog quantity associated with that neuron if it participates in that pattern).
This distribution is based on three quantities associated with the neuron?s activity (figure 1A):
r the number of spikes in a cycle,
? the circular mean phase of those spikes, under the assumption that there is at least one spike,
c the concentration of the spikes (mean resultant length of their phases, [15]), which measures how
tightly clustered they are about ?
In keeping with conventional single-neuron models, we treat r, via a (monotonically increasing)
probabilistic activation function 0 ? ?(r) ? 1, as describing the probability that z = 1 (figure 1B),
z
1?z
so the distribution is q (z; r) = ? (r) (1 ? ? (r)) . We treat the implied distribution over the true
phase x as being conditional on z. If z = 0, then the phase is undefined. However, if z = 1, then the
distribution over x is a mixture of qu (x), a uniform distribution on [0, T ), and a narrow, quasi-delta,
distribution q? (x; ?) (of width   T ) around the mean firing phase (?) of the spikes. The mixing
proportion in this case is determined by a (monotonically increasing) function 0 ? ?(c) ? 1 of the
concentration of the spikes. In total:
z

1?z

q (x, z; ?, c, r) = [? (r) [? (c) q? (x; ?) + (1 ? ? (c)) qu (x)]] (1 ? ? (r))

(1)

as shown in figure 1C. The marginal confidence in ? being correct is thus ? (c, r) = ? (c) ? ? (r),
which we call ?burst strength?. We can rewrite equation 1 in a more convenient form:
z

1?z

q (x, z; ?, c, r) = [? (c, r) q? (x; ?) + (? (r) ? ? (c, r)) qu (x)] (1 ? ? (r))

(2)

Population In the case of a population of neurons, the complexity of representing a full joint distribution P[x, z] over random variables x = {xi }, z = {zi } associated with each neuron i grows
exponentially with the number of neurons N . The natural alternative is to consider an approximation in which neurons make independent contributions, with marginals as in equation 2. The joint

A

B
c

C

q(z ; r)

q(x | z=1; ?, c)
?(r)

r=2

?
?(c)

z

0 1

?

0

? T

x

Figure 1: Representing uncertainty. A) A neuron?s firing times during a period [0, T ) are described
by three parameters: r, the number of spikes; ? the mean phase of those spikes; and c, the phase
concentration. B) The firing rate r determines the probability ?(r) that a Bernoulli variable associated with the unit takes the value z = 1. C) If z = 1, then ? and c jointly define a distribution over
phase which is a mixture (weighted by ?(c)) of a distribution peaked at ? and a uniform distribution.
distribution is then
Q (x, z; ?, c, r) =

Q

i

q (xi , zi ; ?i , ci , ri )

(3)

whose complexity scales linearly with N .
Dynamics When the actual distribution P the population has to represent lies outside the class of
representable distributions Q in equation 3 with independent marginals, a key computational step is
to find activity parameters ?, c, r for the neurons that make Q as close to P as possible. One way to
formalize the discrepancy between the two distributions is the KL-divergence
F (?, c, r) = KL [Q (x, z; ?, c, r) k P (x, z)]

(4)

Minimizing this by gradient descent
?

d?i
?
=?
F (?, c, r)
dt
??i

?

?
dci
=?
F (?, c, r)
dt
?ci

?

?
dri
=?
F (?, c, r)
dt
?ri

(5)

defines dynamics for the evolution of the parameters. In general, this couples the activities of neurons, defining recurrent interactions within the network.1
We have thus suggested a general representational framework, in which the specification of a computational task amounts to defining a P distribution which the network should represent as best as
possible. Equation 5 then defines the dynamics of the interaction between the neurons that optimizes
the network?s approximation.

3

CA3 memory

One of the most widely considered tasks that recurrent neural networks need to solve is that of
autoassociative memory storage and retrieval. Moreover, hippocampal area CA3, which is thought
to play a key role in memory processing, exhibits oscillatory dynamics in which firing phases are
known to play an important functional role. It is therefore an ideal testbed for our theory.
We characterize the activity in CA3 neurons during recall as representing the probability distribution
over memories being recalled. Treating storage from a statistical perspective, we use Bayes rule to
define a posterior distribution over the memory pattern implied by a noisy and impartial cue. This
distribution is represented approximately by the activities ?i , ri , ci of the neurons in the network as
in equation 3. Recurrent dynamics among the neurons as in equation 5 find appropriate values of
these parameters, and model network interactions during recall in CA3.
Storage We consider CA3 as storing patterns in which some neurons are quiet (zim = 0, for the
ith neuron in the mth pattern); and other neurons are active (zim = 1); their activity then defining
1
Of course, the firing rate is really an integer variable, since it is an actual number of spikes per cycle. For
simplicitly, in the simulations below, we considered real-valued firing rates ? an important next step is to drop
this assumption.

a firing phase (xim ? [0, T ), where T is the period of the population oscillation. M such memory
traces, each drawn from an (iid) prior distribution,
Q
1?z
z
(6)
P [x, z] = i [pz P (xi )] i (1 ? pz ) i ,
(where pz is the prior probability of firing in a memory pattern; P (x) is the prior distribution for
firing phases) are stored locally and additively in the recurrent synaptic weight matrix of a network
of N neurons, W, according to learning rule ?:

PM
m
for i 6= j, and Wii = 0
(7)
Wij = m=1 zim zjm ? xm
i , xj
We assume that ? is T?oplitz and periodic in T , and either symmetric or anti-symmetric:
? (x1 , x2 ) = ? (x1 ? x2 ) = ? (x1 ? x2 mod T ) = ?? (x2 ? x1 ).
Posterior for memory recall Following [14, 4], we characterize retrieval in terms of the posterior
distribution over x, z given three sources of information: a recall cue (?
x, ?
z), the synaptic weight matrix, and the prior over the memories. Under some basic independence assumptions, this factorizes
into three terms
P [x, z | x
?, ?
z, W] ? P [x, z] ? P [?
x, ?
z | x, z] ? P [W | x, z]
(8)
The first term is the prior (equation 6). The second term is the likelihood of receiving noisy or partial
recall cue (?
x, ?
z) if the true pattern to be recalled was (x, z):
zi 
1?zi
z?i
z?i
Y 
1??
z
? 0 (?
? 1 (?
(1 ? ?0 ) P
xi )
?01??zi
?1 P
xi | xi )
(1 ? ?1 ) i
(9)
P [?
x, ?
z | x, z] =
i

where ?1 = P [?
z = 1 | z = 1] and ?0 = P [?
z = 0 | z = 0] are the probabilities of the presence or
absence of a spike in the input given the presence or absence of a spike in the memory to be recalled,
? 1 (?
? 0 (?
P
x | x) and P
x) are distributions of the phase of an input spike if there was or was not a spike
in the memory to be recalled.
The last term in equation 8 is the likelihood that weight matrixW arose from M patterns includ
Q
1/2
.
P
[W
|
x
,
z
,
x
,
z
]
ing (x, z). Making a factorized approximation P [W | x, z] '
ij
i
i
j
j
i,j6=i
Since the learning rule is additive and memory traces are drawn iid, the likelihood of a synaptic
weight is approximately Gaussian for large M , with a quadratic log-likelihood [4]:


1 2
+c zi zj
log P [Wij | xi , zi , xj , zj ] = 2 (Wij ? ?W ) ? (xi , xj ) ? ? (xi , xj )
(10)
?W
2
2
are the mean and variance of the distribution of synaptic weights after storing
where ?W and ?W
M ? 1 random memory traces (?W = 0 for antisymmetric ?).

Dynamics for memory recall Plugging the posterior from equation 8 to the general dynamics
equation 5 yields the neuronal update rules that will be appropriate for uncertainty-aware memory
recall, and which we treat as a model of recurrent dynamics in CA3.
We give the exact formul? for the dynamics in the supplementary material. They can be shown
to couple together the various activity parameters of the neurons in appropriate ways, for instance
weighting changes to ?i for neuron i according to the burst strength of its presynaptic inputs, and
increasing the concentration when the log posterior of the firing phase of the neuron, given that it
?, z
?, W], is greater than the average of the log posterior.
should fire, log P[?i |zi = 1, x
These dynamics generalize, and thus inherit, some of the characteristics of the purely phase-based
network suggested in [4]. This means that they also inherit the match with physiologically-measured
phase response curves (PRCs) from in vitro CA3 neurons that were measured to test this suggestion
[16]. The key difference here is that we expect the magnitude (though not the shape) of the influence
of a presynaptic neuron on the phase of a postsynaptic one to scale with its rate, for high concentration. Preliminary in vitro results show that PRCs recorded in response to burst stimulation are not
qualitatively different from PRCs induced by single spikes; however, it remains to be seen if their
magnitude scales in the way implied by the dynamics here.

z=1

0
!2
0

1

2

3

4

5

0.5
0

0

1

2

0

1

2

3
Time

3

4

1
0.5
0

5

0

1

2

z=0

4

5

0.5
0

0

1

2

3
Time

3

4

5

3

4

5

z=0

1

Firing rate

Concentration

Phase

z=0
5

0

z=1

1

Firing rate

Concentration

Phase error

z=1
2

4

5

1
0.5
0

0

1

2
Time

Figure 2: A single retrieval trial in the network. Time evolution of firing phases (left panels),
concentrations (middle panels), and rates (right panels) of neurons that should (top row) or should
not (bottom row) participate in the memory pattern being retrieved. Note that firing phases in the top
row are plotted as a difference from the stored firing phases so that ? = 0 means perfect retrieval.
Color code shows precision (blue: low, yellow: high) of the phase of the input to neurons, with red
lines showing cells receving incorrect input rate.

4

Simulations

Figure 2 shows the course of recall in the full network (with N = 100 neurons, and 10 stored patterns
with pz = 0.5). For didactic convenience, we consider the case that the noise in the phase input
was varied systematically for different neurons within a recall cue (a fact known to the network, ie
incorporated into its dynamics), so that it is possible to see how the differential certainty evolves over
the course of the network?s dynamics. The top left panel shows that neurons that should fire in the
memory trace (ie for which z = 1) quickly converge on their correct phase, and that this convergence
usually takes a longer time for neurons receiving more uncertain input. This is paralleled by the
way their firing concentrations change (top middle panel): neurons with reliable input immediately
increase their concentrations from the initial ?(c) = 0.5 value to ?(c) = 1, while for those having
more unreliable input it takes a longer time to build up confidence about their firing phases (and by
the time they become confident their phases are indeed correct). Neurons that should not fire (z = 0)
build up their confidence even more slowly, more often remain fairly uncertain or only moderately
certain about their firing phases, as expressed by their concentrations (middle bottom panel) ? quite
righteously. Finally, since the firing rate input to the network is correct 90%, most neurons that
should or should not fire do or do not fire, respectively, with maximal certainty about their rate (top
and bottom right panels).
Various other metrics are important for providing insight into the operation of the network. In
particular, we may expect there to be a relationship between the actual error in the phase of firing
of the neurons recalled by the memory, and the firing rates and concentrations (in the form of burst
strengths) of the associated neurons themselves. Neurons which are erring should whisper rather
than shout. Figure 3A shows just this for the network. Here, we have sorted the neurons according to
their burst strengths ?, and plotted histograms of errors in firing phase for each group. The lower the
burst strength, the more likely are large errors ? at least to an approximation. A similar relationship
exists between recalled (analogue) and stored (binary) firing rates, where extreme values of the
recalled firing rate indicate that the stored firing rate was 0 or 1 with higher certainty (Figure 3B).
Figure 3C shows the results of a related analysis of experimental data kindly donated by Francesco
Battaglia. He recorded neurons in hippocampal area CA1 (not CA3, although we may hope for
some similar properties) whilst rats were shuttling on a linear track for food reward. CA1 neurons
have place fields ? locations in the environment where they respond with spikes ? and the phases of
these spikes relative to the ongoing theta oscillation in the hippocampus are also known to convey
information about location in space [5]. To create the plot, we first selected epochs with highquality and high power theta activity in the hippocampus (to ensure that phase is well estimated).
We then computed the mean firing phase within the theta cycle, ?, of each neuron as a function of the
location of the rat, separately for each visit to the same location. We assumed that the ?true? phase
x a neuron should recall at a given location is the average of these phases across different visits. We

B

Frequency

0.5
0.4
0.3
0.2

0.2
1
0.8
0.6
0.4

0.1

burst strength
(spikes / cycle)
0!0.5
0.5!1.5
1.5!2.5
2.5!3.5
3.5!4.5

0.2
0

0.1
0
!"

C
Frequency

0.6

burst strength
0.05
0.2
0.4
0.7

Stored firing rate

A

0
Error in firing phase

"

0

0.2 0.4 0.6 0.8 1
Retrieved firing rate

0
!"

0
?Error? in firing phase

"

Figure 3: Uncertainty signals are predictive of the error a cell is making both in simulation (A,B),
and as recorded from behaving animals (C). Burst strength signals overall uncertainty about and thus
predicts error in mean firing phase (A,C), while graded firing rates signal certainty about whether to
fire or not (B).

then evaluated the error a neuron was making at a given location on a given visit as the difference
between its ? in that trial at that location and the ?true? phase x associated with that location. This
allowed us to compute statistics of the error in phase as a function of the burst strength. The curves
in the figure show that, as for the simulation, burst strength is at least partly inversely correlated with
actual phase error, defined in terms of the overall activity in the population. Of course, this does not
constitute a proof of our representational theory.
One further way to evaluate the memory is to compare it to two existing associative memories that
have previously been studied, and can be seen as special cases. On one hand, our memory adds
the dimension of phase to the uncertainty-aware rate-based memory that Sommer & Dayan [14]
studied. This memory made a somewhat similar variational approximation, but, as for the meanfield Boltzmann machine [17], only involving r and ?(r) and no phases.
On the other hand, the memory device can be seen as adding the dimension of rate to the phase-based
memory that Lengyel & Dayan [4] treated. Note, however, that although this phase-based network
used superficially similar probabilistic principles to the one we have developed here, in fact it did
not operate according to uncertainty, since it made the key simplification that all neurons participate
in all memories, and that they also fire exactly one spike on every cycle during recall. This restricted
the dynamics of that network to perform maximum a posteriori (MAP) inference to find the single
recalled pattern of activity that best accommodated the probabilistic constraints of the cue, the prior
and the synaptic weights, rather than being able to work in the richer space of probabilistic recall of
the dynamics we are suggesting here.
Given these roots, we can follow the logic in figure 4 and compare the performance of our memory
with these precursors in the cases for which they are designed. For instance, to compare with the
rate-based network, we construct memories which include phase information. During recall, we
present cues with relatively accurate rates, but relatively inaccurate phases, and evaluate the extent
to which the network is perturbed by the presence of the phases (which, of course, it has to store
in the single set of synaptic weights). Figure 4A shows exactly this comparison. Here, a relatively
small network (N = 100) was used, with memories that are dense (pz = 0.5), and it is therefore
a stringent test of the storage capacity. Performance is evaluated by calculating the average error
made in recalled firing rates).
In the figure, the two blue curves are for the full model (with the phase information in the input
being relatively unreliable, its circular concentration parameter distributed uniformly between 0.1
and 10 across cells); the two yellow curves are for a network with only rates (which is similar to
that described, but not simulated, by Sommer & Dayan [14]). Exactly the same rate information
is provided to all networks, and is 10% inaccurate (a degree known to the dynamics in the form of
?0 and ?1 ). The two flat dashed lines show the performance in the case that there are no recurrent
synaptic weights at all. This is an important control, since we are potentially presenting substantial
information in the cues themselves. The two solid curves show that the full model tracks the reduced,
rate-based, model almost perfectly until the performance totally breaks down. This shows that the
phase information, and the existence of phase uncertainty and processing during recall, does not

A

B

0.45

0.9

0.4

0.8
0.7

0.3

Average error

Average error

0.35

0.25
0.2
0.15

rate!coded model w/o learning
rate!coded model
full model w/o learning
full model

0.1
0.05
0

0.6
0.5
0.4
phase!coded model w/o learning
phase!coded model
full model w/o learning
full model

0.3
0.2
0.1

1

10
100
Number of stored patterns

1000

1

10
100
Number of stored patterns

1000

Figure 4: Recall performance compared with a rate-only network (A) and a phase-only network (B).
The full model (blue lines) performs just as well as the reduced ?specialist? models (yellow lines)
in comparable circumstances (when the information provided to the networks in the dimension they
shared is exactly the same). All models (solid lines) outperform the standard control of using the
input and the prior alone (dashed lines).
corrupt the network?s capacity to recall rates. Given its small size, the network is quite competent
as an auto-associator.
Figure 4B shows a similar comparison between this network and a network that only has to deal
with uncertainty in firing phases but not in rates. Again, its performance at recalling phase, given
uncertain and noisy phase cues, but good rate-cues, is exactly on a par with the pure, phase-based
network. Further, the average errors are only modest, so the capacity of the network for storing
analog phases is also impressive.

5

Discussion

We have considered an interpretation of the activities of neurons in oscillating structures such as area
CA3 of the hippocampus as representing distributions over two underlying quantities, one binary and
one analogue. We also showed how this representational capacity can be used to excellent effect in
the key, uncertainty-sensitive computation of memory recall, an operation in which CA3 is known to
be involved. The resulting network model of CA3 encompasses critical aspects of its physiological
properties, notably information-bearing firing rates and phases. Further, since it generalizes earlier
theories of purely phase-based memories, this model is also consistent with the measured phase
response curves of CA3 neurons, which characterize their actual dynamical interactions.
Various aspects of this new theory are amenable to experimental investigation. First, the full dynamics (see the supplementary material) imply that firing rate and firing phase should be coupled
together both pre-synpatically, in terms of the influence of timed input spikes, and post-synaptically,
in terms of how changes in the activity of a neuron should depend on its own activity. In vitro experiments along the lines of those carried out before [16], in which we have precise experimental
control over pre- and post-synaptic activity can be used to test these predictions. Further, making
the sort of assumptions that underlie figure 3C, we can use data from awake behaving rats to see if
the gross statistics of the changes in the activity of the neurons fit the expectations licensed by the
theory.
From a computational perspective, we have demonstrated that the network is a highly competent
associative memory, correctly recalling both binary and analog information, along with certainty
about it, and degrading gracefully in the face of overload. In fact, compared with the representation
of other analogue quantities (such as the orientation of a visually preseted bar), analogue memory
actually poses a particularly tough problem for the representation of uncertainty. This is because
for variables like orientation, a whole population is treated as being devoted to the representation
of the distribution of a single scalar value. By contrast, for analogue memory, each neuron has an
independent analogue value, and so the dimensionality of the distribution scales with the number of
neurons involved. This extra representational power comes from the ability of neurons to distribute

their spikes within a cycle to indicate their uncertainty about phase (using the dimension of time in
just the same way that distributional population codes [12] used the dimension of neural space).
This dimension for representing analogue uncertainty is coupled to that of the firing rate for representing binary uncertainty, since neurons have to fire multiple times in a cycle to have a measurable
lack of concentration. However, this coupling is exactly appropriate given the form of the distribution assumed in equation 2, since weakly firing neurons express only weak certainty about phase
in any case. In fact, it is conceivable that we could combine a different model for the firing rate
uncertainty with this model for analogue uncertainty, if, for instance, it is found that neuronal firing
rates covary in ways that are not anticipated from equation 2.
Finally, the most important direction for future work is understanding the uncertainty-sensitive coupling between multiple oscillating memories, where the oscillations, though dynamically coordinated, need not have the same frequencies. Exactly this seems to characterize the interaction between the hippocampus and the necortex during both consolidation and retrieval [18, 19].
Acknowledgments
Funding from the Gatsby Charitable Foundation. We are very grateful to Francesco Battaglia for
allowing us to use his data to produce figure 3C, and to him, and Ole Paulsen and Jeehyun Kwag for
very helpful discussions.
References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]

?
Szaliszny?o K, Erdi
P. In The Handbook of Brain Theory and Neural Networks, 533, 2003.
Hopfield JJ. Nature 376:33, 1995.
Yoshioka M. Physical Review E 65, 2001.
Lengyel M, Dayan P. In Advances in Neural Information Processing Systems 17, 769, Cambridge, MA,
2005. MIT Press.
O?Keefe J, Recce ML. Hippocampus 3:317, 1993.
Huxter J, et al. Nature 425:828, 2003.
Ernst M, Banks M. Nature 415:429, 2002.
K?ording K, Wolpert D. Nature 427:244, 2004.
Gold JI, Shadlen MN. Neuron 36:299, 2002.
Hinton G. Neural Comput 1:143, 1990.
Peterson C, Anderson J. Complex Systems 1:995, 1987.
Pouget A, et al. Annu Rev Neurosci 26:381, 2003.
MacKay DJC. In Maximum Entropy and Bayesian Methods, Laramie, 1990, 237, 1991.
Sommer FT, Dayan P. IEEE Trans Neural Netw 9:705, 1998.
Fisher NI. Statistical analysis of circular data. Cambridge University Press, 1995.
Lengyel M, et al. Nat Neurosci 8:1677, 2005.
Dayan P, Abbott LF. Theoretical Neuroscience. MIT Press, 2001.
Siapas AG, Wilson MA. Neuron 21:1123, 1998.
Jones M, Wilson M. PLoS Biol 3:e402, 2005.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

