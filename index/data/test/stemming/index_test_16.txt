query sentence: Storing potentiation of synaptic strengths
---------------------------------------------------------------------
title: 100-storing-covariance-by-the-associative-long-term-potentiation-and-depression-of-synaptic-strengths-in-the-hippocampus.pdf

store covari associ long term potenti depress synapt strength hippocampus patric k. stanton terrenc j. sejnowski depart biophys john hopkin univers baltimor md abstract model studi memori base neural network select enhanc depress synapt strength requir ror effid storag inrorm sejnowski kohonen bienenstock ai sejnowski tesauro test assumpt hippocampus cortic structur brain involv long-term memori brier high-frequ activ excitatori synaps hippocampus produc increas synapt strength known long-term potenti ltp buss lomo last ror mani day ltp known hebbian sinc requir simultan releas neurotransmitt presynapt termin coupl postsynapt depolar kelso al malinow miller gustatrson al howev mechan ror persist reduct synapt strength could balanc ltp yet demonstr studi associ interact separ input onto dendrit tree hippocamp pyramid cell field cal round low-frequ input itselr persist chang synapt strength either increas associ ltp decreas strength associ long-term depress ltd depend upon whether posit negat correl time second high-frequ burst input ltp synapt strength hebbian ltd anti-hebbian sinc elicit pair presynapt fire postsynapt hyperpolar suffici block postsynapt activ thus associ ltp associ lto capabl store inrorm contain covari separ converg hippocamp input present address dep~ent new'osci neurolog albert einstein colleg medicin pelham parkway south bronx ny usa tpresent address comput neurobiolog laboratori salk institut p.o box san diego ca usa store covari synapt strength hippocampus introduct associ ltp produc hippocamp neuroo lowfrequ weak high-frequ strong input cell simultan activ levi steward levi steward barrionuevo brown stimul alon weak input long-last effect synapt strength howev pair stimul separ strong input suffici produc homo synapt ltp pathway weak pathway associ potenti neural network model studi predict addit hebbian form plastic synapt strength weaken weak strong input anti-correl sejnowski kohonen bienenstock al sejnowski tesauro evid heterosynapt depress hippocampus found input inact levi steward lynch al weak activ levi steward stimul strong input depress depend pattern weak input activ typic long-last ltp therefor search condit stimul hippocamp pathway rather inact could produc either long-term depress potenti synapt strength depend pattern stimul stimulus paradigm use illustr i base find burst stimuli hz optim elicit ltp hippocampus larson lynch highfrequ burst s'irong stimulus appli schaffer collater axon lowfrequ weak stimulus given separ subicular input come opposit side record site termin dendrit popul cal pyramid neuron due rhythmic natur strong input burst weak input shock could either superimpos middl burst strong input phase place symmetr burst phase result extracellular evok field potenti record apic dendrit somat layer cal pyramid cell weak stimulus train first appli alon induc long-last chang strong site stimul alon elicit homosynapt ltp strong pathway signific alter amplitud respons weak input weak strong input activ phase associ ltp weak input synaps shown synapt excitatori post-synapt potenti popul action potenti pike signific enhanc least min min follow stimul contrast weak strong input appli phase elicit associ long-term depress lto weak input synaps shown there mark reduct popul spike smaller decreas note stimulus pattern appli input ident two experi relat stanton sejnowski phase weak strong stimuli alter stimulus pattern synapt strength could repeat enhanc depress singl slice illustr fig control experi determin whether inform concern covari input actual determin plastic combin phase phase condit give weak input shock superimpos burst plus burst net frequenc hz pattern result zero covari weak strong input produc net chang weak input synapt strength measm extracellular evok potenti thus assoa a.ssocia.t stimulus pa.ra.digm posjtive.li corkela ted phase si1iong njo\it u.jj1l negat correl phase w akin'ltf stiong i figur hippocamp slice prepar stimulus paradigm vitro hippocamp slice show record site cal pyramid cell somat stratum pyramidal dendrit stratum radiatum layer stimulus site activ schaffer collater strong commissur weak affer hippocamp slice jlm thick incub interfac slice chamber c. extracellular m l resist 2m naci fill intracellular 2m k-acet fill record electrod bipolar glass-insul platinum wire stimul electrod jlm tip diamet prepar standard method modi al stimulus paradigm use strong input stimuli strong input four train hz burst burst stimuli interburst interv msec train last second total stimuli weak input stimuli weak input four train shock hz frequenc train last second when input phase weak singl shock superimpos middl each burst strong input when weak input phase singl shock place symmetr burst store covari synapt strength hippocampus ciativ ltp ltd mechan appear balanc manner ideal storag tempor covari relat simultan depolar postsynapt membran activ glutam receptor n-methyl-d-aspart nmda subtyp appear necessari ltp induct collingridg harri al wigstrom gustaffson sj read current strong weak synaps dendrit tree associ lon .te i'otenti long-t de /tession associ i i i i i i figur mustrat associ long-term potenti ltp associ longterm depress ltd use extracellular record associ ltp evok excitatori postsynapt potenti popul action potenti respons weak inpul test respons shown pre min post applic weak stimuli phase coactiv strong input associ ltd evok popul spike respons weak input test respons shown pre min post applic weak stimuli phase coactiv strong input time cours chang popul spike amplitud observ each input typic experi test respons strong input open circl show high-frequ burst pulses/l00 hz msec interburst interv elicit synapse-specif ltp independ input activ test respons weak input fill circl show stimul weak pathway out phase strong one produc associ ltd assoc ltd input associ ltp assoc ltp pathway elicit follow phase stimul amplitud durat associ ltd ltp could increas stimul input pathway train shock stanton sejnowski coupl releas glutam weak input could account abil strong pathway associ potenti weak one kelso al malinow miller gustaffson al consist hypothesi we find nmda receptor antagonist 2-amino-s-phosphonovaler acid ap block induct associ ltp cal pyramid neuron data shown contrast applic ap bath solut concentr signific effect associ ltd data shown thus induct ltd seem involv cellular mechan differ associ ltp condit necessari ltd induct explor anoth seri experi use intracellular record cal pyramid neuron made use standard techniqu modi al induct associ ltp fig weak s+w phase produc increas amplitud singl cell evok lower action potenti threshold weak pathway report previous barrionuevo brown convers induct associ ltd weak s+w out phase accompani long-last reduct amplitud reduc abil elicit action potenti fire control extracellular experi weak input alon produc long-last alter intracellular fire properti strong input alon yield specif increas strong pathway without alter elicit weak input stimul pre min post s+w out phase min post s+w phase figur demonstr associ ltp ltd use intracellular record cal pyramid neuron intracellular prior repetit stimul min out phase stimul out phase min subsequ phase stimuli phase strong input schaffer collater side lower trace exhibit ltp evok independ weak input activ out phase stimul weak subicular side upper trace pathway produc mark persist reduct amplitud cell subsequ phase stimuli result associ ltp weak input revers ltd enhanc amplitud past origin baselin rmp my rn mo store covari synapt strength hippocampus weak stimulus out phase strong one aniv when postsynapt neuron hyperpolar consequ inhibitori postsynapt potenti afterhyperpolar mechan intrins pyramid neuron this suggest postsynapt hyperpolar coupl presynapt activ may trigger l'id test this hypothesi we inject current intracellular microelectrod hyperpolar depolar cell stimul synapt input pair inject depolar current weak input led ltp synaps stim pre idpost s'i1m depol coi'itrol jj i w.c ulvllj pre loliiin post stlm hyperpol figur pair postsynapt hyperpolar stimul synaps cal hippocamp pyramid neuron produc l'id specif activ pathway pair postsynapt depolar synapt stimul produc synapsespecif ltp intracellular evok shown stimul stim unstimul control pathway synaps pre min post pair my depolar constant current na hz synapt stimul stimul pathway exhibit associ ltp control unstimul input show chang synapt strength rmp my rn mfl intracellular shown evok stimul control pathway synaps pre min post pair mv hyperpolar constant current na hz synapt stimul input stim activ hyperpolar show associ ltd synapt evok synapt strength silent input control unalt rmp mv rn stanton sejnowski control input inact stimul chang control report previous kelso al malinow miller gustaffson al convers prolong hyperpolar current inject pair low-frequ stimuli led induct ltd stimul pathway stim unstimul pathway control applic either depolar current hyperpolar current weak hz synapt stimul alon induc long-term alter in synapt strength thus hyperpolar simultan presynapt activ suppli suffici condit induct ltd in cal pyramid neuron conclus these experi identifi a novel fono anti-hebbian synapt plastic in the hippocampus confirm predict made model studi inform storag in neural network unlik previous report of synapt depress in the hippocampus the plastic associ long-last produc when presynapt activ occur the postsynapt membran hyperpolar in combin hebbian mechan also present hippocamp synaps associ ltp associ ltd may allow neuron in the hippocampus comput store covari input sejnowski stanton sejnowski these find make tempor as well as spatial context import featur of memori mechan in the hippocampus elsewher in the brain the recept field properti of cell in cat visual cortex alter visual experi pair iontophoret excit depress of cellular activ fregnac al greuel al in particular the chronic hyperpolar of neuron in visual cortex coupl with presynapt transmitt releas lead a long-teno depress of the activ inact input the later genicul nucleus reiter stryker thus both hebbian anti-hebbian mechan found in the hippocampus seem also present in brain area covari of fire pattern converg input a like key understand higher cognit function this research support by grant the nation scienc foundat the offic of naval research to tjs we thank drs charl steven and richard morri discuss relat experi
----------------------------------------------------------------

title: 4871-correlations-strike-back-again-the-case-of-associative-memory-retrieval.pdf

correl strike back case associ memori retriev cristina savin1 cs664 cam.ac.uk peter dayan2 dayan gatsby.ucl.ac.uk m e lengyel1 m.lengyel eng.cam.ac.uk comput biolog learn lab dept engin univers cambridg uk gatsbi comput neurosci unit univers colleg london uk abstract long recognis statist depend neuron activ need taken account decod stimuli encod neural popul less studi though equal pernici need take account depend synapt weight decod pattern previous encod auto-associ memori show activity-depend learn generic produc correl fail take account dynam memori retriev lead catastroph poor recal deriv optim network dynam recal face synapt correl caus rang synapt plastic rule dynam involv well-studi circuit motif form feedback inhibit experiment observ dendrit nonlinear therefor show address problem synapt correl lead novel function account key biophys featur neural substrat introduct auto-associ memori vener histori comput neurosci howev rather recent statist revolut wider field provid theoret traction problem idea see memori storag form lossi compress inform item store map set synapt chang neural dynam retriev repres biolog analog correspond decompress algorithm impli tight inde testabl link learn rule use encod neural dynam use retriev one issu either ignor trivial treatment recal correl among synaps beyond perfect anti- correl emerg reciproc synaps precis anti- symmetr learn rule ampl experiment data exist correl exampl rat visual cortex synapt connect tend cluster togeth form overrepres pattern motif reciproc connect much common expect chanc strength connect neuron correl studi neural code indic essenti treat correl neural activ appropri order extract stimulus inform well similar becom press examin natur correl among synapt weight auto-associ memori consequ retriev ignor method might accommod here consid sever well-known learn rule simpl addit one bound synaps metaplast show signific except induc correl synaps share pre post-synapt partner assess import depend recal adopt strategi compar perform decod either take account show inde import effect effici retriev final show approxim optim retriev involv particular form nonlinear interact differ neuron input observ experiment general problem formul consid network binari neuron enjoy all-to-al connectivity.1 convent inde plausibl underpin neuromodulatori interact assum network dynam play role storag stimuli impos pattern activ neuron learn occur retriev isol effect differ plastic rule synapt correl sourc correl assum pattern activ induc synapt chang particular structur distribut factor simplic take activ pattern binari pattern densiti prior pattern defin pstore pstore pstore recal network present cue noisi partial version one origin store pattern network dynam complet partial pattern use inform weight cue start consid arbitrari dynam later impos critic constraint biolog realis strict local activ neuron depend exclus input incom synaps sinc inform storag synapt plastic lossi recal inher probabilist infer problem requir estim posterior pattern given inform weight recal cue pstore pnois formul form foundat recent work construct effici autoassoci recal dynam rang differ learn rule paper focus last term express probabl obtain synapt weight matrix store along random pattern sampl prior critic diverg previous analys assum distribut factoris trivial correl due reciproc synaps precis anti- symmetr contrast explicit studi emerg effect non-trivi correl synapt weight matrixdistribt almost synapt plastic rule induc statist depend synapt weight neuron infer problem express translat neural dynam sever way dynam could determinist attractor-lik converg like pattern map estim distribut mean-field approxim solut altern dynam could stochast activ time repres sampl posterior henc implicit captur uncertainti associ answer consid latter sinc estim perform averag error optim respons mean posterior estim integr activ network retriev start analys class addit learn rule get sens effect correl retriev later focus multi-st synaps learn rule describ transit probabl state use captur varieti import biolog constraint bound synapt strength metaplast fact synapt chang induc certain activ pattern depend histori activ synaps two class learn rule radic differ synapt correl matter retriev case conclus like appli general complet connect simplifi comput paramet optim dynam cascadelik learn rule consid follow necessari theori covari rule simpl hebb rule cortic data song error corr error corr control exact consid correl simpl ignor correl control figur memori recal infer addit learn rule top synapt weight aris store target pattern togeth pattern dure noisi version target pattern task recal infer given recal cue marginalis bottom activ neuron across store pattern sourc share variabl synaps connect neuron covari rule pattern synapt correl recal perform retriev dynam ignor consid synapt correl simpl hebbian learn rule control optim decod ignor w. addit learn rule local addit learn rule assum synapt chang induc differ activ pattern combin addit store sequenc pattern pstore result weight wij function describ chang synapt strength induc presynapt activ postsynapt activ consid general hebbian form function class includ exampl covari rule classic use hopfield network simpl hebbian learn synapt chang determinist sourc uncertainti distribut ident store pattern estim let us first consid distribut weight store one random pattern pstore mean covari weight chang induc event comput pstore pstore dx sinc rule addit pattern independ mean covari scale linear number interven pattern henc distribut possibl weight valu recal given pattern store along random pattern mean covari cw c. import rule addit limit mani store pattern practic even modest valu distribut approach multivari gaussian character complet two quantiti moreov covari independ retriev dynam base gibb sampl key quantiti log-odd ratio p xi ii log p xi neuron could repres total current enter unit would translat probabl fire given sigmoid activ function ii e ii total current enter neuron sum two term one term extern input form c1 c2 constant c1 c2 determin paramet one term recurr input form iirec notat conveni use column-vector form matrix weight chang weight matrix mark subscript vector activ obtain activ neuron set respect easi see covari rule synaps share singl pre post-synapt partner happen uncorrel moreov anti- symmetr addit learn rule reciproc connect perfect correl wij wji non-degener part covari matrix case becom diagon total current optim retriev reduc simpl linear dynam ii wij recurr input 2f 2f wij feedback inhibit homeostat term constant varianc synapt weight result store singl pattern term includ contribut recurr excitatori input dynam feedback inhibit proport total popul activ homeostat term reduc neuron excit function net strength synaps proxi averag current neuron expect receiv reassur optim decod covari rule recov form input current close relat classic hopfield-lik dynam extern field feedback inhibit need store pattern balanc balanc case homeostat term integr recurr current rewrit neural activ spin sum covari rule synaps fortuit uncorrel except symmetr pair perfect correl thus simpl classic linear recal dynam suffic covari rule howev except rather rule exampl simpl hebbian learn synaps share pre post-synapt partner correl covari matrix longer diagon interest final express recurr current neuron remain strict local addit symmetri similar feedback inhibit becom non-linear function total activ network case synapt correl dramat effect use optim non-linear dynam ensur high perform tri retriev inform use decod assum synapt independ thus use linear dynam yield extrem poor perform even wors obvious control reli inform recal cue prior pattern general hebbian case optim decod becom even complex total current includ addit term account pairwis correl two synaps neuron pre post-synapt partner henc retriev longer strict local3 biolog implement requir approxim contribut non-loc term function local avail inform discuss detail palimpsest learn palimpsest learn rule though addit learn rule attract analyt tractabl ignor sever import aspect synapt plastic assum synaps grow without bound investig effect bound weight consid anoth class learn rule assum synapt efficaci take binari valu stochast transit two underpin pair cascad latent intern state learn rule though simpl captur import aspect memori fact memori leaki inform past overwritten newli store item usual refer palimpsest properti addit rule account experiment observ synapt metaplast addit learn rule current neuron alway depend synaps local neuron also includ outgo synaps weight w influenc dynam refer dynam semi-loc learn rule optim current neuron may depend connect network includ wjk non-loc dynam r1 post r2 r3 pre cortex data song correl synaps error correl coeffici pseudostorag exact approx simpl dynam corr-depend dynam figur palimpsest learn cascad model color circl latent state belong two differ synapt weight arrow state transit blue depress red potenti differ variant map pre post-synapt activ depress potenti r1 postsynapt gate r2 presynapt gate r3 xor rule correl structur induc these learn rule retriev perform rule learn rule learn stochast local chang state synaps vij determin activ pre post-synapt neuron general one could defin separ transit matric activ pattern m xi describ probabl synapt state transit two state vij vij0 follow activ pattern simplic defin two matric potenti depress respect map differ activ pattern these event particular assum fusi cascad model three possibl map 2b postsynapt gate learn rule chang occur postsynapt neuron activ co-activ pre post neuron lead potenti depress otherwise5 presynapt gate learn rule typic assum analys cascad xor-lik learn rule assum potenti occur whenev pre post synapt activ level depress otherwis last rule propos ref specif design elimin correl synaps view version classic covari rule fashion binari synaps estim mean covari synapt weight level singl synaps present sequenc uncorrel pattern pstore correspond markov random walk defin transit matrix averag possibl neural activ pattern pstore pstore m xi distribut synapt state step initi encod calcul start stationari distribut weight assum larg number pattern previous store formal eigenvector correspond eigenvalu store pattern final pattern prior m xi lv distribut state given column vector p vij l|xi depth cascad last distribut weight p wij deriv mv mv determinist map state observ weight addit case state synaps share pre post synapt partner correl fig degre correl differ synapt configur estim generalis procedur comput joint distribut state pair synaps repres matrix e.g pair synaps share postsynapt partner fig element uv p vpost pre1 vpost pre2 henc present activ pattern xpre1 xpre2 xpost induc chang correspond pair model serial could use well without qualit affect result one could argu biolog relev plastic often nmda-receptor depend henc requir postsynapt depolaris effect occur incom synaps neuron post m xpost xpre1 m xpost xpre2 stationari distribut correspond store infinit number triplet pattern distribut replac function triplet xpre1 xpre2 xpost multipl slight complic oper estim evolut joint distribut synapt state manner similar m x pstore m x m x pstore m xi also final joint distribut state map joint distribut synapt weight mv mt approach natur extend correl pair synaps structur correl differ synapt pair vari signific function learn rule overal degre correl depend rang factor correl tend decreas cascad depth pattern sparsiti first two variant learn rule consid symmetr induc differ pattern correl addit rule xor rule similar covari rule reciproc connect longer perfect correl due metaplast mean longer possibl factor henc assum independ decod seem bound introduc error approxim optim retriev synaps independ if ignor synapt correl evid weight factor j p wij exact dynam would semi-loc we approxim contribut outgo weight mean recov simpl dynam deriv addit case p xi ii log c1 wij c2 wij c3 c4 x c5 p xi paramet depend prior nois model paramet learn rule optim decod similar previous deriv attractor dynam particular stochast binari synaps presynapt gate learn optim dynam requir dynam inhibit spars pattern homeostat term use valid these dynam we remov synapt correl pseudo-storag procedur synaps allow evolv independ accord transit matrix rather chang actual intermedi pattern store dynam work well this case expect blue bar howev store actual pattern drawn prior perform becom extrem poor often wors control gray bar moreov perform worsen network size increas shown henc ignor correl high detriment this class learn rule approxim optim retriev synaps correl accommod synapt correl we approxim maximum entropi distribut margin covari structur ignor higher order moments.6 specif we assum evid weight function form 1x exp kij wij j ij kl wij wkl ij ijkl we use tap mean-field method find paramet partit function possibl activ pattern given mean covari synapt weight matrix comput above7 this generalis simpl dynam assum first order max entropi model moreov result weight distribut binari analog multivari normal use addit case allow two direct compar here we ask whether possibl accommod correl appropri neural dynam ignor issu optim valu paramet network dynam would come corr corr number coactiv input number coactiv input normal epsp tip middl postsynapt current postsynapt current base number input figur implic neural dynam paramet iirec linear modul network activ nb nonlinear modul pairwis term network activ middl panel paramet linear depend nb total current pfunction number coactiv input wij line differ level neural excit wij line width scale frequenc occurr sampl run r2 nonlinear integr dendrit reproduc cf curv exact retriev dynam base respect local constraint work substanti better presenc synapt correl rule yellow bar import note xor rule suppos closest analog covari rule henc afford simpl recal dynam error rate stay control suggest it actual case even depend beyond 2nd-order correl would need consid addit case exact recal dynam biolog implaus total current neuron depend full weight matrix it possibl approxim dynam use strict local inform replac nonloc term mean howev longer constant rather linear function total activ network nb this approxim current recurr connect correspond evid weight becom 1x j4 x wij wik iirec log ij ij jk index neuron updat activ vector to-be-upd neuron activ set respect other compon given current network state function kij kij kij j ij kl j ij kl log log depend local activ index synaps modul number activ neuron network nb this approxim again consist previous analysi absenc synapt correl complex dynam recov simpl case present import this approxim also well as exact dynam red bar post-synapt gate learn compar paramet dynam case independ versus correl synaps reveal modest modul recurr input total activ import net current postsynapt neuron depend non-linear formal quadrat number co-act input nw wij reminisc experiment observ dendrit non-linear convers presynapt gate learn rule approxim optim dynam predict non-monoton modul activ later inhibit linear neural integr last retriev base xor rule same form as simpl dynam deriv factor case howev total current rescal compens correl introduc reciproc connect differ two rule emerg exclus constraint strict local approxim sinc exact form dynam essenti same two addit cascad rule covari simpl hebbian general hebbian presyn gate postsyn gate xor exact dynam strict local linear strict local nonlinear semi-loc nonlinear nonloc nonlinear nonloc nonlinear beyond correl neural implement linear feedback inh homeostasi nonlinear feedback inh nonlinear feedback inh nonlinear feedback inh linear dendrit integr linear feedback inh non-linear dendrit integr tabl result summari circuit adapt correl for differ learn rule discuss statist depend synapt efficaci natur consequ activ depend synapt plastic yet implic for network function unexplor here context auto-associ memori network we investig pattern synapt correl induc sever well-known learn rule consequ effect retriev we show most rule consid inde induc synapt correl fail take account great damag recal one fortuit except covari rule for synapt correl this might explain bulk classic treatment autoassoci memori use covari rule could achiev satisfi capac level despit overlook issu synapt correl general take correl account optim dure recal requir dynam non-loc interact neuron howev we deriv approxim perform well biolog realis without non-loc tabl exampl includ modul neural respons total activ popul could mediat feedback inhibit specif dendrit nonlinear particular for post-synapt gate learn rule may view as abstract model hippocamp nmda receptor-depend plastic model predict form non-linear map recurr input postsynapt current similar experiment observ dendrit integr in cortic pyramid cell in general tight coupl the synapt plastic use for encod manifest in pattern synapt correl circuit dynam offer import rout for experiment valid none the rule govern synapt plastic we consid perfect reproduc the pattern correl in inde exact rule appli in region the brain neuromodulatori influenc unclear furthermor result in concern the neocortex rather the hippocampus more common target for model auto-associ memori nonetheless analysi shown synapt correl matter for rang differ learn rule span the spectrum empir observ anoth strategi handl the negat effect synapt correl to weaken elimin for instanc in the palimpsest synapt model the deeper the cascad the weaker the correl metaplast may the benefici effect make recal easier anoth popular idea to use spars pattern although this reduc the inform content one more specul one might imagin process off-lin synapt prune recod in strong correl remov the weight adjust simpl recal method work here we focus second-ord correl howev for plastic rule as xor we show this suffic rather higher-ord correl would need to consid thus presum higher-ord interact neuron approxim final we know work neural code sensori stimuli there regim in correl either help hurt the inform qualiti the code assum decod take account given result it becom import to look at the relat qualiti differ plastic rule assum realiz decod it clear whether rule strive to elimin correl best one acknowledg this work support the wellcom trust the gatsbi charit foundat the european union seventh framework programm under grant agreement brainscal
----------------------------------------------------------------

title: 4872-a-memory-frontier-for-complex-synapses.pdf

memori frontier complex synaps subhaneil lahiri surya ganguli depart appli physic stanford univers stanford ca sulahiri stanford.edu sganguli stanford.edu abstract incred gulf separ theoret model synaps often describ sole singl scalar valu denot size postsynapt potenti immens complex molecular signal pathway under real synaps understand function contribut molecular complex learn memori essenti expand theoret concept synaps singl scalar entir dynam system mani intern molecular function state moreov theoret consider alon demand expans network model scalar synaps assum finit number distinguish synapt strength strike limit memori capac rais fundament question synapt complex give rise memori address develop new mathemat theorem elucid relationship structur organ memori properti complex synaps molecular network moreov prove theorem uncov framework base first passag time theori impos order intern state complex synapt model therebi simplifi relationship synapt structur function introduct wide thought abil rememb past long time scale depend crucial abil modifi synaps brain experi depend manner classic model synapt plastic model synapt efficaci analog scalar valu denot size postsynapt potenti inject one neuron anoth theoret work shown model reason extens memori capac number long term associ store neuron proport number affer synaps howev recent experiment work shown mani synaps digit analog robust assum infinit continuum analog valu rather take finit number distinguish strength number small two though see one simpl modif lead catastroph memori capac classic model digit synaps oper palimpset mode ongo storag new memori overwrit previous memori memori capac proport logarithm number synaps intuit synaps digit storag new memori flip popul synapt switch therebi rapid eras previous memori store synapt popul result indic domin theoret basi storag long term memori modifi synapt switch flaw recent work suggest way logarithm catastroph expand theoret concept synaps singl scalar valu entir stochast dynam system right conceptu expans necessit experiment realiti synaps contain within immens complex molecular signal pathway mani intern molecular function state see extern synapt efficaci could digit candid pattern electr activ lead potenti depress could yield transit intern molecular state without necessarili induc associ chang synapt efficaci form synapt chang known metaplast allow probabl synapt potenti depress acquir rich depend histori prior chang efficaci therebi potenti improv memori capac theoret studi complex metaplast synaps focus analyz memori perform limit number specif molecular dynam system character number intern state potenti depress induc specif set allow transit state see figur while model vast outperform simpl binari synapt switch analys leav open sever deep import question exampl structur synapt dynam system determin memori perform fundament limit memori perform space possibl synapt dynam system structur organ synapt dynam system achiev limit moreov experiment perspect unlik synaps describ singl canon synapt model like case neuron incred divers molecular network under synaps across speci across brain region within singl organ order elucid function contribut divers molecular complex learn memori essenti move beyond analysi specif model instead develop general theori learn memori complex synaps moreov general theori complex synaps could aid develop novel artifici memori storag devic initi general theori prove upper bound memori curv associ synapt dynam system within well establish ideal observ framework along way develop principl base first passag time theori order structur synapt dynam system relat structur memori perform summar main result discuss section overal framework synapt model memori curv section describ class model synapt plastic studi quantifi memori perform subsequ section find upper bound perform use well establish formal studi learn memori complex synaps approach electr pattern activ correspond candid potenti depress plastic event occur random independ synaps poisson rate event reflect possibl synapt chang due either spontan network activ storag new memori let pot dep denot fraction event candid potenti depress event respect furthermor assum synapt model intern molecular function state candid potenti depotenti event induc stochast transit intern state describ discret time markov transit matrix mpot mdep framework state differ synaps independ entir synapt popul fulli describ probabl distribut across state indic row-vector thus th compon denot fraction synapt popul state furthermor state synapt weight take worst case scenario restrict two valu after shift scale two valu assum without loss general also employ ideal observ approach memori readout synapt weight read direct provid upper bound qualiti readout use neural activ singl memori store time assum ideal pattern synapt weight across popul synaps element vector ideal synaps experi candid potenti event synaps experi candid depress event time memori storag assum pattern synapt weight close ideal suffici recal memori howev actual pattern synapt weight later time chang due modif storag subsequ memori use overlap ideal measur qualiti memori system return steadi state distribut uncorrel cascad model serial model snr cascad serial time figur model complex synaps cascad model show transit state high/low synapt weight red/blu circl due potentiation/depress solid red/dash blue arrow serial model memori curv two model show decay signal-to-nois ratio defin subsequ memori store memori store probabl distribut quantiti ideal use null model comparison extent memori store describ signal-to-nois ratio snr hw ideal w hw ideal snr var w ideal nois denomin essenti correct potenti depress imbalanc affect upper bound discuss ignor subsequ formula simpl averag memori curv deriv follow preced plastic event prior put popul synaps steady-st distribut memori track chang intern state distribut mpot mdep synaps experi candid potenti depress event potentiating/depress natur subsequ memori independ ideal averag sequenc result evolut probabl distribut dp rp wf wf pot mpot dep mdep i. dt here wf continu time transit matrix model process forget memori store time due random candid potentiation/depress event occur synaps due storag subsequ memori stationari distribut result follow snr snr 2f pot dep mpot mdep ertw detail deriv formula found supplementari materi frequent refer function memori curv thought excess fraction synaps relat equilibrium maintain ideal synapt strength time dictat store memori time much previous work type complex synapt model focus understand memori curv specif model choic mpot/dep two exampl model shown figur see differ memori properti serial model perform relat well one particular timescal perform poor time cascad model perform quit well time maintain perform wider rang timescal work rather analyz specif model take differ approach order obtain general theori consid entir space model find upper bound memori capac space model fix number intern state parameter pair discret time stochast transit matric mpot mdep addit pot/dep paramet must satisfi follow constraint mpot/dep ij mpot/dep ij pot/dep pot dep wf pot/dep follow automat constraint upper bound mpot/dep ij critic question constraint impli space achiev memori curv answer question especi limit achiev memori finit time use employ eigenmod decomposit wf qa ua va va ub ab wf ua qa ua va wf qa va here qa negat eigenvalu forget process wf ua right column eigenvector va left row eigenvector decomposit allow us write memori curv sum exponenti snr ia e rt/ ia pot dep mpot mdep ua va ask question constraint quantiti name eigenmod initi snr ia time constant impli constraint deriv constraint next section upper bound achiev memori capac previous section describ analyt express memori curv function structur synapt dynam system describ pair stochast transit matric mpot/dep sinc perform measur memori entir memori curv singl number univers scalar notion optim memori space synapt dynam system instead tradeoff store proxim distal memori often attempt increas memori late earli time chang mpot/dep incur perform loss memori earli late time specif model consid far thus end goal achiev deriv envelop memori curv snr-time plane curv form upper-bound entir memori curv model order achiev goal section must first deriv upper bound space possibl synapt model two differ scalar function memori curv initi snr area memori curv process upper-bound area develop essenti framework organ structur synapt dynam system base first passag time theori bound initi snr give upper bound initi snr 2f pot dep mpot mdep possibl model also find class model satur bound use quantiti equilibrium probabl flux two disjoint set state xx ab rp wij j b initi snr close relat flux state wj supplementari materi inequ becom equal potenti never decreas synapt weight depress never increas properti sensibl model maxim flux potenti weak state must guarante end strong state depress must revers exampl model shown figur model properti known lumpabl discret time version continu time complet equival memori curv two state model transit probabl equal shown figur figur synapt model maxim initi snr potenti transit start weak state lead strong state probabl transit leav given weak state sum depress similar potenti strong weak interchang equival two state model transit probabl potenti depress equal one two state model equilibrium distribut dep pot flux given rf pot dep maxim pot dep lead upper bound note while model high initi snr also fast memori decay timescal 1r synaps plastic initi memori encod easili subsequ memori also overwrit rapid one exampl tradeoff optim memori earli versus late time impos order intern state first passag time goal understand relationship structur function space possibl synapt model complic fact space contain mani differ possibl network topolog encod nonzero matrix element mpot/dep systemat analyz entir space develop import organ principl use theori first passag time stochast process forget describ wf mean first passag time matrix tij defin averag time take reach state first time start state diagon element defin zero remark theorem exploit quantiti tij known kemeni constant independ start state intuit state averag time take reach state weight equilibrium probabl independ start state impli hidden constanc inher stochast process context complex synaps defin partial sum tij tij thought averag time take reach strong/weak state respect use definit impos order state arrang order decreas increas independ two order order depend sensit structur mpot/dep state later right figur consid potenti state earlier left figur despit fact synapt efficaci essenc order state consid potenti averag time take reach strong efficaci state shorter see synapt model optim various measur memori exceed simpl structur state arrang order.1 note need worri order chang optim necessari condit maximum requir infinitesim perturb increas area therefor need consid infinitesim neighborhood model order chang figur perturb increas area perturb increas element mpot diagon decreas correspond element mdep longer use mdep lower triangular depress must move synaps depress state perturb decreas element mpot diagon increas correspond element mdep longer use mpot upper triangular potenti must move synaps potenti state perturb decreas shortcut transit increas bypass direct transit it longer use nearestneighbor direct transit bound area now consid area memori curv dt snr find upper bound quantiti well model satur bound first passag time theori introduc previous section becom use becaus area simpl express term quantiti introduc supplementari materi pot dep pot dep ij ij ij pot dep dep mpot ij mij ij state order describ find perturb mpot/dep alway increas area whilst leav equilibrium distribut unchang perturb shown figur see supplementari materi detail exampl figur two state left right potenti dep proven increas mpot ij decreas mij lead increas area thing prevent perturb increas area requir decreas matrix element alreadi set this determin topolog non-zero transit probabl model maxim area it form shown figur c potenti move one step right depress move one step left topolog would allow class perturb figur increas area as perturb chang equilibrium distribut this mean area model bound linear chain equilibrium distribut area linear chain model express direct term it equilibrium state distribut yield follow upper bound area model supplementari materi jp jp pk chose wk sgn k jp maxim this push equilibrium distribut symmetr two end state this done reduc transit probabl state as figur this make it difficult exit state enter result area this analyt result similar numer result found slight differ inform theoret measur memori perform sticki end state result slow decay memori also make it difficult encod memori first place sinc small fraction synaps abl chang synapt efficaci storag new memori thus model maxim area optim memori late time expens earli time memori curv envelop now look implic upper bound found previous section snr finit time as argu memori curv written form snr ia e rt/ upper bound initi snr area impli follow constraint paramet ia ia ia claim complet set constraint everi set ia satisfi inequ actual achiev synapt model howev set violat either inequ definit achiev now we pick fix time t0 maxim snr time wrt paramet ia subject constraint this alway result singl nonzero ia essenc optim memori singl time requir singl exponenti result optim memori curv along achiev memori chosen time depend t0 as follow t0 snr e rt/ m snr t0 e rt0 t0 snr snr t0 rt0 ert0 initi snr bound area bound satur earli time late time area bound satur function snr t0 green curv figur form memori curv envelop late-tim power-law decay synapt model snr greater this time we use this find upper bound memori lifetim find point envelop cross er we assum intrigu lifetim memori envelop expand linear number intern state increas as squar root number synaps this leav question whether this bound achiev time we find model whose memori curv touch envelop red curv figur show closest we come envelop actual model repeat numer optim snr t0 mpot/dep random initi hand design model we see earli late time gap upper bound we prove what we achiev actual model there may model we found could beat one we come closer proven envelop howev we suspect area constraint bottleneck optim memori time less we believ there some constraint prevent model approach envelop current explor sever mathemat conjectur precis form this constraint in order obtain potenti tighter envelop nevertheless we proven rigor no model memori curv ever exceed this envelop it least tight late time longer model form in figur c come close envelop discuss we initi develop a general theori learn memori complex synaps allow explor entir space complex synapt model rather snr envelop numer search hand design area bound activ initi snr bound activ time figur memori curv envelop an upper bound the snr time shown in green the red dash curv show the result numer optim synapt model random initi the solid red curv show the highest snr we found hand design model earli time these model the form shown in differ number state all transit probabl equal late time the form shown in differ valu the model shown in also satur the area bound in the limit analyz individu model one at a time in we obtain sever new mathemat result delin the function limit memori achiev synapt complex the structur character synapt dynam system achiev these limit in particular oper within the ideal observ framework we shown a popul synaps intern state the initi snr synapt model exceed model achiev this bound equival a binari synaps the area the memori curv model exceed a linear chain model the equilibrium distribut both the area memori lifetim model exceed the model achiev this limit a linear chain topolog nearest neighbor transit we deriv an envelop memori curv in the snr-time plane exceed the memori curv model model approach this envelop time greater linear chain model this late-tim envelop a power-law proport indic synapt complex strong enhanc the limit achiev memori this theoret studi open sever avenu inquiri in particular the tight envelop for earli time less remain an open question we current pursu sever conjectur we also deriv memori constrain envelop ask in the space model achiev a given snr at a given time what the maxim snr achiev at time these two time beyond a threshold separ optim constrain model requir two exponenti it would interest systemat analyz the space model achiev good memori at multipl time understand structur organ they give rise multipl exponenti lead power law memori decay final it would interest to design physiolog experi in order to perform optim system identif potenti markovian dynam system hide within biolog synaps given measur pre post-synapt spike train along with chang in post-synapt potenti then given theori we could match this measur synapt model to optim model to understand for timescal memori if ani biolog synapt dynam may tune in summari we hope a deeper theoret understand the function role synapt complex initi here help advanc our understand the neurobiolog learn memori aid in the design engin memori circuit lead to new mathemat theorem stochast process acknowledg we thank sloan genenetech burroughs-wellcom swartz foundat for support we thank larri abbott marcus benna stefano fusi jascha sohl-dickstein david sussillo for use discuss
----------------------------------------------------------------

title: 1620-temporally-asymmetric-hebbian-learning-spike-liming-and-neural-response-variability.pdf

tempor asymmetr hebbian learn spike time neuron respons variabl l.f. abbott sen song volen center depart biolog brandei univers waltham ma abstract recent experiment data indic strengthen weaken synapt connect neuron depend relat time pre postsynapt action potenti hebbian synapt modif rule base data lead stabl state excitatori inhibitori input neuron balanc produc irregular pattern fire propos neuron vivo oper mode introduct hebbian modif network interconnect play central role studi learn neural network rumelhart mcclelland hertz work hebbian learn involv network model activ individu unit repres continu variabl hebbian learn rule context specifi describ network weight chang function activ unit transmit receiv signal across given network connect analys hebbian learn along line provid import result direct applic idea neurosci hinder fact real neuron adequ describ continu activ variabl fire rate instead input output neuron sequenc action potenti spike inform convey one neuron anoth appreci distanc carri tempor pattern action potenti sequenc rule synapt connect real neuron modifi hebbian manner proper express function relat time action potenti fire input presynapt output postsynapt neuron until recent littl inform avail exact depend synapt modif pre postsynapt spike time howev levi steward gustafsson new experiment result markram bell debann zhang bi poo chang l. abbott s. song situat dramat allow us studi hebbian learn manner much realist relev biolog neural network result may find applic artifici neural network well tempor asymmetr ltp ltd biolog substrat hebbian learn neurosci provid long-term potenti ltp long-term depress ltd synapt connect neuron exampl malenka nicol ltp long-last strengthen synapt efficaci associ pair pre postsynapt activ ltd long-last weaken synapt strength recent experi neocort slice markram hippocamp cell cultur bi poo vivo studi tadpol tectum zhang induct ltp requir presynapt action potenti preced postsynapt fire ms maxim ltp occur presynapt spike preced postsynapt action potenti less millisecond presynapt spike follow postsynapt action potenti long-term depress rather potenti result result summar schemat figur figur model chang synapt strength produc pair pre postsynapt spike occur time tpre tpost respect posit chang correspond ltp negat ltd abrupt transit tpre tpost unit arbitrari figur data indic maximum chang approxim per spike pair curv figur caricatur use model weight chang aris pair pre postsynapt action potenti separ various interv time curv resembl data three prepar discuss coupl assumpt made construct data indic rapid transit ltp ltd depend whether time differ pre postsynapt spike posit negat exist data resolv exact happen transit point assum discontinu jump ltp ltd point addit assum area ltp side curv slight less area ltd side figur diffet impos make magnitud ltd slight greater magnitud ltp side curv equal exponenti fall-off away zero time differ altern could given ltd side slower exponenti fall-off equal amplitud data support either assumpt unambigu indic area larger assumpt area ltd side curv larger ltp side critic result synapt modif rule stabl uncontrol growth synapt strength hebb postul synaps strengthen presynapt neuron frequent involv make postsynapt neuron fire action potenti causal import element hebb 's statement synapt potenti occur causal relationship pre postsynapt spike ltpiltd rule summar figur impos causal tight time requir narrow hebbian learn respons variabl window ltp ltd seen data abrupt transit potenti depress near zero separ pre postsynapt spike time impos strict causal condit ltp induct respons variabl implic synapt modif rule summar figur i address question introduc anoth topic discuss extens within comput neurosci communiti recent year origin respons variabl softki koch shadlen newsom tsodyk sejnowski amit brunei troyer miller bugmann van vreeswijk sompolinski neuron respond multipl synapt input two differ mode oper figur show membran potenti model neuron receiv excitatori inhibitori synapt input each input consist independ poisson spike train drive synapt conduct integrate-and-fir model neuron use exampl integr synapt conduct simpl capacitor-resistor circuit generat action potenti model monitor membran potenti compar threshold voltag whenev membran potenti reach threshold action potenti past onto membran potenti trace membran potenti reset prescrib valu e. figur regular irregular fire mode model integrate-and-fir neuron upper panel show model action potenti deactiv dash line show action potenti threshold lower figur show model action potenti activ regular fire mode averag membran potenti without spike threshold fire pattern fast regular note differ time scale lower panel irregular fire mode averag membran potenti without spike threshold fire pattern slower irregular figur 2a 2b illustr two mode oper upper panel figur show membran potenti action potenti generat mechan model turn lower panel show membran potenti spike sequenc result action potenti generat turn figur effect excitatori input strong enough relat inhibitori input averag membran potenti action potenti generat block spike threshold model action potenti mechan turn back lower panel figur produc fair regular pattern action potenti relat high rate total synapt input attempt charg neuron threshold everi time potenti reach threshold get reset start charg regular l. abbott s. song fire mode oper time action potenti determin primarili charg rate cell control membran time constant sinc vari function time fire pattern regular despit fact synapt input vari figur 2b show mode oper produc irregular fire pattern irregular fire mode averag membran hyperpolar threshold action potenti generat upper panel figur mode action potenti generat fluctuat total synapt current strong enough make membran potenti cross threshold result slower irregular fire lower panel figur irregular fire mode number interest featur shadlen newsom tsodyk sejnowski amit brunei troyer miller bugmann van vreeswijk sompolinski first generat irregular fire pattern far closer fire pattern seen vivo pattern produc regular fire mode second respons chang synapt input much rapid mode limit synapt rise time rather membran time constant final time action potenti irregular fire mode relat time fluctuat synapt input rather determin primarili membran time constant cell tpre ipost figur histogram indic relat probabl find pre postsynapt spike separ indic time interv regular fire mode probabl essentiaili flat chanc level one irregular fire mode excess presynapt spike short postsynapt spike import differ regular irregular fire mode illustr cross-correlogram shown figur troyer miller bugmann indic probabl action potenti fire postsynapt neuron preced follow presynapt spike separ various interv histogram normal valu pair due sole chanc one histogram model regular fire mode figur take valu close one almost all input-output spike time differ reflect fact time individu action potenti regular fire mode relat independ time presynapt input contrast histogram model neuron irregular fire mode figur show much larger excess presynapt spike occur short postsynapt neuron fire excess reflect fluctuat total synapt input push membran potenti threshold produc spike irregular fire mode indic mode tight tempor correl time fluctuat output spike neuron oper irregular fire mode must appropri balanc strength excitatori inhibitori input excitatori input must weak enough relat inhibitori input averag membran potenti absenc spike action potenti threshold avoid regular fire howev excitatori input must suffici strong keep averag potenti close enough hebbian learn respons variabl threshold fluctuat reach caus cell fire how this balanc achiev asymmetr ltpiltd lead irregular fire state comparison ltpiltd synapt modif rule illustr figur presynaptic/postsynapt time histogram shown figur reveal tempor asymmetr synapt modif rule base curv figur automat generat balanc excit inhibit need produc irregular fire state suppos start neuron model regular fire mode give relat strong excitatori synapt strength appli ltpiltd rule figur excitatori synaps while hold inhibitori synaps constant valu recal figur adjust area ltd part curv greater ltp part this mean there equal probabl presynapt spike either preced follow postsynapt spike net effect weaken excitatori synaps this exact what happen regular fire mode relationship time pre postsynapt spike approxim random figur ltpiltd rule weaken excitatori synaps averag membran potenti drop neuron enter irregular fire mode irregular fire mode there higher probabl presynapt spike preced follow postsynapt spike figur this compens fact rule use produc ltd ltp equilibrium reach asymmetri ltpiltd modif curv figur match asymmetri presynaptic/postsynapt time histogram figur equilibrium state correspond balanc irregular fire mode oper automat produc tempor asymmetr learn rule figur 4a show transit regular irregular fire state mediat tempor asymmetr ltpiltd modif rule irregular postsynapt spike train quantifi plot coeffici variat standard deviat mean interspik interv model neuron function time initi neuron regular fire state low cv valu after synapt modif rule reach equilibrium state cv took valu near one indic neuron transform irregular fire mode solid curv in figur 4b show tempor asymmetr ltpiltd robust generat irregular output fire wide rang input fire rate qi time step input rate figur coeffici variat output spike train model neuron transit regular an irregular fire state tempor asymmetr ltpiltd modifi synapt strength unit time in this plot arbitrari depend the magnitud ltp ltd use in the model equilibrium cv valu a function the fire rate excitatori input the model neuron the solid curv give the result tempor asymmetr ltp/ltd activ the dash curv show the result the synapt strength aros hz input left unmodifi l. abbott s. song discuss tempor asymmetr ltpiltd provid a hebbian-typ learn rule interest properti kempter in the past tempor asymmetr hebbian learn rule studi appli problem tempor sequenc generat manai levi navig blum abbott gerstner abbott motor learn abbott blum detect spike synchroni gerstner in these studi two differ ltpiltd window size assum either order ms manai levi blum abbott gerstner abbott abbott blum around ms gerstner the new data markram bell zhang bi poo give a window size order ms alm window size tempor asymmetr ltpiltd sensit precis spike time when the window size order ms chang in stimuli motor action a behavior level becom relev ltp ltd. a window size ms support the recent data suggest ltp ltd sensit fire correl relev neuron circuitri as input-output correl vari this time scale tempor asymmetr ltpiltd interest properti distinguish hebbian learn rule base correl covari in pre postsynapt rate we found the rule use sensit input fire rate variabl in input rate if we split the excitatori input the model two group give these two input set differ rate we see differ in the distribut synapt strength aris the learn rule similar if one group given a steadi fire rate the group fire rate vari in time differ in synapt strength appar the most effect way induc ltp in a set input to synchron spike input synchron spike slight effect fire the neuron un synchron spike this mean input preced postsynapt spike frequent thus get stronger this suggest spike synchroni may a signal mark a set input learn even when this synchroni particular function effect it littl impact the fire pattern the postsynapt neuron it lead to dramat shift in synapt strength thus spike synchron may a mechan for induc ltp ltd acknowledg research support the nation scienc foundat the sloan center for theoret neurobiolog brandei univers a howard hugh predoctor fellowship the w.m keck foundat
----------------------------------------------------------------

title: 4364-two-is-better-than-one-distinct-roles-for-familiarity-and-recollection-in-retrieving-palimpsest-memories.pdf

two better one distinct role familiar recollect retriev palimpsest memori cristina savin1 cs664 cam.ac.uk peter dayan2 dayan gatsby.ucl.ac.uk m e lengyel1 m.lengyel eng.cam.ac.uk comput biolog learn lab dept engin univers cambridg uk gatsbi comput neurosci unit univers colleg london uk abstract store new pattern palimpsest memori system come cost interf memori trace previous store item know age pattern thus becom critic recal faith impli tight coupl estim age form familiar neural dynam recollect someth current theori omit use normat model autoassoci memori show dual memori system consist two interact modul familiar recollect best perform recollect recognit find provid new window onto activ contenti psycholog neural aspect recognit memori introduct episod memori hippocampus act like palimpsest new entiti store overlaid top predecessor turn submerg successor impli anterograd interfer exist memori hinder process new one retrograd interfer new memori overwrit inform old one pose import challeng storag retriev inform neural circuit aspect challeng address two theoret framework one focus anterograd interfer interact novelti storag retrograd interfer individu synaps howev neither fulli consid critic issu retriev palimpsest focus first made critic observ autoassoci memori work normal recal dynam suppress present new pattern need store otherwis rather memor new pattern memori associ exist pattern close match new input strengthen suggest critic mechan assess pattern novelti convers familiar function often ascrib neocort area surround hippocampus second consid palimpsest problem overwrit inform synaps whose efficaci limit dynam rang point least partial address allow multipl intern state instanc form cascad observ synapt efficaci level howev although provid attract formal analyz optim synapt storag retriev mechan associ storag miss potenti depress figur cascad model intern state synaps circl express one two differ efficaci column transit state stochast either potenti depress depend pre postsynapt activ probabl transit state express efficaci state express differ efficaci decreas geometr cascad depth generat model autoassoci memori task noisi version one store pattern upon store pattern synapt state recal cue chang v0 sampl stationari distribut synapt dynam v1 recal occur present interven pattern synaps state vt observ recal correspond synapt efficaci wt wt although piec work might seem complet unrel show close link via retriev critic fact recal memori general know inform appear time retriev case palimpsest trace memori synapt efficaci depend critic age memori relat familiar suggest central role novelti familiar signal recollect inde show retriev substanti wors familiar explicit repres dual system model recognit memori topic heat debat result could provid comput rational show separ perirhinal-lik network involv familiar hippocampal-lik network benefici even task recollect also show task recognit also best accomplish combin output network suggest experiment storag palimpsest memori consid task autoassoci recal binari pattern palimpsest memori specif neural circuit consist binari neuron enjoy all-to-al connect storag network activ clamp present pattern induc chang synaps intern state correspond observ binari efficaci recal seek retriev pattern origin store given noisi cue current weight matrix w. weight matrix assum result store top stationari distribut synapt efficaci come larg number pattern previous store subsequ store sequenc interven pattern statist top detail pattern store densiti drawn distribut pstore pstore recal cue noisi version origin pattern model use binari symmetr channel pnois pnois pnois r xi x defin level input nois rxi recal time assum come geometr distribut mean precal synapt learn rule local stochast probabl event actual lead state chang determin current state synaps vij activ pre post-synapt neuron henc learn specifi set transit matric p vij0 l0 vij conveni adopt cascad model assum probabl potenti depress decay cascad depth geometr progress qi qn compens boundari effect transit metast given correct factor ensur differ metast equal occupi differ pattern spars valu furthermor assum synapt chang occur postsynapt neuron activ lead potenti presynapt neuron also activ depress otherwis specif form learn rule could influenc memori span network expect chang result qualit evolut distribut synapt state encod describ markov process transit matrix given averagep chang synapt state expect store arbitrari pattern prior pstore pstore pstore addit defin column vector distribut synapt state observ efficaci respect one pattern store lw p wij l|xi lv p vij l|xi given definit express final distribut synapt state precal m xi start stationari distribut eigenvector eigenvalu encod pattern addit pattern distribut correspond weight distribut 2n matrix defin determinist map synapt state observ efficaci fact recenc pattern recal appear equat impli pattern age strong influenc inform retriev follow consid two possibl solut problem first show limit recal dynam involv singl monolith modul averag prove benefit dual system two qualit differ modul one explicit repres estim pattern age singl modul recollect system optim retriev dynam sinc inform storag synapt plastic lossi recollect task describ probabilist infer problem essenti neural dynam repres aspect posterior store pattern express probabl pattern synapt efficaci w. correct respons recal queri given noisi recal cue detail posterior possibl store pattern comput pstore pnois assum evid weight factor synaps ij ij assumpt never exact true practic synaps share pre post synapt partner bound correl assum interven pattern caus independ weight chang ignor effect correl previous bayesian recal dynam deriv assum learn rule contribut pattern final weight irrespect order pattern present contrast markov chain behaviour synapt learn rule forc us explicit consid pattern age furthermor pattern age unknown recal need integr possibl valu integr technic sum discret comput analyt use eigenvalu decomposit transit matrix m. altern valu known recal prior replac delta function precal sever possibl way repres posterior neural dynam without reifi consist assum neural state binari network activ step repres sampl posterior advantag approach full posterior repres network dynam higher decis modul extract best pattern mean squar error cost function consid would mean posterior also estim uncertainti solut nevertheless represent exampl repres paramet mean-field approxim true posterior would also possibl similar inform uncertainti particular use gibb sampl allow neural plausibl recal dynam result asynchron updat activ neuron chang stochast function input cue activ neuron x\i neighbour synaps specif gibb sampler result sigmoid transfer function total current neuron given log-odd ratio iirec log p xi iirec iirec p xi in/out defin evid incom outgo synaps neuron term irec constant determin prior pattern nois model.2 term describ contribut recurr interact similar shape iirec cin wij c2 wij c3 c4 iirec cout wji c2 wji c3 c4 in/out paramet ck uniqu determin learn rule prior rescal contribut evid weight function pattern age supplementari text furthermor constant translat uniqu signal give sort suffici statist expect memori strength notep optim dynam includ two homeostat process correspond global inhibit neuron excit regul wij stabil network activ recal limit besid effect assum factor weight distribut neural dynam deriv best given avail data recal cue synapt weight well network fare practic perform expect pattern age assum known avail inform weight decreas perform final converg control level defin retriev perform network without plastic recurr connect infer use recal cue prior store pattern green unknown perform also deterior increas pattern age howev time beneath control level blue intuit one see reli prior similar assum fix valu close real neuron receiv inform presynapt partner estim irec therefor ran simul without term dynam found although decreas recal perform decreas similar obtain random prune half connect network keep term dynam shown indic perform most determin number avail synaps use infer much direct synaps henc follow use term leav systemat studi connect futur work known unknown control control error error known singl modul dual system gibb temper transit figur recal perform singl modul memori system averag recollect error comparison singl dual memori system black line mark control perform ignor inform synapt weight mean prior pattern actual present older estim result memori signal weaker expect suggest initi pattern spars sinc pair inact element induc synapt chang accord learn rule howev less reason fact averag prior distribut recal time perform wors control one possibl reason failur sampl procedur use infer might work certain case sinc gibb sampler known mix poor shape posterior complex strong correl frustrat ise model perhap neural dynam unabl sampl desir distribut effect confirm hypothesi implement sophist sampl procedur use temper transit detail supplementari text inde temper transit perform becom signific better control even case gibb sampl fail unfortun yet convinc suggest how temper dynam fact sampl algorithm work well correl posterior repres neural sinc exampl they requir global accept decis taken end temperatur cycl worth note complex synapt dynam deeper cascad simpl gibb sampl work reason well data shown probabl posterior smoother henc easier sampl dual memori system altern implicit margin age pattern throughout infer process estim time perform recollect suggest use dual modul togeth estim joint posterior sampl proceed loop familiar modul generat sampl posterior age current esti recollect modul use estim age comput new mate pattern sampl distribut possibl store pattern given age modul comput familiar also seen palimpsest pattern overlay overlaid predecessor successor formal need comput probabl system continu implement gibb sampler addit dimenp t|x sion separ modul neural network estim familiar howev access weight recollect modul biolog plausibl approxim assum familiar modul use separ set weight call wfam also clear condit thus condit drop 1b independ comput posterior extern input need feed direct recollect familiar modul particular assum feedforward network structur familiar modul neuron receiv output recollect modul input synaps wfam synapt cue familiar recollect activ neuron index familiar signal figur overview dual memori system familiar network feedforward structur activ individu neuron estim probabl true pattern age certain valu see exampl inset estim pattern age translat familiar signal scale contribut recurr input network dynam depend familiar signal estim pattern age weight chang accord cascad rule use recollection.3 simplic assum familiar neuron alway activ encod synaps chang state either potenti depress everi storag event concret familiar modul consist nfam neuron correspond certain pattern age rang nfam last unit code nfam this form localist code familiar total input neuron given log-posterior iifam log p wfam translat simpl linear activ function fam fam fam fam iifam cfam cfam log log z wij wij in/out albeit differ neuron constant cfam k similar paramet tune differ valu unknown partit function mention treat activ familiar modul sampl posterior age this represent requir later competit differ unit one becom activ step dynam this sort implement use softmax oper ii p xfam pe eij thus render evalu partit function unnecessari common featur rang neural model critic this familiar modul conveni theoret construct associ retriev first mention assess novelti actual play key part memori storag make decis whether pattern present novel store familiar detail recal this vener suggest play central part understand structure-funct relationship hippocampus grade familiar modul suggest obvious extens this idea use retriev new second general accord substanti data role perirhin cortex activ neuron this structur recenc neuron would associ small valu novelti neuron larg effect infinit valu although perirhin cortex appear adopt popul code strategi age rather one-of-n recollect modul dynam constant ci comput assum fix output familiar modul thus predict familiar multipl modul recurr interact recollect modul dure recal sinc determinist map this modulatori factor comput use linear unit pool output neuron familiar modul weight given correspond valu cfam there noth say learn rule optim recollect network abil recal pattern equal appropri assess familiar henc familiar modul could learn rule optim specif task novel familiar hit familiar estim fam rec recollect averag entropi fals alarm fam rec figur decis boundari recognit modul correspond roc curv perform comparison decis layer use signal familiar modul recollect modul comparison data restrict recent stimuli note differ fam rec becam signific compar order compar singl dual modul system fair comput resourc employ therefor reduc overal connect dual system two total number synaps moreov sinc element wfam correl effect number connect fact somewhat lower dual system regardless dual memori system perform signific better singl modul system recognit memori far consid familiar mere instrument effect recollect howev there mani practic experiment task suffici make binari decis whether pattern novel familiar rather recal gori detail task use elucid role perirhin cortex recognit memori dual modul system inform recognit avail familiar modul pattern judg young age recogn recollect modul pattern recal higher certainti recogn we therefor construct addit decis modul take output familiar recollect modul map binari behavior respons familiar novel specif we use averag entropi associ activ neuron recollect modul mean estim familiar modul sinc palimpsest properti implicit assum pattern present point we defin pattern familiar age less fix threshold tth we train decis modul use gaussian process classifier4 yield outcom probabl hit p familiar|t shown shape result discrimin parallel either axi suggest output modul need success recognit suggest experiment fact classifi train use one two dimens match recognit perform use confirm this observ moreov roc curv produc classifi plot hit rate fals alarm relat loss vari similar shape obtain human behavior data so-cal curvi-linear charact appar intersect finit hit probabl fals alarm rate last recognit known reli familiar relat recent pattern we estim recognit perform recent pattern we defin age t2th determin contribut modul recognit outcom this case we estim perform classifi train singl input dimens this test data consist experiment data analysi reveal familiar signal give reliabl estim novelti compar recollect output relat recent item specif classifi chosen allow an easi estim roc curv futur work explor analyt decis rule conclus discuss know age pattern critic retriev palimpsest memori consider far elud theoret inquiri we show memori system could either treat this inform implicit margin possibl age could estim age explicit form familiar principl solut similar perform given resourc practic howev system involv dual modul signific better model posterior possibl store pattern repres in neural activ via sampl we show complex biologically-question sampl procedur would necessari implicit singl modul system instead dual memori system two function distinct close interact modul yield best perform both effici recollect recognit import though gibb sampl temper transit provid use framework understand perform differ differ memori system present result restrict sampling-bas implement sinc age ident tight correl mean field solut use factor distribut show similar behavior supplementari text similar specif detail familiar modul critic these effect appar altern implement correct estim pattern age repres pattern age explicit essenti amount implement an auxiliari variabl sampl space possibl pattern effici such auxiliari variabl method wide use increas sampl effici when simpler method fail moreov sinc in case specif modul correl compon posterior seen temperatur paramet we understand advantag brought dual system due implement form simul temper class method known help mix in strong correl posterior propos provid a power new window onto contenti debat neural mechan recognit recal rational familiar network improv recollect howev the form the network motiv the substanti experiment data recognit inde standard model perirhin cortex activ these instanc also reli some form inhibit mediat interact differ familiar neuron nevertheless model the first link the comput function familiar network recal it distinct also in it consid palimpsest synaps as previous model use pure addit learn rule although we onli consid pattern age as the basi familiar here the principl the interact familiar recollect remain the same in an extend set when familiar character the expect strength the memori trace complet includ the effect retent interv number repetit space repetit futur work the extend model allow us address familiar novelti recenc neuron in the perirhin cortex inde provid a foundat for new think this region in model familiar interact recollect multipl divis modul the contribut recurr input in the recollect modul neural this effect could mediat shunt inhibit via specif class hippocamp interneuron target the dendrit segment correspond recurr connect thus rescal the relat contribut extern versus recurr input whether pathway reach ca3 perirhin cortex entorhin cortex preserv a suffici amount input specif feed-forward inhibit unknown our theori predict import systems-level aspect memori synaptic-level constraint in particular optim our dual system sole for memori recal we also predict non-trivi roc curv for recognit in at least broad qualit agreement experi futur work need explor whether the roc curv in our model show similar dissoci in respons specif lesion the two modul found in recent experi the relat to recognit memori model acknowledg this work support by the wellcom trust ml the gatsbi charit foundat
----------------------------------------------------------------

title: 353-self-organization-of-hebbian-synapses-in-hippocampal-neurons.pdf

self-organ hebbian synaps hippocamp neuron thoma h. brown zachari f. mainen anthoni m. zador brenda j. claiborn depart psycholog divis life scienc yale univers univers texa new haven cr san antonio tx abstract explor signific biolog complex neuron comput we demonstr hebbian synaps realistically-model hippocamp pyramid cell may give rise two novel form self-organ respons structur synapt input first basi electroton relationship synapt contact cell may becom tune small subset input space second mechan may produc cluster potenti synaps across space dendrit latter type self-organ may function signific presenc nonlinear dendrit conduct introduct long-term potenti ltp experiment observ form synapt plastic interpret instanc hebbian modif kelso al brown al induct ofltp requir synchron presynapt activ postsynapt depolar kelso al we previous develop detail biophys model ltp observ synaps onto hippocamp region cal pyrami brown mainen zador claiborn figur two-dimension project reconstruct hippocamp cal pyramid cell dal neuron zador al synaps form ltp occur distribut across extens dendrit arbor dure synapt stimul membran voltag synaps differ way biolog neuron differ process element typic use neural network model postsynapt activ repres singl state variabl we develop electroton model base anatom reconstruct neuron we use model explor spatial distribut input tempor relationship activ affect synapt potenti neuron model standard compartment model techniqu use repres electr structur hippocamp cal pyramid cell morpholog electr paramet morphometr data obtain three-dimension reconstruct brown hippocamp neuron correct factor appli membran area base estim spine densiti origin measur divid singl neuron cylind averag length simul purpos structur collaps compart preserv connect pattern chang process diamet electr constant rm id-cm em jlf'lcrrll ri n-cm spruston johnston membran electr passiv synapt current model sum fast ampa slow nmda conduct head two-compart spine zador ampa conduct repres alpha function jack time constant msec brown johnston nmda conduct repres complic function two time constant voltag depend due voltage-sensit channel block ion zador brown initi peak conduct gampa gnmda set ns respect self-organ hebbian synaps hippocamp neuron simul synapt modif simul run sun workstat use custom version neuron simul develop michael hine hine prior simul pattern synaps select random pool synaps distribut unifonn apic basal dendrit simul divid trial msec begin trial particular pattern synaps activ synchron stimuli interv msec sequenti present select pattern constitut epoch entir simul consist present epoch cours trial membran potenti comput locat dendrit tree voltag use comput weight chang accord hebbian algorithm describ after trial actual peak ampa conduct gampa hereaft denot scale sigmoid function gmax detennin steep sigmoid gfm set ns rule synapt modif base biophys interpret kairiss ai brown ai general bilinear fonn hebbian algorithm brown functionals.l constant repres postsynapt activ repres presynapt activ equat specifi interact fonn synapt ehhanc combin three noninteract form synapt depress possibl neurobiolog analog brown ai interact tenn deriv biophys model ltp induct spine zador simplifi version model use comput concentr ca bound calmodulin suggest cam-c84 may trigger protein kinas respons ltp induct general nonlinear function subsynapt voltag zador al biophys mechan under synapt depress less well understood constant repres passiv decay process general set zero function repres heterosynapt depress base postsynapt activ simul proport amount depolar subsynapt membran rest potenti function repres homosynapt depress base presynapt activ proport ampa conduct consid measur exclus presynapt activ insensit postsynapt voltag three activity-depend tenn integr over period trial order obtain measur weight chang reinterpret yas constant equat thus ial camca v.ryii ygampa dt brown mainen zador claiborn too m.sec too m.sec epoch figur interact among hebbian synaps produc differ global effect win lose pattern basi spatial distribut synaps psp alway measur soma due two differ pattern synaps plot function present epoch initi pattern solid line evok slight greater psp pattern dot line inset top right mter epoch respons revers thepsp due pattern depress psp due pattern potenti inset top left result analysi simul reveal self-organ form differenti modif synapt strength mainen two aspect self-organ phenomena distinguish simul form pattern select observ clear winner loser emerg simul averag synapt efficaci remain spatial heterogeneities~lustering~f synapt strength develop differ measur use assess phenomena patternselect chang peak postsynapt potenti record soma sp provid one use measur pattern select mani simul pattern select result mark potenti psp due pattern depress psp due other psp regard indirect measur function consequ self-organ simul illustr pattern synaps produc averag psp mv learn after learn respons rang amount underlying.pattern select ch8 ge averag peak synapt conduct patterng8yiio initi valu g8yii pattern final valu bound eq mani simul g8yii approach upper bound pattern lower bound pattern way neuron becam select tune subset origin set input specif self-organ hebbian synaps hippocamp neuron epoch figur mean synapt conduct gsi two pattern plot function present epoch pattern began iaenuc total synapt strength synaps gs r synapt conduct constrain rang ns mter twenti epoch gsi pattern solid line approach minimum ofo.on gsi pattern dot line approach maximum ns tune depend paramet valu neuron model learn rule stimulus set cluster formanon heterogen spatial distribut strengthen weaken synaps often observ after learn spatial cluster synaps similar conduct form spatial heterogen illustr sever way one conveni method brown synaps repres color point superimpos rendit neuron morpholog illustr color-cod gsyn synaps pattern correl synapt strength across dendrit space immedi appar second method better suit monochrom graphic avail present text evolut varianc gsyn plot function time simul illustr here increas varianc due format singl relat larg cluster strengthen synaps within paramet regim multipl cluster smaller size form discuss import differ synapt modif in biophysically-model neuron in simpl process element aris voltag gradient present in realist model brown kairiss in standard process element although sj somat psp were general correl relationship two linear often evid in simul compar initi trial in fig brown mainen zador claiborn til epoch figur synapt heterogen indic increas in varianc set synapt conduct for pattern varianc peak synapt conduct pattern plot aji lction epoch varianc pattern approach theoret maximum in paramet regim the varianc due the potenti singl larg cluster synap combin the depress synaps singl state variabl repres postsynapt activ in contrast the critic subsynapt voltag repres postsynapt activ in the neuron correl strict equal the structur electr properti the cell interact synapt input detennin the precis spatiotempor pattern membran voltag thus the voltag synaps depend strong electroton relationship activ synaps the way in this local depolar affect the natur self-organ depend the specif mechan the synapt modif rule we model pair oppos voltage-depend mechan an interact potenti mechan the function ex promot cooper spatial proxim synaps tempor correl activ heterosynapt depress mechan the function independ presynapt activ promot competit among spatial proxim synaps through mechan the specif electroton structur neuron predetennin complex set interact given spatial distribut synapt input we shown higher-ord interact give rise self-organ at least two interest effect spars represent the phenomenon pattern select demonstr hebbian self-organ may natur tune neuron respond subset input space this tune mechan might allow larg field neuron develop spars code the activ in set input fiber sinc neuron would respond a particular small portion the input space spars code may advantag associ learn type neural comput kanerva self-organ hebbian synaps in hippocamp neuron cluster nonlinear comput the fonnat cluster strengthen synaps illustr a properti hebbian selforgan whose function signific might appreci in the presenc nonlinear voltage-depend dendrit conduct we examin the self-organ process in an electr passiv neuron under these condit the presenc cluster within pattern littl effect the observ output in fact it known hippocamp cell the type model possess a varieti spatial heterogen nonlinear dendrit conduct jone the comput role nonlinear begin explor it possibl interact synapt cluster and nonlinear membran patch may signific affect both the perfonn dendrit comput and the process self-organ acknowledg this research support by grant the offic naval research the defens advanc research project agenc and the air forc offic scientif research
----------------------------------------------------------------

title: 526-oscillatory-model-of-short-term-memory.pdf

oscillatori model short term memori david horn school physic astronomi raymond bever sackler faculti exact scienc tel-aviv univers tel aviv israel marius sher dept appli mathemat comput scienc weizmann institut scienc rehovot israel abstract investig model excitatori neuron dynam threshold display fatigu potenti fatigu properti lead oscillatori behavior respons abil model perform segment decompos mix input stagger oscil activ cell-assembl memori affect potenti respons sustain stagger oscil input turn system serv model short term memori limit stm capac reminisc magic number introduct limit capac short term memori stm subject major interest psycholog physiolog literatur seem quit natur assum limit capac due special dynam natur stm recent crick koch suggest work memori function relat bind process obtain via synchron oscil neural popul capac limit stm may result competit oscil repres item stm model investig inde case present address divis biolog caltech pasadena ca horn usher model oscil neural network perform various task phase-lock synchron respons global coher stimuli similar orient continu kamen sompolinsyet konig schillen segment incoher stimuli low level vision via desynchron use oscil network delay connect schillen konig segment accord semant content separ input mix inform compon known memori system wang horn usher model memori repres compet cell 3sembl input affect subset assembl induc stagger oscil activ work long number memori input small order bind connect correct differ attribut object appear mix input horn bind interpret match phase oscil repres attribut object two differ network coupl way assum relat attribut add import task stm keep inform segment bind input turn order qualifi model stm stagger oscil prevail input stimuli disappear unfortun hold model quot. input disappear either network 's activ die oscil assembl includ origin input turn word oscil inertia thus persist disappear sensori input purpos present model compet neural assembl upon receiv mix input develop oscil prevail st.imulus disappear order achiev biolog mechan post tetan potenti use dynail short ternl potenti shown follow t.etanus electrophysiolog stimul temporari modif synapt strength most non hebbian observ crick koch zucker time scale synapt modif rang sever minut detail descript process respons mechan given zucker exhibit rather complex behavior follow use simplifi version mechan involv two process differ time scale assum follow prolong activ synaps synapt strength exhibit depress short time scale recov becom slight enhanc longer time scale illustr fig zucker captur dynam short term potenti fact mechan non hebbian impli synaps associ presynapt cell affect thus unit chang presynapt cell crick koch oscillatori model shorr term memori previous oscillatori neural network base assumpt addit customari properti formal neuron threshold increas neuron keep fire thus exhibit adapt fatigu horn usher motiv stp find add new compon offacilitaion take place longer time scale fatigu denot dynam threshold continu variabl chosen sum two compon i repres fatigu potenti dynam govern equat dl/dt l/ci dp/dt l p describ averag neuron activ fire rate time scale larg compar refractori period time constant fatigu potenti compon tj chosen ti t2 result neuron display fatigu short time scale recov becom slight enhanc potenti longer time scale clear seen show behavior activ correspond neuron clamp time due sensori input quench zero afterward i time figur behavior dynam threshold fatigu i potenti compon neuron activ clamp shown time scale arbitrari paramet ci c2 al a2 observ threshold increas cell 's activ driven asymptot valu al releas stimulus dycl namic threshold decreas neuron recov turn negat signifi horn usher potenti paramet chosen asymptot threshold reach zero perman effect left model assum similar behavior excitatori cell-assembl carri memori system model basic model horn usher compos two kind neuron assum excitatori inhibitori synaps exclus memori pattern carri excitatori neuron furthermor make simplifi assumpt pattern overlap one anoth model compos disjoint hebbian cell-assembl excitatori neuron affect one anoth interact singl assembl inhibitori neuron let us denot fraction cell-assembl number il fire time i fraction activ inhibitori neuron refer ms activ ilth memori pattern there differ memori model activ obey follow differenti equat ft am bm i dmi/dt i ft cm dm i lms dms dt f i threshold excitatori inhibitori neuron correspond repres input cell assembl il four paramet abc posit repres differ coupl neuron system attractor neural network absenc input dynam threshold dissip system flow fix point determin memori system general e-i model wilson cowan introduc compet memori pattern latter make attractor neural network wilson cowan shown pair excitatori inhibitori assembl proper connect form oscil induc oscil differ way keep option network behav either attractor neural network oscil one turn threshold excitatori neuron dynam variabl defin brs dynam new variabl rs chosen follow equat element refer cell-assembl understand effect chang let us first limit fatigu compon a2 imagin situat system would flow a1 fix point ms rs increas reach valu c1 mean argument ft function equat ms decreas bci/ cl if this overcom effect term amplitud ms decreas system move attractor fall basin differ center attract this process continu indefinit creat oscillatori model short term memori oscillatori network move one memori anoth envisag turn p/lo compon lead r/lo behavior type depict effect evid input i/lo time activ word help reactiv cell-assembl thus carri inform this memori activ therefor role system serv inertia compon necessari creat effect stm seglnent short term memori this section present result numer investig model paramet use follow oj i valu ci let memori constant input form i/lo i/lo p. exampl result system shown u1 o+j o+j cj co i i i i i i i i i tr1 i i. oj i i i i i i i i i i i i i i. i i i i i il'l i time figur result. model memori input first frame display activ four relev cell-assembl second frame repres valu arrow indic durat mix input horn usher display activ cell-assembl receiv constant input correspond averag threshold while signal mix input denot arrow along time scale we see phenomenon segment develop stagger oscil four cell-assembl receiv input sustain signal turn this indic system function stm note synapt connect chang onc system receiv new input it behavior revis howev long it left alon it continu activ cell-assembl affect origin input we abl obtain good result low valu increas we difficulti wit.h segment stm modifi slight paradigm we abl feed differ input stm shown this requir present differ time indic arrow this figur word t.his system perform segment it continu work stm note howev order differ activ longer maintain after stimuli turn i tzl tl ttl i i i i i i i i i i time figur result. input fed consecut time indic short arrow model function stm without segment oscillatori model short term memori discuss psycholog experi show subject repeat sequenc verbal item perfect order long their number small item may number let.ter also combin latter as word recogniz date acronym this prove stm make use encod materi long term memori miller this relat two differ kind memot'i lie in basi our model long term memori repres excitatori cell assembl incorpor threshold fatigu model it acquir capabl perform tempor segment extern input ad the threshold post tetan potenti the model becom capabl maintain the segment inform in the form stagger oscil this the properti we view as respons stm segment stm limit capac this seem follow t.he oscillatori natur the system we use model function in contrast long term memori whose capac increas endless ad neuron synapt connect we find here item st.ore in t.he dynam fashion stagger oscil irrespect the size the system vve regard this result as signific in view the fact the hold the limit psycholog abil attent stm it may indic t.hat the oscillatori model contain the key the understand psycholog find in order valid the hypothesi stm base oscillatori correl fire rate neuron experiment neurobiolog psychophys research requir while conclus result yet obtain record t.he cortic activ in the monkey posit support obtain in psychophys experi preliminari result show oscillatori compon found in the percentag correct respons in stm match experi usher sagi our mathemat model base mani specif assumpt we believ our main result characterist a class model obtain by chang various element in our system the main point dynam storag inform achiev stagger oscil memori activit.i moreov sustain in the absenc an extern input a potenti capabl ha 'l present a model contain both abl to accomod stm in t.he fashion we demonstr a cknowledgenl m. usher the recipi a dov biegun post-doctor fellowship we wish to thank s. popescu help discuss
----------------------------------------------------------------

title: 1658-spike-based-learning-rules-and-stabilization-of-persistent-neural-activity.pdf

spike-bas learn rule stabil persist neural activ xiaohui xie h. sebastian seung dept brain cog sci mit cambridg ma xhxie seung mit.edu abstract analyz condit synapt learn rule base action potenti time approxim learn rule base fire rate particular consid form plastic synaps depress presynapt spike follow postsynapt spike potenti opposit tempor order such differenti anti-hebbian plastic approxim certain condit learn rule depend time deriv postsynapt fire rate such learn rule act stabil persist neural activ pattern recurr neural network introduct recent experi demonstr type synapt plastic depend post tempor order presynapt postsynapt spike cortic i hippocamp synaps long-term potenti1000 tpost tpre time ation induc repeat pair presynapt spike figur i pair function differenti heband succeed postsynapt bian learn chang synapt strength plotspik long-term deprest versus time differ postsynapt sion result order presynapt spike pair function difi revers depend ferenti anti-hebbian learn differenti antiof chang synapt hebbian learn driven chang fire rate strength differ synapt learn rule appli two tpost tpre poisson spike train synapt strength remain postsynapt presynapt rough constant time except postsynapspik time measur tic rate chang quantit pair function sketch figur la posit negat lobe correspond potenti depress width ten millisecond refer synapt plastic associ pair function differenti hebbian plasticity-hebbian condit xie h. s. seung potenti predict differenti driven differ oppos process potenti depress pair function figur ia characterist synaps exampl opposit tempor depend observ electrosensori lobe synaps electr shown figur ib synaps depress presynapt spike follow postsynapt one potenti order revers refer differenti anti-hebbian plastic accord experi maximum rang differenti hebbian antihebbian pair function rough ms respect fair short seem compat descript neural activ base spike time rather instantan fire rate fact show condit spike-bas learn rule approxim rate-bas learn rule peopl also studi relationship spike-bas rate-bas learn rule pair function figur ia ib lead rate-bas learn rule like tradit use neural network except depend tempor deriv fire rate well fire rate argu differenti antihebbian learn rule figur ib could general mechan tune strength posit feedback network maintain short-term memori analog variabl persist neural activ number recurr network model propos explain memory-rel neural activ motor prefront cortic area well head direct system oculomotor integr model requir precis tune synapt strength order maintain continu variabl level persist activ simpl illustr tune differenti antihebbian learn model persist activ maintain integrate-and-fir neuron excitatori autaps studi spike-bas learn rule pair function like figur measur use repeat pair singl presynapt spike singl postsynapt spike quantit measur synapt chang due complex pattern spike activ yet done assum simpl model synapt chang due arbitrari spike train sum contribut possibl pair presynapt postsynapt spike model unlik exact descript real synaps could turn approxim valid write spike train ith neuron seri dirac delta function si tr nth spike time ith neuron synapt weight neuron time denot ij chang synapt weight induc presynapt spike occur time interv tj model ln wij dtj io foo dti f ti tj si ti sj tj presynapt spike pair all postsynapt spike produc pair synapt weight chang amount depend pair function pair function assum nonzero insid interv tj zero outsid refer pair rang accord model presynapt spike result induct plastic latenc accord argument ij left hand side equat shift relat limit integr right hand side spike-bas learn stabil ofpersist neural activ assum latenc greater pair rang wi time influenc presynapt postsynapt spike happen time therefor learn rule causal relat rate-bas learn rule learn rule driven correl presynapt postsynapt activ depend made explicit make chang variabl ti yield wij ij itt duf u cij u defin cross-correl cij u dt si sj made use fact vanish outsid interv immedi goal relat learn rule base cross-correl fire rate crre u dt vi vj number way defin instantan fire rate sometim comput averag repeat present stimulus situat defin tempor filter spike train follow discuss general appli definit fire rate rate correl common subtract total correl obtain spike correl c r ke cij cijat deriv rate-bas approxim learn rule rewrit wij itt du f u cijat u itt du f u c r ke simpli neglect second term short discuss condit good approxim first deriv anoth form first term appli approxim vi t vi t uvi t obtain duf u crre u dt fiovi t defin approxim good fire rate vari slowli compar pair rang learn rule depend postsynapt rate fio vi vi first term domin second learn rule convent one base correl fire rate sign fio determin whether rule hebbian anti-hebbian remaind paper discuss novel case hold pair function shown figur la ib posit negat lobe area exact cancel definit depend xie h. s. seung postsynapt activ pure time deriv fire rate differenti hebbian learn correspond figur differenti anti-hebbian learn lead figur ib summar case synapt chang due rate correl approxim ij ex vivj diff anti-hebbian slowli vari rate formula impli constant postsynapt fire rate caus net chang synapt strength instead chang rate requir induc synapt plastic illustr point figur lc show result appli differenti anti-hebbian learn two spike train presynapt spike train generat hz poisson process postsynapt spike train generat inhomogen poisson process rate shift hz hz sec shift synapt strength fluctuat remain rough constant but upward shift fire rate caus downward shift synapt strength accord sign differenti anti-hebbian rule rate-bas approxim work well exampl second term import let us return issu general condit pike this term neglect poisson spike train spike correl zero limit but finit fluctuat zero integr~l second term dampen fluctuat amount dampen depend pair rang set limit integr figur 1c we use relat long pair rang ms made fluctuat small even small t. hand short fluctuat would small larg averag larg relev when amplitud small rate learn slow this case take long time signific synapt chang accumul plastic effect driven integr long time period brain nonvanish spike correl sometim observ even limit unlik poisson spike train these correl often rough symmetr zero case produc littl plastic pair function antisymmetr figur la lb other hand spike correl asymmetr could lead substanti effect effect recurr network dynam learn rule depend presynapt postsynapt rate like learn rule convent use neural network special featur they depend on time deriv comput consequ recurr neural network form wiju xj bi such classic neural network equat deriv biophys realist model use method averag mean field approxim fire rate neuron convent identifi vj cost function li quantifi amount drift fire rate point xl state space network we consid vi function ij defin gradient ofth cost function respect ij given bwij xi vivj assum monoton increas function xd follow differenti hebbian updat increas cost function spike-bas learn stabil ofpersist neural activ henc increas magnitud drift veloc contrast differenti antihebbian updat decreas drift veloc this suggest differenti anti-hebbian updat could use creat fix point network dynam persist activ spike autaps model preced argument drift veloc base on approxim rate-bas descript learn network dynam it import implement spike-bas learn spike network dynam check approxim valid therefor we numer simul simpl recurr circuit integrate-and-fir neuron shown figur core circuit memori neuron make excitatori autaps onto it also receiv synapt input three input neuron tonic neuron excitatori burst neuron inhibitori burst neuron it known this circuit store shortterm memori analog variabl persist activ strength autaps tonic synaps precis inhibitori burst tune here we show this tun ing accomplish spikebas learn rule dfigur circuit diagram autaps model ifferenti anti-hebbian pair function like figur memori neuron describ equat dr tsyn dt dv dt membran potenti when reach v'thres spike consid occur reset vreset each spike time tn caus jump synapt activ size cy.r/tsyn decay exponenti time constant tsyn next spike synapt conduct memori neuron given term recurr excit autaps strength autaps synapt activ ro tonic excitatori burst inhibitori burst neuron govern equat like differ these neuron synapt input fire pattern instead determin appli current lapp lapp lapp tonic neuron constant appli current make it fire repetit rough hz figur excitatori inhibitori burst neuron appli current normal zero except brief ms current puls caus burst action potenti shown figur synapt strength wo arbitrarili set learn burst neuron caus transient chang fire rate memori neuron appli spike-bas learn rule tune memori xie h. s. seung i iiiiiiiii i iuiiiiiiii i untun i i i tune 1iiiiiiiiiiiiiiiiiiiiiiiiiiiniiiiii'.tl i sec figur untun tune autaps activ middl three trace membran potenti three input neuron figur spike drawn reset time integrate-and-fir neuron befor learn activ memori neuron persist shown top trace spike-bas learn rule appli synapt weight wand then burst input caus persist chang activ em nf gl j-ls vl my ve my vi my vthres my vr eset my tsyn ms iapp na i app na ts yn ms tsyn ts ms neuron abl maintain persist activ interburst interv after one burst befor next we made synapt chang use differenti antihebbian pair function asin 7l'tjt spike time differ rang ms result increas persist time seen figur along valu synapt weight versus time quantifi perform system maintain persist activ we determin relationship dv dt use long sequenc interburst interv defin reciproc interspik interv wand wo fix optim tune valu there still residu drift shown figur but if these paramet allow adapt continu even after good tune achiev then residu drift even smaller magnitud this learn rule tweak synapt weight dure each interburst interv reduc drift for particular fire rate autaps learn driven autocorrel spike train rather crosscorrel peak in autocorrelogram at zero lag effect sinc pair function zero at origin sinc the autocorrel zero for small time lag we use fair larg pair rang in simul in recurr network mani neuron a shorter pair rang would suffic the cross-correl vanish near zero discuss we shown differenti anti-hebbian learn tune a recurr circuit maintain persist neural activ this behavior understood reduc the spike-bas learn rule the rate-bas learn rule ofeq the rate-bas approxim good if two condit satisfi first the pair rang must larg the rate learn must slow second spike synchroni must weak littl effect on learn due the shape the pair function the differenti anti-hebbian pair function result in a learn rule use vi a negat feedback signal reduc the amount drift in fire rate as illustr our simul integrate-and-fir neuron excitatori autaps more general the learn rule could relev for tune the strength posit feedback in network maintain a short-term memori analog variabl in persist neural activ spike-bas learn stabil persist neural activ a wo i i tlme at rate hzl figur tune the autaps the persist time activ increas as the weight wand wo tune each transit driven pseudorandom burst input systemat relationship drift dv/dt in fire rate as measur a long sequenc interburst interv if the weight continu fine-tun the drift less with fix well-tun weight for exampl the learn rule could use to improv the robust the oculomotor integr head direct system l1 to mistun paramet in deriv the differenti form the learn rule in we assum the area the posit negat lobe the pair function equal the integr defin vanish in realiti this cancel might exact then the ratio would limit the persist time be achiev the learn rule both the oculomotor integr the head direct system also abl to integr vestibular input to produc chang in activ pattern the problem find general the present learn rule train network to integr is still open
----------------------------------------------------------------

title: 4690-towards-a-learning-theoretic-analysis-of-spike-timing-dependent-plasticity.pdf

toward learning-theoret analysi spike-tim depend plastic david balduzzi mpi intellig system ubingen germani eth zurich switzerland david.balduzzi inf.ethz.ch michel besserv mpi intellig system mpi biolog cybernet t ubingen germani michel.besserv tuebingen.mpg.d abstract paper suggest learning-theoret perspect synapt plastic benefit global brain function introduc model selectron aris fast time constant limit leaki integrate-and-fir neuron equip spike time depend plastic stdp amen theoret analysi show selectron encod reward estim spike error bound spike control spike margin sum synapt weight moreov efficaci spike use reward maxim selectron also depend total synapt strength final base analysi propos regular version stdp show regular improv robust neuron learn face multipl stimuli introduct find principl under learn neural network import problem artifici biolog network eleg suggest global object function may optim learn biolog network howev current known neural plastic mechan use restrict set data larg consist spike diffus neuromodulatori signal global optim procedur could implement neuron cellular level thus difficult problem success approach question rosenblatt perceptron extens multilay perceptron via backpropag similar restrict boltzmann machin construct simpl stochast unit provid remark power approach organ distribut optim across mani layer contrast although signific progress develop understand biolog realist model neuron learn match perform simpler analyt comput tractabl model learn task overview paper construct bridg biolog realist analyt tractabl model selectron model deriv leaki integr fire neuron equip spiketim depend plastic amen learning-theoret analysi aim extract principl implicit stdp thorough investig limit case section introduc selectron state constrain reward maxim problem impli selectron encod empir reward estim spike first result section selectron aris fast time constant limit well-establish model neuron spike plastic suggest cortic neuron may also encod reward estim spiketrain two import question immedi aris first guarante provid spike reliabl predictor global neuromodulatori outcom second guarante provid use spike neuron section answer question provid upper bound suitabl defin loss lower bound efficaci selectron spike measur term contribut expect reward downstream selectron bound control sum synapt weight kwk1 therebi justifi constraint introduc final motiv analysi introduc regular stdp rule show learn robust classic stdp conclud paper proof theorem provid supplementari materi relat work spike-tim depend plastic implic neural code intens studi recent year work closest spirit seung hedonist synaps seek increas averag reward work provid guarante finit sampl behavior discrete-tim analog hedonist neuron anoth relat line research deriv inform bottleneck method provid altern constraint one consid information-theoret perspect synapt homeostasi metabol cost complement result paper found simul combin synapt renorm burst-stdp found import aspect plastic consid properti specif continuoustim model stdp behavior tempor filter also issu relat converg learning-theoret properti neural network intens studi most focus perceptron see exampl non-biolog motiv large-margin analog perceptron propos selectron introduc selectron consid biolog motiv adapt perceptron see mechan govern whether selectron spike heavisid function act weight sum synapt input our contribut propos new reward function correspond learn rule let us establish notat let denot set dimension -valu vector form synapt input selectron set output selectron spike accord fw els heavisid function valu vector specifi selectron synapt weight let denot probabl input aris model neuromodulatori system introduc random variabl posit valu correspond desir outcom negat undesir zero neutral let denot probabl releas neuromodulatori signal subsequ input definit defin reward function fw neuromodul fw margin select els reward consist three compon first term neuromodulatori signal act supervisor second term total current minus threshold analog margin support vector machin boost algorithm see section precis formul third term gate reward accord whether selectron spike reward thus selected1 neuromodulatori signal ignor selectron reward function spike enabl special constrain reward maxim selectron solv follow optim problem bn maxim fw subject kwk1 remark spike encod reward optim problem ensur selectron spike input basi empir sampl reliabl lead neuromodulatori reward thus spike encod expect reward constraint motiv discuss theorem analysi postpon discuss impos constraint focus reward maxim reward maxim problem solv analyt general howev possibl use iter approach although fw continu reward function continu function differenti everywher except corner therefor appli gradient ascent comput deriv respect synapt weight obtain onlin learn rule wj fw els updat factor control learn rate learn rule select regardless neuromodulatori signal synaps wjk updat input output spike fw selectron guarante find global optimum prone initi condit depend local optima reward depend output spike learn rule although undesir properti isol learner less import perhap even advantag larg popul encourag special remark unsupervis set defin unsupervis set reward function reduc fw fw without constraint synaps satur impos constraint yield interest solut selectron find weight vector sum balanc frequent spike high margin theorem control frequenc spike assum synapt input bernoulli variabl spike kwk1 fw bernoulli regim discrete-tim analog homogen poisson set use prove converg reward-modul stdp interest set constraint provid lever control lower bound reward per spike reward per spike fw c1 input bernoulli still covari although precis relationship difficult quantifi although input unrealist note recent neurophysiolog evid suggest neuron fire even nearbi neuron uncorrel name selectron chosen emphas select aspect relat leaki integrate-and-fir neuron equip stdp literatur contain enorm varieti neuron model vari dramat sophist extent incorpor detail under biochem process similar larg menageri model synapt plastic consid two well-establish model gerstner spike respons model srm general leaki integrate-and-fir neuron origin spike-tim depend plastic learn rule propos song al show selectron aris fast time constant limit two model first let us recal srm suppos neuron nk last output spike time tk receiv input spike time tj neuron nj neuron nk spike accord heavisid function appli membran potenti mw fw mw mw tk wjk tj time tk tj input output spike add tj tk tk k2 tk membran potenti tj tk respect here membran synaps time constant origin stdp updat rule wjk tk tj tj tk els time constant stdp potenti input synaps spike prior output spike depotenti input synaps spike subsequ output spike theorem selectron fast time constant limit srm stdp fast time constant limit lim srm transform selectron fw mw mw wjk tk j|tj tk moreov stdp transform learn rule unsupervis set final stdp aris gradient ascent reward function whose limit unsupervis set reward function theorem show stdp implicit maxim time-discount analog reward function expect mani model reward-modul synapt plastic analyt tractabl fast time constant limit import properti share stdp selectron synapt de potenti gate output spike see comparison perceptron gate synapt learn error bound maxim reward function impli selectron encod reward estim spike inde recurs justifi incorpor spike reward function via margin make sens upstream spike predict reward howev larg system estim pile top tendenc overfit lead poor general therefor crucial provid guarante qualiti spike estim boost algorithm output mani weak learner aggreg classifi remark resist overfit number learner increas cortic learn may analog boost individu neuron access tini fraction total brain state weak learner fast time constant limit neuron essenti aggreg we sharpen analog use selectron first step toward understand cortex combat overfit we adapt theorem develop explain effect boost goal show margin constraint synapt weight improv error bound definit selectron incur loss spike follow negat neuromodulatori feedback fw fw els loss fail take estim spike selectron account difficult optim we also introduc hing loss fw fw els note paramet control satur point beyond size margin make differ altern loss2 penal selectron fire t fire howev sinc cortex contain mani neuron spike metabol expens we propos conserv loss penal error commiss first harm penal special theorem spike error bound suppos selectron synaps selectron nk let nk nj nj nk denot 2-layer feedforward subnetwork probabl least log n fw fw 2b hing loss loss 2b capac term log confid term remark theoret justif maxim margin constrain kwk1 theorem show how subset distribut system avoid overfit first demonstr import maxim margin empir reward second show capac term depend number synaps constraint synapt weight rather capac larg hing loss difficult optim direct sinc gate output spike fw render discontinu howev bernoulli regim theorem impli bound theorem rewritten fw bn fw capac term confid term provid lever requir control loss constraint kwk1 best impos offlin see bound efficaci inter-neuron communic even neuron spike perfect predict posit neuromodulatori signal spike matter extent affect neuron cortex spike produc neuron neuron therefor crucial provid guarante use spike this section we quantifi effect one selectron spike anoth selectron expect reward we demonstr lower bound efficaci discuss consequ see error bound definit efficaci spike selectron nj selectron nk rk e rk e rk expect contribut spike selectron nj selectron nk expect reward relat spike notat intend suggest analog differenti infinitesim differ made spike singl synaps efficaci zero e rk e rk word spike nj make differ expect reward nk follow theorem reli assumpt averag contribut neuromodul higher nj spike it spike upstream spike predict reward see precis statement assumpt fals synaps wjk prune theorem spike efficaci bound let pj e y denot frequenc spike neuron nj efficaci nj spike nk lower bound 2e wc wc wj e y c2 pj pj pj pj efficaci wj weight co-spik frequenc co-spik frequenc nk spike frequenc c2 describ wijc efficaci guarante interpret follow first guarante improv co-spik nj nk increas howev denomin impli increas frequenc nj spike worsen guarante insofar nj correl nk similar third term increas nk spike worsen guarante correl nj immedi corollari theorem hebbian learn rule stdp selectron learn rule improv efficaci spike howev it also show naiv increas frequenc spike carri cost neuron therefor face tradeoff fact bernoulli regim theorem impli rewritten rk wj c2 e y wjc constraint synapt strength use lever improv guarante efficaci remark efficaci improv prune weak synaps 1st term suggest prune weak synaps increas efficaci spike may aid learn popul selectron neuron experi cortic neuron constant expos differ input pattern organ engag differ activ it therefor import neuron learn robust chang input this section proof principl we investig simpl tweak classic stdp involv offlin regular we show it improv robust neuron expos one pattern observ regular optim problem yield maxim learn rule fw wj fw kwk1 kwk1 wj incorpor synapt renorm direct updat howev requir continu re-evalu sum synapt weight we therefor decoupl learn an onlin reward maxim phase an offlin regular phase reset synapt weight similar decoupl may occur cortex it recent propos function nrem sleep may regul synapt weight inde neurophysiolog evid suggest averag cortic fire rate increas wake decreas sleep possibl reflect synapt strength experiment evid also point net increas dendrit spine synaps wake net decreas sleep setup we train neuron random input pattern accuraci regular stdp see detail structur input we perform trial classic regular expos neuron new pattern second observ perform classic regular stdp srm neuron classic stdp we use gerstner srm model recal paramet chosen exact coincid k1 k2 synaps stdp implement via paramet also taken synapt weight clip fall regular stdp consist small tweak classic stdp onlin phase an addit offlin regular phase onlin onlin phase reduc depotenti bias classic implement offlin the offlin phase modifi synaps per second accord wj if wj els output spike per second 5hz the target rate updat factor the offlin updat rule fire rate spike depend classic stdp depotenti bias prevent runaway potenti feedback loop lead seizur sinc synaps frequent renorm offlin we incorpor weak exploratori potenti bias the onlin phase help avoid local minima.3 this line experiment evid show increas cortic activ wake sinc comput the sum synapt weight non-physiolog we draw theorem use the neuron fire rate when respond uncorrel input proxi kwk1 thus the offlin phase synaps receiv input generat the onlin phase without repeat pattern note larger prune effect stronger synaps discourag special motiv remark we introduc bias wj the offlin phase ensur weaker synaps downscal strong synaps exampl synaps downscal twice much synaps weight wj regular stdp altern second onlin second offlin suffic renorm synapt strength the frequenc the offlin phase could reduc decreas the updat factor present stimuli less frequent time per second ad inhibitori neuron the system result summari result present the tabl accuraci quantifi the fraction spike co-occur pattern regular stdp outperform classic stdp pattern averag it note regular neuron onlin second also offlin expos poisson nois second interest exposur poisson nois improv perform algorithm accuraci pattern pattern classic regular the input stream contain repeat pattern potenti bias in practic even though the net integr stdp in the onlin phase negat trial accuraci trial accuraci accuraci trial classic stdp accuraci trial regular stdp figur accuraci second exposur novel pattern provid detail analysi each panel show 2d-histogram darker shade gray correspond trial plot accuraci on pattern simultan two 1d histogram plot accuraci on the two pattern separ the 1d histogram regular stdp show unimod distribut pattern the mass accuraci for pattern unlearn for twice long the train period the mass accuraci signific fraction unlearnt contrast classic stdp exhibit extrem brittl behavior it complet unlearn the origin pattern in half the trial also fail learn the new pattern in the trial thus as suggest our analysi introduc a regular both improv the robust stdp enabl an exploratori bias by prevent runaway feedback lead epilept seizur discuss the selectron provid a bridg a particular model spike neuron the spike respons model the origin spike-tim depend plastic rule model amen learning-theoret analysi our hope the selectron relat model lead an improv understand the principl under learn in cortex it remain seen whether stdp-base model also tractabl discrete-tim analog the selectron an interest model in right it emb reward estim spike maxim a margin improv error bound it impos a constraint on synapt weight concentr rewards/spik tighten error bound improv guarante on spike efficaci although the analysi appli direct to continuous-tim model experi show a tweak inspir by our analysi improv the perform a realist model an import avenu for futur research investig the role feedback in cortex specif nmda synaps may interest learning-theoret implic acknowledg we thank timoth ee masqueli for generous share sourc code samori kpotuf for use discuss
----------------------------------------------------------------

title: 1972-self-regulation-mechanism-of-temporally-asymmetric-hebbian-plasticity.pdf

self-regul mechan tempor asymmetr hebbian plastic narihisa matsumoto graduat school scienc engin saitama univers riken brain scienc institut saitama japan xmatumo brain.riken.go.jp masato okada riken brain scienc institut saitama japan okada brain.riken.go.jp abstract recent biolog experiment find shown synapt plastic depend relat time pre postsynapt spike determin whether long term potenti ltp occur long term depress ltd synapt plastic call tempor asymmetr hebbian plastic mani author numer shown spatiotempor pattern store neural network howev mathemat mechan storag spatio-tempor pattern still unknown especi effect ltd paper employ simpl neural network model show interfer ltp ltd disappear spars code scheme hand known covari learn indispens store spars pattern also show tah qualit effect covari learn spatio-tempor pattern embed network introduct recent biolog experiment find indic synapt plastic depend relat time pre post synapt spike determin whether long term potenti ltp occur long term depress ltd ltp occur presynapt fire preced postsynapt one contrast ltd occur presynapt fire follow postsynapt one rapid transit occur ltp ltd within time differ ms learn rule call tempor asymmetr hebbian learn spike time depend synapt plastic stdp mani author numer shown spatio-tempor pattern store neural network song discuss variabl spike generat network consist spike neuron use tah found condit area ltd slight larger ltp indispens stabil name balanc ltp ltd crucial yoshioka also discuss associ memori network consist spike neuron use tah he found area ltp need equal ltd stabl retriev munro hernandez numer show network retriev spatio-tempor pattern even noisi environ owe ltd howev they discuss reason tah effect term storag retriev spatio-tempor pattern sinc tah effect ltp ltd interfer ltp ltd may prevent retriev pattern investig unknown mathemat mechan retriev employ associ memori network consist binari neuron simplifi dynam intern potenti enabl us analyz detail retriev process use learn rule similar formul previous work show mechan spatio-tempor pattern retriev network there mani work concern associ memori network store spatio-tempor pattern covari learn mani biolog find impli spars code scheme may use brain wellknown covari learn indispens spars pattern embed network attractor inform fire rate store pattern indispens tah although indispens covari learn theoret show tah qualit effect covari learn spatio-tempor pattern embed network mean differ spike time induc ltp ltd effect fire rate inform cancel spike time differ conclud reason tah requir inform fire rate store pattern model investig network consist binari neuron connect mutual paper consid case use neuron model binari state also use discret time step follow synchron updat rule ui jij state i-th neuron time ui intern potenti uniform threshold i-th neuron fire time state otherwis specif valu threshold discuss later jij synapt weight j-th neuron i-th neuron element memori pattern generat independ prob prob expect thus consid mean fire rate memori pattern memori pattern spars code scheme call spars code synapt weight jij follow synapt plastic depend differ spike time i-th post j-th neuron differ determin whether ltp occur ltd such learn rule call tempor asymmetr hebbian learn spike time depend synapt plastic biolog ltp ltp jij chang epsp amplitud experiment find indic ltp ltd induc differ pre post-synapt spike time fall within figur defin one time step equat correspond figur time durat within ignor figur figur show ltp occur j-th neuron fire one time step i-th neuron ltd occur j-th neuron fire one time step i-th neuron previous work indic blanc ltp ltd signific therefor defin area ltp ltd ltd tpre tpost tj ti figur tempor asymmetr hebbian plastic result biolog find learn rule model ltp occur j-th neuron fire one time step i-th one contrari ltd occur j-th neuron fire one time step i-th one synapt weight jij follow rule ltd amplitud ltp also ltd. basi definit employ follow learn rule jij number memori pattern defin load rate there critic valu load rate if load rate larger pattern sequenc becom unstabl call storag capac previous work shown learn method equat store spatio-tempor pattern pattern sequenc show memori pattern retriev period like word retriev here discuss valu threshold well-known threshold valu control accord progress retriev process timedepend one candid algorithm control threshold valu maintain mean fire rate network memori pattern follow known obtain threshold valu near optim sinc it approxim give maxim storag capac valu theori mani neural network model store retriev sequenti pattern tah discuss mani author they numer shown tah effect store pattern sequenc exampl munro hernandez show model could retriev store pattern sequenc even noisi environ howev previous work mention reason tah effect explor such mechan main purpos paper here discuss mechan network learn tah store retriev sequenti pattern befor provid detail retriev process discuss simpl situat number memori pattern small relat number neuron let state time t-th memori pattern then intern potenti equat given ui ui depend two independ random variabl accord equat first term equat signal term recal pattern design retriev time second term interfer retriev accord equat ui take valu mean interfer ltd exist if threshold set influenc interfer interfer influenc retriev consid probabl distribut intern potenti ui examin interfer ltd influenc retriev probabl then probabl distribut given equat prob ui sinc threshold set state probabl overlap state x memori pattern given f xi spars limit probabl approach mean interfer ltd disappear spars limit model retriev next pattern then overlap approach next discuss whether inform fire rate indispens tah investig consid case number memori pattern extens larg o n use equat intern potenti ui i-th neuron time repres ui mt zi zi zi call cross-talk nois repres contribut non-target pattern exclud prevent target pattern retriev disappear finit load case it well-known covari learn indispens spars pattern embed network attractor spars code scheme unless covari learn employ cross-talk nois diverg larg limit consequ pattern store inform fire rate store pattern indispens tah although it indispens covari learn use method statist neurodynam examin whether varianc cross-talk nois diverg if pattern sequenc store cross-talk nois obey gaussian distribut mean time-depend varianc otherwis diverg sinc chang time it necessari control threshold appropri valu each time step accord statist neurodynam obtain recurs equat overlap mt network state target pattern varianc detail deriv shown elsewher here show recurs equat mt 2f mt 2f 2f 2f 2f erf exp ca equat reveal varianc cross-talk nois diverg long pattern sequenc retriev result mean tah qualit effect covari learn next we discuss mechan varianc cross-talk nois diverg let us consid equat synapt weight jij j-th neuron i-th neuron also deriv follow jij equat impli tah inform fire rate memori pattern spatio-tempor pattern embed network therefor varianc cross-talk nois diverg anoth factor network learn tah store retriev pattern sequenc we conclud differ spike time induc ltp ltd effect fire rate inform cancel this spike time differ result we investig properti model examin follow two condit fix threshold time-depend threshold use statist neurodynam comput simul overlap solid activity/f dash figur show overlap mt mean fire rate network depend load rate mean fire rate memori pattern threshold storag capac maximum respect threshold store pattern sequenc retriev initi overlap m1 greater critic valu mc lower line indic critic initi overlap depend on load rate word lower line repres basin attract retriev sequenc upper line denot steadi valu overlap mt pattern sequenc retriev mt obtain set initi state first memori pattern this case storag capac dash line show steadi valu normal mean fire rate network pattern sequenc data point error bar indic result comput simul neuron former indic mean valu latter varianc trial sinc result load rate figur critic overlap lower line overlap stationari state upper line dash line show mean fire rate network divid fire rate threshold number neuron data point error bar show mean varianc respect trial comput simul storag capac comput simul coincid statist neurodynam hereaft we show result statist neurodynam overlap solid activity/f dash next we examin threshold control scheme equat threshold control maintain mean fire rate network pn equat equal mean fire rate n1 under condit thus threshold adjust satisfi follow equat 2f 2f figur show overlap mt function load rate storag capac basin attract becom larger fix threshold condit figur thus network becom robust nois this mean even if initi state differ first memori pattern state includ lot nois pattern sequenc retriev load rate figur critic overlap lower line overlap stationari state upper line when threshold chang time maintain mean fire rate network dash line show mean fire rate network divid fire rate basin attract becom larger fix threshold condit figur final we discuss storag capac depend on fire rate memori pattern it known storag capac diverg log spars limit therefor we investig asymptot properti storag capac spars limit figur show storag capac depend on fire rate threshold control maintain network activ symbol storag capac diverg log spars limit figur storag capac function case maintain activ symbol ths storag capac diverg log in spars limit discuss use simpl neural network model we discuss mechan tah enabl network store retriev pattern sequenc first we show interfer ltp ltd disappear in spars code scheme this factor enabl network store retriev pattern sequenc next we show mechan tah qualit effect covari learn analyz stabil store pattern sequenc retriev process mean the statist neurodynam consequ the varianc cross-talk nois diverg this anoth factor for the network learn tah store retriev pattern sequenc we conclud the differ in spike time induc ltp ltd the effect the fire rate inform cancel this spike time differ we investig the properti model to improv the retriev properti the basin attract we introduc threshold control algorithm threshold valu adjust to maintain the mean fire rate the network memori pattern result we found this scheme enlarg the basin attract the network becam robust nois we also found the load rate diverg log in a spars limit here we compar the storag capac model the model use the covari learn figur the dynam equat the model use the covari learn deriv kitano aoyagi we calcul the storag capac cov dynam equat compar these model tcah the ratio tcah cov the threshold control method the in this paper as decreas the ratio storag capac approach the contribut ltd reduc the storag capac model to half therefor in term the storag capac the covari learn better tah but as we discuss previous the inform the fire rate indispens in tah in biolog system to get the inform the fire rate difficult cov tah figur the comparison the storag capac model the model use the covari learn as decreas the ratio storag capac approach log10f
----------------------------------------------------------------

