query sentence: Bayesian framework
---------------------------------------------------------------------
title: 5537-a-statistical-decision-theoretic-framework-for-social-choice.pdf

statist decision-theoret framework social choic hossein azari soufiani david c. park lirong xia abstract paper take statist decision-theoret viewpoint social choic put focus decis made behalf system agent framework given statist rank model decis space loss function defin paramet decis pair formul social choic mechan decis rule minim expect loss suggest general framework design analysi new social choic mechan compar bayesian estim minim bayesian expect loss mallow model condorcet model respect kemeni rule consid various normat properti addit comput complex asymptot behavior particular show bayesian estim condorcet model satisfi desir properti anonym neutral monoton comput polynomi time asymptot differ two rule data generat condorcet model ground truth paramet introduct social choic studi design evalu vote rule rank aggreg rule two main perspect reach compromis among subject prefer agent make object correct decis former extens studi classic social choic context polit elect latter relat less develop even though date back condorcet juri theorem centuri mani multi-ag social choic scenario main consider achiev second object make object correct decis meanwhil also want respect agent prefer opinion requir vote rule satisfi well-establish normat properti social choic exampl group friend vote choos restaur dinner perhap import goal find object good restaur also import use good vote rule social choic sens even applic less societ context use vote rule aggreg rank meta-search engin recommend system crowdsourc semant web social choic normat properti still desir exampl monoton may desir requir rais posit altern vote hurt altern outcom vote rule addit requir vote rule effici comput scenario propos follow new challeng how design new vote rule good statist properti well social choic normat properti tackl challeng develop general framework adopt statist decis theori approach coupl statist rank model explicit decis space loss function azari google.com googl research new york ny usa work done author harvard univers park eecs.harvard.edu harvard univers cambridg ma usa xial cs.rpi.edu renssela polytechn institut troy ny usa anonym neutral major consist monoton condorcet kemeni bayesian est uni prior bayesian est uni prior complex np-hard np-hard pnp hard pnp hard theorem theorem min bayesian risk tabl kemeni winner bayesian estim choos winner given adopt bayesian estim social choic mechan make decis minim expect loss posterior distribut paramet call bayesian risk provid principl methodolog design analysi new vote rule show viabil framework focus select multipl altern altern thought tie first place natur extens loss function two model let denot mallow model fix dispers let denot condorcet model propos condorcet centuri model dispers paramet denot taken fix paramet differ mallow model paramet space compos linear order altern condorcet model paramet space compos possibl cyclic rank altern irreflex antisymmetr total binari relat natur model captur real-world scenario ground truth may contain cycl agent prefer cyclic report linear order due protocol import show later bayesian estim superior comput viewpoint through approach obtain two vote rule bayesian estim evalu respect various normat properti includ anonym neutral monoton major criterion condorcet criterion consist rule satisfi anonym neutral monoton fail major criterion condorcet criterion,1 consist admit two rule enjoy outstand normat properti bad either also investig comput complex two rule strike despit similar two model bayesian estim comput polynomi time comput bayesian estim pnp hard mean least np-hard result summar tabl also compar asymptot outcom two rule kemeni rule winner natur extens maximum likelihood estim propos fishburn turn vote generat three rule select winner asymptot almost sure vote generat accord rule still select winner kemeni howev paramet winner select rule differ non-neglig probabl confirm experi synthet dataset relat work along second perspect social choic make object correct decis addit condorcet statist approach social choic previous work econom polit scienc statist focus extend theorem heterogen correl strateg agent two altern see among mani other recent work comput scienc view agent vote sampl statist model comput mle estim paramet maxim likelihood limit approach estim paramet model may direct inform right decis make multi-ag context main approach return modal rank order impli estim paramet altern highest predict margin probabl rank top posit also propos go beyond mle social choic fact young propos select win altern like best top-rank true rank provid formula comput three altern idea formal extend procaccia choos given number altern highest margin new vote rule fail probabl mallow model recent independ work elkind shah investig similar question choos multipl winner condorcet model see special case propos framework exampl pivato conduct similar studi conitz sandholm examin vote rule interpret expect-util maxim awar previous work frame problem social choic viewpoint statist decis theori main conceptu contribut technic approach taken paper advoc general paradigm design statist evalu social choic comput scienc awar previous work follow paradigm design evalu new rule moreov normat properti two vote rule investig paper novel even though rule realli novel result comput complex first rule strengthen np-hard result procaccia complex second rule theorem independ discov elkind shah statist decision-theoret framework quit general allow consider estim minim maximum expect loss maximum expect regret differ context focus uncertainti avail altern lu boutili adopt decision-theoret view design optim vote rule caragianni studi robust social choic mechan model uncertainti character uniqu social choic mechan consist larg class rank model number recent paper comput social choic take utilitarian decision-theoret approach toward social choic evalu joint decis agent subject prefer exampl sum agent subject util social welfar view fit classic approach statist decis theori formul wald framework joint decis evalu object ground truth statist model sever paper machin learn develop algorithm comput mle bayesian estim popular rank model without consid normat properti estim preliminari social choic set altern cm set agent let denot set linear order c. altern let lc denot set linear order rank top agent use linear order vj repres prefer call vote collect agent vote call profil denot vn irresolut vote rule l c n select set winner tie first place everi profil vote pair linear order let kendal v denot kendall-tau distanc number differ pairwis comparison kemeni rule kemeny-young method select linear order minimum kendall-tau distanc prefer profil kemeni p arg minw kendal p well-known variant kemeni select win altern denot kemenyc due fishburn defin vote rule select altern rank top posit win linear order kemeni rule kemenyc top v kemeni p top v top-rank altern vote rule often evalu follow normat properti irresolut rule satisfi anonym insensit permut agent neutral insensit permut altern monoton r p obtain rais posit one multipl vote r p condorcet criterion profil condorcet winner exist must uniqu winner condorcet winner altern beat everi altern pair-wis elect major criterion profil altern rank top posit half vote r p satisfi condorcet criterion also satisfi major criterion consist pair profil p1 p2 profil weight major graph denot wmg p weight direct graph whose vertic edg pair altern weight wp parametr model pr compos three part paramet space sampl space compos dataset set probabl distribut index element distribut index denot given parametr model maximum likelihood estim mle function fmle data fmle paramet maxim likelihood data fmle arg pr p paper focus parametr rank model given parametr rank model mc pr compos paramet space distribut number voter sampl space sn l c n vote generat henc profil sn pr p pr v omit sampl space determin definit mallow model paramet compos linear order paramet profil pr p dispers kendal v w kendal v w normal factor statist decis theori studi scenario decis maker must make decis base data generat parametr model general pr qualiti decis evalu loss function take true paramet decis input paper focus bayesian principl statist decis theori design social choic mechan choic function minim bayesian risk prior distribut precis bayesian risk rb expect loss decis paramet generat accord posterior distribut given data rb given parametr model loss function prior distribut determinist bayesian estim fb decis rule make determinist decis minim bayesian risk fb arg mind rb focus determinist estim work leav random estim futur research exampl discret mle parametr model bayesian estim statist decis problem uniform prior distribut loss function otherwis sens previous mle approach social choic view bayesian estim statist decision-theoret framework social choic loss function uniform prior framework framework quit general flexibl choos parametr rank model decis space loss function prior use bayesian estim social choic mechan common choic definit statist decision-theoret framework social choic tupl mc set altern mc pr parametr rank model decis space loss function let denot set irreflex antisymmetr total binari relat c. let bc denot relat follow moreov kendall-tau distanc defin count number pairwis disagr element rest paper focus follow two parametr rank model dispers fix paramet notat taken mean condit distribut unless take bayesian point view definit mallow model fix dispers condorcet model let denot mallow model fix dispers paramet space given mallow model fix condorcet model paramet space profil pr p z1 kendal v w normal factor kendal v w paramet fixed.3 degener condorcet model two altern kemeni rule select linear order mle formal defin two statist decision-theoret framework associ focus rest paper definit defin loss function ltop ltop otherwis ltop let 2c ltop 2c ltop ltop c c ltop let fb respect fb denot bayesian estim respect uniform prior note ltop definit take paramet decis 2c input make differ loss function take pair paramet input one exampl henc fb1 fb2 mles respect model case exampl focus vote rule obtain framework ltop certain framework limit loss function exampl bayesian estim fb1 fb2 coincid young idea select altern like best top-rank true rank respect give theoret justif young idea followup our framework specif fb1 similar rule studi procaccia fb2 independ studi elkind shah normat properti bayesian estim omit proof found full version arxiv theorem fb1 satisfi anonym neutral monoton fb1 satisfi major condorcet criterion satisfi consist proof sketch anonym neutral obvious satisfi monoton monoton follow follow lemma lemma let denot profil obtain rais posit one vote lc pr p pr p lb pr p pr p major condorcet criterion let c3 cm construct profil rank top posit more half vote fb1 let denot profil compos copi c3 cm cm c3 copi cm c3 hard verifi wmg figur prove find lc lb pr p pr p follow condorcet winner minim bayesian risk mean winner fb1 condorcet model sampl space b c n studi variant sampl space l c n character major condorcet criterion fb open question c3 c4 2k 2k 2k 2k 4k c3 cm wmg 2k 2k c4 c3 2k 4k c4 wmgs p1 left p2 right wmg 6p wmg thm figur wmgs profil proof major condorcet thm consist thm comput complex thm consist construct exampl show fb1 satisfi consist our construct even c3 c4 let p1 p2 denot profil whose wmgs shown figur respect we follow lemma lemma let p2 pr p lc pr p 4k 2k it hard verifi fb fb fb p2 mean fb consist similar we prove follow theorem fb2 theorem fb2 satisfi anonym neutral monoton it satisfi major condorcet criterion consist theorem fb1 fb2 satisfi mani desir normat properti kemeni rule winner hand minim bayesian risk respect kemeni neither addit neither fb1 fb2 satisfi consist mean posit score rule comput complex we consid follow two type decis problem definit better bayesian decis problem statist decision-theoret framework mc prior distribut we given d1 d2 profil we ask whether rb d1 rb d2 we also interest check whether given altern optim decis definit optim bayesian decis problem statist decision-theoret framework mc prior distribut we given profil we ask whether minim bayesian risk rb pnp class decis problem comput oracl machin polynomi np number parallel call np oracl decis problem pnp hard problem exist polynomial-tim many-on reduct it known pnp hard problem np-hard theorem better bayesian decis optim bayesian decis uniform prior pnp hard proof hard both problem prove unifi reduct emeni winner problem pnp complet emeni winner problem we given profil altern we ask rank top least one minim kendal p altern kemeni score smallest distanc profil linear order rank top we next prove bayesian risk larg determin kemeni score profil kemeni score strict lemma smaller kemeni score rb rb let natur number emeni winner instanc altern we add two more altern defin profil whose wmg shown figur use mcgarvey trick wmg contain wmg p subgraph weight time weight wmg p we let tp copi it follow pr p pr p lemma altern strict lowest kemeni score profil it uniqu altern minim bayesian risk dispers paramet mean minim bayesian risk dispers paramet let denot set linear order minim kendal tau distanc let denot this minimum distanc choos arbitrari let it follow kendal p exist rank top posit we let we kendal p kemeni winner then rank top posit kendal p therefor minim bayesian risk kemeni winner if minim bayesian risk then henc better decis check if better optim bayesian decis check if a optim altern pnp hard we note optim bayesian decis theorem equival check whether a given altern fb1 we know whether problem pnp complet in sharp contrast fb next theorem state fb uniform prior in p. theorem ration number5 better bayesian decis optim bayesian uniform prior in p. decis theorem a corollari follow stronger theorem provid a closed-form formula bayesian loss we recal profil pair altern wp weight in weight major graph theorem for uniform prior for profil rb wp comparison kemeni fb1 fb2 summar in tabl accord criteria we consid none three outperform other kemeni well in normat properti minim bayesian risk either hard comput fb1 minim bayesian risk hard comput we would like highlight fb2 minim bayesian risk more import comput in polynomi time despit similar asymptot comparison in this section we ask follow question number voter probabl kemeni fb1 fb2 choos differ winner we show data generat three method equal asymptot almost sure equal probabl theorem let pn denot a profil vote generat given lc then prn kemeni pn fb1 pn fb2 pn howev data generat we a differ stori theorem for fb1 pn kemeni pn vote in pn generat given for there exist for there exist probabl least fb1 pn fb2 pn kemeni pn fb2 pn vote in pn generat given we requir ration to avoid represent issu formula resembl young calcul for three altern it clear whether calcul done for recent it clarifi xia this inde case c1 c5 c2 c4 c3 for probabl differ kemeni figur ground truth asymptot comparison kemeni in definit proof sketch first part theorem prove central limit theorem for second part proof for use acycl illustr in figur theorem suggest larg vote generat it matter much fb1 fb2 kemeni we use a similar observ made for vote rule caragianni hand theorem state when vote generat interest for ground truth paramet fb2 differ two non-neglig probabl we see in the experi this probabl quit larg experi we focus on the comparison rule fb2 kemeni use synthet data generat given the binari relat illustr in figur theorem the comput involv comput exponenti small for larg sinc henc we need a special data structur to handl the comput fb2 a straightforward implement easili lose precis in our experi we use the follow approxim for fb2 definit for profil let b wp wp let the vote rule such that for profil g p arg minc in word select the altern the minimum total weight on the incom edg in the wmg by theorem the bayesian risk larg determin by therefor a good approxim fb2 reason larg formal this state in the follow theorem theorem for fb2 pn g pn vote in pn generat given in our experi data generat by given in figur for for set we generat profil calcul the fraction trial in kemeni differ the result shown in figuir we observ that for the probabl for g pn kemeni pn for most in our experi when the probabl in light theorem these result confirm theorem we also conduct similar experi for found that the winner the the kemeni winner in all random generat profil this provid a check for theorem acknowledg we thank shivani agarw craig boutili yile chen vincent conitz edith elkind ariel procaccia anonym review aaai-14 nips-14 for help suggest discuss azari soufiani acknowledg siebel foundat for the scholarship in last year phd studi park support in part by nsf grant ccf the sea tomkat fund xia acknowledg an rpi startup fund for support
----------------------------------------------------------------

title: 1726-a-variational-baysian-framework-for-graphical-models.pdf

variat bayesian framework graphic model hagai attia hagai gatsby.ucl.ac.uk gatsbi unit univers colleg london queen squar london wc1n u.k. abstract paper present novel practic framework bayesian model averag model select probabilist graphic model approach approxim full posterior distribut model paramet structur well latent variabl analyt manner posterior fall free-form optim procedur natur incorpor conjug prior unlik larg sampl approxim posterior general nongaussian hessian need comput predict quantiti obtain analyt result algorithm general standard expect maxim algorithm converg guarante demonstr approach appli larg class model sever domain includ mixtur model sourc separ introduct standard method learn graphic model data maximum likelihood given train dataset ml estim singl optim valu model paramet within fix graph structur howev ml well known tendenc overfit data overfit becom sever complex model involv high-dimension real-world data imag speech text anoth problem ml prefer complex model sinc paramet fit data better henc ml optim model structur bayesian framework provid principl solut these problem rather focus singl model bayesian consid whole finit infinit class model model posterior probabl given dataset comput predict test data made averag predict individu model weight posterior thus bayesian framework avoid overfit integr paramet addit complex model automat penal assign lower posterior probabl therefor optim structur identifi unfortun comput bayesian framework intract even lwe use term model refer collect paramet structur h. attia simpl case factor analysi see most exist approxim method fall two class markov chain mont carlo method larg sampl method laplac approxim mcmc method attempt achiev exact result typic requir vast comput resourc becom impract complex model high data dimens larg sampl method tractabl typic make drastic approxim model posterior paramet normal even paramet posit definit covari matric addit requir comput ofth hessian may becom quit intens paper i present variat bay practic framework for bayesian comput graphic model vb draw togeth variat idea intract latent variabl model bayesian infer turn draw work framework facilit analyt calcul posterior distribut hidden variabl paramet structur posterior fall free-form optim procedur natur incorpor conjug prior emerg standard form one normal they comput via iter algorithm close relat expect maxim whose converg guarante no hessian need comput addit averag model comput predict quantiti perform analyt model select done use posterior structur in particular bic/mdl criteria emerg limit case general framework restrict our attent in this paper direct acycl graph dag bayesian network let denot visibl data node run data instanc let xn denot hidden node let denot paramet simpli addit hidden node distribut model fix structur fulli defin joint distribut elm in dag this joint factor node p x i tiip ui i pai oi ui yux pai set parent ui oi parametr edg direct toward ui in addit we usual assum independ instanc ie tin p y xn ie we shall also consid set structur control number hidden node function form depend ui i pai includ rang valu assum node number compon in a mixtur model associ set structur a structur prior margin likelihood posterior paramet for a fix structur we interest in two quantiti first paramet posterior distribut p e i second the margin likelihood p y i also known the evid assign structur the data in the follow the
----------------------------------------------------------------

title: 4752-bayesian-hierarchical-reinforcement-learning.pdf

bayesian hierarch reinforc learn soumya ray depart eec case western reserv univers cleveland oh sray case.edu feng cao depart eec case western reserv univers cleveland oh fxc100 case.edu abstract describ approach incorpor bayesian prior maxq framework hierarch reinforc learn defin prior primit environ model task pseudo-reward sinc model composit task complex use mix model-based/model-fre learn approach find optim hierarch polici show empir approach result improv converg non-bayesian baselin use task hierarchi bayesian prior better either alon iii take advantag task hierarchi reduc comput cost bayesian reinforc learn framework task pseudo-reward learn instead manual specifi lead hierarch optim rather recurs optim polici introduct reinforc learn well known framework formal decis make unknown uncertain environ rl agent learn polici map environ state avail action optim measur long-term util various algorithm develop rl appli success varieti task standard rl set suffer least two drawback first difficult scale standard rl approach larg state space mani factor well-known curs dimension second vanilla rl approach incorpor prior knowledg environ good polici hierarch reinforc learn hrl attempt address scale problem simplifi overal decis make problem differ way exampl one approach introduc macro-oper sequenc primit action plan level oper may result simpler polici anoth idea decompos task overal valu function exampl defin task hierarchi partial program choic point structur decomposit provid sever benefit first higher level subtask polici defin call lower level subtask may quit complex result polici higher level subtask may express compact second task hierarchi partial program impos constraint space polici encod knowledg structur good polici therebi reduc search space third learn within subtask allow state abstract state variabl ignor affect polici within subtask also simplifi learn problem hrl attempt address scalabl issu take account probabilist prior knowledg agent may task exampl agent may idea high/low util state may locat util may idea approxim shape valu function polici bayesian reinforc learn address issu incorpor prior model valu function polici specifi good prior lead mani benefit includ initi good polici direct explor toward region uncertainti faster converg optim polici paper propos approach incorpor bayesian prior hierarch reinforc learn use maxq framework decompos overal task subtask valu function individu subtask combin recov valu function overal task extend framework incorpor prior primit environ model task pseudo-reward order avoid build model composit task complex adopt mix model-based/model-fre learn approach empir evalu algorithm understand effect prior addit task hierarchi experi indic take advantag probabilist prior knowledg lead faster converg even hrl task hierarchi bayesian prior complementari sourc inform use sourc better either alon iii take advantag task hierarchi reduc comput cost bayesian rl general tend high task pseudo-reward learn instead manual specifi lead automat learn hierarch optim rather recurs optim polici way bayesian rl hrl synergist bayesian rl improv converg hrl learn hierarchi paramet hrl reduc signific comput cost bayesian rl work assum probabilist prior given advanc focus learn other work address issu obtain prior exampl one sourc prior inform multi-task reinforc learn agent use solut previous rl task build prior model polici futur task also assum task hierarchi given other work explor learn maxq hierarchi differ set background relat work maxq framework composit subtask ti defin semi-markov decis process paramet hsi ci gi si defin set non-termin state ti ti may call parent gi defin set goal state ti action avail within ti describ set child task ci final denot set relev state variabl ti often unifi non-si state gi singl termin predic pi s0 tripl pi fals pi true ci transit probabl defin exit call exit subtask ti pseudo-reward function express prefer possibl exit subtask hierarch polici overal task assign local polici smdp ti hierarch optim polici hierarch polici maximum expect reward hierarch polici said recurs optim local polici subtask optim given subtask polici optim given task graph model-fre model-bas method use learn valu function task-subtask pair model-fre method polici produc maintain valu complet function subtask task valu denot expect valu call child task state recurs estim expect reward obtain execut complet function denot expect reward obtain complet call central idea behind maxq valu recurs decompos term model-bas rmaxq algorithm extend rmax maxq learn model primit composit task valu iter use model learn polici subtask optimist explor strategi use togeth paramet determin often transit reward need seen usabl plan step maxq framework pseudo-reward must manual specifi learn hierarch optim polici recent work attempt direct learn hierarch optim polici alisp partial program general maxq task hierarchi use model-fre approach along task valu complet function extern function qe maintain subtask function store reward obtain parent subtask exit problem here hurt state abstract sinc qe longer local subtask later work address recurs repres qe term task valu complet function link condit probabl parent exit given child exit condit probabl recurs decomposit use comput qe need select action bayesian reinforc learn method incorpor probabilist prior knowledg model valu function polici combin one bayesian model-bas rl algorithm proceed follow step distribut model paramet maintain at step model sampl distribut thompson sampl model solv action taken accord polici obtain yield observ use updat paramet current distribut creat posterior distribut model procedur iter converg variat idea investig exampl work convert distribut model empir distribut qfunction produc polici sampl distribut instead relat littl work exist attempt incorpor probabilist prior hrl found one preliminari attempt build rmax maxq method approach add prior subtask model perform separ bayesian model-bas learn subtask approach construct model subtask complex general instead maintain distribut primit action use mix modelbased/model-fre learn algorithm natur integr standard maxq learn algorithm further show learn pseudo-reward maxq bayesian framework bayesian maxq algorithm section describ approach incorpor probabilist prior maxq use prior primit model pseudo-reward explain pseudo-reward valu function thus approach use prior model valu function integr may need standard bayesian rl appear natur set first describ approach incorpor prior environ model alon assum pseudo-reward fix follow bayesian model-bas rl framework at step distribut environ model initi prior algorithm two main subroutin main bayesian maxq routin algorithm auxiliari ecom pute valu routin algorithm descript valu complet function assum global at start episod bayesian maxq routin call root task initi state current episod maxq execut protocol follow task choos action base current valu function initi random primit action reach execut updat posterior model paramet line valu estim reward function primit action when task exit return parent parent subsequ updat complet function base current estim valu exit state line note maxq valu function composit task recurs comput use complet function subtask reward obtain execut primit action need separ store updat valu function except primit action valu function reward final primit action maintain count mani time execut composit task maintain count mani child action taken when algorithm paramet step execut composit task bayesian maxq call ecomput valu re-estim valu complet function check shown ecomput valu line when activ function recurs re-estim value/complet function subtask current task at level primit action simpli involv resampl reward transit paramet current posterior model composit task use maxq algorithm tabl run algorithm sim episod start current subtask root current pseudoreward estim explain obtain algorithm recurs updat complet function task graph current task note step subtask primit action use model-bas updat when primit action execut task current sampl transit function part line use find next state associ reward use updat complet function similar line bayesian maxq except use sampl model instead believ this descript accur unfortun due languag issu miss technic experiment detail cite articl we unabl replic this work algorithm bayesian maxq input task state updat interv simul episod sim output next state s0 step taken cumul reward cr primit execut observ s0 updat current posterior paramet use s0 updat current valu estim count count return els cr taskstack stack composit while termin ecomput valu sim greedi action hs0 na cri bayesian maxq taskstack.push ha cri s0 a0 s0 as0 arg maxa0 na s0 s0 s0 s0 s0 na s0 cr cr cr na count count end while s0 pdate pseudo reward taskstack return cr end algorithm ecomput valu input task updat interv simul episod sim output recomput valu complet function task graph includ count return end primit sampl new transit reward paramet current posterior els child task ecomput valu sim end sim episod random nontermin state run maxq end end count real environ ecomput valu termin new set value/complet function avail bayesian maxq use select action next we discuss task pseudo-reward pr valu associ subtask exit defin good exit subtask ideal pr exit expect reward hierarch optim polici exit subtask global task root end thus pr valu function this pr would enabl subtask choos right exit context rest task hierarchi standard maxq set manual this problemat presuppos quit detail knowledg hierarch optim polici further set wrong prs result non-converg high suboptim polici sometim this problem sidestep simpli set prs zero result in recurs optim polici howev easi construct exampl recurs optim polici algorithm pdate pseudo reward input taskstack parent pseudo reward tempcr rp na cr while taskstack empti ha na cri taskstack.pop tempcr na tempcr cr0 use tempcr updat pseudo-reward posterior resampl na0 na cr0 cr end while arbitrarili wors hierarch optim polici reason prs major nuisanc paramet in maxq framework what make learn prs tricki valu function also function paramet maxq set differ prs essenti result in new learn problem for this reason simpli tri learn prs in standard tempor differ way fail we show in experi fortun bayesian rl allow us address issu first we treat valu function probabilist unknown paramet second import key idea in bayesian rl lift explor space task paramet instead explor action select bayesian rl perform explor sampl task paramet thus treat pr as unknown bayesian paramet also lead explor valu this paramet an optim valu found in this way hierarch optim polici learn scratch major advantag standard maxq set learn prs we maintain distribut paramet initi prior for simplic we focus task multipl exit sinc otherwis pr effect polici though valu function chang when composit task execut we keep track child task execut in stack when parent exit we obtain new observ prs child comput discount cumul reward receiv after exit ad current estim parent pr algorithm this observ use updat current posterior child pr sinc this valu function estim earli in learn process estim noisi follow prior work we use window contain recent observ when new observ arriv oldest observ remov new one ad new posterior estim comput after updat posterior sampl obtain new pr estim for associ exit this estim use need algorithm next posterior updat combin model-bas prior we hypothes that this procedur iter till converg produc hierarch optim polici empir evalu in this section we evalu our approach test four hypothes first incorpor modelbas prior help speed converg maxq optim polici second task hierarchi still matter good prior avail for primit action third bayesian maxq compar standard flat bayesian rl doe bayesian rl perform better term comput time task hierarchi avail final our approach effect learn prs polici that hierarch optim we first focus evalu first three hypothes use domain zero pr result in hierarch optim evalu hypothes we use two domain fickl version taxi-world state resource-collect state in taxi-world agent control taxi in a grid-world that pick a passeng a sourc locat drop at destin the state variabl consist the locat the taxi the sourc destin the passeng the action avail to the agent consist navig action action to pickup putdown the passeng the agent get a reward upon complet the task a constant reward for everi action a penalti for an erron action further task hierarchi for domain avail in the supplementari materi averag cumul reward per episod b-maxq uninform b-maxq good b-mb-q uninform b-mb-q good b-mb-q good compar simul averag cumul reward per episod b-maxq uninform b-maxq good b-mb-q uninform b-mb-q good b-maxq uninform r-maxq maxq flatq b-maxq uninform maxq r-maxq flatq episod episod figur perform taxi-world top row resource-collect bottom the x-axi show episod the prefix denot bayesian uninformed/good denot the prior denot model-bas left column bayesian method right non-bayesian method bayesian maxq for
----------------------------------------------------------------

title: 2935-variational-bayesian-stochastic-complexity-of-mixture-models.pdf

variat bayesian stochast complex mixtur model kazuho watanab depart comput intellig system scienc tokyo institut technolog mail nagatsuta midori-ku yokohama japan kazuho23 pi.titech.ac.jp sumio watanab i lab tokyo institut technolog swatanab pi.titech.ac.jp abstract variat bayesian framework wide use approxim bayesian learn various applic provid comput tractabl good general perform paper discuss variat bayesian learn mixtur exponenti famili provid addit theoret support deriv asymptot form stochast complex stochast complex correspond minimum free energi lower bound margin likelihood key quantiti model select also enabl us discuss e ect hyperparamet accuraci variat bayesian approach approxim true bayesian learn introduct variat bayesian framework wide use approxim bayesian learn model involv hidden latent variabl mixtur framework provid comput tractabl posterior distribut modest comput cost contrast markov chain mont carlo mcmc method mani applic perform better general compar maximum likelihood estim spite tractabl wide rang applic littl done investig theoret properti variat bayesian learn exampl question like accur approxim true one remain unansw quit recent address issu stochast complex variat bayesian learn gaussian mixtur model clari ed accuraci variat bayesian learn discuss work support ministri educ scienc sport cultur grant-in-aid jsps fellow scientif research paper focus variat bayesian learn general mixtur model name mixtur exponenti famili includ mixtur distribut gaussian binomi gamma mixtur model known non-regular statist model due non-identi abil paramet caus hidden variabl recent studi bayesian stochast complex non-regular model clari ed proven becom smaller regular indic advantag bayesian learn appli non-regular model main result asymptot upper lower bound obtain stochast complex free energi variat bayesian learn mixtur exponenti famili stochast complex import quantiti model select give asymptot form also contribut follow two issu one accuraci variat bayesian learn approxim method sinc stochast complex show distanc variat posterior distribut true bayesian posterior distribut sens kullback inform inde give asymptot form stochast complex log sampl size compar coe cient true bayesian learn discuss accuraci vb approach anoth uenc hyperparamet learn process sinc variat bayesian algorithm procedur minim function nalli give stochast complex deriv bound indic hyperparamet uenc process learn result implic determin hyperparamet valu learn process consid case true distribut contain learner model analyz stochast complex case valuabl compar variat bayesian learn true bayesian learn advantag bayesian learn typic furthermor analysi necessari essenti address model select problem hypothesi test paper organ follow section introduc mixtur exponenti famili model section describ bayesian learn section variat bayesian framework describ variat posterior distribut mixtur exponenti famili model deriv section present main result discuss conclus follow section mixtur exponenti famili denot densiti function input rn given dimension paramet vector b m subset rm general mixtur model paramet vector de ned ak c x|bk integ number compon ak ak ak set mix proport model paramet ak bk mixtur model call mixtur exponenti famili mef model exponenti famili mixtur model probabl distribut compon given follow form exp b f0 call natur paramet inner product vector fm f0 real-valu function input paramet respect suppos function f1 fm constant function linear independ mean e ectiv number paramet singl compon distribut conjug prior distribut mef model given product follow two distribut ak bk ak bk g bk rm constant call hyperparamet function rm mixtur model rewritten follow use hidden variabl yk yk ak c x|bk datum generat kth compon yk bayesian learn suppos train sampl independ ident taken true distribut p0 bayesian learn model whose paramet rst prior distribut paramet set posterior distribut comput given dataset prior exp nhn z x hn empir kullback inform hn p0 log p xi z x normal constant also known margin likelihood evid dataset bayesian predict distribut p x|x given averag model posterior distribut follow p x|x stochast complex de ned log z x also call free energi import data model problem practic use criterion model select hyperparamet prior optim de ne averag stochast complex ex ex denot expect valu set train sampl recent prove follow asymptot log log log ration number natur number respect determin singular set true paramet regular statist model equal number paramet wherea non-regular model mixtur model larger number paramet mean advantag bayesian learn howev bayesian learn one comput stochast complex predict distribut integr posterior distribut typic perform analyt approxim vb framework propos variat bayesian learn variat bayesian framework vb framework bayesian posterior p y hidden variabl paramet approxim variat posterior q y factor q y q y q y posterior hidden variabl paramet respect variat posterior q y chosen minim function de ned q y q y log p x k q y k q y kullback inform true bayesian posterior p y variat posterior q y lead follow theorem proof well known theorem function minim constraint variat posterior q y satisfi exp log p x q y cr q y exp log p x cq denot kullback inform distribut distribut dx log cr cq normal constants2 de ne stochast complex vb learn minimum valu function min r q show accuraci vb approach approxim bayesian learn also use model select sinc give upper bound true bayesian stochast complex variat posterior mef model this subsect deriv variat posterior mef model base de ne variat paramet this model use complet data y1 yn put ki yik nk ki f xi nk yik if ith datum kth compon variabl nk expect number data estim kth compon respect prior variat posterior obtain product follow two distributions3 nk ak r bk nk nk exp k bk g bk nk let nk log bk bk r bk de ne variat paramet ak bk then note variat posterior cq parameter variat paramet therefor denot cq henceforth de ne variat estim vb variat paramet attain minimum valu stochast complex then put obtain ak ak x log s x vb log cq vb s x log p0 therefor aim evalu minimum valu function variat paramet denot expect hereaft omit condit variat posterior abbrevi q y q y main result averag stochast complex vb learn de ned ex assum follow condit true distribut p0 mef model k0 com0 ponent paramet b k k0 k exp b k f0 g b k b k compon b k b j suppos model ak exp bk f0 g bk k0 hold prior distribut paramet given bound iii regard distribut compon fisher inform matrix sati es arbitrari function stationari point interior b condit prove follow theorem main result assum condit then averag stochast complex defin satisfi log ex nhn vb c1 log c2 arbitrari natur number c1 c2 constant independ k0 k0 this theorem show asymptot form averag stochast complex variat bayesian learn coe cient lead term identi ed number compon learner true distribut number paramet compon hyperparamet conjug prior given this theorem nhn log p xi log p xi vb train error comput learn if term ex nhn vb bound function then immedi follow this theorem log log denot matrix whose ijth entri matrix denot determin bound function certain case binomi mixtur mixtur von-mis distribut actual bound function case gaussian mixtur if rn conjectur minus likelihood ratio min nhn lower bound nhn vb order log log sinc dimens paramet averag stochast complex regular statist model coincid bayesian inform criterion given bic log bic theorem claim coe cient log smaller bic this impli advantag non-regular model bayesian learn still remain vb learn outlin proof theorem condit calcul saddl point approxim evalu as follow log op function ak given mk log ak log then log cq in evalu as follow nhn log cq s x nh op p xi log ak c xi bk exp nk constant thus evalu right-hand side speci c point near true paramet obtain upper bound in lower bound in obtain from jensen s inequ constraint ak discuss conclus in this paper show upper lower bound stochast complex mixtur exponenti famili model in vb learn first compar stochast complex shown in theorem one in true bayesian learn mixtur model paramet in compon follow upper bound coe cient in known k0 k0 k0 k0 certain condit prior distribut bound deriv we compar stochast complex put in we k0 k0 k0 op denot a random variabl bound in probabl sinc we obtain log under certain assumpt let us compar vb learn in true bayesian learn compon one paramet hold sinc k0 k. this mean redund compon model vb learn di er from true bayesian learn in this case equal number paramet model henc the correspond log if the upper bound equal this impli the variat posterior close the true bayesian posterior more precis discuss the accuraci the approxim done model on tighter bound exact valu the coe cient in second we point theorem show the hyperparamet in uenc the process the vb learn the coe cient in indic when the prior distribut work elimin the redund compon the model and otherwis it work use the compon and last let us give exampl use the theoret bound in one examin experiment whether the actual iter algorithm converg the optim variat posterior instead local minima by compar the stochast complex theoret result the theoret bound would also enabl us to compar the accuraci the vb learn the laplac approxim the mcmc method as mention in section our result import for develop e ectiv model select method use in the futur work
----------------------------------------------------------------

title: 2912-sensory-adaptation-within-a-bayesian-framework-for-perception.pdf

sensori adapt within bayesian framework percept alan a. stocker eero p. simoncelli howard hugh medic institut center neural scienc new york univers abstract extend previous develop bayesian framework percept account sensori adapt first note perceptu effect adapt seem inconsist adjust intern repres prior distribut instead postul adapt increas signal-to-nois ratio measur adapt oper rang measur stage input rang show chang likelihood function way bayesian estim model account report perceptu behavior particular compar model predict human motion discrimin data demonstr model account common observ perceptu adapt effect repuls enhanc discrimin motiv grow number studi support notion human near optim perform perceptu estim task requir combin sensori observ priori knowledg bayesian formul problem defin optim strategi provid principl yet simpl comput framework percept account larg number known perceptu effect illus demonstr sensorimotor learn cue combin visual motion percept name mani exampl adapt fundament phenomenon sensori percept seem occur process level modal varieti comput principl suggest explan adapt mani base concept maxim sensori inform observ obtain stimulus despit limit sensori resourc mechanist adapt interpret attempt sensori system adjust limit dynam rang maxim inform respect statist stimulus typic exampl observ retina manag encod light intens vari nine order magnitud use ganglion cell whose dynam rang cover two order magnitud achiev adapt local mean well higher order statist visual input short time-scal correspond author bayesian framework provid valid comput explan perceptu process need account behavior perceptu system regardless adapt state general adapt sensori estim task seem two fundament effect subsequ percept repuls estim paramet subsequ stimuli repel adaptor stimulus perceiv valu stimulus variabl subject estim task distant adaptor valu adapt repuls effect report percept visual speed direction-of-mot orient increas sensit adapt increas observ discrimin abil around adaptor visual speed howev also seem decreas away adaptor shown case direction-of-mot discrimin paper show two perceptu effect explain within bayesian estim framework percept note descript abstract function level attempt provid comput model under mechan respons adapt clear separ paper work might seem first glanc similar adapt bayesian estim framework suppos observ want estim properti stimulus denot variabl base measur general measur vector-valu corrupt intern extern nois henc combin noisi inform gain measur priori knowledg advantag accord bay rule probabl stimulus valu given posterior product likelihood particular measur prior normal constant serv ensur posterior proper probabl distribut assump tion squared-error loss function optim estim mean posterior thus note describ estim singl measur discuss measur vari stochast cours mani exposur stimulus thus estim also vari return issu section figur 1a illustr bayesian estim shape arbitrari prior distribut lead averag shift estim toward lower valu true stimulus valu stim likelihood prior fundament constitu bayesian estim model goal describ adapt alter constitu account perceptu effect repuls increas sensit adapt chang prior intuit sensibl hypothesi adapt chang prior distribut sinc prior meant reflect knowledg observ distribut occurr variabl world repeat view stimuli paramet probabl probabl attract posterior likelihood prior modifi prior adapt figur hypothet model adapt alter prior distribut unadapt bayesian estim configur prior lead shift estim relat stimulus paramet stim likelihood function prior distri bution contribut exact valu estim mean posterior adapt act increas prior distribut around valu adapt adapt stimulus paramet consequ subsequ estim stimulus paramet valu stim attract toward adaptor opposit observ perceptu effect thus conclud adjust prior bayesian model account adapt valu adapt presum increas prior probabl vicin adapt figur 1b schemat illustr effect chang prior distribut estim perceiv valu paramet adapt condit attract adapt paramet valu order account observ perceptu repuls effect prior would decreas locat adapt paramet behavior seem fundament inconsist notion prior distribut increas reliabl measur sinc chang prior distribut consist repuls led conclus adapt must chang likelihood function occur order answer question reconsid function purpos adapt assum adapt act alloc more resourc represent paramet valu vicin adaptor result local increas signal-to-nois ratio accomplish exampl dynam adjust oper rang statist input kind increas oper gain around adaptor effect demonstr process retin adapt context bayesian estim framework restrict simpl case scalar-valu measur adapt result narrow condit probabl densiti immedi vicin adaptor thus increas reliabl measur offset broaden condit probabl densiti region beyond adaptor vicin assum total resourc conserv thus increas around adaptor must necessarili lead decreas elsewher figur illustr effect local increas signal-to-nois ratio like unadapt adapt adapt 1/snr m2 m1 adapt likelihood p m| adapt condit figur measur nois condit likelihood two-dimension condit densiti shown grayscal imag unadapt adapt case assum adapt increas reliabl snr measur around paramet valu adaptor balanc decreas snr measur away adaptor likelihood function horizont slice shown plot right result asymmetr chang likelihood agreement repuls effect estim deg adapt adapt deg figur repuls model predict human psychophys differ perceiv direct pre post-adapt condit predict model postadapt percept motion direct repel away direct adaptor typic human subject data show qualit similar repuls effect data fit replot hood function two gray-scal imag repres condit probabl densiti unadapt adapt state they form assum addit nois measur constant varianc unadapt varianc decreas symmetr vicin adaptor paramet valu adapt grow slight region beyond unadapt state likelihood convolut shape varianc equival distribut measur nois howev adapt state becaus likelihood function horizont slice condit surfac longer convolut around adaptor result mean push away adaptor illustr two graph right assum prior distribut fair smooth this repuls effect transfer posterior distribut thus estim simul result qualit demonstr increas measur reliabl around adaptor consist repuls effect common seen result perceptu adapt this section simul adapt bayesian observ assum simpl model chang signal-to-nois ratio due adapt address repuls chang discrimin threshold particular compar model predict previous publish data psychophys experi examin human percept motion direct repuls unadapt state assum measur nois addit normal distribut constant whole measur space thus assum live space likelihood gaussian constant width adapt state assum simpl function descript varianc measur nois around adapt specif we use constant plus differ two gaussian relat discrimin threshold relat discrimin threshold adapt adapt deg figur discrimin threshold model predict human psychophys model predict threshold direct discrimin reduc adaptor also predict two side-lob increas threshold distanc adaptor data human psychophys qualit agreement model data replot also equal area one twice broad final simplic we assum flat prior reason smooth prior would lead result qualit similar then accord we comput predict estim motion direct unadapt adapt case figur 3a show predict differ pre post-adapt averag estim direct function stimulus direct stim adaptor indic arrow repuls effect clear visibl comparison figur 3b show human subject data replot perceiv motion direct grate estim under adapt unadapt condit use two-alternative-forced-choic experiment paradigm plot show chang perceiv direct function test stimulus direct relat adaptor comparison two panel figur indic despit high simplifi construct model predict quit good even includ small consist repuls effect observ degre adaptor chang discrimin threshold adapt also chang abil human observ discrimin direct two differ move stimuli order model discrimin threshold we need consid bayesian framework account mean estim also variabl we recent develop framework use quantit constrain likelihood prior psychophys data this framework account effect measur nois variabl specif provid character distribut stim estim estim given stimulus direct term expect valu varianc function measur nois we write stim varhmi varh stim assum discrimin threshold proport standard deviat stim we predict discrimin threshold chang adapvarh tation figur 4a show predict chang discrimin threshold relat unadapt condit model paramet repuls exampl figur threshold slight reduc adaptor increas symmetr direct away adaptor comparison figur 4b show relat chang discrimin threshold for typic human subject again behavior human observ qualit well predict discuss we shown adapt incorpor bayesian estim framework for human sensori percept adapt seem unlik manifest chang intern represent prior distribut this would lead perceptu bias effect opposit observ in human subject instead we argu adapt lead increas in reliabl measur in vicin adapt stimulus paramet we show this chang in measur reliabl result in chang likelihood function an estim util this likelihood function exhibit commonly-observ adapt effect repuls chang in discrimin threshold we confirm model make quantit predict compar known psychophys data in case human percept motion direct mani open question remain result demonstr indic resourc alloc explan consist the function effect adapt seem unlik theori alon lead uniqu quantit predict the detail form effect specif the constraint impos biolog implement like play role in determin the chang in measur nois as function adaptor paramet valu import character interpret neural respons chang in the context our framework also although we argu chang in the prior seem inconsist adapt effect may chang occur but offset the likelihood effect occur much longer timescal last if one consid sensori percept as the result a cascad success process stage both feedforward feedback connect becom necessari expand the bayesian descript describ this cascad for exampl may possibl interpret this cascad as a sequenc bayesian estim in the measur stage consist the estim comput the previous stage adapt could potenti occur in process stage it fundament interest understand a cascad perform use stabl comput despit the fact that element constant readjust respons properti
----------------------------------------------------------------

title: 4489-efficient-coding-provides-a-direct-link-between-prior-and-likelihood-in-perceptual-bayesian-inference.pdf

effici code provid direct link prior likelihood perceptu bayesian infer xue-xin wei alan a. stocker depart psycholog electr system engin univers pennsylvania philadelphia abstract common challeng bayesian model percept fact two fundament bayesian compon prior distribut likelihood function formal unconstrain argu neural system emul bayesian infer natur constrain way repres sensori inform popul neuron specif show effici code principl creat direct link prior likelihood base under stimulus distribut result bayesian estim show bias away peak prior distribut behavior seem odd tradit view bayesian estim yet one report human percept demonstr framework correct account repuls bias previous report percept visual orient show predict tune characterist model neuron match report orient tune properti neuron primari visual cortex result suggest effici code promis hypothesi constrain bayesian model perceptu infer motiv human percept perfect bias observ larg number perceptu task modal salient one constitut mani well-known perceptu illus suggest howev bias reflect failur percept rather observ attempt optim combin inher noisi ambigu sensori inform appropri prior knowledg world hypothesi refer bayesian hypothesi inde proven quit success provid normat explan percept qualit recent quantit level major challeng form model base bayesian hypothesi correct select two main compon prior distribut belief likelihood function encourag critic bayesian hypothesi altogeth claim arbitrari choic compon alway allow unjustifi post-hoc explan data share critic refer number success attempt constrain prior belief likelihood function base principl ground exampl prior belief defin relat distribut sensori variabl environ case statist relat easi measur local visual orient assum subject learn cours experi time percept other studi constrain likelihood function accord known nois characterist neuron crucial involv specif perceptu process motion tune neuron visual cor http //www.sas.upenn.edu astocker/lab world neural represent effici encod percept bayesian decod figur encoding-decod framework stimulus repres sensori variabl elicit fire rate respons r2 rn popul neuron perceptu task generat good estim present valu sensori variabl base popul respons framework assum encod effici decod bayesian base likelihood prior squared-error loss function tex howev agre find appropri constraint general difficult prior belief likelihood function often select basi mathemat conveni here propos effici code hypothesi offer joint constraint prior likelihood function neural implement bayesian infer effici code provid normat descript neuron encod sensori inform suggest direct link measur perceptu discrimin neural tune characterist environment statist show link extend full bayesian account percept includ perceptu bias valid model framework behavior well neural data character percept visual orient demonstr account report perceptu bias away cardin orient also specif respons characterist orientation-tun neuron primari visual cortex work novel propos two import normat hypothes percept scienc name effici en code bayesian decod might link encoding-decod framework consid percept infer process take place along simplifi neural encodingdecod cascad illustr effici encod effici encod propos tune characterist neural popul adapt prior distribut sensori variabl popul optim repres sensori variabl differ definit optim possibl may lead differ result here assum effici represent maxim mutual inform sensori variabl popul respons definit upper limit total fire activ square-root fisher inform must proport prior distribut order constrain tune curv individu neuron popul also impos homogen constraint requir exist one-to-on map transform physic space unit homogen space unit stimulus distribut becom uniform defin map cumul prior distribut assum neural popul ident tune curv even tile stimulus rang homogen space popul provid effici represent sensori variabl accord constraint tune curv physic space obtain appli invers map context paper consid infer decod estim synonym stimulus distribut sampl fisher inform discrimin averag fire rate fire rate hz effici encod likelihood function likelihood symmetr asymmetr homogen space physic space figur effici encod constrain likelihood function prior distribut deriv stimulus statist effici code defin shape tune curv physic space transform set homogen neuron use map invers cumul prior result likelihood shape constrain prior distribut show heavier tail side lower prior densiti fisher inform discrimin threshold averag fire rate uniform homogen space illustr appli effici encod scheme map concept homogen space exampl symmetr exponenti decay prior distribut key idea here assum effici encod prior stimulus distribut world direct constrain likelihood function particular shape likelihood determin cumul distribut prior result likelihood general asymmetr shown exhibit heavier tail side prior lower densiti bayesian decod let us consid popul sensori neuron effici repres stimulus variabl describ stimulus elicit specif popul respons character vector r2 rn ri spike-count ith neuron given time-window under assumpt variabl individu fire rate govern poisson process write likelihood function fi ri fi fi describ tune curv neuron defin bayesian decod lse estim minim expect squared-error estim true stimulus valu thus lse use bay rule appropri combin sensori evid stimulus prior bayesian estim bias away prior peak bayesian model percept typic predict perceptu bias toward peak prior densiti characterist often consid hallmark bayesian infer origin prior attract prior prior attract likelihood repuls likelihood prior prior repuls bias likelihood likelihood mean posterior mean posterior mean figur bayesian estim bias away prior likelihood function symmetr estim posterior mean averag shift away actual valu sensori variabl toward prior peak effici encod typic lead asymmetr likelihood function whose normal mean away peak prior relat estim determin combin prior attract shift likelihood mean exhibit overal repuls bias likelihood relat narrow blue line estim bias away prior peak common approach choos parametr descript likelihood function comput conveni gaussian consequ likelihood function typic assum symmetr see leav bias bayesian estim main determin shape prior densiti lead bias toward peak prior model framework shape likelihood function constrain stimulus prior via effici neural encod general symmetr non-flat prior heavier tail side lower prior densiti intuit due effici alloc neural resourc side smaller prior densiti encod less accur lead broader likelihood function side likelihood asymmetri pull bay least-squar estim away peak prior time prior pull toward peak thus result estim bias combin two counter-act forc determin prior general deriv estim bias follow formal deriv mean estim bias propos encodingdecod framework specif studi condit bias repuls away peak prior densiti first re-writ estim lse replac invers map homo motiv likelihood homogen geneous space space symmetr given valu elicit popul respons write estim lse p r|f calcul deriv invers function note cumul prior densiti get df p f henc simplifi lse lse p r|f p r|f p r|f we simplifi notat get lse we margin popul order get expect valu estim lse respons space dr lse p r f we defin due symmetri this space shown follow symmetr around true stimulus valu intuit thought normal averag likelihood homogen space we comput expect bias defin invers cumul arbitrari this express general determin intern nois level prior densiti dispers assum prior densiti smooth we expand neighborhood larger support likelihood function use taylor theorem mean-valu form remaind we get lie appli this express we find p f general simpl rule judg sign howev prior monoton interv sign alway sign also likelihood suffici narrow we approxim therefor approxim bias posit constant result quit surpris state long prior monoton support likelihood function expect estim bias alway away peak prior intern neural versus extern stimulus nois deriv estim bias base assumpt uncertainti sensori variabl caus neural respons variabl this level intern nois depend respons magnitud thus modul chang stimulus contrast this contrastcontrol nois modul common exploit perceptu studi intern nois alway lead repuls bias framework if prior monoton if intern nois low likelihood narrow thus bias small increas intern nois lead increas larger bias point likelihood becom wide enough monoton prior support likelihood potenti violat stimulus nois anoth way modul nois level percept random-dot motion stimuli extern nois howev differ effect shape likelihood function compar intern nois it modifi likelihood function convolv it nois kernel extern nois frequent chosen addit symmetr zero-mean gaussian it straightforward prove symmetr extern nois lead chang mean likelihood thus alter repuls effect induc asymmetri howev increas overal width likelihood attract influenc prior increas result estim closer prior peak without extern noise2 percept visual orient we test framework model percept visual orient choic base fact we pretti good estim prior distribut local orient natur imag ii tune characterist orient select neuron visual cortex wellstudi monkey/cat iii bias perceiv stimulus orient well character we start creat effici neural popul base measur prior distribut local visual orient compar result tune characterist popul predict perceptu bias report data literatur effici neural model popul visual orient previous studi measur statist local orient larg set natur imag consist found orient distribut multimod peak two cardin orient shown 4a we assum visual system prior belief orient follow this distribut approxim it formal black line base this prior distribut we defin effici neural represent orient we assum popul model neuron tune curv follow von-mis distribut homogen space top constant spontan fire rate hz we tune curv get correspond tune appli invers transform curv physic space 4b red curv cumul prior concentr paramet von-mis tune curv set homogen space order match measur averag tune width deg neuron area v1 macaqu predict tune characterist neuron primari visual cortex orient tune characterist our model popul well match neurophysiolog data neuron primari visual cortex effici encod predict distribut neuron prefer orient follow prior neuron tune cardin obliqu orient factor approxim a similar ratio found neuron area v1 monkey/cat also tune width model neuron vari deg depend prefer tune match measur tune width ratio neuron tune cardin versus obliqu orient import predict our model tune curv asymmetr such asymmetri inde report orient tune neuron area v1 we comput the asymmetri index our model popul defin previous studi plot it a function the prefer tune neuron the overal asymmetri index our model popul approxim match the measur valu neuron area v1 the cat it also predict neuron tune the cardin obliqu orient show less symmetri tune orient final note predict like chang if the extern nois symmetr a fire rate hz orient deg asymmetri tune width asymmetri asymmetri index width deg prefer tune deg asymmetri index orient deg tune width probabl effici represent imag statist prefer tune deg tune width deg figur tune characterist model neuron distribut local orient in natur imag replot prior use in the model black predict tune curv accord effici code tune width as a function prefer orient tune curv cardin obliqu neuron more symmetr tune orient in both narrowli broad tune neuron neuron show less asymmetri neuron with tune width in neuron with tune width the lower upper end the rang predict exhibit less asymmetri neuron whose width lie in extrem illustr in last two predict test yet predict perceptu bias our model framework also provid specif predict for the expect perceptu bias human show systemat bias in perceiv orient visual stimuli such as array gabor patch two type bias distinguish first perceiv orient show an absolut bias away the cardin orient thus away the peak the orient prior we refer these bias as absolut typic measur by adjust a noise-fre
----------------------------------------------------------------

title: 2565-instance-specific-bayesian-model-averaging-for-classification.pdf

instance-specif bayesian model averag classif shyam visweswaran center biomed informat intellig system program pittsburgh pa shyam cbmi.pitt.edu gregori f. cooper center biomed informat intellig system program pittsburgh pa gfc cbmi.pitt.edu abstract classif algorithm typic induc population-wid model train perform well averag expect futur instanc introduc bayesian framework learn instance-specif model data optim predict well particular instanc base framework present lazi instance-specif algorithm call isa perform select model averag restrict class bayesian network experiment evalu algorithm show superior perform model select intend appli instance-specif algorithm improv perform patient-specif predict model induc medic data ro common use classif algorithm neural network decis tree bayesian network support vector machin typic induc singl model train set instanc intent appli futur instanc call model population-wid model intend appli entir popul futur instanc population-wid model optim predict well averag appli expect futur instanc contrast instance-specif model one construct specif particular instanc structur paramet instance-specif model special particular featur instanc optim predict especi well instanc usual method induc population-wid model employ eager learn model induc train data test instanc encount contrast lazi learn defer process respons test instanc requir learner induc instance-specif model necessarili lazi natur sinc take advantag inform test instanc exampl lazi instance-specif method lazi bayesian rule lbr learner implement zheng webb induc rule lazi fashion exampl neighborhood test instanc rule generat lbr consist conjunct attribute-valu pair present test instanc anteced local simpl na bay classifi consequ structur local simpl bay classifi consist attribut interest parent attribut appear anteced paramet classifi estim subset train instanc satisfi anteced greedi step-forward search select optim lbr rule test instanc classifi evalu uci dataset lbr lowest averag error rate compar sever eager learn method typic eager lazi algorithm select singl model model space ignor uncertainti model select bayesian model averag coher approach deal uncertainti model select shown improv predict perform classifi howev sinc number model practic use model space enorm exact model averag entir model space usual feasibl paper describ lazi instance-specif averag isa algorithm classif approxim bayesian model averag instance-sensit manner isa extend lbr ad bayesian model averag instance-specif model select algorithm isa algorithm current abl direct handl discret variabl comput intens compar eager algorithm result paper show perform well medicin lazi instance-specif algorithm appli patient-specif model improv accuraci diagnosi prognosi risk assess rest paper structur follow section introduc bayesian framework instance-specif learn section describ implement isa section evalu isa compar perform lbr final section discuss result comparison deci si th eo ret rame wo rk use follow notat capit letter like denot random variabl correspond lower case letter denot specif valu assign thus denot variabl assign valu bold upper case letter repres set variabl random vector realize denot correspond bold lower case letter henc denot variabl state given addit denot target variabl predict denot set attribut variabl denot model denot train dataset xt zt denot generic test instanc d. character population-wid instance-specif model select decis theoret term given train data separ generic test instanc bay optim predict zt obtain combin predict model weight posterior probabl follow dm optim population-wid model predict zt follow max xt function give util approxim bay optim estim p zt xt estim p zt xt obtain model m. term p x given d dm optim instance-specif model predict zt follow max valu attribut test instanc xt want predict zt bay optim estim p zt xt equat deriv use equat special case xt differ population-wid instance-specif model note compar equat equat population-wid model select model averag greatest util equat instance-specif model howev select model greatest expect util specif instanc xt predict zt given instanc xt model select use equat never expect util greater model select use equat observ provid support develop instance-specif model equat repres theoret ideal population-wid instancespecif model select respect suggest practic comput current paper focus model averag rather model select ideal bayesian model averag given equat model averag previous appli use population-wid model studi shown approxim bayesian model averag use population-wid model improv predict perform population-wid model select current paper concentr investig predict perform approxim bayesian model averag use instance-specif model st ce eci fi algo ri present implement lazi instance-specif algorithm base framework isa search space restrict class bayesian network select subset model deriv weight averag posterior target variabl zt key characterist search use heurist select model signific influenc weight posterior introduc bayesian network briefli describ isa detail ay bayesian network probabilist model combin graphic represent bayesian network structur quantit inform paramet bayesian network repres joint probabl distribut set random variabl specif bayesian network repres set variabl consist pair direct acycl graph contain node everi variabl arc everi pair node correspond variabl direct probabilist depend convers absenc arc pair node denot probabilist independ correspond variabl repres parameter model bayesian network immedi predecessor node call parent successor immedi remot call descend immedi successor call children node local probabl distribut may discret continu node given state parent complet joint probabl distribut repres parameter factor product local probabl distribut defin node network factor determin independ captur structur bayesian network formal bayesian network markov condit node repres variabl independ nondescend given parent accord markov condit joint probabl distribut model variabl factor follow parent parent xi denot set node parent parent set parent xi empti p xi parent x p xi i od lbr model zheng webb repres member restrict class bayesian network figur use class bayesian network isa model facilit comparison two algorithm figur node repres attribut discret node either outgo arc target node receiv arc z node either parent child z thus partit two set first contain node figur parent everi node second set second contain node figur parent node everi node first set node first set instanti correspond valu test instanc zt predict thus first set node repres anteced lbr rule second set node repres consequ xk figur exampl bayesian network lbr model target node attribut node x1 instanti valu present anteced lbr rule form local simpl bay classifi present consequ indic need order shown present exampl conveni exposit od ag bayesian network equat evalu follow bayesian network compris structur paramet probabl distribut interest weight averag posterior distribut possibl bayesian network weight probabl bayesian network given data sinc exhaust enumer possibl model feasibl even class simpl bayesian network approxim exact model averag select model averag let set model select search procedur possibl model model space describ next section select model averag p zt estim assum uniform prior belief possibl model model posterior p m equat replac margin likelihood p d obtain follow equat uncondit margin likelihood p d equat measur good fit model data also known model score while score suitabl assess model fit joint probabl distribut necessarili appropri assess good fit condit probabl distribut focus predict classif task case suitabl score situat condit model score comput train data instanc score score comput predict sequenti fashion pth train instanc probabl predict observ valu zp target variabl comput base valu variabl preced train instanc valu xp attribut pth instanc one limit score valu depend order data despit limit shown an effect score criterion classif model paramet bayesian network use comput defin follow parent ijk ijk ijk ij ij nijk number instanc train dataset variabl valu parent state ij ijk iii ijk paramet prior interpret belief equival previous observ ijk instanc variabl valu parent state ij ijk od se we use two-phas best-first heurist search sampl model space first phase ignor evid test instanc while search model high score given equat follow second phase search model greatest impact predict zt test instanc we formal first phase search model predict train data well model high condit model score initi model simpl bay network includ attribut children z succeed model deriv current model revers arc child node current model ad new outgo arc remain children instanti node valu test instanc this process perform child current model an incom arc child node consid revers if node valu miss test instanc newli deriv model ad prioriti queue q dure iter search model highest score given equat remov place set follow new model generat describ score ad q first phase termin user-specifi number model accumul r. second phase search model chang current model-averag estim p zt idea find viabl compet model make this posterior probabl predict when competit model found predict becom stabl dure iter search highest rank model remov ad r. rank base much model chang current estim p zt d chang better particular model maxim follow function set model function comput approxim model averag predict zt follow p z score score second phase termin when new model found valu given equat greater user-specifi minimum threshold t. final distribut zt comput model in use equat ev lu we evalu isa uci dataset zheng webb use the evalu lbr the dataset we also evalu simpl bay classifi lbr sb lbr we use the weka implement weka http //www.cs.waikato.ac.nz/ml/weka default set we implement the isa algorithm standalon applic in java the follow set use isa maximum phase-1 model a threshold in phase-2 an upper limit model in r. the paramet prior in equat ijk set error rate obtain averag the result two stratifi 10-fold cross-valid trial total similar use zheng webb sinc lbr isa handl discret attribut all numer attribut discret in a pre-process step use the entropi base discret method describ in for pair train test fold the discret interv first estim the train fold then appli fold the error rate two algorithm a dataset compar a pair t-test carri the signific level the error rate statist obtain the trial the result shown in tabl compar sb isa signific fewer error dataset signific error one dataset compar lbr isa signific fewer error dataset signific error two dataset two dataset chess tic-tac-to isa show consider improv in perform sb lbr respect comput tabl percent error rate simpl bay lazi bayesian rule lbr instance-specif averag a indic the isa error rate statist signific lower the mark sb lbr error rate a indic the isa error rate statist signific higher dataset size anneal audiolog breast chess kr-kp credit echocardiogram glass heart hepat hors colic hous vote hypothyroid iri labor led liver disord lung cancer lymphographi pima postop primari tumor promot solar flare sonar soybean splice junction tic-tac-to wine zoo no class num attrib nom attrib percent error rate sb lbr isa time isa took time longer run lbr averag for a singl test instanc on a desktop comput a ghz pentium processor gb ram lu si a fu ea rc we introduc a bayesian framework for instance-specif model averag present isa one exampl a classif algorithm base on this framework an instance-specif algorithm like lbr model select shown zheng webb perform classif better sever eager algorithm our result show isa extend lbr ad bayesian model averag improv overal on lbr provid support we obtain addit predict improv perform instance-specif model averag rather instance-specif model select in futur work we plan explor the behavior isa with respect the number model averag the effect the number model select in each the two phase the search we also investig method improv the comput effici isa in addit we plan examin heurist for model search well more general model space unrestrict bayesian network the instance-specif framework restrict the bayesian network model that we use in this investig in the futur we plan explor model use this framework our ultim interest appli instancespecif algorithm improv patient-specif predict for diagnosi therapi select prognosi therebi improv patient care a ow this work support the grant the nation librari medicin nlm the univers pittsburgh biomed informat train program we would like thank the three anonym review for help comment
----------------------------------------------------------------

title: 2267-data-dependent-bounds-for-bayesian-mixture-methods.pdf

data-depend bound bayesian mixtur method ron meir depart electr engin technion haifa israel rmeir ee.technion.ac.il tong zhang ibm t.j. watson research center yorktown height ny usa tzhang watson.ibm.com abstract consid bayesian mixtur approach predictor construct form weight averag hypothes space function procedur known lead optim predictor sever case suffici accur prior inform avail clear perform prior assumpt violat paper establish data-depend bound procedur extend previous random approach gibb algorithm fulli bayesian set finite-sampl guarante establish work enabl util bayesian mixtur approach agnost set usual assumpt bayesian paradigm fail hold moreov bound deriv direct appli non-bayesian mixtur approach bag boost introduct motiv standard approach comput learn theori usual formul within so-cal frequentist approach statist within paradigm one interest construct estim base finit sampl possess small loss general error while mani algorithm construct analyz within context clear approach relat standard optim criteria within frequentist framework two classic optim criteria within latter approach minimax admiss criteria character optim estim rigor precis fashion except special case known whether approach use within learn communiti lead optim either sens word hand known certain regular condit bayesian estim lead either minimax admiss estim thus well-defin optim classic frequentist sens fact shown bay estim essenti estim achiev optim sens optim featur provid strong motiv studi bayesian approach frequentist set while bayesian approach wide studi general applic bound frequentist framework recent sever approach attempt address problem paper establish finit sampl datadepend bound bayesian mixtur method togeth optim properti suggest approach becom wide use consid problem supervis learn attempt construct estim base finit sampl pair exampl y1 yn drawn independ accord unknown distribut let learn algorithm base sampl construct hypothesi estim set hypothes h. denot instantan loss hypothesi wish assess true loss expect taken respect particular object provid data-depend bound follow form probabl least empir assess true loss complex term exampl inpth classic vapnik-chervonenki framework empir error h xi depend vcdimens independ hypothesi sampl s. algorithm data-depend bound mean bound complex term depend hypothesi chosen algorithm sampl s. decis theoret bayesian framework consid decis theoret set defin sampl depend loss algorithm let optim predictor name function minim clear best algorithm bay algorithm one alway return assum known interest expect loss algorithm averag sampl es expect taken respect sampl drawn probabl measur consid famili measur possess under prior distribut construct averag risk function respect prior posterior distribut famili induc posterior distribut sampl space algorithm minim bay risk refer bay algorithm fact given prior given sampl optim algorithm return bay optim predictor respect posterior measur mani import practic problem optim bay predictor linear function under probabl measur exampl loss function quadrat name optim bay predictor condit mean name binari classif problem let predictor condit probabl optim classif decis rule correspond test whether also linear function clear bay predictor linear function probabl measur optim bay algorithm respect prior given ab case optim bayesian algorithm regard predictor construct averag predictor respect data-depend posterior refer method bayesian mixtur method while bay estim ab optim respect bay risk shown appropri condit appropri prior also minimax admiss estim general unknown rather may prior inform possibl model view consid hypothesi space algorithm base mixtur hypothes h. contrast classic approach algorithm select singl hypothesi form h. simplic consid countabl hypothesi space h2 general case deferredpto full paper let qj probabl vector name qj qj construct composit predictor fq qj hj observ general fq may great deal complex singl hypothesi hj exampl hj non-polynomi ridg function composit predictor correspond two-lay neural network univers approxim power denot probabl distribut defin name qj hj eh q main featur work establish data-depend bound l eh q loss bay mixtur algorithm there flurri recent activ concern data-depend bound non-exhaust list includ relat vein mcallest provid data-depend bound so-cal gibb algorithm select hypothesi random base posterior distribut essenti result provid bound averag error eh q rather bound error averag hypothesi later langford extend result mixtur classifi use margin-bas loss function general result also obtain use cover number approach describ final herbrich graepel show certain condit bound gibb classifi extend bayesian mixtur classifi howev bound contain explicit depend dimens thm although approach pioneer mcallest came known pac-bay term somewhat mislead sinc optim bayesian method decis theoret framework outlin averag loss function rather hypothes regard learn behavior true bayesian method address pac-bay analysi paper would like narrow discrep analyz bayesian mixtur method consid predictor averag famili predictor respect data-depend posterior distribut bayesian mixtur often regard good approxim true optim bayesian method fact shown equival mani import practic problem therefor main contribut present work extens mention result pac-bay analysi rather unifi set bayesian mixtur method differ regular criteria may incorpor effect perform easili assess furthermor also essenti bound obtain dimension-independ sinc otherwis yield useless result appli kernel-bas method often map input space space high dimension similar result also obtain use cover number analysi howev approach present current paper reli direct comput rademach complex direct give better bound analysi also easier general correspond cover number approach moreov analysi appli direct non-bayesian mixtur approach bag boost befor move deriv bound formal approach consid countabl hypothesi space hj probabl distribut qj h. introduc vector notat qk hk learn algorithm within bayesian mixtur framework use sampl select distribut construct mixtur hypothesi fq order constrain class mixtur use construct mixtur impos constraint mixtur vector let non-neg convex function defin posit fa fq fq denot probabl simplex subsequ section consid differ choic essenti act regular term final mixtur defin loss pn h xi empir loss incur sampl l q mixtur algorithm entrop constraint section consid entrop constraint penal weight deviat signific prior probabl distribut may incorpor prior inform problem weight chosen algorithm base data particular section set kullback-leibl diverg qj log qj let class real-valu function denot independ bernoulli random variabl assum valu equal probabl defin data-depend rademach complex sup respect denot rn note expect rn concentr around mean valu rn thm quot slight adapt result theorem adapt theorem let sequenc point generat independ random accord a probabl distribut let a class measur function r. furthermor let a non-neg lipschitz function lipschitz constant uniform bound a constant probabl least 1x 2n an immedi consequ theorem follow lemma let loss function bound assum lipschitz constant a probabl least l q l q fa 2n next bound empir rademach averag fa use lemma empir rademach complex fa upper bound follow u1 2a rn fa sup hj proof first recal a fact theori convex dualiti let a convex function a domain set dual supp u u known also convex set qj log qj find log ezj definit follow qj log qj log ez sinc arbitrari set h xi conclud a sup a log exp h xi hj take use chernoff bound expect 2respect exp exp a fa exp a log hj a sup log exp hj jensen hj a sup log exp chernoff a sup hj 2n minim respect obtain desir result combin lemma yield basic bound defin lemma theorem let y1 yn a sampl point drawn accord a distribut let a countabl hypothesi class set fa class defin set supj pn hj a probabl least 2a l q l q 2n note hj uniform bound hj then theorem hold a fix valu a use so-cal multipl test lemma obtain corollari let assumpt theorem hold let ai pi a set posit number pi then ai ai probabl least 2ai log 1/pi l q l q 2n note distinct theorem extra factor log pi price paid uniform bound final present a data-depend bound form theorem let assumpt theorem hold then probabl least l q l q max h proof sketch pick ai 2i pi note pi let smallest index ai q impli log 1/pi q log log2 a line algebra present full paper yield desir result result theorem compar deriv mcallest random gibb procedur in latter case first term eh q name averag empir error base classifi in case h q name empir error averag correspond term l e hypothesi sinc eh q potenti much complex singl expect empir term in much smaller correspond term in moreov complex term obtain in fact tighter correspond term in a logarithm factor in although logarithm factor in could probabl elimin thus expect bayesian mixtur approach advoc lead better perform guarante final we comment theorem use obtain so-cal oracl inequ in particular let optim distribut minim comput under distribut known consid an minim algorithm base data select a distribut implicit constant appropri specifi then use standard approach we obtain a bound lack space we defer deriv precis bound full paper general data-depend bound bayesian mixtur kullback-leibl diverg one way incorpor prior inform in section we extend result general convex regular function possibl choic for besid kullback-leibl diverg standard lp norm kqkp in order proceed along line section we let convex function associ name supq a repeat pn argument section we for n1 h xi h xi impli a+ rn fa inf a h xi pn assum second order differenti for h xi h then assum easi show induct xn h xi in remaind section we focus case regular base lp norm consid let p0 max p min q note then p0 if then p0 consid p-norm regular kqkpp in case kzkqq rademach averag result for p-norm regular known in geometr theori banach space type structur banach space also follow khinchtin s inequ we show it easili obtain in framework in this case it easi see substitut in we fa inf a q0 cq q0 kzkq impli q0 kh x kq cq 1x q0 q0 kh xi kq a kh xi kq combin this result method describ in section we establish a bound for regular base lp norm assum kh xi kq finit for pn set kh xi kqq theorem let condit theorem hold set then for probabl least max h q l q l q kqkp p0 p0 kqkp log log kqkp hide a univers constant depend on discuss we introduc analyz a class regular bayesian mixtur approach construct complex composit estim combin hypothes from some under hypothesi class use data-depend weight weight averag approach use extens within bayesian framework well in recent approach such bag boost while bayesian method known favor condit lead optim estim in a frequentist set perform in agnost set reliabl assumpt made concern data generat mechan well understood our data-depend bound allow util bayesian mixtur model in general set while time take advantag the benefit the bayesian approach in term incorpor prior knowledg the bound establish independ the cardin the under hypothesi space direct appli kernel base method acknowledg we thank shimon benjo for help discuss the research r.m partial support the fund for promot research the technion by the ollendorff foundat the electr engin depart the technion
----------------------------------------------------------------

title: 2570-constraining-a-bayesian-model-of-human-visual-speed-perception.pdf

constrain bayesian model human visual speed percept alan a. stocker eero p. simoncelli howard hugh medic institut center neural scienc courant institut mathemat scienc new york univers abstract demonstr basic aspect human visual motion percept qualit consist bayesian estim framework prior probabl distribut veloc favor slow speed here present refin probabilist model account typic trial-to-tri variabl observ psychophys speed percept experi also show data experi use constrain likelihood prior function model specif measur match speed threshold two-altern forc choic speed discrimin task parametr fit data reveal likelihood function well approxim lognorm distribut characterist contrast-depend varianc prior distribut veloc exhibit signific heavier tail gaussian approxim follow power-law function human perceiv visual motion verid various psychophys experi shown perceiv speed visual stimuli affect stimulus contrast low contrast stimuli perceiv move slower high contrast one comput model suggest qualit explain perceptu effect common assum percept visual motion optim either within determinist framework regular constraint bias solut toward zero motion within probabilist framework bayesian estim prior favor slow veloc solut result two framework similar case ident probabilist framework provid principl formul problem term meaning probabilist compon specif bayesian approach reli likelihood function express relationship noisi measur quantiti estim prior distribut express probabl encount particular valu quantiti probabilist model also provid richer descript defin full probabl densiti set possibl percept rather singl valu numer analys psychophys experi made use distribut within framework signal detect theori order model perceptu behavior previous work shown ideal bayesian observ model base gaussian form posterior low contrast probabl densiti probabl densiti high contrast likelihood prior posterior likelihood prior visual speed visual speed figur bayesian model visual speed percept high contrast stimulus likelihood narrow width high signal-to-nois ratio prior induc small shift mean posterior low contrast stimuli measur noisi lead wider likelihood shift much larger perceiv speed lower condit likelihood prior suffici captur basic qualit featur global translat motion percept but behavior result model deviat systemat human perceptu data import regard trial-to-tri variabl precis form interact contrast perceiv speed recent articl achiev better fit model assumpt human contrast percept satur order advanc theori bayesian percept provid signific constraint model neural implement seem essenti constrain quantit likelihood function prior probabl distribut previous work propos likelihood function deriv bright constanc constraint generat principl also previous approach defin prior distribut base general assumpt comput conveni typic choos gaussian zero mean although laplacian prior also suggest paper develop general form bayesian model speed percept account trial-to-tri variabl we use psychophys speed discrimin data order constrain likelihood prior function probabilist model visual speed percept ideal bayesian observ assum observ want obtain estim variabl base measur she/h perform bayesian observ know measur devic ideal therefor measur affect nois henc observ combin inform gain measur priori knowledg do assum prior knowledg valid observ averag perform better estim trust measur accord bay rule probabl perceiv given posterior product likelihood particular measur priori knowledg estim variabl prior normal constant independ ensur posterior proper probabl distribut vmatch vthres v2 figur 2afc speed discrimin experi two patch drift grate display simultan motion without movement subject ask fixat center cross decid present two grate move faster typic psychometr curv obtain paradigm dot repres empir probabl subject perceiv stimulus2 move faster stimulus1 speed stimulus1 fix v2 vari point subject equal vmatch valu v2 pcum threshold veloc vthresh veloc pcum import note measur intern variabl observ necessarili repres space likelihood embodi map nois map far we assum monoton function vm map space m-space do so allow us analyt treat vm space we later propos suitabl form map function ideal bayesian observ select estim minim expect loss given posterior loss function we assum least-squar loss function then optim estim mean posterior equat it easi see model bayesian observ consist fact perceiv speed decreas contrast width likelihood vari invers accuraci measur perform observ presum decreas decreas contrast due decreas signal-to-nois ratio illustr figur shift perceiv speed toward slow veloc grow width likelihood thus bayesian model qualit explain psychophys result two altern forc choic experi we would like examin perceiv speed wide rang condit order constrain bayesian model unfortun perceiv speed intern variabl it obvious design experi would allow subject express it direct perceiv speed access indirect ask subject compar speed two stimuli given trial ideal bayesian observ in two-altern forc choic experiment paradigm simpli decid basi two trial estim stimulus1 stimulus2 stimulus move faster each estim base particular measur for given stimulus speed ideal bayesian observ produc distribut estim noisi over trial observ behavior describ classic signal detect theori base distribut the estim henc the probabl perceiv stimulus2 move although see for exampl determin even chang the prior a bayesian model for a sensorimotor task the estim direct access faster stimulus1 given as the cumul probabl pcum v2 v2 v1 v1 v2 pcum describ the full psychometr curv figur 2b illustr the measur psychometr curv fit experiment situat experiment method we measur match speed pcum threshold pcum in a 2afc speed discrimin task subject present simultan two circular patch horizont drift sine-wav grate for the durat one second figur patch 3deg in diamet display 6deg eccentr either side a fixat cross the stimuli an ident spatial frequenc cycle/deg one stimulus consid the
----------------------------------------------------------------

title: 5553-a-framework-for-testing-identifiability-of-bayesian-models-of-perception.pdf

framework test identifi bayesian model percept luigi acerbi1,2 wei ji ma2 sethu vijayakumar1 school informat univers edinburgh uk center neural scienc depart psycholog new york univers usa luigi.acerbi weijima nyu.edu sethu.vijayakumar ed.ac.uk abstract bayesian observ model effect describ human perform perceptu task much trust faith recov hidden mental represent prior likelihood loss function data howev intrins degeneraci bayesian framework multipl combin element yield empir indistinguish result prompt question model identifi propos novel framework systemat test identifi signific class bayesian observ model practic applic improv experiment design examin theoret identifi infer intern represent two case studi first show experiment design work better remov under degeneraci time interv estim task second find reconstruct represent speed percept task slow-spe prior fair robust motiv bayesian decis theori bdt tradit use benchmark ideal perceptu perform larg bodi work establish human behav close bayesian observ varieti psychophys task efficaci bayesian framework explain huge set divers behavior data suggest stronger interpret bdt process model percept accord formal element decis process prior likelihood loss function independ repres brain share across task import mental represent albeit direct access experiment tentat recov behavior data invert model decis process prior likelihood loss function abil faith reconstruct observ intern represent key understand sever outstand issu complex statist learn natur mental categori link behavior neural represent uncertainti spite success valid conclus reach fit bayesian observ model data question major issu invers map observ behavior element decis process uniqu see degeneraci consid simpl perceptu task observ expos stimulus induc noisi sensori measur bayesian observ report optim estim minim expect loss loss function encod loss cost choos real stimulus optim estim given measur comput follow arg min qmea x|s qprior ds qprior observ prior densiti stimuli qmea observ sensori likelihood function crucial given solut triplet prior qprior likelihood qmea loss function q3 three generic function constant analysi show invers problem ill-pos multipl combin prior likelihood loss function yield ident behavior even consid confound issu latent state if uncontrol redund solut may condemn bayesian model percept sever form model non-identifi prevent reliabl recoveri model compon particular sought-aft intern represent data practic degeneraci prevent enforc constraint shape intern represent allow take constraint includ theoret consider likelihood emerg specif nois model assumpt relat experiment layout observ adopt loss function impos reward system task addit measur obtain either independ experi distinct condit experi bayesian transfer crucial partial control experiment depend experiment design choic reward system number condit separ control experi although sever approach use propos suppress degeneraci bayesian model percept systemat analysi neither empir theoret effect framework perform studi priori run experi paper aim fill gap larg class psychophys task similar issu model non-identifi new psycholog generic techniqu analysi propos here present effici method exploit common structur share mani bayesian model sensori estim first provid general framework allow model perform systemat priori investig identifi abil reliabl recov paramet interest chosen bayesian observ model second show compar identifi within distinct ideal experiment setup framework use improv experiment design section introduc novel class observ model flexibl effici key requir subsequ analysi section describ method effici explor identifi given observ model within framework section show applic techniqu two well-known scenario time percept speed percept conclud remark section bayesian observ model here introduc continu class bayesian observ model parametr vector each valu correspond specif observ use model psychophys task interest current model class extend previous work encompass sensorimotor estim task one-dimension stimulus magnitud variabl durat distanc speed etc direct estim observ this fundament experiment condit repres sever studi field minor modif model also cover angular variabl orient small error multidimension variabl symmetri make actual infer space one-dimension main novel featur present model cover larg represent basi singl parametr still allow fast comput observ behavior necessari requir permit explor complex model space describ section generic observ model construct four step figur sensat stage describ physic stimulus determin intern measur percept stage describ intern measur combin prior yield posterior distribut decision-mak stage describ posterior distribut loss function guid choic optim estim possibl corrupt laps final respons stage describ optim estim lead observ respons sensat stage comput conveni assum stimulus task space come discret experiment distribut stimuli si frequenc pi pi pi nexp discret distribut stimuli common psychophys continu2 intern model generat model percept decision-mak sensat pmea pest respons preport decision-mak percept qmea qprior minimize laps figur observ model graphic model sensorimotor estim task seen outsid subject point view observ object generat model task stimulus induc noisi sensori measur observ decid estim record respons perturb report nois shade node denot experiment access variabl observ intern model task observ perform infer intern measur space unknown stimulus denot observ either choos subject optim valu given intern measur minim expect loss simpli laps probabl observ chosen estim convert task space invers map whole process this panel encod estim distribut pest ous distribut bin approxim desir precis increas nexp due nois sensori system stimulus induc intern measur accord measur distribut pmea general magnitud sensori nois may stimulus-depend task space case shape likelihood would chang point point unwieldi subsequ comput want instead find transform space scale nois stimulus-independ likelihood translate invari supplementari materi assum chang variabl perform function monoton map stimulus task space live intern measur space assum follow parametr form b invers s0 s0 chosen without loss general such discret distribut stimuli map intern space si nexp rang parametr form sensori map approxim weber-fechn law steven law differ valu base nois magnitud s0 power expon supplementari materi determin shape pmea maximum-entropi approach fix first four moment distribut rather general assumpt sensori measur unimod center stimulus intern measur space comput conveni express pmea mixtur two gaussian intern measur space pmea x|f x|f normal distribut mean varianc this paper consid two-compon mixtur deriv easili general compon paramet partial determin specifi first four central moment var x skew x kurt x free paramet remain degre freedom one two gaussian fix pick distribut satisfi unimod local maxim differenti entropi supplementari materi sensat model repres eq allow express larg class sensori model psychophys literatur includ instanc stimulus-depend nois robust mixtur model perceptu stage without loss general repres observ prior distribut qprior mixtur dens regular space gaussian distribut intern measur space qprior wm t| min a2 max min wm mix weight lattic space min max rang intern space prior defin chosen wider true stimulus rang allow model approxim observ prior regul fine-grained represent determin comput constraint analys fix simplic assum observ intern represent likelihood qmea express measur space take form unimod mixtur two gaussian although possibl differ varianc skew kurtosi respect true likelihood write observ posterior distribut qpost mea normal constant prior decision-mak stage accord bayesian decis theori observ optim estim correspond valu stimulus minim expect loss respect loss function true valu stimulus estim general loss could depend in differ way assum function depend stimulus differ in intern measur space subject optim estim arg min qpost dt integr repres expect loss make assumpt loss function well-behav smooth uniqu minimum zero loss minim estim match true stimulus local minima we adopt maximum-entropi approach we restrict class loss function describ as mixtur two invert gaussian although loss function distribut we find conveni parametr in term statist correspond unimod distribut obtain flip upsid mode var skew kurt t0 note we fix locat mode mixtur gaussian global minimum loss zero as remain free paramet fix take local maximum-entropi solut singl invert gaussian alreadi allow express larg varieti loss delta function map strategi quadrat loss practic shown captur human sensorimotor behavior quit well extend rang describ loss asymmetr less peak function crucial eq combin yield analyt express expect loss a mixtur gaussian supplementari materi allow for a fast numer solut we allow possibl observ may occasion deviat bdt due laps probabl in case laps observ estim drawn random the prior the combin stochast estim laps in task space distribut pest qprior the deriv the map in supplementari materi respons stage we assum the observ respons equal the observ estim corrupt independ normal nois in task space due to motor error residu sourc variabl preport report we choos a simpl parameter form for the varianc report s2 the sum two independ nois term constant nois plus nois grow with the magnitud the stimulus in current analysi we interest in observ model percept we explicit model detail the motor aspect the task we includ the consequ respons error the decis make part the model final the main observ the experiment measur the respons probabl densiti presp a respons for a given stimulus observ paramet vector presp report pest x pmea ds dx obtain margin unobserv variabl figur we comput eq an observ model fulli character paramet vector s0 wn m0 m1 an experiment design specifi a
----------------------------------------------------------------

