query sentence: Self-organization of associative database and its applications
---------------------------------------------------------------------
title: 1-self-organization-of-associative-database-and-its-applications.pdf

self-organ associ databas applic hisashi suzuki suguru arimoto osaka univers toyonaka osaka japan abstract effici method self-organ associ databas propos togeth applic robot eyesight system propos databas associ input output first half part discuss algorithm self-organ propos aspect hardwar produc new style neural network latter half part applic handwritten letter recognit autonom mobil robot system demonstr introduct let map given here finit infinit set anoth finit infinit set learn machin observ set pair sampl random y. mean cartesian product comput estim make small estim error measur usual say faster decreas estim error increas number sampl better learn machin howev express perform incomplet sinc lack consider candid assum preliminarili find good learn machin clarifi concept let us discuss type learn machin let us advanc understand self-organ associ databas paramet type ordinari type learn machin assum equat relat x 's 's paramet indefinit name structur equival defin implicit set candid subset map comput valu paramet base observ sampl call type paramet type learn machin defin well approach number sampl increas altern case howev estim error remain etern thus problem design learn machin return find proper structur sens hand assum structur demand compact possibl achiev fast learn word number paramet small sinc paramet uniqu determin even though observ sampl howev demand proper contradict compact consequ paramet type better compact assum structur proper better learn machin elementari concept design learn machin univers ordinari neural network suppos suffici knowledg given though unknown case compar easi find proper compact structur j altern case howev sometim difficult possibl solut give compact assum almighti structur cover various combin orthogon base infinit dimens structur neural network approxim obtain truncat finit dimens implement american institut physic main topic design neural network establish desir structur work includ develop practic procedur comput valu coeffici observ sampl discuss flourish sinc mani effici method propos recent even hardwar unit comput coeffici parallel speed-up sold anza mark iii odyssey e-1 nevertheless neural network alway exist danger error remain etern estim precis speak suppos combin base finit number defin structur essenti word suppos locat near f. case estim error none neglig howev distant estim error never becom neglig inde mani research report follow situat appear complex onc estim error converg valu number sampl increas decreas hard even though dimens heighten properti sometim consider defect neural network recursi type recurs type found anoth methodolog learn follow initi stage sampl set fa instead notat candid equal set map observ first sampl yl fa reduc fi i xt yl i f. observ second sampl fl reduc f2 i xt yl y2 i f. thus candid set becom gradual small observ sampl proceed observ i-sampl write one likelihood estim select henc contrarili paramet type recurs type guarante sure approach number sampl increas recurs type observ sampl yd rewrit valu x 's correl sampl henc type architectur compos rule rewrit free memori space architectur form natur kind databas build manag system data self-organ way howev databas differ ordinari one follow sens record sampl alreadi observ comput estim call databas associ databas first subject construct associ databas establish rule rewri ting purpos adap measur call dissimilari ty here dissimilari ty mean map real whenev howev necessarili defin singl formula defin exampl collect rule written form dissimilar defin structur local henc even though knowledg imperfect flect heurist way henc contrarili neural network possibl acceler speed learn establish well especi easili find simpl 's l 's process analog inform like human see applic paper recurs type show strong effect denot sequenc observ sampl yd one simplest construct associ databas after observ i-sampl follow i algorithm initi stage let empti set everi let equal such min furthermor add produc sa anoth version improv econom memori follow algorithm initi stage let so compos arbitrari element everi let ii-lex equal such si-l min furthermor ii-l xi yi then let si si-l add yi si-l produc si si si-l either construct ii approach increas howev comput time grow proport size si second subject construct associ databas address rule employ econom comput time subsequ chapter construct associ databas purpos propos manag data form binari tree self-organ associ databas given sampl sequenc algorithm construct associ databas follow algorithm step i initi let x root y root yd here variabl assign respect node memor data furthermor let step increas put after reset pointer root repeat follow arriv termin node leaf notat nand xt let mean descend node otherwis let step display yin relat inform next put yin back step otherwis first establish new descend node second let yin yin final back step here loop step stop time also continu now suppos gate element name artifici synaps play role branch prepar then obtain new style neural network gate element random connect algorithm letter recognit recen tli vertic slit method recogn typograph english letters3 elast match method recogn hand written discret english letters4 global train fuzzi logic search method recogn chines charact written squar style etc publish self-organ associ databas realiz recognit handwritten continu english letter nov xk la.t dw1lo sourc document window number sampl nualber sampl es experi result imag scanner take document imag letter recogn use parallelogram window least cover maxim letter process sequenc letter shift window recogn scan word slant direct place window so left vicin may first black point detect then window catch letter part succeed letter recognit head letter perform end posit name boundari line two letter becom known henc start scan boundari repeat oper recogn accomplish recurs task thus major problem come identifi head letter window consid defin follow regard window imag defin accord denot black point left area boundari window imag project onto window imag then measur euclidean distanc fj black point closest b let summat black point b 's divid number b 's regard coupl read posit boundari defin accord oper teach recogn interact relat window imag read boundari algorithm precis if recal read incorrect oper teach correct read via consol moreov if boundari posit incorrect teach correct posit via mous show partial document imag use experi show chang number node recognit rate defin relat frequenc correct answer past trial speciiic window height width slant angular exampl level tree distribut time recognit rate converg experiment recognit rate converg case rare case howev attain sinc distinguish excess lluctuat write if consist y-relat assur like number node increas endless henc clever stop learn recognit rate attain upper limit improv recognit rate must consid spell word one futur subject obstacl avoid movement various system camera type autonom mobil robot report flourishingly6-1o system made author also belong categori now mathemat methodolog solv usual problem obstacl avoid movement cost minim problem cost criterion establish artifici contrarili self-organ associ databas reproduc faith cost criterion oper therefor motion robot after learn becom natur now length width height robot weight visual angl camera robot follow three factor motion turn less advanc less control speed less experi done passageway wid th insid build author laboratori exist becaus experiment intent arrang box smoke stand gas cylind stool handcart etc passag way random let robot take imag camera recal similar imag trace rout preliminarili record this purpos we defin follow let camera face 28deg downward take an imag process it low pass filter scan vertic filter imag bottom top search first point lumin chang excess then su bstitu te point bottom white point top black if obstacl exist front robot white area show area robot move around regard binari 32dot imag process thus defin accord everi let number black point exclusive-or imag regard y 's imag obtain draw rout imag defin accord robot superimpos current camera imag rout recal inquir oper instruct oper judg subject whether suggest rout appropri negat answer draw desir rout mous teach new robot this opera.t defin implicit sampl sequenc reflect cost criterion oper iibub roan stationari uni configur autonom mobil robot system i north rmbi ie unit robot roan experiment environ wall camera imag preprocess fa preprocess cours suggest ion search process for obstacl avoid movement process for posit identif we defin satisfact rate relat frequenc accept suggest rout in past trial in typic experi chang satisfact rate show similar tendenc it attain around time here notic rest mean direct percentag collis in practic we prevent collis adopt supplementari measur at time number node level tree distribut in propos method reflect delic various charact oper for exampl robot train an oper move slowli enough space obstacl one train anoth oper brush quick obstacl this fact give us hint method print charact machin posit identif robot identifi posit recal similar landscap posit data camera imag for this purpos in principl it suffic regard camera imag posit data x 's respect howev memori capac finit in actual compu ter henc we compress camera imag at slight loss inform such compress admitt long precis posit identif in an accept area thus major problem come find suitabl compress method in experiment environ jut passageway at interv section adjac jut at one door robot identifi rough surround landscap section place in it use temporarili triangular survey techniqu if an exact measur necessari realiz former task we defin follow turn camera take panorama imag scan horizont center line substitut point lumin excess chang for black point for white regard binari line imag process thus defin accord for everi project black point onto measur euclidean distanc black point a closest a let summat s. similar calcul exchang role denot number a 's and a 's respect nand defin regard posit integ label section y 's and defin accord in learn mode robot check exact it posit a counter reset period oper robot run arbitrarili passageway within area and learn relat landscap and posit data posit identif beyond area achiev cross plural databas one anoth this task automat except period reset counter name it a kind learn without teacher we defin identif rate relat frequenc correct recal posit data in past trial in a typic exampl it converg around time at time the number level and the level oftre distribut in sinc the identif failur reject consid the trajectori pro blem aris in practic use in order improv the identif rate the compress ratio camera imag must loosen such possibl depend improv the hardwar in the futur show an exampl actual motion the robot base the databas for obstacl avoid movement and for posit identif this exampl correspond a case move from in here the time interv per frame i i actual motion the robot conclus a method self-organ associ databas propos the applic robot eyesight system the machin decompos a global structur unknown a set local structur known and learn univers input-output respons this framework problem impli a wide applic area the exampl shown in this paper a defect the algorithm self-organ that the tree balanc well for a subclass structur a subject impos us to widen the class a probabl solut to abolish the address rule depend direct valu and instead to establish anoth rule depend on the distribut function of valu of it now investig
----------------------------------------------------------------

title: 1105-cholinergic-suppression-of-transmission-may-allow-combined-associative-memory-function-and-self-organization-in-the-neocortex.pdf

cholinerg suppress transmiss may allow combin associ memori function self-organ neocortex michael e. hasselmo milo cekic depart psycholog program neurosci harvard univers kirkland cambridg ma hasselmo katia.harvard.edu abstract select suppress transmiss feedback synaps learn propos mechan combin associ feedback self-organ feed forward synaps experiment data demonstr cholinerg suppress synapt transmiss layer i feedback synaps lack suppress layer iv feedforward synaps network featur use local rule learn map linear separ learn sensori stimuli desir respons simultan present input feedforward connect form self-organ represent input suppress feedback connect learn transpos feedforward connect recal suppress remov sensori input activ self-organ represent activ generat learn respons introduct synapt connect model cortex defin either associ self-organ basi singl featur relat infl uenc modifi synaps post-synapt activ learn figur associ memori postsynapt activ learn determin nonmodifi affer input connect chang storag due synapt transmiss modifi synaps anderson mcnaughton morri self-organ post-synapt activ predomin influenc modifi synaps modif synaps influenc subsequ learn von der malsburg miller model cortic function must combin capac form new represent store associ represent network combin self-organ associ memori function learn complex map function biolog plausibl learn rule hecht-nielsen carpent dayan m. e. hasselmo m. cekic must control influenc feedback associ connect self-organ some network use special activ dynam prevent feedback influenc activ unless coincid feedforward activ carpent new network altern shut feedforward feedback synapt transmiss dayan a. self-organ affer self-organ feedforward associ feedback figur defin characterist self-organ associ memori self-organ synaps post-synapt activ learn depend predomin upon transmiss modifi synaps b synaps mediat associ memori function post-synapt activ learn depend primarili modifi synaps predomin influenc separ affer input c. selforgan associ memori function combin associ feedback synaps select suppress learn recal present model use select suppress feedback synapt transmiss learn allow simultan self-organ associ two region previous experi show neuromodul acetylcholin select suppress synapt transmiss within olfactori cortex hasselmo bower hippocampus hasselmo schnell if model valid neocort structur cholinerg suppress stronger feedback feedforward synaps here review experiment data hasselmo cekic compar cholinerg suppress synapt transmiss layer predomin feedforward feedback synaps brain slice physiolog shown figur util brain slice prepar rat somatosensori neocortex investig whether cholinerg suppress synapt transmiss select feedback feedforward synapt connect possibl feedforward feedback connect show differ pattern termin neocortex shown figur layer i contain primarili feedback synaps cortic region cauller connor wherea layer iv contain primarili affer synaps thalamus feedforward synaps primari neocort structur van essen maunsel use previous develop techniqu cauller connor li cauller test predomin feedback connect layer i stimul layer i record layer i cut prevent spread cholinerg suppress transmiss neocortex activ layer iii test predomin feedforward connect termin layer iv elicit synapt potenti stimul white matter deep layer vi record layer iv we test suppress measur chang height synapt potenti perfus cholinerg agonist carbachol looj,1m figur show perfus carbachol caus much stronger suppress synapt transmiss layer i compar layer iv hasselmo cekic suggest cholinerg suppress transmiss select feedback synaps feedforward synaps i ll-ill i iv v-vi layer iv record region foedback i ll-ill iv v-vi region white matter stimul figur brain slice prepar somatosensori cortex show locat stimul record electrod test suppress synapt transmiss layer i layer iv experi base procedur develop cauller cauller connor li cauller b. anatom pattern feedforward feedback connect within cortic structur base van essen maunsel feedforward layer iv control carbachol oojlm wash i 5ms feedback layer i control carbachol oojlm wash figur suppress transmiss somatosensori neocortex top synapt potenti record layer iv feedforward affer synaps predomin show littl effect l00j.tm carbachol bottom synapt potenti record layer i feedback synaps predomin show suppress presenc looj,1m carbachol m. e. hasselmo m. cekic comput model experiment result support use select suppress comput model hasselmo cekic self-organ feedforward synapt connect associ memori function feedback synapt connect fig propos network use local hebb-typ learn rule support evid physiolog long-tenn potenti hippocampus gustafsson wigstrom learn rule set connect network take fonn tlws 'y w x. design connect region region threshold synapt modif region rate modif output function repres constraint posit valu feedforward connect self-organ properti feedback connect associ memori properti differ depend entir upon select suppress feedback synaps learn implement activ rule form entir network activ rule take fonn ii x ii x x=lk=l ii x=lk=l k=l where repres activ neuron region activ neuron region total number region provid feedforward input total number region provid feedback input aj y input pattern region repres inhibit neuron region repres suppress synapt transmiss learn take a valu recal suppress remov network synaps region take posit valu reflect fact long-rang connect cortic region consist excitatori synaps aris pyramid cell thus inhibit mediat local inhibitori interneuron within a region repres a separ inhibitori connect matrix h. step learn total weight synapt connect nonnal pre-synapt neuron region ij wij wij l1wij synapt weight normal post-synapt neuron region replac sum denomin equat nonnal synapt strength repres slower cellular mechan redistribut pre postsynapt resourc maintain synaps depend upon local influenc simul sensori input stimuli desir output respons learn present affer input neuron region most network use error-bas learn rule consist feedforward architectur separ layer input output unit one imagin this network auto-encod network fold back input output unit region hidden unit region cholinerg suppress transmiss neocortex as exampl function properti network present here train xor problem xor problem previous use as exampl capabl error base train scheme solv problem linear separ specif characterist network pattern use this simul shown figur two logic state compon xor problem repres two separ unit design figur ensur activ network equal for input condit problem appear two xor problem invers logic state solv simultan as shown figur input desir output network present simultan learn region six neuron region project along feedforward connect four neuron region hidden unit network four neuron project along feedback connect six neuron region all connect take random initi weight dure learn feedforward connect undergo self-organ ultim caus hidden unit becom featur detector respond four pattern input region thus row feedforward synapt connect matrix gradual take form individu input pattern stimulus respons yes oeeo eo oeoe oe eooe eo affer input region figur network for learn xor problem unit region unit region four differ pattern affer input present success region input stimuli xor problem repres four unit left desir output design xor not-xor repres two unit right xor problem four basic state on-off off-on input categor yes output on-on off-off input categor output modul appli dure learn form select suppress synapt transmiss along feedback connect this suppress need complet give connect associ memori function hebbian synapt modif caus these connect link featur detect hidden unit region cell region activ pattern hidden unit respond gradual feedback synapt connect matrix becom transpos feedforward connect matrix paramet use simul aj l i function similar converg obtain rapid feedback synapt transmiss prevent con m. e. hasselmo m. cekic vergenc dure learn dure recal modul synapt transmiss remov various input stimuli xor problem present region without correspond output pattern activ spread along self-organ feedforward connect activ specif hidden layer unit respond pattern activ spread back along feedback connect particular unit activ desir output unit activ in two region settl a final pattern recal figur show settl recal network differ stage learn it seen network initi may show littl recal activ erron recal activ after sever cycl learn network settl proper respons the xor problem state converg dure learn recal obtain problem includ recognit whether unit the left right symmetri unit number unit in addit larger scale problem involv multipl feedforward feedback layer shown converg i yes en region i yes region figur output neuron activ in the network shown differ learn step the four input pattern shown at top below these degrad pattern present dure recal miss the respons compon the input pattern the output the region unit the region unit shown at stage learn as learn progress gradual one region unit start respond select input pattern the correct output unit becom activ in respons the degrad input note as learn progress the respons pattern chang gradual incorrect yes correct cholinerg suppress transmiss in the neocortex
----------------------------------------------------------------

title: 251-a-self-organizing-associative-memory-system-for-control-applications.pdf

hormel sell-organ associ memori system lor control applic michael bormel depart control theori robot technic univers darmstadt schlossgraben darmstadt/w.-ger.ani abstract chac storag scheme use basi softwar implement associ emori system ah major part learn control loop lerna major disadvantag chac-concept degre local general area interpol fix paper deal algorithm self-organ variabl general ak base idea t. kohonen introduct sever year research depart control theori robot technic univers darmstadt concern design learn real-tim control loop neuron-lik associ memori lerna self-organ associ memori system control applic control unknown nonlinear process ersu toll control concept use associ memori system ah base cerebellar cortex model chac albus albus storag predict nonlinear process model appropri nonlinear control strategi e ect process respons i plann control input red setpoint co predict process opti.iud control input evalu opti. actual/past process infor. control strate actual control input i unknown process i i short ter e.ori process infor. i i lassocial lie.ori syst figur learn control loop lerna one problem adjust control loop process howev find suitabl set paramet associ memori paramet question determin degre general within memori therefor direct influenc number train step requir learn process behaviour good perform control loop desir small general around given setpoint larg general elsewher actual amount collect data small transit phase two hormel setpoint larg setpoint control therefor self-organ variabl general adapt amount avail data would advantag up work fix general find right paramet meant find best compromis perform learn time requir generat process model paper show possibl introduc self-organ variabl general capabl exist ams/cmac algorithm ams-concept associ memori syst am base cerebellar model articul control cmac present j.s albus inform process structur am divid three stage each compon n-dimension input vector stimulus activ fix number sensori cell recept field overlap n p sensori cell becom activ activ sensori cell group form n-dimension vector these vector map associ cell merg recept field sensori cell describ one vector seen hypercub n-dimension input space therefor recept field associ cell normal applic total number avail associ cell associ cell connect output cell modifi synapt weight output cell comput mean valu weight connect activ associ cell activ weight figur show basic principl associ memori system am self-organ associ memori system control applic output valu input space adjust weight figur basic aechan am train generat output compar desir output error comput equal distribut activ weight map sensori cell associ cell hash-cod mechan use self-organ featur map approach explain self-organ capabl nervous system present t. kohonen kohonen self-organ featur mapft network later interconnect neuron adapt accord densiti train point input space present n-diaension input vector network caus everi neuron produc output signal correl similar input vector templat vector may store synapt weight neuron due mexican-hat coupl function neuron one maximum output activ excit nearest neighbour inhibit neuron farther away therefor generat local respons network activ cell adapt input weight order increas similar input vector if defin recept field neuron number input vector neuron activ greater hormel neuron net yield effect area high densiti train point recept field becom small wherea area low densiti train point size recept field larg mention desir effect workin learn control loop self-organ variabl general both approach sever advantag disadvantag use real-tim control applic ak algorithm one care predefin network coupl function coupl matric among element network associ weight cell generat need train adress quiet produc memori respons one disadvantag fix general paramet eaori unit chosen unlik ah featur map allow adapt network accord input data advantag pay extens search best match neuron network therefor respons time network aay larg real-tia control work big network these problem overcom allow map sensori cell associ cell ak longer fix chang train accomplish this templat vector introduc everi associ cell this vector serv indic stimuli associ cell access previous dure an associ recal stimulus preliminari set associ cell activ hash code mechan due self-organ process dure train templat vector need correspond input vector search self-organ associ memori system control applic best aatch cell templat vector access associ cell compar stiaulus differ vector calcul l.v number search step this vector use comput virtual stimulus compens map error hash-cod mechan best match cell found ns adress virtual stimulus use hash code mechan this search mechan ensur best match cell found even if self organ effect dure train templat cell updat vector associ later distanc neuron network denot valu teaplat vector time denot stimulus is monoton decreas function time later distanc neuron network simul result figur show simul result present algorithm for the dase two dimension stimulus vector hormel figur show the expect posit input space the untrain templat vector denot untrain associ cell figur untrain etwork figur show the network train step stimuli gaussian distribut input space the posit the templat vector train cell shift the direct the better train area so associ cell use repres this area therefor the store inform exact this area figur network train step a self-organ associ memori system for control applic conclus the ney algorithm present introduc the capabl adapt the storag mechan a cmac-typ associ memori accord the arriv stimuli this result in various degre general depend the number train point in a given area therefor make it unnecessari to choos a general factor a compromis sever constraint repres nonlinear function store in this type associ memori some result test present togeth a comparison respect result for the origin am acknowledg this work sponsor the german inistri for technolog bmft grant itr research
----------------------------------------------------------------

title: 972-a-model-of-the-hippocampus-combining-self-organization-and-associative-memory-function.pdf

model hippocampus combin selforgan associ memori function michael e. hasselmo eric schnell joshua berk edi barkai dept psycholog harvard univers kirkland cambridg ma hasselmo katla.harvard.edu abstract model hippocampus present form rapid self-organ represent input arriv via perfor path perform recal previous associ region perform comparison recal affer input region ca comparison drive feedback regul cholinerg modul set appropri dynam learn new represent region ca3 ca network respond novel pattern increas cholinerg modul allow storag new self-organ represent respond familiar pattern decreas acetylcholin allow recal base previous represent requir select cholinerg suppress synapt transmiss stratum radiatum region ca3 cal demonstr experiment introduct number model hippocamp function develop burgess myer gluck touretzki remark simul address hippocamp function within constraint provid physiolog anatom data theori function specif subregion hippocamp format often address physiolog mechan chang dynam learn novel stimuli recal familiar stimuli exampl affer input hippocampus propos form orthogon represent entorhin activ marr mcnaughton morri eichenbaum buckingham simul address problem represent michael e. hasselmo eric schnell joshua berk edi barkai remain stabl alter addit model autoassoci memori function region ca3 marr mcnaughton morri levi eichenbaum buckingham heteroassoci memori function schaffer collater project region ca3 cal levi mcnaughton requir differ activ dynam learn versus recal acetylcholin may set appropri dynam store new inform cortex hasselmo hasselmo hasselmo bower acetylcholin shown select suppress synapt transmiss intrins affer fiber synaps hasselmo bower suppress neuron adapt cortic pyramid cell hasselmo barkai hasselmo enhanc long-term potenti synapt potenti hasselmo model show suppress synapt transmiss learn prevent recal previous store inform interf storag new inform hasselmo hasselmo cholinerg enhanc synapt modif enhanc rate learn hasselmo feedback regul cholinerg modul may set appropri level cholinerg modul depend upon novelti familiar particular input pattern explor possibl mechan feedback regul cholinerg modul simul region cal hasselmo schnell region ca3 we show self-regul learn recal self-organ represent obtain network simul hippocamp format model util select cholinerg suppress synapt transmiss stratum radiatum region demonstr brain slice prepar hippocampus method simplifi representa non hippocamp neuron place sigmoid input-output function use mani model model use simpl represent output neuron explicit constrain total network activ regul feedback inhibitori interneuron adapt due intracellular calcium concentr separ variabl repres pyramid cell membran potenti intracellular calcium concentr membran potenti inhibitori interneuron l1a ai wijg aj hikg h i1c i vg i i1hk qc iwkjg aj-eo -l1hk ihk/g h/-e affer input passiv decay membran potenti il strength cal model hippocampus cium-depend potassium current proport intracellular calcium wij excitatori recurr synaps longitudin associ path tennin stratum radiatum go threshold linear function proport amount membran potenti exceed output threshold threshold calcium current oc strength voltagedepend calcium current diffus constant calcium wki excitatori synaps inhibitori interneuron hilc inhibitori synaps interneuron pyramid cell inhibitori synaps interneuron represent give neuron adapt characterist similar observ intracellular record barkai hasselmo includ promin afterhyperpolar potenti figur n~jjl lo figur comparison pyramid cell model experiment data figur i show membran potenti model pyramid cell respons simul current inject output model continu variabl proport much membran potenti exceed threshold analog reciproc interspik interv real neuron record note model display adapt current inject afterhyperpolar afterward due calcium-depend potassium current show intracellular record membran potenti pirifonn cortex pyramid cell demonstr adapt fire frequenc due activ calcium-depend potassium current fire rate fall manner similar smooth decreas fire rate simplifi represent show intracellular record illustr long-tenn afterhyperpolar caus calcium influx induc spike neuron current inject network connect schemat represent network simul hippocamp fonnat shown figur anatomi hippocamp fonnat summar left function differ subregion model shown right b subregion model contain popul excitatori neuron singl inhibitori interneuron mediat feedback inhibit keep excitatori activ bound thus local activ dynam region follow equat present connect network summar figur result section learn rule hebbian type util synapt connect except mossi fiber dentat gyrus region connect medial septum self-organ perfor path synaps obtain decay synaps pre post-synapt activ growth synaps combin activ associ memori function synaps michael e. hasse/mo eric schnell joshua berk edi barkai aris region ca3 obtain synapt modif cholinerg suppress synapt transmiss entorhin cortex self-organ represent comparison feedback regul cholinerg modul regul learn dynam figur schemat represent hippocamp circuitri correspond function connect model cholinerg modulanon total output region cal determin level cholinerg modul within region ca3 cal increas output caus decreas modul consist experiment evid suggest activ region cal region ca3 inhibit activ medial septum therebi downregul cholinerg modul this effect obtain model excitatori connect region cal inhibitori interneuron medial septum suppress activ cholinerg neuron provid modul full network level cholinerg modul high strong suppress synapt transmiss excitatori recurr synaps ca3 schaffer collater project region ca3 cal this prevent spread activ due previous learn interf self-organ when level cholinerg modul decreas strength synapt transmiss increas allow associ recal domin cholinerg modul also increas rate synapt modif depolar neuron test self-regul learn recal simul full hippocamp network evalu respons sequenti present seri high overlap activ pattern entorhin cortex recal test interspers present degrad version previous present activ pattern effect recal pattern activ entorhin cortex layer iv evok degrad pattern match pattern evok full learn version pattern function full network illustr figur simul model hippocampus focus region activ pattern induc sequenti region repres affer input entorhin cortex differ level extern activ cholinerg neuron result differ level learn new overlap pattern these result illustr figur brain slice experi effect simul region ca3 depend upon cholinerg suppress synapt transmiss stratum radiatum this region cholinerg suppress glutamaterg synapt transmiss region ca3 test brain slice prepar analysi influenc cholinerg agonist carbachol size field potenti elicit stimul stratum radiatum these experi use techniqu similar previous publish work region cal hasselmo schnell result full hippocamp simul input unfamiliar pattern entorhin cortex layer result high level acetylcholin this allow rapid self-organ perfor path input dentat gyrus region cal cholinerg suppress synapt transmiss region cal prevent recal interf self-organ instead recurr collater region ca3 store autoassoci represent input dentat gyrus region connect ca3 ca store associ pattern activ ca3 associ self-organ represent region cal ident self-org matrix auto assoc self-org iden~ hetero.9 hetero8 matrix assoc assoc i i i i i i i ld i i i i i i i i i 3d 4d ld 2d n n i i i i i i i 1i i i i i i itt i.ll i i i i i u. i i i i i i i i i i i i i i j1 iii i i i i i i i i i iii i i w. jl lu neuron figur activ subregion full network simul hippocamp format present sequenc activ pattern entorhin cortex michael e. hasselmo eric schnell joshua berk edi barkai figur width line repres activ neuron particular time step seen here network form self-organ represent new pattern consist activ neuron dentat gyrus region cal time associ form self-organ represent region cal affer input pattern present entorhin cortex layer iv four overlap pattern present sequenti result learn separ selforgan represent dentat gyrus region cal associ form this represent full input pattern entorhin cortex recal characterist network appar when degrad version affer input pattern present sequenc this degrad affer input weak activ represent previous form dentat gyrus recurr excit region ca3 enhanc this activ give robust recal full version this pattern this activ reach ca caus strong activ if match pattern affer input entorhin cortex strong activ region cal decreas cholinerg modul prevent format a new represent allow recal domin strong activ represent store region cal activ full represent pattern entorhin cortex layer iv thus network accur recal mani high overlap pattern effect cholinerg modul level learn recal seen clear a simul auto-associ memori function region ca3 shown figur box show respons network sequenti present full degrad version two high overlap input pattern width black trace repres activ each ca3 pyramid cell each simul step top row level cholinerg modul ach plot a. extern activ cholinerg neuron absent cholinerg suppress synapt transmiss this case first pattern learn recal proper subsequ present a second overlap pattern result recal previous learn pattern b. greater cholinerg suppress recal suppress suffici allow learn a combin two input pattern final c. strong cholinerg suppress prevent recal allow learn the new overlap pattern domin the previous store pattern a store pattern ach inhib ach input ach input ach input i figur increas cholinerg suppress synapt transmiss region ca3 caus greater learn new aspect affer input pattern a model hippocampus extracellular record brain slice prepar hippocamp region ca3 demonstr perfus the cholinerg agonist carbachol strong suppress synapt potenti record stratum radiatum as shown figur contrast suppress synapt transmiss the affer fiber synaps aris entorhin cortex much weaker at a concentr carbachol suppress synapt potenti in stratum radiatum averag synapt potenti elicit in stratum lacunosum weak suppress averag suppress control carbachol wash figur cholinerg suppress synapt transmiss in stratum radiatum ca3 discuss in this model the hippocampus self-organ at perfor path synaps form compress represent specif pattern cortic activ associ event in the environ feedback regul cholinerg modul set appropri dynam learn in respons novel stimuli allow predomin self-organ appropri dynam recal in respons familiar stimuli allow predomin associ memori function this combin self-organ associ memori function may also occur in neocort structur the select cholinerg suppress feedback intrins synaps propos allow self-organ feedforward synaps feedback synaps mediat storag associ higher level represent activ in primari cortic area hasselmo this previous propos could provid a physiolog justif a similar mechan util in recent model dayan detail model cholinerg effect in the hippocampus provid a theoret framework link the consider behavior evid for a role of acetylcholin in memori function hagan morri the neurophysiolog evid for the effect of acetylcholin within cortic structur hasselmo bower hasselmo acknowledg this work support a pilot grant the massachusett alzheim 's diseas research center and an nimh first award
----------------------------------------------------------------

title: 1210-self-organizing-and-adaptive-algorithms-for-generalized-eigen-decomposition.pdf

self-organ adapt algorithm general eigen-decomposit chanchal chatterje vwani p. roychowdhuri newport corpor deer avenu irvin ca electr engin depart ucla los angel ca abstract paper develop two part discuss new approach self-organ single-lay linear feed-forward network first two novel algorithm self-organ deriv two-lay linear hetero-associ network perform one-of-m classif train constrain least-mean-squar classif error criterion second two adapt algorithm deriv selforgan procedur comput princip general eigenvector two correl matric two sequenc random vector novel adapt algorithm implement single-lay linear feed-forward network give rigor converg analysi adapt algorithm use stochast approxim theori exampl consid problem onlin signal detect digit mobil communic introduct studi problem hetero-associ trammg linear discrimin analysi general eigen-decomposit theoret connect paper divid two part first part studi relat hetero-associ train linear feed-forward network featur extract linear discrimin analysi loa criterion here deriv two novel algorithm unifi two problem second part general self-organ algorithm loa obtain adapt algorithm general eigen-decomposit provid rigor proof converg use stochast approxim theori hetero-associ linear discrimin analysi discuss consid special case hetero-associ deal classif problem here input belong finit m-set pattern class self-organ adapt general eigen-decomposit output indic class input belong usual ith standard basi vector ei chosen indic particular input vector belong class lda problem hand aim project multi-class data lower dimension subspac group well-separ cluster class method base upon set scatter matric common known mixtur scatter sm class scatter sb fukunaga matric use formul criteria tr sm-isb det sb det sm yield linear transform satisfi general eigenvector problem general eigenvalu matrix sm posit definit obtain furthermor signific eigenvector class separ determin correspond general eigenvalu relat hetero-associ lda demonstr gallinari work made explicit linear multi-lay perceptron perform one-from-m classif minim total mean squar error mse network output also maxim criterion det sb /det sm lda final hidden layer studi general webb low use nonlinear transform input data final hidden unit linear transform final layer general chatterje roychowdhuri includ bay cost misclassif criteria tr sm-isb although studi offer use insight relat heteroassoci lda suggest algorithm extract optim lda transform sinc criteria class separ insensit multipl nonsingular matric studi suggest train procedur minim mse network output yield nonsingular transform obtain nonsingular matrix sinc satisfi general eigenvector problem arbitrari nonsingular matrix need determin algorithm yield q=i order obtain optimum linear transform constrain train twolay linear feed-forward network converg weight first layer simultan diagon sm sb thus hetero-associ network train minim constrain mse network output train procedur yield two novel algorithm lda lda general eigen-decomposit sinc lda problem general eigen-decomposit problem symmetric-definit case self-organ algorithm deriv heteroassoci network lead us construct adapt algorithm general eigendecomposit adapt algorithm requir sever applic imag signal process exampl consid problem onlin interfer cancel digit mobil communic similar lda problem general eigen-decomposit problem involv matrix pencil assum real symmetr posit definit although solut problem obtain convent method sever applic imag signal process onlin solut general eigen-decomposit desir these real-tim situat matric unknown instead avail two c. chatterje v. roychowdhuri sequenc random vector limk~oo x~/j limk~oo e yky/'i=b xk yk repres onlin observ applic everi sampl need obtain current estim ak respect ak converg strong true valu convent approach evalu requir comput collect sampl applic numer procedur approach work batch fashion two problem approach first dimens sampl may larg even sampl avail perform general eigen-decomposit may take prohibit larg amount comput time second convent scheme adapt slow small chang data approach suitabl real-tim applic sampl come onlin fashion although adapt general eigen-decomposit algorithm natur general self-organ algorithm lda deriv constitut proof converg therefor give rigor proof converg stochast approxim theori show estim obtain adapt algorithm converg probabl one general eigenvector summari studi offer follow contribut present two novel algorithm unifi problem hetero-associ train lda featur extract discuss two single-stag adapt algorithm general eigendecomposit two sequenc random vector experi consid exampl onlin interfer cancel digit mobil communic problem signal desir user far distanc receiv corrupt anoth user near base optimum linear transform weight signal first princip general eigenvector signal correl matrix respect interfer correl matrix experi algorithm suggest rapid converg within four bit transmit signal provid signific advantag mani current method hetero-associ train lda consid two-lay linear network perform one-from-m classif let xe 9t input network classifi one class ro ro desir output d=e ith std basi vector without loss general assum input zero-mean stationari process nonsingular covari matrix extract princip lda compon two-lay linear hetero-associ network let neuron hidden layer output unit aim develop algorithm so indi idual weight vector first layer converg first p~m general eigenvector correspond signific general eigenvalu arrang decreas order let wje9t weight vector input layer vje9t weight vector output layer neuron train sequenti train jlh neuron start weight vector j_i fh neuron converg assum j-i previous neuron alreadi train weight converg self-organ adapt general eigen-decomposit optim weight vector extract j'h general eigenvector output neuron updat model neuron construct subtract result previous comput j-i general eigenvector desir output dj dj dj j-i vi process equival deflat desir output scatter matric sm sb obtain sm=e xx sb mmt need extract j1h loa transform wj satisfi general eigenvector equat sbwj=almwj aj j'h largest general eigenvalu constrain mse criterion network output jh vj v wtx-vjwjxr p wjsmw use obtain updat equat wj hi w j v l.. differenti respect vi equat zero obtain optimum valu ofvj mtwj substitut this vj in obtain w j w j ts wu w l.. let wk matrix whose ith column written in matrix form wk r sbwk smwku~w sbwk set element diagon matrix argument zero therebi make upper triangular anoth self-organ algorithm lda in previous analysi two-lay linear hetero-associ network observ optimum valu v=wtm jlh column wand row form wi vi respect it therefor worthwhil explor gradient descent procedur error function instead e lld mtwwtxi12 differenti this error function respect includ deflat process obtain follow updat procedur instead wk 2sbwk sm wk ut sbwk sbwkut smwk lda general eigen-decomposit sinc loa consist solv general eigenvector problem sb p=sm pa natur general algorithm obtain adapt algorithm general eigen-decomposit problem p=b pa assum symmetr posit definit here matric b instead c. chatterje v. p. roychowdhuri avail two sequenc random vector limk~oo xp limk~~ yky/ =b xk yk repres onlin observ obtain follow adapt algorithm general eigendecomposit here sequenc scalar gain whose properti describ in section sequenc instantan valu matric respect although ak bk valu obtain xk yk xp yki respect algorithm requir least one sequenc domin converg properti thus bk sequenc may obtain xp yki follow algorithm ak yk xkxk i bk bk i yk ykyk ao bo symmetr scalar gain sequenc done general obtain follow adapt algorithm general eigen-decomposit sequenc sampl wk wk bkwkut akwk akwkut bkwk although algorithm deriv network mse gradient descent approach this deriv guarante converg in order prove their converg use stochast approxim theori give converg result algorithm stochast approx convg proof alg in order prove con vergenc use stochast approxim theori due ljung in stochast approxim theori studi asymptot properti in term ordinari differenti equat ode e 2akw bkwut akw akwut continu time counterpart wk denot continu time method proof requir follow step establish set condit impos find stabl stationari point ode demonstr wk visit compact subset domain attract stabl stationari point infinit often we use theorem ljung converg proof follow general set assumpt converg proof assumpt xk yk bound probabl one limk~oo xp limk~oo ky posit definit assumpt satisfi lk=ol7k oo lk=ol7k limk~oo sup l7i assumpt largest general eigenvalu a respect unit multipl lemma let al a2 hold let a local asymptot stabl sens liapunov solut ordinari differenti equat self-organ adapt general eigen-decomposit bw u4w aw t u4w t domain attract if a compact subset wk infinit often we wk probabl one as we denot a ap as general eigenvalu a respect as general eigenvector correspond a orthonorm respect b let a=diag a denot matrix general eigenvector eigenvalu a respect b note if a general eigenvector then also a general eigenvector in next two lemma we first prove possibl equilibrium point ofth ode arbitrari permut general eigenvector a respect correspond largest general eigenvalu we next prove these equilibrium point ode unstabl equilibrium point except nl lemma ordinari differenti equat let al a3 hold then w= l dp equilibrium point d= d\iov a nxp matrix di a pxp diagon matrix diagon element id l a nxn arbitrari permut matrix lemma let al a3 hold then diag id i=i stabl equilibrium point ode in addit w= l dp i~p unstabl equilibrium point ode lemma for ordinari differenti equat let al a3 hold then point diag dp for asymptot stabl lemma let ai-a3 hold then there exist a uniform upper boundfor such wk uniform bound w.p i converg alg establish refer theorem ljung theorem let a hold assum probabl one process wk visit infinit often a compact subset domain attract one asymptot stabl point then probabl one lim wk k~ocl proof lemma asymptot stabl point ode sinc we assum wk visit a compact subset domain attract infmit often lemma then impli theorem experi al result we describ perform algorithm an exampl onlin interfer cancel in a high-dimension signal in a digit mobil communic problem problem occur desir user transmit a signal a far distanc receiv anoth user simultan transmit near base for common receiv qualiti receiv signal desir user domin by interfer from user close base due high rate larg dimens data system demand an accur detect method for a data sampl c. chatterje v. p. roychowdhuri if we use convent numer analysi method signal detect requir a signific part time slot allot a receiv accord reduc effect communic rate adapt general eigen-decomposit algorithm hand allow track slow chang direct perform signal detect the detail the data model found in zoltowski in this applic the durat for each transmit code il within we loll signal interfer we take frequenc sampl equi-spac o.4mhz use antenna the signal interfer correl matric dimens in the complex domain we use algorithm for the cancel the interfer figur show the converg the princip general eigenvector and eigenvalu the close form solut obtain collect the signal and interfer sampl in order to measur the accuraci the algorithm we comput the direct cosin the estim princip general eigenvector and the general eigenvector comput by the convent method the optimum valu one we also show the estim princip general eigenvalu in figur the result show algorithm converg the 4th bit signal algonthm algonlhm algonthm algonlhm closl d form soultlon lll i i i iii iii oj i i iii iii ii number sampl number of sampl figur direct cosin of estim first princip general eigenvector and estim first princip general eigenvalu
----------------------------------------------------------------

title: 1774-effective-learning-requires-neuronal-remodeling-of-hebbian-synapses.pdf

effect learn requir neuron remodel hebbian synaps gal chechik isaac meilijson eytan ruppin school mathemat scienc tel-aviv univers tel aviv israel ggal math.tau.ac.il isaco math.tau.ac.il ruppin math.tau.ac.il abstract this paper revisit classic neurosci paradigm hebbian learn we find necessari requir effect associ memori learn efficaci incom synaps uncorrel this requir difficult achiev robust manner hebbian synapt learn sinc depend network level inform effect learn yet obtain neuron process maintain zero sum incom synapt efficaci this normal drastic improv memori capac associ network essenti bound capac one linear scale network 's size it also enabl effect storag pattern heterogen code level singl network such neuron normal success carri activity-depend homeostasi neuron 's synapt efficaci recent observ cortic tissu thus find strong suggest effect associ learn hebbian synaps alon biolog implaus hebbian synaps must continu remodel neuronally-driven regulatori process brain introduct synapse-specif chang synapt efficaci carri long-term potenti ltp depress ltd thought underli cortic self-organ learn brain accord hebbian paradigm ltp ltd modifi synapt efficaci function fire pre post synapt neuron this paper revisit hebbian paradigm show synapt learn alon provid effect associ learn biolog plausibl manner must complement neuronally-driven synapt remodel import neuron driven normal process alreadi demonstr context self-organ cortic map continu unsupervis learn in principal-component-analysi network in scenario normal necessari prevent the excess growth synap
----------------------------------------------------------------

title: 1014-associative-decorrelation-dynamics-a-theory-of-self-organization-and-optimization-in-feedback-networks.pdf

associ decorrel dynam theori self-organ optim feedback network dawei w. dong lawrenc berkeley laboratori univers california berkeley ca abstract paper outlin dynam theori develop adapt neural network feedback connect given input ensembl connect chang strength accord associ learn rule approach stabl state neuron output decorrel appli theori primari visual cortex examin implic dynam decorrel activ orient select cell intracort connect theori give unifi quantit explan psychophys experi orient contrast orient adapt use one paramet achiev good agreement theoret predict experiment data introduct mammalian visual system effect detect orient line neuron primari visual cortex select respond orient line form orient column visual system organ present address rockefel univers york avenu ny ny dawei dong believ visual system self-organ long term develop short term adapt ensur optim inform process linsker appli hebbian learn model develop orient select later propos principl maximum inform preserv earli visual pathway focus work feedforward connect model feedback connect isotrop unchang develop orient column actual circuitri visual cortex involv extens columnar specifi feedback connect exist even function column appear cat striat cortex earlier research emphas import role feedback connect develop columnar structur visual cortex develop theoret framework help understand dynam hebbian learn feedback network show columnar structur origin symmetri break develop feedback connect intracort later connect within visual cortex figur illustr theoret predict intracort connect break symmetri develop strip-lik pattern characterist wave length compar develop intracort inhibitori rang lgn-cortex affer rang left feedforward lgn-cortex connect develop influenc symmetri break develop intracort connect develop feedforward connect cell form recept field orient select nearbi cell similar orient prefer right orient chang period strip-lik pattern intracort connect figur result develop visual cortex feedback connect simul cortex consist neuron connect cortic neuron left receiv input lgn neuron right figur white inclic posit connect black inclic negat connect one see chang recept field 's orient right high correl strip-lik pattern intracort connect left mani aspect theoret predict agre qualit neurobiolog observ primari visual cortex anoth way test idea optim associ correl dynam inform process self-organ theori quantit psychophys studi idea look chang percept follow chang input environ psychophys experi orient illus offer opportun test theori orient select orient illus effect perceiv orient line affect neighbor time space orient stimuli observ mani psychophys experi attribut inhibitori interact channel tune differ orient unifi quantit explan neurophysiolog evid support earlier comput model intracort inhibit play role gain-control orient select but order gain-control mechan effect signal differ statist system develop adapt differ environ paper we examin implic hypothesi intracort connect dynam decorrel activ orient select cell intracort connect activ adapt visual environ output activ orient select cell decorrel dynam ensur decorrel associ learn outlin next section theoret framework develop adapt intracort connect we emphas feedback connect follow section assum feedforward connect develop orient select base earlier work quantit comparison theori experi present section associ decorrel dynam two differ kind variabl neural network one class variabl repres activ nerv cell neuron class variabl describ synaps connect nerv cell complet model adapt neural system requir two set dynam equat one class variabl specifi evolut behavior neural system set equat describ chang state activ neuron dvi adt i vii i time constant tij strength synapt connect neuron neuron ii addit feedforward input neuron besid describ feedback connect matrix nj second set equat describ way synaps chang time due neuron activ learn rule propos dnj dt time constant follow vi i i feedback learn signal describ feedback learn signal vi generat hopfield type associ memori network vi lj t/j vi t/j strength associ connect dawei dong neuron neuron recent correl neuron activ vi vj determin hebbian learn decay term dtfj dt iij vivj time constant vi t j involv learn direct affect network output straight forward show time constant dynam reduc dt dt vvt vit bold-fac quantiti matric vector denot ensembl averag difficult show equat lyapunov energi function vv vvt lower bound satisfi dl dt dl dt dtij dt i'lor thus dynam stabl when stabl output activ decorrel vvt equat show dynam alway lead stabl state neuron activ decorrel their correl matrix orthonorm yet connect chang associ fashion equat almost hebbian whi we call it associ decorrel dynam inform process point view network self-organ satisfi equat optim gaussian input ensembl white output nois linear first order analysi appli our theori associ decorrel dynam visual cortex compar psychophys experi orient illus linear first-ord approxim use va 6t ex i it va i 6v ti it assum input correl small it interest notic linear first-ord approxim lead anti-hebbian feedback connect iij ex guarantte stabl around quantit predict orient illus basic phenomena orient illus demonstr figur left top effect orient contrast also call tilt illus within two surround circl tilt line orient a center rectangl associ correl dynam appear rotat opposit side surround tilt two rectangl one without surround left-cent this figur fact exact on bottom effect orient adapt also call tilt aftereffect one fixat small circl in one two big circl tilt line second look rectangl without surround orient line rectangl appear tilt opposit side these two effect orient illus both in direct repuls appar orient a line chang increas differ induc line care experiment measur also reveal angl induc line maximum orient adapt effect but orient contrast stimulus orient degre figur effect orient contrast upper-left orient adapt lowerleft attribut feedback connect cell tune differ orient upper-right network lower-right tune curv orient illus attribut feedback connect orient select cell this illustr in figur right on the top the network orient select cell feedback connect four cell shown the left receiv orient select feedforward input optim respect the dot line repres the feedback connect onli the connect from the second cell drawn on the bottom the orient tune curv the feedforward input the second cell optim tune stimulus vertic assum gaussian width becaus the feedback connect the output the second cell differ tune curv from feedforward input depend on the activ cell primari visual cortex we suppos that there orient select neuron tune orient it conveni use the continu variabl instead the index repres neuron optim tune to the orient angl the neuron activ repres the feedforward input to neuron repres the feedforward input orient dawei w. dong select given a visual stimulus orient eo the input this kind the orient tune measur experi for
----------------------------------------------------------------

title: 161-neural-approach-for-tv-image-compression-using-a-hopfield-type-network.pdf

neural approach tv imag compress use hopfield type network martin naillon jean-bernard theeten laboratoir d'electroniqu de physiqu applique avenu descart bp limeil brevann cedex franc abstract self-organ hopfield network develop context vector ouantiza-t aim compress televis imag metast state spin glass-lik network use extra storag resourc use minim overlap learn rule krauth mezard optim organ attractor sel f-organi zi ng scheme devis result generat adapt codebook qiven tv imag i ntrodocti abil hopfield network hopfield amit personnaz hertz behav associ memori usua asslj11 pri ori knowl edg pattern store mani applic unknown aim work develop network capabl learn select attractor tv imag compress use vector quantize key issu hotv transmiss typic case sinc non neural algorithm generat list code codebookl suboptim altern prani si ng neural canpressi techni que jackel kohonen grossberg cottrel idea use metast spin glass-lik net addit storag resourc cl usteri nq a1gori thm deriv cl assi cal sel f-organi zi ng sheme generatf ng adapt codebook present illustr case 2d-vector lep member philip research organ neural approach tv imag compress non neural approach imag divid block name vector pixel typic pixel given codebook vector code associ nearest element list nearest neighbour classifi fi ure emcad input yetta cop1par index ftecdnindex codebook struct vector code book figur basic scheme vector quantize design optim codebook cluster algorithm app1 ie train set vector figur criterium optim distors measur train set codebook algorithm actua subopt ima1 especi non connex train set base iter comput center grav ty whi ch tend overcod dens region poi nts wherea 1ight one undercod figur pixel figur train set two pixel vector associ codebook canput non neural c1 uster algorithm overcod dens region pixel subcod light one naillon theeten neural approach hopfield neural network code vector attractor net neural dynam resolut phase substitut nearest neighbourg classif en pattern refer prototyp name explicit memori prescrib spin glass-lik net attractor refer tastabl state induc net sherrington kirkpatrick toulous hopfield mezard consid induc attractor addit memori name impl icit memori whi ch use network code previous mention light region point provid higher flexibl net self-organ process choos larg basi explicit implicit attractor one optim code task neural notat vector pixel bit per pel vector dimens eucl idean space dimens correspond grey level preserv euclidean di stanc use well-known themometri notati neuron level per dimen number neuron set one th reg ul ar orderi ng iv ng pixel lumin vector dimens neuron use induct process induc impl icit memori depend prescript rule we compar project rule personnaz minim overlap rule krauth mezard metast state detect relax point train set figur correspond prescrib induc attractor mark figur small diamond two rule induct process rather detenni ni stic generati ng orthogon mesh two prototyp prescrib metast state induc cross-point name figur neural approach tv imag compress pdib pdcei figur comparaison induct process prescript rule prescrib state full squar induc state open diamond what differ two rul es number induc attractor for prototyp train set 2d-vector project rule induc metast state ratio wherea min over induc ratio due differ stabil iti prescrib induc state case min over naillon theeten publish general attractor attractor induc imag space figur neuron space configur compar imag configurati on we extend imag space defi n1 ng genera 1i ze attractor class pattern number neuron set one for pixel whatev thei orderi ng such notati correspond random thermometri neural representati simul ati shown general attractor correspond accept state figur locat place one would like obtain normal attractor nsiilon theeten generauz witi-i generauzatjon wrthovt cii jemijzm aj'taact'or fl i j.j i pixel i't hjlt pixel figur induc bassin attract repres arrow left plot some train vector no attractor imag space after general randon thermometr notat right ot show correspond attractor adapt neural codebook learn iter sel organi zi ng process develop optimi ze codebook for given tv imag codebook defin step process set prescrib induc attractor select train set vector self-organ scheme control cost function distors measur train set codebook have target code vector we prescri step discuss typic prototyp seen figur sa we choos initi prototyp uniform distribut along bisect line use train set vector figur induc metast state detect correspond bassin attract frequent prescrib induc attractor select center gravi ty thei bassi ns attracti taken new prototyp figur 5b after iter distors measur stabil tabl neural approach for tv imag compress inmal plxb.1 pixel initi self-organ scheme fi gure 5a iter fast organ prototyp i figur 5b scheme first iter self-organizinq iobal codebook dislofs size itrrlliom ener auraclor i tabl evolut distors measur versus iter self-organ scheme it stabil in iter noollon theeten fourti 1i nes tv imag the port ba 1timor bit per pel code adapt neural codebook 20-vector the coher the code visibl the appar continu the imag figur the code imag bit per pel i figur neural code imag bit per pel conclus use a classic clusterinq algorithm a self-organ scheme develop in a hopfield network f.or the adapt design a codebook small imensi vector ina vector quanti zati techni que it shown use the minim overlap prescript rule the metast state induc in a spin gl ass-lik network use extra-cod the optim organ the prescrib induc attractor defin as the limit organ obtain the iter learn process it an exampl learn select as alreadi propos physicist biologist toulous ale hard~r impl ement on the neural vlsi ci rcuit curren~i design at lep allow for on-lin codebook comput we woul like thank j.j. hopfield inspir this studi as well h. bosma w. kreuwel phil ip research laboratori eindhoven allow to initi this research neural approach for tv imag compress
----------------------------------------------------------------

title: 1554-neuronal-regulation-implements-efficient-synaptic-pruning.pdf

neuron regul implement effici synapt prune gal chechik isaac meilijson school mathemat scienc tel aviv univers tel aviv israel ggal math.tau.ac.il isaco math.tau.ac.il eytan ruppin school medicin mathemat scienc tel aviv univers tel aviv israel ruppin math.tau.ac.il abstract human anim studi show mammalian brain undergo massiv synapt prune childhood remov half synaps puberti previous shown maintain network memori perform synaps delet requir synaps proper modifi prune remov weaker synaps show neuron regul mechan recent observ maintain averag neuron input field result weight-depend synapt modif correct rang degrad dimens synapt upper bound neuron regul remov weaker synaps judici modifi remain synaps implement near optim synapt modif maintain memori perform network undergo massiv synapt prune thus paper show addit known effect hebbian chang neuron regul may play import role self-organ brain network develop introduct paper studi one fundament puzzl brain develop massiv synapt prune observ mammal childhood remov half synaps puberti review phenomenon observ various area brain anim studi human studi how brain function massiv synapt elimin could comput advantag seem wast development strategi g. chechik i. meilijson e. ruppin previous work shown synapt overgrowth follow judici prune along develop improv perform associ memori network limit synapt resourc thus suggest new comput explan synapt prune childhood optim prune strategi found requir synaps delet accord efficaci remov weaker synaps first mechan implement theoretically-deriv synapt prune strategi biolog plausibl manner answer question focus studi role neuron regul mechan oper maintain homeostasi neuron membran potenti nr recent identifi experiment show neuron up-regul down-regul efficaci incom excitatori synaps multipl manner maintain membran potenti around baselin level independ studi nr theoret show effici maintain memori perform network undergo synapt degrad hypothes nr may lead synapt prune develop paper show hypothesi comput feasibl biolog plausibl studi modif synapt valu result oper nr work thus give possibl account way brain network maintain perform undergo massiv synapt prune model nr-driven synapt modif nrsm result two concomit process synapt degrad inevit consequ synapt turnov neuron regul oper compens degrad therefor model nrsm sequenc degradation-strengthen step time step synapt degrad stochast reduc synapt strength w't+l w't+l nois term posit mean power defin degrad dimens paramet chosen rang neuron regul model let post-synapt neuron multipl strengthen synaps common factor restor origin input field w'th li ii input field neuron time excitatori synapt efficaci assum viabil lower bound synaps degener vanish soft upper bound beyond synaps strong degrad reflect maxim efficaci studi process network model incorpor segreg inhibitori excitatori neuron obey dale 's law requir generat essenti segreg modifi standard low-act associ memori model propos ad small posit term synapt learn rule model memori store excitatori neuron network form attractor network dynam synapt efficaci wij jth pre-synapt neuron ith post-synapt neuron wij i p ej neuron regul implement effici synapt prnning i memori pattern code level fraction fire neuron posit constant updat rule state xf ith neuron time if l9 wij xj j=l sign j j=l neuron threshold i inhibit strength general modif function excitatori synaps either deriv explicit see section determin implicit oper nrsm if linear i math model reduc origin model describ overlap mil similar network activ pattern memori serv measur memori perform retriev acuiti defin mil ef=l p xj euron regul synapt modif nrsm studi simul degradation-strengthen sequenc network memori pattern store accord figur la plot typic distribut synapt valu trace along sequenc degradationstrengthen step evid synapt valu diverg weight strengthen lie close upper synapt bound synaps degener vanish use probabilist consider shown synapt distribut converg meta-st state it remain long wait time figur ib describ metast synapt distribut calcul differ valu evolv distribut synapt efficaci simul result numer result cj cj i i i i ctl i alpha=o.o alpha=o.5 alpha=o.9 i figur distribut synapt strength follow degradation-strengthen process synapt distribut degradationstrengthen step neuron network store memori pattern qualit similar result obtain wide rang simul paramet synapt distribut remain synaps meta-st state calcul main eigen vector transit probabl matrix weight normal distribut expect standard deviat o vm probabl negat synaps vanish goe infin neglig alreadi sever dozen memori paramet rang use g. chechik i meilijson e. ruppin nrsm function metast state nrsm random delet nr modif random delet origin synapt strength network 's connect figur nrsm function metast state differ valu result obtain 400-neuron network perform degradationstrengthen step paramet valu figur except perform nr modif random delet retriev acuiti memori store network neuron portray function network connect network undergo continu prune nr reach metast state rna n o.oi investig synaps strengthen prune studi result synapt modif function figur 2a plot valu synapt efficaci metast state function initi synapt efficaci differ valu degrad dimens observ sigmoid depend obtain slope sigmoid s.trong depend degradatiori dimens two limit case addit degrad result step function metast state multipl degrad result random diffus synapt weight toward memori less mean valu differ valu result differ level synapt prune when synapt upper bound high surviv synaps assum high valu lead massiv prune maintain neuron input field turn reduc network perform low valu lead high connect limit synaps small set possibl valu reduc memori perform simul show optim memori retriev obtain valu lead delet level nr inde maintain network perform figur 2b trace averag retriev acuiti network throughout oper nr versus network subject random delet prune level retriev random prune network collaps alreadi low delet level network undergo nr perform well even high delet level optim modif excitatory-inhibitori network obtain compar yardstick evalu effici nr select prune mechan deriv optim modif function maxim memori perform excitatory-inhibitori model compar nrsm function neuron regul implement effici synapt prune we studi general synapt modif function prune synaps possibl modifi rest satisfi global constraint synaps number total strength synaps constraint reflect observ synapt activ strong correl energi consumpt brain synapt resourc may henc inher limit adult brain we evalu impact function network 's retriev perform deriv effect signal nois ratio sin neuron 's input field eq known primari determin retriev capac analysi conduct similar manner yield modif function but explicit appli synaps deriv optim synapt modif function limit synapt resourc we consid function zero synaps except set keep integr ovz limit we maxim sin constraint use lagrang method result show without synapt constraint optim function ident function origin hebbian rule optim when number synaps restrict optim modif function linear function remain synaps aw j.ta+b ta dz delet set find synaps delet we numer search delet set maxim sin limit posit valu requir segreg excitatori inhibitori neuron result show weak synaps prune modif strategi remov weakest synaps modifi rest accord optim delet level lower delet level function fail satisfi posit constraint set when posit constraint ignor sin maxim if weight closest mean delet remain synaps modifi accord to eq we name strategi mean synaps prune figur plot memori capac weak-synaps prune compar random delet mean-synapt prune show prune weak synaps perform least near optim lower delet level well even interest under correct paramet valu weak-synaps prune result modif function similar form to nr-driven modif function studi previous section both strategi remov weakest synaps linear modifi remain synaps similar manner case limit overal synapt strength optim satisfi thus optim modif function linear sublinear modif function optim function g. chechik i. meilijson e. ruppin capac differ synapt modif function analysi result simul result i i i figur comparison perform differ modif strategi as function delet level percentag synaps prune capac measur as number pattern store network recal almost correct rn degrad pattern rna thus unbound for therefor our model bound synapt efficaci dictat optim process comput advantag aris effect preserv memori capac face ongo synapt prune discuss by studi nr-driven synapt modif framework associ memori network we show nr prune weaker synaps modifi remain synaps sigmoid manner critic variabl govern prune process degrad dimens upper synapt bound our result show correct rang these paramet nr implement near optim strategi maxim memori capac spars connect level observ brain a fundament requir central nervous system develop system continu function undergo major structur function development chang it propos a major function role neuron down-regul earli infanc to maintain neuron activ at baselin level while face continu increas number efficaci synaps focus up-regul our work show nr anoth import interest effect modifi prune synaps a continu optim manner neuron regul synapt modif may play role also peripher nervous system it recent shown neuro-muscular junction muscl regul incom synaps a way similar to nr our analysi suggest this process may the under caus for the find synaps in the neuro-muscular junction either strengthen prune accord to their initi efficaci the signific our work goe beyond understand synapt organ remodel in the associ memori model studi in this paper our analysi bear relev to two fundament paradigm hetero associ memori self organ map share the basic synapt structur store as neuron regul implement effici synapt prune sociat set pattern via a hebbian learn rule combin the investig a biolog identifi mechan the analyt studi perform optim in neural network model this paper show the biolog plausibl benefici role weight depend synapt prune thus in addit to the known effect hebbian learn neuron regul may play import role in the self-organ brain network develop
----------------------------------------------------------------

title: 353-self-organization-of-hebbian-synapses-in-hippocampal-neurons.pdf

self-organ hebbian synaps hippocamp neuron thoma h. brown zachari f. mainen anthoni m. zador brenda j. claiborn depart psycholog divis life scienc yale univers univers texa new haven cr san antonio tx abstract explor signific biolog complex neuron comput we demonstr hebbian synaps realistically-model hippocamp pyramid cell may give rise two novel form self-organ respons structur synapt input first basi electroton relationship synapt contact cell may becom tune small subset input space second mechan may produc cluster potenti synaps across space dendrit latter type self-organ may function signific presenc nonlinear dendrit conduct introduct long-term potenti ltp experiment observ form synapt plastic interpret instanc hebbian modif kelso al brown al induct ofltp requir synchron presynapt activ postsynapt depolar kelso al we previous develop detail biophys model ltp observ synaps onto hippocamp region cal pyrami brown mainen zador claiborn figur two-dimension project reconstruct hippocamp cal pyramid cell dal neuron zador al synaps form ltp occur distribut across extens dendrit arbor dure synapt stimul membran voltag synaps differ way biolog neuron differ process element typic use neural network model postsynapt activ repres singl state variabl we develop electroton model base anatom reconstruct neuron we use model explor spatial distribut input tempor relationship activ affect synapt potenti neuron model standard compartment model techniqu use repres electr structur hippocamp cal pyramid cell morpholog electr paramet morphometr data obtain three-dimension reconstruct brown hippocamp neuron correct factor appli membran area base estim spine densiti origin measur divid singl neuron cylind averag length simul purpos structur collaps compart preserv connect pattern chang process diamet electr constant rm id-cm em jlf'lcrrll ri n-cm spruston johnston membran electr passiv synapt current model sum fast ampa slow nmda conduct head two-compart spine zador ampa conduct repres alpha function jack time constant msec brown johnston nmda conduct repres complic function two time constant voltag depend due voltage-sensit channel block ion zador brown initi peak conduct gampa gnmda set ns respect self-organ hebbian synaps hippocamp neuron simul synapt modif simul run sun workstat use custom version neuron simul develop michael hine hine prior simul pattern synaps select random pool synaps distribut unifonn apic basal dendrit simul divid trial msec begin trial particular pattern synaps activ synchron stimuli interv msec sequenti present select pattern constitut epoch entir simul consist present epoch cours trial membran potenti comput locat dendrit tree voltag use comput weight chang accord hebbian algorithm describ after trial actual peak ampa conduct gampa hereaft denot scale sigmoid function gmax detennin steep sigmoid gfm set ns rule synapt modif base biophys interpret kairiss ai brown ai general bilinear fonn hebbian algorithm brown functionals.l constant repres postsynapt activ repres presynapt activ equat specifi interact fonn synapt ehhanc combin three noninteract form synapt depress possibl neurobiolog analog brown ai interact tenn deriv biophys model ltp induct spine zador simplifi version model use comput concentr ca bound calmodulin suggest cam-c84 may trigger protein kinas respons ltp induct general nonlinear function subsynapt voltag zador al biophys mechan under synapt depress less well understood constant repres passiv decay process general set zero function repres heterosynapt depress base postsynapt activ simul proport amount depolar subsynapt membran rest potenti function repres homosynapt depress base presynapt activ proport ampa conduct consid measur exclus presynapt activ insensit postsynapt voltag three activity-depend tenn integr over period trial order obtain measur weight chang reinterpret yas constant equat thus ial camca v.ryii ygampa dt brown mainen zador claiborn too m.sec too m.sec epoch figur interact among hebbian synaps produc differ global effect win lose pattern basi spatial distribut synaps psp alway measur soma due two differ pattern synaps plot function present epoch initi pattern solid line evok slight greater psp pattern dot line inset top right mter epoch respons revers thepsp due pattern depress psp due pattern potenti inset top left result analysi simul reveal self-organ form differenti modif synapt strength mainen two aspect self-organ phenomena distinguish simul form pattern select observ clear winner loser emerg simul averag synapt efficaci remain spatial heterogeneities~lustering~f synapt strength develop differ measur use assess phenomena patternselect chang peak postsynapt potenti record soma sp provid one use measur pattern select mani simul pattern select result mark potenti psp due pattern depress psp due other psp regard indirect measur function consequ self-organ simul illustr pattern synaps produc averag psp mv learn after learn respons rang amount underlying.pattern select ch8 ge averag peak synapt conduct patterng8yiio initi valu g8yii pattern final valu bound eq mani simul g8yii approach upper bound pattern lower bound pattern way neuron becam select tune subset origin set input specif self-organ hebbian synaps hippocamp neuron epoch figur mean synapt conduct gsi two pattern plot function present epoch pattern began iaenuc total synapt strength synaps gs r synapt conduct constrain rang ns mter twenti epoch gsi pattern solid line approach minimum ofo.on gsi pattern dot line approach maximum ns tune depend paramet valu neuron model learn rule stimulus set cluster formanon heterogen spatial distribut strengthen weaken synaps often observ after learn spatial cluster synaps similar conduct form spatial heterogen illustr sever way one conveni method brown synaps repres color point superimpos rendit neuron morpholog illustr color-cod gsyn synaps pattern correl synapt strength across dendrit space immedi appar second method better suit monochrom graphic avail present text evolut varianc gsyn plot function time simul illustr here increas varianc due format singl relat larg cluster strengthen synaps within paramet regim multipl cluster smaller size form discuss import differ synapt modif in biophysically-model neuron in simpl process element aris voltag gradient present in realist model brown kairiss in standard process element although sj somat psp were general correl relationship two linear often evid in simul compar initi trial in fig brown mainen zador claiborn til epoch figur synapt heterogen indic increas in varianc set synapt conduct for pattern varianc peak synapt conduct pattern plot aji lction epoch varianc pattern approach theoret maximum in paramet regim the varianc due the potenti singl larg cluster synap combin the depress synaps singl state variabl repres postsynapt activ in contrast the critic subsynapt voltag repres postsynapt activ in the neuron correl strict equal the structur electr properti the cell interact synapt input detennin the precis spatiotempor pattern membran voltag thus the voltag synaps depend strong electroton relationship activ synaps the way in this local depolar affect the natur self-organ depend the specif mechan the synapt modif rule we model pair oppos voltage-depend mechan an interact potenti mechan the function ex promot cooper spatial proxim synaps tempor correl activ heterosynapt depress mechan the function independ presynapt activ promot competit among spatial proxim synaps through mechan the specif electroton structur neuron predetennin complex set interact given spatial distribut synapt input we shown higher-ord interact give rise self-organ at least two interest effect spars represent the phenomenon pattern select demonstr hebbian self-organ may natur tune neuron respond subset input space this tune mechan might allow larg field neuron develop spars code the activ in set input fiber sinc neuron would respond a particular small portion the input space spars code may advantag associ learn type neural comput kanerva self-organ hebbian synaps in hippocamp neuron cluster nonlinear comput the fonnat cluster strengthen synaps illustr a properti hebbian selforgan whose function signific might appreci in the presenc nonlinear voltage-depend dendrit conduct we examin the self-organ process in an electr passiv neuron under these condit the presenc cluster within pattern littl effect the observ output in fact it known hippocamp cell the type model possess a varieti spatial heterogen nonlinear dendrit conduct jone the comput role nonlinear begin explor it possibl interact synapt cluster and nonlinear membran patch may signific affect both the perfonn dendrit comput and the process self-organ acknowledg this research support by grant the offic naval research the defens advanc research project agenc and the air forc offic scientif research
----------------------------------------------------------------

