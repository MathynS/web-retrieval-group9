query sentence: anomaly detection
---------------------------------------------------------------------
title: 6456-multi-view-anomaly-detection-via-robust-probabilistic-latent-variable-models.pdf

Multi-view Anomaly Detection via Robust
Probabilistic Latent Variable Models
Tomoharu Iwata
NTT Communication Science Laboratories
iwata.tomoharu@lab.ntt.co.jp

Makoto Yamada
Kyoto University
makoto.m.yamada@ieee.org

Abstract
We propose probabilistic latent variable models for multi-view anomaly detection, which is the task of finding instances that have inconsistent views given
multi-view data. With the proposed model, all views of a non-anomalous instance
are assumed to be generated from a single latent vector. On the other hand, an
anomalous instance is assumed to have multiple latent vectors, and its different
views are generated from different latent vectors. By inferring the number of latent vectors used for each instance with Dirichlet process priors, we obtain multiview anomaly scores. The proposed model can be seen as a robust extension of
probabilistic canonical correlation analysis for noisy multi-view data. We present
Bayesian inference procedures for the proposed model based on a stochastic EM
algorithm. The effectiveness of the proposed model is demonstrated in terms of
performance when detecting multi-view anomalies.

1 Introduction
There has been great interest in multi-view learning, in which data are obtained from various information sources. In a wide variety of applications, data are naturally comprised of multiple views.
For example, an image can be represented by color, texture and shape information; a web page can
be represented by words, images and URLs occurring on in the page; and a video can be represented
by audio and visual features. In this paper, we consider the task of finding anomalies in multi-view
data. The task is called horizontal anomaly detection [13], or multi-view anomaly detection [16].
Anomalies in multi-view data are instances that have inconsistent features across multiple views.
Multi-view anomaly detection can be used for many applications, such as information disparity management [9], purchase behavior analysis [13], malicious insider detection [16], and user aggregation
from multiple databases. In information disparity management, multiple views can be obtained from
documents written in different languages such as Wikipedia. Multi-view anomaly detection tries to
find documents that contain different information across different languages, which would be helpful for editors to select documents to be updated, or beneficial for cultural anthropologists to analyze
social difference across different languages. In purchase behavior analysis, multiple views for each
item can be defined as its genre and its purchase history, i.e. a set of users who purchased the item.
Multi-view anomaly detection can find movies inconsistently purchased by users based on the movie
genre, which would assist creating marketing strategies.
Multi-view anomaly detection is different from standard (single-view) anomaly detection. Singleview anomaly detection finds instances that do not conform to expected behavior [6]. Figure 1 (a)
shows the difference between a multi-view anomaly and a single-view anomaly in a two-view data
set. ?M? is a multi-view anomaly since ?M? belongs to different clusters in different views (?A?D?
cluster in View 1 and ?E?J? cluster in View 2) and views of ?M? are not consistent. ?S? is a singleview anomaly since ?S? is located far from other instances in each view. However, both views of
?S? have the same relationship with the others (they are far from the other instances), and then ?S?
30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.

Latent space
BA
MC
D

F GI M
J
HE
S

W1
BD
MC
A

?

? W2

a
b

?

w

S

F GI
J
H E

?
M

S

Observed view 1

I EH
J G
F

?

s

x

D

z

?N

r

AD
C
B

Observed view 2
(a)

(b)

Figure 1: (a) A multi-view anomaly ?M? and a single-view anomaly ?S? in a two-view data set. Each
letter represents an instance, and the same letter indicates the same instance. Wd is a projection
matrix for view d. (b) Graphical model representation of the proposed model.
is not a multi-view anomaly. Single-view anomaly detection methods, such as one-class support
vector machines [18] or tensor-based anomaly detection [11], consider that ?S? is anomalous. On
the other hand, we would like to develop a multi-view anomaly detection method that detects ?M? as
anomaly, but not ?S?. Note that although single-view anomalies are uncommon instances, multi-view
anomalies can be majority if they are inconsistent across multiple views.
We propose a probabilistic latent variable model for multi-view anomaly detection. With the proposed model, there is a latent space that is shared across all views. We assume that all views of a
non-anomalous (normal) instance are generated using a single latent vector. On the other hand, an
anomalous instance is assumed to have multiple latent vectors, and its different views are generated
using different latent vectors, which indicates inconsistency across different views of the instance.
Figure 1 (a) shows an example of a latent space shared by the two-view data. Two views of every
non multi-view anomaly can be generated from a latent vector using view-dependent projection matrices. On the other hand, since two views of multi-view anomaly ?M? are not consistent, two latent
vectors are required to generate the two views using the projection matrices.
Since the number of latent vectors for each instance is unknown, we automatically infer it from the
given data by using Dirichlet process priors. The inference of the proposed model is based on a
stochastic EM algorithm. In the E-step, a latent vector is assigned for each view of each instance
using collapsed Gibbs sampling while analytically integrating out latent vectors. In the M-step,
projection matrices for mapping latent vectors into observations are estimated by maximizing the
joint likelihood. By alternately iterating E- and M-steps, we infer the number of latent vectors used
in each instance and calculate its anomaly score from the probability of using more than one latent
vector.

2 Proposed Model
D
Suppose that we are given N instances with D views X = {Xn }N
n=1 , where Xn = {xnd }d=1
Md
is a set of multi-view observation vectors for the nth instance, and xnd ? R
is the observation
vector of the dth view. The task is to find anomalous instances that have inconsistent observation
features across multiple views. We propose a probabilistic latent variable model for this task. The
proposed model assumes that each instance has potentially a countably infinite number of latent
K
vectors Zn = {znj }?
j=1 , where znj ? R . Each view of an instance xnd is generated depending
on a view-specific projection matrix Wd ? RMd ?K and a latent vector znsnd that is selected from
a set of latent vectors Zn . Here, snd ? {1, ? ? ? , ?} is the latent vector assignment of xnd . When
the instance is non-anomalous and all its views are consistent, all of the views are generated from
a single latent vector. In other words, the latent vector assignments for all views are the same,
sn1 = sn2 = ? ? ? = snD . When it is an anomaly and some views are inconsistent, different views

2

are generated from different latent vectors, and some latent vector assignments are different, i.e.
snd 6= snd? for some d 6= d? .
Specifically, the proposed model is an infinite mixture model, where the probability for the dth view
of the nth instance is given by
p(xnd |Zn , Wd , ?n , ?) =

?
X
j=1

?nj N (xnd |Wd znj , ??1 I),

(1)

where ?n = {?nj }?
j=1 are the mixture weights, ?nj represents the probability of choosing the jth
latent vector, ? is a precision parameter, N (?, ?) denotes the Gaussian distribution with mean ?
and covariance matrix ?, and I is the identity matrix. Information of non-anomalous instances that
cannot be handled by a single latent vector is modeled in Gaussian noise which is controlled by ?.
Since we assume the same observation noise ? across different views, the observations need to be
normalized. We use a Dirichlet process for the prior of mixture weight ?n . Its use enables us to
automatically infer the number of latent vectors for each instance from the given data.
The complete generative process of the proposed model for multi-view instances X is as follows,
1. Draw a precision parameter ? ? Gamma(a, b)
2. For each instance: n = 1, . . . , N

(a) Draw mixture weights ?n ? Stick(?)
(b) For each latent vector: j = 1, . . . , ?
i. Draw a latent vector znj ? N (0, (?r)?1 I)
(c) For each view: d = 1, . . . , D
i. Draw a latent vector assignment snd ? Discrete(?n )
ii. Draw an observation vector xnd ? N (Wd znsnd , ??1 I)
Here, Stick(?) is the stick-breaking process [19] that generates mixture weights for a Dirichlet
process with concentration parameter ?, and r is the relative precision for latent vectors. ? is shared
for observation and latent vector precision because it makes it possible to analytically integrate out ?
as shown in (4). Figure 1 (b) shows a graphical model representation of the proposed model, where
the shaded and unshaded nodes indicate observed and latent variables, respectively.
N
The joint probability of the data X and the latent vector assignments S = {{snd }D
d=1 }n=1 is given
by

p(X, S|W , a, b, r, ?) = p(S|?)p(X|S, W , a, b, r),

(2)

where W = {Wd }D
d=1 . Because we use conjugate priors, we can analytically integrate out mixture
weights ? = {?n }N
n=1 , latent vectors Z, and precision parameter ?. Here, we use a Dirichlet
process prior for multinomial parameter ?n , and a Gaussian-Gamma prior for latent vector znj . By
integrating out mixture weights ?, the first factor is calculated by
Q n
N
Y
? Jn Jj=1
(Nnj ? 1)!
p(S|?) =
,
(3)
?(? + 1) ? ? ? (? + D ? 1)
n=1
where Nnj represents the number of views assigned to the jth latent vector in the nth instance, and
Jn is the number of latent vectors of the nth instance for which Nnj > 0. By integrating out latent
vectors Z and precision parameter ?, the second factor of (2) is calculated by
p(X|S, W , a, b, r) = (2?)?

N

P
d Md
2

r

K

P

n Jn
2

N Jn
1
ba ?(a? ) Y Y
|Cnj | 2 ,
?
?a
b ?(a) n=1 j=1

(4)

where
?

a =a+

N

PD

d=1

2

Md

,

b? = b +

N D
N Jn
1 XX ?
1 XX
?? C ?1 ?nj ,
xnd xnd ?
2 n=1
2 n=1 j=1 nj nj
d=1

3

(5)

?nj = Cnj

X

?1
Cnj
=

Wd? xnd ,

d:snd =j

X

Wd? Wd + rI.

(6)

d:snd =j

The posterior for the precision parameter ? and that for the latent vector znj are given by
p(?|X, S, W , a, b) = Gamma(a? , b? ),

p(znj |X, S, W , r) = N (?nj , ??1 Cnj ),

(7)

respectively.

3 Inference
We describe inference procedures for the proposed model based on a stochastic EM algorithm, in
which collapsed Gibbs sampling of latent vector assignments S and the maximum joint likelihood
estimation of projection matrices W are alternately iterated while analytically integrating out the
latent vectors Z, mixture weights ? and precision parameter ?. By integrating out latent vectors,
we do not need to explicitly infer the latent vectors, leading to a robust and fast-mixing inference.
Let ? = (n, d) be the index of the dth view of the nth instance for notational convenience. In the
E-step, given the current state of all but one latent assignment s? , a new value for s? is sampled from
{1, ? ? ? , Jn\? + 1} according to the following probability,
p(s? = j|X, S\? , W , a, b, r, ?) ?

p(s? = j, S\? |?) p(X|s? = j, S\? , W , a, b, r)
?
,
p(S\? |?)
p(X\? |S\? , W , a, b, r)

(8)

where \? represents a value or set excluding the dth view of the nth instance. The first factor is given
by
(
Nnj\?
p(s? = j, S\? |?)
if j ? Jn\?
D?1+?
=
(9)
?
if j = Jn\? + 1,
p(S\? |?)
D?1+?
using (3), where j ? Jn\? is for existing latent vectors, and j = Jn\? + 1 is for a new latent vector.
By using (4), the second factor is given by
?a?

b\?\? ?(a?s? =j ) |Cj,s? =j | 21
Md
p(X|s? = j, S\? , W , a, b, r)
K
= (2?)? 2 rI(j=Jn\? +1) 2 ?a?
,
s? =j
p(X\? |S\? , W , a, b, r)
?(a?\? ) |Cj\? | 12
bs? =j

(10)

where I(?) represents the indicator function, i.e. I(A) = 1 if A is true and 0 otherwise, and subscript
s? = j indicates the value when x? is assigned to the jth latent vector as follows,
1
1
1
b?s? =j = b?\? + x?
x? + ??
C ?1 ?nj\? ? ??
C ?1
?nj,s? =j ,
2 ?
2 nj\? nj\?
2 nj,s? =j nj,s? =j
a?s? =j = a? ,

(11)

?1
?nj,s? =j = Cnj,s? =j (Wd? x? + Cnj\?
?nj\? ),

(12)

?1
?1
Cnj,s
= Wd? Wd + Cnj\?
.
? =j

(13)

Intuitively, if the current view cannot be modeled well by existing latent vectors, a new latent vector
is used, which indicates that the view is inconsistent with the other views.
In the M-step, the projection matrices W are estimated by maximizing the logarithm of the joint
likelihood (2) while fixing cluster assignment variables S. By setting the gradient of the joint log
likelihood with respect to W equal to zero, an estimate of W is obtained as follows,
Wd =

N
 a? X

b?

n=1

xnd ??
nsnd

N X
Jn
X
n=1 j=1

Cnj +

N
?1
a? X
?
?
?
.
nsnd nsnd
b? n=1

(14)

When we iterate the E-step that samples the latent vector assignment snd by employing (8) for
each view d = 1, . . . , D in each instance n = 1, . . . , N , and the M-step that maximizes the joint
likelihood using (14) with respect to the projection matrix Wd for each view d = 1, . . . , D, we
obtain an estimate of the latent vector assignments and projection matrices.
4

In Section 2, we defined that an instance is an anomaly when its different views are generated from
different latent vectors. Therefore, for an anomaly score, we use the probability that the instance
uses more than one latent vector. It is estimated by using the samples obtained in the inference as
PH
(h)
(h)
follows, vn = H1 h=1 I(Jn > 1), where Jn is the number of latent vectors used by the nth
instance in the hth iteration of the Gibbs sampling after the burn-in period, and H is the number
of the iterations. The output of the proposed method is a ranked list of anomalies based on their
anomaly scores. An analyst would investigate top few anomalies, or use a threshold to select the
anomalies [6]. The threshold can be determined based on a targeted false alarm and detection rate.
We can use cross-validation to select an appropriate dimensionality for the latent space K. With
cross-validation, we assume that some features are missing from the given data, and infer the model
with a different K. Then, we select the smallest K value that has performed the best at predicting
missing values.

4 Related Work
Anomaly detection has had a wide variety of applications, such as credit card fraud detection [1],
intrusion detection for network security [17], and analysis for healthcare data [3]. However, most
existing anomaly detection techniques assume data with a single view, i.e. a single observation
feature set.
A number of anomaly detection methods for two-view data have been proposed [12, 20?22, 24].
However, they cannot be used for data with more than two views. Gao et al. [13] proposed a
HOrizontal Anomaly Detection algorithm (HOAD) for finding anomalies from multi-view data. In
HOAD, there are hyperparameters including a weight for the constraint that require the data to be
labeled as anomalous or not for tuning, and the performance is sensitive to the hyperparameters. On
the other hand, the parameters with the proposed model can be estimated from the given multi-view
data without label information by maximizing the likelihood. In addition, because the proposed
model is a probabilistic generative model, we can extend it in a probabilistically principled manner,
for example, for handling missing data and combining with other probabilistic models.
Liu and Lam [16] proposed multi-view anomaly detection methods using consensus clustering. They
found anomalies based on the inconsistency of clustering results across multiple views. Therefore,
they cannot find inconsistency within a cluster. Christoudias et al. [8] proposed a method for filtering
instances that are corrupted by background noise from multi-view data. The multi-view anomalies
considered in this paper include not only instances corrupted by background noise but also instances
categorized into different foreground classes across views, and instances with inconsistent views
even if they belong to the same cluster. Recently, Alvarez et al. [2] proposed a multi-view anomaly
detection method. However, since the method is based on clustering, it cannot find anomalies when
there are no clusters in the given data.
The proposed model is a generalization of either probabilistic principal component analysis
(PPCA) [23] or probabilistic canonical correlation analysis (PCCA) [5]. When all views are generated from different latent vectors for every instance, the proposed model corresponds to PPCA
that is performed independently for each view. When all views are generated from a single latent
vector for every instance, the proposed model corresponds to PCCA with spherical noise.
PCCA, or canonical correlation analysis (CCA), can be used for multi-view anomaly detection. With
PCCA, a latent vector that is shared by all views for each instance and a linear projection matrix for
each view are estimated by maximizing the likelihood, or minimizing the reconstruction error of the
given data. The reconstruction error for each instance can be used as an anomaly score. However, the
reconstruction errors are not reliable because they are calculated from parameters that are estimated
using data with anomalies by assuming that all of the instances are non-anomalous. On the other
hand, because the proposed model simultaneously estimates the parameters and infers anomalies,
the estimated parameters are not contaminated by the anomalies. With PPCA and PCCA, Gaussian
distributions are used for observation noise, which are sensitive to atypical observations. Robust
PPCA and PCCA [4] use Student-t distributions instead of Gaussian distributions, which are stable
to data containing single-view anomalies. The proposed model assumes Gaussian observation noise,
and its precision is parameterized by a Gamma distributed variable ?. Since we marginalize out ?
in the inference as written in (4), the observation noise becomes a Student-t distribution. Therefore,
the proposed model is robust to single-view anomalies.
5

With some CCA-related methods, each latent vector is factorized into shared and private components
across different views [10]. They assume that every instance has shared and private parts that are the
same dimensionality for all instances. In contrast, the proposed model assumes that non-anomalous
instances have only shared latent vectors, and anomalies have private latent vectors. The proposed
model can be seen as CCA with private latent vectors, where latent vectors across views are clustered for each instance. When CCA with private latent vectors are inferred without clustering, the
inferred private latent vectors do not become the same even if it is generated from a single latent vector, because switching latent dimension or rotating the latent space does not change the likelihood.
Therefore, difference of the latent vectors cannot be used for multi-view anomaly detection.

5 Experiments
Data We evaluated the proposed model quantitatively by using 11 data sets, which we obtained
from the LIBSVM data sets [7]. We generated two views by randomly splitting the features, where
each feature can belong to only a single view, and anomalies were added by swapping views of
two randomly selected instances regardless of their class labels for each view. Splitting data does
not generate anomalies. Therefore, we can evaluate methods while controlling the anomaly rate
properly. By swapping, although single-view anomalies cannot be created since the distribution for
each view does not change, multi-view anomalies are created.
Comparing methods We compared the proposed model with probabilistic canonical correlation
analysis (PCCA), horizontal anomaly detection (HOAD) [13], consensus clustering based anomaly
detection (CC) [16], and one-class support vector machine (OCSVM) [18]. For PCCA, we used
the proposed model in which the number of latent vectors was fixed at one for every instance. The
anomaly scores obtained with PCCA were calculated based on the reconstruction errors. HOAD requires to select an appropriate hyperparameter value for controlling the constraints whereby different
views of the same instance are embedded close together. We ran HOAD with different hyperparameter settings {0.1, 1, 10, 100}, and show the results that achieved the highest performance for each
data set. For CC, first we clustered instances for each view using spectral clustering. We set the
number of clusters at 20, which achieved a good performance in preliminary experiments. Then, we
calculated anomaly scores by the likelihood of consensus clustering when an instance was removed
since it indicates inconsistency of the instance across different views. OCSVM is a representative
method for single-view anomaly detection. To investigate the performance of a single-view method
for multi-view anomaly detection, we included OCSVM as a comparison method. For OCSVM,
multiple views are concatenated in a single vector, then use it for the input. We used Gaussian kernel. In the proposed model, we used ? = 1, a = 1, and b = 1 for all experiments. The number of
iterations for the Gibbs sampling was 500, and the anomaly score was calculated by averaging over
the multiple samples.
Multi-view anomaly detection For the evaluation measurement, we used the area under the ROC
curve (AUC). A higher AUC indicates a higher anomaly detection performance. Figure 2 shows
AUCs with different rates of anomalies using 11 two-view data sets, which are averaged over 50
experiments. For the dimensionality of the latent space, we used K = 5 for the proposed model,
PCCA, and HOAD. In general, as the anomaly rate increases, the performance decreases. The
proposed model achieved the best performance with eight of the 11 data sets. This result indicates
that the proposed model can find anomalies effectively by inferring a number of latent vectors for
each instance. The performance of CC was low because it assumes that there are clusters for each
view, and it cannot find anomalies within clusters. The AUC of OCSVM was low, because it is a
single-view anomaly detection method, which considers instances anomalous that are different from
others within a single view. Multi-view anomaly detection is the task to find instances that have
inconsistent features across views, but not inconsistent features within a view. The computational
time needed for PCCA was 2 sec, and that needed for the proposed model was 35 sec with wine
data.
Figure 3 shows AUCs with different dimensionalities of latent vectors using data sets whose anomaly
rate is 0.4. When the dimensionality was very low (K = 1 or 2), the AUC was low in most of the data
sets, because low-dimensional latent vectors cannot represent the observation vectors well. With all
the methods, the AUCs were relatively stable when the latent dimensionality was higher than four.
6

(a) breast-cancer

(b) diabetes

0.7

(c) glass

0.6

Proposed
PCCA
HOAD
CC
OCSVM

0.65

0.58
0.65

AUC

AUC

AUC

0.6

0.56
0.54

0.6

0.55

0.52
0.55
0.4
0.6
anomaly rate

0.2

0.8

(d) heart

0.4
0.6
anomaly rate

0.8

0.2

(e) ionosphere

0.4
0.6
anomaly rate

0.8

(f) sonar

(g) svmguide2

0.85
0.8

0.6
AUC

0.56

AUC

0.75

0.58

0.7
0.65

0.54

0.6

0.52

0.55

0.9

0.56

0.8

0.54
AUC

0.62

AUC

0.5

0.5
0.2

0.7

0.52
0.5

0.6

0.2

0.4
0.6
anomaly rate

0.48

0.8

0.2

(h) svmguide4

0.4
0.6
anomaly rate

0.8

0.2

0.4
0.6
anomaly rate

(i) vehicle

0.2

0.8

(j) vowel

0.4
0.6
anomaly rate

0.8

(k) wine
0.8

0.85

0.75

0.8

0.7

0.7

0.7

0.75

AUC

AUC

AUC

0.8

0.7

0.55
0.4
0.6
anomaly rate

0.65
0.6

0.55

0.6
0.2

0.65
0.6

0.65
0.6

AUC

0.9

0.75

0.55

0.5

0.8

0.2

0.4
0.6
anomaly rate

0.8

0.2

0.4
0.6
anomaly rate

0.2

0.8

0.4
0.6
anomaly rate

0.8

Figure 2: Average AUCs with different anomaly rates, and their standard errors. A higher AUC is
better.
(a) breast-cancer

(b) diabetes

(c) glass

0.58

0.6

0.65

0.6

AUC

AUC

0.56
AUC

Proposed
PCCA
HOAD

0.62

0.54

0.56
0.54

0.52

0.55

0.58

0.52
0.5
2

4
6
8
latent dimensionality

2

10

(d) heart

4
6
8
latent dimensionality

0.5

10

(e) ionosphere

0.6

4
6
8
latent dimensionality

10

(f) sonar

(g) svmguide2
0.55

0.9

0.8

0.58
0.7

AUC

0.56

AUC

0.8
AUC

AUC

2

0.7

0.5

0.54
0.6

0.6

0.52
0.5
4
6
8
latent dimensionality

10

2

(h) svmguide4

4
6
8
latent dimensionality

0.5

10

(i) vehicle

0.9

0.85

0.8

0.75

0.45

10

2

0.65

10

0.75
0.7

0.7

0.7

4
6
8
latent dimensionality

(k) wine

0.75

AUC

AUC

AUC

0.7

4
6
8
latent dimensionality

(j) vowel

0.8

0.65

0.65

0.6

0.6

0.55

0.55

0.6

0.6

0.55
0.5

2

AUC

2

0.5

2

4
6
8
latent dimensionality

10

2

4
6
8
latent dimensionality

10

2

4
6
8
latent dimensionality

10

2

4
6
8
latent dimensionality

10

Figure 3: Average AUCs with different dimensionalities of latent vectors, and their standard errors.

Single-view anomaly detection We would like to find multi-view anomalies, but woul not like to
detect single-view anomalies. We illustrated that the proposed model does not detect single-view
anomalies using synthetic single-view anomaly data. With the synthetic data, latent vectors for
7

Table 1: Average AUCs for single-view anomaly detection.
Proposed
0.117 ? 0.098

PCCA
0.174 ? 0.095

OCSVM
0.860 ? 0.232

Table 2: High and low anomaly score movies calculated by the proposed model.
Title
Score Title
Score
The Full Monty
0.98 Star Trek VI
0.04
Liar Liar
0.93 Star Trek III
0.04
The Professional
0.91 The Saint
0.04
Mr. Holland?s Opus 0.88 Heat
0.03
Contact
0.87 Conspiracy Theory 0.03
?
single-view anomalies were generated from N (0, 10I), and those for non-anomalous instances
were generated from N (0, I). Since each of the anomalies has only one single latent vector, it is
not a multi-view anomaly. The numbers of anomalous and non-anomalous instances were 5 and 95,
respectively. The dimensionalities of the observed and latent spaces were five and three, respectively.
Table 1 shows the average AUCs with the single-view anomaly data, which are averaged over 50
different data sets. The low AUC of the proposed model indicates that it does not consider singleview anomalies as anomalies. On the other hand, the AUC of the one-class SVM (OCSVM) was
high because OCSVM is a single-view anomaly detection method, and it leads to low multi-view
anomaly detection performance.
Application to movie data For an application of multi-view anomaly detection, we analyzed inconsistency between movie rating behavior and genre in MovieLens data [14]. An instance corresponds to a movie, where the first view represents whether the movie is rated or not by users, and the
second view represents the movie genre. Both views consist of binary features, where some movies
are categorized in multiple genres. We used 338 movies, 943 users and 19 genres. Table 2 shows
high and low anomaly score movies when we analyzed the movie data by the proposed method with
K = 5. ?The Full Monty? and ?Liar Liar? were categorized in ?Comedy? genre. They are rated
by not only users who likes ?Comedy?, but also who likes ?Romance? and ?Action-Thriller?. ?The
Professional? was anomaly because it was rated by two different user groups, where a group prefers
?Romance? and the other prefers ?Action?. Since ?Star Trek? series are typical Sci-Fi and liked by
specific users, its anomaly score was low.

6 Conclusion
We proposed a generative model approach for multi-view anomaly detection, which finds instances
that have inconsistent views. In the experiments, we confirmed that the proposed model could
perform much better than existing methods for detecting multi-view anomalies. There are several
avenues that can be pursued for future work. Since the proposed model assumes the linearity of
observations with respect to their latent vectors, it cannot find anomalies when different views are
in a nonlinear relationship. We can relax this assumption by using Gaussian processes [15]. We can
also relax the assumption that non-anomalous instances have the same latent vector across all views
by introducing private latent vectors [10]. The proposed model assumes Gaussian observation noise.
Our framework can be extended for binary or count data by using Bernoulli or Poisson distributions
instead of Gaussian.
Acknowledgments
MY was supported by KAKENHI 16K16114.

References
[1] E. Aleskerov, B. Freisleben, and B. Rao. Cardwatch: A neural network based database mining system for
credit card fraud detection. In Proceedings of the IEEE/IAFE Computational Intelligence for Financial
Engineering, pages 220?226, 1997.

8

[2] A. M. Alvarez, M. Yamada, A. Kimura, and T. Iwata. Clustering-based anomaly detection in multi-view
data. In Proceedings of ACM International Conference on Information and Knowledge Management,
CIKM, 2013.
[3] M.-L. Antonie, O. R. Zaiane, and A. Coman. Application of data mining techniques for medical image
classification. MDM/KDD, pages 94?101, 2001.
[4] C. Archambeau, N. Delannay, and M. Verleysen. Robust probabilistic projections. In Proceedings of the
23rd International Conference on Machine Learning, pages 33?40, 2006.
[5] F. R. Bach and M. I. Jordan. A probabilistic interpretation of canonical correlation analysis. Technical
Report 688, Department of Statistics, University of California, Berkeley, 2005.
[6] V. Chandola, A. Banerjee, and V. Kumar. Anomaly detection: A survey. ACM Computing Surveys
(CSUR), 41(3):15, 2009.
[7] C. Chang and C. Lin. LIBSVM: a library for support vector machines. ACM Transactions on Intelligent
Systems and Technology (TIST), 2(3):27, 2011.
[8] C. M. Christoudias, R. Urtasun, and T. Darrell. Multi-view learning in the presence of view disagreement.
In Proceedings of the 24th Conference on Unvertainty in Artificial Intelligence, UAI, 2008.
[9] K. Duh, C.-M. A. Yeung, T. Iwata, and M. Nagata. Managing information disparity in multilingual
document collections. ACM Transactions on Speech and Language Processing (TSLP), 10(1):1, 2013.
[10] C. H. Ek, J. Rihan, P. H. Torr, G. Rogez, and N. D. Lawrence. Ambiguity modeling in latent spaces. In
Machine Learning for Multimodal Interaction, pages 62?73. Springer, 2008.
[11] H. Fanaee-T and J. a. Gama. Tensor-based anomaly detection. Know.-Based Syst., 98(C):130?147, 2016.
[12] J. Gao, F. Liang, W. Fan, C. Wang, Y. Sun, and J. Han. On community outliers and their efficient
detection in information networks. In Proceedings of the 16th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pages 813?822. ACM, 2010.
[13] J. Gao, W. Fan, D. Turaga, S. Parthasarathy, and J. Han. A spectral framework for detecting inconsistency
across multi-source object relationships. In IEEE 11th International Conference on Data Mining (ICDM),
pages 1050?1055. IEEE, 2011.
[14] J. L. Herlocker, J. A. Konstan, A. Borchers, and J. Riedl. An algorithmic framework for performing
collaborative filtering. In Proceedings of the 22nd Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval, pages 230?237. ACM, 1999.
[15] N. D. Lawrence. Gaussian process latent variable models for visualisation of high dimensional data.
Advances in Neural Information Processing Systems, 16(3):329?336, 2004.
[16] A. Y. Liu and D. N. Lam. Using consensus clustering for multi-view anomaly detection. In 2012 IEEE
Symposium on Security and Privacy Workshops (SPW), pages 117?124. IEEE, 2012.
[17] L. Portnoy, E. Eskin, and S. Stolfo. Intrusion detection with unlabeled data using clustering. In Proceedings of ACM CSS Workshop on Data Mining Applied to Security, 2001.
[18] B. Sch?lkopf, J. C. Platt, J. Shawe-Taylor, A. J. Smola, and R. C. Williamson. Estimating the support of
a high-dimensional distribution. Neural computation, 13(7):1443?1471, 2001.
[19] J. Sethuraman. A constructive definition of Dirichlet priors. Statistica Sinica, 4:639?650, 1994.
[20] S. Shekhar, C.-T. Lu, and P. Zhang. Detecting graph-based spatial outliers. Intelligent Data Analysis, 6
(5):451?468, 2002.
[21] X. Song, M. Wu, C. Jermaine, and S. Ranka. Conditional anomaly detection. IEEE Transactions on
Knowledge and Data Engineering, 19(5):631?645, 2007.
[22] J. Sun, H. Qu, D. Chakrabarti, and C. Faloutsos. Neighborhood formation and anomaly detection in
bipartite graphs. In Proceedings of the 5th IEEE International Conference on Data Mining, pages 418?
425. IEEE, 2005.
[23] M. Tipping and C. Bishop. Probabilistic principal component analysis. Journal of the Royal Statistical
Society: Series B (Statistical Methodology), 61(3):611?622, 1999.
[24] X. Wang and I. Davidson. Discovering contexts and contextual outliers using random walks in graphs. In
Proceedings of the 9th IEEE International Conference on Data Mining, pages 1034?1039. IEEE, 2009.

9


----------------------------------------------------------------

title: 4612-multi-criteria-anomaly-detection-using-pareto-depth-analysis.pdf

Multi-criteria Anomaly Detection using
Pareto Depth Analysis

Ko-Jen Hsiao, Kevin S. Xu, Jeff Calder, and Alfred O. Hero III
University of Michigan, Ann Arbor, MI, USA 48109
{coolmark,xukevin,jcalder,hero}@umich.edu

Abstract
We consider the problem of identifying patterns in a data set that exhibit anomalous behavior, often referred to as anomaly detection. In most anomaly detection
algorithms, the dissimilarity between data samples is calculated by a single criterion, such as Euclidean distance. However, in many cases there may not exist a
single dissimilarity measure that captures all possible anomalous patterns. In such
a case, multiple criteria can be defined, and one can test for anomalies by scalarizing the multiple criteria using a linear combination of them. If the importance
of the different criteria are not known in advance, the algorithm may need to be
executed multiple times with different choices of weights in the linear combination. In this paper, we introduce a novel non-parametric multi-criteria anomaly
detection method using Pareto depth analysis (PDA). PDA uses the concept of
Pareto optimality to detect anomalies under multiple criteria without having to
run an algorithm multiple times with different choices of weights. The proposed
PDA approach scales linearly in the number of criteria and is provably better than
linear combinations of the criteria.

1

Introduction

Anomaly detection is an important problem that has been studied in a variety of areas and used in diverse applications including intrusion detection, fraud detection, and image processing [1, 2]. Many
methods for anomaly detection have been developed using both parametric and non-parametric approaches. Non-parametric approaches typically involve the calculation of dissimilarities between
data samples. For complex high-dimensional data, multiple dissimilarity measures corresponding
to different criteria may be required to detect certain types of anomalies. For example, consider the
problem of detecting anomalous object trajectories in video sequences. Multiple criteria, such as
dissimilarity in object speeds or trajectory shapes, can be used to detect a greater range of anomalies
than any single criterion. In order to perform anomaly detection using these multiple criteria, one
could first combine the dissimilarities using a linear combination. However, in many applications,
the importance of the criteria are not known in advance. It is difficult to determine how much weight
to assign to each dissimilarity measure, so one may have to choose multiple weights using, for example, a grid search. Furthermore, when the weights are changed, the anomaly detection algorithm
needs to be re-executed using the new weights.
In this paper we propose a novel non-parametric multi-criteria anomaly detection approach using
Pareto depth analysis (PDA). PDA uses the concept of Pareto optimality to detect anomalies without
having to choose weights for different criteria. Pareto optimality is the typical method for defining
optimality when there may be multiple conflicting criteria for comparing items. An item is said to
be Pareto-optimal if there does not exist another item that is better or equal in all of the criteria. An
item that is Pareto-optimal is optimal in the usual sense under some combination, not necessarily
linear, of the criteria. Hence, PDA is able to detect anomalies under multiple combinations of the
criteria without explicitly forming these combinations.
1

6
5

3

3

3

|?y|

|?y|

y

4
2

2

2
1

1

1
0

0

1

2

3
x

4

5

6

0

0

1

2
|?x|

3

0

0

1

2
|?x|

3

Figure 1: Left: Illustrative example with 40 training samples (blue x?s) and 2 test samples (red circle
and triangle) in R2 . Center: Dyads for the training samples (black dots) along with first 20 Pareto
fronts (green lines) under two criteria: |?x| and |?y|. The Pareto fronts induce a partial ordering on
the set of dyads. Dyads associated with the test sample marked by the red circle concentrate around
shallow fronts (near the lower left of the figure). Right: Dyads associated with the test sample
marked by the red triangle concentrate around deep fronts.

The PDA approach involves creating dyads corresponding to dissimilarities between pairs of data
samples under all of the dissimilarity measures. Sets of Pareto-optimal dyads, called Pareto fronts,
are then computed. The first Pareto front (depth one) is the set of non-dominated dyads. The second
Pareto front (depth two) is obtained by removing these non-dominated dyads, i.e. peeling off the
first front, and recomputing the first Pareto front of those remaining. This process continues until
no dyads remain. In this way, each dyad is assigned to a Pareto front at some depth (see Fig. 1 for
illustration). Nominal and anomalous samples are located near different Pareto front depths; thus
computing the front depths of the dyads corresponding to a test sample can discriminate between
nominal and anomalous samples. The proposed PDA approach scales linearly in the number of criteria, which is a significant improvement compared to selecting multiple weights via a grid search,
which scales exponentially in the number of criteria. Under assumptions that the multi-criteria dyads
can be modeled as a realizations from a smooth K-dimensional density we provide a mathematical
analysis of the behavior of the first Pareto front. This analysis shows in a precise sense that PDA
can outperform a test that uses a linear combination of the criteria. Furthermore, this theoretical prediction is experimentally validated by comparing PDA to several state-of-the-art anomaly detection
algorithms in two experiments involving both synthetic and real data sets.
The rest of this paper is organized as follows. We discuss related work in Section 2. In Section 3 we
provide an introduction to Pareto fronts and present a theoretical analysis of the properties of the first
Pareto front. Section 4 relates Pareto fronts to the multi-criteria anomaly detection problem, which
leads to the PDA anomaly detection algorithm. Finally we present two experiments in Section 5 to
evaluate the performance of PDA.

2

Related work

Several machine learning methods utilizing Pareto optimality have previously been proposed; an
overview can be found in [3]. These methods typically formulate machine learning problems as
multi-objective optimization problems where finding even the first Pareto front is quite difficult.
These methods differ from our use of Pareto optimality because we consider multiple Pareto fronts
created from a finite set of items, so we do not need to employ sophisticated methods in order to find
these fronts.
Hero and Fleury [4] introduced a method for gene ranking using Pareto fronts that is related to our
approach. The method ranks genes, in order of interest to a biologist, by creating Pareto fronts of
the data samples, i.e. the genes. In this paper, we consider Pareto fronts of dyads, which correspond
to dissimilarities between pairs of data samples rather than the samples themselves, and use the
distribution of dyads in Pareto fronts to perform multi-criteria anomaly detection rather than ranking.
Another related area is multi-view learning [5, 6], which involves learning from data represented by
multiple sets of features, commonly referred to as ?views?. In such case, training in one view helps to
2

improve learning in another view. The problem of view disagreement, where samples take different
classes in different views, has recently been investigated [7]. The views are similar to criteria in
our problem setting. However, in our setting, different criteria may be orthogonal and could even
give contradictory information; hence there may be severe view disagreement. Thus training in one
view could actually worsen performance in another view, so the problem we consider differs from
multi-view learning. A similar area is that of multiple kernel learning [8], which is typically applied
to supervised learning problems, unlike the unsupervised anomaly detection setting we consider.
Finally, many other anomaly detection methods have previously been proposed. Hodge and Austin
[1] and Chandola et al. [2] both provide extensive surveys of different anomaly detection methods
and applications. Nearest neighbor-based methods are closely related to the proposed PDA approach. Byers and Raftery [9] proposed to use the distance between a sample and its kth-nearest
neighbor as the anomaly score for the sample; similarly, Angiulli and Pizzuti [10] and Eskin et al.
[11] proposed to the use the sum of the distances between a sample and its k nearest neighbors.
Breunig et al. [12] used an anomaly score based on the local density of the k nearest neighbors
of a sample. Hero [13] and Sricharan and Hero [14] introduced non-parametric adaptive anomaly
detection methods using geometric entropy minimization, based on random k-point minimal spanning trees and bipartite k-nearest neighbor (k-NN) graphs, respectively. Zhao and Saligrama [15]
proposed an anomaly detection algorithm k-LPE using local p-value estimation (LPE) based on a
k-NN graph. These k-NN anomaly detection schemes only depend on the data through the pairs of
data points (dyads) that define the edges in the k-NN graphs.
All of the aforementioned methods are designed for single-criteria anomaly detection. In the multicriteria setting, the single-criteria algorithms must be executed multiple times with different weights,
unlike the PDA anomaly detection algorithm that we propose in Section 4.

3

Pareto depth analysis

The PDA method proposed in this paper utilizes the notion of Pareto optimality, which has been
studied in many application areas in economics, computer science, and the social sciences among
others [16]. We introduce Pareto optimality and define the notion of a Pareto front.
Consider the following problem: given n items, denoted by the set S, and K criteria for evaluating
each item, denoted by functions f1 , . . . , fK , select x ? S that minimizes [f1 (x), . . . , fK (x)]. In
most settings, it is not possible to identify a single item x that simultaneously minimizes fi (x)
for all i ? {1, . . . , K}. A minimizer can be found by combining the K criteria using a linear
combination of the fi ?s and finding the minimum of the combination. Different choices of (nonnegative) weights in the linear combination could result in different minimizers; a set of items that
are minimizers under some linear combination can then be created by using a grid search over the
weights, for example.
A more powerful approach involves finding the set of Pareto-optimal items. An item x is said to
strictly dominate another item x? if x is no greater than x? in each criterion and x is less than
x? in at least one criterion. This relation can be written as x  x? if fi (x) ? fi (x? ) for each i
and fi (x) < fi (x? ) for some i. The set of Pareto-optimal items, called the Pareto front, is the set
of items in S that are not strictly dominated by another item in S. It contains all of the minimizers
that are found using linear combinations, but also includes other items that cannot be found by linear
combinations. Denote the Pareto front by F1 , which we call the first Pareto front. The second Pareto
front can be constructed by finding items that are not strictly dominated by any of the remaining
items, which are members of the set S \ F1 . More generally, define the ith Pareto front by
?
?
i?1
[
Fi = Pareto front of the set S \ ?
Fj ? .
j=1

For convenience, we say that a Pareto front Fi is deeper than Fj if i > j.
3.1

Mathematical properties of Pareto fronts

The distribution of the number of points on the first Pareto front was first studied by BarndorffNielsen and Sobel in their seminal work [17]. The problem has garnered much attention since; for a
3

survey of recent results see [18]. We will be concerned here with properties of the first Pareto front
that are relevant to the PDA anomaly detection algorithm and thus have not yet been considered in
the literature. Let Y1 , . . . , Yn be independent and identically distributed (i.i.d.) on Rd with density
function f : Rd ? R. For a measurable set A ? Rd , we denote by FA the points on the first Pareto
front of Y1 , . . . , Yn that belong to A. For simplicity, we will denote F1 by F and use |F| for the
cardinality of F. In the general Pareto framework, the points Y1 , . . . , Yn are the images in Rd of n
feasible solutions to some optimization problem under a vector of objective functions of length d.
In the context of this paper, each point Yl corresponds to a dyad Dij , which we define in Section 4,
and d = K is the number of criteria. A common approach in multi-objective optimization is linear
scalarization [16], which constructs a new single criterion as a convex combination of the d criteria.
It is well-known, and easy to see,
S that linear scalarization will only identify Pareto points on the
boundary of the convex hull of x?F (x + Rd+ ), where Rd+ = {x ? Rd | xi ? 0, i = 1 . . . , d}.
Although this is a common motivation for Pareto methods, there are, to the best of our knowledge,
no results in the literature regarding how many points on the Pareto front are missed by scalarization.
We present such a result here. We define
)
( d
[
X
L=
argmin
?i xi , Sn = {Y1 , . . . , Yn }.
??Rd
+

x?Sn

i=1

The subset L ? F contains all Pareto-optimal points that can be obtained by some selection of
weights for linear scalarization. We aim to study how large L can get, compared to F, in expectation.
In the context of this paper, if some Pareto-optimal points are not identified, then the anomaly
score (defined in section 4.2) will be artificially inflated, making it more likely that a non-anomalous
sample will be rejected. Hence the size of F \ L is a measure of how much the anomaly score is
inflated and the degree to which Pareto methods will outperform linear scalarization.
Pareto points in F \ L are a result of non-convexities in the Pareto front. We study two kinds of
non-convexities: those induced by the geometry of the domain of Y1 , . . . , Yn , and those induced by
randomness. We first consider the geometry of the domain. Let ? ? Rd be bounded and open with
a smooth boundary ?? and suppose the density f vanishes outside of ?. For a point z ? ?? we
denote by ?(z) = (?1 (z), . . . , ?d (z)) the unit inward normal to ??. For T ? ??, define Th ? ? by
Th = {z + t? | z ? T, 0 < t ? h}. Given h > 0 it is not hard to see that all Pareto-optimal points
will almost surely lie in ??h for large enough n, provided the density f is strictly positive on ??h .
Hence it is enough to study the asymptotics for E|FTh | for T ? ?? and h > 0.
Theorem 1. Let f ? C 1 (?) with inf ? f > 0. Let T ? ?? be open and connected such that
inf min(?1 (z), . . . , ?d (z)) ? ? > 0,

z?T

and

{y ? ? : y  x} = {x}, for x ? T.

Then for h > 0 sufficiently small, we have
 d?2 
d?1
E|FTh | = ?n d + ? ?d?1 O n d
as n ? ?,
Z
d?1
1
1
where ? = d?1 (d!) d ?(d?1 )
f (z) d (?1 (z) ? ? ? ?d (z)) d dz.
T

The proof of Theorem 1 is postponed to Section 1 of the supplementary material. Theorem 1 shows
asymptotically how many Pareto points are contributed on average by the segment T ? ??. The
number of points contributed depends only on the geometry of ?? through the direction of its normal
vector ? and is otherwise independent of the convexity of ??. Hence, by using Pareto methods, we
will identify significantly more Pareto-optimal points than linear scalarization when the geometry
of ?? includes non-convex regions. For example, if T ? ?? is non-convex (see left panel of
Figure 2) and satisfies the hypotheses of Theorem 1, then for large enough n, all Pareto points in
a neighborhood of T will be unattainable by scalarization. Quantitatively, if f ? C on T , then
d?1
d?2
d?1
1
E|F \ L| ? ?n d + ? ?d?1 O(n d ), as n ? ?, where ? ? d?1 (d!) d ?(d?1 )|T |?C d and |T |
is the d ? 1 dimensional Hausdorff measure of T . It has recently come to our attention that Theorem
1 appears in a more general form in an unpublished manuscript of Baryshnikov and Yukich [19].
We now study non-convexities in the Pareto front which occur due to inherent randomness in the
samples. We show that, even in the case where ? is convex, there are still numerous small-scale
non-convexities in the Pareto front that can only be detected by Pareto methods. We illustrate this in
the case of the Pareto box problem for d = 2.
4

0.25

0.2

0.15

0.1

0.05

0

?0.05
?0.05

0

0.05

0.1

0.15

0.2

0.25

0.3

0.35

0.4

Figure 2: Left: Non-convexities in the Pareto front induced by the geometry of the domain ? (Theorem 1). Right: Non-convexities due to randomness in the samples (Theorem 2). In each case, the
larger points are Pareto-optimal, and the large black points cannot be obtained by scalarization.
Theorem 2. Let Y1 , . . . , Yn be independent and uniformly distributed on [0, 1]2 . Then
1
5
ln n + O(1) ? E|L| ? ln n + O(1), as n ? ?.
2
6
The proof of Theorem 2 is also postponed to Section 1 of the supplementary material. A proof that
E|F| = ln n + O(1) as n ? ? can be found in [17]. Hence Theorem 2 shows that, asymptotically
and in expectation, only between 12 and 65 of the Pareto-optimal points can be obtained by linear
scalarization in the Pareto box problem. Experimentally, we have observed that the true fraction of
points is close to 0.7. This means that at least 16 (and likely more) of the Pareto points can only be
obtained via Pareto methods even when ? is convex. Figure 2 gives an example of the sets F and L
from the two theorems.

4

Multi-criteria anomaly detection

Assume that a training set XN = {X1 , . . . , XN } of nominal data samples is available. Given a test
sample X, the objective of anomaly detection is to declare X to be an anomaly if X is significantly
different from samples in XN . Suppose that K > 1 different evaluation criteria are given. Each criterion is associated with a measure for computing dissimilarities. Denote the dissimilarity between
Xi and Xj computed using the measure corresponding to the lth criterion by dl (i, j).
We define a dyad by Dij = [d1 (i, j), . . . , dK (i, j)]T ? RK
+ , i ? {1, . . . , N }, j ? {1, . . . , N } \ i.
Each dyad
D
corresponds
to
a
connection
between
samples
Xi and Xj . Therefore, there are in
ij

total N2 different dyads. For convenience, denote the set of all dyads by D and the space of all
dyads RK
+ by D. By the definition of strict dominance in Section 3, a dyad Dij strictly dominates
another dyad Di? j ? if dl (i, j) ? dl (i? , j ? ) for all l ? {1, . . . , K} and dl (i, j) < dl (i? , j ? ) for some
l. The first Pareto front F1 corresponds to the set of dyads from D that are not strictly dominated by
any other dyads from D. The second Pareto front F2 corresponds to the set of dyads from D \ F1
that are not strictly dominated by any other dyads from D \ F1 , and so on, as defined in Section 3.
Recall that we refer to Fi as a deeper front than Fj if i > j.
4.1

Pareto fronts of dyads

For each sample Xn , there are N ? 1 dyads corresponding to its connections with the other N ? 1
samples. Define the set of N ? 1 dyads associated with Xn by Dn . If most dyads in Dn are located
at shallow Pareto fronts, then the dissimilarities between Xn and the other N ? 1 samples are small
under some combination of the criteria. Thus, Xn is likely to be a nominal sample. This is the basic
idea of the proposed multi-criteria anomaly detection method using PDA.
We construct Pareto fronts F1 , . . . , FM of the dyads from the training set, where the total number
of fronts M is the required number of fronts such that each dyad is a member of a front. When a test
sample X is obtained, we create new dyads corresponding to connections between X and training
samples, as illustrated in Figure 1. Similar to many other anomaly detection methods, we connect
each test sample to its k nearest neighbors. k could be different for each criterion, so we denote ki
PK
as the choice of k for criterion i. We create s = i=1 ki new dyads, which we denote by the set
5

Algorithm 1 PDA anomaly detection algorithm.
Training phase:
1: for l = 1 ? K do
2:
Calculate pairwise dissimilarities dl (i, j) between all training samples Xi and Xj
3: Create dyads Dij = [d1 (i, j), . . . , dK (i, j)] for all training samples
4: Construct Pareto fronts on set of all dyads until each dyad is in a front
Testing phase:
1: nb ? [ ] {empty list}
2: for l = 1 ? K do
3:
Calculate dissimilarities between test sample X and all training samples in criterion l
4:
nbl ? kl nearest neighbors of X
5:
nb ? [nb, nbl ] {append neighbors to list}
6: Create s new dyads Dinew between X and training samples in nb
7: for i = 1 ? s do
8:
Calculate depth ei of Dinew
Ps
9: Declare X an anomaly if v(X) = (1/s) i=1 ei > ?
Dnew = {D1new , D2new , . . . , Dsnew }, corresponding to the connections between X and the union of the
ki nearest neighbors in each criterion i. In other words, we create a dyad between X and Xj if Xj
is among the ki nearest neighbors1 of X in any criterion i. We say that Dinew is below a front Fl if
Dinew  Dl for some Dl ? Fl , i.e. Dinew strictly dominates at least a single dyad in Fl . Define the
depth of Dinew by
ei = min{l | Dinew is below Fl }.
Therefore if ei is large, then Dinew will be near deep fronts, and the distance between X and the
corresponding training sample is large under all combinations of the K criteria. If ei is small, then
Dinew will be near shallow fronts, so the distance between X and the corresponding training sample
is small under some combination of the K criteria.
4.2

Anomaly detection using depths of dyads

In k-NN based anomaly detection algorithms such as those mentioned in Section 2, the anomaly
score is a function of the k nearest neighbors to a test sample. With multiple criteria, one could define an anomaly score by scalarization. From the probabilistic properties of Pareto fronts discussed
in Section 3.1, we know that Pareto methods identify more Pareto-optimal points than linear scalarization methods and significantly more Pareto-optimal points than a single weight for scalarization2 .
This motivates us to develop a multi-criteria anomaly score using Pareto fronts. We start with the
observation from Figure 1 that dyads corresponding to a nominal test sample are typically located
near shallower fronts than dyads corresponding to an anomalous test sample. Each test sample is
associated with s new dyads, where the ith dyad Dinew has depth ei . For each test sample X, we
define the anomaly score v(X) to be the mean of the ei ?s, which corresponds to the average depth
of the s dyads associated with X. Thus the anomaly score can be easily computed and compared to
the decision threshold ? using the test
s

v(X) =

1 X H1
ei ? ?.
s i=1 H0

Pseudocode for the PDA anomaly detector is shown in Algorithm 1. In Section 3 of the supplementary material we provide details of the implementation as well as an analysis of the time complexity
and a heuristic for choosing the ki ?s that performs well in practice. Both the training time and the
1

If a training sample is one of the ki nearest neighbors in multiple criteria, then multiple copies of the dyad
corresponding to the connection between the test sample and the training sample are created.
2
Theorems 1 and 2 require i.i.d. samples, but dyads are not independent. However, there are O(N 2 ) dyads,
and each dyad is only dependent on O(N ) other dyads. This suggests that the theorems should also hold for the
non-i.i.d. dyads as well, and it is supported by experimental results presented in Section 2 of the supplementary
material.

6

Table 1: AUC comparison of different methods for both experiments. Best AUC is shown in bold.
PDA does not require selecting weights so it has a single AUC. The median and best AUCs (over all
choices of weights selected by grid search) are shown for the other four methods. PDA outperforms
all of the other methods, even for the best weights, which are not known in advance.
(a) Four-criteria simulation (? standard error)

Method
PDA
k-NN
k-NN sum
k-LPE
LOF

(b) Pedestrian trajectories

AUC by weight
Median
Best
0.948 ? 0.002
0.848 ? 0.004 0.919 ? 0.003
0.854 ? 0.003 0.916 ? 0.003
0.847 ? 0.004 0.919 ? 0.003
0.845 ? 0.003 0.932 ? 0.003

Method
PDA
k-NN
k-NN sum
k-LPE
LOF

AUC by weight
Median Best
0.915
0.883
0.906
0.894
0.911
0.893
0.908
0.839
0.863

time required to test a new sample using PDA are linear in the number of criteria K. To handle
multiple criteria, other anomaly detection methods, such as the ones mentioned in Section 2, need
to be re-executed multiple times using different (non-negative) linear combinations of the K criteria. If a grid search is used for selection of the weights in the linear combination, then the required
computation time would be exponential in K. Such an approach presents a computational problem
unless K is very small. Since PDA scales linearly with K, it does not encounter this problem.

5

Experiments

We compare the PDA method with four other nearest neighbor-based single-criterion anomaly detection algorithms mentioned in Section 2. For these methods, we use linear combinations of the
criteria with different weights selected by grid search to compare performance with PDA.
5.1

Simulated data with four criteria

First we present an experiment on a simulated data set. The nominal distribution is given by the
uniform distribution on the hypercube [0, 1]4 . The anomalous samples are located just outside of
this hypercube. There are four classes of anomalous distributions. Each class differs from the
nominal distribution in one of the four dimensions; the distribution in the anomalous dimension is
uniform on [1, 1.1]. We draw 300 training samples from the nominal distribution followed by 100
test samples from a mixture of the nominal and anomalous distributions with a 0.05 probability of
selecting any particular anomalous distribution. The four criteria for this experiment correspond to
the squared differences in each dimension. If the criteria are combined using linear combinations,
the combined dissimilarity measure reduces to weighted squared Euclidean distance.
The different methods are evaluated using the receiver operating characteristic (ROC) curve and
the area under the curve (AUC). The mean AUCs (with standard errors) over 100 simulation runs
are shown in Table 1(a). A grid of six points between 0 and 1 in each criterion, corresponding to
64 = 1296 different sets of weights, is used to select linear combinations for the single-criterion
methods. Note that PDA is the best performer, outperforming even the best linear combination.
5.2

Pedestrian trajectories

We now present an experiment on a real data set that contains thousands of pedestrians? trajectories
in an open area monitored by a video camera [20]. Each trajectory is approximated by a cubic spline
curve with seven control points [21]. We represent a trajectory with l time samples by


x1 x2 . . . x l
T =
,
y1 y2 . . . yl
where [xt , yt ] denote a pedestrian?s position at time step t.
7

1

0.06
0.05
Shape dissimilarity

True positive rate

0.8

0.6

0.4
PDA method
k?LPE with best AUC weight
k?LPE with worst AUC weight
Attainable region of k?LPE

0.2

0

0

0.2

0.4
0.6
False positive rate

0.8

0.04
0.03
0.02
0.01
0

1

0

0.01

0.02
0.03
0.04
Walking speed dissimilarity

0.05

Figure 3: Left: ROC curves for PDA and attainable region for k-LPE over 100 choices of weights.
PDA outperforms k-LPE even under the best choice of weights. Right: A subset of the dyads for the
training samples along with the first 100 Pareto fronts. The fronts are highly non-convex, partially
explaining the superior performance of PDA.

We use two criteria for computing the dissimilarity between trajectories. The first criterion is to
compute the dissimilarity in walking speed. We compute the instantaneous speed at all time steps
along
p each trajectory by finite differencing, i.e. the speed of trajectory T at time step t is given
by (xt ? xt?1 )2 + (yt ? yt?1 )2 . A histogram of speeds for each trajectory is obtained in this
manner. We take the dissimilarity between two trajectories to be the squared Euclidean distance
between their speed histograms. The second criterion is to compute the dissimilarity in shape. For
each trajectory, we select 100 points, uniformly positioned along the trajectory. The dissimilarity
between two trajectories T and T 0 is then given by the sum of squared Euclidean distances between
the positions of T and T 0 over all 100 points.
The training sample for this experiment consists of 500 trajectories, and the test sample consists of
200 trajectories. Table 1(b) shows the performance of PDA as compared to the other algorithms
using 100 uniformly spaced weights for linear combinations. Notice that PDA has higher AUC than
the other methods under all choices of weights for the two criteria. For a more detailed comparison,
the ROC curve for PDA and the attainable region for k-LPE (the region between the ROC curves
corresponding to weights resulting in the best and worst AUCs) is shown in Figure 3 along with
the first 100 Pareto fronts for PDA. k-LPE performs slightly better at low false positive rate when
the best weights are used, but PDA performs better in all other situations, resulting in higher AUC.
Additional discussion on this experiment can be found in Section 4 of the supplementary material.

6

Conclusion

In this paper we proposed a new multi-criteria anomaly detection method. The proposed method
uses Pareto depth analysis to compute the anomaly score of a test sample by examining the Pareto
front depths of dyads corresponding to the test sample. Dyads corresponding to an anomalous
sample tended to be located at deeper fronts compared to dyads corresponding to a nominal sample.
Instead of choosing a specific weighting or performing a grid search on the weights for different
dissimilarity measures, the proposed method can efficiently detect anomalies in a manner that scales
linearly in the number of criteria. We also provided a theorem establishing that the Pareto approach
is asymptotically better than using linear combinations of criteria. Numerical studies validated our
theoretical predictions of PDA?s performance advantages on simulated and real data.
Acknowledgments
We thank Zhaoshi Meng for his assistance in labeling the pedestrian trajectories. We also thank
Daniel DeWoskin for suggesting a fast algorithm for computing Pareto fronts in two criteria. This
work was supported in part by ARO grant W911NF-09-1-0310.
8

References
[1] V. J. Hodge and J. Austin (2004). A survey of outlier detection methodologies. Artificial Intelligence Review 22(2):85?126.
[2] V. Chandola, A. Banerjee, and V. Kumar (2009). Anomaly detection: A survey. ACM Computing Surveys 41(3):1?58.
[3] Y. Jin and B. Sendhoff (2008). Pareto-based multiobjective machine learning: An overview
and case studies. IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications
and Reviews 38(3):397?415.
[4] A. O. Hero III and G. Fleury (2004). Pareto-optimal methods for gene ranking. The Journal of
VLSI Signal Processing 38(3):259?275.
[5] A. Blum and T. Mitchell (1998). Combining labeled and unlabeled data with co-training. In
Proceedings of the 11th Annual Conference on Computational Learning Theory.
[6] V. Sindhwani, P. Niyogi, and M. Belkin (2005). A co-regularization approach to semisupervised learning with multiple views. In Proceedings of the Workshop on Learning with
Multiple Views, 22nd International Conference on Machine Learning.
[7] C. M. Christoudias, R. Urtasun, and T. Darrell (2008). Multi-view learning in the presence of
view disagreement. In Proceedings of the Conference on Uncertainty in Artificial Intelligence.
[8] M. G?onen and E. Alpayd?n (2011). Multiple kernel learning algorithms. Journal of Machine
Learning Research 12(Jul):2211?2268.
[9] S. Byers and A. E. Raftery (1998). Nearest-neighbor clutter removal for estimating features in
spatial point processes. Journal of the American Statistical Association 93(442):577?584.
[10] F. Angiulli and C. Pizzuti (2002). Fast outlier detection in high dimensional spaces. In Proceedings of the 6th European Conference on Principles of Data Mining and Knowledge Discovery.
[11] E. Eskin, A. Arnold, M. Prerau, L. Portnoy, and S. Stolfo (2002). A geometric framework for
unsupervised anomaly detection: Detecting intrusions in unlabeled data. In Applications of
Data Mining in Computer Security. Kluwer: Norwell, MA.
[12] M. M. Breunig, H.-P. Kriegel, R. T. Ng, and J. Sander (2000). LOF: Identifying density-based
local outliers. In Proceedings of the ACM SIGMOD International Conference on Management
of Data.
[13] A. O. Hero III (2006). Geometric entropy minimization (GEM) for anomaly detection and
localization. In Advances in Neural Information Processing Systems 19.
[14] K. Sricharan and A. O. Hero III (2011). Efficient anomaly detection using bipartite k-NN
graphs. In Advances in Neural Information Processing Systems 24.
[15] M. Zhao and V. Saligrama (2009). Anomaly detection with score functions based on nearest
neighbor graphs. In Advances in Neural Information Processing Systems 22.
[16] M. Ehrgott (2000). Multicriteria optimization. Lecture Notes in Economics and Mathematical
Systems 491. Springer-Verlag.
[17] O. Barndorff-Nielsen and M. Sobel (1966). On the distribution of the number of admissible
points in a vector random sample. Theory of Probability and its Applications, 11(2):249?269.
[18] Z.-D. Bai, L. Devroye, H.-K. Hwang, and T.-H. Tsai (2005). Maxima in hypercubes. Random
Structures Algorithms, 27(3):290?309.
[19] Y. Baryshnikov and J. E. Yukich (2005). Maximal points and Gaussian fields. Unpublished.
URL http://www.math.illinois.edu/?ymb/ps/by4.pdf.
[20] B. Majecka (2009). Statistical models of pedestrian behaviour in the Forum. Master?s thesis,
University of Edinburgh.
[21] R. R. Sillito and R. B. Fisher (2008). Semi-supervised learning for anomalous trajectory detection. In Proceedings of the 19th British Machine Vision Conference.

9


----------------------------------------------------------------

title: 3145-geometric-entropy-minimization-gem-for-anomaly-detection-and-localization.pdf

Geometric entropy minimization (GEM) for anomaly
detection and localization
Alfred O Hero, III
University of Michigan
Ann Arbor, MI 48109-2122
hero@umich.edu

Abstract
We introduce a novel adaptive non-parametric anomaly detection approach, called
GEM, that is based on the minimal covering properties of K-point entropic graphs
when constructed on N training samples from a nominal probability distribution. Such graphs have the property that as N ? ? their span recovers the
entropy minimizing set that supports at least ? = K/N (100)% of the mass of the
Lebesgue part of the distribution. When a test sample falls outside of the entropy
minimizing set an anomaly can be declared at a statistical level of significance
? = 1 ? ?. A method for implementing this non-parametric anomaly detector is
proposed that approximates this minimum entropy set by the influence region of a
K-point entropic graph built on the training data. By implementing an incremental
leave-one-out k-nearest neighbor graph on resampled subsets of the training data
GEM can efficiently detect outliers at a given level of significance and compute
their empirical p-values. We illustrate GEM for several simulated and real data
sets in high dimensional feature spaces.

1

Introduction

Anomaly detection and localization are important but notoriously difficult problems. In such problems it is crucial to identify a nominal or baseline feature distribution with respect to which statistically significant deviations can be reliably detected. However, in most applications there is seldom
enough information to specify the nominal density accurately, especially in high dimensional feature spaces for which the baseline shifts over time. In such cases standard methods that involve
estimation of the multivariate feature density from a fixed training sample are inapplicable (high
dimension) or unreliable (shifting baseline). In this paper we propose an adaptive non-parametric
method that is based on a class of entropic graphs [1] called K-point minimal spanning trees [2]
and overcomes the limitations of high dimensional feature spaces and baseline shift. This method
detects outliers by comparing them to the most concentrated subset of points in the training sample.
It follows from [2] that this most concentrated set converges to the minimum entropy set of probability ? as N ? ? and K/N ? ?. Thus we call this approach to anomaly detection the geometric
entropy minimization (GEM) method.
Several approaches to anomaly detection have been previously proposed. Parametric approaches
such as the generalized likelihood ratio test lead to simple and classical algorithms such as the Student t-test for testing deviation of a Gaussian test sample from a nominal mean value and the Fisher
F-test for testing deviation of a Gaussian test sample from a nominal variance. These methods fall
under the statistical nomenclature of the classical slippage problem [3] and have been applied to
detecting abrupt changes in dynamical systems, image segmentation, and general fault detection applications [4]. The main drawback of these algorithms is that they rely on a family of parameterically
defined nominal (no-fault) distributions.

An alternative to parametric methods of anomaly detection are the class of novelty detection algorithms and include the GEM approach described herein. Scholkopf and Smola introduced a kernelbased novelty detection scheme that relies on unsupervised support vector machines (SVM) [5]. The
single class minimax probability machine of Lanckriet etal [6] derives minimax linear decision regions that are robust to unknown anomalous densities. More closely related to our GEM approach is
that of Scott and Nowak [7] who derive multiscale approximations of minimum-volume-sets to estimate a particular level set of the unknown nominal multivariate density from training samples. For a
simple comparative study of several of these methods in the context of detecting network intrusions
the reader is referred to [8].
The GEM method introduced here has several features that are summarized below. (1) Unlike the
MPM method of Lanckriet etal [6] the GEM anomaly detector is not restricted to linear or even
convex decision regions. This translates to higher power for specified false alarm level. (2) GEMs
computational complexity scales linearly in dimension and can be applied to level set estimation
in feature spaces of unprecedented (high) dimensionality. (3) GEM has no complicated tuning parameters or function approximation classes that must be chosen by the user. (4) Like the method
of Scott and Nowak [7] GEM is completely non-parametric, learning the structure of the nominal
distribution without assumptions of linearity, smoothness or continuity of the level set boundaries.
(5) Like Scott and Nowak?s method, GEM is provably optimal - indeed uniformly most powerful
of specified level - for the case that the anomaly density is a mixture of the nominal and a uniform
density. (6) GEM easily adapts to local structure, e.g. changes in local dimensionality of the support
of the nominal density.
We introduce an incremental Leave-one-out (L1O) kNNG as a particularly versatile and fast anomaly detector in the GEM class. Despite the similarity in nomenclature, the L1O kNNG is different
from k nearest neighbor (kNN) anomaly detection of [9]. The kNN anomaly detector is based on
thresholding the distance from the test point to the k-th nearest neighbor. The L1O kNNG detector
computes the change in the topology of the entire kNN graph due to the addition of a test sample and
does not use a decision threshold. Furthermore, the parent GEM anomaly detection methodology
has proven theoretical properties, e.g. the (restricted) optimality property for uniform mixtures and
general consistency properties.
We introduce the statistical framework for anomaly detection in the next section. We then describe
the GEM approach in Section . Several simulations are presented n Section 4.

2

Statistical framework

The setup is the following. Assume that a training sample Xn = {X1 , . . . , Xn } of d-dimensional
vectors Xi is available. Given a new sample X the objective is to declare X to be a ?nominal?
sample consistent with Xn or an ?anomalous? sample that is significantly different from Xn . This
declaration is to be constrained to give as few false positives as possible. To formulate this problem
we adopt the standard statistical framework for testing composite hypotheses. Assume that Xn is
an independent identically distributed (i.i.d.) sample from a multivariate density f0 (x) supported on
the unit d-dimensional cube [0, 1]d . Let X have density f (x). Anomaly detection can be formulated
as testing the hypotheses H0 : f = fo versus H0 : f = fo at a prescribed level ? of significance
P (declare H1 |H0 ) ? ?.
The minimum-volume-set
of level ? is defined as a set ?? in IRd which minimizes the volume

|?? | = ?? dx subject to the constraint ?? f0 (x)dx ? 1 ? ?. The minimum-entropy-set of level

1
ln ?? f ? (x)dx
? is defined as a set ?? in IRd which minimizes the R?enyi entropy H? (?? ) = 1??

subject to the constraint ?? f0 (x)dx ? 1 ? ?. Here ? is any real valued parameter between
0 < ? < 1. When f is a Lebesgue density in IRd it is easy to show that these three sets are identical
almost everywhere.
The test ?decide anomaly if X ? ?? ? is equivalent to implementing the test function


1, x ? ??
.
?(x) =
0,
o.w.
This test has a strong optimality property: when f0 is Lebesgue continuous it is a uniformly most
powerful (UMP) level ? for testing anomalies that follow a uniform mixture distribution. Specif-

ically, let X have density f (x) = (1 ? )f0 (x) + U (x) where U (x) is the uniform density over
[0, 1]d and  ? [0, 1]. Consider testing the hypotheses
H0
H1

:
:

=0
>0

(1)
(2)

Proposition 1 Assume that under H0 the random vector X has a Lebesgue continuous density f0
and that Z = f0 (X) is also a continuous random variable. Then the level-set test of level ? is
uniformly most powerful for testing (2). Furthermore, its power function ? = P (X ? ?? |H1 ) is
given by
? = (1 ? )? + (1 ? |?? |).
A sufficient condition for the random variable Z above to be continuous is that the density f0 (x)
have no flat spots over its support set {f0 (x) > 0}. The proof of this proposition is omitted.
There are two difficulties with implementing the level set test. First, for known f0 the level set
may be very difficult if not impossible to determine in high dimensions d  2. Second, when only
a training sample from f0 is available and f0 is unknown the level sets have to be learned from
the training data. There are many approaches to doing this for minimum volume tests and these
are reviewed in [7]. These methods can be divided into two main approaches: density estimation
followed by plug in estimation of ?? via variational methods; and (2) direct estimation of the level
set using function approximation and non-parametric estimation. Since both approaches involve
explicit approximation of high dimensional quantities, e.g. the multivariate density or the boundary
of the set ??, these methods are difficult to apply in high dimensional problems, i.e. d > 2. The
GEM method we propose in the next section overcomes these difficulties.

3

GEM and entropic graphs

GEM is a method that directly estimates the critical region for detecting anomalies using minimum coverings of subsets of points in a nominal training sample. These coverings are obtained by
constructing minimal graphs, e.g. a MST or kNNG, covering a K-point subset that is a given proportion of the training sample. Points not covered by these K-point minimal graphs are identified
as tail events and allow one to adaptively set a pvalue for the detector.
For a set of n points Xn in IRd a graph G over Xn is a pair (V, E) where V = Xn is the set of vertices
and E = {e} is the set of
edges of the graph. The total power weighted length, or, more simply, the
length, of G is L(Xn ) = e?E |e|? where ? > 0 is a specified edge exponent parameter.
3.1

K-point MST

The MST with power weighting ? is defined as the graph that spans Xn with minimum total length:

|e|? .
LM ST (Xn ) = min
T ?T

e?T

where T is the set of all trees spanning Xn .

n
subsets of K distinct points from Xn .
Definition 1 K-point MST: Let Xn,K denote one of the K
Among all of the MST?s spanning these sets, the K-MST is defined as the one having minimal length
minXn,K ?Xn LM ST (Xn,k ).

The K-MST thus specifies the minimal subset of K points in addition to specifying the minimum
length. This subset of points, which we call a minimal graph covering of Xn of size K, can be viewed
as capturing the densest region of Xn . Furthermore, if Xn is a i.i.d. sample from a multivariate
density f (x) and if limK,n?? K/n = ? and a greedy version of the K-MST is implemented, this
set converges a.s. to the minimum ?-entropy set containing a proportion of at least ? = K/n of
the mass of the (Lebesgue component of) f (x), where ? = (d ? ?)/d. This fact was used in [2] to
motivate the greedy K-MST as an outlier resistant estimator of entropy for finite n, K.
Define the K-point subset
?
Xn,K
= argminXn,K ?Xn LM ST (Xn,K )

selected by the greedy K-MST. Then we have the following As the minimum entropy set and minimum volume set are identical, this suggests the following minimal-volume-set anomaly detection
algorithm, which we call the ?K-MST anomaly detector.?
K-MST anomaly detection algorithm
[1]Process training sample: Given a level of significance ? and a training sample Xn =
?
{X1 , . . . , Xn }, construct the greedy K-MST and retain its vertex set Xn,K
.
[2]Process test sample: Given a test sample X run the K-MST on the merged training-test sample
?
Xn+1 = Xn ? {X} and store the minimal set of points Xn+1,K
.
[3]Make decision: Using the test function ? defined below decide H1 if ?(X) = 1 and decide H0
if ?(X) = 0.

?
1, X ? Xn+1,K
.
?(x) =
0,
o.w.
When the density f0 generating the training sample is Lebesgue continuous, it follows from [2, Theorem 2] that as K, n ? ? the K-MST anomaly detector has false alarm probability that converges
to ? = 1 ? K/n and power that converges to that of the minimum-volume-set test of level ?. When
the density f0 is not Lebesgue continuous some optimality properties of the K-MST anomaly detector still hold. Let this nominal density have the decomposition f0 = ?0 + ?0 , where ?0 is Lebesgue
continuous and ?0 is singular. Then, according to [2, Theorem 2], the K-MST anomaly detector will
have false alarm probability that converges to (1 ? ?)?, where ? is the mass of the singular component of f0 , and it is a uniformly most powerful test for anomalies in the continuous component, i.e.
for the test of H0 : ? = ?0 , ? = ?0 against H1 : ? = (1 ? )?0 + U (x), ? = ?0 .
It is well known that the K-MST construction is of exponential complexity in n [10]. In fact, even
for K = n ? 1, a case one can call the leave-one-out MST, there is no simple fast algorithm
for computation. However, the leave-one-out kNNG, described below, admits a fast incremental
algorithm.
3.2

K-point kNNG

Let Xn = {X1 , . . . , Xn } be a set of n points. The k nearest neighbors (kNN) {Xi(1) , . . . Xi(k) }
of a point Xi ? Xn are the k closest points to Xi points in Xn ? {Xi }. Here the measure of
closeness is the Euclidean distance. Let {ei(1) , . . . , ei(k) } be the set of edges between Xi and its k
nearest neighbors. The kNN graph (kNNG) over Xn is defined as the union of all of the kNN edges
{ei(1) , . . . , ei(k) }ni=1 and the total power weighted edge length of the kNN graph is
LkN N (Xn ) =

n 
k


|ei(l) |? .

i=1 l=1

n
subsets of K distinct points from Xn .
Definition 2 K-point kNNG: Let Xn,K denote one of the K
Among all of the kNNG over each of these sets, the K-kNNG is defined as the one having minimal
length minXn,K ?Xn LkN N (Xn,k ).
As the kNNG length is also a quasi additive continuous functional [11], the asymptotic KMST
theory of [2] extends to the K-point kNNG. Of course, computation of the K-point kNNG also has
exponential complexity. However, the same type of greedy approximation introduced by Ravi [10]
for the K-MST can be implemented to reduce complexity of the K-point kNNG. This approximation
to the K-point kNNG will satisfy the tightly coverable graph property of [2, Defn. 2]. We have the
following result that justifies the use of such an approximation as an anomaly detector of level
? = 1 ? ?, where ? = K/n:
?
Proposition 2 Let Xn,K
be the set of points in Xn that results from any approximation to the K?
point kNNG that satisfies the property [2, Defn. 2]. Then limn?? P0 (Xn,K
? ?? ) ? 1 and
?
limn?? P0 (Xn,K ? ?? ) ? 0, where K = K(n) = ?oor(?n), ?? is a minimum-volume-set of
level ? = 1 ? ? and ?? = [0, 1]d ? ?? .

Proof: We provide a rough sketch using the terminology of [2]. Recall that a set B m ? [0, 1]d
of resolution 1/m is representable by a union of elements of the uniform partition of [0, 1]d into
hypercubes of volume 1/md . Lemma 3 of [2] asserts that there exists an M such that for m > M the
limits claimed in Proposition 2 hold with ?? replaced by Am
? , a minimum volume set of resolution
1/m that contains ?? . As limm?? Am
=
?
this
establishes
the proposition.
?
?
Figures 1-2 illustrate the use of the K-point kNNG as an anomaly detection algorithm.
K?point kNNG, k=5, N=200, ?=0.9, K=180

Bivariate Gaussian mixture density
3

3

2

2

1

1

0

0

?1

?1

?2

?2

?3

?3

?4

?4

?5
?6

?4

?2

0

2

4

?5
?6

?4

?2

0

2

4

Figure 1: Left: level sets of the nominal bivariate mixture density used to illustrate the K point kNNG
anomaly detection algorithms. Right: K-point kNNG over N=200 random training samples drawn
from the nominal bivariate mixture at left. Here k=5 and K=180, corresponding to a significance
level of ? = 0.1.
K?point kNNG, k=5, N=200, ?=0.9, K=180

K?point kNNG, k=5, N=200, ?=0.9, K=180

3

3

2

2

1

1

0

0

?1

?1

?2

?2

?3

?3

?4

?4

?5
?6

?4

?2

0

2

4

?5
?6

?4

?2

0

2

4

Figure 2: Left: The test point ?*? is declared anomalous at level ? = 0.1 as it is not captured by the
K-point kNNG (K=180) constructed over the combined test sample and the training samples drawn
from the nominal bivariate mixture shown in Fig. 1. Right: A different test point ?*? is declared
non-anomalous as it is captured by this K-point kNNG.
3.3

Leave-one-out kNNG (L1O-kNNG)

The theoretical equivalence between the K-point kNNG and the level set anomaly detector motivates
a low complexity anomaly detection scheme, which we call the leave-one-out kNNG, discussed
in this section and adopted for the experiments below. As before, assume a single test sample
X = Xn+1 and a training sample Xn . Fix k and assume that the kNNG over the set Xn has been
computed. To determine the kNNG over the combined sample Xn+1 = Xn ? {Xn+1 } one can
execute the following algorithm:
L1O kNNG anomaly detection algorithm
1. For each Xi ? Xn+1 , i = 1, . . . , n + 1, compute the kNNG total length difference
?i LkN N = LkN N (Xn+1 ) ? LkN N (Xn+1 ? {Xi }) by the following steps. For each
i:

k
(a) Find the k edges Ei??
of all of the kNN?s of Xi .
k
(b) Find the edges E??i of other points in Xn+1 ? {Xi } that have Xi as one of their
kNNs. For these points find the edges E?k+1 to their respective k + 1st NN point.



(c) Compute ?i LkN N = e?E k |e|? + e?E k |e|? ? e?E?k+1 |e|?
i??

??i

2. Define the kNNG most ?outlying point? as Xo = argmaxi=1,...,n+1 ?i LkN N .
3. Declare the test sample Xn+1 an anomaly if Xn+1 = Xo .
This algorithm will detect anomalies with a false alarm level of approximately 1/(n+1). Thus larger
sizes n of the training sample will correspond to more stringent false alarm constraints. Furthermore,
the p-value of each test point Xi is easily computed by recursing over the size n of the training


sample. In particular, let n vary from k to n and define n? as the minimum value of n for which
Xi is declared an anomaly. Then the p-value of Xi is approximately 1/(n? + 1).
A useful relative influence coefficient ? can be defined for each point Xi in the combined sample
Xn+1
?(Xi ) =

?i LkN N
.
maxi ?i LkN N

(3)

The coefficient ?(Xn+1 ) = 1 when the test point Xn+1 is declared an anomaly.
Using matlab?s matrix sort algorithm step 1 of this algorithm can be computed an order of magnitude
faster than the K-point MST (N 2 logN vs N 3 logN ). For example, the experiments below have
shown that the above algorithm can find and determine the p-value of 10 outliers among 1000 test
samples in a few seconds on a Dell 2GHz processor running Matlab 7.1.

4

Illustrative examples

Here we focus on the L1O kNNG algorithm due to its computational speed. We show a few representative experiments for simple Gaussian and Gaussian mixture nominal densities f0 .
L1O kNN scores. rho=0.998, Mmin=500 , detection rate=0.009
iteration 20, pvalue 0.001

1

4

2

2

0

0

0

?2

?2

?2

?4

?4

?4

?6
?4

0.6

iteration 246, pvalue 0.001

4

2

?2

0

2

4

6

?6
?4

?2

0

2

4

6

?6
?4

?2

0

2

4

6

n

i

i

score = ? /max (? )

0.8

iteration 203, pvalue 0.001

4

iteration 294, pvalue 0.001443

iteration 307, pvalue 0.001

4

0.4

2

0.2

2

2

0

0

0

?2

?2

?4

?4

?4

0

2

4

6

?6
?4

iteration 574, pvalue 0.001

?2

0

2

4

6

?6
?2

iteration 712, pvalue 0.0011614

4

0

2

4

6

iteration 791, pvalue 0.0011682

4

2

?0.2

4

?2

?6
?2

0

iteration 334, pvalue 0.001

4

4
2

2

0

0
0

?2

?0.4

?2
?2

?4

100

200

300

400
500
600
sample number

700

800

900

1000

?6
?5

0

5

?4
?2

?4

0

2

4

6

?6
?2

0

2

4

6

Figure 3: Left: The plot of the anomaly curve for the L1O kNNG anomaly detector for detecting
deviations from a nominal 2D Gaussian density with mean (0,0) and correlation coefficient -0.5.
The boxes on peaks of curve correspond to positions of detected anomalies and the height of the
boxes are equal to one minus the computed p-value. Anomalies were generated (on the average)
every 100 samples and drawn from a 2D Gaussian with correlation coefficient 0.8. The parameter
? is equal to 1 ? ?, where ? is the user defined false alarm rate. Right: the resampled nominal
distribution (???) and anomalous points detected (?*?) at the iterations indicated at left.
First we illustrate the L1O kNNG algorithm for detection of non-uniformly distributed anomalies
from training samples following a bivariate Gaussian nominal density. Specifically, a 2D Gaussian
density with mean (0,0) and correlation coefficient -0.5 was generated to train of the L1O kNNG
detector. The test sample consisted of a mixture of this nominal and a zero mean 2D Gaussian with
correlation coefficient 0.8 with mixture coefficient  = 0.01. In Fig. 3 the results of simulation with
a training sample of 2000 samples and 1000 tests samples are shown. Fig. 3 is a plot of the relative

influence curve (3) over the test samples as compared to the most outlying point in the (resampled)
training sample. When the relative influence curve is equal to 1 the corresponding test sample is the
most outlying point and is declared an anomaly. The 9 detected anomalies in Fig. 3 have p-values
less than 0.001 and therefore one would expect an average of only one false alarm at this level of
significance. In the right panel of Fig. 3 the detected anomalies (asterisks) are shown along with the
training sample (dots) used to grow the L1O kNNG for that particular iteration - note that to protect
against bias the training sample is resampled at each iteration.
Next we compare the performance of the L1O kNNG detector to that of the UMP test for the
hypotheses (2). We again trained on a bivariate Gaussian f0 with mean zero, but this time with
identical component variances of ? = 0.1. This distribution has essential support on the unit
square. For this?simple case the minimum volume set of level ? is a disk centered at the origin with radius 2? 2 ln 1/? and the power of the of the UMP can be computed in closed form:
? = (1 ? )? + (1 ? 2?? 2 ln 1/?). We implemented the GEM anomaly detector with the incremental leave-one-out kNNG using k = 5. The training set consisted of 1000 samples from f0 and
the test set consisted of 1000 samples from the mixture of a uniform density and f0 with parameter
 ranging from 0 to 0.2. Figure 4 shows the empirical ROC curves obtained using the GEM test vs
the theoretical curves (labeled ?clairvoyant?) for several different values of the mixing parameter.
Note the good agreement between theoretical prediction and the GEM implementation of the UMP
using the kNNG.
ROC curves for Gaussian+uniform mixture. k=5, N=1000, Nrep=10
0.5
L1O?kNN
Clairvoyant
?=0.5

0.45

0.4

0.35
?=0.3

?

0.3

0.25

0.2
?=0.1

0.15

0.1

?=0

0.05

0

0

0.01

0.02

0.03

0.04

0.05
?

0.06

0.07

0.08

0.09

0.1

Figure 4: ROC curves for the leave-one-out kNNG anomaly detector described in Sec. 3.3. The
labeled ?clairvoyant? curve is the ROC of the UMP anomaly detector. The training sample is a zero
mean 2D spherical Gaussian distribution with standard deviation 0.1 and the test sample is a this
2D Gaussian and a 2D uniform-[0, 1]2 mixture density. The plot is for various values of the mixture
parameter .

5

Conclusions

A new and versatile anomaly detection method has been introduced that uses geometric entropy
minimization (GEM) to extract minimal set coverings that can be used to detect anomalies from a
set of training samples. This method can be implemented through the K-point minimal spanning tree
(MST) or the K-point nearest neighbor graph (kNNG). The L1O kNNG is significantly less computationally demanding than the K-point MST. We illustrated the L1O kNNG method on simulated
data containing anomalies and showed that it comes close to achieving the optimal performance of
the UMP detector for testing the nominal against a uniform mixture with unknown mixing parameter. As the L1O kNNG computes p-values on detected anomalies it can be easily extended to
account for false discovery rate constraints. By using a sliding window, the methodology derived in
this paper is easily extendible to on-line applications and has been applied to non-parametric intruder
detection using our Crossbow sensor network testbed (reported elsewhere).

Acknowledgments
This work was partially supported by NSF under Collaborative ITR grant CCR-0325571.

References
[1] A. Hero, B. Ma, O. Michel, and J. Gorman, ?Applications of entropic spanning graphs,? IEEE Signal Processing Magazine, vol. 19, pp. 85?95, Sept. 2002.
www.eecs.umich.edu/?hero/imag_proc.html.
[2] A. Hero and O. Michel, ?Asymptotic theory of greedy approximations to minimal k-point
random graphs,? IEEE Trans. on Inform. Theory, vol. IT-45, no. 6, pp. 1921?1939, Sept. 1999.
[3] T. S. Ferguson, Mathematical Statistics - A Decision Theoretic Approach. Academic Press,
Orlando FL, 1967.
[4] I. V. Nikiforov and M. Basseville, Detection of abrupt changes: theory and applications.
Prentice-Hall, Englewood-Cliffs, NJ, 1993.
[5] B. Scholkopf, R. Williamson, A. Smola, J. Shawe-Taylor, and J. Platt, ?Support vector method
for novelty detection,? in Advances in Neural Information Processing Systems (NIPS), vol. 13,
2000.
[6] G. R. G. Lanckriet, L. El Ghaoui, and M. I. Jordan, ?Robust novelty detection with single-class
mpm,? in Advances in Neural Information Processing Systems (NIPS), vol. 15, 2002.
[7] C. Scott and R. Nowak, ?Learning minimum volume sets,? Journal of Machine Learning Research, vol. 7, pp. 665?704, April 2006.
[8] A. Lazarevic, A. Ozgur, L. Ertoz, J. Srivastava, and V. Kumar, ?A comparative study of anomaly detection schemes in network intrusion detection,? in SIAM Conference on data mining,
2003.
[9] S. Ramaswamy, R. Rastogi, and K. Shim, ?Efficient algorithms for mining outliers from large
data sets,? in Proceedings of the ACM SIGMOD Conference, 2000.
[10] R. Ravi, M. Marathe, D. Rosenkrantz, and S. Ravi, ?Spanning trees short or small,? in Proc. 5th
Annual ACM-SIAM Symposium on Discrete Algorithms, (Arlington, VA), pp. 546?555, 1994.
[11] J. E. Yukich, Probability theory of classical Euclidean optimization, vol. 1675 of Lecture Notes
in Mathematics. Springer-Verlag, Berlin, 1998.


----------------------------------------------------------------

title: 4287-efficient-anomaly-detection-using-bipartite-k-nn-graphs.pdf

Efficient anomaly detection using
bipartite k-NN graphs
Kumar Sricharan
Department of EECS
University of Michigan
Ann Arbor, MI 48104
kksreddy@umich.edu

Alfred O. Hero III
Department of EECS
University of Michigan
Ann Arbor, MI 48104
hero@umich.edu

Abstract
Learning minimum volume sets of an underlying nominal distribution is a very effective approach to anomaly detection. Several approaches to learning minimum
volume sets have been proposed in the literature, including the K-point nearest
neighbor graph (K-kNNG) algorithm based on the geometric entropy minimization (GEM) principle [4]. The K-kNNG detector, while possessing several desirable characteristics, suffers from high computation complexity, and in [4] a
simpler heuristic approximation, the leave-one-out kNNG (L1O-kNNG) was proposed. In this paper, we propose a novel bipartite k-nearest neighbor graph (BPkNNG) anomaly detection scheme for estimating minimum volume sets. Our
bipartite estimator retains all the desirable theoretical properties of the K-kNNG,
while being computationally simpler than the K-kNNG and the surrogate L1OkNNG detectors. We show that BP-kNNG is asymptotically consistent in recovering the p-value of each test point. Experimental results are given that illustrate
the superior performance of BP-kNNG as compared to the L1O-kNNG and other
state of the art anomaly detection schemes.

1 Introduction
Given a training set of normal events, the anomaly detection problem aims to identify unknown,
anomalous events that deviate from the normal set. This novelty detection problem arises in applications where failure to detect anomalous activity could lead to catastrophic outcomes, for example,
detection of faults in mission-critical systems, quality control in manufacturing and medical diagnosis.
Several approaches have been proposed for anomaly detection. One class of algorithms assumes a
family of parametrically defined nominal distributions. Examples include Hotelling?s T test and the
Fisher F-test, which are both based on a Gaussian distribution assumption. The drawback of these
algorithms is model mismatch: the supposed distribution need not be a correct representation of the
nominal data, which can then lead to poor false alarm rates. More recently, several non-parametric
methods based on minimum volume (MV) set estimation have been proposed. These methods aim to
find the minimum volume set that recovers a certain probability mass ? with respect to the unknown
probability density of the nominal events. If a new event falls within the MV set, it is classified as
normal and otherwise as anomalous.
Estimation of minimum volume sets is a difficult problem, especially for high dimensional data.
There are two types of approaches to this problem: (1) transform the MV estimation problem to an
equivalent density level set estimation problem, which requires estimation of the nominal density;
and (2) directly identify the minimal set using function approximation and non-parametric estimation [10, 6, 9]. Both types of approaches involve explicit approximation of high dimensional quant1

ities - the multivariate density function in the first case and the boundary of the minimum volume
set in the second and are therefore not easily applied to high dimensional problems.
The GEM principle developed by Hero [4] for determining MV sets circumvents the above difficulties by using the asymptotic theory of random Euclidean graphs instead of function approximation. However, the GEM based K-kNNG anomaly detection scheme proposed in [4] is computationally difficult. To address this issue, a surrogate L1O-kNNG anomaly detection scheme was proposed
in [4]. L1O-kNNG is computationally simpler than K-kNNG, but loses some desirable properties of
the K-kNNG, including asymptotic consistency, as shown below.
In this paper, we use the GEM principle to develop a bipartite k-nearest neighbor (k-NN) graphbased anomaly detection algorithm. BP-kNNG retains the desirable properties of the GEM principle
and as a result inherits the following features: (i) it is not restricted to linear or even convex decision
regions, (ii) it is completely non-parametric, (iii) it is optimal in that it converges to the uniformly
most powerful (UMP) test when the anomalies are drawn from a mixture of the nominal density and
the uniform density, (iv) it does not require knowledge of anomalies in the training sample, (v) it is
asymptotically consistent in recovering the p-value of the test point and (vi) it produces estimated
p-values, allowing for false positive rate control.
K-LPE [13] and RRS [7] are anomaly detection methods which are also based on k-NN graphs. BPkNNG differs from L1O-kNNG, K-LPE and RRS in the following respects. L1O-kNNG, K-LPE
and RRS do not use bipartite graphs. We will show that the bipartite nature of BP-kNNG results
in significant computational savings. In addition, the K-LPE and RRS test statistics involve only
the k-th nearest neighbor distance, while the statistic in BP-kNNG, like the L1O-kNNG, involves
summation of the power weighted distance of all the edges in the k-NN graph. This will result
in increased robustness to outliers in the training sample. Finally, we will show that the mean
square rate of convergence of p-values in BP-kNNG (O(T ?2/(2+d) )) is faster as compared to the
convergence rate of K-LPE (O(T ?2/5 +T ?6/5d )), where T is the size of the nominal training sample
and d is the dimension of the data.
The rest of this paper is organized as follows. In Section 2, we outline the statistical framework
for minimum volume set anomaly detection. In Section 3, we describe the GEM principle and the
K-kNNG and L1O-kNNG anomaly detection schemes proposed in [4]. Next, in Section 4, we
develop our bipartite k-NN graph (BP-kNNG) method for anomaly detection. We show consistency
of the method and compare its computational complexity with that of the K-kNNG, L1O-kNNG and
K-LPE algorithms. In Section 5, we show simulation results that illustrate the superior performance
of BP-kNNG over L1O-kNNG. We also show that our method compares favorably to other state of
the art anomaly detection schemes when applied to real world data from the UCI repository [1]. We
conclude with a short discussion in Section 6.

2 Statistical novelty detection
The problem setup is as follows. We assume that a training sample X T = {X1 , . . . , XT } of ddimensional vectors is available. Given a new sample X, the objective is to declare X to either be
a ?nominal? event consistent with X T or an ?anomalous? event which deviates from X T . We seek to
find a functional D and corresponding detection rule D(x) > 0 so that X is declared to be nominal if
D(x) > 0 holds and anomalous otherwise. The acceptance region is given by A = {x : D(x) > 0}.
We seek to further constrain the choice of D to allow as few false negatives as possible for a fixed
allowance of false positives.
To formulate this problem, we adopt the standard statistical framework for testing composite hypotheses. We assume that the training sample X T is an i.i.d sample draw from an unknown ddimensional probability distribution f 0 (x) on [0, 1]d . Let X have density f on [0, 1] d . The anomaly
detection problem can be formulated as testing the hypotheses H 0 : f = f0 versus H1 : f = f0 .
For a given ? ? (0, 1), we seek an acceptance region A that satisfies P r(X ? A|H 0 ) ? 1 ? ?.
This
requirement maintains the false positive rate at a level no greater than ?. Let A = {A :

f
(x)dx ? 1 ? ?} denote the collection of acceptance regions of level ?. The most suitable
0
A
acceptance region from the collection A would be the set which minimizes the false negative rate.
Assume that the density f is bounded above by some constant C. In this case the false negative rate
is bounded by C?(A) where ?(.) is the Lebesgue measure in R d . Consider the relaxed problem of
2

minimizing the upper bound C?(A) or equivalently the volume ?(A) of A. The optimal acceptance
region with a maximum
 false alarm rate ? is therefore given by the minimum volume set of level ?:
?? = min{?(A) : A f0 (x)dx ? ?}.

Define the minimum entropy
set of level ? to be ? ? = min{H? (A) : A f0 (x)dx ? 1 ? ?} where

H? (A) = (1 ? ?)?1 A f0? (x)dx is the R?enyi ?-entropy of the density f 0 over the set A. It can be
shown that when f 0 is a Lebesgue density in R d , the minimum volume set and the minimum entropy
set are equivalent, i.e. ? ? and ?? are identical. Therefore, the optimal decision rule for a given level
of false alarm ? is to declare an anomaly if X ?
/ ? ?.
This decision rule has a strong optimality property [4]: when f 0 is Lebesgue continuous and has
no ?flat? regions over its support, this decision rule is a uniformly most powerful (UMP) test at level
1 ? ? for the null hypothesis that the test point has density f (x) equal to the nominal f 0 (x) versus
the alternative hypothesis that f (x) = (1 ? )f 0 (x) + U (x), where U (x) is the uniform density
over [0, 1]d and  ? [0, 1]. Furthermore, the power function is given by ? = P r(X ?
/ ? ? |H1 ) =
(1 ? )? + (1 ? ?(?? )).

3 GEM principle
In this section, we briefly review the geometric entropy minimization (GEM) principle method [4]
for determining minimum entropy sets ? ? of level ?. The GEM method directly estimates the critical region ?? for detecting anomalies using minimum coverings of subsets of points in a nominal
training sample. These coverings are obtained by constructing minimal graphs, e.g., the k-minimal
spanning tree or the k-nearest neighbor graph, covering a K-point subset that is a given proportion
of the training sample. Points in the training sample that are not covered by the K-point minimal
graphs are identified as tail events.
T 
In particular, let X K,T denote one of the K
K point subsets of XT . The k-nearest neighbors
(k-NN) of a point X i ? XK,T are the k closest points to X i among XK,T ? Xi . Denote the
corresponding set of edges between X i and its k-NN by {e i(1) , . . . , ei(k) }. For any subset XK,T ,
define the total power weighted edge length of the k-NN graph on X K,T with power weighting ?
(0 < ? < d), as
K 
k

LkN N (XK,T ) =
|eti (l) |? ,
i=1 l=1

where {t1 , . . . , tK } are the indices of X i ? XK,T . Define the K-kNNG
to be the K-point
 T graph

k-NN graph having minimal length min XT ,K ?XT LkN N (XT,K ) over all K subsets XK,T . Denote
?
= argmin LkN N (XK,T ).
the corresponding length minimizing subset of K points by X T,K
XT ,K ?X

?
minimal graph covering X K,T

of size K. This graph can be viewed as
The K-kNNG thus specifies a
capturing the densest regions of X T . If XT is an i.i.d. sample from a multivariate density f 0 (x) and
?
converges a.s. to the minimum ?-entropy set containing
if limK,T ?? K/T = ?, then the set XK,T
a proportion of at least ? of the mass of f 0 (x), where ? = 1 ? ?/d [4]. This set can be used to
perform anomaly detection.
3.1 K-kNNG anomaly detection
Given a test sample X, denote the pooled sample X T +1 = XT ? {X} and determine the K-kNNG
?
/ X K,T
graph over X T +1 . Declare X to be an anomaly if X ?
+1 and nominal otherwise. When the
density f0 is Lebesgue continuous, it follows from [4] that as K, T ? ?, this anomaly detection
algorithm has false alarm rate that converges to ? = 1 ? K/T and power that converges to that of
the minimum volume set test of level ?. An identical detection scheme based on the K-minimal
spanning tree has also been developed in [4].
The K-kNNG anomaly detection scheme therefore offers a direct approach to detecting outliers
while bypassing the more difficult problems of density estimation and level set estimation in high dimensions. However, this
 T algorithm requires construction of k-nearest neighbor graphs (or k-minimal
spanning trees) over K
different subsets. For each input test point, the runtime of this algorithm
3

T 
). As a result, the K-kNNG method is not well suited for anomaly detection
is therefore O(dK 2 K
for large sample sizes.
3.2 L1O-kNNG
To address the computational problems of K-kNNG, Hero [4] proposed implementing the K-kNNG
for the simplest case K = T ? 1. The runtime of this algorithm for each input test point is O(dT 2 ).
Clearly, the L1O-kNNG is of much lower complexity that the K-kNNG scheme. However, the L1OkNNG detects anomalies at a fixed false alarm rate 1/(T + 1), where T is the training sample size.
To detect anomalies at a higher false alarm rate ? ? , one would have to subsample the training set
and only use T ? = 1/?? ? 1 training samples. This destroys any hope for asymptotic consistency
of the L1O-kNNG.
In the next section, we propose a different GEM based algorithm that uses bipartite graphs. The
algorithm has algorithm has a much faster runtime than the L1O-kNNG, and unlike the L1O-kNNG,
is asymptotically consistent and can operate at any specified alarm rate ?. We describe our algorithm
below.

4 BP-kNNG
Let {XN , XM } be a partition of X T with card{XN } =
 N and card{XM } = M = T ? N
N
respectively. As above, let X K,N denote one of the K subsets of K distinct points from X N .
Define the bipartite k-NN graph on {X K,N , XM } to be the set of edges linking each X i ? XK,N
to its k nearest neighbors in X M . Define the total power weighted edge length of this bipartite
k-NN graph with power weighting ? (0 < ? < d) and a fixed number of edges s (1 ? s ? k)
corresponding to each vertex X i ? XK,N to be
Ls,k (XK,N , XM ) =

K


k


|eti (l) |? ,

i=1 l=k?s+1

where {t1 , . . . , tK } are the indices of X i ? XK,N and {eti (1) , . . . , eti (k) } are the k-NN edges in
the bipartite graph originating from X ti ? XK,N . Define the bipartite K-kNNG graph to be the one
 
having minimal weighted length min XN,K ?XN Ls,k (XN,K , XM ) over all N
K subsets XK,N . Define
?
= argmin Ls,k (XK,N , XM ).
the corresponding minimizing subset of K points of X K,N by XK,N
XK,N ?X

Using the theory of partitioned k-NN graph entropy estimators [11], it follows that as k/M ?
?
0, k, N ? ? and for fixed s, the set X K,N
converges a.s. to the minimum ?-entropy set ? 1??
containing a proportion of at least ? of the mass of f 0 (x), where ? = limK,N ?? K/N and ? =
1 ? ?/d.
This suggests using the bipartite k-NN graph to detect anomalies in the following way. Given a
test point X, denote the pooled sample X N +1 = XN ? {X} and determine the optimal bipartite
?
?
/ X K,N
K-kNNG graph X K,N
+1 over {XK,N +1 , XM }. Now declare X to be an anomaly if X ?
+1
and nominal otherwise. It is clear that by the GEM principle, this algorithm detects false alarms at
a rate that converges to ? = 1 ? K/T and power that converges to that of the minimum volume set
test of level ?.
?
We can equivalently determine X K,N
+1 as follows. For each X i ? XN , construct ds,k (Xi ) =
k
k
?
?
|e
|
.
For
each
test
point
X, define d s,k (X) =
l=k?s+1 i(l)
l=s?k+1 |eX(l) | , where
{eX(1) , . . . , eX(k) } are the k-NN edges from X to X M . Now, choose the K points among X N ? X
with the K smallest of the N + 1 edge lengths {d s,k (Xi ), Xi ? XN } ? {ds,k (X)}. Because of
?
the bipartite nature of the construction, this is equivalent to choosing X K,N
+1 . This leads to the
proposed BP-kNNG anomaly detection algorithm described by Algorithm 1.

4.1 BP-kNNG p-value estimates
The p-value is a score between 0 and 1 that is associated with the likelihood that a given point X 0
comes from a specified nominal distribution. The BP-kNNG generates an estimate of the p-value
4

Algorithm 1 Anomaly detection scheme using bipartite k-NN graphs
1. Input: Training samples X T , test samples X, false alarm rate ?
2. Training phase
a. Create partition {XN , XM }
b. Construct k-NN bipartite graph on partition
k
c. Compute k-NN lengths d s,k (Xi ) for each Xi ? XN : ds,k (Xi ) = l=k?s+1 |ei(l) |?
3. Test phase: detect anomalous points
for each input test sample X do
k
Compute k-NN length d s,k (X) = l=k?s+1 |eX(l) |?
if

(1/N )
1(ds,k (Xi ) < ds,k (X)) ? 1 ? ?
Xi ?XN

then
Declare X to be anomalous
else
Declare X to be non-anomalous
end if
end for
that is asymptotically consistent, guaranteeing that the BP-kNNG detector is a consistent novelty
detector.
Specifically, for a given test point X 0 , the
 true p-value associated with a point X 0 in a minimum
volume set test is given by p true (X0 ) = S(X0 ) f0 (z)dz where S(X0 ) = {z : f0 (z) ? f0 (X0 )} and
E(X0 ) = {z : f0 (z) = f0 (X0 )}. ptrue (X0 ) is the minimal level ? at which X 0 would be rejected.
The empirical p-value associated with the BP-kNNG is defined as

Xi ?XN 1(ds,k (Xi ) ? ds,k (X0 ))
pbp (X0 ) =
.
(1)
N
4.2 Asymptotic consistency and optimal convergence rates
Here we prove that the BP-kNNG detector is asymptotically consistent by showing that for a fixed
number of edges s, E[(p bp (X0 ) ? ptrue (X0 ))2 ] ? 0 as k/M ? 0, k, N ? ?. In the process,
we also obtain rates of convergence of this mean-squared error. These rates depend on k, N and M
and result in the specification of an optimal number of neighbors k and an optimal partition ratio
N/M that achieve the best trade-off between bias and variance of the p-value estimates p bp (X0 ).
We assume that the density f 0 (i) is bounded away from 0 and ? and is continuous on its support
S, (ii) has no flat spots over its support set and (iii) has a finite number of modes. Let E denote the
expectation w.r.t. the density f 0 , and B, V denote the bias and variance operators. Throughout this
section, assume without loss of generality that {X 1 , . . . , XN } ? XN and {XN +1 , . . . , XT } ? XM .

Bias: We first introduce the oracle p-value p orac (X0 ) = (1/N ) Xi ?XN 1(f0 (Xi ) ? f0 (X0 ))
and note that E[p orac (X0 )] = ptrue (X0 ). The distance ei(l) of a point X i ? XN to its l-th
nearest neighbor in X M is related to the bipartite l-nearest neighbor density estimate f?l (Xi ) =
(l ? 1)/(M cd edi(l) ) (section 2.3, [11]) where c d is the unit ball volume in d dimensions. Let
 k
	??1 

 k ? 1
f?l (X)
? s(f (X))??1
e(X) =
l?1
l=k?s+1

and

?(Xi , X0 ) = ?i = (f (Xi ))??1 ? (f (X0 ))??1 .

We then have
B[pbp (X0 )]

= E[pbp (X0 )] ? ptrue (X0 ) = E[pbp (X0 ) ? porac(X0 )]
= E[1(ds,k (X1 ) ? ds,k (X0 ))] ? E[1(f (X1 ) ? f (X0 ))]
= E[1(e(X1 ) ? e(X0 ) + ?1 ? 0) ? 1(?1 ? 0)].
5

This bias will be non-zero when 1(e(X 1 ) ? e(X0 ) + ?1 ? 0) = 1(?1 ? 0). First we investigate
this condition when ? 1 > 0. In this case, for 1(e(X 1 ) ? e(X0 ) + ?1 ? 0) = 1(?1 ? 0), we need
?e(X1 ) + e(X0 ) ? ?1 . Likewise, when ?1 ? 0, 1(e(X1 ) ? e(X0 ) + ?1 ? 0) = 1(?1 ? 0) occurs
when e(X1 ) ? e(X0 ) > |?1 |.
?
From the theory developed in [11], for any fixed s, |e(X)| = O(k/M ) 1/d + O(1/ k) with probability greater than 1 ? o(1/M ). This implies that
B[pbp (X0 )]

= E[1(e(X1 ) ? e(X0 ) + ?1 ? 0) ? 1(?1 ? 0)]
?
?
= P r{|?1 | = O((k/M )1/d + 1/ k)} + o(1/M ) = O((k/M )1/d + 1/ k), (2)

where the last step follows from our assumption that the density f 0 is continuous and has a finite
number of modes.
Variance: Define b i = 1(e(Xi ) ? e(X0 ) + ?i ? 0) ? 1(?i ? 0). We can compute the variance
in a similar manner to the bias as follows (for additional details, please refer to the supplementary
material):
V[pbp (X0 )] =
=

1
N ?1
V[1(e(X1 ) ? e(X0 ) + ?1 ? 0)] +
Cov[b1 , b2 ]
N
N
O(1/N ) + E[b1 b2 ] ? (E[b1 ]E[b2 ]) = O(1/N + (k/M )2/d + 1/k).

(3)

Consistency of p-values: From (2) and (3), we obtain an asymptotic representation of the estimated p-value E[(p bp (X0 ) ? ptrue (X0 ))2 ] = O((k/M )2/d ) + O(1/k) + O(1/N ). This implies that
pbp converges in mean square to p true , for a fixed number of edges s, as k/M ? 0, k, N ? ?.
Optimal choice of parameters: The optimal choice of k to minimize the MSE is given by k =
?(M 2/(2+d) ). For fixed M + N = T , to minimize MSE, N should then be chosen to be of the
order O(M (4+d)/(4+2d) ), which implies that M = ?(T ). The mean square convergence rate for
this optimal choice of k and partition ratio N/M is given by O(T ?2/(2+d) ). In comparison, the
K-LPE method requires that k grows with the sample size at rate k = ?(T 2/5 ). The mean square
rate of convergence of the p-values in K-LPE is then given by O(T ?2/5 + T ?6/5d ). The rate of
convergence of the p-values is therefore faster in the case of BP-kNNG as compared to K-LPE.
4.3 Comparison of run time complexity
Here we compare complexity of BP-kNNG with that ofK-kNNG,
L1O-kNNG and K-LPE. For a

T
single query point X, the runtime of K-kNNG is O(dK 2 K
), while the complexity of the surrogate
L1O-kNN algorithm and the K-LPE is O(dT 2 ). On the other hand, the complexity of the proposed
BP-kNNG algorithm is dominated by the computation of d k (Xi ) for each Xi ? XN and dk (X),
which is O(dN M ) = O(dT (8+3d)/(4+2d) ) = o(dT 2 ).
For the K-kNNG, L1O-kNNG and K-LPE, a new k-NN graph has to be constructed on {X N ?{X}}
for every new query point X. On the other hand, because of the bipartite construction of our k-NN
graph, dk (Xi ) for each Xi ? XN needs to be computed and stored only once. For every new query
X that comes in, the cost to compute d k (X) is only O(dM ) = O(dT ). For a total of L query points,
the overall runtime complexity of our algorithm is therefore much smaller than the L1O-kNNG, K(4+d)/(4+2d)
LPE and K-kNNG anomaly
+ L)) compared to O(dLT 2 ),
 detection schemes (O(dT (T
2
2 T
O(dLT ) and O(dLK K ) respectively).

5 Simulation comparisons
We compare the L1O-kNNG and the bipartite K-kNNG schemes on a simulated data set. The
training set contains 1000 realizations drawn from a 2-dimensional Gaussian density f 0 with mean
0 and diagonal covariance with identical component variances of ? = 0.1. The test set contains 500
realizations drawn from 0.8f 0 + 0.2U , where U is the uniform density on [0, 1] 2 . Samples from the
uniform distribution are classified to be anomalies. The percentage of anomalies in the test set is
therefore 20%.
6

0.16

0.98

0.14
0.97
0.12
0.1
Observed

True positive rate

0.96
0.95
0.94

0.08
0.06

0.93

0.04
BP?kNNG
L10?kNNG
Clairvoyant

0.92
0.91
0

0.02

0.04

0.06
0.08
0.1
False positive rate

0.12

0.14

0.02
0
0

0.16

BP?kNNG
L10?kNNG
0.02

0.04

0.06

0.08
Desired

0.1

0.12

0.14

0.16

(a) ROC curves for L1O-kNNG and BP-kNNG. (b) Comparison of observed false alarm rates for
The labeled ?clairvoyant? curve is the ROC of the L1O-kNNG and BP-kNNG with the desired false
UMP anomaly detector..
alarm rates.

Figure 1: Comparison of performance of L1O-kNNG and BP-kNNG.
Data set
HTTP (KDD?99)
Forest
Mulcross
SMTP (KDD?99)
Shuttle

Sample size
567497
286048
262144
95156
49097

Dimension
3
10
4
3
9

Anomaly class
attack (0.4%)
class 4 vs class 2 (0.9%)
2 clusters (10%)
attack (0.03%)
class 2,3,5,6,7 vs class 1 (7%)

Table 1: Description of data used in anomaly detection experiments.
The distribution f 0 has essential support on the unit square. For
? this simple case the minimum
volume set of level ? is a disk centered at the origin with radius 2? 2 log(1/?). The power of the
uniformly most powerful (UMP) test is 1 ? 2?? 2 log(1/?).
L1O-kNNG and BP-kNNG were implemented in Matlab 7.6 on an 2 GHz Intel processor with
3 GB of RAM. The value of k was set to 5. For the BP-kNNG, we set s = 1, N = 100 and
M = 900. In Fig. 1(a), we compare the detection performance of L1O-kNNG and BP-kNNG
against the ?clairvoyant? UMP detector in terms of the ROC. We note that the proposed BP-kNNG
is closer to the optimal UMP test as compared to the L1O-kNNG. In Fig. 1(b) we note the close
agreement between desired and observed false alarm rates for BP-kNNG. Note that the L1O-kNNG
significantly underestimates its false alarm rate for higher levels of true false alarm. In the case
of the L1O-kNNG, it took an average of 60ms to test each instance for possible anomaly. The
total run-time was therefore 60x500 = 3000ms. For the BP-kNNG, for a single instance, it took an
average of 57ms. When all the instances were processed together, the total run time was only 97ms.
This significant savings in runtime is due to the fact that the bipartite graph does not have to be
constructed separately for each new test instance; it suffices to construct it once on the entire data
set.
5.1 Experimental comparisons
In this section, we compare our algorithm to several other state of the art anomaly detection algorithms, namely: MassAD [12], isolation forest (or iForest) [5], two distance-based methods
ORCA [2] and K-LPE [13], a density-based method LOF [3], and the one-class support vector
machine (or 1-SVM) [9]. All the methods are tested on the five largest data sets used in [5]. The
data characteristics are summarized in Table 1. One of the anomaly data generators is Mulcross [8]
and the other four are from the UCI repository [1]. Full details about the data can be found in [5].
The comparison performance is evaluated in terms of averaged AUC (area under ROC curve) and
processing time (a total of training and test time). Results for BP-kNNG are compared with results
for L1O-kNNG, K-LPE, MassAD, iForest and ORCA in Table 2. The results for MassAD, iForest
and ORCA are reproduced from [12]. MassAD and iForest were implemented in Matlab and tested
on an AMD Opteron machine with a 1.8 GHz processor and 4 GB memory. The results for ORCA,
7

Data sets
HTTP
Forest
Mulcross
SMTP
Shuttle

BP
0.99
0.86
1.00
0.90
0.99

L10
NA
NA
NA
NA
NA

K-LPE
NA
NA
NA
NA
NA

AUC
Mass
1.00
0.91
0.99
0.86
0.99

iF
1.00
0.87
0.96
0.88
1.00

ORCA
0.36
0.83
0.33
0.87
0.60

BP
3.81
7.54
4.68
0.74
1.54

L10
.10/i
.18/i
.26/i
.11/i
.45/i

Time (secs)
K-LPE
Mass
.19/i
34
.18/i
18
.17/i
17
.17/i
7
.16/i
4

iF
147
79
75
26
15

ORCA
9487
6995
2512
267
157

Table 2: Comparison of anomaly detection schemes in terms of AUC and run-time for BP-kNNG
(BP) against L1O-kNNG (L10), K-LPE, MassAD (Mass), iForest (iF) and ORCA. When reporting
results for L1O-kNNG and K-LPE, we report the processing time per test instance (/i). We are
unable to report the AUC for K-LPE and L1O-kNNG because of the large processing time. We note
that BP-kNNG compares favorably in terms of AUC while also requiring the least run-time.
Data sets
HTTP (KDD?99)
Forest
Mulcross
SMTP (KDD?99)
Shuttle

0.01
0.007
0.009
0.008
0.006
0.026

Desired false alarm
0.02
0.05
0.1
0.015 0.063 0.136
0.015 0.035 0.071
0.014 0.040 0.096
0.017 0.046 0.099
0.030 0.045 0.079

0.2
0.216
0.150
0.186
0.204
0.179

Table 3: Comparison of desired and observed false alarm rates for BP-kNNG. There is good agreement between the desired and observed rates.
LOF and 1-SVM were conducted using the same experimental setting but on a faster 2.3 GHz
machine. We exclude the results for LOF and 1-SVM in table 2 because MassAD, iForest and
ORCA have been shown to outperform LOF and 1-SVM in [12].
We implemented BP-kNNG, L1O-kNNG and K-LPE in Matlab on an Intel 2 GHz processor with 3
GB RAM. We note that this machine is comparable to the AMD Opteron machine with a 1.8 GHz
processor. We choose T = 10 4 training samples and fix k = 50 in all three cases. For BP-kNNG,
we fix s = 5 and N = 103 . When reporting results for L1O-kNNG and K-LPE, we report the
processing time per test instance (/i). We are unable to report the AUC for K-LPE because of the
large processing time and for L1O-kNNG because it cannot operate at high false alarm rates.
From the results in Table 2, we see that BP-kNNG performs comparably in terms of AUC to the
other algorithms, while having the least processing time across all algorithms (implemented on
different, but comparable machines). In addition, BP-kNNG allows the specification of a threshold
for anomaly detection at a desired false alarm rate. This is corroborated by the results in Table 3,
where we see that the observed false alarm rates across the different data sets are close to the desired
false alarm rate.

6 Conclusions
The geometric entropy minimization (GEM) principle was introduced in [4] to extract minimal set
coverings that can be used to detect anomalies from a set of training samples. In this paper we
propose a bipartite k-nearest neighbor graph (BP-kNNG) anomaly detection algorithm based on the
GEM principle. BP-kNNG inherits the theoretical optimality properties of GEM methods including
consistency, while being an order of magnitude faster than the methods proposed in [4].
We compared BP-kNNG against state of the art anomaly detection algorithms and showed that BPkNNG compares favorably in terms of both ROC performance and computation time. In addition,
BP-kNNG enjoys several other advantages including the ability to detect anomalies at a desired false
alarm rate. In BP-kNNG, the p-values of each test point can also be easily computed (1), making
BP-kNNG easily extendable to incorporating false discovery rate constraints.

8

References
[1] A. Asuncion and D.J. Newman. UCI machine learning repository, 2007.
[2] S. D. Bay and M. Schwabacher. Mining distance-based outliers in near linear time with randomization and a simple pruning rule. In Proceedings of the ninth ACM SIGKDD international
conference on Knowledge discovery and data mining, KDD ?03, pages 29?38, New York, NY,
USA, 2003. ACM.
[3] M. M. Breunig, H. Kriegel, R. T. Ng, and J. Sander. Lof: identifying density-based local
outliers. In Proceedings of the 2000 ACM SIGMOD international conference on Management
of data, SIGMOD ?00, pages 93?104, New York, NY, USA, 2000. ACM.
[4] A. O. Hero. Geometric entropy minimization (gem) for anomaly detection and localization. In
Proc. Advances in Neural Information Processing Systems (NIPS, pages 585?592. MIT Press,
2006.
[5] F. T. Liu, K. M. Ting, and Z. Zhou. Isolation forest. In Proceedings of the 2008 Eighth IEEE
International Conference on Data Mining, pages 413?422, Washington, DC, USA, 2008. IEEE
Computer Society.
[6] C. Park, J. Z. Huang, and Y. Ding. A computable plug-in estimator of minimum volume sets
for novelty detection. Operations Research, 58(5):1469?1480, 2010.
[7] S. Ramaswamy, R. Rastogi, and K. Shim. Efficient algorithms for mining outliers from large
data sets. SIGMOD Rec., 29:427?438, May 2000.
[8] D. M. Rocke and D. L. Woodruff. Identification of Outliers in Multivariate Data. Journal of
the American Statistical Association, 91(435):1047?1061, 1996.
[9] B. Sch?olkopf, R. Williamson, A. Smola, J. Shawe-Taylor, and J.Platt. Support Vector Method
for Novelty Detection. volume 12, 2000.
[10] C. Scott and R. Nowak. Learning minimum volume sets. J. Machine Learning Res, 7:665?704,
2006.
[11] K. Sricharan, R. Raich, and A. O. Hero. Empirical estimation of entropy functionals with
confidence. ArXiv e-prints, December 2010.
[12] K. M. Ting, G. Zhou, T. F. Liu, and J. S. C. Tan. Mass estimation and its applications. In
Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and
data mining, KDD ?10, pages 989?998, New York, NY, USA, 2010. ACM.
[13] M. Zhao and V. Saligrama. Anomaly detection with score functions based on nearest neighbor
graphs. Computing Research Repository, abs/0910.5461, 2009.

9


----------------------------------------------------------------

title: 3723-anomaly-detection-with-score-functions-based-on-nearest-neighbor-graphs.pdf

Anomaly Detection with Score functions based on
Nearest Neighbor Graphs

Manqi Zhao
ECE Dept.
Boston University
Boston, MA 02215
mqzhao@bu.edu

Venkatesh Saligrama
ECE Dept.
Boston University
Boston, MA, 02215
srv@bu.edu

Abstract
We propose a novel non-parametric adaptive anomaly detection algorithm for high
dimensional data based on score functions derived from nearest neighbor graphs
on n-point nominal data. Anomalies are declared whenever the score of a test
sample falls below ?, which is supposed to be the desired false alarm level. The
resulting anomaly detector is shown to be asymptotically optimal in that it is uniformly most powerful for the specified false alarm level, ?, for the case when
the anomaly density is a mixture of the nominal and a known density. Our algorithm is computationally efficient, being linear in dimension and quadratic in
data size. It does not require choosing complicated tuning parameters or function
approximation classes and it can adapt to local structure such as local change in
dimensionality. We demonstrate the algorithm on both artificial and real data sets
in high dimensional feature spaces.

1 Introduction
Anomaly detection involves detecting statistically significant deviations of test data from nominal
distribution. In typical applications the nominal distribution is unknown and generally cannot be
reliably estimated from nominal training data due to a combination of factors such as limited data
size and high dimensionality.
We propose an adaptive non-parametric method for anomaly detection based on score functions that
maps data samples to the interval [0, 1]. Our score function is derived from a K-nearest neighbor
graph (K-NNG) on n-point nominal data. Anomaly is declared whenever the score of a test sample
falls below ? (the desired false alarm error). The efficacy of our method rests upon its close connection to multivariate p-values. In statistical hypothesis testing, p-value is any transformation of the
feature space to the interval [0, 1] that induces a uniform distribution on the nominal data. When test
samples with p-values smaller than ? are declared as anomalies, false alarm error is less than ?.
We develop a novel notion of p-values based on measures of level sets of likelihood ratio functions.
Our notion provides a characterization of the optimal anomaly detector, in that, it is uniformly most
powerful for a specified false alarm level for the case when the anomaly density is a mixture of the
nominal and a known density. We show that our score function is asymptotically consistent, namely,
it converges to our multivariate p-value as data length approaches infinity.
Anomaly detection has been extensively studied. It is also referred to as novelty detection [1, 2],
outlier detection [3], one-class classification [4, 5] and single-class classification [6] in the literature. Approaches to anomaly detection can be grouped into several categories. In parametric
approaches [7] the nominal densities are assumed to come from a parameterized family and generalized likelihood ratio tests are used for detecting deviations from nominal. It is difficult to use
parametric approaches when the distribution is unknown and data is limited. A K-nearest neighbor
1

(K-NN) anomaly detection approach is presented in [3, 8]. There an anomaly is declared whenever
the distance to the K-th nearest neighbor of the test sample falls outside a threshold. In comparison
our anomaly detector utilizes the global information available from the entire K-NN graph to detect
deviations from the nominal. In addition it has provable optimality properties. Learning theoretic
approaches attempt to find decision regions, based on nominal data, that separate nominal instances
from their outliers. These include one-class SVM of Sch?olkopf et. al. [9] where the basic idea
is to map the training data into the kernel space and to separate them from the origin with maximum margin. Other algorithms along this line of research include support vector data description
[10], linear programming approach [1], and single class minimax probability machine [11]. While
these approaches provide impressive computationally efficient solutions on real data, it is generally
difficult to precisely relate tuning parameter choices to desired false alarm probability.
Scott and Nowak [12] derive decision regions based on minimum volume (MV) sets, which does
provide Type I and Type II error control. They approximate (in appropriate function classes) level
sets of the unknown nominal multivariate density from training samples. Related work by Hero
[13] based on geometric entropic minimization (GEM) detects outliers by comparing test samples
to the most concentrated subset of points in the training sample. This most concentrated set is the
K-point minimum spanning tree(MST) for n-point nominal data and converges asymptotically to
the minimum entropy set (which is also the MV set). Nevertheless, computing K-MST for n-point
data is generally intractable. To overcome these computational limitations [13] proposes heuristic
greedy algorithms based on leave-one out K-NN graph, which while inspired by K-MST algorithm
is no longer provably optimal. Our approach is related to these latter techniques, namely, MV sets
of [12] and GEM approach of [13]. We develop score functions on K-NNG which turn out to be the
empirical estimates of the volume of the MV sets containing the test point. The volume, which is a
real number, is a sufficient statistic for ensuring optimal guarantees. In this way we avoid explicit
high-dimensional level set computation. Yet our algorithms lead to statistically optimal solutions
with the ability to control false alarm and miss error probabilities.
The main features of our anomaly detector are summarized. (1) Like [13] our algorithm scales
linearly with dimension and quadratic with data size and can be applied to high dimensional feature
spaces. (2) Like [12] our algorithm is provably optimal in that it is uniformly most powerful for
the specified false alarm level, ?, for the case that the anomaly density is a mixture of the nominal
and any other density (not necessarily uniform). (3) We do not require assumptions of linearity,
smoothness, continuity of the densities or the convexity of the level sets. Furthermore, our algorithm
adapts to the inherent manifold structure or local dimensionality of the nominal density. (4) Like [13]
and unlike other learning theoretic approaches such as [9, 12] we do not require choosing complex
tuning parameters or function approximation classes.

2 Anomaly Detection Algorithm: Score functions based on K-NNG
In this section we present our basic algorithm devoid of any statistical context. Statistical analysis
appears in Section 3. Let S = {x1 , x2 , ? ? ? , xn } be the nominal training set of size n belonging to
the unit cube [0, 1]d . For notational convenience we use ? and xn+1 interchangeably to denote a test
point. Our task is to declare whether the test point is consistent with nominal data or deviates from
the nominal data. If the test point is an anomaly it is assumed to come from a mixture of nominal
distribution underlying the training data and another known density (see Section 3).
Let d(x, y) be a distance function denoting the distance between any two points x, y ? [0, 1]d . For
simplicity we denote the distances by dij = d(xi , xj ). In the simplest case we assume the distance
function to be Euclidean. However, we also consider geodesic distances to exploit the underlying manifold structure. The geodesic distance is defined as the shortest distance on the manifold.
The Geodesic Learning algorithm, a subroutine in Isomap [14, 15] can be used to efficiently and
consistently estimate the geodesic distances. In addition by means of selective weighting of different coordinates note that the distance function could also account for pronounced changes in local
dimensionality. This can be accomplished for instance through Mahalanobis distances or as a by
product of local linear embedding [16]. However, we skip these details here and assume that a
suitable distance metric is chosen.
Once a distance function is defined our next step is to form a K nearest neighbor graph (K-NNG) or
alternatively an ? neighbor graph (?-NG). K-NNG is formed by connecting each xi to the K closest
2

points {xi1 , ? ? ? , xiK } in S ? {xi }. We then sort the K nearest distances for each xi in increasing
order di,i1 ? ? ? ? ? di,iK and denote RS (xi ) = di,iK , that is, the distance from xi to its K-th
nearest neighbor. We construct ?-NG where xi and xj are connected if and only if dij ? ?. In this
case we define NS (xi ) as the degree of point xi in the ?-NG.
For the simple case when the anomalous density is an arbitrary mixture of nominal and uniform
density1 we consider the following two score functions associated with the two graphs K-NNG and
?-NNG respectively. The score functions map the test data ? to the interval [0, 1].
n

K-LPE: p?K (?) =

1X
I{RS (?)?RS (xi )}
n i=1

?-LPE: p?? (?) =

1X
I{NS (?)?NS (xi )}
n i=1

(1)

n

(2)

where I{?} is the indicator function.
Finally, given a pre-defined significance level ? (e.g., 0.05), we declare ? to be anomalous if
p?K (?), p?? (?) ? ?. We call this algorithm Localized p-value Estimation (LPE) algorithm. This
choice is motivated by its close connection to multivariate p-values(see Section 3).
The score function K-LPE (or ?-LPE) measures the relative concentration of point ? compared to
the training set. Section 3 establishes that the scores for nominally generated data is asymptotically
uniformly distributed in [0, 1]. Scores for anomalous data are clustered around 0. Hence when scores
below level ? are declared as anomalous the false alarm error is smaller than ? asymptotically (since
the integral of a uniform distribution from 0 to ? is ?).
anomaly detection via K?LPE, n=200, K=6, ?=0.05
5

4

4

3

3

2

2

1

1

0

0

?1

?1

?2

?2

?3

?3

?4

?4

?5

?5

empirical distribution of the scoring function K?LPE
12
nominal data
anomaly data
10

empirical density

Bivariate Gaussian mixture distribution
5

level set at ?=0.05

8

6

4

2

labeled as anomaly
labeled as nominal

?6
?6

?4

?2

0

2

?6
?6

4

?4

?2

0

2

4

0

0

0.2

?=0.05

0.4
0.6
value of K?LPE

0.8

1

Figure 1: Left: Level sets of the nominal bivariate Gaussian mixture distribution used to illustrate the KLPE algorithm. Middle: Results of K-LPE with K = 6 and Euclidean distance metric for m = 150 test
points drawn from a equal mixture of 2D uniform and the (nominal) bivariate distributions. Scores for the test
points are based on 200 nominal training samples. Scores falling below a threshold level 0.05 are declared as
anomalies. The dotted contour corresponds to the exact bivariate Gaussian density level set at level ? = 0.05.
Right: The empirical distribution of the test point scores associated with the bivariate Gaussian appear to be
uniform while scores for the test points drawn from 2D uniform distribution cluster around zero.

Figure 1 illustrates the use of K-LPE algorithm for anomaly detection when the nominal data is a
2D Gaussian mixture. The middle panel of figure 1 shows the detection results based on K-LPE are
consistent with the theoretical contour for significance level ? = 0.05. The right panel of figure 1
shows the empirical distribution (derived from the kernel density estimation) of the score function
K-LPE for the nominal (solid blue) and the anomaly (dashed red) data. We can see that the curve for
the nominal data is approximately uniform in the interval [0, 1] and the curve for the anomaly data
has a peak at 0. Therefore choosing the threshold ? = 0.05 will approximately control the Type I
error within 0.05 and minimize the Type II error. We also take note of the inherent robustness of our
algorithm. As seen from the figure (right) small changes in ? lead to small changes in actual false
alarm and miss levels.
?
?
1 Pn
1
1
When the mixing density is not uniform but, say f1 , the score functions must be modified to p
?K (?) = n
i=1 I R (?)f1 (?) ? R (xi )f1 (xi )
S
S
?
?
NS (?)
NS (xi )
1 Pn
and p
?? (?) = n
for the two graphs K-NNG and ?-NNG respectively.
i=1 I f (?) ? f (x )

1

1

1

i

3

To summarize the above discussion, our LPE algorithm has three steps:
(1) Inputs: Significance level ?, distance metric (Euclidean, geodesic, weighted etc.).
(2) Score computation: Construct K-NNG (or ?-NG) based on dij and compute the score function
K-LPE from Equation 1 (or ?-LPE from Equation 2).
(3) Make Decision: Declare ? to be anomalous if and only if p?K (?) ? ? (or p?? (?) ? ?).
Computational Complexity: To compute each pairwise distance requires O(d) operations; and
O(n2 d) operations for all the nodes in the training set. In the worst-case computing the K-NN graph
(for small K) and the functions RS (?), NS (?) requires O(n2 ) operations over all the nodes in the
training data. Finally, computing the score for each test data requires O(nd+n) operations(given that
RS (?), NS (?) have already been computed).
Remark: LPE is fundamentally different from non-parametric density estimation or level set estimation schemes (e.g., MV-set). These approaches involve explicit estimation of high dimensional
quantities and thus hard to apply in high dimensional problems. By computing scores for each test
sample we avoid high-dimensional computation. Furthermore, as we will see in the following section the scores are estimates of multivariate p-values. These turn out to be sufficient statistics for
optimal anomaly detection.

3

Theory: Consistency of LPE

A statistical framework for the anomaly detection problem is presented in this section. We establish
that anomaly detection is equivalent to thresholding p-values for multivariate data. We will then
show that the score functions developed in the previous section is an asymptotically consistent estimator of the p-values. Consequently, it will follow that the strategy of declaring an anomaly when a
test sample has a low score is asymptotically optimal.
Assume that the data belongs to the d-dimensional unit cube [0, 1]d and the nominal data is sampled from a multivariate density f0 (x) supported on the d-dimensional unit cube [0, 1]d . Anomaly
detection can be formulated as a composite hypothesis testing problem. Suppose test data, ? comes
from a mixture distribution, namely, f (?) = (1 ? ?)f0 (?) + ?f1 (?) where f1 (?) is a mixing density
supported on [0, 1]d . Anomaly detection involves testing the nominal hypotheses H0 : ? = 0 versus
the alternative (anomaly) H1 : ? > 0. The goal is to maximize the detection power subject to false
alarm level ?, namely, P(declare H1 | H0 ) ? ?.
Definition 1. Let P0 be the nominal probability measure and f1 (?) be P0 measurable. Suppose the
likelihood ratio f1 (x)/f0 (x) does not have non-zero flat spots on any open ball in [0, 1]d . Define
the p-value of a data point ? as
?
?
f1 (?)
f1 (x)
?
p(?) = P0 x :
f0 (x)
f0 (?)
Note that the definition naturally accounts for singularities which may arise if the support of f0 (?)
is a lower dimensional manifold. In this case we encounter f1 (?) > 0, f0 (?) = 0 and the p-value
p(?) = 0. Here anomaly is always declared(low score).
The above formula can be thought of as a mapping of ? ? [0, 1]. Furthermore, the distribution of
p(?) under H0 is uniform on [0, 1]. However, as noted in the introduction there are other such transformations. To build intuition about the above transformation and its utility consider the following
example. When the mixing density is uniform, namely, f1 (?) = U (?) where U (?) is uniform over
[0, 1]d , note that ?? = {? | p(?) ? ?} is a density level set at level ?. It is well known (see [12])
that such a density level set is equivalent to a minimum volume set of level ?. The minimum volume
set at level ? is known to be the uniformly most powerful decision region for testing H0 : ? = 0
versus the alternative H1 : ? > 0 (see [13, 12]). The generalization to arbitrary f1 is described next.
Theorem 1. The uniformly most powerful test for testing H0 : ? = 0 versus the alternative
(anomaly) H1 : ? > 0 at a prescribed level ? of significance P(declare H1 | H0 ) ? ? is:
?
H1 , p(?) ? ?
?(?) =
H0 , otherwise
4

Proof. We provide the main idea for the proof. First, measure theoretic arguments are used to
establish p(X) as a random variable over [0, 1] under both nominal and anomalous distributions.
d

d

Next when X ? f0 , i.e., distributed with nominal density it follows that the random variable p(X) ?
d

d

U [0, 1]. When X ? f = (1 ? ?)f0 + ?f1 with ? > 0 the random variable, p(X) ? g where g(?)
is a monotonically decreasing PDF supported on [0, 1]. Consequently, the uniformly most powerful
test for a significance level ? is to declare p-values smaller than ? as anomalies.
Next we derive the relationship between the p-values and our score function. By definition, RS (?)
and RS (xi ) are correlated because the neighborhood of ? and xi might overlap. We modify our
algorithm to simplify our analysis. We assume n is odd (say) and can be written as n = 2m + 1.
We divide training set S into two parts:
S = S1 ? S2 = {x0 , x1 , ? ? ? , xm } ? {xm+1 , ? ? ? , x2m }
P
1
We modify ?-LPE to p?? (?) = m
?K (?)
xi ?S1 I{NS2 (?)?NS1 (xi )} (or K-LPE to p
P
1
I
).
Now
R
(?)
and
R
(x
)
are
independent.
S2
S1
i
xi ?S1 {RS2 (?)?RS1 (xi )}
m

=

Furthermore, we assume f0 (?) satisfies the following two smoothness conditions:
1. the Hessian matrix H(x) of f0 (x) is always dominated by a matrix with largest eigenvalue
?M , i.e., ?M s.t. H(x) ? M ?x and ?max (M ) ? ?M
2. In the support of f0 (?), its value is always lower bounded by some ? > 0.
We have the following theorem.
Theorem 2. Consider the setup above with the training data {xi }ni=1 generated i.i.d. from f0 (x).
Let ? ? [0, 1]d be an arbitrary test sample. It follows that for a suitable choice K and under the
above smoothness conditions,
n??

|?
pK (?) ? p(?)| ?? 0 almost surely, ?? ? [0, 1]d
For simplicity, we limit ourselves to the case when f1 is uniform. The proof of Theorem 2 consists
of two steps:
n??

? We show that the expectation ES1 [?
p? (?)] ?? p(?) (Lemma 3). This result is then exn??
tended to K-LPE (i.e. ES1 [?
pK (?)] ?? p(?)) in Lemma 4.
n??

? Next we show that p?K (?) ?? ES1 [?
pK (?)] via concentration inequality (Lemma 5).
q
1/15
3
d
, with probability at least 1 ? e??m /2 ,
Lemma 3 (?-LPE). By picking ? = m? 5d 2?e
lm (?) ? ES1 [?
p? (?)] ? um (?)

(3)

where
1/15

/2

1/15

/2

lm (?) = P0 {x : (f0 (?) ? ?1 ) (1 ? ?2 ) ? (f0 (x) + ?1 ) (1 + ?2 )} ? e??m

um (?) = P0 {x : (f0 (?) + ?1 ) (1 + ?2 ) ? (f0 (x) ? ?1 ) (1 ? ?2 )} + e??m
?1 = ?M m?6/5d /(2?e(d + 2)) and ?2 = 2m?1/6 .

Proof. We only prove the lower bound since the upper bound follows along similar lines. By interchanging the expectation with the summation,
"
#
1 X
ES1 [?
p? (?)] = ES1
I{NS2 (?)?NS1 (xi )}
m
xi ?S1
h
i
1 X
=
Exi ES1 \xi I{NS2 (?)?NS1 (xi )}
m
xi ?S1

= Ex1 [PS1 \x1 (NS2 (?) ? NS1 (x1 ))]
5

where the last inequality follows from the symmetric structure of {x0 , x1 , ? ? ? , xm }.
n??

Clearly the objective of the proof is to show PS1 \x1 (NS2 (?) ? NS1 (x1 )) ?? I{f0 (?)?f0 (x1 )} .
Skipping technical details, this can be accomplishedRin two steps. (1) Note that NS (x1 ) is a binomial
random variable with success probability q(x1 ) := B? f0 (x1 + t)dt. This relates PS1 \x1 (NS2 (?) ?
NS1 (x1 )) to I{q(?)?q(x1 )} . (2) We relate I{q(?)?q(x1 )} to I{f0 (?)?f0 (x1 )} based on the function
smoothness condition. The details of these two steps are shown in the below.
Note that NS1 (x1 ) ? Binom(m, q(x1 )). By Chernoff bound of binomial distribution, we have
2

?
? 2mq(x

PS1 \x1 (NS1 (x1 ) ? mq(x1 ) ? ?) ? e

1)

that is, NS1 (x1 ) is concentrated around mq(x1 ). This implies,
PS1 \x1 (NS2 (?) ? NS1 (x1 )) ? I{NS

2

(?)?mq(x1 )+?x1 }

2
?x

1
? 2mq(x

?e

(4)

1)

We choose ?x1 = q(x1 )m? (? will be specified later) and reformulate equation (4) as
PS1 \x1 (NS2 (?) ? NS1 (x1 )) ? I?

NS (?)
q(x )
2
? Vol(B1 )
mVol(B? )
?

?
2
(1+ m1??
)

q(x1 )m2??1
2

? e?

(5)

R
Next, we relate q(x1 )(or B? f0 (x1 + t)dt) to f0 (x1 ) via the Taylor?s expansion and the smoothness
condition of f0 ,
?
?R
Z
? ?
?
1
?M ?2
?
? B? f0 (x1 + t)dt
M
? f0 (x1 )? ?
?
ktk2 dt =
(6)
?
?
?
Vol(B? )
2 Vol(B? ) B?
2d(d + 2)
and then equation (5) becomes
PS1 \x1 (NS2 (?) ? NS1 (x1 )) ? I?

?
?
NS (?)
?M ?2
2
? f0 (x1 )+ 2d(d+2)
mVol(B? )

?

(

2
1+ 1??
m

)

? e?

q(x1 )m2??1
2

By applying the same steps to NS2 (?) as equation 4 (Chernoff bound) and equation 6 (Taylor?s
explansion), we have with probability at least 1 ? e?
Ex1 [PS1 \x1 (NS2 (?) ? NS1 (x1 ))] ?
6

Finally, by choosing ?2 = m? 5d ?

q(?)m2??1
2

,

??
??
??
q(x1 )m2??1
? ?
??
?
?M ?2
?M ?2
2
2
2
? f0 (x1 )+ 2d(d+2)
?e
1? 1??
1+ 1??
Px1 f0 (?)? 2d(d+2)
m
m

d
2?e

and ? = 5/6, we prove the lemma.
?
?
Lemma 4 (K-LPE). By picking K = 1 ? 2m?1/6 m2/5 (f0 (?) ? ?1 ), with probability at least
1/15
1 ? e??m /2 ,
lm (?) ? ES1 [?
pK (?)] ? um (?)
(7)

Proof. The proof is very similar to the proof to Lemma 3 and we only give a brief outline here. Now
n??
the objective is to show PS1 \x1 (RS2 (?) ? RS1 (x1 )) ?? I{f0 (?)?f0 (x1 )} .The basic idea is to use
the result of Lemma 3. To accomplish this, we note that {RS2 (?) ? RS1 (x1 )} contains the events
{NS2 (?) ? K} ? {NS1 (x1 ) ? K}, or equivalently
{NS2 (?) ? q(?)m ? K ? q(?)m} ? {NS1 (x1 ) ? q(x1 )m ? K ? q(x1 )m}
(8)
By the tail probability of Binomial distribution, the probability of the above two events converges to
1 exponentially fast if K ? q(?)m < 0 and K ? q(x1 )m > 0. By using the same two-step bounding
techniques developed in the proof to Lemma 3, these two inequalities are implied by
K ? m2/5 (f0 (?) ? ?1 ) < 0 and K ? m2/5 (f0 (x1 ) + ?1 ) > 0
?
?
Therefore if we choose K = 1 ? 2m?1/6 m2/5 (f0 (?) ? ?1 ), we have with probability at least
?1/15
/2
1 ? e??m
,
?1/15

PS1 \x1 (RS2 (?) ? RS1 (x1 )) ? I{(f0 (?)??1 )(1??2 )?(f0 (x1 )+?1 )(1+?2 )} ? e??m

6

/2

Remark: Lemma 3 and Lemma 4 were proved with specific choices for ? and K. However, they
can be chosen in a range of values, but will lead to different lower and upper bounds. We will show
in Section 4 via simulation that our LPE algorithm is generally robust to choice of parameter K.
P
1
Lemma 5. Suppose K = cm2/5 and denote p?K (?) = m
xi ?S1 I{RS2 (?)?RS1 (xi )} . We have
2 m1/5
c2 ? 2
d

? 2?

P0 (|ES1 [?
pK (?)] ? p?K (?)| > ?) ? 2e

where ?d is a constant and is defined as the minimal number of cones centered at the origin of angle
?/6 that cover Rd .
Proof. We can not apply Law of Large Number in this case because I{RS2 (?)?RS1 (xi )} are correlated. Instead, we need to use the more generalized concentration-of-measure
inequality such
P
1
as MacDiarmid?s inequality[17]. Denote F (x0 , ? ? ? , xm ) = m
xi ?S1 I{RS2 (?)?RS1 (xi )} . From
Corollary 11.1 in [18],
sup
x0 ,??? ,xm ,x0i

|F (x0 , ? ? ? , xi , ? ? ? , xm ) ? F (x0 , ? ? ? , x0i , ? ? ? , xn )| ? K?d /m

(9)

Then the lemma directly follows from applying McDiarmid?s inequality.
Theorem 2 directly follows from the combination of Lemma 4 and Lemma 5 and a standard application of the first Borel-Cantelli lemma. We have used Euclidean distance in Theorem 2. When the
support of f0 lies on a lower dimensional manifold (say d0 < d) adopting the geodesic metric leads
to faster convergence. It turns out that d0 replaces d in the expression for ?1 in Lemma 3.

4

Experiments

First, to test the sensitivity of K-LPE to parameter changes, we run K-LPE on the benchmark dataset Banana [19] with K varying from 2 to 12. We randomly pick 109 points with ?+1? label and
regard them as the nominal training data. The test data comprises of 108 ?+1? points and 183 ??1?
points (ground truth) and the algorithm is supposed to predict ?+1? data as nominal and ??1? data
as anomalous. Scores computed for test set using Equation 1 is oblivious to true f1 density (??1?
labels). Euclidean distance metric is adopted for this experiment.
To control false alarm at level ?, points with score smaller than ? are predicted as anomaly. Empirical false alarm and true positives are computed from ground truth. We vary ? to obtain the empirical
ROC curve. The above procedure is followed for the rest of the experiments in this section. As
shown in 2(a), the LPE algorithm is insensitive to K. For comparison we plot the empirical ROC
curve of the one-class SVM of [9]. For our OC-SVM implementation, for a fixed bandwidth, c, we
obtain the empirical ROC curve by varying ?. We then vary the bandwidth, c, to obtain the best
(in terms of AUC) ROC curve. The optimal bandwidth turns out to be c = 1.5. In LPE if we set
? = 0.05 we get empirical F A = 0.06 and for ? = 0.08, empirical F A = 0.09. For OC-SVM we
are unaware of any natural way of picking c and ? to control FA rate based on training data.
Next, we apply our K-LPE to the problem where the nominal and anomalous data are generated in
the following way:
?? ? ?
??
?? ? ?
??
? ?
??
1
1
8
1 0
?8
1 0
49 0
f0 ? N
,
+ N
,
, f1 ? N 0,
(10)
0
0 9
0
0 9
0 49
2
2
We call ROC curve corresponding to the optimal Bayesian classifier as the Clairvoyant ROC (the
red dashed curve in Figure 2(b)). The other two curves are averaged (over 15 trials) empirical ROC
curves via LPE. Here we set K = 6 and n = 40 or n = 160. We see that for a relatively small
training set of size 160 the average empirical ROC curve is very close to the clairvoyant ROC curve.
Finally, we ran LPE on three real-world datasets: Wine, Ionosphere[20] and MNIST US Postal
Service (USPS) database of handwritten digits. If there are more than 2 labels in the data set, we
artificially regard points with one particular label as nominal and regard the points with other labels
as anomalous. For example, for the USPS dataset, we regard instances of digit 0 as nominal and
instances of digits 1, ? ? ? , 9 as anomaly. The data points are normalized to be within [0, 1]d and we
7

2D Gaussian mixture
1

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

true positives

true positives

banana data set
1

0.5
ROC of LPE (K=2)

0.4

0.5
0.4

ROC of LPE (K=4)
0.3

0.3

ROC of LPE (K=6)
ROC of LPE (K=8)

0.2

0.2

ROC of LPE (K=10)
ROC of LPE (K=12)

0.1

ROC of LPE(n=40)
ROC of LPE(n=160)

0.1

Clairvoyant ROC

ROC of one?class SVM
0

0

0.1

0.2

0.3

0.4
0.5
0.6
false positives

0.7

0.8

0.9

0

1

0

0.1

(a) SVM vs. K-LPE for Banana Data

0.2

0.3

0.4
0.5
0.6
false positives

0.7

0.8

0.9

1

(b) Clairvoyant vs. K-LPE

Figure 2: (a) Empirical ROC curve of K -LPE on the banana dataset with K = 2, 4, 6, 8, 10, 12 (with
n = 400) vs the empirical ROC curve of one class SVM developed in [9]; (b) Empirical ROC curves of
K -LPE algorithm vs clairvoyant ROC curve (f0 is given by Equation 10) for K = 6 and for n = 40 or 160.

1

1

0.9

0.9

0.8

0.8

0.8

0.7

0.7

0.7

0.6

0.6

0.6

0.5
0.4

true positive

1
0.9

true positive

true positive

use geodesic distance [14]. The ROC curves are shown in Figure 3. The feature dimension of Wine
is 13 and we apply the ?-LPE algorithm with ? = 0.9 and n = 39. The test set is a mixture of
20 nominal points and 158 anomaly points. The feature dimension of Ionosphere is 34 and we
apply the K-LPE algorithm with K = 9 and n = 175. The test set is a mixture of 50 nominal points
and 126 anomaly points. The feature dimension of USPS is 256 and we apply the K-LPE algorithm
with K = 9 and n = 400. The test set is a mixture of 367 nominal points and 33 anomaly points.
In USPS, setting ? = 0.5 induces empirical false-positive 6.1% and empirical false alarm rate 5.7%
(In contrast F P = 7% and F A = 9% with ? = 5% for OC-SVM as reported in [9]). Practically we
find that K-LPE is more preferable to ?-LPE and as a rule of thumb setting K ? n2/5 is generally
effective.

0.5
0.4

0.5
0.4

0.3

0.3

0.3

0.2

0.2

0.2

0.1

0.1

0

0

0.1

0.2

0.3

0.4
0.5
0.6
false positive

(a) Wine

0.7

0.8

0.9

1

0

0.1

0

0.1

0.2

0.3

0.4
0.5
0.6
false positive

0.7

(b) Ionosphere

0.8

0.9

1

0

0

0.1

0.2

0.3

0.4
0.5
0.6
false positive

0.7

0.8

0.9

1

(c) USPS

Figure 3: ROC curves on real datasets via LPE; (a) Wine dataset with D = 13, n = 39, ? = 0.9; (b)
Ionosphere dataset with D = 34, n = 175, K = 9; (c) USPS dataset with D = 256, n = 400, K = 9.

5

Conclusion

In this paper, we proposed a novel non-parametric adaptive anomaly detection algorithm which leads
to a computationally efficient solution with provable optimality guarantees. Our algorithm takes a
K-nearest neighbor graph as an input and produces a score for each test point. Scores turn out to be
empirical estimates of the volume of minimum volume level sets containing the test point. While
minimum volume level sets provide an optimal characterization for anomaly detection, they are
high dimensional quantities and generally difficult to reliably compute in high dimensional feature
spaces. Nevertheless, a sufficient statistic for optimal tradeoff between false alarms and misses is
the volume of the MV set itself, which is a real number. By computing score functions we avoid
computing high dimensional quantities and still ensure optimal control of false alarms and misses.
The computational cost of our algorithm scales linearly in dimension and quadratically in data size.
8

References
[1] C. Campbell and K. P. Bennett, ?A linear programming approach to novelty detection,? in Advances in
Neural Information Processing Systems 13. MIT Press, 2001, pp. 395?401.
[2] M. Markou and S. Singh, ?Novelty detection: a review ? part 1: statistical approaches,? Signal Processing,
vol. 83, pp. 2481?2497, 2003.
[3] R. Ramaswamy, R. Rastogi, and K. Shim, ?Efficient algorithms for mining outliers from large data sets,?
in Proceedings of the ACM SIGMOD Conference, 2000.
[4] R. Vert and J. Vert, ?Consistency and convergence rates of one-class svms and related algorithms,? Journal
of Machine Learning Research, vol. 7, pp. 817?854, 2006.
[5] D. Tax and K. R. M?
uller, ?Feature extraction for one-class classification,? in Artificial neural networks
and neural information processing, Istanbul, TURQUIE, 2003.
[6] R. El-Yaniv and M. Nisenson, ?Optimal singl-class classification strategies,? in Advances in Neural Information Processing Systems 19. MIT Press, 2007.
[7] I. V. Nikiforov and M. Basseville, Detection of abrupt changes: theory and applications. Prentice-Hall,
New Jersey, 1993.
[8] K. Zhang, M. Hutter, and H. Jin, ?A new local distance-based outlier detection approach for scattered
real-world data,? March 2009, arXiv:0903.3257v1[cs.LG].
[9] B. Sch?
olkopf, J. C. Platt, J. Shawe-Taylor, A. J. Smola, and R. Williamson, ?Estimating the support of a
high-dimensional distribution,? Neural Computation, vol. 13, no. 7, pp. 1443?1471, 2001.
[10] D. Tax, ?One-class classification: Concept-learning in the absence of counter-examples,? Ph.D. dissertation, Delft University of Technology, June 2001.
[11] G. R. G. Lanckriet, L. E. Ghaoui, and M. I. Jordan, ?Robust novelty detection with single-class MPM,?
in Neural Information Processing Systems Conference, vol. 18, 2005.
[12] C. Scott and R. D. Nowak, ?Learning minimum volume sets,? Journal of Machine Learning Research,
vol. 7, pp. 665?704, 2006.
[13] A. O. Hero, ?Geometric entropy minimization(GEM) for anomaly detection and localization,? in Neural
Information Processing Systems Conference, vol. 19, 2006.
[14] J. B. Tenenbaum, V. de Silva, and J. C. Langford, ?A global geometric framework fo nonlinear dimensionality reduction,? Science, vol. 290, pp. 2319?2323, 2000.
[15] M. Bernstein, V. D. Silva, J. C. Langford, and J. B. Tenenbaum, ?Graph approximations to geodesics on
embedded manifolds,? 2000.
[16] S. T. Roweis and L. K. Saul, ?Nonlinear dimensionality reduction by local linear embedding,? Science,
vol. 290, pp. 2323?2326, 2000.
[17] C. McDiarmid, ?On the method of bounded differences,? in Surveys in Combinatorics.
University Press, 1989, pp. 148?188.
[18] L. Devroye, L. Gy?orfi, and G. Lugosi, A Probabilistic Theory of Pattern Recognition.
New York, Inc., 1996.

Cambridge

Springer Verlag

[19] ?Benchmark repository.? [Online]. Available: http://ida.first.fhg.de/projects/bench/benchmarks.htm
[20] A. Asuncion and D. J. Newman, ?UCI machine learning repository,? 2007. [Online]. Available:
http://www.ics.uci.edu/?mlearn/MLRepository.html

9


----------------------------------------------------------------

title: 3156-in-network-pca-and-anomaly-detection.pdf

In-Network PCA and Anomaly Detection
Ling Huang
University of California
Berkeley, CA 94720
hling@cs.berkeley.edu

Michael I. Jordan
University of California
Berkeley, CA 94720
jordan@cs.berkeley.edu

XuanLong Nguyen
University of California
Berkeley, CA 94720

xuanlong@cs.berkeley.edu

Anthony Joseph
University of California
Berkeley, CA 94720
adj@cs.berkeley.edu

Minos Garofalakis
Intel Research
Berkeley, CA 94704

minos.garofalakis@intel.com

Nina Taft
Intel Research
Berkeley, CA 94704
nina.taft@intel.com

Abstract
We consider the problem of network anomaly detection in large distributed systems. In this
setting, Principal Component Analysis (PCA) has been proposed as a method for discovering anomalies by continuously tracking the projection of the data onto a residual subspace.
This method was shown to work well empirically in highly aggregated networks, that is,
those with a limited number of large nodes and at coarse time scales. This approach, however, has scalability limitations. To overcome these limitations, we develop a PCA-based
anomaly detector in which adaptive local data filters send to a coordinator just enough data
to enable accurate global detection. Our method is based on a stochastic matrix perturbation analysis that characterizes the tradeoff between the accuracy of anomaly detection and
the amount of data communicated over the network.

1 Introduction
The area of distributed computing systems provides a promising domain for applications of machine
learning methods. One of the most interesting aspects of such applications is that learning algorithms
that are embedded in a distributed computing infrastructure are themselves part of that infrastructure
and must respect its inherent local computing constraints (e.g., constraints on bandwidth, latency,
reliability, etc.), while attempting to aggregate information across the infrastructure so as to improve
system performance (or availability) in a global sense.
Consider, for example, the problem of detecting anomalies in a wide-area network. While it is
straightforward to embed learning algorithms at local nodes to attempt to detect node-level anomalies, these anomalies may not be indicative of network-level problems. Indeed, in recent work, [8]
demonstrated a useful role for Principal Component Analysis (PCA) to detect network anomalies.
They showed that the minor components of PCA (the subspace obtained after removing the components with largest eigenvalues) revealed anomalies that were not detectable in any single node-level
trace. This work assumed an environment in which all the data is continuously pushed to a central
site for off-line analysis. Such a solution cannot scale either for networks with a large number of
monitors nor for networks seeking to track and detect anomalies at very small time scales.
Designing scalable solutions presents several challenges. Viable solutions need to process data ?innetwork? to intelligently control the frequency and size of data communications. The key underlying
problem is that of developing a mathematical understanding of how to trade off quantization arising
from local data filtering against fidelity of the detection analysis. We also need to understand how
this tradeoff impacts overall detection accuracy. Finally, the implementation needs to be simple if it
is to have impact on developers.

In this paper, we present a simple algorithmic framework for network-wide anomaly detection that
relies on distributed tracking combined with approximate PCA analysis, together with supporting
theoretical analysis. In brief, the architecture involves a set of local monitors that maintain parameterized sliding filters. These sliding filters yield quantized data streams that are sent to a coordinator.
The coordinator makes global decisions based on these quantized data streams. We use stochastic
matrix perturbation theory to both assess the impact of quantization on the accuracy of anomaly
detection, and to design a method that selects filter parameters in a way that bounds the detection
error. The combination of our theoretical tools and local filtering strategies results in an in-network
tracking algorithm that can achieve high detection accuracy with low communication overhead; for
instance, our experiments show that, by choosing a relative eigen-error of 1.5% (yielding, approximately, a 4% missed detection rate and a 6% false alarm rate), we can filter out more than 90% of
the traffic from the original signal.
Prior Work. The original work on a PCA-based method by Lakhina et al. [8] has been extended
by [17], who show how to infer network anomalies in both spatial and temporal domains. As with
[8], this work is completely centralized. [14] and [1] propose distributed PCA algorithms distributed
across blocks of rows or columns of the data matrix; however, these methods are not applicable to
our case. Furthermore, neither [14] nor [1] address the issue of continuously tracking principal
components within a given error tolerance or the issue of implementing a communication/accuracy
tradeoff; issues which are the main focus of our work. Other initiatives in distributed monitoring,
profiling and anomaly detection aim to share information and foster collaboration between widely
distributed monitoring boxes to offer improvements over isolated systems [12, 16]. Work in [2, 10]
posits the need for scalable detection of network attacks and intrusions. In the setting of simpler
statistics such as sums and counts, in-network detection methods related to ours have been explored
by [6]. Finally, recent work in the machine learning literature considers distributed constraints
in learning algorithms such as kernel-based classification [11] and graphical model inference [7].
(See [13] for a survey).

2 Problem description and background
We consider a monitoring system comprising a set of local monitor nodes M 1 , . . . , Mn , each of
which collects a locally-observed time-series data stream (Fig. 1(a)). For instance, the monitors
may collect information on the number of TCP connection requests per second, the number of
DNS transactions per minute, or the volume of traffic at port 80 per second. A central coordinator
node aims to continuously monitor the global collection of time series, and make global decisions
such as those concerning matters of network-wide health. Although our methodology is generally
applicable, in this paper we focus on the particular application of detecting volume anomalies. A
volume anomaly refers to unusual traffic load levels in a network that are caused by anomalies such
as worms, distributed denial of service attacks, device failures, misconfigurations, and so on.
Each monitor collects a new data point at every time step and, assuming a naive, ?continuous push?
protocol, sends the new point to the coordinator. Based on these updates, the coordinator keeps track
of a sliding time window of size m (i.e., the m most recent data points) for each monitor time series,
organized into a matrix Y of size m ? n (where the ith column Yi captures the data from monitor
i, see Fig. 1(a)). The coordinator then makes its decisions based solely on this (global) Y matrix.
In the network-wide volume anomaly detection algorithm of [8] the local monitors measure the total
volume of traffic (in bytes) on each network link, and periodically (e.g., every 5 minutes) centralize
the data by pushing all recent measurements to the coordinator. The coordinator then performs
PCA on the assembled Y matrix to detect volume anomalies. This method has been shown to work
remarkably well, presumably due to the inherently low-dimensional nature of the underlying data
[9]. However, such a ?periodic push? approach suffers from inherent limitations: To ensure fast
detection, the update periods should be relatively small; unfortunately, small periods also imply
increased monitoring communication overheads, which may very well be unnecessary (e.g., if there
are no significant local changes across periods). Instead, in our work, we study how the monitors
can effectively filter their time-series updates, sending as little data as possible, yet enough so as
to allow the coordinator to make global decisions accurately. We provide analytical bounds on the
errors that occur because decisions are made with incomplete data, and explore the tradeoff between
reducing data transmissions (communication overhead) and decision accuracy.

18

3
Anomaly

State Vector

Data Flow

? =
Y

Result

x 10

2

1

0

Mon

Tue

Wed

Thu

Fri

Sat

Sun

Tue

Wed

Thu

Fri

Sat

Sun

17

Y=

M2

M3

Mn

1
3

4

3

2

7

6

5

5

2

1

8

Residual Vector

2
M1

x 10

1.5
1
0.5
0

Mon

(b) Abilene network traffic data

(a) The system setup

Figure 1: (a) The distributed monitoring system; (b) Data sample (kyk2 ) collected over one week (top); its
projection in residual subspace (bottom). Dashed line represents a threshold for anomaly detection.

Using PCA for centralized volume anomaly detection. As observed by Lakhina et al. [8], due to
the high level of traffic aggregation on ISP backbone links, volume anomalies can often go unnoticed by being ?buried? within normal traffic patterns (e.g., the circle dots shown in the top plot in
Fig 1(b)). On the other hand, they observe that, although, the measured data is of seemingly high
dimensionality (n = number of links), normal traffic patterns actually lie in a very low-dimensional
subspace; furthermore, separating out this normal traffic subspace using PCA (to find the principal
traffic components) makes it much easier to identify volume anomalies in the remaining subspace
(bottom plot of Fig. 1(b)).
As before, let Y be the global m ? n time-series data matrix, centered to have zero mean, and let
y = y(t) denote a n-dimensional vector of measurements (for all links) from a single time step t.
Formally, PCA is a projection method that maps a given set of data points onto principal components ordered by the amount of data variance that they capture. The set of n principal components,
{vi }ni=1 , are defined as:
i?1
X
vi = arg max k(Y ?
Yvj vjT )xk
kxk=1

j=1

1
YT Y. As shown in [9],
and are the n eigenvectors of the estimated covariance matrix A := m
PCA reveals that the Origin-Destination (OD) flow matrices of ISP backbones have low intrinsic
dimensionality: For the Abilene network with 41 links, most data variance can be captured by the
first k = 4 principal components. Thus, the underlying normal OD flows effectively reside in a
(low) k-dimensional subspace of Rn . This subspace is referred to as the normal traffic subspace
Sno . The remaining (n ? k) principal components constitute the abnormal traffic subspace S ab .

Detecting volume anomalies relies on the decomposition of link traffic y = y(t) at any time step into
normal and abnormal components, y = yno +yab , such that (a) yno corresponds to modeled normal
traffic (the projection of y onto Sno ), and (b) yab corresponds to residual traffic (the projection of y
onto Sab ). Mathematically, yno (t) and yab (t) can be computed as
yno (t) = PPT y(t) = Cno y(t) and yab (t) = (I ? PPT )y(t) = Cab y(t)

where P = [v1 , v2 , . . . , vk ] is formed by the first k principal components which capture the dominant variance in the data. The matrix Cno = PPT represents the linear operator that performs
projection onto the normal subspace Sno , and Cab projects onto the abnormal subspace Sab .
As observed in [8], a volume anomaly typically results in a large change to y ab ; thus, a useful metric
for detecting abnormal traffic patterns is the squared prediction error (SPE):

SPE ? kyab k2 = kCab yk2
(essentially, a quadratic residual function). More formally, their proposed algorithm signals a volume anomaly if SPE > Q? , where Q? denotes the threshold statistic for the SPE residual function
at the 1 ? ? confidence level. Such a statistical test for the SPE residual function, known as the
Q-statistic [4], can be computed as a function Q? = Q? (?k+1 , . . . , ?n ) of the (n?k) non-principal
eigenvalues of the covariance matrix A.

Distr. Monitors

?1 - Filter/
Predict

-

?2 - Filter/
Predict

Anomaly

R1 (t)


Y2(t)

?

6

Input: 

Y1(t)

?

R2 (t)

w

?

6

Perturbation
Analysis

q

?


w

Yn (t)

?

?n- Filter/
Predict

Rn (t)

Subspace
Method

Adaptive
?1 , . . . , ? n

Coordinator

Figure 2: Our in-network tracking and detection framework.

3 In-network PCA for anomaly detection
We now describe our version of an anomaly detector that uses distributed tracking and approximate
PCA analysis. A key idea is to curtail the amount of data each monitor sends to the coordinator.
Because our job is to catch anomalies, rather than to track ongoing state, we point out that the
coordinator only needs to have a good approximation of the state when an anomaly is near. It need
not track global state very precisely when conditions are normal. This observation makes it intuitive
that a reduction in data sharing between monitors and the coordinator should be possible. We curtail
the amount of data flow from monitors to the coordinator by installing local filters at each monitor.
These filters maintain a local constraint, and a monitor only sends the coordinator an update of its
data when the constraint is violated. The coordinator thus receives an approximate, or ?perturbed,?
view of the data stream at each monitor and hence of the global state. We use stochastic matrix
perturbation theory to analyze the effect on our PCA-based anomaly detector of using a perturbed
global matrix. Based on this, we can choose the filtering parameters (i.e., the local constraints) so as
to limit the effect of the perturbation on the PCA analysis and on any deterioration in the anomaly
detector?s performance. All of these ideas are combined into a simple, adaptive distributed protocol.
3.1 Overview of our approach
Fig. 2 illustrates the overall architecture of our system. We now describe the functionality at the
monitors and the coordinator. The goal of a monitor is to track its local raw time-series data, and to
decide when the coordinator needs an update. Intuitively, if the time series does not change much,
or doesn?t change in a way that affects the global condition being tracked, then the monitor does not
send anything to the coordinator. The coordinator assumes that the most recently received update
is still approximately valid. The update message can be either the current value of the time series,
or a summary of the most recent values, or any function of the time series. The update serves as a
prediction of the future data, because should the monitor send nothing in subsequent time intervals,
then the coordinator uses the most recently received update to predict the missing values.
For our anomaly detection application, we filter as follows. Each monitor i maintains a filtering
window Fi (t) of size 2?i centered at a value Ri (i.e., Fi (t) = [Ri (t) ? ?i , Ri (t) + ?i ]). At each
time t, the monitor sends both Yi (t) and Ri (t) to the coordinator only if Yi (t) ?
/ Fi , otherwise it
sends nothing. The window parameter ?i is called the slack; it captures the amount the time series
can drift before an update to the coordinator needs to be sent. The center parameter R i (t) denotes
the approximate representation, or summary, of Yi (t). In our implementation, we set Ri (t) equal
to the average of last five signal values observed locally at monitor i. Let t ? denote the time of the
most recent update happens. The monitor needs to send both Y i (t? ) and Ri (t? ) to the coordinator
when it does an update, because the coordinator will use Yi (t? ) at time t? and Ri (t? ) for all t > t?
until the next update arrives. For any subsequent t > t? when the coordinator receives no update
from that monitor, it will use Ri (t? ) as the prediction for Yi (t).
The role of the coordinator is twofold. First, it makes global anomaly-detection decisions based
upon the received updates from the monitors. Secondly, it computes the filtering parameters (i.e., the
slacks ?i ) for all the monitors based on its view of the global state and the condition for triggering an
anomaly. It gives the monitors their slacks initially and updates the value of their slack parameters
when needed. Our protocol is thus adaptive. Due to lack of space we do not discuss here the
method for deciding when slack updates are needed. The global detection task is the same as in the

centralized scheme. In contrast to the centralized setting, however, the coordinator does not have
? instead. The PCA analysis,
an exact version of the raw data matrix Y; it has the approximation Y
? := A ? ?. The
including the computation of Sab is done on the perturbed covariance matrix A
magnitude of the perturbation matrix ? is determined by the slack variables ? i (i = 1, . . . , M ).
3.2 Selection of filtering parameters
A key ingredient of our framework is a practical method for choosing the slack parameters ? i . This
choice is critical because these parameters balance the tradeoff between the savings in data communication and the loss of detection accuracy. Clearly, the larger the slack, the less the monitor needs
to send, thus leading to both more reduction in communication overhead and potentially more information loss at the coordinator. We employ stochastic matrix perturbation theory to quantify the
effects of the perturbation of a matrix on key quantities such as eigenvalues and the eigen-subspaces,
which in turn affect the detection accuracy.
Our approach is as follows. We measure the size of a perturbation using a norm on ?. We derive
an upper bound on the changes to the eigenvalues ?i and the residual subspace Cab as a function of
k?k. We choose ?i to ensure that an approximation to this upper bound on ? is not exceeded. This
in turn ensures that ?i and Cab do not exceed their upper bounds. Controlling these latter terms, we
are able to bound the false alarm probability.
? = Y + W,
Recall that the coordinator?s view of the global data matrix is the perturbed matrix Y
where all elements of the column vector Wi are bounded within the interval [??i , ?i ]. Let ?i and
? i (i = 1, . . . , n) denote the eigenvalues of the covariance matrix A = 1 YT Y and its perturbed
?
m
? Applying the classical theorems of Mirsky and Weyl [15], we obtain bounds
? T Y.
? := 1 Y
version A
m
on the eigenvalue perturbation in terms of the Frobenius norm k.k F and the spectral norm k.k2 of
? respectively:
? := A ? A,
v
u n
uX 1
?
? i ? ?i | ? k?k2
? i ? ?i )2 ? k?kF / n and max|?
eig := t
(1)
(?
i
n
i=1
Applying the sin theorem and results on bounding the angle of projections to subspaces [15] (see
[3] for more details), we can bound the perturbation of the residual subspace C ab in terms of the
Frobenius norm of ?:
?
? ab kF ? 2k?kF
kCab ? C
(2)
?

where ? denotes the eigengap between the k th and (k +1)th eigenvalues of the estimated covariance
?
matrix A.
To obtain practical (i.e., computable) bound on the norms of ?, we derive expectation bounds
instead of worst case bounds. We make the following assumptions on the error matrix W:
1. The column vectors W1 , . . . , Wn are independent and radially symmetric m-vectors.
2. For each i = 1, . . . , n, all elements of column vector Wi are i.i.d. random variables with
mean 0, variance ?i2 := ?i2 (?i ) and fourth moment ?4i := ?4i (?i ).
Note that the independence assumption is imposed only on the error?this by no means implies that
the signals received by different
monitors are statistically independent. Under the above assumption,
?
we can show that k?kF / n is upper bounded in expectation by the following quantity:
v
v
u
u
 n
n
n
n
X
u 1 X
u 1
1 X 4
1 X 4
2
t
T olF = 2
+
?i ?
?i + t
?i +
(?i ? ?i4 ).
(3)
mn i=1
m
n
mn
i=1
i=1
i=1
Similar results can be obtained for the spectral norm as well. In practice, these upper bounds are
very tight because ?1 , . . . , ?n tend to be small compared to the top eigenvalues. Given the tolerable
perturbation T olF , we can use Eqn. (3) to select the slack variables. For example, we can divide the
overall tolerance across monitors either uniformly or in proportion to their observed local variance.

3.3 Guarantee on false alarm probability
Because our approximation perturbs the eigenvalues, it also impacts the accuracy with which the
trigger is fired. Since the trigger condition is kCab yk2 > Q? , we must assess the impact on both
of these terms. We can compute an upper bound on the perturbation of the SPE statistic, SPE =
kCab yk2 , as follows. First, note that
v
?
u n
uX
2k?k
k?
y
k
F
?
?
? k ? kCab yk| ? k(Cab ? Cab )?
? )k ?
|kCab y
yk + kCab (y ? y
+ kCab k2 t
?i2
?
i=1
!v
?
?
u n
uX
2k?kF k?
yk
? ab k + 2k?kF t
?
+ kC
?i2 =: ?1 (?
y).
?
?
i=1
? ab y
? ab y
? k2 ? kCab yk2 | ? ?1 (?
? k + ?1 (?
|kC
y)(2kC
y)) =: ?2 (?
y).

(4)

The dependency of the threshold Q? on the eigenvalues, ?k+1 , . . . , ?n , can be expressed as [4]:
# h1
" p
c? 2?2 h20
?2 h0 (h0 ? 1) 0
+1+
,
(5)
Q? = ?1
?1
?21
where c? is the (1 ? ?)-percentile of the standard normal distribution, h0 = 1 ?
Pn
i
j=k+1 ?j for i = 1, 2, 3.

2?1 ?3
,
3?22

?i =

To assess the perturbation in false alarm probability, we start by considering the following random
variable c derived from Eqn. (5):
?1 [(SPE/?1 )h0 ? 1 ? ?2 h0 (h0 ? 1)/?21 ]
p
.
(6)
c=
2?2 h20

The random variable c essentially normalizes the random quantity kC ab yk2 and is known to approximately follow a standard normal distribution [5]. The false alarm probability in the centralized
system is expressed as


Pr kCab yk2 > Q? = Pr [c > c? ] = ?,
where the lefthand term of this equation is conditioned upon the SPE statistics being inside the
??.
? ab y
? k2 > Q
normal range. In our distributed setting, the anomaly detector fires a trigger if k C
We thus only observe a perturbed version c? for the random variable c. Let ? c denote the bound on
|?
c ? c|. The deviation of the false alarm probability in our approximate detection scheme can then
be approximated as P (c? ? ?c < U < c? + ?c ), where U is a standard normal random variable.

4 Evaluation
We implemented our algorithm and developed a trace-driven simulator to validate our methods. We
used a one-week trace collected from the Abilene network1. The traces contains per-link traffic
loads measured every 10 minutes, for all 41 links of the Abilene network. With a time unit of 10
minutes, data was collected for 1008 time units. This data was used to feed the simulator. There
are 7 anomalies in the data that were detected by the centralized algorithm (and verified by hand
to be true anomalies). We also injected 70 synthetic anomalies into this dataset using the method
described in [8], so that we would have sufficient data to compute error rates. We used a threshold
Q? corresponding to an 1 ? ? = 99.5% confidence level. Due to space limitations, we present
results only for the case of uniform monitor slack, ?i = ?.
The input parameter for our algorithm is the tolerable relative error of theqeigenvalues (?relative
P 2
eigen-error? for short), which acts as a tuning knob. (Precisely, it is T ol F / n1
?i , where T olF
is defined in Eqn. (3).) Given this parameter and the input data we can compute the filtering slack ?
for the monitors using Eqn. (3). We then feed in the data to run our protocol in the simulator with the
1

Abilene is an Internet2 high-performance backbone network that interconnects a large number of universities as well as a few other research institutes.

7

Fal. Alarm Rate

2

0

0.005

0.01

0.015

0.015

(a)

0.02

0.025

0.03

0.01
0.005

Rel. Threshold Error

0

0

0.005

0.01

0.1

0.015

(b)

0.02

0.025

0.03

0.05

0

0

0.005

0.01

0.015

(c)

0.02

0.025

0.03

Missed Detec. Rate

4

0
Rel. Eigen Error

x 10

0.4

Upper Bound
Actual Accrued

0.3
0.2
0.1
0

0

0.005

0.01

0.015

0.02

0.025

0.03

0

0.005

0.01

0.015

0.02

0.025

0.03

0

0.005

0.01

0.015

0.02

0.025

0.03

0.1

(d)

0.05

Comm. Overhead

Slack

6

0
1

(e)

0.5

0

(f)

Figure 3: In all plots the x-axis is the relative eigen-error. (a) The filtering slack. (b) Actual accrued eigenerror. (c) Relative error of detection threshold. (d) False alarm rates. (e) Missed detection rates. (f) Communication overhead.
computed ?. The simulator outputs a set of results including: 1) the actual relative eigen errors and
the relative errors on the detection threshold Q? ; 2) the missed detection rate, false alarm rate and
communication cost achieved by our method. The missed-detection rate is defined as the fraction of
missed detections over the total number of real anomalies, and the false-alarm rate as the fraction
of false alarms over the total number of detected anomalies by our protocol, which is ? (defined in
Sec. 3.3) rescaled as a rate rather than a probability. The communication cost is computed as the
fraction of number of messages that actually get through the filtering window to the coordinator.
The results are shown in Fig. 3. In all plots, the x-axis is the relative eigen-error. In Fig. 3(a) we plot
the relationship between the relative eigen-error and the filtering slack ? when assuming filtering
errors are uniformly distributed on interval [??, ?]. With this model, the relationship between the
2
relative eigen-error and the slack is determined by a simplified version of Eqn. (3) (with all ? i2 = ?3 ).
The results make intuitive sense. As we increase our error tolerance, we can filter more at the monitor
and send less to the coordinator. The slack increases almost linearly with the relative eigen-error
because the first term in the right hand side of Eqn. (3) dominates all other terms.
In Fig.
we compare the relative eigen-error to the actual accrued relative eigen-error (defined as
q3(b)
P 2
1
?i , where eig is defined in Eqn (1)). These were computed using the slack parameters
eig / n
? as computed by our coordinator. We can see that the real accrued eigen-errors are always less than
the tolerable eigen errors. The plot shows a tight upper bound, indicating that it is safe to use our
model?s derived filtering slack ?. In other words, the achieved eigen-error always remains below the
requested tolerable error specified as input, and the slack chosen given the tolerable error is close
to being optimal. Fig. 3(c) shows the relationship between the relative eigen-error and the relative
error of detection threshold Q? 2 . We see that the threshold for detecting anomalies decreases as we
tolerate more and more eigen-errors. In these experiments, an error of 2% in the eigenvalues leads
to an error of approximately 6% in our estimate of the appropriate cutoff threshold.
We now examine the false alarm rates achieved. In Fig. 3(d) the curve with triangles represents
the upper bound on the false alarm rate as estimated by the coordinator. The curve with circles
is the actual accrued false alarm rate achieved by our scheme. Note that the upper bound on the
false alarm rate is fairly close to the true values, especially when the slack is small. The false alarm
rate increases with increasing eigen-error because as the eigen-error increases, the corresponding
detection threshold Q? will decrease, which in turn causes the protocol to raise an alarm more
? rather than the relative threshold difference, we would obviously see a
often. (If we had plotted Q
2

? k+1 , . . . , ?
?n .
? ? /Q? , where Q
? ? is computed from ?
Precisely, it is 1 ? Q

? with increasing eigen-error.) We see in Fig. 3(e) that the missed detection rates remain
decreasing Q
below 4% for various levels of communication overhead.
The communication overhead is depicted in Fig. 3(f). Clearly, the larger the errors we can tolerate,
the more overhead can be reduced. Considering these last three plots (d,e,f) together, we observe
several tradeoffs. For example, when the relative eigen-error is 1.5%, our algorithm reduces the data
sent through the network by more than 90%. This gain is achieved at the cost of approximately a
4% missed detection rate and a 6% false alarm rate. This is a large reduction in communication for
a small increase in detection error. These initial results illustrate that our in-network solution can
dramatically lower the communication overhead while still achieving high detection accuracy.

5 Conclusion
We have presented a new algorithmic framework for network anomaly detection that combines distributed tracking with PCA analysis to detect anomalies with far less data than previous methods.
The distributed tracking consists of local filters, installed at each monitoring site, whose parameters
are selected based upon global criteria. The idea is to track the local monitoring data only enough so
as to enable accurate detection. The local filtering reduces the amount of data transmitted through
the network but also means that anomaly detection must be done with limited or partial views of the
global state. Using methods from stochastic matrix perturbation theory, we provided an analysis for
the tradeoff between the detection accuracy and the data communication overhead. We were able
to control the amount of data overhead using the the relative eigen-error as a tuning knob. To the
best of our knowledge, this is the first result in the literature that provides upper bounds on the false
alarm rate of network anomaly detection.

References
[1] BAI , Z.-J., C HAN , R. AND L UK , F. Principal component analysis for distributed data sets with updating.
In Proceedings of International workshop on Advanced Parallel Processing Technologies (APPT), 2005.
[2] D REGER , H., F ELDMANN , A., PAXSON , V. AND S OMMER , R. Operational experiences with highvolume network intrusion detection. In Proceedings of ACM Conference on Computer and Communications
Security (CCS), 2004.
[3] H UANG , L., N GUYEN , X., G AROFALAKIS , M., J ORDAN , M., J OSEPH , A. AND TAFT, N. In-network
PCA and anomaly detection. Technical Report No. UCB/EECS-2007-10, EECS Department, UC Berkeley.
[4] JACKSON , J. E. AND M UDHOLKAR , G. S. Control procedures for residuals associated with principal
component analysis. In Technometrics, 21(3):341-349, 1979.
[5] J ENSEN , D. R. AND S OLOMON , H. A Gaussian approximation for the distribution of definite quadratic
forms. In Journal of the American Statistical Association, 67(340):898-902, 1972.
[6] K ERALAPURA , R., C ORMODE , G. AND R AMAMIRTHAM , J. Communication-efficient distributed monitoring of thresholded counts. In Proceedings of ACM International Conference on Management of Data
(SIGMOD), 2006.
[7] K REIDL , P. O., W ILLSKY, A. Inference with minimal communication: A decision-theoretic variational
approach. In Proceedings of Neural Information Processing Systems (NIPS), 2006.
[8] L AKHINA , A., C ROVELLA , M. AND D IOT, C. Diagnosing network-wide traffic anomalies. In Proceedings
of ACM Conference of the Special Interest Group on Data Communication (SIGCOMM), 2004.
[9] L AKHINA , A., PAPAGIANNAKI , K., C ROVELLA , M., D IOT, C., KOLACZYK , E. D. AND TAFT, N.
Structural analysis of network traffic flows. In Proceedings of International Conference on Measurement
and Modeling of Computer Systems (SIGMETRICS), 2004.
[10] L EVCHENKO , K., PATURI , R. AND VARGHESE , G. On the difficulty of scalably detecting network
attacks. In Proceedings of ACM Conference on Computer and Communications Security (CCS), 2004.
[11] N GUYEN , X., WAINWRIGHT, M. AND J ORDAN , M. Nonparametric decentralized detection using kernel
methods. In IEEE Transactions on Signal Processing, 53(11):4053-4066, 2005.
[12] PADMANABHAN , V. N., R AMABHADRAN , S., AND PADHYE , J. Netprofiler: Profiling wide-area networks using peer cooperation. In Proceedings of International Workshop on Peer-to-Peer Systems, 2005.
[13] P REDD , J.B., K ULKARNI , S.B., AND P OOR , H.V. Distributed learning in wireless sensor networks. In
IEEE Signal Processing Magazine, 23(4):56-69, 2006.
[14] Q U , Y., O STROUCHOVZ , G., S AMATOVAZ , N AND G EIST, A. Principal component analysis for dimension reduction in massive distributed data sets. In Proceedings of IEEE International Conference on Data
Mining (ICDM), 2002.
[15] S TEWART, G. W., AND S UN , J.-G. Matrix Perturbation Theory. Academic Press, 1990.
[16] Y EGNESWARAN , V., BARFORD , P., AND J HA , S. Global intrusion detection in the domino overlay
system. In Proceedings of Network and Distributed System Security Symposium (NDSS), 2004.
[17] Z HANG , Y., G E , Z.-H., G REENBERG , A., AND ROUGHAN , M. Network anomography. In Proceedings
of Internet Measurement Conference (IMC), 2005.


----------------------------------------------------------------

title: 4299-group-anomaly-detection-using-flexible-genre-models.pdf

Group Anomaly Detection using Flexible Genre Models

Liang Xiong
Machine Learning Department,
Carnegie Mellon University
lxiong@cs.cmu.edu

Barnab?as P?oczos
Robotics Institute,
Carnegie Mellon University
bapoczos@cs.cmu.edu

Jeff Schneider
Robotics Institute,
Carnegie Mellon University
schneide@cs.cmu.edu

Abstract
An important task in exploring and analyzing real-world data sets is to detect
unusual and interesting phenomena. In this paper, we study the group anomaly
detection problem. Unlike traditional anomaly detection research that focuses on
data points, our goal is to discover anomalous aggregated behaviors of groups of
points. For this purpose, we propose the Flexible Genre Model (FGM). FGM is
designed to characterize data groups at both the point level and the group level so
as to detect various types of group anomalies. We evaluate the effectiveness of
FGM on both synthetic and real data sets including images and turbulence data,
and show that it is superior to existing approaches in detecting group anomalies.

1

Introduction

Anomaly detection is a crucial problem in processing large-scale data sets when our goal is to
find rare or unusual events. These events can either be outliers that should be ignored or novel
observations that could lead to new discoveries. See [1] for a recent survey of this field. Traditional
research often focuses on individual data points. In this paper, however, we are interested in finding
group anomalies, where a set of points together exhibit unusual behavior. For example, consider
text data where each article is considered to be a set (group) of words (points). While the phrases
?machine learning? or ?gummy bears? will not surprise anyone on their own, an article containing
both of them might be interesting.
We consider two types of group anomalies. A point-based group anomaly is a group of individually
anomalous points. A distribution-based anomaly is a group where the points are relatively normal,
but as a whole they are unusual. Most existing work on group anomaly detection focuses on pointbased anomalies. A common way to detect point-based anomalies is to first identify anomalous
points and then find their aggregations using scanning or segmentation methods [2, 3, 4]. This
paradigm clearly does not work well for distribution-based anomalies, where the individual points
are normal. To handle distribution-based anomalies, we can design features for groups and then treat
them as points [5, 6]. However, this approach relies on feature engineering that is domain specific
and can be difficult. Our contribution is to propose a new method (FGM) for detecting both types of
group anomalies in an integral way.
Group anomalies exist in many real-world problems. In astronomical studies, modern telescope
pipelines1 produce descriptions for a vast amount of celestial objects. Having these data, we want
to pick out scientifically valuable objects like planetary nebulae, or special clusters of galaxies that
could shed light on the development of the universe [7]. In physics, researchers often simulate the
motion of particles or fluid. In these systems, a single particle is seldom interesting, but a group of
particles can exhibit interesting motion patterns like the interweaving of vortices. Other examples
are abundant in the fields of computer vision, text processing, time series and spatial data analysis.
1

For example, the Sloan Digital Sky Survey (SDSS), http://www.sdss.org

1

We take a generative approach to address this problem. If we have a model to generate normal
data, then we can mark the groups that have small probabilities under this model as anomalies.
Here we make the ?bag-of-points? assumption, i.e., points in the same group are unordered and
exchangeable. Under this assumption, mixture models are often used to generate the data due to
De Finetti?s theorem [8]. The most famous class of mixture models for modeling group data is
the family of topic models [9, 10]. In topic models, distributions of points in different groups are
mixtures of components (?topics?), which are shared among all the groups.
Our proposed method is closely related to the class of topic models, but it is designed specifically for
the purpose of detecting group anomalies. We use two levels of concepts/latent variables to describe
a group. At the group level, a flexible structure based on ?genres? is used to characterize the topic
distributions so that complex normal behaviors are allowed and can be recognized. At the point level,
each group has its own topics to accommodate and capture the variations of points? distributions
(while global topic information is still shared among groups). We call this model the Flexible Genre
Model (FGM). Given a group of points, we can examine whether or not it conforms to the normal
behavior defined by the learned genres and topics. We will also propose scoring functions that can
detect both point-based and distribution-based group anomalies. Exact inference and learning for
FGM is intractable, so we resort to approximate methods. Inference for the FGM model will be
done by Gibbs sampling [11], which is efficient and simple to implement due to the application of
conjugate distributions. Single-sample Monte Carlo EM [12] is used to learn parameters based on
samples produced by the Gibbs sampler.
We demonstrate the effectiveness of the FGM on synthetic and on real-world data sets including
scene images and turbulence data. Empirical results show that FGM is superior to existing approaches in finding group anomalies.
The paper is structured as follows. In Section 2 we review related work and discuss the limitations
with existing algorithms and why a new method is needed for group anomaly detection. Section 3 introduces our proposed model. The parameter learning of our model and inference on it are explained
in Section 4. Section 5 describes how to use our method for group anomaly detection. Experimental
results are shown in Section 6. We finish that paper by drawing conclusions (Section 7).

2

Background and Related Work

In this section, we provide background about topic models and explain the limitation of existing
methods in detecting group anomalies. For intuition, we introduce the problem in the context of
detecting anomalous images, rare galaxy clusters, and unusual motion in a dynamic fluid simulation.
We consider a data set with M pre-defined groups G1 , . . . , GM (e.g. spatial clusters of galaxies, patches in an image, or fluid motions in a local region). Group Gm contains Nm points
(galaxies, image patches, simulation grid points). The features of these points are denoted by
xm = {xm,n 2 Rf }n=1,...,Nm , where f is the dimensionality of the points? features. These would
be spectral features of each galaxy, SIFT features of each image patch, or velocities at each grid
point of a simulation. We assume that points in the same group are unordered and exchangeable.
Having these data, we ask the question whether in group Gm the distribution of features xm looks
anomalous.
Topic models such as Latent Dirichlet Allocation (LDA) [10] are widely used to model data having
this kind of group structure. The original LDA model was proposed for text processing. It represents
the distribution of points (words) in a group (document) as a mixture of K global topics 1 , . . . K ,
each of which is a distribution (i.e., i 2 Sf , where Sf is the f -dimensional probability simplex).
Let M(?) be the multinomial distribution parameterized by ? 2 SK and Dir(?) be the Dirichlet
distribution with parameter ? 2 RK
+ . LDA generates the mth group by first drawing its topic
distribution ?m from the prior distribution Dir(?). Then for each point xmn in the mth group
it draws one of the K topics from M(?m ) (i.e., zmn ? M(?m )) and then generates the point
according to this topic (xmn ? M( zmn )).

In our examples, the topics can represent galaxy types (e.g. ?blue?,?red?, or ?emissive?, with
K = 3), image features (e.g. edge detectors representing various orientations), or common motion patterns in the fluid (fast left, slow right, etc). Each point in the group has its own topic. We
consider points that have multidimensional continuous feature vectors. In this case, topics can be
2

modeled by Gaussian distributions, and each point is generated from one of the K Gaussian topics.
At a higher level, a group is characterized by the distribution of topics ?m , i.e., the proportion of
different types in the group Gm . The concepts of topic and topic distribution help us define group
anomalies: a point-based anomaly contains points that do not belong to any of the normal topics
and a distribution-based anomaly has a topic distribution ?m that is uncommon.
Although topic models are very useful in estimating the topics and topic distributions in groups, the
existing methods are incapable of detecting group anomalies comprehensively. In order to detect
anomalies, the model should be flexible enough to enable complex normal behaviors. For example,
it should be able to model complex and multi-modal distributions of the topic distribution ?. LDA,
however, only uses a single Dirichlet distribution to generate topic distributions, and cannot effectively define what normal and abnormal distributions should be. It also uses the same K topics for
every group, which makes groups indifferentiable when looking at their topics. In addition, these
shared topics are not adapted to each group either.
The Mixture of Gaussian Mixture Model (MGMM) [13] firstly uses topic modeling for group
anomaly detection. It allows groups to select their topic distributions from a dictionary of multinomials, which is learned from data to define what is normal. [14] employed the same idea but
did not apply their model to anomaly detection. The problem of using multinomials is that it does
not consider the uncertainty of topic distributions. The Theme Model (ThM) [15] lets a mixture
of Dirichlets generate the topic distributions and then uses the memberships in this mixture to do
clustering on groups. This idea is useful for modeling group-level behaviors but fails to capture
anomalous point-level behaviors. The topics are still shared globally in the same way as in LDA. In
contrast, [16] proposed to use different topics for different groups in order to account for the burstiness of the words (points). These adaptive topics are useful in recognizing point-level anomalies,
but cannot be used to detect anomalous behavior at the group level. For the group anomaly detection
problem we propose a new method, the Flexible Genre Model, and demonstrate that it is able to cope
with the issues mentioned above and performs better than the existing state-of-the-art algorithms.

3

Model Specification

The flexible genre model (FGM) extends LDA such that the generating processes of topics and topic
distributions can model more complex distributions. To achieve this goal, two key components are
added. (i) To model the behavior of topic distributions, we use several ?genres?, each of which is a
typical distribution of topic distributions. (ii) We use ?topic generators? to generate adaptive topics
for different groups. We will also use them to learn how the normal topics have been generated. The
generative process of FGM is presented in Algorithm 1. A graphical representation of FGM is given
in Figure 1.
Algorithm 1 Generative process of FGM
for Groups m = 1 to M do
? Draw a genre {1, . . . , T } 3 ym ? M(?).
? Draw a topic distribution according to the genre ym : SK 3 ?m ? Dir(?ym ).
? Draw K topics { m,k ? P ( m,k |?k )}k=1,...,K .
for Points n = 1 to Nm do
? Draw a topic membership {1, . . . , K} 3 zm,n ? M(?m ). [ m,zmn topic will be active.]
? Generate a point xm,n ? P (xm,n | m,zmn ).
end for
end for
We assume there are T genres and K topics. M(?) denotes the global distribution of genres. Each
genre is a Dirichlet distribution for generating the topic distributions, and ? = {?t }t=1,...,T is the
set of genre parameters. Each group has K topics m = { m,k }k=1,...,K . The ?topic generators?,
? = {?k }, {P (?|?k )}k=1,...,K , are the global distributions for generating the corresponding topics.
Having the topic distribution ?m and the topics { m,k }, points are generated as in LDA.
By comparing FGM to LDA, the advantages of FGM become evident. (i) In FGM, each group has a
latent genre attribute ym , which determines how the topic distribution in this group should look like
(Dir(?ym )), and (ii) each group has its own topics { m,k }K
k=1 , but they are still tied through the
3

?
?

?m

ym

?

?

K

T

M

zmn

xmn

K

N

Figure 1: The Flexible Genre Model (FGM).
global distributions P (?|?). Thus, the topics can be adapted to local group data, but the information
is still shared globally. Moreover, the topic generators P (?|?) determine how the topics { m,k }
should look like. In turn, if a group uses unusual topics to generate its points, it can be identified.
To handle real-valued multidimensional data, we set the point-generating distributions (i.e., the topics) to be Gaussians, P (xm,n | m,k ) = N (xm,n | m,k ), where m,k = {?m,k , ?m,k } includes
the mean and covariance parameters. For computational convenience, the topic generators are
Gaussian-Inverse-Wishart (GIW) distributions, which are conjugate to the Gaussian topics. Hence
?k = {?0 , ?0 , 0 , ?0 } parameterizes the GIW distribution [17] (See the supplementary materials
for more details). Let ? = {?, ?, ?} denote the model parameters. We can write the complete
likelihood of data and latent variables in group Gm under FGM as follows:
P (Gm , ym , ?m ,

m |?)

= M(ym |?)Dir(?m |?ym )

Y

k

GIW (

m,k |?k )

Y

n

M(zmn |?m )N (xmn |

m,zmn ).

By integrating out ?m , m and summing out ym , z, we get the marginal likelihood of Gm :
X Z
Y
YX
P (Gm |?) =
?t Dir(?m |?t )
GIW ( m,k |?k )
?mk N (xmn | m,k )d m d?m .
t

?m ,

m

n

k

k

Finally, the data-set?s likelihood is just the product of all groups? likelihoods.

4

Inference and Learning

To learn FGM, we update the parameters ? to maximize the likelihood of data. The inferred latent
states?including the topic distributions ?m , the topics m , and the topic and genre memberships
zm , ym ?can be used for detecting anomalies and exploring the data. Nonetheless, the inference
and learning in FGM is intractable, so we train FGM using an approximate method described below.
4.1

Inference

The approximate inference of the latent variables can be done using Gibbs sampling [11]. In Gibbs
sampling, we iteratively update one variable at a time by drawing samples from its conditional
distribution when all the other parameters are fixed. Thanks to the use of conjugate distributions,
Gibbs sampling in FGM is simple and easy to implement. The sampling distributions of the latent
variables in group m are given below. We use P (?| ?) to denote the distribution of one variable
conditioned on all the others. For the genre membership ym we have that:
P (ym = t| ?) / P (?m |?t )P (ym = t|?) = ?t Dir(?m |?t ).

For the topic distribution ?m :

P (?m | ?) / P (zm |?m )P (?m |?, ym ) = M(zm |?m )Dir(?m |?ym ) = Dir(?ym + nm ),

where nm denotes the histogram of the K values in vector zm . The last equation follows from the
Dirichlet-Multinomial conjugacy. For m,k , the kth topic in group m, one can find that:
P(

m,k |

?) / P (x(k)
m |

m,k )P ( m,k |?k )

= N (x(k)
m |
4

m,k )GIW ( m,k |?k )

= GIW (

0
m,k |?k ),

(k)

where xm are points in group Gm from topic k, i.e., zm,n = k. The last equation follows from
the Gaussian-Inverse-Wishart-Gaussian conjugacy. ?k0 is the parameter of the posterior GIW distri(k)
bution given xm ; its exact form can be found in the supplementary material. For zmn , the topic
membership of point n in group m is as follows:
P (zmn = k| ?) / P (xmn |zmn = k,
4.2

m )P (zmn

= k|?m ) = ?m,k N (xmn |

m,k ).

Learning

Learning the parameters of FGM helps us identify the groups? and points? normal behaviors. Each of
the genres ? = {?t }t=1,...,T captures one typical distribution of topic distributions as ? ? Dir(?t ).
The topic generators ? = {?k }k=1,...,K determine how the normal topics { m,k } should look like.
We use single-sample Monte Carlo EM [12] to learn parameters from the samples provided by
the Gibbs sampler. Given sampled latent variables, we update the parameters to their maximum
likelihood estimations (MLE): we learn ? from y and ?; ? from ; and ? from y.
? can easily be estimated from the histogram of y?s. ?t is learned by the MLE of a Dirichlet distribution given the multinomials {?m |ym = t, m = 1, . . . , M } (i.e., the topic distributions having
genre t), which can be solved using the Newton?Raphson method [18]. The kth topic-generator?s
parameter ?k = {?0k , ?0k , 0k , ?0k } is the MLE of a GIW distribution given the parameters
{ m,k = (?m,k , ?m,k )}m=1,...,M (the kth topics of all groups). We have derived an efficient solution for this MLE problem. The details can be found in the supplementary material.
The overall learning algorithm works by repeating the following procedure until convergence: (1)
do Gibbs sampling to infer the states of the latent variables; (2) update the model parameters using
the estimations above. To select appropriate values for the parameters T and K (the number of
genres and topics), we can apply the Bayesian information criterion (BIC) [19], or use the values
that maximize the likelihood of a held-out validation set.

5

Scoring Criteria

The learned FGM model can easily be used for anomaly detection on test data. Given a test group,
we first infer its latent variables including the topics and the topic distribution. Then we treat these
latent states as the group?s characteristicsand examine if they are compatible with the normal behaviors defined by the FGM parameters.
Point-based group anomalies can be detected by examining the topics of the groups. If a group
contains anomalous points with rare feature values xmn , then the topics { m,k }K
k=1 that generate these points will deviate from the normal behavior defined by the topic generators ?. Let
QK
P ( m |?) = k=1 GIW ( m,k |?k ). The point-based anomaly score (PB score) of group Gm is
Z
E m [ ln P ( m |?)] =
P ( m |?, Gm ) ln P ( m |?)d m .
m

The posterior P ( m |?, Gm ) can again be approximated using Gibbs sampling, and the expectation
can be done by Monte Carlo integration.
Distribution-based group anomalies can be detected by examining the topic distributions. The genres
{?t }t=1,...,T capture the typical distributions of topic distributions. If a group?s topic distribution
?m is unlikely to be generated from any of these genres, we call it anomalous. Let P (?m |?) =
PT
t=1 ?t Dir(?m |?t ). The distribution-based anomaly score (DB score) of group Gm is defined as
Z
E?m [ ln P (?m |?)] =
P (?m |?, Gm ) ln P (?m |?)d?m .
(1)
?m

Again, this expectation can be approximated using Gibbs sampling and Monte Carlo integration.
Using a combination of the point-based and distribution-based scores, we can detect both pointbased and distribution-based group anomalies.
5

6

Experiments

In this section we provide empirical results produced by FGM on synthetic and real data. We show
that FGM outperforms several sate-of-the-art competitors in the group anomaly detection task.
6.1

Synthetic Data

In the first experiment, we compare FGM with the Mixture of Gaussian Mixture Model
(MGMM) [13] and with an adaptation of the Theme Model (ThM) [15] on synthetic data sets. The
original ThM handles only discrete data and was proposed for clustering. To handle continuous data
and detect anomalies, we modified it by using Gaussian topics and applied the distribution-based
anomaly scoring function (1). To detect both distribution-based and point-based anomalies, we can
use the data?s likelihood under ThM as the scoring function.
Using the synthetic data sets described below, we can demonstrate the behavior of the different
models and scoring functions. We generated the data using 2-dimensional GMMs as in [13]. Here
each group has a GMM to generate its points. All GMMs share three Gaussian components with
covariance 0.2 ? I2 and centered at points ( 1.7, 1), (1.7, 1), and (0, 2), respectively. A group?s
mixing weights are randomly chosen from w1 = [0.33, 0.33, 0.33] or w2 = [0.84, 0.08, 0.08]. Thus,
a group is normal if its points are sampled from these three Gaussians, and their mixing weights are
close to either w1 or w2 . To test the detectors, we injected both point-based and distribution-based
anomalies. Point-based anomalies were groups of points sampled from N ((0, 0), I2 ). Distributionbased anomalies were generated by GMMs consisting of normal Gaussian components but with
mixing weights [0.33, 0.64, 0.03] and [0.08, 0.84, 0.08], which were different from w1 and w2 . We
generated M = 50 groups, each of which had Nm ? P oisson(100) points. One point-based
anomalous group and two distribution-based anomalous groups were injected into the data set.
The detection results of MGMM, ThM, and FGM are shown in Fig. 2. We show 12 out of the
50 groups. Normal groups are surrounded by black solid boxes, point-based anomalies have green
dashed boxes, and distribution-based anomalies have red/magenta dashed boxes. Points are colored by the anomaly scores of the groups (darker color means more anomalous). An ideal detector
would make dashed boxes? points dark and solid boxes? points light gray. We can see that all the
MGMM

ThM

FGM

ThM ? Likelihood

Figure 2: Detection results on synthetic data.
models can find the distribution-based anomalies since they are able to learn the topic distributions.
However, MGMM and ThM miss the point-based anomaly. The explanation is simple; the anomalous points are distributed in the middle of the topics, thus the inferred topic distribution is around
[0.33, 0.33, 0.33], which is exactly w1 . As a result, MGMM and ThM infer this group to be normal,
although it is not. This example shows one possible problem of scoring groups based on topic distributions only. On the contrary, using the sum of point-based and distribution-based scores, FGM
found all of the group anomalies thanks to its ability to characterize groups both at the point-level
and the group-level. We also show the result of scoring the groups by the ThM likelihood. Only
point anomalies are found. This is because the data likelihood under ThM is dominated by the
anomalousness of points, thus a few eccentric points will overshadow group-level behaviors.
Figures 3(a) ? 3(c) show the density estimations given by MGMM, ThM, and FGM, respectively, for
the point-based anomalous group. We can see that FGM gives a better estimation due to its adaptive
topics, while MGMM and ThM are limited to use their global topics. Figure 3(d) shows the learned
6

PT
genres visualized as the distribution t=1 ?t Dir(?|?t ) on the topic simplex. This distribution summarizes the normal topic distributions in this data set. Observe that the two peaks in the probability
simplex are very close to w1 and w2 indeed.

(a)

(b)

(c)

(d)

Figure 3: (a),(b),(c) show the density of the point-based anomaly estimated by MGMM, ThM, and
FGM respectively. In MGMM and ThM, topics must be shared globally, therefore their perform
badly. (d) The genres in the synthetic data set learned by FGM.
6.2

Image Data

In this experiment we test the performance of our method on detecting anomalous scene images. We
use the data set from [15]. We selected the first 100 images from categories ?mountain?, ?coast?,
and ?inside city?. These 300 images are randomly divided: 80% are used for training and the rest
for testing. We created anomalies by stitching random normal test images from different categories.
For example, an anomaly may be a picture that is half mountain and half city street. These anomalies are challenging since they have the same local patches as the normal images. We mixed the
anomalies with normal test images and asked the detectors to find them. Some examples are shown
in Fig. 4(a). The images are represented as in [15]: we treat each of them as a group of local points.
On each image we randomly sample 100 patches, on each patch extract the 128-dimensional SIFT
feature [20], and then reduce its dimension to 2 using PCA. Points near the stitching boundaries are
discarded to avoid boundary artifacts.
We compare FGM with several other methods. We implemented a simple detector based on Gaussian
mixture models (GMM); it is able to detect point-based anomalies. This method fits a GMM to all
data points, calculates the points? scores as their likelihood under this GMM, and finally scores
a group by averaging these numbers. To be able to detect distribution-based anomalies, we also
implemented two other competitors. The first one, called LDA-KNN, uses LDA to estimate the topic
distributions of the groups and treats these topic distributions (vector parameters of multinomials)
as the groups? features. Then, a k-nearest neighbor (KNN) based point detector [21] is used to score
the groups? features. The second method uses symmetrized Kullback-Leibler (KL) divergences
between densities (DD). For each group, DD uses a GMM to estimate the distribution of its points.
Then KL divergences between these GMMs are estimated using Monte Carlo method, and then the
KNN-based detector is used to find anomalous GMMs (i.e., groups).
For all algorithms we used K = 8 topics and T = 6 genres as it was suggested by BIC searches. We
set ?0 = ?0 = 200 for FGM. The performance is measured by the area under the ROC curve (AUC)
of retrieving the anomalies from the test set. In the supplementary material we also show results
using the average precision performance measure. The performances from 30 random runs are
shown in Figure 4(b). GMM cannot detect the group anomalies that do not have anomalous points.
The performance of LDA-KNN was also close to the 50% random baseline. A possible reason is
that the KNN detector did not perform well in the K = 8 dimensional space. MGMM, ThM, and
FGM show improvements over the random baseline, and FGM achieves significantly better results
than others: the paired t-test gives a p-value of 1.6 ? 10 5 for FGM vs. ThM. We can also see that
the DD method performs poorly possibly due to many error-prone steps including fitting the GMMs
and estimating divergences using Monte Carlo method.
6.3

Turbulence Data

We present an explorative study of detecting group anomalies on turbulence data from the JHU Turbulence Database Cluster2 (TDC) [22]. TDC simulates fluid motion through time on a 3-dimensional
grid, and here we perform our experiment on a continuous 1283 sub-grid. In each time step and each
2

http://turbulence.pha.jhu.edu

7

0.75
0.7
0.65

AUC

0.6
0.55
0.5
0.45
0.4
0.35
P

(a) Sample images and stitched anomalies

LDA?KNN MGMM

ThM

FGM?DB

DD

(b) Detection performance

Figure 4: Detection of stitched images. (a) Images samples. Green boxes (first row) contain natural
images, and yellow boxes (second row) contain stitched anomalies. (b) The detection AUCs.
vertex of the grid, TDC records the 3-dimensional velocity of the fluid. We consider the vertices in a
local cubic region as a group, and the goal is to find groups of vertices whose velocity distributions
(i.e. moving patterns) are unusual and potentially interesting. The following steps were used to extract the groups: (1) We chose the {(8i, 8j, 8k)}i,j,k grid points as centers of our groups. Around
these centers, the points in 73 sized cubes formed our groups. (2) The feature of a point in the cube
was its velocity relative to the velocity at its cube?s center point. After these pre-processing steps,
we had M = 4 096 groups, each of which had 342 3-dimensional feature vectors.
We applied MGMM, ThM, and FGM to find anomalies in this group data. T = 4 genres and K = 6
topics were used for all methods. We do not have a groundtruth for anomalies in this data set.
However, we can compute the ?vorticity score? [23] for each vertex that indicates the tendency of
the fluid to ?spin?. Vortices and especially their interactions are uncommon and of great interest in
the field of fluid dynamics. This vorticity can be considered as a hand crafted anomaly score based
on expert knowledge of this fluid data. We do not want an anomaly detector to match this score
perfectly because there are other ?non-vortex? anomalous events it should find as well. However,
we do think higher correlation with this score indicates better anomaly detection performance.
Figure 5 visualizes the anomaly scores of FGM and the vorticity. We can see that these pictures are
highly correlated, which implies that FGM was able to find interesting turbulence activities based on
velocity only and without using the definition of vorticity or any other expert knowledge. Correlation
values between vorticity and the MGMM, ThM, and FGM scores from 20 random runs are displayed
in Fig. 5(c), showing that FGM is better at finding regions with high vorticity.
Correlation with Vorticity

0.54
0.52
0.5
0.48
0.46
0.44
0.42
MGMM

(a) FGM-DB Score

(b) Vorticity

ThM

FGM?DB

(c)

Figure 5: Detection results for the turbulence data. (a) & (b) FGM-DB anomaly score and vorticity
visualized on one slice of the cube. (c) Correlations of the anomaly scores with the vorticity.

7

Conclusion

We presented the generative Flexible Genre Model (FGM) for the group anomaly detection problem.
Compared to traditional topic models, FGM is able to characterize groups? behaviors at multiple
levels. This detailed characterization makes FGM an ideal tool for detecting different types of group
anomalies. Empirical results show that FGM achieves better performance than existing approaches.
In the future, we will examine other possibilities as well. For model selection, we can extend FGM
by using nonparametric Bayesian techniques such as hierarchical Dirichlet processes [24]. It would
also be interesting to study structured groups in which the exchangeability assumption is not valid.
8

References
[1] Varun Chandola, Arindam Banerjee, and Vipin Kumar. Anomaly detection: A survey. ACM
Computing Surveys, 41-3, 2009.
[2] Geoffrey G. Hazel. Multivariate gaussian MRF for multispectral scene segmentation and
anomaly detection. IEEE Trans. Geoscience and Remote Sensing, 38-3:1199 ? 1211, 2000.
[3] Kaustav Das, Jeff Schneider, and Daniel Neill. Anomaly pattern detection in categorical
datasets. In Knowledge Discovery and Data Mining (KDD), 2008.
[4] Kaustav Das, Jeff Schneider, and Daniel Neill. Detecting anomalous groups in categorical
datasets. Technical Report 09-104, CMU-ML, 2009.
[5] Philip K. Chan and Matthew V. Mahoney. Modeling multiple time series for anomaly detection.
In IEEE International Conference on Data Mining, 2005.
[6] Eamonn Keogh, Jessica Lin, and Ada Fu. Hot sax: Efficiently finding the most unusual time
series subsequence. In IEEE International Conference on Data Mining, 2005.
[7] G. Mark Voit. Tracing cosmic evolution with clusters of galaxies. Reviews of Modern Physics,
77(1):207 ? 258, 2005.
[8] B. de Finetti. Funzione caratteristica di un fenomeno aleatorio. Atti della R. Academia
Nazionale dei Lincei, Serie 6. Memorie, Classe di Scienze Fisiche, Mathematice e Naturale, 4,
1931.
[9] Thomas Hofmann. Unsupervised learning with probabilistic latent semantic analysis. Machine
Learning Journal, 2001.
[10] David M. Blei, Andrew Y. Ng, and Michael I. Jordan. Latent Dirichlet allocation. JMLR,
3:993?1022, 2003.
[11] Stuart Geman and Donald Geman. Stochastic relaxation, gibbs distributions, and the bayesian
restoration of images. IEEE Trans. PAMI, 6:721 ? 741, 1984.
[12] Gilles Celeux, Didier Chaveau, and Jean Diebolt. Stochastic version of the em algorithm: An
experimental study in the mixture case. J. of Statistical Computation and Simulation, 55, 1996.
[13] Liang Xiong, Barnab?as P?oczos, and Jeff Schneider. Hierarchical probabilistic models for group
anomaly detection. In International conference on Artificial Intelligence and Statistics (AISTATS), 2011.
[14] Mikaela Keller and Samy Bengio. Theme-topic mixture model for document representation.
In Learning Methods for Text Understanding and Mining, 2004.
[15] Li Fei-Fei and P. Perona. A bayesian hierarchical model for learning natural scene categories.
IEEE Conf. CVPR, pages 524?531, 2005.
[16] Gabriel Doyle and Charles Elkan. Accounting for burstiness in topic models. In International
Conference on Machine Learning, 2009.
[17] Andrew Gelman, John B. Carlin, Hal S. Stern, and Donald B. Rubin. Bayesian Data Analysis.
Chapman and Hall/CRC, 2003.
[18] Thomas P. Minka. Estimating a dirichlet distribution. http://research.microsoft.
com/en-us/um/people/minka/papers/dirichlet, 2009.
[19] Gideon E. Schwarz. Estimating the dimension of a model. Annals of Statistics, (6-2):461?464,
1974.
[20] David G. Lowe. Distinctive image features from scale-invariant keypoints. IJCV, 60(2):91 ?
110, 2004.
[21] Manqi Zhao. Anomaly detection with score functions based on nearest neighbor graphs. In
NIPS, 2009.
[22] E. Perlman, R. Burns, Y. Li, and C. Meneveau. Data exploration of turbulence simulations
using a database cluster. In Supercomputing SC, 2007.
[23] Charles Meneveau. Lagrangian dynamics and models of the velocity gradient tensor in turbulent flows. Annual Review of Fluid Mechanics, 43:219?45, 2011.
[24] Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and David M. Blei. Hierarchical Dirichlet
process. Journal of the American Statistical Association, 101:1566 ? 1581, 2006.
9


----------------------------------------------------------------

title: 1077-a-neural-network-autoassociator-for-induction-motor-failure-prediction.pdf

A Neural Network Autoassociator for
Induction Motor Failure Prediction
Thomas Petsche, Angelo Marcantonio, Christian Darken,
Stephen J. Hanson, Gary M. Kuhn and Iwan Santoso
[PETSCHE, ANGELO, DARKEN, JOSE, GMK, NIS]@SCR.SIEMENS.COM

Siemens Corporate Research, Inc.
755 College Road East
Princeton, NJ 08853

Abstract
We present results on the use of neural network based autoassociators
which act as novelty or anomaly detectors to detect imminent motor
failures. The autoassociator is trained to reconstruct spectra obtained
from the healthy motor. In laboratory tests, we have demonstrated that the
trained autoassociator has a small reconstruction error on measurements
recorded from healthy motors but a larger error on those recorded from a
motor with a fault. We have designed and built a motor monitoring system
using an autoassociator for anomaly detection and are in the process of
testing the system at three industrial and commercial sites.

1 Introduction
An unexpected breakdown of an electric induction motor can cause financial loss significantly in excess of the cost of the motor. For example, the breakdown of a motor in a
production line during a production run can cause the loss of work in progress as well as
loss of production time.
When a motor does fail, it is not uncommon to replace it with an oversized motor based on
the assumption that if a motor is not running at its design limit then it will survive longer.
While this is frequently effective, this leads to significantly lower operating efficiencies and
higher initial and operating costs.
The primary motivation behind this project is the observation that if a motor breakdown and
be predicted before the actual breakdown occurs, then the motor can be replaced in a more
orderly way, with minimal interruption of the process in which it is involved. The goal is
to produce a system that is conceptually similar to a fuel gauge on an automobile. When
the system detects conditions that indicate that the motor is approaching its end-of-life, the
operators are notified that a replacement is necessary in the near future.

A Neural Network Autoassociator for Induction Motor Failure Prediction

925

2 Background
At present, motors in critical operations that are subject to mechanical failures - for example,
fire pump motors on US Navy vessels - are typically monitored by a human expert who
periodically listens to the vibrations of the motor and, based on experience, determines
whether the motor sounds healthy or sounds like a problem is developing. Since mechanical
probiems in motors typically lead to increased or changed vibrations, this technique can
werk well. Unfortunately, it depends on a competent and expensive expert.
In an attempt to automate motor monitoring, several vendors have "automated motor monitoring" equipment available. For mechanical failure monitoring, such systems typically rely
on several accelerometers to measure the vibration of the motor at various points and along
various axes. The systems then display information, primarily about the vibration spectrum,
to an operator who determines whether the motor is functioning properly. These systems
are expensive since they rely on several accelerometers, each of which is itself expensive,
as well as data collection hardware and a computer. Further, the systems require an expert
operator and frequently require that the motor be tested only when it is driving a known load.
Neither the human motor expert nor the existing motor monitoring systems provide an
affordable solution for continuous on-line mechanical failure monitoring. However, the
success of the human expert and existing vibration monitors does demonstrate that in fact,
there is sufficient information in the vibration of an electric induction motor to detect
imminent mechanical failures.
Siemens Energy and Automation has proposed a new product, the Siemens Advanced Motor
Master System II (SAMMS II), that will continuously monitor and protect an electric induction motor while it is operating on-line. Like the presently available SAMMS, the SAMMS
II is designed to provide protection against thermal and electrical overload an, in addition,
it will provide detection of insulation deterioration and mechanical fault monitoring.
In contrast to existing systems and techniques, the SAMMS II is designed to (1) require
no human expert to determine if a motor is developing problems; (2) be inexpensive; and
(3) provide continuous, on-line monitoring of the motor in normal operation.
The requirements for the SAMMS II, in partiCUlar the cost constraint, require that several
issues be resolved. First, in order to produce a low cost system, it is necessary to eliminate
the need for expensive accelerometers. Second, wiring should be limited to the motor control
center, i.e., it should not be necessary to run new signal wires from the motor control center
to the motor. Third, the SAMMS II is to provide continuous on-line monitoring, so the
system must adapt to or factor out the effect of changing loads on the motor. Finally since
the SAMMS II would not necessarily be bundled with a motor and so might be used to
control and monitor an arbitrary motor from an arbitrary manufacturer, the design can not
assume that a full description of the motor construction is available.

3 Approach
The first task was to determine how to eliminate the accelerometers. Based on work done
elsewhere (Schoen, Habetler & Bartheld, 1994), SE&A determined that it might be possible
to use measurements of the current on a single phase of the power supply to estimate the
vibration of the motor. This depends on the assumption that any vibration of the motor will
cause the rotor to move radially relative to the stator which will cause changes in the airgap
which, in tum, will induce changes in the current.
Experiments were done at the Georgia Institute of Technology to determine the feasibility
of this idea using the same sort of data collection system described later. Early experiments
indicated that, for a single motor driving a variety of loads, it is possible to distinguish

926

T. PETSCHE, A. MARCANTONIO, C. DARKEN, S. J. HANSON, G. M. KUHN, I. SANTOSO

Table 1: Loads for motors #1 and #2.

Load type
constant
sinusoidal oscillation at rotating frequency
sinusoidal oscillation at twice the rotating frequency
switching load (50% duty cycle) at rotating frequency
sinusoidal oscillation 28 Hz
sinusoidal oscillation at 30 Hz
switching load (50% duty cycle) at 30 Hz

Load Magnitude
half and full rated
half and full rated
full rated
full rated
half and full rated
full rated
full rated

Table 2: Neural network classifier experiment.

Features (N)
Performance on motor #1
Performance on motor #2

48
100%

63
100%
30%

64
92%
25%

110
100%
55%

320
100%
37%

between a current spectrum obtained from the motor while it is healthy and another obtained
when the motor contains a fault. Moreover, it is also possible to automatically generate a
classifiers that correctly determine the presence or absence of a fault in the motor.
The first, obvious approach to this monitoring task would seem to be to build a classifier
that would be used to distinguish between a healthy motor and one that has developed a
fault that is likely to lead to a breakdown. Unfortunately, this approach does not work.
As described above, we have successfully built classifiers of various sorts using manual and
automatic techniques to distinguish between current spectra obtained from a motor when it
is healthy and those obtained when it contains a fault.
However, since the SAMMS II will be connected to a motor before it fails and will be asked
to identify a failure without ever seeing a labeled example of a failure from that motor, a
classifier can only be used if it can be trained on data collected from one or more motors
and then used to monitor the motor of interest. Unfortunately, experiments indicate that
this will not work.
One of these experiments is illustrated in table 2. Several feedforward neural network classifiers were trained using examples from a single motor under four conditions: (1) healthy,
(2) unbalanced, (3) containing a broken rotor bar and (4) containing a hole in the outer
bearing race. The ten different loads listed in table 1 were applied to the motor for each of
these conditions.
The networks contained N inputs (where N is given in table 2); 9 hidden units and 4
outputs. There were 40 training examples where each example is the average of 50 distinct
magnitude scaled FFrs obtained from motor #1 from a single load/fault combination. The
test data for which the results are reported in the table consisted of 40 averaged FFfs from
motor #1 and 20 averaged FFfs (balanced and unbalanced only) from motor #2. The test
set for motor #1 is completely distinct from the training set.
In the case where n = 110, the FFf components were selected to include the frequencies
identified by the theory of motor physics as interesting for the three fault conditions and
exclude all other components. This led to an improvement over the other cases where a
single contiguous set of components was chosen, but the performance still degrades to about
random chance instead of 100%.
This experiment clearly illustrates that is is possible to distinguish between healthy and
faulty spectra obtained from the same motor. However, it also clearly illustrates that a

A Neural Network Autoassociator for Induction Motor Failure Prediction

Measurements

Novelty
detection

Novelty

Decision

927
Diagnosis

Adaptation
AlgOrithm

Figure 1: The basic form of an anomaly detection system.
classifier trained on one motor does not perform well on another motor since the error rates
increase immensely. Based on results such as these, we have concluded that it is not feasible
to build a single classifier that would be trained once and then placed in the field to monitor
a motor. Instead we are pursuing an alternative based on anomaly detection which adapts
a monitor to the particular motor for which it is responsible.

4

Anomaly detection

The basic notion of anomaly detection for monitoring is illustrated in figure 1. Statistical
anomaly detection centers around a model of the data that was seen while the motor was
operating normally. This model is produced by collecting spectra from the motor while
it is operating normally. Once trained, the system compares each new spectrum to the
model to determine how similar to or different from the training set it is. This similarity
is described by an "anomaly metric" which, in the simplest case, can be thresholded to
determine whether the motor is still normal or has developed a fault. Once the "anomaly
metric" has been generated, various statistical techniques can be used to determine if there
has been a change in the distribution of values.

5 A Neural Network-based Anomaly Detector
The core of the most successful monitoring system we have built to date is a neural network
designed to function as an autoassociator (Rumelhart, Hinton & Williams, 1986, called it
an "encoder"). We use a simple three layer feedforward network with N inputs, N outputs
and K < N hidden units. The input layer is fully connected to the hidden layer which is
fully connected to the output layer. Each unit in the hidden and output layers computes

= (J ( 2::;0 Wi,jXj) , where Xi is the output of neuron i which receives inputs from Mi other
neurons and Wi,j is the weight on the connection from neuron} to neuron i. The network is
trained using the backpropagation algorithm to reconstruct the input vector on the output
units. Specifically, if Xi is one of n input vectors and Xi is the corresponding output vector,
the network is trained to minimize the sum of squared errors E = 2::~1 Ilxi - xdl 2. Once
training is complete, the anomaly metric is mi = IIXi - xi11 2 .

Xi

6

Anomaly Detection Test

We have tested the effectiveness of the neural network autoassociator as an anomaly detector
on several motors. For all these tests, the autoasociator had 20 hidden units. The hidden
layer size was chosen after some experimentation and data analysis on motor #1 , but no
attempt was made to tune the' hidden layer size for motor #2 or motor #3.
Motor #1 was tested using the ten different loads listed in table 1 and four different

T. PETSCHE, A. MARCANTONIO, C. DARKEN, S. 1. HANSON, O. M. KUHN, I: SANTOSO

928

q

,---------------------------~

. .......

,.;- ,

,_.-

<Xl

<Xl

o

o

.. ..-...

..-

... :

C\I

"!

o

o

0.0

o.oooos

0.0001
Threshold

0.00015

0.0002

balanced
unbalanced

...-

0.0

0.00002 0.00004 0.00006 0.00008 0.00010 0.00012
Threshold

Figure 2: Probability of error as a function of threshold using individual FFfs on (a) motor #1 with 319 inputs and (b) motor #2 with 320 inputs.
health/fault conditions: healthy (balanced); unbalanced; broken rotor bar; and a hole in
the outer bearing race. Motor #2 was tested while driving the same ten loads, but for one
healthy and one faulty condition: healthy (balanced) and unbalanced.
For both motors #1 and #2, recordings of a single current phase were made as follows. For
each fault condition, a load was selected and applied and the motor was run and the current
signal recorded for five minutes. Then a new load was introduced and the motor was run
again. The load was constant during any five minute recording session.
Motor #3 was tested using thirteen different loads, but only two fault conditions: healthy
(balanced) and unbalanced. In this case, however, load changes occurred at random times.
We preprocessed this data to to identify where the load changes occurred to generate the
training set and the healthy motor test sets.

6.1

Preprocessing

Recordings were made on a digital audio tape (OAT). The current on a single phase was
measured with a current transformer, amplified, notch filtered to reduce the magnitude of
the 60Hz component, amplified again and then applied as input to the OAT. The notch filter
was a switched capacitor filter which reduced the magnitude at 60Hz by about 30dB.
The time series obtained from the OAT was processed to reduce the sampling rate and then
dividing the data into non-overlapping blocks and computing the FFT of each block. A
subset of the FFf magnitude coefficients was selected and for each FFT, independent of
any other FFf, the components were linearly scaled and translated to the interval [e, 1 e] (typically e = 0.02). That is, for each FFT consisting of coefficients to, ... .tn-t,
we selected a subset, F, (the same for all FFTs) of the components and computed a =
(l - 2e)(maxiEFh - miniEFh)-t and b = miniEFh. Then the input vector, x, to the
network is Xj = a(fij - b) + e where, for allj < k: ij, ik E F and ij < ik.

6.2 Experimental Results
In figure 2a, we illustrate the results of a typical anomaly detection experiment on motor #1
using an autoassociator with 319 inputs and 20 hidden units. This graph illustrates the
performance (false alarm and miss rates) of a very simple anomaly detection system which
thresholds the anomaly metric to determine if the motor is good or bad. The decreasing
curve that starts at threshold = 0, P(error) = 1 is the false alarm rate as a function of the
threshold. Each increasing curve is the miss rate for a particular fault type.
In figure 2b we illustrate the performance of an autoassociator on motor #2 using an

A Neural Network Autoassociator for Induction Motor Failure Prediction
q

I

.....

929

-'

/~',.....

<Xl

ci

%~
ii

,.I

/

/

,,/

iL-.:t:
0

.... -.

......

'"ci

../ - - - - - - - - - - - - 1

0

ci

0.0

0.0001

0.0002

0.0003

0.0004

0.0005

Threshold

Figure 3: Probability of error for motor #3 using individual FFTs and 319 inputs.
q ,----------------------------,

q

<Xl

o

,---------------------------~

<Xl

ci

,

....... .

,/

'"ci

balanced
unbalanced
.,.-'

o
ci ~---.---,r_--.---~--_r--_.~

0.0

0.00005

0.0001

0.00015

Threshold

0.0002

0.0

0.00002 0.00004 0.00006 0.00008 0.00010 0.00012
Threshold

Figure 4: Probability of error using averaged FFTs for (a) motor #1 and 319 inputs
(b) motor #2 and 320 inputs.
autoassociator with 320 inputs and 20 hidden units. Figure 3 shows our results on motor #3
using an autoassociator with 319 inputs.
We have found significant performance improvements by averaging several consecutive
FFTs. In figure 4 we show the results for motors #1 and #2 when we averaged 11 FFTs to
produce the input features. Compare these curves to those in figure 2. In particular, notice
that the probability of error is much lower for the averaged FFTs when the good motor
curve crosses anyone of the faulty motor curves.

7

Candor System Design

Based on our experiments with autoassociators, we designed a prototype mechanical motor
condition monitoring system. The functional system architecture is shown in figure 5. In
order to control costs, the system is implemented on a PC. The system is designed so that
each PC can monitor up to 128 motors using one 16-bit analog to digital converter. The
signals are collected, filtered and multiplexed on custom external signal processing cards.
Each card supports up to eight motors (with up to 16 cards per PC).
The system records current measurements from one motor at a time. For each motor,
measurements are collected, four FFTs are computed on non-overlapping time series, and
the four FFTs are averaged to produce a vector that is input to the neural network. The system
reports that a motor is bad only if more than five of the last ten averaged FFTs produced an
anomaly metric more than five standard deviations greater than the mean metric computed
on the training set. Otherwise the motor is reported to be normal. In addition to monitoring
the motors, the prototype systems are designed to record all measurements on tape to support

930

T. PETSCHE, A. MARCANTONIO, C. DARKEN, S. 1. HANSON, G. M. KUHN, I. SANTOSO

GOOD
BAD

Figure 5: Functional architecture of Candor.
future experiments with alternative algorithms and tuning to improve performance.
To date, three monitoring systems have been installed: in an oil refinery, in a testing
laboratory and on an office building ventilation system. The system has correctly detected
the only failure it has seen so far: when a filter on the inlet to a water circulation pump
became clogged the spectrum changed so much that the average daily novelty metric jumped
from less than one standard deviation above the training set average to more than twenty
standard deviations. We hope to have further test results in a year or so.

8

Related work

Gluck and Myers (1993) proposed a model oflearning in the hippocampus based in part on
an autoassociator which is used to detect novel stimuli and to compress the representation
of the stimuli. This model has accurately predicted many of the classical conditioning
behaviors that have been observed in normal and hippocampal-damaged animals. Based on
this work, Japkowicz, Myers and Gluck (1995) independently derived an autoassociatorbased novelty detector for machine learning tasks similar to that used in our system.
Together with Gluck, we have tested an autoassociator based anomaly detector on helicopter
gearbox failures for the US Navy. In this case, the autoassociator is given 512 inputs
consisting of 64 vibration based features from each of 8 accelerometers mounted at different
locations on the gearbox. In a blind test, the autoassociator was able to correctly distinguish
between feature vectors taken from a damaged gearbox and other feature vectors taken
from normal gearboxes, all recorded in flight. Our anomaly detector will be included in
test flights of a gearbox monitoring system later this year.

References
Gluck, M. A. & Myers, C. E. (1993). Hippocampal mediation of stimulus representation:
A compuational theory. Hippocampus, 3(4), 491-561.
Japkowicz, N., Myers, c., & Gluck, M. A. (1995). A novelty detection approach to
classification. In Proceedings of the Fourteenth International Joint Conference on
Artificial Intelligence.
Rumelhart, D ., Hinton, G., & Williams, R. (1986). Learning internal representations by
error propagation. In D . Rumelhart & J. McClelland (Eds.), Parallel Distributed
Processing (pp. 318-362). MIT Press.
Schoen, R., Habetler, T., & Bartheld, R. (1994) . Motor bearing damage detection using
stator current monitoring. In Proceedings of the IEEE lAS Annual Meeting.


----------------------------------------------------------------

title: 1459-intrusion-detection-with-neural-networks.pdf

Intrusion Detection with Neural Networks

Jake Ryan*
Department of Computer Sciences
The University of Texas at Austin
Austin, TX 78712

Department of Electrical and Computer Engineering
The University of Texas at Austin
Austin, TX 78712

raven@cs.utexas.edu

mj@orac.ece . utexas.edu

Meng-Jang Lin

Risto Miikkulainen
Department of Computer Sciences
The University of Texas at Austin
Austin, TX 78712

risto@cs.utexas.edu

Abstract
With the rapid expansion of computer networks during the past few years,
security has become a crucial issue for modern computer systems. A
good way to detect illegitimate use is through monitoring unusual user
activity. Methods of intrusion detection based on hand-coded rule sets or
predicting commands on-line are laborous to build or not very reliable.
This paper proposes a new way of applying neural networks to detect
intrusions. We believe that a user leaves a 'print' when using the system;
a neural network can be used to learn this print and identify each user
much like detectives use thumbprints to place people at crime scenes. If
a user's behavior does not match hislher print, the system administrator
can be alerted of a possible security breech. A backpropagation neural
network called NNID (Neural Network Intrusion Detector) was trained
in the identification task and tested experimentally on a system of 10
users. The system was 96% accurate in detecting unusual activity, with
7% false alarm rate. These results suggest that learning user profiles is
an effective way for detecting intrusions.

1 INTRODUCTION
Intrusion detection schemes can be classified into two categories: misuse and anomaly
intrusion detection. Misuse refers to known attacks that exploit the known vulnerabilities
of the system. Anomaly means unusual activity in general that could indicate an intrusion.
?Currently: MCI Communications Corp., 9001 N. IH 35, Austin, TX 78753; jake.ryan@mci.com.

944

1. Ryan, M-J. Lin and R. Miikkulainen

If the observed activity of a user deviates from the expected behavior, an anomaly is said
to occur.

Misuse detection can be very powerful on those attacks that have been programmed in
to the detection system. However, it is not possible to anticipate all the different attacks
that could occur, and even the attempt is laborous. Some kind of anomaly detection is
ultimately necessary. One problem with anomaly detection is that it is likely to raise many
false alarms. Unusual but legitimate use may sometimes be considered anomalous. The
challenge is to develop a model of legitimate behavior that would accept novel legitimate
use.
It is difficult to build such a model for the same reason that it is hard to build a comprehensive misuse detection system: it is not possible to anticipate aU possible variations of such
behavior. The task can be made tractable in three ways: (1) Instead of general legitimate
use, the behavior of individual users in a particular system can be modeled. The task of
characterizing regular patterns in the behavior of an individual user is an easier task than
trying to do it for aU users simultaneously. (2) The patterns of behavior can be learned
for examples of legitimate use, instead of having to describe them by hand-COding possible
behaviors. (3) Detecting an intrusion real-time, as the user is typing commands, is very
difficult because the order of commands can vary a lot. In many cases it is enough to recognize that the distribution of commands over the entire login session, or even the entire
day, differs from the usual.

The system presented in this paper, NNID (Neural Network Intrusion Detector), is based on
these three ideas. NNID is a backpropagation neural network trained to identify users based
on what commands they use during a day. The system administrator runs NNID at the end
of each day to see if the users' sessions match their normal pattern. If not, an investigation
can be launched. The NNID model is implemented in a UNIX environment and consists of
keeping logs of the commands executed, forming command histograms for each user, and
learning the users' profiles from these histograms. NNID provides an elegant solution to
off-line monitoring utilizing these user profiles. In a system of 10 users, NNID was 96%
accurate in detecting anomalous behavior (i.e. random usage patterns), with a false alarm
rate of 7%. These results show that a learning offline monitoring system such as NNID
can achieve better performance than systems that attempt to detect anomalies on-line in the
command sequences, and with computationally much less effort.
The rest of the paper outlines other approaches to intrusion detection and motivates the
NNID approach in more detail (sections 2 and 3), presents the implementation and an
evaluation on a real-world computer system (sections 4 and 5), and outlines some open
issues and avenues for future work (section 6).

2

INTRUSION DETECTION SYSTEMS

Many misuse and anomaly intrusion detection systems (lDSs) are based on the general
model proposed by Denning (1987). This model is independent of the platform, system vulnerability, and type of intrusion. It maintains a set of historical profiles for users, matches
an audit record with the appropriate profile, updates the profile whenever necessary, and reports any anomalies detected. Another component, a rule set, is used for detecting misuse.
Actual systems implement the general model with different techniques (see Frank 1994;
Mukherjee et al. 1994, for an overview). Often statistical methods are used to measure how
anomalous the behavior is, that is, how different e.g. the commands used are from normal
behavior. Such approaches require that the distribution of subjects' behavior is known.
The behavior can be represented as a rule-based model (Garvey and Lunt 1991), in terms
of predictive pattern generation (Teng et al. 1990), or using state transition analysis (Porras

Intrusion Detection with Neural Networks

945

et al. 1995). Pattern matching techniques are then used to detennine whether the sequence
of events is part of normal behavior, constitutes an anomaly, or fits the description of a
known attack.
IDSs also differ in whether they are on-line or off-line. Off-line IDSs are run periodically and they detect intrusions after-the-fact based on system logs. On-line systems are
designed to detect intrusions while they are happening, thereby allowing for quicker intervention. On-line IDSs are computationally very expensive because they require continuous
monitoring. Decisions need to be made quickly with less data and therefore they are not as
reliable.
Several IDSs that employ neural networks for on-line intrusion detection have been proposed (Debar et al. 1992; Fox et al. 1990). These systems learn to predict the next command based on a sequence of previous commands by a specific user. Through a shifting
window, the network receives the w most recent commands as its input. The network is
recurrent, that is, part of the output is fed back as the input for the next step; thus, the
network is constantly observing the new trend and "forgets" old behavior over time. The
size of the window is an important parameter: If w is too small, there will be many false
positives; if it is too big, the network may not generalize well to novel sequences. The most
recent of such systems (Debar et al. 1992) can predict the next command correctly around
80% of the time, and accept a command as predictable (among the three most likely next
commands) 90% of the time.
One problem with the on-line approach is that most of the effort goes into predicting the
order of commands. In many cases, the order does not matter much, but the distribution of
commands that are used is revealing. A possibly effective approach could therefore be to
collect statistics about the users' command usage over a period of time, such as a day, and
try to recognize the distribution of commands as legitimate or anomalous off-line. This is
the idea behind the NNID system.

3 THE NNID SYSTEM
The NNID anomaly intrusion detection system is based on identifying a legitimate user
based on the distribution of commands she or he executes. This is justifiable because
different users tend to exhibit different behavior, depending on their needs of the system.
Some use the system to send and receive e-mail only, and do not require services such as
programming and compilation. Some engage in all kinds of activities including editing,
programming, e-mail, Web browsing, and so on. However, even two users that do the same
thing may not use the same application program. For example, some may prefer the "vi"
editor to "emacs", favor "pine" over "elm" as their mail utility program, or use "gcc" more
often than "cc" to compile C programs. Also, the frequency with which a command is
used varies from user to user. The set of commands used and their frequency, therefore,
constitutes a 'print' of the user, reflecting the task performed and the choice of application
programs, and it should be possible to identify the user based on this information.
It should be noted that this approach works even if some users have aliases set up as shorthands for long commands they use frequently, because the audit log records the actual
commands executed by the system. Users' privacy is not violated, since the arguments to
a command do not need to be recorded. That is, we may know that a user sends e-mail five
times a day, but we do not need to know to whom the mail is addressed.
Building NNID for a particular computer system consists of the following three phases:
1. Collecting training data: Obtain the audit logs for each user for a period of several
days. For each day and user, form a vector that represents how often the user
executed each command.

946

1 Ryan, M-J. Un and R. Miikkulainen

as
cut
expr
ghostview
Id
man
netstat
rm
tcsh
vi

awk
cvs
fgrep
gmake
fess
mesg
nm
rsh
tee
virtex

be
date
filter
grep
look
metamail
objdump
sed
test
w

61btex
df
find
gs
Ipq
rillCdir
perl
sendmail
tgif
wc

calendar
diff
finger
gzip
Ipr
more
pgp
sh
top
whereis

cat
du
fmt
hostname
Iprm
movemail
ping
sort
tput
xbiff++

chmOd
dvips
from
id
Is
mpage
ps
strip
tr
xca1c

comsat
egrep
ftp
ifConfig
machine
mt
pwd
stty
tty
xdvi

cp
elm
gcc
Ispell
mail
mv
rcp
tail
uname
xhost

cpp
emacs
gdb
fast
make
netscape
resize
tar

vacation
xterm

Table 1: The 100 commands used to describe user behavior. The number of times the user
executed each of these commands during the day was recorded, mapped into a nonlinear scale of 11
intervals, and concatenated into a l00-dimensional input vector, representing the usage pattern for
that user for that day.
2. Training: Train the neural network to identify the user based on these command
distribution vectors.
3. Perfonnance: Let the network identify the user for each new command distribution vector. If the network's suggestion is different from the actual user, or if the
network does not have a clear suggestion, signal an anomaly.
The particular implementation of NNID and the environment where it was tested is described in the next section.

4 EXPERIMENTS
The NNID system was built and tested on a machine that serves a particular research group
at the Department of Electrical and Computer Engineering at the University of Texas at
Austin. This machine has 10 total users; some are regular users, with several other users
logging in intennittently. This platfonn was chosen for three reasons:
1. The operating system (NetBSD) provides audit trail logging for accounting purposes and this option had been enabled on this system.
2. The number of users and the total number of commands executed per day are on
an order of magnitude that is manageable. Thus, the feasibility of the approach
could be tested with real-world data without getting into scalability issues.
3. The system is relatively unknown to outsiders and the users are all known to us, so
that it is likely that the data collected on it consists of nonnal user behavior (free
of intrusions).
Data was collected on this system for 12 days, resulting in 89 user-days. Instead of trying
to optimize the selection of features (commands) for the input, we decided to simply use
a set of 100 most common commands in the logs (listed in Table 1), and let the network
figure out what infonnation was important and what superfluous. Intelligent selection of
features might improve the results some but the current approach is easy to implement and
proves the point.
In order to introduce more overlap between input vectors, and therefore better generalization, the number of times a command was used was divided into intervals. There were 11
intervals, non-linearly spaced, so that the representation is more accurate at lower frequencies where it is most important. The first interval meant the command was never used; the
second that it was used once or twice, and so on until the last interval where the command
was used more than 500 times. The intervals were represented by values from 0.0 to 1.0
in 0.1 increments. These values, one for each command, were then concatenated into a
100-dimensional command distribution vector (also called user vector below) to be used as
input to the neural network.

Intrusion Detection with Neural Networks

947

The standard three-layer backpropagation architecture was chosen for the neural network.
The idea was to get results on the most standard and general architecture so that the feasibility of the approach could be demonstrated and the results would be easily replicable.
More sophisticated architectures could be used and they would probably lead to slightly
better results. The input layer consisted of 100 units, representing the user vector; the hidden layer had 30 units and the output layer 10 units, one for each user. The network was
implemented in the PlaNet Neural Network simulator (Miyata 1991).

5

RESULTS

To avoid overtraining, several training sessions were run prior to the actual experiments to
see how many training cycles would give the highest performance. The network was trained
on 8 randomly chosen days of data (65 user vectors), and its performance was tested on the
remaining 4 days (24 vectors) after epochs 30, 50, 100,200, and 300, of which 100 gave
the best performance. Four splits of the data into training and testing sets were created by
randomly picking 8 days for training. The reSUlting four networks were tested in two tasks:
1. Identifying the user vectors of the remaining 4 days. If the activation of the output
unit representing the correct user was higher than those of all other units, and
also higher than 0.5, the identification was counted as correct. Otherwise, a false
positive was counted.
2. Identifying 100 randomly-generated user vectors. If all output units had an activation less than 0.5, the network was taken to correctly identify the vector as an
anomaly (i.e. not any of the known users in the system). Otherwise, the most
highly active output unit identifies the network's suggestion. Since all intrusions
occur under one of the 10 user accounts, there is a 111 0 chance that the suggestion
would accidentally match the compromised user account and the intrusion would
not be detected. Therefore, 1/10 of all such cases were counted as false negatives.
The second test is a suggestive measure of the accuracy of the system. It is not possible to
come up with vectors that would represent a good sampling of actual intrusions; the idea
here was to generate vectors where the values for each command were randomly drawn
from the distribution of values for that command in the entire data set. In other words, the
random test vectors had the same first-order statistics as the legitimate user vectors, but
had no higher-order correlations. Therefore they constitute a neutral but realistic sample of
unusual behavior.
All four splits led to similar results. On average, the networks rejected 63% of the random
user vectors, leading to an anomaly detection rate of 96%. They correctly identified the
legitimate user vectors 93% of the time, giving a false alarm rate of 7%.
Figure 1 shows the output of the network for one of the splits. Out of 24 legitimate user
vectors, the network identified 22. Most of the time the correct output unit is very highly
activated, indicating high certainty of identification. However, the activation of the highest
unit was below 0.5 for two of the inputs, resulting in a false alarm.
Interestingly, in all false alarms in all splits, the falsely-accused user was always the same.
A closer look at the data set revealed that there were only 3 days of data on this user. He
used the system very infrequently, and the network could not learn a proper profile for him.
While it would be easy to fix this problem by collecting more data in this case, we believe
this is a problem that would be difficult to rule out in general. No matter how much data
one collects, there may still not be enough for some extremely infrequent user. Therefore,
we believe the results obtained in this rather small data set give a realistic picture of the
performance of the NNID system.

948

1. Ryan, M-l. lin and R. Miikkulainen

O~t.,ut;':

.> 4 ?

)

2 3

...

?

:l

~t? - 4 , ?

""

6

~

0

L Z

?

~

D.itrut

. .
~

.. .

..

,

~

u

"

~~-

n..,.!. -

~"":;l

e

~~t

~t<'4'"

.

?

.

. .
~

..

-

o

?

~

?

-.

"

...
_ ?

-

~

,

t

"

e

9

?

0 1 2 3
00. .......

?

5 6

?

u

~

~<

~

,

?

.

~t

~

0

1 2
Oo.t"",

~

,

"

o::.+~"

Eo

6
9

..

"

5 6 7 8 9

<

,

Out.~, ~

"

~

0

.

?
?

g

?

?
.

"

t

?

?

??
~

~~,.,,,

?

-

??
D~t~2~'56

"

5 6 7 B 9

?
"

tI

.

??

.?

.

...

D.np;;.. '"

~

?

??

D~~L

tI

?

5 6 7 B

D.~t '" ? ?

.

'

.

?
O.lt('t-rt

..
...

??

?

,

xr~ct

..
~

.

~

Out.~, ~"O'

?

~

~Zl.'5

.

ti

"

Ou<.~.

, ,

~

~

L

?"

~
t

"

o::...~"'.'~

? s

Figure 1: User identification with the NNID Network. The output layer of NNID is shown for
each of the 24 test vectors in one of the 4 splits tested. The output units are lined up from left to
right, and their activations are represented by the size of the squares. In this split there were two false
alarms: one is displayed in the top right with activation 0.01, and one in the second row from the
bottom, second column from the left with 0.35. All the other test vectors are identified correctly with
activation higher than 0.5.

6 DISCUSSION AND FUTURE WORK
An important question is, how well does the performance of NNID scale with the number
of users? Although there are many computer systems that have no more than a dozen
users, most intrusions occur in larger systems with hundreds of users. With more users,
the network would have to make finer distinctions, and it would be difficult to maintain the
same low level of false alarms. However, the rate of detecting anomalies may not change
much, as long as the network can learn the user patterns well. Any activity that differs from
the user's normal behavior would still be detected as an anomaly.
Training the network to represent many more users may take longer and require a larger
network, but it should be possible because the user profiles share a lot of common structure, and neural networks in general are good at learning such data. Optimizing the set of
commands included in the user vector, and the size of the value intervals, might also have a
large impact on performance. It would be interesting to determine the curve of performance

Intrusion Detection with Neural Networks

949

versus the number of users, and also see how the size of the input vector and the granularity
of the value intervals affect that curve. This is the most important direction of future work.
Another important issue is, how much does a user's behavior change over time? If behavior
changes dramatically, NNID must be recalibrated often or the number of false positives
would increase. Fortunately such retraining is easy to do. Since NNID parses daily activity
of each user into a user-vector, the user profile can be updated daily. NNID could then be
retrained periodically. In the current system it takes only about 90 seconds and would not
be a great burden on the system.

7

CONCLUSION

Experimental evaluation on real-world data shows that NNID can learn to identify users
simply by what commands they use and how often, and such an identification can be used
to detect intrusions in a network computer system. The order of commands does not need
to be taken into account. NNID is easy to train and inexpensive to run because it operates
off-line on daily logs. As long as real-time detection is not required, NNID constitutes a
promising, practical approach to anomaly intrusion detection.

Acknowledgements
Special thanks to Mike Dahlin and Tom Ziaja for feedback on an earlier version of this paper, and to
Jim Bednar for help with the PlaNet simulator. This research was supported in part by DOD-ARPA
contract F30602-96-1-0313, NSF grant IRI-9504317, and the Texas Higher Education Coordinating
board grant ARP-444.

References
Debar, H., Becker, M., and Siboni, D. (1992). A neural network component for an intrusion
detection system. In Proceedings of the 1992 IEEE Computer Society Symposium on
Research in Computer Security and Privacy, 240-250.
Denning, D. E. (1987). An intrusion detection model. IEEE Transactions on Software
Engineering, SE-13:222-232.
Fox, K. L., Henning, R. R., Reed, J. H., and Simonian, R. (1990). A neural network
approach towards intrusion detection. In Proceedings of the 13th National Computer
Security Conference, 125-134.
Frank, J. (1994). Artificial intelligence and intrusion detection: Current and future directions. In Proceedings of the National 17th Computer Security Conference.
Garvey, T. D., and Lunt, T. F. (1991). Model-based intrusion detection. In Proceedings of
the 14th National Computer Security Conference.
Miyata, Y. (1991). A User's Guide to PlaNet Version 5.6 -A Toolfor Constructing, Running, and Looking in to a PDP Network. Computer Science Department, University
of Colorado, Boulder, Boulder, CO.
Mukherjee, B., Heberlein, L. T., and Levitt, K. N. (1994). Network intrusion detection.
IEEE Network, 26-41.
Porras, P. A., IIgun, K., and Kemmerer, R. A. (1995). State transition analysis: A rulebased intrusion detection approach. IEEE Transactions on Software Engineering, SE21 : 181-199.
Teng, H. S., Chen, K., and Lu, S. C. (1990). Adaptive real-time anomaly detection using inductively generated sequential patterns. In Proceedings of the 1990 IEEE Symposium
on Research in Computer Security and Privacy, 278-284.


----------------------------------------------------------------

title: 4044-subgraph-detection-using-eigenvector-l1-norms.pdf

Subgraph Detection Using Eigenvector L1 Norms

Nadya T. Bliss
Lincoln Laboratory
Massachusetts Institute of Technology
Lexington, MA 02420
nt@ll.mit.edu

Benjamin A. Miller
Lincoln Laboratory
Massachusetts Institute of Technology
Lexington, MA 02420
bamiller@ll.mit.edu

Patrick J. Wolfe
Statistics and Information Sciences Laboratory
Harvard University
Cambridge, MA 02138
wolfe@stat.harvard.edu

Abstract
When working with network datasets, the theoretical framework of detection theory for Euclidean vector spaces no longer applies. Nevertheless, it is desirable to
determine the detectability of small, anomalous graphs embedded into background
networks with known statistical properties. Casting the problem of subgraph detection in a signal processing context, this article provides a framework and empirical results that elucidate a ?detection theory? for graph-valued data. Its focus is
the detection of anomalies in unweighted, undirected graphs through L1 properties
of the eigenvectors of the graph?s so-called modularity matrix. This metric is observed to have relatively low variance for certain categories of randomly-generated
graphs, and to reveal the presence of an anomalous subgraph with reasonable reliability when the anomaly is not well-correlated with stronger portions of the
background graph. An analysis of subgraphs in real network datasets confirms the
efficacy of this approach.

1

Introduction

A graph G = (V, E) denotes a collection of entities, represented by vertices V , along with some
relationship between pairs, represented by edges E. Due to this ubiquitous structure, graphs are used
in a variety of applications, including the natural sciences, social network analysis, and engineering.
While this is a useful and popular way to represent data, it is difficult to analyze graphs in the
traditional statistical framework of Euclidean vector spaces.
In this article we investigate the problem of detecting a small, dense subgraph embedded into an
unweighted, undirected background. We use L1 properties of the eigenvectors of the graph?s modularity matrix to determine the presence of an anomaly, and show empirically that this technique has
reasonable power to detect a dense subgraph where lower connectivity would be expected.
In Section 2 we briefly review previous work in the area of graph-based anomaly detection. In
Section 3 we formalize our notion of graph anomalies, and describe our experimental regime. In
Section 4 we give an overview of the modularity matrix and observe how its eigenstructure plays
a role in anomaly detection. Sections 5 and 6 respectively detail subgraph detection results on
simulated and actual network data, and in Section 7 we summarize and outline future research.
1

2

Related Work

The area of anomaly detection has, in recent years, expanded to graph-based data [1, 2]. The work of
Noble and Cook [3] focuses on finding a subgraph that is dissimilar to a common substructure in the
network. Eberle and Holder [4] extend this work using the minimum description length heuristic to
determine a ?normative pattern? in the graph from which the anomalous subgraph deviates, basing
3 detection algorithms on this property. This work, however, does not address the kind of anomaly
we describe in Section 3; our background graphs may not have such a ?normative pattern? that
occurs over a significant amount of the graph. Research into anomaly detection in dynamic graphs
by Priebe et al [5] uses the history of a node?s neighborhood to detect anomalous behavior, but this
is not directly applicable to our detection of anomalies in static graphs.
There has been research on the use of eigenvectors of matrices derived from the graphs of interest
to detect anomalies. In [6] the angle of the principal eigenvector is tracked in a graph representing
a computer system, and if the angle changes by more than some threshold, an anomaly is declared
present. Network anomalies are also dealt with in [7], but here it is assumed that each node in the
network has some highly correlated time-domain input. Since we are dealing with simple graphs,
this method is not general enough for our purposes. Also, we want to determine the detectability of
small anomalies that may not have a significant impact on one or two principal eigenvectors.
There has been a significant amount of work on community detection through spectral properties of
graphs [8, 9, 10]. Here we specifically aim to detect small, dense communities by exploiting these
same properties. The approach taken here is similar to that of [11], in which graph anomalies are
detected by way of eigenspace projections. We here focus on smaller and more subtle subgraph
anomalies that are not immediately revealed in a graph?s principal components.

3

Graph Anomalies

As in [12, 11], we cast the problem of detecting a subgraph embedded in a background as one of
detecting a signal in noise. Let GB = (V, E) denote the background graph; a network in which
there exists no anomaly. This functions as the ?noise? in our system. We then define the anomalous subgraph (the ?signal?) GS = (VS , ES ) with VS ? V . The objective is then to evaluate the
following binary hypothesis test; to decide between the null hypothesis H0 and alternate hypothesis
H1 :

H0 : The observed graph is ?noise? GB
H1 : The observed graph is ?signal+noise? GB ? GS .
Here the union of the two graphs GB ? GS is defined as GB ? GS = (V, E ? ES ).
In our simulations, we formulate our noise and signal graphs as follows. The background graph GB
is created by a graph generator, such as those outlined in [13], with a certain set of parameters. We
then create an anomalous ?signal? graph GS to embed into the background. We select the vertex
subset VS from the set of vertices in the network and embed GS into GB by updating the edge set
to be E ? ES . We apply our detection algorithm to graphs with and without the embedding present
to evaluate its performance.

4

The Modularity Matrix and its Eigenvectors

Newman?s notion of the modularity matrix [8] associated with an unweighted, undirected graph G
is given by
1
B := A ?
KK T .
(1)
2|E|
Here A = {aij } is the adjacency matrix of G, where aij is 1 if there is an edge between vertex i
and vertex j and is 0 otherwise; and K is the degree vector of G, where the ith component of K
is the number of edges adjacent to vertex i. If we assume that edges from one vertex are equally
likely to be shared with all other vertices, then the modularity matrix is the difference between the
?actual? and ?expected? number of edges between each pair of vertices. This is also very similar to
2

(a)

(b)

(c)

Figure 1: Scatterplots of an R-MAT generated graph projected into spaces spanned by two eigenvectors of its modularity matrix, with each point representing a vertex. The graph with no embedding
(a) and with an embedded 8-vertex clique (b) look the same in the principal components, but the
embedding is visible in the eigenvectors corresponding to the 18th and 21st largest eigenvalues (c).
the matrix used as an ?observed-minus-expected? model in [14] to analyze the spectral properties of
random graphs.
Since B is real and symmetric, it admits the eigendecomposition B = U ?U T , where U ? R|V |?|V |
is a matrix where each column is an eigenvector of B, and ? is a diagonal matrix of eigenvalues.
We denote by ?i , 1 ? i ? |V |, the eigenvalues of B, where ?i ? ?i+1 for all i, and by ui the
unit-magnitude eigenvector corresponding to ?i .
Newman analyzed the eigenvalues of the modularity matrix to determine if the graph can be split
into two separate communities. As demonstrated in [11], analysis of the principal eigenvectors of
B can also reveal the presence of a small, tightly-connected component embedded in a large graph.
This is done by projecting B into the space of its two principal eigenvectors, calculating a Chisquared test statistic, and comparing this to a threshold. Figure 1(a) demonstrates the projection of
an R-MAT Kronecker graph [15] into the principal components of its modularity matrix.
Small graph anomalies, however, may not reveal themselves in this subspace. Figure 1(b) demonstrates an 8-vertex clique embedded into the same background graph. In the space of the two principal eigenvectors, the symmetry of the projection looks the same as in Figure 1(a). The foreground
vertices are not at all separated from the background vertices, and the symmetry of the projection has
not changed (implying no change in the test statistic). Considering only this subspace, the subgraph
of interest cannot be detected reliably; its inward connectivity is not strong enough to stand out in
the two principal eigenvectors.
The fact that the subgraph is absorbed into the background in the space of u1 and u2 , however, does
not imply that it is inseparable in general; only in the subspace with the highest variance. Borrowing
language from signal processing, there may be another ?channel? in which the anomalous signal
subgraph can be separated from the background noise. There is in fact a space spanned by two
eigenvectors in which the 8-vertex clique stands out: in the space of the u18 and u21 , the two
eigenvectors with the largest components in the rows corresponding to VS , the subgraph is clearly
separable from the background, as shown in Figure 1(c).
4.1

Eigenvector L1 Norms

The subgraph detection technique we propose here is based on L1 properties of the eigenvectors
of the graph?s modularity matrix, where the L1 norm of a vector x = [x1 ? ? ? xN ]T is kxk1 :=
PN
i=1 |xi |. When a vector is closely aligned with a small number of axes, i.e., if |xi | is only large for
a few values of i, then its L1 norm will be smaller than that of a vector of the same magnitude where
this is not the case. For example, if x ? R1024
? has unit magnitude and only has nonzero components
along two of the 1024 axes, then kxk1 ? 2. If it has a component of equal magnitude along all
axes, then kxk1 = 32. This property has been exploited in the past in a graph-theoretic setting, for
finding maximal cliques [16, 17].
This property can also be useful when detecting anomalous clustering behavior. If there is a subgraph
GS that is significantly different from its expectation, this will manifest itself in the modularity
3

(a)

(b)

Figure 2: L1 analysis of modularity matrix eigenvectors. Under the null model, ku18 k has the
distribution in (a). With an 8-vertex clique embedded, ku18 k1 falls far from its average value, as
shown in (b).
matrix as follows. The subgraph GS has a set of vertices VS , which is associated with a set of indices
corresponding to rows and columns of the adjacency matrix A. Consider the vector x ? {0, 1}N ,
where xi is 1 if vi ? VS and xi = 0 otherwise. For any S ? V and v ? V , letP
dS (v) denote the
number of edges between the vertex v and the vertex set S. Also, let dS (S 0 ) := v?S 0 dS (v) and
d(v) := dV (v). We then have
2
X
d(VS )
2
kBxk2 =
,
dVS (v) ? d(v)
(2)
d(V )
v?V

xT Bx = dVS (VS ) ?

d2 (VS )
,
d(V )

(3)

p
and kxk2 = |VS |. Note that d(V ) = 2|E|. A natural interpretation of (2) is that Bx represents the difference between the actual and expected connectivity to VS across the entire graph,
and likewise (3) represents this difference within the subgraph. If x is an eigenvector of B, then
of course xT Bx/(kBxk2 kxk2 ) = 1. Letting
internal and
P each subgraph vertex have uniform
external degree, this ratio approaches 1 as v?V
(dVS (v) ? d(v)d(VS )/d(V ))2 is dominated by
/
S
P
2
v?VS (dVS (v) ? d(v)d(VS )/d(V )) . This suggests that if VS is much more dense than a typical
subset of background vertices, x is likely to be well-correlated with an eigenvector of B. (This becomes more complicated when there are several eigenvalues that are approximately dVS (VS )/|VS |,
but this typically occurs for smaller graphs than are of interest.) Newman made a similar observation: that the magnitude of a vertex?s component in an eigenvector is related to the ?strength? with
which it is a member of the associated community. Thus if a small set of vertices forms a community, with few belonging to other communities, there will be an eigenvector well aligned with this
set, and this implies that the L1 norm of this eigenvector would be smaller than that of an eigenvector
with a similar eigenvalue when there is no anomalously dense subgraph.
4.2

Null Model Characterization

To examine the L1 behavior of the modularity matrix?s eigenvectors, we performed the following
experiment. Using the R-MAT generator we created 10,000 graphs with 1024 vertices, an average
degree of 6 (the result being an average degree of about 12 since we make the graph undirected),
and a probability matrix


0.5 0.125
P =
.
0.125 0.25
For each graph, we compute the modularity matrix B and its eigendecomposition. We then compute
kui k1 for each i and store this value as part of our background statistics. Figure 2(a) demonstrates
the distribution of ku18 k1 . The distribution has a slight left skew, but has a tight variance (a standard
deviation of 0.35) and no large deviations from the mean under the null (H0 ) model.
After compiling background data, we computed the mean and standard deviation of the L1 norms
for each ui . Let ?i be the average of kui k1 and ?i be its standard deviation. Using the R-MAT graph
with the embedded 8-vertex clique, we observed eigenvector L1 norms as shown in Figure 2(b). In
4

the figure we plot kui k1 as well as ?i , ?i + 3?i and ?i ? 3?i . The vast majority of eigenvectors
have L1 norms close to the mean for the associated index. There are very few cases with a deviation
from the mean of greater than 3?. Note also that ?i decreases with decreasing i. This suggests that
the community formation inherent in the R-MAT generator creates components strongly associated
with the eigenvectors with larger eigenvalues.
The one outlier is u18 , which has an L1 norm that is over 10 standard deviations away from the mean.
Note that u18 is the horizontal axis in Figure 1(c), which by itself provides significant separation
between the subgraph and the background. Simple L1 analysis would certainly reveal the presence
of this particular embedding.

5

Embedded Subgraph Detection

With the L1 properties detailed in Section 4 in mind, we propose the following method to determine
the presence of an embedding. Given a graph G, compute the eigendecomposition of its modularity
matrix. For each eigenvector, calculate its L1 norm, subtract its expected value (computed from the
background statistics), and normalize by its standard deviation. If any of these modified L1 norms
is less than a certain threshold (since the embedding makes the L1 norm smaller), H1 is declared,
and H0 is declared otherwise. Pseudocode for this detection algorithm is provided in Algorithm 1.
Algorithm 1 L1S UBGRAPH D ETECTION
Input: Graph G = (V, E), Integer k, Numbers `1MIN , ?[1..k], ?[1..k]
B ? M OD M AT(G)
U ? EIGENVECTORS(B, k) hhk eigenvectors of Bii
for i ? 1 to k do
m[i] ? (kui k1 ? ?[i])/?[i]
if m[i] < `1MIN then
return H1 hhdeclare the presence of an embeddingii
end if
end for
return H0 hhno embedding foundii
We compute the eigenvectors of B using eigs in MATLAB, which has running time O(|E|kh +
|V |k 2 h + k 3 h), where h is the number of iterations required for eigs to converge [10]. While
the modularity matrix is not sparse, it is the sum of a sparse matrix and a rank-one matrix, so we
can still compute its eigenvalues efficiently, as mentioned in [8]. Computing the modified L1 norms
and comparing them to the threshold takes O(|V |k) time, so the complexity is dominated by the
eigendecomposition.
The signal subgraphs are created as follows. In all simulations in this section, |VS | = 8. For each
simulation, a subgraph density of 70%, 80%, 90% or 100% is chosen. For subraphs of this size and
density, the method of [11] does not yield detection performance better than chance.
The subgraph

is created by, uniformly at random, selecting the chosen proportion of the 82 possible edges. To
determine where to embed the subgraph into the background, we find all vertices with at most 1, 3
or 5 edges and select 8 of these at random. The subgraph is then induced on these vertices.
For each density/external degree pair, we performed a 10,000-trial Monte Carlo simulation in which
we create an R-MAT background with the same parameters as the null model, embed an anomalous
subgraph as described above, and run Algorithm 1 with k = 100 to determine whether the embedding is detected. Figure 3 demonstrates detection performance in this experiment. In the receiver
operating characteristic (ROC), changing the L1 threshold (`1MIN in Algorithm 1) changes the position on the curve. Each curve corresponds to a different subgraph density. In Figure 3(a), each
vertex of the subgraph has 1 edge adjacent to the background. In this case the subgraph connectivity
is overwhelmingly inward, and the ROC curve reflects this. Also, the more dense subgraphs are
more detectable. When the external degree is increased so that a subgraph vertex may have up to
3 edges adjacent to the background, we see a decline in detection performance as shown in Figure
3(b). Figure 3(c) demonstrates the additional decrease in detection performance when the external
subgraph connectivity is increased again, to as much as 5 edges per vertex.
5

(a)

(b)

(c)

Figure 3: ROC curves for the detection of 8-vertex subgraphs in a 1024-vertex R-MAT background.
Performance is shown for subgraphs of varying density when each foreground vertex is connected
to the background by up to 1, 3 and 5 edges in (a), (b) and (c), respectively.

6

Subgraph Detection in Real-World Networks

To verify that we see similar properties in real graphs that we do in simulated ones, we analyzed
five data sets available in the Stanford Network Analysis Package (SNAP) database [18]. Each network is made undirected before we perform our analysis. The data sets used here are the Epinions
who-trusts-whom graph (Epinions, |V | = 75,879, |E| = 405,740) [19], the arXiv.org collaboration
networks on astrophysics (AstroPh, |V | = 18,722, |E| = 198,050) and condensed matter (CondMat,
|V |=23,133, |E|=93,439) [20], an autonomous system graph (asOregon, |V |=11,461, |E|=32,730)
[21] and the Slashdot social network (Slashdot, |V |=82,168, |E|=504,230) [22]. For each graph, we
compute the top 110 eigenvectors of the modularity matrix and the L1 norm of each. Comparing
each L1 sequence to a ?smoothed? (i.e., low-pass filtered) version, we choose the two eigenvectors that deviate the most from this trend, except in the case of Slashdot, where there is only one
significant deviation.
Plots of the L1 norms and scatterplots in the space of the two eigenvectors that deviate most are
shown in Figure 4. The eigenvectors declared are highlighted. Note that, with the exception of the
asOregon, we see as similar trend in these networks that we did in the R-MAT simulations, with
the L1 norms decreasing as the eigenvalues increase (the L1 trend in asOregon is fairly flat). Also,
with the exception of Slashdot, each dataset has a few eigenvectors with much smaller norms than
those with similar eigenvalues (Slashdot decreases gradually, with one sharp drop at the maximum
eigenvalue).
The subgraphs detected by L1 analysis are presented in Table 1. Two subgraphs are chosen for each
dataset, corresponding to the highlighted points in the scatterplots in Figure 4. For each subgraph
we list the size (number of vertices), density (internal degree divided by the maximum number of
edges), external degree, and the eigenvector that separates it from the background. The subgraphs
are quite dense, at least 80% in each case.
To determine whether a detected subgraph is anomalous with respect to the rest of the graph, we
sample the network and compare the sample graphs to the detected subgraphs in terms of density
and external degree. For each detected subgraph, we take 1 million samples with the same number
of vertices. Our sampling method consists of doing a random walk and adding all neighbors of each
vertex in the path. We then count the number of samples with density above a certain threshold
and external degree below another threshold. These thresholds are the parenthetical values in the
4th and 5th columns of Table 1. Note that the thresholds are set so that the detected subgraphs
comfortably meet them. The 6th column lists the number of samples out of 1 million that satisfy
both thresholds. In each case, far less than 1% of the samples meet the criteria. For the Slashdot
dataset, no sample was nearly as dense as the two subgraphs we selected by thresholding along the
principal eigenvector. After removing samples that are predominantly correlated with the selected
eigenvectors, we get the parenthetical values in the same column. In most cases, all of the samples
meeting the thresholds are correlated with the detected eigenvectors. Upon further inspection, those
remaining are either correlated with another eigenvector that deviates from the overall L1 trend, or
correlated with multiple eigenvectors, as we discuss in the next section.
6

(a) Epinions L1 norms

(b) Epinions scatterplot

(c) AstroPh L1 norms

(d) AstroPh scatterplot

(e) CondMat L1 norms

(f) CondMat scatterplot

(g) asOregon L1 norms

(h) asOregon scatterplot

(i) Slashdot L1 norms

(j) Slashdot scatterplot

Figure 4: Eigenvector L1 norms in real-world network data (left column), and scatterplots of the
projection into the subspace defined by the indicated eigenvectors (right column).

7

dataset

eigenvector

subgraph
size

Epinions
Epinions
AstroPh
AstroPh
CondMat
CondMat
asOregon
asOregon
Slashdot
Slashdot

u36
u45
u57
u106
u29
u36
u6
u32
u1 > 0.08
u1 > 0.07

34
27
30
24
19
20
15
6
36
51

subgraph
(sample)
density
80% (70%)
83% (75%)
100% (90%)
100% (90%)
100% (90%)
83% (75%)
96% (85%)
93% (80%)
95% (90%)
89% (80%)

subgraph
(sample)
external degree
721 (1000)
869 (1200)
93 (125)
73 (100)
2 (50)
70 (120)
1089 (1500)
177 (200)
10570 (?)
12713 (?)

# samples
that meet
threshold
46 (0)
261 (6)
853 (0)
944 (0)
866 (0)
1596 (0)
23 (0)
762 (393)
0 (0)
0 (0)

Table 1: Subgraphs detected by L1 analysis, and a comparison with randomly-sampled subgraphs
in the same network.

Figure 5: An 8-vertex clique that does not create an anomalously small L1 norm in any eigenvector.
The scatterplot looks similar to one in which the subgraph is detectable, but is rotated.

7

Conclusion

In this article we have demonstrated the efficacy of using eigenvector L1 norms of a graph?s modularity matrix to detect small, dense anomalous subgraphs embedded in a background. Casting the
problem of subgraph detection in a signal processing context, we have provided the intuition behind
the utility of this approach, and empirically demonstrated its effectiveness on a concrete example:
detection of a dense subgraph embedded into a graph generated using known parameters. In real
network data we see trends similar to those we see in simulation, and examine outliers to see what
subgraphs are detected in real-world datasets.
Future research will include the expansion of this technique to reliably detect subgraphs that can be
separated from the background in the space of a small number of eigenvectors, but not necessarily
one. While the L1 norm itself can indicate the presence of an embedding, it requires the subgraph to
be highly correlated with a single eigenvector. Figure 5 demonstrates a case where considering multiple eigenvectors at once would likely improve detection performance. The scatterplot in this figure
looks similar to the one in Figure 1(c), but is rotated such that the subgraph is equally aligned with
the two eigenvectors into which the matrix has been projected. There is not significant separation in
any one eigenvector, so it is difficult to detect using the method presented in this paper. Minimizing
the L1 norm with respect to rotation in the plane will likely make the test more powerful, but could
prove computationally expensive. Other future work will focus on developing detectability bounds,
the application of which would be useful when developing detection methods like the algorithm
outlined here.
Acknowledgments
This work is sponsored by the Department of the Air Force under Air Force Contract FA8721-05-C0002. Opinions, interpretations, conclusions and recommendations are those of the author and are
not necessarily endorsed by the United States Government.
8

References
[1] J. Sun, J. Qu, D. Chakrabarti, and C. Faloutsos, ?Neighborhood formation and anomaly detection in bipartite graphs,? in Proc. IEEE Int?l. Conf. on Data Mining, Nov. 2005.
[2] J. Sun, Y. Xie, H. Zhang, and C. Faloutsos, ?Less is more: Compact matrix decomposition for
large sparse graphs,? in Proc. SIAM Int?l. Conf. on Data Mining, 2007.
[3] C. C. Noble and D. J. Cook, ?Graph-based anomaly detection,? in Proc. ACM SIGKDD Int?l.
Conf. on Knowledge Discovery and Data Mining, pp. 631?636, 2003.
[4] W. Eberle and L. Holder, ?Anomaly detection in data represented as graphs,? Intelligent Data
Analysis, vol. 11, pp. 663?689, December 2007.
[5] C. E. Priebe, J. M. Conroy, D. J. Marchette, and Y. Park, ?Scan statistics on enron graphs,?
Computational & Mathematical Organization Theory, vol. 11, no. 3, pp. 229?247, 2005.
[6] T. Id?e and H. Kashima, ?Eigenspace-based anomaly detection in computer systems,? in Proc.
KDD ?04, pp. 440?449, 2004.
[7] S. Hirose, K. Yamanishi, T. Nakata, and R. Fujimaki, ?Network anomaly detection based on
eigen equation compression,? in Proc. KDD ?09, pp. 1185?1193, 2009.
[8] M. E. J. Newman, ?Finding community structure in networks using the eigenvectors of matrices,? Phys. Rev. E, vol. 74, no. 3, 2006.
[9] J. Ruan and W. Zhang, ?An efficient spectral algorithm for network community discovery and
its applications to biological and social networks,? in Proc. IEEE Int?l Conf. on Data Mining,
pp. 643?648, 2007.
[10] S. White and P. Smyth, ?A spectral clustering approach to finding communities in graphs,? in
Proc. SIAM Data Mining Conf., 2005.
[11] B. A. Miller, N. T. Bliss, and P. J. Wolfe, ?Toward signal processing theory for graphs and other
non-Euclidean data,? in Proc. IEEE Int?l Conf. on Acoustics, Speech and Signal Processing,
pp. 5414?5417, 2010.
[12] T. Mifflin, ?Detection theory on random graphs,? in Proc. Int?l Conf. on Information Fusion,
pp. 954?959, 2009.
[13] D. Chakrabarti and C. Faloutsos, ?Graph mining: Laws, generators, and algorithms,? ACM
Computing Surveys, vol. 38, no. 1, 2006.
[14] F. Chung, L. Lu, and V. Vu, ?The spectra of random graphs with given expected degrees,? Proc.
of National Academy of Sciences of the USA, vol. 100, no. 11, pp. 6313?6318, 2003.
[15] D. Chakrabarti, Y. Zhan, and C. Faloutsos, ?R-MAT: A recursive model for graph mining,? in
Proc. Fourth SIAM Int?l Conference on Data Mining, vol. 6, pp. 442?446, 2004.
[16] T. S. Motzkin and E. G. Straus, ?Maxima for graphs and a new proof of a theorem of Tur?an,?
Canad. J. Math., vol. 17, pp. 533?540, 1965.
[17] C. Ding, T. Li, and M. I. Jordan, ?Nonnegative matrix factorization for combinatorial optimization: Spectral clustering, graph matching, and clique finding,? in Proc. IEEE Int?l Conf.
on Data Mining, pp. 183?192, 2008.
[18] J. Leskovec, ?Stanford network analysis package.? http://snap.stanford.edu.
[19] M. Richardson, R. Agrawal, and P. Domingos, ?Trust management for the semantic web,? in
Proc. ISWC, 2003.
[20] J. Leskovec, J. Kleinberg, and C. Faloutsos, ?Graph evolution: Densification and shinking
diameters,? ACM Trans. on Knowledge Discovery from Data, vol. 1, no. 1, 2007.
[21] J. Leskovec, J. Kleinberg, and C. Faloutsos, ?Graphs over time: Densification laws, shinking
diameters and possible explanations,? in Proc. KDD ?05, 2005.
[22] J. Leskovec, K. Lang, A. Dasgupta, and M. Mahoney, ?Community structure in large networks:
Natural cluster sizes and the absence of large well-defined clusters.? arXiv.org:0810.1355,
2008.

9


----------------------------------------------------------------

