query sentence: Storing covariance by the associative long-term potentiation and depression of synaptic strengths in the hippocampus
---------------------------------------------------------------------
title: 100-storing-covariance-by-the-associative-long-term-potentiation-and-depression-of-synaptic-strengths-in-the-hippocampus.pdf

394

STORING COVARIANCE BY THE ASSOCIATIVE
LONG?TERM POTENTIATION AND DEPRESSION
OF SYNAPTIC STRENGTHS IN THE HIPPOCAMPUS
Patric K. Stanton? and Terrence J. Sejnowski t
Department of Biophysics
Johns Hopkins University
Baltimore, MD 21218
ABSTRACT

In modeling studies or memory based on neural networks, both the selective
enhancement and depression or synaptic strengths are required ror effident storage
or inrormation (Sejnowski, 1977a,b; Kohonen, 1984; Bienenstock et aI, 1982;
Sejnowski and Tesauro, 1989). We have tested this assumption in the hippocampus,
a cortical structure or the brain that is involved in long-term memory. A brier,
high-frequency activation or excitatory synapses in the hippocampus produces an
increase in synaptic strength known as long-term potentiation, or LTP (BUss and
Lomo, 1973), that can last ror many days. LTP is known to be Hebbian since it
requires the simultaneous release or neurotransmitter from presynaptic terminals
coupled with postsynaptic depolarization (Kelso et al, 1986; Malinow and Miller,
1986; Gustatrson et al, 1987). However, a mechanism ror the persistent reduction or
synaptic strength that could balance LTP has not yet been demonstrated. We studied the associative interactions between separate inputs onto the same dendritic
trees or hippocampal pyramidal cells or field CAl, and round that a low-frequency
input which, by itselr, does not persistently change synaptic strength, can either
increase (associative LTP) or decrease in strength (associative long-term depression
or LTD) depending upon whether it is positively or negatively correlated in time
with a second, high-frequency bursting input. LTP or synaptic strength is Hebbian,
and LTD is anti-Hebbian since it is elicited by pairing presynaptic firing with postsynaptic hyperpolarization sufficient to block postsynaptic activity. Thus, associative LTP and associative LTO are capable or storing inrormation contained in the
covariance between separate, converging hippocampal inputs?

?Present address: Dep~ents of NeW'Oscience and Neurology, Albert Einstein College
of Medicine, 1410 Pelham Parkway South, Bronx, NY 10461 USA.
tPresent address: Computational Neurobiology Laboratory, The Salk Institute, P.O. Box
85800, San Diego, CA 92138 USA.

Storing Covariance by Synaptic Strengths in the Hippocampus

INTRODUCTION
Associative LTP can be produced in some hippocampal neuroos when lowfrequency. (Weak) and high-frequency (Strong) inputs to the same cells are simultaneously activated (Levy and Steward, 1979; Levy and Steward, 1983; Barrionuevo and
Brown, 1983). When stimulated alone, a weak input does not have a long-lasting effect
on synaptic strength; however, when paired with stimulation of a separate strong input
sufficient to produce homo synaptic LTP of that pathway, the weak pathway is associatively potentiated. Neural network modeling studies have predicted that, in addition to
this Hebbian form of plasticity, synaptic strength should be weakened when weak and
strong inputs are anti-correlated (Sejnowski, 1977a,b; Kohonen, 1984; Bienenstock et al,
1982; Sejnowski and Tesauro, 1989). Evidence for heterosynaptic depression in the hippocampus has been found for inputs that are inactive (Levy and Steward, 1979; Lynch et
al, 1977) or weakly active (Levy and Steward, 1983) during the stimulation of a strong
input, but this depression did not depend on any pattern of weak input activity and was
not typically as long-lasting as LTP.
Therefore, we searched for conditions under which stimulation of a hippocampal
pathway, rather than its inactivity, could produce either long-term depression or potentiation of synaptic strengths, depending on the pattern of stimulation. The stimulus paradigm that we used, illustrated in Fig. I, is based on the finding that bursts of stimuli at 5
Hz are optimal in eliciting LTP in the hippocampus (Larson and Lynch, 1986). A highfrequency burst (S'IRONG) stimulus was applied to Schaffer collateral axons and a lowfrequency (WEAK) stimulus given to a separate subicular input coming from the opposite side of the recording site, but terminating on dendrites of the same population of CAl
pyramidal neurons. Due to the rhythmic nature of the strong input bursts, each weak
input shock could be either superimposed on the middle of each burst of the strong input
(IN PHASE), or placed symmetrically between bursts (OUT OF PHASE).

RESULTS
Extracellular evoked field potentials were recorded from the apical dendritic and
somatic layers of CAl pyramidal cells. The weak stimulus train was first applied alone
and did not itself induce long-lasting changes. The strong site was then stimulated alone,
which elicited homosynaptic LTP of the strong pathway but did not significantly alter
amplitude of responses to the weak input. When weak and strong inputs were activated
IN PHASE, there was an associative LTP of the weak input synapses, as shown in Fig.
2a. Both the synaptic excitatory post-synaptic potential (e.p.s.p.) (Ae.p.s.p. = +49.8 ?
7.8%, n=20) and population action potential (&Pike = +65.4 ? 16.0%, n=14) were
significantly enhanced for at least 60 min up to 180 min following stimulation.
In contrast, when weak and strong inputs were applied OUT OF PHASE, they elicited an associative long-term depression (LTO) of the weak input synapses, as shown in
Fig. 2b. There was a marked reduction in the population spike (-46.5 ? 11.4%, n=10)
with smaller decreases in the e.p.s.p. (-13.8 ? 3.5%, n=13). Note that the stimulus patterns applied to each input were identical in these two experiments, and only the relative

395

396

Stanton and Sejnowski

phase of the weak and strong stimuli was altered. With these stimulus patterns. synaptic
strength could be repeatedly enhanced and depressed in a single slice. as illustrated in Fig
2c. As a control experiment to determine whether information concerning covariance
between the inputs was actually a determinant of plasticity. we combined the in phase
and out of phase conditions, giving both the weak input shocks superimposed on the
bursts plus those between the bursts. for a net frequency of 10 Hz. This pattern. which
resulted in zero covariance between weak and strong inputs. produced no net change in
weak input synaptic strength measmed by extracellular evoked potentials. Thus. the assoa

b
A.SSOCIA.TIVE STIMULUS PA.RA.DIGMS
POSJTIVE.LY CORKELA TED ? "IN PHASE"

~K~~ _I~__~I____~I____~I_
SI1IONG,NJO\IT

. u.Jj1l 11l. -1---1&1111.....
11 ---1&1
111.....
11 ---,I~IIII

NEGATIVELY CORRELATED? 'our OF PHASE"
W[AKIN'lTf

STIONG 'N''''

~I

11111

--,-;

11111

11111

Figure 1. Hippocampal slice preparation and stimulus paradigms. a: The in vitro hippocampal slice showing recording sites in CAl pyramidal cell somatic (stratum pyramidale) and dendritic (stratum radiatum) layers. and stimulus sites activating Schaffer collateral (STRONG) and commissural (WEAK) afferents. Hippocampal slices (400 Jlm
thick) were incubated in an interface slice chamber at 34-35 0 C. Extracellular (1-5 M!l
resistance, 2M NaCI filled) and intracellular (70-120 M 2M K-acetate filled) recording electrodes. and bipolar glass-insulated platinum wire stimulating electrodes (50 Jlm
tip diameter). were prepared by standard methods (Mody et al, 1988). b: Stimulus paradigms used. Strong input stimuli (STRONG INPUT) were four trains of 100 Hz bursts.
Each burst had 5 stimuli and the interburst interval was 200 msec. Each train lasted 2
seconds for a total of 50 stimuli. Weak input stimuli (WEAK INPUT) were four trains of
shocks at 5 Hz frequency. each train lasting for 2 seconds. When these inputs were IN
PHASE. the weak single shocks were superimposed on the middle of each burst of the
strong input. When the weak input was OUT OF PHASE. the single shocks were placed
symmetrically between the bursts.

n.

Storing Covariance by Synaptic Strengths in the Hippocampus

ciative LTP and LTD mechanisms appear to be balanced in a manner ideal for the
storage of temporal covariance relations.
The simultaneous depolarization of the postsynaptic membrane and activation of
glutamate receptors of the N-methyl-D-aspartate (NMDA) subtype appears to be necessary for LTP induction (Collingridge et ai, 1983; Harris et al, 1984; Wigstrom and Gustaffson, 1984). The SJ?read of current from strong to weak synapses in the dendritic tree,
d

ASSOCIATIVE

LON(;.TE~

I'OTENTIATION

LONG-TE~

DE,/tESSION

-

!!Ll!!!!.

b

ASSOCIATIVE

I

11111

?

11111.
I

c

e...

I

I

I

I

Figure 2. mustration of associative long-term potentiation (LTP) and associative longterm depression (LTD) using extracellular recordings. a: Associative LTP of evoked
excitatory postsynaptic potentials (e.p.s.p.'s) and population action potential responses in
the weak inpuL Test responses are shown before (Pre) and 30 min after (post) application of weak stimuli in phase with the coactive strong input. b: Associative LTD of
evoked e.p.s.p.'s and population spike responses in the weak input. Test responses are
shown before (Pre) and 30 min after (post) application of weak stimuli out of phase with
the coactive strong input. c: Time course of the changes in population spike amplitude
observed at each input for a typical experiment. Test responses from the strong input (S,
open circles), show that the high-frequency bursts (5 pulses/l00 Hz, 200 msec interburst
interval as in Fig. 1) elicited synapse-specific LTP independent of other input activity.
Test responses from the weak input (W. filled circles) show that stimulation of the weak
pathway out of phase with the strong one produced associative LTD (Assoc LTD) of this
input. Associative LTP (Assoc LTP) of the same pathway was then elicited following in
phase stimulation. Amplitude and duration of associative LTD or LTP could be increased
by stimulating input pathways with more trains of shocks.

397

398

Stanton and Sejnowski

coupled with release of glutamate from the weak inputs, could account for the ability of
the strong pathway to associatively potentiate a weak one (Kelso et al, 1986; Malinow
and Miller, 1986; Gustaffson et al, 1987). Consistent with this hypothesis, we find that
the NMDA receptor antagonist 2-amino-S-phosphonovaleric acid (APS, 10 J.1M) blocks
induction of associative LTP in CAl pyramidal neurons (data not shown, n=S). In contrast, the application of APS to the bathing solution at this same concentration had no
significant effect on associative LTD (data not shown, n=6). Thus, the induction of LTD
seems to involve cellular mechanisms different from associative LTP.
The conditions necessary for LTD induction were explored in another series of
experiments using intracellular recordings from CAl pyramidal neurons made using
standard techniques (Mody et al, 1988). Induction of associative LTP (Fig 3; WEAK
S+W IN PHASE) produced an increase in amplitude of the single cell evoked e.p.s.p. and
a lowered action potential threshold in the weak pathway, as reported previously (Barrionuevo and Brown, 1983). Conversely, the induction of associative LTD (Fig. 3;
WEAK S+W OUT OF PHASE) was accompanied by a long-lasting reduction of e.p.s.p.
amplitude and reduced ability to elicit action potential firing. As in control extracellular
experiments, the weak input alone produced no long-lasting alterations in intracellular
e.p.s.p.'s or firing properties, while the strong input alone yielded specific increases of
the strong pathway e.p.s.p. without altering e.p.s.p. 's elicited by weak input stimulation.

PRE

30 min POST
S+W OUT OF PHASE

30 min POST
S+W IN PHASE

Figure 3. Demonstration of associative LTP and LTD using intracellular recordings from
a CAl pyramidal neuron. Intracellular e.p.s.p.'s prior to repetitive stimulation (pre), 30
min after out of phase stimulation (S+W OUT OF PHASE), and 30 min after subsequent in phase stimuli (S+W IN PHASE). The strong input (Schaffer collateral side,
lower traces) exhibited LTP of the evoked e.p.s.p. independent of weak input activity.
Out of phase stimulation of the weak (Subicular side, upper traces) pathway produced a
marked, persistent reduction in e.p.s.p. amplitude. In the same cell, subsequent in phase
stimuli resulted in associative LTP of the weak input that reversed the LTD and enhanced
amplitude of the e.p.s.p. past the original baseline. (RMP = -62 mY, RN = 30 MO)

Storing Covariance by Synaptic Strengths in the Hippocampus

A weak stimulus that is out of phase with a strong one anives when the postsynaptic neuron is hyperpolarized as a consequence of inhibitory postsynaptic potentials and
afterhyperpolarization from mechanisms intrinsic to pyramidal neurons. This suggests
that postsynaptic hyperpolarization coupled with presynaptic activation may trigger L'ID.
To test this hypothesis, we injected current with intracellular microelectrodes to hyperpolarize or depolarize the cell while stimulating a synaptic input. Pairing the injection of
depolarizing current with the weak input led to LTP of those synapses (Fig. 4a; STIM;

a

PRE

? ?IDPOST
S'I1M ? DEPOL

~l"V
lS.,.c

r
," i

COI'ITROL

-Jj

b

I

--" \

"----

(W.c:ULVllj

PRE

lOlIIin POST
STlM ? HYPERPOL

Figure 4. Pairing of postsynaptic hyperpolarization with stimulation of synapses on CAl
hippocampal pyramidal neurons produces L'ID specific to the activated pathway, while
pairing of postsynaptic depolarization with synaptic stimulation produces synapsespecific LTP. a: Intracellular evoked e.p.s.p.'s are shown at stimulated (STIM) and
unstimulated (CONTROL) pathway synapses before (Pre) and 30 min after (post) pairing a 20 mY depolarization (constant current +2.0 nA) with 5 Hz synaptic stimulation.
The stimulated pathway exhibited associative LTP of the e.p.s.p., while the control,
unstimulated input showed no change in synaptic strength. (RMP = -65 mY; RN = 35
Mfl) b: Intracellular e.p.s.p. 's are shown evoked at stimulated and control pathway
synapses before (Pre) and 30 min after (post) pairing a 20 mV hyperpolarization (constant current -1.0 nA) with 5 Hz synaptic stimulation. The input (STIM) activated during
the hyperpolarization showed associative LTD of synaptic evoked e.p.s.p.'s, while
synaptic strength of the silent input (CONTROL) was unaltered. (RMP =-62 mV; RN =
38M!l)

399

400

Stanton and Sejnowski

+64.0 -9.7%, n=4), while a control input inactive during the stimulation did not change
(CONTROL), as reported previously (Kelso et al, 1986; Malinow and Miller, 1986; Gustaffson et al, 1987). Conversely, prolonged hyperpolarizing current injection paired with
the same low-frequency stimuli led to induction of LTD in the stimulated pathway (Fig.
4b; STIM; -40.3 ? 6.3%, n=6). but not in the unstimulated pathway (CONTROL). The
application of either depolarizing current, hyperpolarizing current, or the weak 5 Hz
synaptic stimulation alone did not induce long-term alterations in synaptic strengths.
Thus. hyperpolarization and simultaneous presynaptic activity supply sufficient conditions for the induction of LTD in CAl pyramidal neurons.

CONCLUSIONS
These experiments identify a novel fono of anti-Hebbian synaptic plasticity in the
hippocampus and confirm predictions made from modeling studies of information storage
in neural networks. Unlike previous reports of synaptic depression in the hippocampus,
the plasticity is associative, long-lasting, and is produced when presynaptic activity
occurs while the postsynaptic membrane is hyperpolarized. In combination with Hebbian
mechanisms also present at hippocampal synapses. associative LTP and associative LTD
may allow neurons in the hippocampus to compute and store covariance between inputs
(Sejnowski, 1977a,b; Stanton and Sejnowski. 1989). These finding make temporal as
well as spatial context an important feature of memory mechanisms in the hippocampus.
Elsewhere in the brain, the receptive field properties of cells in cat visual cortex
can be altered by visual experience paired with iontophoretic excitation or depression of
cellular activity (Fregnac et al, 1988; Greuel et al, 1988). In particular, the chronic hyperpolarization of neurons in visual cortex coupled with presynaptic transmitter release leads
to a long-teno depression of the active. but not inactive, inputs from the lateral geniculate
nucleus (Reiter and Stryker, 1988). Thus. both Hebbian and anti-Hebbian mechanisms
found in the hippocampus seem to also be present in other brain areas, and covariance of
firing patterns between converging inputs a likely key to understanding higher cognitive
function.
This research was supported by grants from the National Science Foundation and
the Office of Naval research to TJS. We thank Drs. Charles Stevens and Richard Morris
for discussions about related experiments.

Rererences
Bienenstock, E., Cooper. LN. and Munro. P. Theory for the development of neuron
selectivity: orientation specificity and binocular interaction in visual cortex. J. Neurosci. 2. 32-48 (1982).
Barrionuevo, G. and Brown, T.H. Associative long-teno potentiation in hippocampal
slices. Proc. Nat. Acad. Sci. (USA) 80, 7347-7351 (1983).
Bliss. T.V.P. and Lomo, T. Long-lasting potentiation of synaptic ttansmission in the dentate area of the anaesthetized rabbit following stimulation of the perforant path. J.
Physiol. (Lond.) 232. 331-356 (1973).

Storing Covariance by Synaptic Strengths in the Hippocampus

Collingridge, GL., Kehl, SJ. and McLennan, H. Excitatory amino acids in synaptic
transmission in the Schaffer collateral-commissural pathway of the rat hippocampus. J.
Physiol. (Lond.) 334, 33-46 (1983).
Fregnac, Y., Shulz, D., Thorpe, S. and Bienenstock, E. A cellular analogue of visual cortical plasticity. Nature (Lond.) 333, 367-370 (1988).
Greuel. J.M.. Luhmann. H.J. and Singer. W. Pharmacological induction of usedependent receptive field modifications in visual cortex. Science 242,74-77 (1988).
Gustafsson, B., Wigstrom, H., Abraham, W.C. and Huang. Y.Y. Long-term potentiation
in the hippocampus using depolarizing current pulses as the conditioning stimulus to
single volley synaptic potentials. J. Neurosci. 7, 774-780 (1987).
Harris. E.W., Ganong, A.H. and Cotman, C.W. Long-term potentiation in the hippocampus involves activation of N-metbyl-D-aspartate receptors. Brain Res. 323, 132137 (1984).
Kelso, S.R.. Ganong, A.H. and Brown, T.H. Hebbian synapses in hippocampus. Proc.
Natl. Acad. Sci. USA 83, 5326-5330 (1986).
Kohonen. T. Self-Organization and Associative Memory. (Springer-Verlag. Heidelberg,
1984).
Larson. J. and Lynch. G. Synaptic potentiation in hippocampus by patterned stimulation
involves two events. Science 232, 985-988 (1986).
Levy. W.B. and Steward, O. Synapses as associative memory elements in the hippocampal formation. Brain Res. 175,233-245 (1979).
Levy. W.B. and Steward, O. Temporal contiguity requirements for long-term associative
potentiation/depression in the hippocampus. Neuroscience 8, 791-797 (1983).
Lynch. G.S., Dunwiddie. T. and Gribkoff. V. Heterosynaptic depression: a postsynaptic
correlate oflong-term potentiation. Nature (Lond.) 266. 737-739 (1977).
Malinow. R. and Miller, J.P. Postsynaptic hyperpolarization during conditioning reversibly blocks induction of long-term potentiation Nature (Lond.)32.0. 529-530 (1986).
Mody. I.. Stanton. PK. and Heinemann. U. Activation of N-methyl-D-aspartate
(NMDA) receptors parallels changes in cellular and synaptic properties of dentate
gyrus granule cells after kindling. J. Neurophysiol. 59. 1033-1054 (1988).
Reiter, H.O. and Stryker, M.P. Neural plasticity without postsynaptic action potentials:
Less-active inputs become dominant when kitten visual cortical cells are pharmacologically inhibited. Proc. Natl. Acad. Sci. USA 85, 3623-3627 (1988).
Sejnowski, T J. and Tesauro, G. Building network learning algorithms from Hebbian
synapses, in: Brain Organization and Memory JL. McGaugh, N.M. Weinberger, and
G. Lynch, Eds. (Oxford Univ. Press, New York, in press).
Sejnowski, TJ. Storing covariance with nonlinearly interacting neurons. J. Math. Biology 4, 303-321 (1977).
Sejnowski, T. J. Statistical constraints on synaptic plasticity. J. Theor. Biology 69, 385389 (1977).
Stanton, P.K. and Sejnowski, TJ. Associative long-term depression in the hippocampus:
Evidence for anti-Hebbian synaptic plasticity. Nature (Lond.), in review.
Wigstrom, H. and Gustafsson, B. A possible correlate of the postsynaptic condition for
long-lasting potentiation in the guinea pig hippocampus in vitro. Neurosci. Lett. 44,
327?332 (1984).

401


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4871-correlations-strike-back-again-the-case-of-associative-memory-retrieval.pdf

Correlations strike back (again): the case of
associative memory retrieval

Cristina Savin1
cs664@cam.ac.uk

Peter Dayan2
dayan@gatsby.ucl.ac.uk

M?at?e Lengyel1
m.lengyel@eng.cam.ac.uk
1

Computational & Biological Learning Lab, Dept. Engineering, University of Cambridge, UK
2
Gatsby Computational Neuroscience Unit, University College London, UK

Abstract
It has long been recognised that statistical dependencies in neuronal activity need
to be taken into account when decoding stimuli encoded in a neural population.
Less studied, though equally pernicious, is the need to take account of dependencies between synaptic weights when decoding patterns previously encoded in an
auto-associative memory. We show that activity-dependent learning generically
produces such correlations, and failing to take them into account in the dynamics
of memory retrieval leads to catastrophically poor recall. We derive optimal network dynamics for recall in the face of synaptic correlations caused by a range of
synaptic plasticity rules. These dynamics involve well-studied circuit motifs, such
as forms of feedback inhibition and experimentally observed dendritic nonlinearities. We therefore show how addressing the problem of synaptic correlations leads
to a novel functional account of key biophysical features of the neural substrate.

1

Introduction

Auto-associative memories have a venerable history in computational neuroscience. However, it is
only rather recently that the statistical revolution in the wider field has provided theoretical traction
for this problem [1]. The idea is to see memory storage as a form of lossy compression ? information
on the item being stored is mapped into a set of synaptic changes ? with the neural dynamics during
retrieval representing a biological analog of a corresponding decompression algorithm. This implies
there should be a tight, and indeed testable, link between the learning rule used for encoding and the
neural dynamics used for retrieval [2].
One issue that has been either ignored or trivialized in these treatments of recall is correlations
among the synapses [1?4] ? beyond the perfect (anti-)correlations emerging between reciprocal
synapses with precisely (anti-)symmetric learning rules [5]. There is ample experimental data for
the existence of such correlations: for example, in rat visual cortex, synaptic connections tend to
cluster together in the form of overrepresented patterns, or motifs, with reciprocal connections being
much more common than expected by chance, and the strengths of the connections to and from
each neuron being correlated [6]. The study of neural coding has indicated that it is essential to
treat correlations in neural activity appropriately in order to extract stimulus information well [7?
9]. Similarly, it becomes pressing to examine the nature of correlations among synaptic weights in
auto-associative memories, the consequences for retrieval of ignoring them, and methods by which
they might be accommodated.
1

Here, we consider several well-known learning rules, from simple additive ones to bounded synapses
with metaplasticity, and show that, with a few significant exceptions, they induce correlations between synapses that share a pre- or a post-synaptic partner. To assess the importance of these dependencies for recall, we adopt the strategy of comparing the performance of decoders which either
do or do not take them into account [10], showing that they do indeed have an important effect on
efficient retrieval. Finally, we show that approximately optimal retrieval involves particular forms
of nonlinear interactions between different neuronal inputs, as observed experimentally [11].

2

General problem formulation

We consider a network of N binary neurons that enjoy all-to-all connectivity.1 As is conventional,
and indeed plausibly underpinned by neuromodulatory interactions [12], we assume that network
dynamics do not play a role during storage (with stimuli being imposed as patterns of activity on the
neurons), and that learning does not occur during retrieval.
To isolate the effects of different plasticity rules on synaptic correlations from other sources of
correlations, we assume that the patterns of activity inducing the synaptic changes have no particular
structure, i.e. their distribution factorizes. For further simplicity, we take these activity patterns to
be binary with pattern density f , i.e. a prior over patterns defined as:
Y
Pstore (x) =
Pstore (xi )
Pstore (xi ) = f xi ? (1 ? f )1?xi
(1)
i

During recall, the network is presented with a cue, x
?, which is a noisy or partial version of one
of the originally stored patterns. Network dynamics should complete this partial pattern, using the
information in the weights W (and the cue). We start by considering arbitrary dynamics; later we
impose the critical constraint for biological realisability that they be strictly local, i.e. the activity of
neuron i should depend exclusively on inputs through incoming synapses Wi,? .
Since information storage by synaptic plasticity is lossy, recall is inherently a probabilistic inference
problem [1, 13] (Fig. 1a), requiring estimation of the posterior over patterns, given the information
in the weights and the recall cue:
? ) ? Pstore (x) ? Pnoise (?
P (x|W, x
x|x) ? P(W|x)

(2)

This formulation has formed the foundation of recent work on constructing efficient autoassociative
recall dynamics for a range of different learning rules [2?4]. In this paper, we focus on the last term
P(W|x), which expresses the probability of obtaining W as the synaptic weight matrix when x is
stored along with T ? 1 random patterns (sampled from the prior, Eq. 1). Critically, this is where
we diverge from previous analyses that assumed this distribution was factorised, or only trivially
correlated due to reciprocal synapses being precisely (anti-)symmetric [1, 2, 4]. In contrast, we
explicitly study the emergence and effects of non-trivial correlations in the synaptic weight matrixdistribtion, because almost all synaptic plasticity rules induce statistical dependencies between the
synaptic weights of each neuron (Fig. 1a, d).
The inference problem expressed by Eq. 2 can be translated into neural dynamics in several ways
? dynamics could be deterministic, attractor-like, converging to the most likely pattern (a MAP
estimate) of the distribution of x [2], or to a mean-field approximate solution [3]; alternatively, the
dynamics could be stochastic, with the activity over time representing samples from the posterior,
and hence implicitly capturing the uncertainty associated with the answer [4]. We consider the latter.
Since we estimate performance by average errors, the optimal response is the mean of the posterior,
which can be estimated by integrating the activity of the network during retrieval.
We start by analysing the class of additive learning rules, to get a sense for the effect of correlations on retrieval. Later, we focus on multi-state synapses, for which learning rules are described
by transition probabilities between the states [14]. These have been used to capture a variety of
important biological constraints such as bounds on synaptic strengths and metaplasticity, i.e. the
fact that synaptic changes induced by a certain activity pattern depend on the history of activity at
the synapse [15]. The two classes of learning rule are radically different; so if synaptic correlations
matter during retrieval in both cases, then the conclusion likely applies in general.
1
Complete connectivity simplifies the computation of the parameters for the optimal dynamics for cascadelike learning rules considered in the following, but is not necessary for the theory.

2

1

covariance rule
simple Hebb rule
cortical data (Song 2005)

0.5
0

d

e
error (%)

1

corr

c

error (%)

b
corr

a

0.5
0

10 control
exact (considering correlations)
simple (ignoring correlations)

5
0

25

30

50

100

50

100

N

20
10 control
0

25

N

Figure 1: Memory recall as inference and additive learning rules. a. Top: Synaptic weights,
W, arise by storing the target pattern x together with T ?1 other patterns, {x(t) }t=1...T?1 . During
? , is a noisy version of the target pattern. The task of recall is to infer x given W
recall, the cue, x
and x
? (by marginalising out {x(t) }). Bottom: The activity of neuron i across the stored patterns is
a source of shared variability between synapses connecting it to neurons j and k. b-c. Covariance
rule: patterns of synaptic correlations and recall performance for retrieval dynamics ignoring or
considering synaptic correlations; T = 5. d-e. Same for the simple Hebbian learning rule. The
control is an optimal decoder that ignores W.

3

Additive learning rules

Local additive learning rules assume that synaptic changes induced by different activity patterns
combine additively; such that storing a sequence of T patterns from Pstore (x), results in weights
P
(t)
(t)
Wij = t ?(xi , xj ), with function ?(xi , xj ) describing the change in synaptic strength induced
by presynaptic activity xj and postsynaptic activity xi . We consider a generalized Hebbian form for
this function, with ? (xi , xj ) = (xi ? ?)(xj ? ?). This class includes, for example, the covariance
rule (? = ? = f ), classically used in Hopfield networks, or simple Hebbian learning (? = ? = 0).
As synaptic changes are deterministic, the only source of uncertainty in the distribution P(W|x)
is the identity of the other stored patterns. To estimate this, let us first consider the distribution of
the weights after storing one random pattern from Pstore (x). The mean ? and covariance C of the
weight change induced by this event can be computed as:2
Z
Z

? = Pstore (x)?| (x)dx,
C = Pstore (x) ?| (x) ? ?| (x)T dx ? ? ? ?T
(3)
Since the rule is additive and the patterns are independent, the mean and covariance scale linearly
with the number of intervening patterns. Hence, the distribution over possible weight values at
recall, given that pattern x is stored along with T ? 1 other, random, patterns has mean ?W =
?(x) + (T ? 1) ? ?, and covariance CW = (T ? 1) ? C. Most importantly, because the rule is
additive, in the limit of many stored patterns (and in practice even for modest values of T ), the
distribution P(W|x) approaches a multivariate Gaussian that is characterized completely by these
two quantities; moreover, its covariance is independent of x.
For retrieval dynamics based on Gibbs sampling, the key quantity is the log-odds ratio


P(xi = 1|x?i , W, x
?)
(4)
Ii = log
P(xi = 0|x?i , W, x
?)
for neuron i, which could be represented by the total current entering the unit. This would translate
into a probability of firing given by the sigmoid activation function f (Ii ) = 1/(1 + e?Ii ).
The total current entering a neuron is a sum of two terms: one term from the external input of the
form c1 ? x
?i + c2 (with constants c1 and c2 determined by parameters f and r [16]), and one term
from the recurrent input, of the form:

T
 
T



1
(0)
(0)
(1)
(1)
Iirec =
(5)
W| ? ?W
C?1 W| ? ?W ? W| ? ?W
C?1 W| ? ?W
2(T ?1)
2
For notational convenience, we use a column-vector form of the matrix of weight changes ?, and the
weight matrix W, marked by subscript | .

3

(0/1)

where ?W = ?| (x(0/1) )+(T?1)? and x(0/1) is the vector of activities obtained from x in which
the activity of neuron i is set to 0, or 1, respectively.
It is easy to see that for the covariance rule, ? (xi , xj ) = (xi ? f )(xj ? f ), synapses sharing
a single pre- or post-synaptic partner happen to be uncorrelated (Fig. 1b). Moreover, as for any
(anti-)symmetric additive learning rule, reciprocal connections are perfectly correlated (Wij = Wji ).
The (non-degenerate part of the) covariance matrix in this case becomes diagonal, and the total
current in optimal retrieval reduces to simple linear dynamics :
Ii =

1
2
(T ? 1) ?W

X

Wij xj ?

j

|

{z

}

recurrent input


X
(1 ? 2f )2 X
1 ? 2f
Wij ? f 2
xj ? f
2
2
j
j
| {z }
{z
}
| {z }
|
feedback inhibition

homeostatic term

(6)

constant

2
where ?W
is the variance of a synaptic weight resulting from storing a single pattern. This term
includes a contribution from recurrent excitatory input, dynamic feedback inhibition (proportional
to the total population activity) and a homeostatic term that reduces neuronal excitability as function
of the net strength of its synapses (a proxy for average current the neuron expects to receive) [17].
Reassuringly, the optimal decoder for the covariance rule recovers a form for the input current that is
closely related to classic Hopfield-like [5] dynamics (with external field [1, 18]): feedback inhibition
is needed only when the stored patterns are not balanced (f 6= 0.5); for the balanced case, the
homeostatic term can be integrated in the recurrent current, by rewriting neural activities as spins.
In sum, for the covariance rule, synapses are fortuitously uncorrelated (except for symmetric pairs
which are perfectly correlated), and thus simple, classical linear recall dynamics suffice (Fig. 1c).

The covariance rule is, however, the exception rather than the rule. For example, for simple Hebbian
learning, ? (xi , xj ) = xi ?xj , synapses sharing a pre- or post-synaptic partner are correlated (Fig. 1d)
and so the covariance matrix C is no longer diagonal. Interestingly, the final expression of the
recurrent current to a neuron remains strictly local (because of additivity and symmetry), and very
similar to Eq. 6, but feedback inhibition becomes a non-linear function of the total activity in the
network [16]. In this case, synaptic correlations have a dramatic effect: using the optimal non-linear
dynamics ensures high performance, but trying to retrieve information using a decoder that assumes
synaptic independence (and thus uses linear dynamics) yields extremely poor performance, which
is even worse than the obvious control of relying only on the information in the recall cue and the
prior over patterns (Fig. 1e).
For the generalized Hebbian case, ? (xi , xj ) = (xi ??)(xj ??) with ? 6= ?, the optimal decoder becomes even more complex, with the total current including additional terms accounting for pairwise
correlations between any two synapses that have neuron i as a pre- or post-synaptic partner [16].
Hence, retrieval is no longer strictly local3 and a biological implementation will require approximating the contribution of non-local terms as a function of locally available information, as we discuss
in detail for palimpsest learning below.

4

Palimpsest learning rules

Though additive learning rules are attractive for their analytical tractability, they ignore several important aspects of synaptic plasticity, e.g. they assume that synapses can grow without bound. We
investigate the effects of bounded weights by considering another class of learning rules, which assumes synaptic efficacies can only take binary values, with stochastic transitions between the two
underpinned by paired cascades of latent internal states [14] (Fig. 2). These learning rules, though
very simple, capture an important aspect of memory ? the fact that memory is leaky, and information
about the past is overwritten by newly stored items (usually referred to as the palimpsest property).
Additionally, such rules can account for experimentally observed synaptic metaplasticity [15].
3
For additive learning rules, the current to neuron i always depends only on synapses local to a neuron, but
these can also include outgoing synapses of which the weight, W?i , should not influence its dynamics. We refer
to such dynamics as ?semi-local?. For other learning rules, the optimal current to neuron i may depend on all
connections in the network, including Wjk with j, k 6= i (?non-local? dynamics).

4

R1

D P

post

R2

R3

c

- -

0
1

D
P

P D
D P
0 1
pre

0.4

cortex data (Song 2005)

d

correlated synapses

20
10

0.2
0

0

0.4

20

error (%)

b

correlation coefficient

a

0.2
0
0.6

pseudostorage

10
0
20

0.3

*

10

0

exact approx

0

simple
dynamics

*

corr-dependent
dynamics

Figure 2: Palimpsest learning. a. The cascade model. Colored circles are latent states (V ) that
belong to two different synaptic weights (W ), arrows are state transitions (blue: depression, red:
potentiation) b. Different variants of mapping pre- and post-synaptic activations to depression (D)
and potentiation (P): R1?postsynaptically gated, R2?presynaptically gated, R3?XOR rule. c. Correlation structure induced by these learning rules. c. Retrieval performance for each rule.
Learning rule
Learning is stochastic and local, with changes in the state of a synapse Vij being determined only by
the activation of the pre- and post-synaptic neurons, xj and xi . In general, one could define separate
transition matrices for each activity pattern, M(xi , xj ), describing the probability of a synaptic state
transitioning between any two states Vij to Vij0 following an activity pattern, (xi , xj ). For simplicity,
we define only two such matrices, for potentiation, M+ , and depression, M? , respectively, and then
map different activity patterns to these events. In particular, we assume Fusi?s cascade model [14]4
and three possible mappings (Fig. 2b [16]): 1) a postsynaptically gated learning rule, where changes
occur only when the postsynaptic neuron is active, with co-activation of pre- and post- neuron leading to potentiation, and to depression otherwise5 ; 2) a presynaptically gated learning rule, typically
assumed when analysing cascades[20, 21]; and 3) an XOR-like learning rule which assumes potentiation occurs whenever the pre- and post- synaptic activity levels are the same, with depression
otherwise. The last rule, proposed by Ref. 22, was specifically designed to eliminate correlations
between synapses, and can be viewed as a version of the classic covariance rule fashioned for binary
synapses.
Estimating the mean and covariance of synaptic weights
At the level of a single synapse, the presentation of a sequence of uncorrelated patterns from
Pstore (x) corresponds to a Markov random walk, P
defined by a transition matrix M, which averages over possible neural activity patterns: M = xi ,xj Pstore (xi ) ? Pstore (xj ) ? M(xi , xj ). The
distribution over synaptic states t steps after the initial encoding can be calculated by starting from
the stationary distribution of the weights ? V 0 (assuming a large number of other patterns have previously been stored; formally, this is the eigenvector of M corresponding to eigenvalue ? = 1), then
storing the pattern (xi , xj ), and finally t ? 1 other patterns from the prior:
t?1

? V (xi , xj , t) = M

? M(xi , xj ) ? ? V 0 ,

(7)

?lV

with the distribution over states given as a column vector,
= P(Vij = l|xi , xj ), l ? {1 . . . 2n},
where n is the depth of the cascade. Lastly, the distribution over weights, P(Wij |xi , xj ), can be
derived as ? W = MV ?W ? ? V , where MV ?W is a deterministic map from states to observed
weights (Fig. 2a).
As in the additive case, the states of synapses sharing a pre- or post- synaptic partner will be correlated (Figs. 1a, 2c). The degree of correlations for different synaptic configurations can be estimated
by generalising the above procedure to computing the joint distribution of the states of pairs of
synapses, which we represent as a matrix ?. E.g. for a pair of synapses sharing a postsynaptic
partner (Figs. 1b, d, and 2c), element (u, v) is ?uv = P(Vpost,pre1 = u, Vpost,pre2 = v). Hence, the
presentation of an activity pattern (xpre1 , xpre2 , xpost ) induces changes in the corresponding pair of
4

Other models, e.g. serial [19], could be used as well without qualitatively affecting the results.
One could argue that this is the most biologically relevant as plasticity is often NMDA-receptor dependent,
and hence it requires postsynaptic depolarisation for any effect to occur.
5

5

incoming synapses to neuron post as ?(1) = M(xpost , xpre1 ) ? ?(0) ? M(xpost , xpre2 )T , where ?(0)
is the stationary distribution corresponding to storing an infinite number of triplets from the pattern
distribution [16].
Replacing ? V with ? (which is now a function of the triplet (xpre1 , xpre2 , xpost )), and the multiplication by M with the slightly more complicated operator above, we can estimate the evolution of
the joint distribution over synaptic states in a manner very similar to Eq. 7:
X
? i ) ? ?(t?1) ? M(x
? i )T ,
Pstore (xi ) ? M(x
(8)
?(t) =
xi
P
? i) =
where M(x
xj Pstore (xj )M(xi , xj ). Also as above, the final joint distribution over states
can be mapped into a joint distribution over synaptic weights as MV ?W ? ?(t) ? MT
V ?W . This
approach can be naturally extended to all other correlated pairs of synapses [16].
The structure of correlations for different synaptic pairs varies significantly as a function of the
learning rule (Fig. 2c), with the overall degree of correlations depending on a range of factors.
Correlations tend to decrease with cascade depth and pattern sparsity. The first two variants of the
learning rule considered are not symmetric, and so induce different patterns of correlations than the
additive rules above. The XOR rule is similar to the covariance rule, but the reciprocal connections
are no longer perfectly correlated (due to metaplasticity), which means that it is no longer possible
to factorize P(W|x). Hence, assuming independence at decoding seems bound to introduce errors.
Approximately optimal retrieval when synapses are independent
If we ignore synaptic correlations, the evidence from the weights factorizes, P(W|x) =
Q
3
i,j P(Wij |xi , xj ), and so the exact dynamics would be semi-local . We can further approximate
the contribution of the outgoing weights by its mean, which recovers the same simple dynamics
derived for the additive case:


X
X
X
P(xi = 1|x?i , W, x
?)
Ii = log
= c1
Wij xj + c2
Wij + c3
xj + c4 x?i + c5 (9)
j
j
j
P(xi = 0|x?i , W, x
?)
The parameters c. depend on the prior over x, the noise model, the parameters of the learning rule
and t. Again, the optimal decoder is similar to previously derived attractor dynamics; in particular,
for stochastic binary synapses with presynaptically gated learning the optimal dynamics require
dynamic inhibition only for sparse patterns, and no homeostatic term, as used in [21] .
To validate these dynamics, we remove synaptic correlations by a pseudo-storage procedure in which
synapses are allowed to evolve independently according to transition matrix M, rather than changing
as actual intermediate patterns are stored. The dynamics work well in this case, as expected (Fig. 2d,
blue bars). However, when storing actual patterns drawn from the prior, performance becomes extremely poor, and often worse than the control (Fig. 2d, gray bars). Moreover, performance worsens
as the network size increases (not shown). Hence, ignoring correlations is highly detrimental for this
class of learning rules too.
Approximately optimal retrieval when synapses are correlated
To accommodate synaptic correlations, we approximate P(W|x) with a maximum entropy distribution with the same marginals and covariance structure, ignoring the higher order moments.6
Specifically, we assume the evidence from the weights has the functional form:
X

1X
1
exp
kij (x, t) ? Wij +
J(ij)(kl) (x, t) ? Wij Wkl
(10)
P(W|x, t) =
ij
ijkl
Z(x, t)
2
We use the TAP mean-field method [23] to find parameters k and J and the partition function, Z,
for each possible activity pattern x, given the mean and covariance for the synaptic weights matrix,
computed above7 [16].
6
This is just a generalisation of the simple dynamics which assume a first order max entropy model; moreover, the resulting weight distribution is a binary analog of the multivariate normal used in the additive case,
allowing the two to be directly compared.
7
Here, we ask whether it is possible to accommodate correlations in appropriate neural dynamics at all,
ignoring the issue of how the optimal values for the parameters of the network dynamics would come about.

6

a

b

no corr
corr

5

0.05

0.5

0.01

0
0

0

0

?5
?10

?0.05

d

12

6

0
?2

0

2

4

6

8

10

number of coactive inputs

12

10

20

0

10

0

10

20

e

10
5
0
?5
?10

?0.01

20

0

2

4

6

8

10

12

number of coactive inputs

normalized EPSP

0

TIP

20

MIDDLE

10

postsynaptic current

c

postsynaptic current

0

BASE

?0.5

1.0
0.8
0.6
0.4
0.2
0.0

0

1

2 3 4 5 6
number of inputs

7

Figure 3: Implications for neural dynamics. a. R1: parameters for Iirec ; linear modulation by
network activity, nb . b. R2: nonlinear modulation of pairwise term by network activity (cf. middle
panel in a); other parameters have
P linear dependences on nb . c. R1: Total current as
Pfunction of
number of coactivated inputs, j Wij xj ; lines: different levels of neural excitability j Wij , line
widths scale with frequency of occurrence in a sample run. d. Same for R2. e. Nonlinear integration
in dendrites, reproduced from [11], cf. curves in c.
Exact retrieval dynamics based on Eq. 10, but not respecting locality constraints, work substantially
better in the presence of synaptic correlations, for all rules (Fig. 2d, yellow bars). It is important to
note that for the XOR rule, which was supposed to be the closest analog to the covariance rule and
hence afford simple recall dynamics [22], error rates stay above control, suggesting that it is actually
a case in which even dependencies beyond 2nd-order correlation would need to be considered.
As in the additive case, exact recall dynamics are biologically implausible, as the total current to
the neuron depends on the full weight matrix. It is possible to approximate the dynamics using
strictly local information by replacing the nonlocal term by its mean, which, however,
is no longer a
P
constant, but rather a linear function of the total activity in the network, nb = j6=i xj [16]. Under
this approximation, the current from recurrent connections corresponding to the evidence from the
weights becomes:
 X

P(W|x(1) )
1X
4
J4
=
k
(x)Wij Wik ? Z 4
(11)
(x)W
+
Iirec = log
ij
ij
jk (ij)(ik)
j
2
P(W|x(0) )
where i is the index of the neuron to be updated, and x(0/1) activity vector has the to-be-updated
neuron?s activity set to 1 or 0, respectively, and all other components given by the
 current network

4
4
state. The functions kij
(x) = kij (x(1) )?kij (x(0) ), J(ij)(kl)
(x) = J(ij)(kl) x(1) ?J(ij)(kl) x(0) ,


and Z 4 = log Z x(1) ? log Z x(0) depend on the local activity at the indexed synapses,
modulated by the number of active neurons in the network, nb . This approximation is again consistent with our previous analysis, i.e. in the absence of synaptic correlations, the complex dynamics
recover the simple case presented before. Importantly, this approximation also does about as well as
exact dynamics (Fig. 2d, red bars).
For post-synaptically gated learning, comparing the parameters of the dynamics in the case of independent versus correlated synapses (Fig. 3a) reveals a modest modulation of the recurrent input by
the total activity. More importantly, the net current to the postsynaptic P
neuron depends non-linearly
(formally, quadratically) on the number of co-active inputs, nW 1 = j xj Wij , (Fig. 3c), which
is reminiscent of experimentally observed dendritic non-linearities [11] (Fig. 3e). Conversely, for
the presynaptically gated learning rule, approximately optimal dynamics predict a non-monotonic
modulation of activity by lateral inhibition (Fig. 3b), but linear neural integration (Fig. 3d).8 Lastly,
retrieval based on the XOR rule has the same form as the simple dynamics derived for the factorized
case [16]. However, the total current has to be rescaled to compensate for the correlations introduced
by reciprocal connections.
8
The difference between the two rules emerges exclusively because of the constraint of strict locality of the
approximation, since the exact form of the dynamics is essentially the same for the two.

7

additive
cascade

RULE
covariance
simple Hebbian
generalized Hebbian
presyn. gated
postsyn. gated
XOR

EXACT DYNAMICS
strictly local, linear
strictly local, nonlinear
semi-local, nonlinear
nonlocal, nonlinear
nonlocal, nonlinear
beyond correlations

NEURAL IMPLEMENTATION
linear feedback inh., homeostasis
nonlinear feedback inh.
nonlinear feedback inh.
nonlinear feedback inh., linear dendritic integr.
linear feedback inh., non-linear dendritic integr.
?

Table 1: Results summary: circuit adaptations against correlations for different learning rules.

5

Discussion

Statistical dependencies between synaptic efficacies are a natural consequence of activity dependent
synaptic plasticity, and yet their implications for network function have been unexplored. Here, in
the context of an auto-associative memory network, we investigated the patterns of synaptic correlations induced by several well-known learning rules and their consequent effects on retrieval. We
showed that most rules considered do indeed induce synaptic correlations and that failing to take
them into account greatly damages recall. One fortuitous exception is the covariance rule, for which
there are no synaptic correlations. This might explain why the bulk of classical treatments of autoassociative memories, using the covariance rule, could achieve satisfying capacity levels despite
overlooking the issue of synaptic correlations [5, 24, 25].
In general, taking correlations into account optimally during recall requires dynamics in which there
are non-local interactions between neurons. However, we derived approximations that perform well
and are biologically realisable without such non-locality (Table 1). Examples include the modulation of neural responses by the total activity of the population, which could be mediated by feedback
inhibition, and specific dendritic nonlinearities. In particular, for the post-synaptically gated learning rule, which may be viewed as an abstract model of hippocampal NMDA receptor-dependent
plasticity, our model predicts a form of non-linear mapping of recurrent inputs into postsynaptic
currents which is similar to experimentally observed dendritic integration in cortical pyramidal cells
[11]. In general, the tight coupling between the synaptic plasticity used for encoding (manifested
in patterns of synaptic correlations) and circuit dynamics offers an important route for experimental
validation [2].
None of the rules governing synaptic plasticity that we considered perfectly reproduced the pattern
of correlations in [6]; and indeed, exactly which rule applies in what region of the brain under which
neuromodulatory influences is unclear. Furthermore, results in [6] concern the neocortex rather
than the hippocampus, which is a more common target for models of auto-associative memory.
Nonetheless, our analysis has shown that synaptic correlations matter for a range of very different
learning rules that span the spectrum of empirical observations.
Another strategy to handle the negative effects of synaptic correlations is to weaken or eliminate
them. For instance, in the palimpsest synaptic model [14], the deeper the cascade, the weaker the
correlations, and so metaplasticity may have the beneficial effect of making recall easier. Another,
popular, idea is to use very sparse patterns [21], although this reduces the information content of
each one. More speculatively, one might imagine a process of off-line synaptic pruning or recoding,
in which strong correlations are removed or the weights adjusted so that simple recall methods will
work.
Here, we focused on second-order correlations. However, for plasticity rules such as XOR, we
showed that this does not suffice. Rather, higher-order correlations would need to be considered,
and thus, presumably higher-order interactions between neurons approximated. Finally, we know
from work on neural coding of sensory stimuli that there are regimes in which correlations either
help or hurt the informational quality of the code, assuming that decoding takes them into account.
Given our results, it becomes important to look at the relative quality of different plasticity rules,
assuming realizable decoding ? it is not clear whether rules that strive to eliminate correlations will
be bested by ones that do not.
Acknowledgments This work was supported by the Wellcome Trust (CS, ML), the Gatsby Charitable Foundation (PD), and the European Union Seventh Framework Programme (FP7/2007?2013)
under grant agreement no. 269921 (BrainScaleS) (ML).
8

References
1. Sommer, F.T. & Dayan, P. Bayesian retrieval in associative memories with storage errors. IEEE transactions on neural networks 9, 705?713 (1998).
2. Lengyel, M., Kwag, J., Paulsen, O. & Dayan, P. Matching storage and recall: hippocampal spike timingdependent plasticity and phase response curves. Nature Neuroscience 8, 1677?1683 (2005).
3. Lengyel, M. & Dayan, P. Uncertainty, phase and oscillatory hippocampal recall. Advances in Neural
Information Processing (2007).
4. Savin, C., Dayan, P. & Lengyel, M. Two is better than one: distinct roles for familiarity and recollection in
retrieving palimpsest memories. in Advances in Neural Information Processing Systems, 24 (MIT Press,
Cambridge, MA, 2011).
5. Hopfield, J.J. Neural networks and physical systems with emergent collective computational abilities.
Proc. Natl. Acad. Sci. USA 76, 2554?2558 (1982).
6. Song, S., Sj?ostr?om, P.J., Reigl, M., Nelson, S. & Chklovskii, D.B. Highly nonrandom features of synaptic
connectivity in local cortical circuits. PLoS biology 3, e68 (2005).
7. Dayan, P. & Abbott, L. Theoretical Neuroscience (MIT Press, 2001).
8. Averbeck, B.B., Latham, P.E. & Pouget, A. Neural correlations, population coding and computation.
Nature Reviews Neuroscience 7, 358?366 (2006).
9. Pillow, J.W. et al. Spatio-temporal correlations and visual signalling in a complete neuronal population.
Nature 454, 995?999 (2008).
10. Latham, P.E. & Nirenberg, S. Synergy, redundancy, and independence in population codes, revisited.
Journal of Neuroscience 25, 5195?5206 (2005).
11. Branco, T. & H?ausser, M. Synaptic integration gradients in single cortical pyramidal cell dendrites. Neuron
69, 885?892 (2011).
12. Hasselmo, M.E. & Bower, J.M. Acetylcholine and memory. Trends Neurosci. 16, 218?222 (1993).
13. MacKay, D.J.C. Maximum entropy connections: neural networks. in Maximum Entropy and Bayesian
Methods, Laramie, 1990 (eds. Grandy, Jr, W.T. & Schick, L.H.) 237?244 (Kluwer, Dordrecht, The Netherlands, 1991).
14. Fusi, S., Drew, P.J. & Abbott, L.F. Cascade models of synaptically stored memories. Neuron 45, 599?611
(2005).
15. Abraham, W.C. Metaplasticity: tuning synapses and networks for plasticity. Nature Reviews Neuroscience
9, 387 (2008).
16. For details, see Supplementary Information.
17. Zhang, W. & Linden, D. The other side of the engram: experience-driven changes in neuronal intrinsic
excitability. Nature Reviews Neuroscience (2003).
18. Engel, A., Englisch, H. & Sch?utte, A. Improved retrieval in neural networks with external fields. Europhysics Letters (EPL) 8, 393?397 (1989).
19. Leibold, C. & Kempter, R. Sparseness constrains the prolongation of memory lifetime via synaptic metaplasticity. Cerebral cortex (New York, N.Y. : 1991) 18, 67?77 (2008).
20. Amit, Y. & Huang, Y. Precise capacity analysis in binary networks with multiple coding level inputs.
Neural computation 22, 660?688 (2010).
21. Huang, Y. & Amit, Y. Capacity analysis in multi-state synaptic models: a retrieval probability perspective.
Journal of computational neuroscience (2011).
22. Dayan Rubin, B. & Fusi, S. Long memory lifetimes require complex synapses and limited sparseness.
Frontiers in Computational Neuroscience (2007).
23. Thouless, D.J., Anderson, P.W. & Palmer, R.G. Solution of ?Solvable model of a spin glass?. Philosophical
Magazine 35, 593?601 (1977).
24. Amit, D., Gutfreund, H. & Sompolinsky, H. Storing infinite numbers of patterns in a spin-glass model of
neural networks. Phys Rev Lett 55, 1530?1533 (1985).
25. Treves, A. & Rolls, E.T. What determines the capacity of autoassociative memories in the brain? Network
2, 371?397 (1991).

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 2859-learning-in-silicon-timing-is-everything.pdf

Learning in Silicon: Timing is Everything

John V. Arthur and Kwabena Boahen
Department of Bioengineering
University of Pennsylvania
Philadelphia, PA 19104
{jarthur, boahen}@seas.upenn.edu

Abstract
We describe a neuromorphic chip that uses binary synapses with spike
timing-dependent plasticity (STDP) to learn stimulated patterns of activity and to compensate for variability in excitability. Specifically, STDP
preferentially potentiates (turns on) synapses that project from excitable
neurons, which spike early, to lethargic neurons, which spike late. The
additional excitatory synaptic current makes lethargic neurons spike earlier, thereby causing neurons that belong to the same pattern to spike in
synchrony. Once learned, an entire pattern can be recalled by stimulating
a subset.

1

Variability in Neural Systems

Evidence suggests precise spike timing is important in neural coding, specifically, in the
hippocampus. The hippocampus uses timing in the spike activity of place cells (in addition
to rate) to encode location in space [1]. Place cells employ a phase code: the timing at
which a neuron spikes relative to the phase of the inhibitory theta rhythm (5-12Hz) conveys
information. As an animal approaches a place cell?s preferred location, the place cell not
only increases its spike rate, but also spikes at earlier phases in the theta cycle.
To implement a phase code, the theta rhythm is thought to prevent spiking until the input
synaptic current exceeds the sum of the neuron threshold and the decreasing inhibition on
the downward phase of the cycle [2]. However, even with identical inputs and common
theta inhibition, neurons do not spike in synchrony. Variability in excitability spreads the
activity in phase. Lethargic neurons (such as those with high thresholds) spike late in the
theta cycle, since their input exceeds the sum of the neuron threshold and theta inhibition
only after the theta inhibition has had time to decrease. Conversely, excitable neurons
(such as those with low thresholds) spike early in the theta cycle. Consequently, variability
in excitability translates into variability in timing.
We hypothesize that the hippocampus achieves its precise spike timing (about 10ms)
through plasticity enhanced phase-coding (PEP). The source of hippocampal timing precision in the presence of variability (and noise) remains unexplained. Synaptic plasticity can
compensate for variability in excitability if it increases excitatory synaptic input to neurons
in inverse proportion to their excitabilities. Recasting this in a phase-coding framework, we
desire a learning rule that increases excitatory synaptic input to neurons directly related to
their phases. Neurons that lag require additional synaptic input, whereas neurons that lead

120?m

190?m

A

B

Figure 1: STDP Chip. A The chip has a 16-by-16 array of microcircuits; one microcircuit
includes four principal neurons, each with 21 STDP circuits. B The STDP Chip is embedded in a circuit board including DACs, a CPLD, a RAM chip, and a USB chip, which
communicates with a PC.
require none. The spike timing-dependent plasticity (STDP) observed in the hippocampus
satisfies this requirement [3]. It requires repeated pre-before-post spike pairings (within a
time window) to potentiate and repeated post-before-pre pairings to depress a synapse.
Here we validate our hypothesis with a model implemented in silicon, where variability is
as ubiquitous as it is in biology [4]. Section 2 presents our silicon system, including the
STDP Chip. Section 3 describes and characterizes the STDP circuit. Section 4 demonstrates that PEP compensates for variability and provides evidence that STDP is the compensation mechanism. Section 5 explores a desirable consequence of PEP: unconventional
associative pattern recall. Section 6 discusses the implications of the PEP model, including
its benefits and applications in the engineering of neuromorphic systems and in the study
of neurobiology.

2

Silicon System

We have designed, submitted, and tested a silicon implementation of PEP. The STDP Chip
was fabricated through MOSIS in a 1P5M 0.25?m CMOS process, with just under 750,000
transistors in just over 10mm2 of area. It has a 32 by 32 array of excitatory principal neurons commingled with a 16 by 16 array of inhibitory interneurons that are not used here
(Figure 1A). Each principal neuron has 21 STDP synapses. The address-event representation (AER) [5] is used to transmit spikes off chip and to receive afferent and recurrent spike
input.
To configure the STDP Chip as a recurrent network, we embedded it in a circuit board (Figure 1B). The board has five primary components: a CPLD (complex programmable logic
device), the STDP Chip, a RAM chip, a USB interface chip, and DACs (digital-to-analog
converters). The central component in the system is the CPLD. The CPLD handles AER
traffic, mediates communication between devices, and implements recurrent connections
by accessing a lookup table, stored in the RAM chip. The USB interface chip provides
a bidirectional link with a PC. The DACs control the analog biases in the system, including the leak current, which the PC varies in real-time to create the global inhibitory theta
rhythm.
The principal neuron consists of a refractory period and calcium-dependent potassium circuit (RCK), a synapse circuit, and a soma circuit (Figure 2A). RCK and the synapse are

ISOMA

Soma

Synapse

STDP

Presyn.
Spike

PE
LPF

A

Presyn.
Spike

Raster

AH

0
0.1

Spike probability

RCK

Postsyn.
Spike

B

0.05

0.1

0.05

0.1

0.08
0.06
0.04
0.02
0

0

Time(s)

Figure 2: Principal neuron. A A simplified schematic is shown, including: the synapse,
refractory and calcium-dependent potassium channel (RCK), soma, and axon-hillock (AH)
circuits, plus their constituent elements, the pulse extender (PE) and the low-pass filter
(LPF). B Spikes (dots) from 81 principal neurons are temporally dispersed, when excited
by poisson-like inputs (58Hz) and inhibited by the common 8.3Hz theta rhythm (solid line).
The histogram includes spikes from five theta cycles.
composed of two reusable blocks: the low-pass filter (LPF) and the pulse extender (PE).
The soma is a modified version of the LPF, which receives additional input from an axonhillock circuit (AH).
RCK is inhibitory to the neuron. It consists of a PE, which models calcium influx during
a spike, and a LPF, which models calcium buffering. When AH fires a spike, a packet of
charge is dumped onto a capacitor in the PE. The PE?s output activates until the charge
decays away, which takes a few milliseconds. Also, while the PE is active, charge accumulates on the LPF?s capacitor, lowering the LPF?s output voltage. Once the PE deactivates, this charge leaks away as well, but this takes tens of milliseconds because the leak is
smaller. The PE?s and the LPF?s inhibitory effects on the soma are both described below
in terms of the sum (ISHUNT ) of the currents their output voltages produce in pMOS transistors whose sources are at Vdd (see Figure 2A). Note that, in the absence of spikes, these
currents decay exponentially, with a time-constant determined by their respective leaks.
The synapse circuit is excitatory to the neuron. It is composed of a PE, which represents
the neurotransmitter released into the synaptic cleft, and a LPF, which represents the bound
neurotransmitter. The synapse circuit is similar to RCK in structure but differs in function:
It is activated not by the principal neuron itself but by the STDP circuits (or directly by
afferent spikes that bypass these circuits, i.e., fixed synapses). The synapse?s effect on the
soma is also described below in terms of the current (ISYN ) its output voltage produces in a
pMOS transistor whose source is at Vdd.
The soma circuit is a leaky integrator. It receives excitation from the synapse circuit and
shunting inhibition from RCK and has a leak current as well. Its temporal behavior is
described by:
?

dISOMA
ISYN I0
+ ISOMA =
dt
ISHUNT

where ISOMA is the current the capacitor?s voltage produces in a pMOS transistor whose
source is at Vdd (see Figure 2A). ISHUNT is the sum of the leak, refractory, and calciumdependent potassium currents. These currents also determine the time constant: ? =
C Ut
?ISHUNT , where I0 and ? are transistor parameters and Ut is the thermal voltage.

STDP circuit

~LTP

SRAM

Presynaptic spike

A

~LTD

Inverse number of pairings

Integrator

Decay

Postsynaptic spike

Potentiation

0.1
0.05
0
0.05
0.1 Depression
-80
-40

0

Presynaptic spike
Postsynaptic spike
40

Spike timing: t pre - t post (ms)

80

B

Figure 3: STDP circuit design and characterization. A The circuit is composed of three
subcircuits: decay, integrator, and SRAM. B The circuit potentiates when the presynaptic
spike precedes the postsynaptic spike and depresses when the postsynaptic spike precedes
the presynaptic spike.
The soma circuit is connected to an AH, the locus of spike generation. The AH consists
of model voltage-dependent sodium and potassium channel populations (modified from [6]
by Kai Hynna). It initiates the AER signaling process required to send a spike off chip.
To characterize principal neuron variability, we excited 81 neurons with poisson-like 58Hz
spike trains (Figure 2B). We made these spike trains poisson-like by starting with a regular
200Hz spike train and dropping spikes randomly, with probability of 0.71. Thus spikes
were delivered to neurons that won the coin toss in synchrony every 5ms. However, neurons
did not lock onto the input synchrony due to filtering by the synaptic time constant (see
Figure 2B). They also received a common inhibitory input at the theta frequency (8.3Hz),
via their leak current. Each neuron was prevented from firing more than one spike in a theta
cycle by its model calcium-dependent potassium channel population.
The principal neurons? spike times were variable. To quantify the spike variability, we used
timing precision, which we define as twice the standard deviation of spike times accumulated from five theta cycles. With an input rate of 58Hz the timing precision was 34ms.

3

STDP Circuit

The STDP circuit (related to [7]-[8]), for which the STDP Chip is named, is the most
abundant, with 21,504 copies on the chip. This circuit is built from three subcircuits:
decay, integrator, and SRAM (Figure 3A). The decay and integrator are used to implement
potentiation, and depression, in a symmetric fashion. The SRAM holds the current binary
state of the synapse, either potentiated or depressed.
For potentiation, the decay remembers the last presynaptic spike. Its capacitor is charged
when that spike occurs and discharges linearly thereafter. A postsynaptic spike samples the
charge remaining on the capacitor, passes it through an exponential function, and dumps
the resultant charge into the integrator. This charge decays linearly thereafter. At the time
of the postsynaptic spike, the SRAM, a cross-coupled inverter pair, reads the voltage on the
integrator?s capacitor. If it exceeds a threshold, the SRAM switches state from depressed
to potentiated (?LTD goes high and ?LTP goes low). The depression side of the STDP
circuit is exactly symmetric, except that it responds to postsynaptic activation followed by
presynaptic activation and switches the SRAM?s state from potentiated to depressed (?LTP
goes high and ?LTD goes low). When the SRAM is in the potentiated state, the presynaptic

50

After STDP

83

92

100

Timing precision(ms)

Before STDP

75

B

Before STDP
After STDP

40
30
20
10

0

50

60

70
80
90
Input rate(Hz)

100

50

58

67

text

A

0.2

0.4
Time(s)

0.6

0.2

0.4
Time(s)

0.6

C

Figure 4: Plasticity enhanced phase-coding. A Spike rasters of 81 neurons (9 by 9 cluster)
display synchrony over a two-fold range of input rates after STDP. B The degree of enhancement is quantified by timing precision. C Each neuron (center box) sends synapses to
(dark gray) and receives synapses from (light gray) twenty-one randomly chosen neighbors
up to five nodes away (black indicates both connections).

spike activates the principal neuron?s synapse; otherwise the spike has no effect.
We characterized the STDP circuit by activating a plastic synapse and a fixed synapse?
which elicits a spike at different relative times. We repeated this pairing at 16Hz. We
counted the number of pairings required to potentiate (or depress) the synapse. Based
on this count, we calculated the efficacy of each pairing as the inverse number of pairings required (Figure 3B). For example, if twenty pairings were required to potentiate the
synapse, the efficacy of that pre-before-post time-interval was one twentieth. The efficacy
of both potentiation and depression are fit by exponentials with time constants of 11.4ms
and 94.9ms, respectively. This behavior is similar to that observed in the hippocampus:
potentiation has a shorter time constant and higher maximum efficacy than depression [3].

4

Recurrent Network

We carried out an experiment designed to test the STDP circuit?s ability to compensate for
variability in spike timing through PEP. Each neuron received recurrent connections from
21 randomly selected neurons within an 11 by 11 neighborhood centered on itself (see
Figure 4C). Conversely, it made recurrent connections to randomly chosen neurons within
the same neighborhood. These connections were mediated by STDP circuits, initialized to
the depressed state. We chose a 9 by 9 cluster of neurons and delivered spikes at a mean
rate of 50 to 100Hz to each one (dropping spikes with a probability of 0.75 to 0.5 from a
regular 200Hz train) and provided common theta inhibition as before.
We compared the variability in spike timing after five seconds of learning with the initial
distribution. Phase coding was enhanced after STDP (Figure 4A). Before STDP, spike
timing among neurons was highly variable (except for the very highest input rate). After
STDP, variability was virtually eliminated (except for the very lowest input rate). Initially,
the variability, characterized by timing precision, was inversely related to the input rate,
decreasing from 34 to 13ms. After five seconds of STDP, variability decreased and was
largely independent of input rate, remaining below 11ms.

Potentiated synapses

25

A

Synaptic state
after STDP

20
15
10
5
0

B

50

100

150

200

Spiking order

250

Figure 5: Compensating for variability. A Some synapses (dots) become potentiated (light)
while others remain depressed (dark) after STDP. B The number of potentiated synapses
neurons make (pluses) and receive (circles) is negatively (r = -0.71) and positively (r =
0.76) correlated to their rank in the spiking order, respectively.

Comparing the number of potentiated synapses each neuron made or received with its excitability confirmed the PEP hypothesis (i.e., leading neurons provide additional synaptic
current to lagging neurons via potentiated recurrent synapses). In this experiment, to eliminate variability due to noise (as opposed to excitability), we provided a 17 by 17 cluster
of neurons with a regular 200Hz excitatory input. Theta inhibition was present as before
and all synapses were initialized to the depressed state. After 10 seconds of STDP, a large
fraction of the synapses were potentiated (Figure 5A). When the number of potentiated
synapses each neuron made or received was plotted versus its rank in spiking order (Figure
5B), a clear correlation emerged (r = -0.71 or 0.76, respectively). As expected, neurons that
spiked early made more and received fewer potentiated synapses. In contrast, neurons that
spiked late made fewer and received more potentiated synapses.

5

Pattern Completion

After STDP, we found that the network could recall an entire pattern given a subset, thus
the same mechanisms that compensated for variability and noise could also compensate
for lack of information. We chose a 9 by 9 cluster of neurons as our pattern and delivered
a poisson-like spike train with mean rate of 67Hz to each one as in the first experiment.
Theta inhibition was present as before and all synapses were initialized to the depressed
state. Before STDP, we stimulated a subset of the pattern and only neurons in that subset
spiked (Figure 6A). After five seconds of STDP, we stimulated the same subset again. This
time they recruited spikes from other neurons in the pattern, completing it (Figure 6B).
Upon varying the fraction of the pattern presented, we found that the fraction recalled
increased faster than the fraction presented. We selected subsets of the original pattern
randomly, varying the fraction of neurons chosen from 0.1 to 1.0 (ten trials for each). We
classified neurons as active if they spiked in the two second period over which we recorded.
Thus, we characterized PEP?s pattern-recall performance as a function of the probability
that the pattern in question?s neurons are activated (Figure 6C). At a fraction of 0.50 presented, nearly all of the neurons in the pattern are consistently activated (0.91?0.06), showing robust pattern completion. We fitted the recall performance with a sigmoid that reached
0.50 recall fraction with an input fraction of 0.30. No spurious neurons were activated during any trials.

Rate(Hz)

Rate(Hz)
8
7

7

6

6

5

5
4
2

A

0

B

Network activity
after STDP

0.6
0.4

2

0.2

0

0

1

1

0.8

4
3

3

Network activity
before STDP

1

Fraction of pattern actived

8

C

0

0.2

0.4

0.6

0.8

Fraction of pattern stimulated

1

Figure 6: Associative recall. A Before STDP, half of the neurons in a pattern are stimulated;
only they are activated. B After STDP, half of the neurons in a pattern are stimulated, and
all are activated. C The fraction of the pattern activated grows faster than the fraction
stimulated.

6

Discussion

Our results demonstrate that PEP successfully compensates for graded variations in our silicon recurrent network using binary (on?off) synapses (in contrast with [8], where weights
are graded). While our chip results are encouraging, variability was not eliminated in every
case. In the case of the lowest input (50Hz), we see virtually no change (Figure 4A). We
suspect the timing remains imprecise because, with such low input, neurons do not spike
every theta cycle and, consequently, provide fewer opportunities for the STDP synapses to
potentiate. This shortfall illustrates the system?s limits; it can only compensate for variability within certain bounds, and only for activity appropriate to the PEP model.
As expected, STDP is the mechanism responsible for PEP. STDP potentiated recurrent
synapses from leading neurons to lagging neurons, reducing the disparity among the diverse population of neurons. Even though the STDP circuits are themselves variable, with
different efficacies and time constants, when using timing the sign of the weight-change
is always correct (data not shown). For this reason, we chose STDP over other more
physiological implementations of plasticity, such as membrane-voltage-dependent plasticity (MVDP), which has the capability to learn with graded voltage signals [9], such as those
found in active dendrites, providing more computational power [10].
Previously, we investigated a MVDP circuit, which modeled a voltage-dependent NMDAreceptor-gated synapse [11]. It potentiated when the calcium current analog exceeded a
threshold, which was designed to occur only during a dendritic action potential. This circuit
produced behavior similar to STDP, implying it could be used in PEP. However, it was
sensitive to variability in the NMDA and potentiation thresholds, causing a fraction of the
population to potentiate anytime the synapse received an input and another fraction to never
potentiate, rendering both subpopulations useless. Therefore, the simpler, less biophysical
STDP circuit won out over the MVDP circuit: In our system timing is everything.
Associative storage and recall naturally emerge in the PEP network when synapses between
neurons coactivated by a pattern are potentiated. These synapses allow neurons to recruit
their peers when a subset of the pattern is presented, thereby completing the pattern. However, this form of pattern storage and completion differs from Hopfield?s attractor model
[12] . Rather than forming symmetric, recurrent neuronal circuits, our recurrent network
forms asymmetric circuits in which neurons make connections exclusively to less excitable
neurons in the pattern. In both the poisson-like and regular cases (Figures 4 & 5), only
about six percent of potentiated connections were reciprocated, as expected by chance. We
plan to investigate the storage capacity of this asymmetric form of associative memory.
Our system lends itself to modeling brain regions that use precise spike timing, such as

the hippocampus. We plan to extend the work presented to store and recall sequences of
patterns, as the hippocampus is hypothesized to do. Place cells that represent different
locations spike at different phases of the theta cycle, in relation to the distance to their preferred locations. This sequential spiking will allow us to link patterns representing different
locations in the order those locations are visited, thereby realizing episodic memory.
We propose PEP as a candidate neural mechanism for information coding and storage in the
hippocampal system. Observations from the CA1 region of the hippocampus suggest that
basal dendrites (which primarily receive excitation from recurrent connections) support
submillisecond timing precision, consistent with PEP [13]. We have shown, in a silicon
model, PEP?s ability to exploit such fast recurrent connections to sharpen timing precision
as well as to associatively store and recall patterns.
Acknowledgments
We thank Joe Lin for assistance with chip generation. The Office of Naval Research funded
this work (Award No. N000140210468).
References
[1] O?Keefe J. & Recce M.L. (1993). Phase relationship between hippocampal place units and the
EEG theta rhythm. Hippocampus 3(3):317-330.
[2] Mehta M.R., Lee A.K. & Wilson M.A. (2002) Role of experience and oscillations in transforming
a rate code into a temporal code. Nature 417(6890):741-746.
[3] Bi G.Q. & Wang H.X. (2002) Temporal asymmetry in spike timing-dependent synaptic plasticity.
Physiology & Behavior 77:551-555.
[4] Rodriguez-Vazquez, A., Linan, G., Espejo S. & Dominguez-Castro R. (2003) Mismatch-induced
trade-offs and scalability of analog preprocessing visual microprocessor chips. Analog Integrated
Circuits and Signal Processing 37:73-83.
[5] Boahen K.A. (2000) Point-to-point connectivity between neuromorphic chips using address
events. IEEE Transactions on Circuits and Systems II 47:416-434.
[6] Culurciello E.R., Etienne-Cummings R. & Boahen K.A. (2003) A biomorphic digital image sensor. IEEE Journal of Solid State Circuits 38:281-294.
[7] Bofill A., Murray A.F & Thompson D.P. (2005) Citcuits for VLSI Implementation of Temporally
Asymmetric Hebbian Learning. In: Advances in Neural Information Processing Systems 14, MIT
Press, 2002.
[8] Cameron K., Boonsobhak V., Murray A. & Renshaw D. (2005) Spike timing dependent plasticity (STDP) can ameliorate process variations in neuromorphic VLSI. IEEE Transactions on Neural
Networks 16(6):1626-1627.
[9] Chicca E., Badoni D., Dante V., D?Andreagiovanni M., Salina G., Carota L., Fusi S. & Del Giudice P. (2003) A VLSI recurrent network of integrate-and-fire neurons connected by plastic synapses
with long-term memory. IEEE Transaction on Neural Networks 14(5):1297-1307.
[10] Poirazi P., & Mel B.W. (2001) Impact of active dendrites and structural plasticity on the memory
capacity of neural tissue. Neuron 29(3)779-796.
[11] Arthur J.V. & Boahen K. (2004) Recurrently connected silicon neurons with active dendrites for
one-shot learning. In: IEEE International Joint Conference on Neural Networks 3, pp.1699-1704.
[12] Hopfield J.J. (1984) Neurons with graded response have collective computational properties like
those of two-state neurons. Proceedings of the National Academy of Science 81(10):3088-3092.
[13] Ariav G., Polsky A. & Schiller J. (2003) Submillisecond precision of the input-output transformation function mediated by fast sodium dendritic spikes in basal dendrites of CA1 pyramidal
neurons. Journal of Neuroscience 23(21):7750-7758.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4364-two-is-better-than-one-distinct-roles-for-familiarity-and-recollection-in-retrieving-palimpsest-memories.pdf

Two is better than one: distinct roles for familiarity
and recollection in retrieving palimpsest memories

Cristina Savin1
cs664@cam.ac.uk

Peter Dayan2
dayan@gatsby.ucl.ac.uk

M?at?e Lengyel1
m.lengyel@eng.cam.ac.uk
1

Computational & Biological Learning Lab, Dept. of Engineering, University of Cambridge, UK
2
Gatsby Computational Neuroscience Unit, University College London, UK

Abstract
Storing a new pattern in a palimpsest memory system comes at the cost of interfering with the memory traces of previously stored items. Knowing the age of
a pattern thus becomes critical for recalling it faithfully. This implies that there
should be a tight coupling between estimates of age, as a form of familiarity, and
the neural dynamics of recollection, something which current theories omit. Using a normative model of autoassociative memory, we show that a dual memory
system, consisting of two interacting modules for familiarity and recollection, has
best performance for both recollection and recognition. This finding provides a
new window onto actively contentious psychological and neural aspects of recognition memory.

1

Introduction

Episodic memory such as that in the hippocampus acts like a palimpsest ? each new entity to be
stored is overlaid on top of its predecessors, and, in turn, is submerged by its successors. This implies
both anterograde interference (existing memories hinder the processing of new ones) and retrograde
interference (new memories overwrite information about old ones). Both pose important challenges
for the storage and retrieval of information in neural circuits. Some aspects of these challenges have
been addressed in two theoretical frameworks ? one focusing on anterograde interference through the
interaction of novelty and storage [1]; the other on retrograde interference in individual synapses [2].
However, neither fully considered the critical issue of retrieval from palimpsests; this is our focus.
First, [1] made the critical observation that autoassociative memories only work if normal recall
dynamics are suppressed on presentation of new patterns that need to be stored. Otherwise, rather
than memorizing the new pattern, the memory associated with the existing pattern that most closely
matches the new input will be strengthened. This suggests that it is critical to have a mechanism for
assessing pattern novelty or, conversely, familiarity, a function that is often ascribed to neocortical
areas surrounding the hippocampus.
Second, [2] considered the palimpsest problem of overwriting information in synapses whose efficacies have limited dynamic ranges. They pointed out that this can be at least partially addressed
through allowing multiple internal states (for instance forming a cascade) for each observable synaptic efficacy level. However, although [2] provide an attractive formalism for analyzing and optimizing synaptic storage, a retrieval mechanism associated with this storage is missing.
1

a

b

potentiation
depression

Figure 1: a. The cascade model. Internal states of a synapse (circles) can express one of two different
efficacies (W, columns). Transitions between states are stochastic and can either be potentiating,
or depressing, depending on pre- and postsynaptic activities. Probabilities of transitions between
states expressing the same efficacy p and between states expressing different efficacies, q, decrease
geometrically with cascade depth. b. Generative model for the autoassociative memory task. The
? is a noisy version of one of the stored patterns x. Upon storing pattern x synaptic states
recall cue x
changed from V0 (sampled from the stationary distribution of synaptic dynamics) to V1 . Recall
occurs after the presentation of t ? 1 intervening patterns, when synapses are in states Vt , with
? are observed at recall.
corresponding synaptic efficacies Wt . Only Wt and x
Although these pieces of work might seem completely unrelated, we show here that they are closely
linked via retrieval. The critical fact about recall from memory, in general, is to know how the information should appear at the time of retrieval. In the case of a palimpsest, the trace of a memory
in the synaptic efficacies depends critically on the age of the memory, i.e., its relative familiarity.
This suggests a central role for novelty (or familiarity) signals during recollection. Indeed, we show
retrieval is substantially worse when familiarity is not explicitly represented than when it is.
Dual system models for recognition memory are the topic of a heated debate [3, 4]. Our results
could provide a computational rationale for them, showing that separating a perirhinal-like network
(involved in familiarity) from a hippocampal-like network can be beneficial even when the only
task is recollection. We also show that the task of recognition can also be best accomplished by
combining the outputs of both networks, as suggested experimentally [4].

2

Storage in a palimpsest memory

We consider the task of autoassociative recall of binary patterns from a palimpsest memory. Specifically, the neural circuit consists of N binary neurons that enjoy all-to-all connectivity. During
storage, network activity is clamped to the presented pattern x, inducing changes in the synapses?
?internal? states V and corresponding observed binary efficacies W (Fig. 1a).
At recall, we seek to retrieve a pattern x that was originally stored, given a noisy cue x
? and the
current weight matrix W. This weight matrix is assumed to result from storing x on top of the
stationary distribution of the synaptic efficacies coming from the large number of patterns that had
been previously stored, and then subsequently storing a sequence of t ? 1 other intervening patterns
with the same statistics on top of x (Fig. 1b).
In more detail, a pattern to be stored has density f , and is drawn from the distribution:
Y
Y
Pstore (x) =
Pstore (xi ) =
f xi ? (1 ? f )1?xi
i

i

(1)

The recall cue is a noisy version of the original pattern, modeled using a binary symmetric channel:
Pnoise (?
x|x) =

Y
i

Pnoise (x?i |xi )

Pnoise (x?i |xi ) = (1 ? r)xi ? r


1?xi x?i

where r defines the level of input noise.
2

(2)
? rxi ? (1 ? r)


1?xi 1?x?i

(3)

The recall time t is assumed to come from a geometric distribution with mean t?:

t?1
1
1
Precall (t) = ? 1 ?
t?
t?

(4)

The synaptic learning rule is local and stochastic, with the probability of an event actually leading
to state changes determined by the current state of the synapse Vij and the activity at the pre- and
post-synaptic neurons, xi and xj . Hence, learning is specified through a set of transition matrices
M (xi , xj ), with M (xi , xj )l0 l = P(Vij0 = l0 |Vij = l, xi , xj ). For convenience, we adopted the cascade model [2] (Fig. 1a), which assumes that the probability of potentiation and depression decays
n?1
with cascade depth i as a geometric progression, qi? = ?i?1 , with qn? = ?1?? to compensate for
i

?
boundary effects. The transition between metastates is given by p?
i = ?? 1?? , with the correction
f
factors ?+ = 1?f
f and ?? = 1?f ensuring that different metastates are equally occupied for different pattern sparseness values f [2]. Furthermore, we assume synaptic changes occur only when the
postsynaptic neuron is active, leading to potentiation if the presynaptic neuron is also active and to
depression otherwise. The specific form of the learning rule could influence the memory span of the
network, but we expect it not to change the results below qualitatively.

The evolution of the distribution over synaptic states after encoding can be described by a Markov
process, with a transition matrix M given as the averageP
change in synaptic states expected after
storing an arbitrary pattern from the prior Pstore (x), M = xi ,xj Pstore (xi )?Pstore (xj )?M(xi , xj ).
Additionally, we define the column vectors ? V (xi , xj ) and ? W (xi , xj ) for the distribution of the
synaptic states and observable efficacies, respectively, when one of the patterns stored was (xi , xj ),
such that ?lW (xi , xj ) = P(Wij = l|xi , xj ) and ?lV (xi , xj ) = P(Vij = l|xi , xj ). Given these
definitions, we can express the final distribution over synaptic states as:

X
t?1
? V (xi , xj ) =
Precall (t) ? M
? M(xi , xj ) ? ? ?
(5)
t

where we start from the stationary distribution ? ? (the eigenvector of M for eigenvalue 1), encode
pattern (xi , xj ) and then t ? 1 additional patterns from the same distribution. The corresponding
weight distribution is ? W (xi , xj ) = T ? ? V (xi , xj ), where T is a 2 ? 2n matrix defining the
deterministic mapping from synaptic states to observable efficacies.
The fact that the recency of the pattern to be recalled, t, appears in equation 5 implies that pattern age
will strongly influence information retrieval. In the following, we consider two possible solutions
to this problem. We first show the limitations of recall dynamics that involve a single, monolithic
module which averages over t. We then prove the benefits of a dual system with two qualitatively
different modules, one of which explicitly represents an estimate of pattern age.

3
3.1

A single module recollection system
Optimal retrieval dynamics

Since information storage by synaptic plasticity is lossy, the recollection task described above is a
probabilistic inference problem [5,6]. Essentially, neural dynamics should represent (aspects of) the
posterior over stored patterns, P (x|?
x, W), that expresses the probability of any pattern x being the
? , and the synaptic efficacies W.
correct response for the recall query given a noisy recall cue, x
In more detail, the posterior over possible stored patterns can be computed as:
? ) ? Pstore (x) ? Pnoise (?
P (x|W, x
x|x) ? P(W|x)

(6)
1

where
we assume that evidence from the weights factorizes over synapses , P (W|x) =
Q
P
(W
ij |xi , xj ).
ij
1
This assumption is never exactly true in practice, as synapses that share a pre- or post- synaptic partner are
bound to be correlated. Here, we assume the intervening patterns cause independent weight changes and ignore
the effects of such correlations.

3

Previous Bayesian recall dynamics derivations assumed learning rules for which the contribution of
each pattern to the final weight were the same, irrespective of the order of pattern presentation [5,6].
By contrast, the Markov chain behaviour of our synaptic learning rule forces us to explicitly consider
pattern age. Furthermore, as pattern age is unknown at recall, we need to integrate over all possible t
values (Eq. 5). This integral (which is technically a sum, for discrete t) can be computed analytically
using the eigenvalue decomposition of the transition matrix M. Alternatively, if the value of t is
known during recall, the prior is replaced by a delta function, Precall (t) = ?(t ? t? ).
There are several possible ways of representing the posterior in Eq.6 through neural dynamics without reifying t. For consistency, we assume neural states to be binary, with network activity at each
step representing a sample from the posterior [7, 8]. An advantage of this approach is that the full
posterior is represented in the network dynamics, such that higher decision modules can not only
extract the ?best? pattern (for the mean squared error cost function considered here, this would be
the mean of the posterior) but also estimate the uncertainty of this solution. Nevertheless, other
representations, for example representing the parameters of a mean-field approximation to the true
posterior [5, 9, 10], would also be possible and similarly informative about uncertainty.
In particular, we use Gibbs sampling, as it allows for neurally plausible recall dynamics [7]. This
results in asynchronous updates, in which the activity of a neuron xi changes stochastically as a
function of its input cue x
?i , the activity of all other neurons, x\i , and neighbouring synapses, Wi,?
and W?,i . Specifically, the Gibbs sampler results in a sigmoid transfer function, with the total current
to the neuron given by the log-odds ratio:
Iirec

=

log

P(xi = 1|x\i , W, x
?i )
= Iirec,in + Iirec,out + a?
xi + b
P(xi = 0|x\i , W, x
?i )

(7)

in/out

defining the evidence from the incoming and outgoing synapses of neuron i,
with the terms Irec
and the constants a and b determined by the prior over patterns and the noise model.2 The terms
describing the contribution from recurrent interactions, have a similar shape:
X

in
in
in
Iirec,in =
cin
(8)
1 ? Wij xj + c2 ? Wij + c3 ? xj + c4
j

Iirec,out

=

X

out
out
out
cout
1 ? Wji xj + c2 ? Wji + c3 ? xj + c4



(9)

j
in/out

The parameters ck
, uniquely determined by the learning rule and the priors for x and t, rescale
the contribution of the evidence from the weights as a function of pattern age (see supplementary
text). Furthermore, these constants translate into a unique signal, giving a sort of ?sufficient statistic? for the expected memory strength. NoteP
that the optimal dynamics include two homeostatic
P
processes, corresponding to global inhibition, j xj , and neuronal excitability regulation, j Wij ,
that stabilize network activity during recall.
3.2

Limitations

Beside the effects of assuming a factorized weight distribution, the neural dynamics derived above
should be the best we can do given the available data (i.e. recall cue and synaptic weights). How
well does the network fare in practice?
Performance is as expected when pattern age is assumed known: as the available information from
the weights decreases, so does performance, finally converging to control levels, defined by the retrieval performance of a network without plastic recurrent connections, i.e. when inference uses only
the recall cue and the prior over stored patterns (Fig. 2a, green). When t is unknown, performance
also deteriorates with increasing pattern age, however this time beneath control levels (Fig. 2a, blue).
Intuitively, one can see that relying on the prior over t is similar to assuming t fixed to a value close
2
out
Real neurons can only receive information from their presynaptic partners, so cannot estimate Irec
. We
therefore ran simulations without this term in the dynamics and found that although it did decrease recall performance, this decrease was similar to that obtained by randomly pruning half of the connections in the network
and keeping this term in the dynamics (not shown). This indicated that performance is mostly determined by
the number of available synapses used for inference, and not so much by the direction of those synapses. Hence,
in the following we use both terms and leave the systematic study of connectivity for future work.

4

40

t known
t unknown
control

30

b

20

10

control

5

10
0
0

15
error (%)

error (%)

a

50

t

100

150

0

t known

single module
dual system
Gibbs tempered
transitions

Figure 2: a. Recall performance for a single module memory system. b. Average recollection error
comparison for the single and dual memory system. Black lines mark control performance, when
ignoring the information from the synaptic weights.

to the mean of this prior. When the pattern that was actually presented is older than this estimate, the
resulting memory signal is weaker than expected, suggesting that the initial pattern was very sparse
(since a pair of inactive elements does not induce any synaptic changes according to our learning
rule). However, less reasonable is the fact that averaging over the prior distribution of recall times t
(Eq. 4), performance is worse than this control (Fig. 2b).
One possible reason for this failure is that the sampling procedure used for inference might not work
in certain cases. Since Gibbs samplers are known to mix poorly when the shape of the posterior is
complex (with strong correlations, as in frustrated Ising models), perhaps our neural dynamics are
unable to sample the desired distribution effectively. We confirmed this hypothesis by implementing
a more sophisticated sampling procedure using tempered transitions [11] (details in supplementary
text). Indeed, with tempered transitions performance becomes significantly better than control, even
for the cases where Gibbs sampling fails (Fig. 2b). Unfortunately, there has yet to be a convincing
suggestion as to how tempering dynamics (or in fact any other sampling algorithm that works well
with correlated posteriors) can be represented neurally since, for example, they require a global
acceptance decision to be taken at the end of each temperature cycle.
It is worth noting that with more complex synaptic dynamics (e.g. deeper cascades) simple Gibbs
sampling works reasonably well (data not shown), probably because the posterior is smoother and
hence easier to sample.

4

A dual memory system

An alternative to implicitly marginalizing over the age of the pattern throughout the inference process is to estimate it at the same time as performing recollection. This suggests the use of dual
modules that together estimate the joint posterior P (x, t|?
x, W), with sampling proceeding in a
loop: the familiarity module generates a sample from the posterior over the age of the currently esti? , W); and the recollection module uses this estimated age to compute a new
mated pattern, P(t|x, x
sample from the distribution over possible stored patterns given the age, P (x|?
x, W, t) (Fig. 3a).
The module that computes familiarity can also be seen as a palimpsest, with each pattern overlaying,
and being overlaid by, its predecessors and successors. Formally, it needs to compute the probability
? , W), as the system continues to implement a Gibbs sampler with t as an additional dimenP(t|x, x
sion. As a separate module, the neural network estimating familiarity cannot however access the
weights W of the recollection module. A biologically plausible approximation is to assume that
the familiarity module uses a separate set of weights, which we call Wfam . Also, it is clear from
? conditioned on x, thus the conditioning on x
? can be dropped when
Fig. 1b that t is independent of x
computing the posterior over t, that is, external input need only feed directly into the recollection
but not the familiarity module (Fig. 3a).
In particular, we assume a feedforward network structure in the familiarity module, with each neuron
receiving the output of the recollection module as inputs through synapses Wfam . These synaptic
5

b

cue

familiarity

recollection

activation

0.05

0

1

100

neuron index

familiarity signal

a

10 1

10 0

10 ?1

200

0

50

t

100

150

Figure 3: a. An overview of the dual memory system. The familiarity network has a feedforward
structure, with the activity of individual neurons estimating the probability of the true pattern age
being a certain value t, see example in inset. The estimated pattern age translates into a familiarity
signal, which scales the contribution of the recurrent inputs in the network dynamics. b. Dependence
of the familiarity signal on the estimated pattern age.
weights change according to the same cascade rule used for recollection.3 For simplicity, we assume
that the familiarity neurons are always activated during encoding, so that synapses can change state
(either by potentiation or depression) with every storage event.
Concretely, the familiarity module consists of Nfam neurons, each corresponding to a certain pattern
age in the range 1?Nfam (the last unit codes for t ? Nfam ). This forms a localist code for familiarity.
The total input to a neuron is given by the log-posterior Iifam = log P(t = i|x, Wfam ) which
translates into a simple linear activation function:
X

fam
fam
fam
fam
Iifam =
cfam
+ cfam
+ log P(t) ? log(Z)
(10)
1,i Wij xj + c2,i Wij
3,i xj + c4,i
j
in/out
before (albeit different for each neuron
where the constants cfam
k,i are similar to parameters c
because of their tuning to different values of t), and Z is the unknown partition function.

As mentioned above, we treat the activity of the familiarity module as a sample from the posterior
over age t. This representation requires lateral competition between different units such that only one
can become active at each step. Dynamics of this sort can be implemented using a softmax operator,
Ii
P(xfam
= 1) = Pe eIj (thus rendering the evaluation of the partition function Z unnecessary), and
i
j

are a common feature of a range of neural models [12, 13].
Critically, this familiarity module is not just a convenient theoretical construct associated with retrieval. First, as we mentioned before, the assessment of novelty actually plays a key part in memory
storage ? in making the decision as to whether a pattern that is presented is novel, and so should
be stored, or familiar, and so should have its details be recalled. This venerable suggestion [1] has
played a central part in the understanding of structure-function relationships in the hippocampus.
The graded familiarity module that we have suggested is an obvious extension of this idea; the use
for retrieval is new. Second, it is in general accord with substantial data on the role of perirhinal cortex and the activity of neurons in this structure [3]. Recency neurons would be associated with small
values of t; novelty neurons with large or effectively infinite values of t [14], although perirhinal
cortex appears to adopt a population coding strategy for age, rather than just one-of-n.
The recollection module has the same dynamics as before, with constants ci computed assuming t
fixed to the output of the familiarity module. Thus we predict that familiarity multiplicatively modulates recurrent interactions in the recollection module during recall. Since there is a deterministic
mapping between t and this modulatory factor (Fig. 3b), it can be computed using a linear unit pooling the outputs of all the neurons in the familiarity module, with weights given by the corresponding
values for cfam
(t).
i
3
There is nothing to say that the learning rule that optimizes the recollection network?s ability to recall
patterns should be equally appropriate for assessing familiarity. Hence, the familiarity module could have their
own learning rule, optimized for its specific task.

6

b
novel

40

c

0.9

1

0.7

0.9

*

*

100

50

30
0.5

20

0.3

10
0

familiar
0

0.04

0.08

0.12

0.1

hits

familiarity: estimated t

a

0.8

0

0.7

100

d

fam

rec

*

90

0.6
0.5

both

80
0

0.2

recollection: average entropy

0.4

0.6

false alarms

0.8

1

fam

rec

Figure 4: a. Decision boundaries for the recognition module. b. Corresponding ROC curve. c.
Performance comparison when the decision layer uses signals from the familiarity module, the recollection module, or both. d. Same comparison, when data is restricted to recent stimuli. Note that
difference between fam and rec became significant compared to c.
In order to compare single and dual module systems fairly, the computational resources employed by
each should be the same. We therefore reduced the overall connectivity in the dual system such that
the two have the same total number of synapses. Moreover, since elements of Wfam are correlated,
the effective number of connections is in fact somewhat lower in the dual system. Regardless, the
dual memory system performs significantly better than the single module system (Fig. 2b).

5

Recognition memory

We have so far considered familiarity merely as an instrument for effective recollection. However,
there are many practical and experimental tasks in which it is sufficient to make a binary decision
about whether a pattern is novel or familiar rather than recalling it in all its gory detail. It is these
tasks that have been used to elucidate the role of perirhinal cortex in recognition memory.
In the dual module system, information about recognition is available from both the familiarity
module (patterns judged to have young ages are recognized) and the recollection module (patterns
recalled with higher certainty are recognized). We therefore construct an additional decision module
which takes the outputs of the familiarity and recollection modules and maps them into a binary
behavioral response (familiar vs. novel).
Specifically, we use the average of the entropies associated with the activities of neurons in the
recollection module and the mean estimate of t from the familiarity module. Since the palimpsest
property implicitly assumes that all patterns have been presented at some point, we define a pattern to
be familiar if its age is less than a fixed threshold tth . We train the decision module using a Gaussian
process classifier4 [15], which yields as outcome the probability of a hit, P(familiar|t? , x? ), shown
in Fig. 4a. The shape of the resulting discriminator, that it is not parallel to either axis, suggests that
the output of both modules is needed for successful recognition, as suggested experimentally [4,16].
The fact that a classifier trained using only one of the two dimensions cannot match the recognition
performance of that using both confirms this observation (Fig. 4c).
Moreover, the ROC curve produced by the classifier, plotting hit rates against false alarms as relative
losses are varied, has a similar shape to those obtained for human behavioral data: it has a so-called
?curvi-linear? character because of the apparent intersect at a finite hit probability for 0 false alarm
rate [17] (Fig. 4b). Lastly, as recognition is known to rely more on familiarity for relatively recent
patterns [18], we estimate recognition performance for recent patterns, which we define as having
age t ? t2th . To determine the contribution of each module in recognition outcomes in this case, we
estimate performance of classifiers trained on single input dimensions for this test data. Consistent
with experimental data, our analysis reveals that the familiarity signal gives a more reliable estimate
of novelty, compared to the recollection output for relatively recent items (Fig. 4d).
4
The specific classifier was chosen as it allows for an easy estimation of the ROC curves. Future work
should explore analytical decision rules.

7

6

Conclusions and discussion

Knowing the age of a pattern is critical for retrieval from palimpsest memories, a consideration
that has so far eluded theoretical inquiry. We showed that a memory system could either treat this
information implicitly, by marginalizing over all possible ages, or it could estimate age explicitly as
a form of familiarity. In principle, both solutions should have similar performance, given the same
resources. In practice, however, a system involving dual modules is significantly better.
In our model, the posterior over possible stored patterns was represented in neural activities via
samples. We showed that a complex, biologically-questionable sampling procedure would be necessary for the implicit, single module, system. Instead, a dual memory system with two functionally
distinct but closely interacting modules, yielded the best performance both for efficient recollection
and for recognition. Importantly, though Gibbs sampling and tempered transitions provide a useful framework for understanding the performance differences between different memory systems,
the presented results are not restricted to a sampling-based implementation. Since age and identity
are tightly correlated, a mean field solution that use factorized distributions [5] shows very similar behavior (see supplementary text). Similarly, the specific details of the familiarity module are
not critical for these effects, which should be apparent for any alternative implementation correctly
estimating pattern age.
Representing pattern age, t, explicitly essentially amounts to implementing an auxiliary variable for
sampling the space of possible patterns, x more efficiently. Such auxiliary variable methods are
widely used to increase sampling efficiency when other, simpler methods fail [19]. Moreover, since
t in our case specifically modulates the correlated components of the posterior it can be seen as a
?temperature? parameter, and so we can understand the advantages brought about by the dual system
as due to implementing a form of ?simulated tempering? ? a class of methods known to help mixing
in strongly correlated posteriors.
Our proposal provides a powerful new window onto the contentious debate about the neural mechanisms of recognition and recall. The rationale for our familiarity network was improving recollection; however, the form of the network was motivated by the substantial experimental data [14] on
recognition, and indeed standard models of perirhinal cortex activity [20]. These, for instance, also
rely on some form of inhibition to mediate interactions between different familiarity neurons. Nevertheless, our model is the first to link the computational function of familiarity networks to recall;
it is distinct also in that it considers palimpsest synapses, as previous models use purely additive
learning rules [20]. Although we only considered pattern age as the basis of familiarity here, the
principle of the interaction between familiarity and recollection remains the same in an extended
setting, when familiarity characterizes the expected strength of the memory trace more completely,
including the effects of retention interval, number of repetitions, and spacing between repetitions.
Future work with the extended model should allow us to address familiarity, novelty, and recency
neurons in the perirhinal cortex, and indeed provide a foundation for new thinking about this region.
In our model familiarity interacts with recollection by multiplicatively (or divisively) modulating the
contribution of recurrent inputs in the recollection module. Neurally, this effect could be mediated
by shunting inhibition via specific classes of hippocampal interneurons which target the dendritic
segment corresponding to recurrent connections, thus rescaling the relative contribution of external versus recurrent inputs [21]. Whether pathways reaching CA3 from perirhinal cortex through
entorhinal cortex preserve a sufficient amount of input specificity of feed-forward inhibition is unknown.
Our theory predicts important systems-level aspects of memory from synaptic-level constraints. In
particular, by optimizing our dual system solely for memory recall we also predicted non-trivial
ROC curves for recognition that are in at least broad qualitative agreement with experiments. Future
work will be needed to explore whether the ROC curves in our model show similar dissociations in
response to specific lesions of the two modules to those found in recent experiments [22,23] and the
relation to other recognition memory models [24].
Acknowledgements
This work was supported by the Wellcome Trust (CS, ML) and the Gatsby Charitable Foundation
(PD).
8

References
[1] Hasselmo, M.E. The role of acetylcholine in learning and memory. Current opinion in neurobiology 16, 710?715 (2006).
[2] Fusi, S., Drew, P.J. & Abbott, L.F. Cascade models of synaptically stored memories. Neuron
45, 599?611 (2005).
[3] Brown, M.W. & Aggleton, J.P. Recognition memory: What are the roles of the perirhinal
cortex and hippocampus? Nature Reviews Neuroscience 2, 51?61 (2001).
[4] Wixted, J.T. & Squire, L.R. The medial temporal lobe and the attributes of memory. Trends in
Cognitive Sciences 15, 210?217 (2011).
[5] Sommer, F.T. & Dayan, P. Bayesian retrieval in associative memories with storage errors.
IEEE transactions on neural networks 9, 705?713 (1998).
[6] Lengyel, M., Kwag, J., Paulsen, O. & Dayan, P. Matching storage and recall: hippocampal
spike timing-dependent plasticity and phase response curves. Nature Neuroscience 8, 1677?
1683 (2005).
[7] Ackley, D., Hinton, G. & Sejnowski, T. A learning algorithm for Boltzmann machines. Cognitive Science 9, 147?169 (1995).
[8] Fiser, J., Berkes, P., Orb?an, G. & Lengyel, M. Statistically optimal perception and learning:
from behavior to neural representations. Trends in Cognitive Sciences 14, 119?130 (2010).
[9] Hinton, G. Deterministic Boltzmann learning performs steepest descent in weight-space.
Neural Computation 1, 143?150 (1990).
[10] Lengyel, M. & Dayan, P. Uncertainty, phase and oscillatory hippocampal recall. Advances in
Neural Information Processing (2007).
[11] Neal, R.M. Sampling from multimodal distributions using tempered transitions. Statistics and
Computing 6, 353?366 (1996).
[12] Fukai, T. & Tanaka, S. A simple neural network exhibiting selective activation of neuronal
ensembles: from winner-take-all to winners-share-all. Neural computation 9, 77?97 (1997).
[13] Bogacz, R. & Gurney, K. The basal ganglia and cortex implement optimal decision making
between alternative actions. Neural computation 19, 442?477 (2007).
[14] Xiang, J.Z. & Brown, M.W. Differential neuronal encoding of novelty, familiarity and recency
in regions of the anterior temporal lobe. Neuropharmacology 37, 657?676 (1998).
[15] Rasmussen, C.E. & Williams, C.K.I. Gaussian Processes for Machine Learning (MIT Press,
2006).
[16] Warburton, E.C. & Brown, M.W. Findings from animals concerning when interactions between perirhinal cortex, hippocampus and medial prefrontal cortex are necessary for recognition memory. Neuropsychologia 48, 2262?2272 (2010).
[17] Yonelinas, A.P. Components of episodic memory: the contribution of recollection and familiarity. Philosophical Transactions of the Royal Society B: Biological Sciences 356, 1363?1374
(2001).
[18] Yonelinas, A. The nature of recollection and familiarity: A review of 30 years of research.
Journal of memory and language 46, 441?517 (2002).
[19] Iba, Y. Extended ensemble Monte Carlo. Int. J. Mod. Phys 12, 653?656 (2001).
[20] Bogacz, R. Comparison of computational models of familiarity discrimination in the perirhinal
cortex. Hippocampus (2003).
[21] Mitchell, S. Shunting inhibition modulates neuronal gain during synaptic excitation. Neuron
(2003).
[22] Fortin, N.J., Wright, S.P. & Eichenbaum, H. Recollection-like memory retrieval in rats is
dependent on the hippocampus. Nature 431, 188?191 (2004).
[23] Cowell, R., Winters, B., Bussey, T. & Saksida, L. Paradoxical false memory for objects after
brain damage. Science (2010).
[24] Norman, K. & O?Reilly, R. Modeling hippocampal and neocortical contributions to recognition
memory: A complementary-learning-systems approach. Psychological Review (2003).

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 3917-spike-timing-dependent-plasticity-as-dynamic-filter.pdf

Spike timing-dependent plasticity as dynamic filter

Joscha T. Schmiedt?, Christian Albers and Klaus Pawelzik
Institute for Theoretical Physics
University of Bremen
Bremen, Germany
schmiedt@uni-bremen.de, {calbers, pawelzik}@neuro.uni-bremen.de

Abstract
When stimulated with complex action potential sequences synapses exhibit spike
timing-dependent plasticity (STDP) with modulated pre- and postsynaptic contributions to long-term synaptic modifications. In order to investigate the functional
consequences of these contribution dynamics (CD) we propose a minimal model
formulated in terms of differential equations. We find that our model reproduces
data from to recent experimental studies with a small number of biophysically interpretable parameters. The model allows to investigate the susceptibility of STDP
to arbitrary time courses of pre- and postsynaptic activities, i.e. its nonlinear filter
properties. We demonstrate this for the simple example of small periodic modulations of pre- and postsynaptic firing rates for which our model can be solved.
It predicts synaptic strengthening for synchronous rate modulations. Modifications are dominant in the theta frequency range, a result which underlines the
well known relevance of theta activities in hippocampus and cortex for learning.
We also find emphasis of specific baseline spike rates and suppression for high
background rates. The latter suggests a mechanism of network activity regulation
inherent in STDP. Furthermore, our novel formulation provides a general framework for investigating the joint dynamics of neuronal activity and the CD of STDP
in both spike-based as well as rate-based neuronal network models.

1

Introduction

During the past decade the effects of exact spike timing on the change of synaptic connectivity have
been studied extensively. In vitro studies have shown that the induction of long-term potentiation
(LTP) requires the presynaptic input to a cell to precede the postsynaptic output and vice versa
for long-term depression (LTD) (see [1, 2, 3]). This phenomenon has been termed spike timingdependent plasticity (STDP) and emphasizes the importance of a causal order in neuronal signaling.
Thereby it extends pure Hebbian learning, which requires only the coincidence of pre- and postsynaptic activity. Consequently, experiments have shown an asymmetric exponential dependence on
the timing of spike pairs and a molecular mechanism mostly dependent on the influx of Ca2+ (see
[4, 5] for reviews). Further, when induced with more complex spike trains, synaptic modification
shows nonlinearities ([6, 7, 8]) indicating the influence of short-term plasticity.
Theoretical approaches to STDP cover studies using the asymmetric pair-based STDP window as
a lookup table, more biophysical models based on synaptic and neuronal variables, and sophisticated kinetic models (for a review see [9]). Recently, the experimentally observed influence of the
postsynaptic membrane potential (e.g. [10]) has also been taken into account ([11]).
Our approach is based on differential Hebbian learning ([12, 13]), which generates asymmetric
timing windows similar to STDP ([14]) depending on the shape of the back-propagating action
?
Postal correspondence should be addressed to Universit?at Bremen, Fachbereich 1, Institut f?ur Theoretische
Physik, Abt. Neurophysik, Postfach 330 440, D-28334 Bremen, Germany

1

potential ([15]). We extend it with a mechanism for activating learning by an increase in postsynaptic
activity, because both the induction of LTP and LTD require [Ca2+ ] to exceed a threshold ([16]).
Moreover, we include a mechanism for adaptive suppression on both synaptic sides, similar to the
model in [7]. Finally, we for simplicity assume that both the presynaptic and the postsynaptic
side function as low-pass filters; a spike leaves a fast increasing and exponentially decaying trace.
Together, we propose a set of differential equations, which captures the contribution dynamics (CD)
of pre- and postsynaptic activities to STDP, thereby describing synaptic plasticity as a filter.
Our framework reproduces experimental findings from two recent in vitro studies in the visual cortex and the hippocampus in most details. Furthermore, it proves to be particularly suitable for the
analysis of the susceptibility of STDP to pre- and postsynaptic rate modulations. This is demonstrated by an analysis of synaptic changes depending on oscillatory modulations of baseline firing
rates.

2

Formulation of the model

We use a variant of the classical differential Hebbian learning assuming a change of synaptic connectivity w, which is dependent on the presynaptic activity trace ypre and the temporal derivative of
the postsynaptic activity trace ypost :
w(t)
?
= cw ypre (t)y? post (t) .

(1)

cw denotes a constant learning rate. An illustration of this learning rule for pairs of spikes is given
in Figure 1B. For simplicity, we assume these activity traces to be abstract low-pass filtered versions
of neuronal activity x in the presynaptic and postsynaptic cells, e.g. the concentration of Ca2+ or
the amount of bound glutamate:
ypre (t)
?pre
ypost (t)
y? post (t) = upost (t)z(t) ? xpost (t) ?
.
?post
y? pre (t) = upre (t) ? xpre (t) ?

(2)
(3)

The dynamics of the y?s are characterized by their respective time constants ?pre and ?post . The
contribution of each spike is regulated by a suppressing attenuation factor u pre- and postsynaptically. On the postsynaptical side an additional activation factor z ?enables? the synapse to learn.
The dynamics of u and z are discussed below. x represents neuronal activity which can be either a
time-continuous firing rate or spike trains given by series of ? pulses
X
xpre, post (t) =
?(t ? tipre, post ) ,
(4)
i

which allows analytical investigations of the properties of our model. Note that formally x(t) has
then to be taken as x(t + 0). An illustrating overview over the different parts of the model with
sample trajectories is shown in Figure 1A.
We define the relative change of synaptic connectivity after after a period T from Equation (1) as
Z
cw
w(t0 + T )
?1=
ypre y? post dt .
(5)
?w =
w(t0 )
w(t0 ) T
The dependence on the initial synaptic strength w(t0 ) as observed in [3, 8] shall not be discussed
here, but can easily be achieved by making the learning rate cw in Equation (1) w-dependent. Here,
w(t0 ) is chosen to be 1.
Ignoring attenuation and activation, a single pair of spikes at temporal distance ?t analytically yields
the typical STDP window (see Figure 2A and 3A):

?w(?t) =

(


cw 1 ?

cw ?



?pre
??t/?pre
?pre +?post e
?pre
??t/?post
?pre +?post e

2

for

?t > 0

for

?t < 0

(6)

A

Modulation
Factors

Activity

Activity Traces
(Contributions)

Differential Hebbian
Learning

x
Low-pass

u

SYNAPSE

? ?w

POST

y
Low-pass &

u

x

z

B

y

PRE

d
dt

Example for spike pairs
?pre
ypre
0

ypost

ypost

?w ?



?w ?

ypre (t) y? post (t) dt > 0



ypre (t) y? post (t) dt < 0

0
?t > 0

?post

Time

?t < 0

Figure 1: Schematic illustration of differential Hebbian learning with contribution dynamics. A:
Pre- and postsynaptic activity (x, second column) is modulated (attenuated with u, activated with z,
first column) and filtered (y, third column) before it contributes to differential Hebbian learning (w,
fourth column). B: Spike pair example for differential Hebbian learning. Left: a presynaptic spike
trace (ypre ) preceding a postsynaptic spike trace (ypost , dotted line) yields a synaptic strengthening
due to the initially positive postsynaptic contribution (y? post , solid line), which is always stronger
than the following negative part. Right: for the reverse timing the positive presynaptic contribution
is only multiplied with the negative postsynaptic trace (right). Areas contributing to learning are
shaded.
The importance of adaptive suppressing mechanisms for synaptic plasticity has experimentally been
shown by Froemke and colleagues ([7, 6]). Therefore, we down-regulate the contribution of the
spikes to the activity traces y in Equation (2) and (3) with an attenuation factor u on both pre- and
postsynaptic sides:
1
(1 ? upre ) ? cpre upre xpre
rec
?pre
1
= rec (1 ? upost ) ? cpost (upost ? u0 )xpost
?post

u? pre =
u? post

(7)
.

(8)

This should be understood as an abstract representation of for instance the depletion of transmitters
in the presynaptic bouton ([17]) or the frequency-dependent spike attenuation in dendritic spines
([18]), respectively. These recover with their time constants ? rec and are bound between u0 and 1.
3

post
For the presynaptic side we assume in the following upre
0 = 0, so we abbreviate u0 = u0 . The
constants cpre, post ? [0, 1] denote the impact a spike has on the relaxed synapse.

In several experiments it has been shown that a single spike is not sufficient to induce synaptic
modification ([10, 8]). Therefore, we introduce a spike-induced postsynaptic activation factor z
z? = cact xpost z ? ?(z ? z0 )2 ,

(9)

which enhances the contribution of a postsynaptic spike to the postsynaptic trace, e.g. by the removal
of the Mg2+ block from postsynaptic NMDA receptors ([19, 5]). The nonlinear positive feedback
is introduced to describe strong enhancing effects as for instance autocatalytic mechanisms, which
have been suggested to play a role in learning on several time-scales ([20, 21]). The activation
z decays hyperbolically to a lower bound z0 and the contribution of a spike is weighted with the
constant cact .

3

Comparison to experiments

In order to evaluate our model we implemented experimental stimulation protocols from in vitro
studies on synapses of the visual cortex ([7]) and the hippocampus ([8]) of rats. In both studies,
simple pairs of spikes and more complex spike trains were artificially elicited in the presynaptic and
the postsynaptic cell and the induced change of synaptic connectivity was recorded.
Froemke and colleagues ([7]) focused on the effects of spike bursts on synaptic modification in the
visual cortex. In addition to the classical STDP pairing protocol ? a presynaptic spike preceding
or following a postsynaptic spike after a specific time ?t ? four other experimental protocols (see
Figure 2B to E) were performed: (1) 5-5 bursts with five spikes of a certain frequency on both
synaptic sides, where the postsynaptic side follows the presynaptic side, (2) presynaptic 100 Hz
bursts with n spikes following one postsynaptic spike (post-n-pre), (3) presynaptic 100 Hz bursts
with different numbers of spikes followed by one postsynaptic spike (n-pre-post) and (4) a post-pre
pair with varying number of following postsynaptic spikes (post-pre-n-post).
Experiment
Model

1.5

A

1

?w

0.5

pre
post

0

LTP

0.5
0

?0.5

LTD

?0.5

?150

?100

C

?50

? t (ms)

0

50
1

0
?0.2
?0.4
1

2

3

B

4

5

Presynaptic spikes

10

100

D

50

Frequency (Hz)
0.4 E

0.8

0.2

0.6

0

0.4

?0.2

0.2

?0.4

0

1

2

3

4

5

Presynaptic spikes

1

2

3

100

4

5

Postsynaptic spikes

Figure 2: Differential Hebbian learning with CD reproduces synaptic modification induced with
STDP spike patterns in visual cortex. Data taken from [7], personal communication. A: experimental fit and model prediction with Equation (6) of pair-based STDP. B: dependence of synaptic
modifications on the frequency of 5-5 bursts with presynaptic spikes following postsynaptic spikes
by 6 ms. C, D and E: synaptic modification induced by post-n-pre, n-pre-post and post-pre-n-post
100 Hz spike trains.

4

1

A

pre
post

0.1
0

0

?0.5

0.4

?w

0.3 B
0.2

?w

0.5

Experiment
Model

?150

?100

?50

? t (ms)

0

50

100

(5,89,5)

C

0.4

0.3

0.3

0.2

0.2

0

0.1
(5,5)

(10,10)

(5,20,5) (5,84,5)

Interspike interval (ms)

(15,5)

D

0

(5,15)

(5,5)

Interspike interval (ms)

(10,10)

(15,5)

(5,15)

Interspike interval (ms)

Figure 3: Differential Hebbian learning with CD reproduces synaptic modification induced with
STDP spike patterns in hippocampus. Data taken from [8] as reported in [22]. A: experimental
fit and model prediction with Equation (6) of pair-based STDP. B: quadruplet protocol. C and D:
post-pre-post and pre-post-pre triplet protocol for different interspike intervals.
Table 1: Parameters and evaluation results for the data sets from visual cortex ([7]) and hippocampus
([8]). E: normalized mean-square error, S: ratio of correctly predicted signs of synaptic modification.
cpre

cpost

cact

rec
?pre
[s]

rec
?post
[s]

?

u0

z0

E

S

Visual cortex

0.9

1

1.5

2

0.2

1

0.01

1

4.04

18/18

Hippocampus

0.6

0.4

3.5

0.5

0.5

1

0.7

0.2

2.16

10/11

In the hippocampal study of Wang et al. ([8]) synaptic modification induced by triplets (pre-post-pre
and post-pre-post) and quadruplets (pre-post-post-pre and post-pre-pre-post) of spikes was measured
while the respective interspike intervals were varied. (see Figure 3B to D).
As a first step we took the time constants from the experimentally measured pair-based STDP windows as our low-pass filter time constants (see Equation 6). They remained constant for each data
set: (1) ?pre = 13.5 ms and ?post = 42.8 ms for [7], (2) ?pre = 16.8 ms and ?post = 33.7 ms for [8]
(taken from [23] since not present in the study). Next, we chose the learning rate cw in Equation (6)
to fit the synaptic change for the pairing protocol: (1) cw = 1.56 for the visual cortex data, (2)
cw = 0.99 for the hippocampal data set. The remaining parameters were estimated manually within
biologically plausible ranges and are shown in Table 1. The model was then applied to the more
complex stimulation protocols by solving the differential equations semi-analytically, i.e. separately
for every spike and the following interspike interval. As measure for the prediction error of our
model we used the normalized mean-square error E
E=

N
1 X ?wiexp ? ?wimod 2
,
N i=1
?i

(10)

where ?wiexp and ?wimod are the experimentally measured and the predicted modifications of synaptic strength in the ith experiment; N is the number of data points (N = 18 for the visual cortex data
set, N = 11 for the hippocampal data set). ?i is the standard error of the mean of the experimental
data. Additionally we counted the number of correctly predicted signs S of synaptic modification,
i.e. induced depression or potentiation. The prediction error for both data sets is shown in Table 1.
5

?/2

?
?/2

0

0

-?/2

-?/2

-?

Phase shift ??

Cortex
x0 = 1?Hz

?
?/2

1

3

7

-?

20 50 100

?

x0 = 5?Hz

?/2

0

0

-?/2

-?/2

-?
?
?/2

1

3

7

-?

20 50 100

?

x0 = 10?Hz

?/2

0

0

-?/2

-?/2

-?

1

3

7

-?

20 50 100

Hippocampus
x0 = 1?Hz

1

3

7

20 50 100

1

x0 = 5?Hz

?W (a.u.)

?

1

3

7

20 50 100

-1

x0 = 30?Hz

1

0

3

7

20 50 100

Modulation frequency f [Hz]
Figure 4: Synaptic change depending on frequency f and phase shift ?? of pre- and postsynaptic
rate modulations for different baseline rates x0 . The color codes are identical within each column
and in arbitrary units. Note the strong suppression with increasing baseline rate for cortical synapses
which is due to strong attenuation effects of pre- and postsynaptic contributions. It is weaker for
hippocampal synapses because we found the postsynaptic attenuation to be bounded (u0 = 0.7).

4

Phase, frequency and baseline rate dependence of STDP with contribution
dynamics

As shown in the previous section our model can reproduce the experimental findings of synaptic
weight changes in response to spike sequences surprisingly well and yields better fits than former
studies (e.g. [22]). The proposed framework, however, is not restricted to spike sequences but allows to investigate synaptic changes depending on arbitrary pre- and postsynaptic activities. For
instance it could be used for investigations of the plasticity effects in simulations with inhomogeneous Poisson processes. Taking x(t) to be firing rates of Poissonian spike trains our account of
STDP represents a useful approximation for the expected changes of synaptic strength depending
on the time courses of xpre and xpost (compare e.g. [24]). Therefore our model can serve also as
building block in rate based network models for investigation of the joint dynamics of neuronal
activities and synaptic weights.
Here, we demonstrate the benefit of our approach for determining the filter properties of STDP
subject to CD, i.e. we use the equations together with the parameters from the experiments for
determining the dependency of weight changes on frequency, relative phase ?? and baseline rates
of modulated pre- and postsynaptic firing rates. While for substantial modulations of firing rates
the nonlinearities are difficult to be treated analytically, for small periodical modulations around a
baseline rate x0 the corresponding synaptic changes can be calculated analytically. This is done by
considering
xpre (t) = x0 + ? cos(2?f t) and

xpost (t) = x0 + ? cos(2?f t ? ??) ,

(11)

which for small ? < x0 allows linearization of all equations from which one obtains ?W =
?w/(T ?pre ?post ), where T = 1/f = 2?/? is the period of the respective oscillations. Neglect6

ing transients this finally yields the expected weight changes per unit time. Though lengthy the
calculations are straightforward and presented in the supplementary material. We here show only
the exact result for the case of constant u = 1 and z = 1:
p

??pre ?post ? 2 (?post ? ?pre )2 + (1 + ? 2 ?pre ?post )2
?(?post ? ?pre ) 
?W =
?sin
??+arctan
(12)
2 ? 2 )(1 + ? 2 ? 2 )
2(1 + ?pre
1 + ? 2 ?pre ?post
post
The analytical results for the case with CD are shown graphically in Figure 4 using the parameters
from cortex and hippocampus, respectively (see Tab. 1). These plots contain the main findings:
(1) rate modulations in the theta frequency range (' 7Hz) lead to strongest synaptic changes, (2)
also for phase-zero synchronous rate modulations weight changes are positive, (3) in hippocampus
maximal weight change magnitudes occur at baseline rates around 5 Hz, and (4) for high baseline
rates weight changes become suppressed (? 1/x0 for the hippocampus, ? 1/x20 for the visual
cortex). Numerical simulations with finite rate modulations were found to confirm these analytical
predictions surprisingly well. Also for the nonlinear regime and Poissionian spike trains deviations
remained moderate.

5

Discussion

STDP has been proposed to represent a fundamental mechanism underlying learning and many
models explored its computational role (examples are [25, 26, 27]). In contrast, research targeting
the computational roles of dynamical phenomena inherent in STDP are in the beginning (see [9]).
Here, we here formulated a minimal, yet biologically plausible model including the dynamics of how
neuronal activity contributes to STDP. We found that our model reproduces the synaptic changes in
response to spike sequences in experiments in cortex and hippocampus with high accuracy.
Using the corresponding parameters our model predicts weight changes depending on temporal
structures in the pre- and postsynaptic activities including spike sequences and varying firing rates.
When applied to pre- and postsynaptic rate modulations our approach quantifies synaptic changes
depending on frequency and phase shifts between pre- and postsynaptic activities. A rigorous perturbation analysis of our model reveals that the dynamical filter properties of STDP make weight
changes sensitively dependent on combinations of specific features of pre- and postsynaptic signals.
In particular, our analysis indicates that both cortical as well as hippocampal STDP is most susceptible for modulations in the theta frequency range. It predicts the dependency of synaptic changes
on pre- and postsynaptic phase relations of rate modulations. These results are in line with experimental results on the relation of theta rhythms and learning. For instance in hippocampus it is well
established that theta oscillations are relevant for learning (for a recent paper see [28]). Furthermore,
spike activities in hippocampus exhibit specific phase relations with the theta rhythm (for a review
see [29]). Also, it has been found that during learning cortex and hippocampus tend to synchronize
with particular phase relations that depend on the novelty of the item to be learned ([30]). The results
presented here underline these findings and make testable predictions for the corresponding synaptic
changes.
Also, we find potentiation for zero phase differences and strong attenuation of weight changes at
large baseline rates which is particularly strong for cortical synapses. This finding suggests a mechanism for restricting weight changes with high activity levels and that STDP is de facto switched off
when large firing rates are required for the execution of a function as opposed to learning phases;
during the latter baseline rates should be rather low, which is particularly relevant in cortex. While
for cortical synapses our analysis predicts that very low baseline activities are contributing most to
weight changes, in hippocampus synaptic modifications peak at baseline firing rates x0 around 5 Hz,
which suggests that x0 can control learning.
Our study suggests that the filter properties of STDP originating from the dynamics of pre- and
postsynaptic activity contributions are in fact exploited for learning in the brain. In particular, shifts
in baseline rates, as well as the frequency and the respective phases of pre- and postsynaptic rate
modulations induced by theta oscillations could be tuned to match the values that make STDP most
susceptible for synaptic modifications. A fascinating possibility thereby is that these features could
be used to control the learning rate which would represent a novel mechanism in addition to other
control signals as e.g. neuromodulators.

7

References
[1] W. Levy and O. Steward. Temporal contiguity requirements for long-term associative potentiation/depression in the hippocampus. Neuroscience, 8(4):791?797, 1983.
[2] H. Markram, J. Lubke, M. Frotscher, and B. Sakmann. Regulation of synaptic efficacy by
coincidence of postsynaptic APs and EPSPs. Science, 1997.
[3] G. Q. Bi and M. M. Poo. Synaptic modifications in cultured hippocampal neurons: dependence on spike timing, synaptic strength, and postsynaptic cell type. Journal of Neuroscience,
18(24):10464?72, 1998.
[4] P. J. Sj?ostr?om, E. A. Rancz, A. Roth, and M. H?ausser. Dendritic excitability and synaptic
plasticity. Physiological Reviews, 88(2):769?840, 2008.
[5] N. Caporale and Y. Dan. Spike timing?dependent plasticity: a Hebbian learning rule. Annual
Review in Neuroscience, 2008.
[6] R. C. Froemke and Y. Dan. Spike-timing-dependent synaptic modification induced by natural
spike trains. Nature, 2002.
[7] R. C. Froemke, I. A. Tsay, M. Raad, J. D. Long, and Y. Dan. Contribution of individual spikes
in burst-induced long-term synaptic modification. Journal of Neurophysiology, 95(3):1620?9,
2006.
[8] H. X. Wang, R. C. Gerkin, D. W. Nauen, and G. Q. Bi. Coactivation and timing-dependent
integration of synaptic potentiation and depression. Nature Neuroscience, 8(2):187?93, 2005.
[9] A. Morrison, M. Diesmann, and W. Gerstner. Phenomenological models of synaptic plasticity
based on spike timing. Biological Cybernetics, 98(6):459?78, 2008.
[10] P. J. Sj?ostr?om, G. G. Turrigiano, and S. B. Nelson. Rate, timing, and cooperativity jointly
determine cortical synaptic plasticity. Neuron, 32(6):1149?1164, 2001.
[11] C. Clopath, L. B?using, E. Vasilaki, and W. Gerstner. Connectivity reflects coding: a model of
voltage-based STDP with homeostasis. Nature Neuroscience, 13(3):344?52, 2010.
[12] B. Kosco. Differential Hebbian learning. AIP Conference Proceedings 151 on Neural Networks
for Computing, 1987.
[13] A. H. Klopf. A drive-reinforcement model of single neuron function: An alternative to the
Hebbian neuronal model. AIP Conference Proceedings, 151(1):265?270, 1986.
[14] P. D. Roberts. Computational consequences of temporally asymmetric learning rules: I. differential Hebbian learning. Journal of Computational Neuroscience, 7(3):235?246, 1999.
[15] A. Saudargiene, B. Porr, and F. W?org?otter. How the shape of pre-and postsynaptic signals can
influence STDP: a biophysical model. Neural Computation, 2004.
[16] T. Nevian and B. Sakmann. Spine Ca2+ signaling in spike-timing-dependent plasticity. Journal
of Neuroscience, 26(43):11001?13, 2006.
[17] M. V. Tsodyks and H. Markram. The neural code between neocortical pyramidal neurons
depends on neurotransmitter release probability. Proceedings of the National Academy of
Sciences, 94(2):719?723, 1997.
[18] E. Tanaka, H. Higashi, and S. Nishi. Membrane properties of guinea pig cingulate cortical
neurons in vitro. J Neurophysiol, 65(4):808?821, 1991.
[19] L. Nowak, P. Bregestovski, P. Ascher, A. Herbet, and A. Prochiantz. Magnesium gates
glutamate-activated channels in mouse central neurones. Nature, 307(5950):462?5, 1984.
[20] J. E. Lisman. A Mechanism for Memory Storage Insensitive to Molecular Turnover: A Bistable
Autophosphorylating Kinase. Proceedings of the National Academy of Sciences, 82(9):3055?
3057, 1985.
[21] U. S. Bhalla and R. Iyengar. Emergent Properties of Networks of Biological Signaling Pathways. Science, 283(5400):381?387, 1999.
[22] J. P. Pfister and W. Gerstner. Triplets of spikes in a model of spike timing-dependent plasticity.
Journal of Neuroscience, 26(38):9673?82, 2006.
[23] G. Bi and M. Poo. Synaptic modification by correlated activity: Hebb?s postulate revisited.
Annual Review of Neuroscience, 24:139?66, 2001.
8

[24] M. Tsodyks, K. Pawelzik, and H. Markram. Neural networks with dynamic synapses. Neural
Computation, 10(4):821?35, 1998.
[25] M. Lengyel, J. Kwag, O. Paulsen, and P. Dayan. Matching storage and recall: hippocampal spike timing-dependent plasticity and phase response curves. Nature Neuroscience,
8(12):1677?83, 2005.
[26] F. W?org?otter and B. Porr. Temporal sequence learning, prediction, and control: a review of
different models and their relation to biological mechanisms. Neural Computation, 17(2):245?
319, 2005.
[27] E. M. Izhikevich. Solving the distal reward problem through linkage of STDP and dopamine
signaling. Cerebral Cortex, 17(10):2443?52, 2007.
[28] U. Rutishauser, I. B. Ross, A. N. Mamelak, and E. M. Schuman. Human memory strength
is predicted by theta-frequency phase-locking of single neurons. Nature, 464(7290):903?7,
2010.
[29] Y. Yamaguchi, N. Sato, H. Wagatsuma, Z. Wu, C. Molter, and Y. Aota. A unified view of
theta-phase coding in the entorhinal-hippocampal system. Current Opinion in Neurobiology,
17(2):197?204, 2007.
[30] A. Jeewajee, C. Lever, S. Burton, J. O?Keefe, and N. Burgess. Environmental novelty is signaled by reduction of the hippocampal theta frequency. Hippocampus, 18(4):340?8, 2008.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4315-active-dendrites-adaptation-to-spike-based-communication.pdf

Active dendrites:
adaptation to spike-based communication
Bal?azs B Ujfalussy1,2
M?at?e Lengyel1
ubi@rmki.kfki.hu
m.lengyel@eng.cam.ac.uk
1
Computational & Biological Learning Lab, Dept. of Engineering, University of Cambridge, UK
2
Computational Neuroscience Group, Dept. of Biophysics, MTA KFKI RMKI, Budapest, Hungary

Abstract
Computational analyses of dendritic computations often assume stationary inputs to neurons, ignoring the pulsatile nature of spike-based communication between neurons and the moment-to-moment fluctuations caused by such spiking
inputs. Conversely, circuit computations with spiking neurons are usually formalized without regard to the rich nonlinear nature of dendritic processing. Here we
address the computational challenge faced by neurons that compute and represent
analogue quantities but communicate with digital spikes, and show that reliable
computation of even purely linear functions of inputs can require the interplay of
strongly nonlinear subunits within the postsynaptic dendritic tree. Our theory predicts a matching of dendritic nonlinearities and synaptic weight distributions to
the joint statistics of presynaptic inputs. This approach suggests normative roles
for some puzzling forms of nonlinear dendritic dynamics and plasticity.

1

Introduction

The operation of neural circuits fundamentally depends on the capacity of neurons to perform complex, nonlinear mappings from their inputs to their outputs. Since the vast majority of synaptic inputs
impinge the dendritic membrane, its morphology, and passive as well as active electrical properties
play important roles in determining the functional capabilities of a neuron. Indeed, both theoretical
and experimental studies suggest that active, nonlinear processing in dendritic trees can significantly
enhance the repertoire of singe neuron operations [1, 2].
However, previous functional approaches to dendritic processing were limited because they studied
dendritic computations in a firing rate-based framework [3, 4], essentially requiring both the inputs
and the output of a cell to have stationary firing rates for hundreds of milliseconds. Thus, they
ignored the effects and consequences of temporal variations in neural activities at the time scale
of inter-spike intervals characteristic of in vivo states [5]. Conversely, studies of spiking network
dynamics [6, 7] have ignored the complex and highly nonlinear effects of the dendritic tree.
Here we develop a computational theory that aims at explaining some of the morphological and
electrophysiological properties of dendritic trees as adaptations towards spike-based communication. In line with the vast majority of theories about neural network computations, the starting point
of our theory is that each neuron needs to compute some function of the membrane potential (or,
equivalently, the instantaneous firing rate) of its presynaptic partners. However, as the postsynaptic
neuron does not have direct access to the presynaptic membrane potentials, only to the spikes emitted by its presynaptic partners based on those potentials, computing the required function becomes a
non-trivial inference problem. That is, neurons need to perform computations on their inputs in the
face of significant uncertainty as to what those inputs exactly are, and so as to what their required
output might be.
In section 2 we formalize the problem of inferring some required output based on incomplete
spiking-based information about inputs and derive an optimal online estimator for some simple
1

but tractable cases. In section 3 we show that the optimal estimator exhibits highly nonlinear behavior closely matching aspects of active dendritic processing, even when the function of inputs to be
computed is purely linear. We also present predictions about how the statistics of presynaptic inputs
should be matched by the clustering patterns of synaptic inputs onto active subunits of the dendritic
tree. In section 4 we discuss our findings and ways to test our predictions experimentally.

2
2.1

Estimation from correlated spike trains
The need for nonlinear dendritic operations

Ideally, the (subthreshold) dynamics of the somatic membrane potential, v(t), should implement
some nonlinear function, f (u(t)), of the presynaptic membrane potentials, u(t).1
?

dv(t)
= f (u(t))
dt

v(t)

(1)

However, the presynaptic membrane potentials cannot be observed directly, only the presynaptic
spike trains s0:t that are stochastic functions of the presynaptic membrane potential trajectories.
Therefore, to minimise squared error, the postsynaptic membrane potential should represent the
mean of the posterior over possible output function values it should be computing based on the input
spike trains:
Z
dv(t)
?
' f (u(t)) P(u(t)|s0:t ) du(t) v(t)
(2)
dt
Biophysically, to a first approximation, the somatic membrane potential of the postsynaptic neuron
can be described as some function(al), f?, of the local dendritic membrane potentials, vd (t)
?

dv(t)
dt

=

f? vd (t)

v(t)

(3)

This is interesting because Pfister et al. [11, 12] have recently suggested that short-term synaptic
plasticity arranges for each local dendritic postsynaptic potential, vid , to (approximately) represent
the posterior mean of the corresponding presynaptic membrane potential:
Z
d
vi (t) ' ui (t) P(ui (t)|si,0:t ) dui
(4)

Thus, it would be tempting to say that in order to achieve the computational goal of Eq. 2, the way
the dendritic tree (together with the soma) should integrate these local potentials, as given by f?,
should be directly determined by the function that needs to be computed: f? = f . However, it is easy
to see that in general this is going to be incorrect:
! Z
Z
Y
f
u(t)
P(ui (t)|si,0:t ) du(t) 6= f (u(t)) P(u(t)|s0:t ) du(t)
(5)
i

where the l.h.s. is what the neuron implements (eqs. 3-4) and the r.h.s. is what it should compute
(eq. 2). The equality does not hold in general when f is non-linear or P(u(t)|s0:t ) does not factorise.

In the following, we are going to consider
Pthe case when the function, f (u), is a purely linear
combination of synaptic inputs, f (u) =
i ci ui . Such linear transformations seem to suggest
linear dendritic operations and, in combination with a single global ?somatic? nonlinearity, they are
often assumed in neural network models and descriptive models of neuronal signal processing [10].
However, as we will show below, estimation from the spike trains of multiple correlated presynaptic
neurons requires a non-linear integration of inputs even in this case.
1
Dynamics of this form are assumed by many neural network models, though the variables u amd v are
usually interpreted as instantaneous firing rates rather than membrane potentials [10]. However, just as in our
case (Eq. 8), the two are often taken to be related through a simple non-linear function which thus makes the
two frameworks essentially isomorphic.

2

2.2

The mOU-NP model

We assume that the hidden dynamics of presynaptic membrane potentials are described by a multivariate Ornstein?Uhlenbeck (mOU) process (discretised in time into t ! 0 time bins, thus formally
yielding an AR(1) process):
p
1
iid
ut = ut t + (u0 ut t ) t + qt t,
qt ? N (0, Q)
(6)
?
p
t
= ?ut t + qt t + u0
(7)
?
where we described all neurons with the same parameters: u0 , the resting potential and ? , the
membrane time constant (with ? = 1 ?t ). Importantly, Q is the covariance matrix parametrising
the correlations between the subthreshold membrane potential fluctuations of presynaptic neurons.
Spiking is described by a nonlinear-Poisson (NP) process where the instantaneous firing rate, r, is
an exponential function of u with exponent and ?baseline rate? g:
r(u) = g e

u

(8)

and the number of spikes emitted in a time bin, s, is Poisson with this rate:
(9)

P(s|u) = Poisson(s; t r(u))
The spiking process itself is independent i.e., the likelihood is factorised across cells:
Y
P(s|u) =
P(si |ui )

(10)

i

2.3

Assumed density filtering in the mOU-NP model

Our goal is to derive the time evolution of the posterior distribution of the membrane potential,
P(ut |s0:t ), given a particular spiking pattern observed. Ultimately, we will need to compute some
function of u underPthis distribution. For linear computations (see above), the final quantity of
interest depends on i ci ui which in the limit (of many presynaptic cells) is going to be Gaussiandistributed, and as such only dependent on the first two moments of the posterior. This motivates
us to perform assumed density filtering, by which we substitute the true posterior with a momentmatched multivariate Gaussian in each time step, P(ut |s0:t ) ' N (ut ; ?t , ?t ).
After some algebra (see Appendix for details) we obtain the following equations for the time evolution of the mean and covariance of the posterior under the generative process defined by Eqs. 7-10:
??

=

?
?

=

1
(u0 ?) + ? (s(t)
)
?
2
2
(?OU ?)
? ?
?

(11)
(12)

where si (t) is the spike train of presynaptic neuron i represented as a sum of Dirac-delta functions,
2?

ii

( ) is a vector (diagonal matrix) whose elements i = ii = g e ?i + 2 are the estimated firing
rates of the neurons, and ?OU = Q?
2 is the prior covariance matrix of the presynaptic membrane
potentials in the absence of any observation.
2.4

Modelling correlated up and down states

The mOU-NP process is a convenient and analytically tractable way to model correlations between
presynaptic neurons but it obviously falls short of the dynamical complexity of cortical ensembles
in many respects. Following and expanding on [12], here we considered one extension that allowed
us to model coordinated changes between more hyper- and depolarised states across presynaptic
neurons, such as those brought about by cortical up and down states.
In this extension, the ?resting? potential of each presynaptic neuron, u0 , could switch between two
different values, uup and udown , and followed first order Markovian dynamics. Up and down states in
cortical neurons are not independent but occur synchronously [13]. To reproduce these correlations
3

??

?
mean

?
0.6

?1
?2

??

??

0.5
0.1

?

1.2

????

????

0

?????

v (mV)
0
12

-1.2

??

?????

??

?????
???????????
???

???

?????

??

variance

?0.6

???
?

?

???

????

???

200
?????????

?

?

??
????

???

Figure 1: Simulation of the optimal estimator in the case of two presynaptic spikes with different
time delays ( t). A: The posterior means (Aa), variances, ?ii , and the covariance, ?12 (Ab). The
dynamics of the postsynaptic membrane potential, v (Ad) is described by Eq. 1, where f (u) =
u1 + u2 (Ac). B: The same as A on an extended time scale. C: The nonlinear summation of
two EPSPs, characterised by the ratio of the actual EPSP (cyan on Ad) and the linear sum of two
individual EPSPs (grey on Ad) is shown for different delays and correlations between the presynaptic
neurons. The summation is sublinear if the presynaptic neurons are positively correlated, whereas
negative correlations imply supralinear summation.
we introduced a global, binary state variable, x that influenced the Markovian dynamics of the
resting potential of individual neurons (see Appendix and Fig. 2A). Unfortunately, an analytical
solution to the optimal estimator was out of reach in this case, so we resorted to particle filtering
[14] to compute the output of the optimal estimator.

3
3.1

Nonlinear dendrites as near-optimal estimators
Correlated Ornstein-Uhlenbeck process

First, we analysed the estimation problem in case of mOU dynamics where we could derive an optimal estimator for the membrane potential. Postsynaptic dynamics needed to follow the linear sum
of presynaptic membrane potentials. Figure 1 shows the optimal postsynaptic response (Eqs. 11-12)
after observing a pair of spikes from two correlated presynaptic neurons with different time delays.
When one of the cells (black) emits a spike, this causes an instantaneous increase not only in the
membrane potential estimate of the neuron itself but also in those of all correlated neurons (red neuron in Fig. 1Aa and Ba). Consequently, the estimated firing rate, , of both cells increases. Albeit
indirectly, a spike also influences the uncertainty about the presynaptic membrane potentials ? quantified by the posterior covariance matrix. A spike itself does not change this covariance directly, but
since it increases estimated firing rates, the absence of even more spikes in the subsequent period
becomes more informative. This increased information rate following a spike decreases estimator
uncertainty about true membrane potential values for a short period (Fig. 1Ab and Bb). However, as
the estimated firing rate decreases back to its resting value nearly exponentially after the spike, the
estimated uncertainty also returns back to its steady state.
Importantly, the instantaneous increase of the posterior means in response to a spike is proportional
to the estimated uncertainty about the membrane potentials and to the estimator?s current belief
about the correlations between the neurons. As each spike influences not only the mean estimate
of the membrane potentials of other correlated neurons but also the uncertainty of these estimates,
the effect of a spike from one cell on the posterior mean depends on the spiking history of all other
correlated neurons (Fig. 1Ac-Ad).
4

In the example shown in Fig. 1, the postsynaptic dynamics is required to compute a purely linear
sum of two presynaptic membrane potentials, f (u) = u1 + u2 . However, depending on the prior
correlation between the two presynaptic neurons and the time delay between the two spikes, the
amplitude of the postsynaptic membrane potential change evoked by the pair of spikes can be either
larger or smaller than the linear sum of the individual excitatory postsynaptic potentials (EPSPs)
(Fig. 1Ad, C). EPSPs from independent neurons are additive, but if the presynaptic neurons are positively correlated then their spikes convey redundant information and they are integrated sublinearly.
Conversely, simultaneous spikes from negatively correlated presynaptic neurons are largely unexpected and induce supralinear summation. The deviation from the linear summation is proportional
to the magnitude of the correlation between the presynaptic neurons (Fig. 1C).
We compared the nonlinear integration of the inputs in the optimal estimator with experiments measuring synaptic integration in the dendritic tree of neurons. For a passive membrane, cable theory
[15] implies that inputs are integrated linearly only if they are on electronically separated dendritic
branches, but reduction of the driving force entails a sublinear interaction between co-localised inputs. Moreover, it has been found that active currents, the IA potassium current in particular, also
contribute to the sublinear integration within the dendritic tree [16, 17]. Our model predicts that
inputs that are integrated sublinearly are positively correlated (Fig. 1C).
In sum, we can already see that correlated inputs imply nonlinear integration in the postsynaptic
neuron, and that the form of nonlinearity needs to be matched to the degree and sign of correlations between inputs. However, the finding that supralinear interactions are only expected from
anticorrelated inputs defeats biological intuition. Another shortcoming of the mOU model is related
to the second-order effects of spikes on the posterior covariance. As the covariance matrix does not
change instantaneously after observing a presynaptic spikes (Fig. 1B), two spikes arriving simultaneously are summed linearly (not shown). At the other extreme, two spikes separated by long delays
again do not influence each other. Therefore the nonlinearity of the integration of two spikes has a
non-monotonic shape, which again is unlike the monotonic dependence of the degree of nonlinearity
on interspike intervals found in experiments [18, 19]. In order to overcome these limitations, we extended the model to incorporate correlated changes in the activity levels of presynaptic neurons [13].
3.2

Correlated up and down states

While the statistics of presynaptic membrane potentials exhibit more complex temporal dependencies in the extended model (Fig. 2A), importantly, the task is still assumed to be the same simple
linear computation as before: f (u) = u1 + u2 .
However, the more complex P(u) P
distribution means that we need to sum over the possible values
of the hidden variables: P(u) =
u0 P(u|u0 ) P(u0 ). The observation of a spike changes both
the conditional distributions, P(u|u0 ), and the probability of being in the up state, P(u0 = uup ),
by causing an upward shift in both. A second spike causes a further increase in the membrane
potential estimate, and, more importantly, in the probability of being in the up state for both neurons.
Since the probability of leaving the up state is low, the membrane potential estimate decays back
to its steady state more slowly if the probability of being in the up state is high (Fig. 2B). This
causes a supralinear increase in the membrane potential of the postsynaptic neuron which again
depends on the interspike interval, but this time supralinearity is predicted for positively correlated
presynaptic neurons (Fig. 2C,E). Note, that while in the mOU model, supralinear integration arises
due to dynamical changes in uncertainty (of membrane potential estimates), in the extended model
it is associated with a change in a hypothesis (about hidden up-down states).
This is qualitatively similar to what was found in pyramidal neurons in the neocortex [19] and in the
hippocampus [18, 20] that are able to switch from (sub)linear to supralinear integration of synaptic
inputs through the generation of dendritic spikes [21]. Specifically, in neocortical pyramidal neurons
Polsky et al. [19] found, that nearly synchronous inputs arriving to the same dendritic branch evoke
substantially larger postsynaptic responses than expected from the linear sum of the individual responses (Fig. 2D-E). While there is a good qualitative match between model and experiments, the
time scales of integration are off by a factor of 2. Neverthless, given that we did not perform exhaustive parameter fitting in our model, just simply set parameters to values that produced realistic
presynaptic membrane potential trajectories (cf. our Fig. 2A with [13]), we regard the match acceptable and are confident that with further fine tuning of parameters the match would also improve
quantitatively.
5

?

???

1 ms

????
?????????

32 ms

????

????

2 mV

?

100 ms
50 ms

100 ms

?

2 mV
15 ms

50 ms
30 ms

50 ms

2
?4

?2

0

?????????
??????????????
????????????

?20

20
60
time (ms)

100

?20

??????????

20
60
time (ms)

100

?????

????????
??????????????

????????
??????????????

2

0 ms

up state probability
0.0
0.4
0.8

??

?

?

?? ??

?

???????????????????
4
6
8
10

?

Membrane potential (mV)

?

0

10

20
30
40
??????????????????

50

0

20

40
60
80
??????????????????

100

Figure 2: A: Example voltage traces and spikes from the modeled presynaptic neurons (black and
red) with correlated up and down states. The green line indicates the value of the global up-down
state variable. B: InferenceP
in the model: The posterior probability of being in the up state (left)
and the posterior mean of i ui after observing two spikes (grey) from different neurons with
t = 8 ms latency. C: Supralinear summation in the switching mOU-NP model. D: Supralinear
summation by dendritic spikes in a cortical pyramidal neuron. E: Peak amplitude of the response
(red) and the linear sum (black squares) is shown for different delays in experiments (left) and the
model (right). (D and left panel in E are reproduced from [19]).
3.3

Nonlinear dendritic trees are necessary for purely linear computations

In the previous sections we demonstrated that optimal inference based on correlated spike trains
requires nonlinear interaction within the postsynaptic neuron, and we showed that the dynamics of
the optimal estimator is qualitatively similar to the dynamics of the somatic membrane potential of
a postsynaptic neuron with nonlinear dendritic processing. In this section we will build a simplified
model of dendritic signal processing and compare its performance directly to several alternative
models (see below) on a purely linear task, for which the neuron needs to compute the sum of
P10
presynaptic membrane potentials: f (u) = i=1 ui .

We model the dendritic estimator as a two-layer feed-forward network of simple units (Fig. 3A)
that has been proposed to closely mimic the repertoire of input-output transformations achievable
by active dendritic trees [22]. In this model, synaptic inputs impinge on units in the first layer,
corresponding to dendritic branches, where nonlinear integration of inputs arriving to a dendritic
branch is modeled by a sigmoidal input-output function, and the outputs of dendritic branch units
are in turn summed linearly in the single (somatic) unit of the second layer. We trained the model to
estimate f by changing the connection weights of the two layers corresponding to synaptic weights
(wji ) and branch coupling strengths (?
cj , see Appendix, Fig. 3A).
We compared the performance of the dendritic estimator to four alternative models (Figure 3B):
1. The linear estimator, which is similar to the dendritic estimator except that the dendrites are
linear.
2. The independent estimator, in which the individual synapses are independently optimal estimators of the corresponding presynaptic membrane potentials (Eq. 4) [11, 12], and the cell
combines these estimates linearly. Note that the only difference between the independent estimator and the optimal estimator is the assumption implicit to the former that presynaptic cells
are independent.
3. The scaled independent estimator still combines the synaptic potentials linearly, but the weights
of each synapse are rescaled to partially correct for the wrong assumption of independence.
4. Finally, the optimal estimator is represented by the differential equations 11-12.
The performance of the different
estimators were quantified by the estimation error normalized by
P
h( i ui v
?estimator )2 i
P
the variance of the signal,
. Figure 3C shows the estimation error of the five differvar[ i ui ]
ent models in the case of 10 uniformly correlated presynaptic neurons. If the presynaptic neurons
6

0 .8

?

?

???????????????????????????
0 .4
0 .6

?

??????
???????????
??????????????????

?????????

0 .2

???????

0

0 .5
???????????

0 .9

Figure 3: Performance of 5 different estimators are compared in the task of estimating f (u) =
PN
i=1 ui . A: Model of the dendritic estimator. B: Different estimators (see text for more details).
C: Estimation error, normalised with the variance of the signal. The number of presynaptic neurons
were N = 10. Error bars show standard deviations.
were independent, all three estimators that used dynamical synapses (?
vind , v?sind and v?opt ) were optimal, whereas the linear estimator had substantially larger error. Interestingly, the performance of
the dendritic estimator (yellow) was nearly optimal even if the individual synapses were not optimal estimators for the corresponding presynaptic membrane potentials. In fact, adding depressing
synapses to the dendritic model degraded its performance because the sublinear effect introduced
by the saturation of the sigmoidal dendritic nonlinearity interfered with that implied by synaptic
depression. When the correlation increased between the presynaptic neurons, the performance of
the estimators assuming independence (black and orange) became severely suboptimal, whereas the
dendritic estimator (yellow) remained closer to optimal.
Finally, in order to investigate the synaptic mechanisms underlying the remarkably high performance
of the dendritic estimator, we trained a dendritic estimator on a task where the presynaptic neurons
formed two groups. Neurons from different groups were independent or negatively correlated with
each other, cor(ui , uk ) = { 0.6, 0.3, 0}, while there were positive correlations between neurons from the same group, cor(ui , uj ) = {0.3, 0.6, 0.9} (Fig. 4A). The postsynaptic neuron had
two dendritic branches, each of them receiving input from each presynaptic neurons initially. After
tuning synaptic weights and branch coupling strengths to minimize estimation error, and pruning
synapses with weights below threshold, the model achieved near-optimal performance as before
(Fig. 4C). More importantly, we found that the structure of the presynaptic correlations was reflected in the synaptic connection patterns on the dendritic branches: most neurons developed stable
synaptic weights only on one of the two dendritic branches, and synapses originating from neurons
within the same group tended to cluster on the same branch (Fig. 4B).

4

Discussion

In the present paper we introduced a normative framework to describe single neuron computation
that sheds new light on nonlinear dendritic information processing. Following [12], we observe that
spike-based communication causes information loss in the nervous system, and neurons must infer
the variables relevant for the computation [23?25]. As a consequence of this spiking bottleneck,
signal processing in single neurons can be conceptually divided into two parts: the inference of
the relevant variables and the computation itself. When the presynaptic neurons are independent
then synapses with short term plasticity can optimally solve the inference problem [12] and nonlinear processing in the dendrites is only for computation. However, neurons in a population are
often tend to be correlated [5, 13] and so the postsynaptic neuron should combine spike trains from
such correlated neurons in order to find the optimal estimate of its output. We demonstrated that
the solution of this inference problem requires nonlinear interaction between synaptic inputs in the
7

???????

??????????????????
?????? ????

??????

?

? ??

?

?????????

???????

????????????????

? ??
? ??

???????????????

?
?
?

? ??

? ??

????????????????

? ??

?

Figure 4: Synaptic connectivity reflects the correlation structure of the input. A: The presynaptic
covariance matrix is block-diagonal, with two groups (neurons 1?4 and 5?8). Initially, each presynaptic neuron innervates both dendritic branches, and the weights, w, of the static synapses are then
tuned to minimize estimation error. B: Synaptic weights after training, and pruning the weakest
synapses. Columns corresponds to solutions of the error-minimization task with different presynaptic correlations and/or initial conditions, and rows are different synapses. The detailed connectivity
patterns differ across solutions, but neurons from the same group usually all innervate the same dendritic branch. Below: fraction of neurons in each solution innervating 0, 1 or 2 branches. The height
of the yellow (blue, green) bar indicates the proportion of presynaptic neurons innervating two (one,
zero, respectively) branches of the postsynaptic neuron. C: After training, the nonlinear dendritic
estimator performs close to optimal and much better than the linear neuron.
postsynaptic cell even if the computation itself is purely linear. Of course, actual neurons are usually
faced with both problems: they will need to compute nonlinear functions of correlated inputs and
thus their nonlinearities will serve both estimation and computation. In such cases our approach
allows dissecting the respective contributions of active dendritic processing towards estimation and
computation.
We demonstrated that the optimal estimator of the presynaptic membrane potentials can be closely
approximated by a nonlinear dendritic tree where the connectivity from the presynaptic cells to the
dendritic branches and the nonlinearities in the dendrites are tuned according to the dependency
structure of the input. Our theory predicts that independent neurons will innervate distant dendritic domains, whereas neurons that have correlated membrane potentials will impinge on nearby
dendritic locations, preferentially on the same dendritic branches, where synaptic integration in
nonlinear [19, 26]. More specifically, the theory predicts sublinear integration between positively
correlated neurons and supralinear integration through dendritic spiking between neurons with correlated changes in their activity levels. To directly test this prediction the membrane potentials of
several neurons need to be recorded under naturalistic in vivo conditions [5, 13] and then the subcellular topography of their connectivity with a common postsynaptic target needs to be determined.
Similar approaches have been used recently to characterize the connectivity between neurons with
different receptive field properties in vivo [27, 28].
Our model suggests that the postsynaptic neuron should store information about the dependency
structure of its presynaptic partners within its dendritic membrane. Online learning of this information based on the observed spiking patterns requires new, presumably non-associative forms of plasticity such as branch strength potentiation [29, 30] or activity-dependent structural plasticity [31].
Acknowledgments
We thank J-P Pfister for valuable insights and comments on earlier versions of the manuscript, and
P Dayan, B Gutkin, and Sz K?ali for useful discussions. This work has been supported by the Hungarian Scientific Research Fund (OTKA, grant number: 84471, BU) and the Welcome Trust (ML).
8

References
1. Koch, C. Biophysics of computation (Oxford University Press, 1999).
2. Stuart, G., Spruston, N. & Hausser, M. Dendrites (Oxford University Press, 2007).
3. Poirazi, P. & Mel, B.W. Impact of active dendrites and structural plasticity on the memory capacity of
neural tissue. Neuron 29, 779?96 (2001).
4. Poirazi, P., Brannon, T. & Mel, B.W. Arithmetic of subthreshold synaptic summation in a model CA1
pyramidal cell. Neuron 37, 977?87 (2003).
5. Crochet, S., Poulet, J.F., Kremer, Y. & Petersen, C.C. Synaptic mechanisms underlying sparse coding of
active touch. Neuron 69, 1160?75 (2011).
6. Maass, W. & Bishop, C. Pulsed Neural Networks (MIT Press, 1998).
7. Gerstner, W. & Kistler, W. Spiking Neuron Models (Cambridge University Press, 2002).
8. Rieke, F., Warland, D., de Ruyter van Steveninck, R. & Bialek, W. Spikes (MIT Press, 1996).
9. Deneve, S. Bayesian spiking neurons I: inference. Neural Comput. 20, 91?117 (2008).
10. Dayan, P. & Abbot, L.F. Theoretical neuroscience (The MIT press, 2001).
11. Pfister, J., Dayan, P. & Lengyel, M. Know thy neighbour: a normative theory of synaptic depression. Adv.
Neural Inf. Proc. Sys. 22, 1464?1472 (2009).
12. Pfister, J., Dayan, P. & Lengyel, M. Synapses with short-term plasticity are optimal estimators of presynaptic membrane potentials. Nat. Neurosci. 13, 1271?1275 (2010).
13. Poulet, J.F. & Petersen, C.C. Internal brain state regulates membrane potential synchrony in barrel cortex
of behaving mice. Nature 454, 881?5 (2008).
14. Doucet, A., De Freitas, N. & Gordon, N. Sequential Monte Carlo Methods in Practice (Springer, New
York, 2001).
15. Rall, W. Branching dendritic trees and motoneuron membrane resistivity. Exp. Neurol. 1, 491?527 (1959).
16. Hoffman, D.A., Magee, J.C., Colbert, C.M. & Johnston, D. K+ channel regulation of signal propagation
in dendrites of hippocampal pyramidal neurons. Nature 387, 869?75 (1997).
17. Cash, S. & Yuste, R. Linear summation of excitatory inputs by CA1 pyramidal neurons. Neuron 22,
383?94 (1999).
18. Gasparini, S., Migliore, M. & Magee, J.C. On the initiation and propagation of dendritic spikes in CA1
pyramidal neurons. J. Neurosci. 24, 11046?56 (2004).
19. Polsky, A., Mel, B.W. & Schiller, J. Computational subunits in thin dendrites of pyramidal cells. Nat.
Neurosci. 7, 621?7 (2004).
20. Margulis, M. & Tang, C.M. Temporal integration can readily switch between sublinear and supralinear
summation. J. Neurophysiol. 79, 2809?13 (1998).
21. Hausser, M., Spruston, N. & Stuart, G.J. Diversity and dynamics of dendritic signaling. Science 290,
739?44 (2000).
22. Poirazi, P., Brannon, T. & Mel, B.W. Pyramidal neuron as two-layer neural network. Neuron 37, 989?99
(2003).
23. Huys, Q.J., Zemel, R.S., Natarajan, R. & Dayan, P. Fast population coding. Neural Comput. 19, 404?41
(2007).
24. Natarajan, R., Huys, Q.J.M., Dayan, P. & Zemel, R.S. Encoding and decoding spikes for dynamics stimuli.
Neural Computation 20, 2325?2360 (2008).
25. Gerwinn, S., Macke, J. & Bethge, M. Bayesian population decoding with spiking neurons. Frontiers in
Computational Neuroscience 3 (2009).
26. Losonczy, A. & Magee, J.C. Integrative properties of radial oblique dendrites in hippocampal CA1 pyramidal neurons. Neuron 50, 291?307 (2006).
27. Bock, D.D. et al. Network anatomy and in vivo physiology of visual cortical neurons. Nature 471, 177?82
(2011).
28. Ko, H. et al. Functional specificity of local synaptic connections in neocortical networks. Nature (2011).
29. Losonczy, A., Makara, J.K. & Magee, J.C. Compartmentalized dendritic plasticity and input feature storage
in neurons. Nature 452, 436?41 (2008).
30. Makara, J.K., Losonczy, A., Wen, Q. & Magee, J.C. Experience-dependent compartmentalized dendritic
plasticity in rat hippocampal CA1 pyramidal neurons. Nat. Neurosci. 12, 1485?7 (2009).
31. Butz, M., Worgotter, F. & van Ooyen, A. Activity-dependent structural plasticity. Brain Res. Rev. 60,
287?305 (2009).

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 972-a-model-of-the-hippocampus-combining-self-organization-and-associative-memory-function.pdf

A model of the hippocampus combining selforganization and associative memory function.
Michael E. Hasselmo, Eric Schnell
Joshua Berke and Edi Barkai

Dept. of Psychology, Harvard University
33 Kirkland St., Cambridge, MA 02138
hasselmo@katla.harvard.edu

Abstract
A model of the hippocampus is presented which forms rapid self-organized representations of input arriving via the perforant path, performs
recall of previous associations in region CA3, and performs comparison
of this recall with afferent input in region CA 1. This comparison drives
feedback regulation of cholinergic modulation to set appropriate
dynamics for learning of new representations in region CA3 and CA 1.
The network responds to novel patterns with increased cholinergic modulation, allowing storage of new self-organized representations, but
responds to familiar patterns with a decrease in acetylcholine, allowing
recall based on previous representations. This requires selectivity of the
cholinergic suppression of synaptic transmission in stratum radiatum of
regions CA3 and CAl, which has been demonstrated experimentally.

1

INTRODUCTION

A number of models of hippocampal function have been developed (Burgess et aI., 1994;
Myers and Gluck, 1994; Touretzky et al., 1994), but remarkably few simulations have
addressed hippocampal function within the constraints provided by physiological and anatomical data. Theories of the function of specific subregions of the hippocampal formation often do not address physiological mechanisms for changing dynamics between
learning of novel stimuli and recall of familiar stimuli. For example, the afferent input to
the hippocampus has been proposed to form orthogonal representations of entorhinal
activity (Marr, 1971; McNaughton and Morris, 1987; Eichenbaum and Buckingham,
1990), but simulations have not addressed the problem of when these representations

78

Michael E. Hasselmo. Eric Schnell. Joshua Berke. Edi Barkai

should remain stable, and when they should be altered. In addition, models of autoassociative memory function in region CA3 (Marr, 1971; McNaughton and Morris, 1987;
Levy, 1989; Eichenbaum and Buckingham, 1990) and heteroassociative memory function
at the Schaffer collaterals projecting from region CA3 to CAl (Levy, 1989; McNaughton,
1991) require very different activation dynamics during learning versus recall.
Acetylcholine may set appropriate dynamics for storing new information in the cortex
(Hasselmo et aI., 1992, 1993; Hasselmo, 1993, 1994; Hasselmo and Bower, 1993). Acetylcholine has been shown to selectively suppress synaptic transmission at intrinsic but
not afferent fiber synapses (Hasselmo and Bower, 1992), to suppress the neuronal adaptation of cortical pyramidal cells (Hasselmo et aI., 1994; Barkai and Hasselmo, 1994), and
to enhance long-term potentiation of synaptic potentials (Hasselmo, 1994b). Models
show that suppression of synaptic transmission during learning prevents recall of previously stored information from interfering with the storage of new information (Hasselmo
et al., 1992, 1993; Hasselmo, 1993, 1994a), while cholinergic enhancement of synaptic
modification enhances the rate of learning (Hasselmo, 1994b).
Feedback regulation of cholinergic modulation may set the appropriate level of cholinergic modulation dependent upon the novelty or familiarity of a particular input pattern.
We have explored possible mechanisms for the feedback regulation of cholinergic modulation in simulations of region CAl (Hasselmo and Schnell, 1994) and region CA3. Here
we show that self-regulated learning and recall of self-organized representations can be
obtained in a network simulation of the hippocampal formation. This model utilizes selective cholinergic suppression of synaptic transmission in stratum radiatum of region CA3,
which has been demonstrated in brain slice preparations of the hippocampus.

2

METHODS

2.1. SIMPLIFIED REPRESENTA nON OF HIPPOCAMPAL NEURONS.

In place of the sigmoid input-output functions used in many models, this model uses a
simple representation in which the output of a neuron is not explicitly constrained, but the
total network activity is regulated by feedback from inhibitory interneurons and adaptation due to intracellular calcium concentration. Separate variables represent pyramidal
cell membrane potential a, intracellular calcium concentration c, and the membrane potential of inhibitory interneurons h:

l1a i = Ai -l1 ai - J..l.C +

L Wijg(aj - e) - Hikg(h k - e h)
j

I1c?I = 'Vg(a
.i?
I
I1hk

e )- Qc
C

= IWkjg(aj-eo)-l1hk- IHk/g(h/-e)
j

where A = afferent input, "

/

=passive decay of membrane potential, Il =strength of cal-

A Model of Hippocampus

79

cium-dependent potassium current (proportional to intracellular calcium), Wij = excitatory
recurrent synapses (longitudinal association path tenninating in stratum radiatum), gO is a
threshold linear function proportional to the amount by which membrane potential
exceeds an output threshold 00 or threshold for calcium current Oc' 'Y = strength of voltagedependent calcium current, n = diffusion constant of calcium, Wki = excitatory synapses
inhibitory interneurons, Hilc = inhibitory synapses from interneurons to pyramidal cells,
Hk}= inhibitory synapses between interneurons. This representation gives neurons adaptation characteristics similar to those observed with intracellular recording (Barkai and Hasselmo, 1994), including a prominent afterhyperpolarization potential (see Figure 1).

An

B

.... ..
~

....J

'N~JJL

C

lO

\..--14

Figure 1. Comparison of pyramidal cell model with experimental data.
In Figure I, A shows the membrane potential of a modeled pyramidal cell in response to
simulated current injection. Output of this model is a continuous variable proportional to
how much membrane potential exceeds threshold. This is analogous to the reciprocal of
interspike interval in real neuronal recordings. Note that the model displays adaptation
during current injection and afterhyperpolarization afterwards, due to the calcium-dependent potassium current. B shows the intracellularly recorded membrane potential in a pirifonn cortex pyramidal cell, demonstrating adaptation of firing frequency due to
activation of calcium-dependent potassium current. The firing rate falls off in a manner
similar to the smooth decrease in firing rate in the simplified representation. C shows an
intracellular recording illustrating long-tenn afterhyperpolarization caused by calcium
influx induced by spiking of the neuron during current injection.
2.2. NETWORK CONNECTIVITY

A schematic representation of the network simulation of the hippocampal fonnation is
shown in Figure 2. The anatomy of the hippocampal fonnation is summarized on the left
in A, and the function of these different subregions in the model is shown on the right in
B. Each of the subregions in the model contained a population of excitatory neurons with
a single inhibitory interneuron mediating feedback inhibition and keeping excitatory
activity bounded. Thus, the local activation dynamics in each region follow the equations
presented above. The connectivity of the network is further summarized in Figure 3 in the
Results section. A learning rule of the Hebbian type was utilized at all synaptic connections, with the exception of the mossy fibers from the dentate gyrus to region CA3, and the
connections to and from the medial septum. Self-organization of perforant path synapses
was obtained through decay of synapses with only pre or post-synaptic activity, and
growth of synapses with combined activity. Associative memory function at synapses

80

Michael E. Hasse/mo, Eric Schnell, Joshua Berke, Edi Barkai

arising from region CA3 was obtained through synaptic modification during cholinergic
suppression of synaptic transmission.

B

Entorhinal cortex

""""""""""

??

?
???

: Self-organized
: representation
: r-----..L.\

?

~

Comparison

.L-______~~.-----~~~--~~

Feedback regulation of
cholinergic modulation

Regulation of
learning dynamics

Figure 2. Schematic representation of hippocampal circuitry
and the corresponding function of connections in the model.

2.3. CHOLINERGIC MODULAnON
The total output from region CAl determined the level of cholinergic modulation within
both region CA3 and CAl, with increased output causing decreased modulation. This is
consistent with experimental evidence suggesting that activity in region CAl and region
CA3 can inhibit activity in the medial septum, and thereby downregulate cholinergic modulation. This effect was obtained in the model by excitatory connections from region CAl
to an inhibitory interneuron in the medial septum, which suppressed the activity of a cholinergic neuron providing modulation to the full network. When levels of cholinergic
modulation were high, there was strong suppression of synaptic transmission at the excitatory recurrent synapses in CA3 and the Schaffer collaterals projecting from region CA3 to
CAL This prevented the spread of activity due to previous learning from interfering with
self-organization. When levels of cholinergic modulation were decreased, the strength of
synaptic transmission was increased, allowing associative recall to dominate. Cholinergic
modulation also increased the rate of synaptic modification and depolarized neurons.

2.4. TESTS OF SELF-REGULATED LEARNING AND RECALL
Simulations of the full hippocampal network evaluated the response to the sequential presentation of a series of highly overlapping activity patterns in the entorhinal cortex. Recall
was tested with interspersed presentation of degraded versions of previously presented
activity patterns. For effective recall, the pattern of activity in entorhinal cortex layer IV
evoked by degraded patterns matched the pattern evoked by the full learned version of
these patterns. The function of the full network is illustrated in Figure 3. In simulations

A Model of Hippocampus

81

focused on region CA3, activity patterns were induced sequentially in region CA3, representing afferent input from the entorhinal cortex. Different levels of external activation of
the cholinergic neuron resulted in different levels of learning of new overlapping patterns.
These results are illustrated in Figure 4.

2.5. BRAIN SLICE EXPERIMENTS
The effects in the simulations of region CA3 depended upon the cholinergic suppression
of synaptic transmission in stratum radiatum of this region The cholinergic suppression of
glutamatergic synaptic transmission in region CA3 was tested in brain slice preparations
by analysis of the influence of the cholinergic agonist carbachol on the size of field potentials elicited by stimulation of stratum radiatum. These experiments used techniques similar to previously published work in region CAl (Hasselmo and Schnell, 1994).

3 RESULTS
In the full hippocampal simulation, input of an unfamiliar pattern to entorhinal cortex
layer II resulted in high levels of acetylcholine. This allowed rapid self-organization of
the perforant path input to the dentate gyrus and region CAl. Cholinergic suppression of
synaptic transmission in region CAl prevented recall from interfering with self-organization. Instead, recurrent collaterals in region CA3 stored an autoassociative representation
of the input from the dentate gyrus to region CA3, and connections from CA3 to CA 1
stored associations between the pattern of activity in CA3 and the associated self-organized representation in region CAl.
identity
" self-org "matrix ~
,auto-"
,,~>
M assoc
u .....
?
?
'at)
u
u
c >.
--I.~ ?
c
?
c
?
:.a.?:i
Self-org ~
iden~ity
.9
hetero.9 hetero8
matrix
~
assoc
~ assoc
C!

~

~

?

~

111111 I "T I' , If
,r
2 I I I II
n
I I
ld II
r I" I 'I"'"'I II , , ,
Q)2dl' r II' I I ' l l I
~ 311111 I' I I I n
"

j

4

3d
4d
ld

2d

n,n

II
II
II

'f
I I II I n
I
II I
I
,
,
II
,
I
1I
'I

I

'I

.. ,
II f'l't?
U i
I I Itt

~

I.Ll

r"

U
I

"
H
,
I
I
U
I I 1 II r

~'

,,

1

,

'(
( U.

"

I I

I

1'1 I I
I I I n
I"'" , 'I II I II

1 I ' ,I

I

l 11 I J1
't III I'

?"

'I . .

I

I

, I I II
I II ? .1
l " I II
I III I I

W.

Jl 1

lU

Neuron #
Figure 3. Activity in each subregion of the full network simulation of the hippocampal
formation during presentation of a sequence of activity patterns in entorhinal cortex.

82

Michael E. Hasselmo, Eric Schnell, Joshua Berke, Edi Barkai

In Figure 3. width of the lines represents the activity of each neuron at a particular time
step. As seen here. the network forms a self-organized representation of each new pattern
consisting of active neurons in the dentate gyrus and region CAL At the same time. an
association is formed between the self-organized representation in region CAl and the
same afferent input pattern presented to entorhinal cortex layer IV. Four overlapping patterns (1-4) are presented sequentially. each of which results in learning of a separate selforganized representation in the dentate gyrus and region CAl. with an association formed
between this representation and the full input pattern in entorhinal cortex.
The recall characteristics of the network are apparent when degraded versions of the afferent input patterns are presented in the sequence (ld-4d). This degraded afferent input
weakly activates the same representations previously formed in the dentate gyrus. Recurrent excitation in region CA3 enhances this activity. giving robust recall of the full version
of this pattern. This activity then reaches CA 1. where it causes strong activation if it
matches the pattern of afferent input from the entorhinal cortex. Strong activation in
region CAl decreases cholinergic modulation. preventing formation of a new representation and allowing recall to dominate. Strong activation of the representation stored in
region CAl then activates the full representation of the pattern in entorhinal cortex layer
IV. Thus. the network can accurately recall each of many highly overlapping patterns.
The effect of cholinergic modulation on the level of learning or recall can be seen more
clearly in a simulation of auto-associative memory function in region CA3 as shown in
Figure 4. Each box shows the response of the network to sequential presentation of full
and degraded versions of two highly overlapping input patterns. The width of the black
traces represents the activity of each of 10 CA3 pyramidal cells during each simulation
step. In the top row. level of cholinergic modulation (ACh) is plotted. In A. external activation of the cholinergic neuron is absent. so there is no cholinergic suppression of synaptic transmission. In this case. the first pattern is learned and recalled properly. but
subsequent presentation of a second overlapping pattern results only in recall of the previously learned pattern. In B. with greater cholinergic suppression. recall is suppressed sufficiently to allow learning of a combination of the two input patterns. Finally. in C. strong
cholinergic suppression prevents recall. allowing learning of the new overlapping pattern
to dominate over the previously stored pattern.

A

Stored
patterns

???

??
??

?
?

-.gN.g
N

-

ACh
Inhib
Q\

.- .--.

ACh input = 0.0

..... ......

,11",,11.

.....

B

ACh input

=0.15

C

__
ACh input

=0.3

...11'_..,.......,.. ......

111 ... 111...... 11 . . . ."'... 11 ? ?111 ??,

'

I ? ? " '? ? _ _

'111"

.';::
~

~

?'. _"11.. ? .'.? .
.,~

. ",.

.u. . . . .... ,

0

. . . . . . . . . . 111. . . .... .

N

Figure 4. Increased cholinergic suppression of synaptic transmission in region CA3
causes greater learning of new aspects of afferent input patterns.

A Model of Hippocampus

83

Extracellular recording in brain slice preparations of hippocampal region CA3 have demonstrated that perfusion of the cholinergic agonist carbachol strongly suppresses synaptic
potentials recorded in stratum radiatum, as shown in Figure 5. In contrast, suppression of
synaptic transmission at the afferent fiber synapses arising from entorhinal cortex is much
weaker. At a concentration of 20J..tM, carbachol suppressed synaptic potentials in stratum
radiatum on average by 54.4% (n=5). Synaptic potentials elicited in stratum lacunosum
were more weakly suppressed, with an average suppression of28%.

Control

Carbachol
(20JlM)

Wash

Figure 5. Cholinergic suppression of synaptic transmission in stratum radiatum of CA3.

4

DISCUSSION

In this model of the hippocampus, self-organization at perforant path synapses forms compressed representations of specific patterns of cortical activity associated with events in
the environment. Feedback regulation of cholinergic modulation sets appropriate dynamics for learning in response to novel stimuli, allowing predominance of self-organization,
and appropriate dynamics for recall in response to familiar stimuli, allowing predominance of associative memory function. This combination of self-organization and associative memory function may also occur in neocortical structures. The selective cholinergic
suppression of feedback and intrinsic synapses has been proposed to allow self-organization of feedforward synapses while feedback synapses mediate storage of associations
between higher level representations and activity in primary cortical areas (Hasselmo,
1994b). This previous proposal could provide a physiological justification for a similar
mechanism utilized in recent models (Dayan et al., 1995). Detailed modeling of cholinergic effects in the hippocampus provides a theoretical framework for linking the considerable behavioral evidence for a role of acetylcholine in memory function (Hagan and
Morris, 1989) to the neurophysiological evidence for the effects of acetylcholine within
cortical structures (Hasselmo and Bower, 1992; 1993; Hasselmo, 1994a, 1994b).

Acknowledgements
This work supported by a pilot grant from the Massachusetts Alzheimer's Disease
Research Center and by an NIMH FIRST award MH52732-01.

References
Barkai E, Hasselmo ME (1994) Modulation of the input/output function of rat piriform
cortex pyramidal cells. J. Neurophysiol. 72: 644-658.

84

Michael E. Hasselmo, Eric Schnell, Joshua Berke, Edi Barkai

Barkai E, Bergman RE, Horwitz G, Hasselmo ME (1994) Modulation of associative memory function in a biophysical simulation of rat pirifonn cortex. J. Neurophysiol. 72:659677.
Burgess N, Reece M, O'Keefe J (1994) A model of hippocampal function. Neural Networks 7: 1065-1081.
Dayan P, Hinton GE, Neal RM and Zemel RS (1995) The Helmholtz machine. Neural
computation in press.
Eichenbaum, H. and Buckingham, J. (1990) Studies on hippocampal processing: experiment, theory and model. In: Learning and computational neuroscience: foundations of
adaptive networks, M. Gabriel and J. Moore, eds., Cambridge, MA: MIT Press.
Hagan, JJ and Morris, RGM (1989) The cholinergic hypothesis of memory: A review of
animal experiments. In Psychopharmacology of the Aging Nervous System, L.L. Iversen,
S.D. Iversen and S.H. Snyder, eds. New York: Plenum Press, p. 237-324.
Hasselmo, M.E. (1993) Acetylcholine and learning in a cortical associative memory. Neural Compo 5: 22-34.
Hasselmo ME (1994a) Runaway synaptic modification in models of cortex: Implications
for Alzheimer's disease. Neural Networks 7: 13-40.
Hasselmo ME (1994b) Neuromodulation and cortical function. Behav. Brain Res. in press
Hasselmo ME, Anderson, BP and Bower, JM (1992) Cholinergic modulation of cortical
associative memory function. J. Neurophysiol. 67(5): 1230-1246.
Hasselmo ME, Bower JM (1992) Cholinergic suppression specific to intrinsic not afferent
fiber synapses in rat pirifonn (olfactory) cortex. J. Neurophysiol. 67(5): 1222-1229.
Hasselmo ME, Bower JM (1993) Acetylcholine and memory. Trends Neurosci 16:218222.
Hasselmo ME, Barkai E, Horwitz G, Bergman RE (1993) Modulation of neuronal adaptation and cortical associative memory function. In: Computation and Neural Systems II
(Eeckman F, Bower JM, ed). Norwell, MA: Kluwer Academic Publishers.
Hasselmo ME, Schnell E (1994) Laminar selectivity of the cholinergic suppression of synaptic transmission in rat hippocampal region CAl: Computational modeling and brain
slice physiology. J. Neurosci. 14: 3898-3914.
Levy WB (1989) A computational approach to hippocampal function. In: Computational
models of learning in simple neural systems (Hawkins RD, Bower GH, ed), pp. 243-305.
Orlando, FL: Academic Press.
Myers CE and Gluck M (1994) Context, conditioning and hippocampal rerepresentation
in animal learning. Behav. Neurosci. 108: 835-847.
Marr 0 (1971) Simple memory: A theory for archicortex. Phil. Trans. Roy. Soc. B
B262:23-81
McNaughton BL (1991) Associative pattern completion in hippocampal circuits: New
evidence and new questions. Brain Res. Rev. 16:193-220.
McNaughton BL, Morris RGM (1987) Hippocampal synaptic enhancement and infonnation storage within a distributed memory system. Trends Neurosci. 10:408-415.
Touretzky OS, Wan HS and Redish AD (1994) Neural representation of space in rats and
robots. In Zurada JM and Marks RJ (eds) Computational Intelligence: Imitating life.
IEEE Press.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 3102-uncertainty-phase-and-oscillatory-hippocampal-recall.pdf

Uncertainty, phase and oscillatory hippocampal recall

M?at?e Lengyel and Peter Dayan
Gatsby Computational Neuroscience Unit
University College London
17 Queen Square, London WC1N 3AR, United Kingdom
{lmate,dayan}@gatsby.ucl.ac.uk

Abstract
Many neural areas, notably, the hippocampus, show structured, dynamical, population behavior such as coordinated oscillations. It has long been observed that
such oscillations provide a substrate for representing analog information in the
firing phases of neurons relative to the underlying population rhythm. However,
it has become increasingly clear that it is essential for neural populations to represent uncertainty about the information they capture, and the substantial recent
work on neural codes for uncertainty has omitted any analysis of oscillatory systems. Here, we observe that, since neurons in an oscillatory network need not only
fire once in each cycle (or even at all), uncertainty about the analog quantities each
neuron represents by its firing phase might naturally be reported through the degree of concentration of the spikes that it fires. We apply this theory to memory
in a model of oscillatory associative recall in hippocampal area CA3. Although
it is not well treated in the literature, representing and manipulating uncertainty
is fundamental to competent memory; our theory enables us to view CA3 as an
effective uncertainty-aware, retrieval system.

1

Introduction

In a network such as hippocampal area CA3 that shows prominent oscillations during memory retrieval and other functions [1], there are apparently three, somewhat separate, ways in which neurons
might represent information within a single cycle: they must choose how many spikes to fire; what
the mean phase of those spikes is; and how concentrated those spikes are about that mean. Most
groups working on the theory of spiking oscillatory networks have considered only the second of
these ? this is true, for instance, of Hopfield?s work on olfactory representations [2] and Yoshioka?s
[3] and Lengyel & Dayan?s work [4] on analog associative memories in CA3. Since neurons do really fire more or less than one spike per cycle, and furthermore in a way that can be informationally
rich [5, 6], this poses a key question as to what the other dimensions convey.
The number of spikes per cycle is an obvious analog of a conventional firing rate. Recent sophisticated models of firing rates of single neurons and neural populations treat them as representing
uncertainty about the quantities coded, partly driven by the strong psychophysical and computational evidence that uncertainty plays a key role in many aspects of neural processing [7, 8, 9].
Single neurons can convey the certainty of a binary proposition by firing more or less strongly
[10, 11]; a whole population can use firing rates to convey uncertainty about a collectively-coded
analog quantity [12].
However, if neurons can fire multiple spikes per cycle, then the degree to which the spikes are
concentrated around a mean phase is an additional channel for representing information. Concentration is not merely an abstract quantity; rather we can expect that the effect of the neuron on its
postsynaptic partners will be strongly influenced by the burstiness of the spikes, an effect apparent,
for instance, in the complex time-courses of short term synaptic dynamics. Here, we suggest that

concentration codes for the uncertainty about phase ? highly concentrated spiking represents high
certainty about the mean phase in the cycle.
One might wonder whether uncertainty is actually important for the cases of oscillatory processing
that have been identified. One key computation for spiking oscillatory networks is memory retrieval
[3, 4]. Although it is not often viewed this way, memory retrieval is a genuinely probabilistic task
[13, 14], with the complete answer to a retrieval query not being a single memory pattern, but rather
a distribution over memory patterns. This is because at the time of the query the memory device
only has access to incomplete information regarding the memory trace that needs to be recalled.
Most importantly, the way memory traces are stored in the synaptic weight matrix implies a data
lossy compression algorithm, and therefore the original patterns cannot be decompressed at retrieval
with absolute certainty.
In this paper, we first describe how oscillatory structures can use all three activity characteristics
at their disposal to represent two pieces of information and two forms of uncertainty (Section 2).
We then suggest that this representational scheme is appropriate as a model of uncertainty-aware
probabilistic recall in CA3. We derive the recurrent neural network dynamics that manipulate these
firing characteristics such that by the end of the retrieval process neurons represent a good approximation of the posterior distribution over memory patterns given the information in the recall cue
and in the synaptic weights between neurons (Section 3). We show in numerical simulations that the
derived dynamics lead to competent memory retrieval, supplemented by uncertainty signals that are
predictive of retrieval errors (Section 4).

2

Representation

Single cell The heart of our proposal is a suggestion for how to interpret the activity of a single
neuron in a single oscillatory cycle (such as a theta-cycle in the hippocampus) as representing a
probability distribution. This is a significant extension of standard work on single-neuron representations of probability [12]. We consider a distribution over two random variables, z ? {0, 1}, a
Bernoulli variable (for the case of memory, representing the participation of the neuron in the memory pattern), and x ? [0, T ), where T is the period of the underlying oscillation, a real valued phase
variable (representing an analog quantity associated with that neuron if it participates in that pattern).
This distribution is based on three quantities associated with the neuron?s activity (figure 1A):
r the number of spikes in a cycle,
? the circular mean phase of those spikes, under the assumption that there is at least one spike,
c the concentration of the spikes (mean resultant length of their phases, [15]), which measures how
tightly clustered they are about ?
In keeping with conventional single-neuron models, we treat r, via a (monotonically increasing)
probabilistic activation function 0 ? ?(r) ? 1, as describing the probability that z = 1 (figure 1B),
z
1?z
so the distribution is q (z; r) = ? (r) (1 ? ? (r)) . We treat the implied distribution over the true
phase x as being conditional on z. If z = 0, then the phase is undefined. However, if z = 1, then the
distribution over x is a mixture of qu (x), a uniform distribution on [0, T ), and a narrow, quasi-delta,
distribution q? (x; ?) (of width   T ) around the mean firing phase (?) of the spikes. The mixing
proportion in this case is determined by a (monotonically increasing) function 0 ? ?(c) ? 1 of the
concentration of the spikes. In total:
z

1?z

q (x, z; ?, c, r) = [? (r) [? (c) q? (x; ?) + (1 ? ? (c)) qu (x)]] (1 ? ? (r))

(1)

as shown in figure 1C. The marginal confidence in ? being correct is thus ? (c, r) = ? (c) ? ? (r),
which we call ?burst strength?. We can rewrite equation 1 in a more convenient form:
z

1?z

q (x, z; ?, c, r) = [? (c, r) q? (x; ?) + (? (r) ? ? (c, r)) qu (x)] (1 ? ? (r))

(2)

Population In the case of a population of neurons, the complexity of representing a full joint distribution P[x, z] over random variables x = {xi }, z = {zi } associated with each neuron i grows
exponentially with the number of neurons N . The natural alternative is to consider an approximation in which neurons make independent contributions, with marginals as in equation 2. The joint

A

B
c

C

q(z ; r)

q(x | z=1; ?, c)
?(r)

r=2

?
?(c)

z

0 1

?

0

? T

x

Figure 1: Representing uncertainty. A) A neuron?s firing times during a period [0, T ) are described
by three parameters: r, the number of spikes; ? the mean phase of those spikes; and c, the phase
concentration. B) The firing rate r determines the probability ?(r) that a Bernoulli variable associated with the unit takes the value z = 1. C) If z = 1, then ? and c jointly define a distribution over
phase which is a mixture (weighted by ?(c)) of a distribution peaked at ? and a uniform distribution.
distribution is then
Q (x, z; ?, c, r) =

Q

i

q (xi , zi ; ?i , ci , ri )

(3)

whose complexity scales linearly with N .
Dynamics When the actual distribution P the population has to represent lies outside the class of
representable distributions Q in equation 3 with independent marginals, a key computational step is
to find activity parameters ?, c, r for the neurons that make Q as close to P as possible. One way to
formalize the discrepancy between the two distributions is the KL-divergence
F (?, c, r) = KL [Q (x, z; ?, c, r) k P (x, z)]

(4)

Minimizing this by gradient descent
?

d?i
?
=?
F (?, c, r)
dt
??i

?

?
dci
=?
F (?, c, r)
dt
?ci

?

?
dri
=?
F (?, c, r)
dt
?ri

(5)

defines dynamics for the evolution of the parameters. In general, this couples the activities of neurons, defining recurrent interactions within the network.1
We have thus suggested a general representational framework, in which the specification of a computational task amounts to defining a P distribution which the network should represent as best as
possible. Equation 5 then defines the dynamics of the interaction between the neurons that optimizes
the network?s approximation.

3

CA3 memory

One of the most widely considered tasks that recurrent neural networks need to solve is that of
autoassociative memory storage and retrieval. Moreover, hippocampal area CA3, which is thought
to play a key role in memory processing, exhibits oscillatory dynamics in which firing phases are
known to play an important functional role. It is therefore an ideal testbed for our theory.
We characterize the activity in CA3 neurons during recall as representing the probability distribution
over memories being recalled. Treating storage from a statistical perspective, we use Bayes rule to
define a posterior distribution over the memory pattern implied by a noisy and impartial cue. This
distribution is represented approximately by the activities ?i , ri , ci of the neurons in the network as
in equation 3. Recurrent dynamics among the neurons as in equation 5 find appropriate values of
these parameters, and model network interactions during recall in CA3.
Storage We consider CA3 as storing patterns in which some neurons are quiet (zim = 0, for the
ith neuron in the mth pattern); and other neurons are active (zim = 1); their activity then defining
1
Of course, the firing rate is really an integer variable, since it is an actual number of spikes per cycle. For
simplicitly, in the simulations below, we considered real-valued firing rates ? an important next step is to drop
this assumption.

a firing phase (xim ? [0, T ), where T is the period of the population oscillation. M such memory
traces, each drawn from an (iid) prior distribution,
Q
1?z
z
(6)
P [x, z] = i [pz P (xi )] i (1 ? pz ) i ,
(where pz is the prior probability of firing in a memory pattern; P (x) is the prior distribution for
firing phases) are stored locally and additively in the recurrent synaptic weight matrix of a network
of N neurons, W, according to learning rule ?:

PM
m
for i 6= j, and Wii = 0
(7)
Wij = m=1 zim zjm ? xm
i , xj
We assume that ? is T?oplitz and periodic in T , and either symmetric or anti-symmetric:
? (x1 , x2 ) = ? (x1 ? x2 ) = ? (x1 ? x2 mod T ) = ?? (x2 ? x1 ).
Posterior for memory recall Following [14, 4], we characterize retrieval in terms of the posterior
distribution over x, z given three sources of information: a recall cue (?
x, ?
z), the synaptic weight matrix, and the prior over the memories. Under some basic independence assumptions, this factorizes
into three terms
P [x, z | x
?, ?
z, W] ? P [x, z] ? P [?
x, ?
z | x, z] ? P [W | x, z]
(8)
The first term is the prior (equation 6). The second term is the likelihood of receiving noisy or partial
recall cue (?
x, ?
z) if the true pattern to be recalled was (x, z):
zi 
1?zi
z?i
z?i
Y 
1??
z
? 0 (?
? 1 (?
(1 ? ?0 ) P
xi )
?01??zi
?1 P
xi | xi )
(1 ? ?1 ) i
(9)
P [?
x, ?
z | x, z] =
i

where ?1 = P [?
z = 1 | z = 1] and ?0 = P [?
z = 0 | z = 0] are the probabilities of the presence or
absence of a spike in the input given the presence or absence of a spike in the memory to be recalled,
? 1 (?
? 0 (?
P
x | x) and P
x) are distributions of the phase of an input spike if there was or was not a spike
in the memory to be recalled.
The last term in equation 8 is the likelihood that weight matrixW arose from M patterns includ
Q
1/2
.
P
[W
|
x
,
z
,
x
,
z
]
ing (x, z). Making a factorized approximation P [W | x, z] '
ij
i
i
j
j
i,j6=i
Since the learning rule is additive and memory traces are drawn iid, the likelihood of a synaptic
weight is approximately Gaussian for large M , with a quadratic log-likelihood [4]:


1 2
+c zi zj
log P [Wij | xi , zi , xj , zj ] = 2 (Wij ? ?W ) ? (xi , xj ) ? ? (xi , xj )
(10)
?W
2
2
are the mean and variance of the distribution of synaptic weights after storing
where ?W and ?W
M ? 1 random memory traces (?W = 0 for antisymmetric ?).

Dynamics for memory recall Plugging the posterior from equation 8 to the general dynamics
equation 5 yields the neuronal update rules that will be appropriate for uncertainty-aware memory
recall, and which we treat as a model of recurrent dynamics in CA3.
We give the exact formul? for the dynamics in the supplementary material. They can be shown
to couple together the various activity parameters of the neurons in appropriate ways, for instance
weighting changes to ?i for neuron i according to the burst strength of its presynaptic inputs, and
increasing the concentration when the log posterior of the firing phase of the neuron, given that it
?, z
?, W], is greater than the average of the log posterior.
should fire, log P[?i |zi = 1, x
These dynamics generalize, and thus inherit, some of the characteristics of the purely phase-based
network suggested in [4]. This means that they also inherit the match with physiologically-measured
phase response curves (PRCs) from in vitro CA3 neurons that were measured to test this suggestion
[16]. The key difference here is that we expect the magnitude (though not the shape) of the influence
of a presynaptic neuron on the phase of a postsynaptic one to scale with its rate, for high concentration. Preliminary in vitro results show that PRCs recorded in response to burst stimulation are not
qualitatively different from PRCs induced by single spikes; however, it remains to be seen if their
magnitude scales in the way implied by the dynamics here.

z=1

0
!2
0

1

2

3

4

5

0.5
0

0

1

2

0

1

2

3
Time

3

4

1
0.5
0

5

0

1

2

z=0

4

5

0.5
0

0

1

2

3
Time

3

4

5

3

4

5

z=0

1

Firing rate

Concentration

Phase

z=0
5

0

z=1

1

Firing rate

Concentration

Phase error

z=1
2

4

5

1
0.5
0

0

1

2
Time

Figure 2: A single retrieval trial in the network. Time evolution of firing phases (left panels),
concentrations (middle panels), and rates (right panels) of neurons that should (top row) or should
not (bottom row) participate in the memory pattern being retrieved. Note that firing phases in the top
row are plotted as a difference from the stored firing phases so that ? = 0 means perfect retrieval.
Color code shows precision (blue: low, yellow: high) of the phase of the input to neurons, with red
lines showing cells receving incorrect input rate.

4

Simulations

Figure 2 shows the course of recall in the full network (with N = 100 neurons, and 10 stored patterns
with pz = 0.5). For didactic convenience, we consider the case that the noise in the phase input
was varied systematically for different neurons within a recall cue (a fact known to the network, ie
incorporated into its dynamics), so that it is possible to see how the differential certainty evolves over
the course of the network?s dynamics. The top left panel shows that neurons that should fire in the
memory trace (ie for which z = 1) quickly converge on their correct phase, and that this convergence
usually takes a longer time for neurons receiving more uncertain input. This is paralleled by the
way their firing concentrations change (top middle panel): neurons with reliable input immediately
increase their concentrations from the initial ?(c) = 0.5 value to ?(c) = 1, while for those having
more unreliable input it takes a longer time to build up confidence about their firing phases (and by
the time they become confident their phases are indeed correct). Neurons that should not fire (z = 0)
build up their confidence even more slowly, more often remain fairly uncertain or only moderately
certain about their firing phases, as expressed by their concentrations (middle bottom panel) ? quite
righteously. Finally, since the firing rate input to the network is correct 90%, most neurons that
should or should not fire do or do not fire, respectively, with maximal certainty about their rate (top
and bottom right panels).
Various other metrics are important for providing insight into the operation of the network. In
particular, we may expect there to be a relationship between the actual error in the phase of firing
of the neurons recalled by the memory, and the firing rates and concentrations (in the form of burst
strengths) of the associated neurons themselves. Neurons which are erring should whisper rather
than shout. Figure 3A shows just this for the network. Here, we have sorted the neurons according to
their burst strengths ?, and plotted histograms of errors in firing phase for each group. The lower the
burst strength, the more likely are large errors ? at least to an approximation. A similar relationship
exists between recalled (analogue) and stored (binary) firing rates, where extreme values of the
recalled firing rate indicate that the stored firing rate was 0 or 1 with higher certainty (Figure 3B).
Figure 3C shows the results of a related analysis of experimental data kindly donated by Francesco
Battaglia. He recorded neurons in hippocampal area CA1 (not CA3, although we may hope for
some similar properties) whilst rats were shuttling on a linear track for food reward. CA1 neurons
have place fields ? locations in the environment where they respond with spikes ? and the phases of
these spikes relative to the ongoing theta oscillation in the hippocampus are also known to convey
information about location in space [5]. To create the plot, we first selected epochs with highquality and high power theta activity in the hippocampus (to ensure that phase is well estimated).
We then computed the mean firing phase within the theta cycle, ?, of each neuron as a function of the
location of the rat, separately for each visit to the same location. We assumed that the ?true? phase
x a neuron should recall at a given location is the average of these phases across different visits. We

B

Frequency

0.5
0.4
0.3
0.2

0.2
1
0.8
0.6
0.4

0.1

burst strength
(spikes / cycle)
0!0.5
0.5!1.5
1.5!2.5
2.5!3.5
3.5!4.5

0.2
0

0.1
0
!"

C
Frequency

0.6

burst strength
0.05
0.2
0.4
0.7

Stored firing rate

A

0
Error in firing phase

"

0

0.2 0.4 0.6 0.8 1
Retrieved firing rate

0
!"

0
?Error? in firing phase

"

Figure 3: Uncertainty signals are predictive of the error a cell is making both in simulation (A,B),
and as recorded from behaving animals (C). Burst strength signals overall uncertainty about and thus
predicts error in mean firing phase (A,C), while graded firing rates signal certainty about whether to
fire or not (B).

then evaluated the error a neuron was making at a given location on a given visit as the difference
between its ? in that trial at that location and the ?true? phase x associated with that location. This
allowed us to compute statistics of the error in phase as a function of the burst strength. The curves
in the figure show that, as for the simulation, burst strength is at least partly inversely correlated with
actual phase error, defined in terms of the overall activity in the population. Of course, this does not
constitute a proof of our representational theory.
One further way to evaluate the memory is to compare it to two existing associative memories that
have previously been studied, and can be seen as special cases. On one hand, our memory adds
the dimension of phase to the uncertainty-aware rate-based memory that Sommer & Dayan [14]
studied. This memory made a somewhat similar variational approximation, but, as for the meanfield Boltzmann machine [17], only involving r and ?(r) and no phases.
On the other hand, the memory device can be seen as adding the dimension of rate to the phase-based
memory that Lengyel & Dayan [4] treated. Note, however, that although this phase-based network
used superficially similar probabilistic principles to the one we have developed here, in fact it did
not operate according to uncertainty, since it made the key simplification that all neurons participate
in all memories, and that they also fire exactly one spike on every cycle during recall. This restricted
the dynamics of that network to perform maximum a posteriori (MAP) inference to find the single
recalled pattern of activity that best accommodated the probabilistic constraints of the cue, the prior
and the synaptic weights, rather than being able to work in the richer space of probabilistic recall of
the dynamics we are suggesting here.
Given these roots, we can follow the logic in figure 4 and compare the performance of our memory
with these precursors in the cases for which they are designed. For instance, to compare with the
rate-based network, we construct memories which include phase information. During recall, we
present cues with relatively accurate rates, but relatively inaccurate phases, and evaluate the extent
to which the network is perturbed by the presence of the phases (which, of course, it has to store
in the single set of synaptic weights). Figure 4A shows exactly this comparison. Here, a relatively
small network (N = 100) was used, with memories that are dense (pz = 0.5), and it is therefore
a stringent test of the storage capacity. Performance is evaluated by calculating the average error
made in recalled firing rates).
In the figure, the two blue curves are for the full model (with the phase information in the input
being relatively unreliable, its circular concentration parameter distributed uniformly between 0.1
and 10 across cells); the two yellow curves are for a network with only rates (which is similar to
that described, but not simulated, by Sommer & Dayan [14]). Exactly the same rate information
is provided to all networks, and is 10% inaccurate (a degree known to the dynamics in the form of
?0 and ?1 ). The two flat dashed lines show the performance in the case that there are no recurrent
synaptic weights at all. This is an important control, since we are potentially presenting substantial
information in the cues themselves. The two solid curves show that the full model tracks the reduced,
rate-based, model almost perfectly until the performance totally breaks down. This shows that the
phase information, and the existence of phase uncertainty and processing during recall, does not

A

B

0.45

0.9

0.4

0.8
0.7

0.3

Average error

Average error

0.35

0.25
0.2
0.15

rate!coded model w/o learning
rate!coded model
full model w/o learning
full model

0.1
0.05
0

0.6
0.5
0.4
phase!coded model w/o learning
phase!coded model
full model w/o learning
full model

0.3
0.2
0.1

1

10
100
Number of stored patterns

1000

1

10
100
Number of stored patterns

1000

Figure 4: Recall performance compared with a rate-only network (A) and a phase-only network (B).
The full model (blue lines) performs just as well as the reduced ?specialist? models (yellow lines)
in comparable circumstances (when the information provided to the networks in the dimension they
shared is exactly the same). All models (solid lines) outperform the standard control of using the
input and the prior alone (dashed lines).
corrupt the network?s capacity to recall rates. Given its small size, the network is quite competent
as an auto-associator.
Figure 4B shows a similar comparison between this network and a network that only has to deal
with uncertainty in firing phases but not in rates. Again, its performance at recalling phase, given
uncertain and noisy phase cues, but good rate-cues, is exactly on a par with the pure, phase-based
network. Further, the average errors are only modest, so the capacity of the network for storing
analog phases is also impressive.

5

Discussion

We have considered an interpretation of the activities of neurons in oscillating structures such as area
CA3 of the hippocampus as representing distributions over two underlying quantities, one binary and
one analogue. We also showed how this representational capacity can be used to excellent effect in
the key, uncertainty-sensitive computation of memory recall, an operation in which CA3 is known to
be involved. The resulting network model of CA3 encompasses critical aspects of its physiological
properties, notably information-bearing firing rates and phases. Further, since it generalizes earlier
theories of purely phase-based memories, this model is also consistent with the measured phase
response curves of CA3 neurons, which characterize their actual dynamical interactions.
Various aspects of this new theory are amenable to experimental investigation. First, the full dynamics (see the supplementary material) imply that firing rate and firing phase should be coupled
together both pre-synpatically, in terms of the influence of timed input spikes, and post-synaptically,
in terms of how changes in the activity of a neuron should depend on its own activity. In vitro experiments along the lines of those carried out before [16], in which we have precise experimental
control over pre- and post-synaptic activity can be used to test these predictions. Further, making
the sort of assumptions that underlie figure 3C, we can use data from awake behaving rats to see if
the gross statistics of the changes in the activity of the neurons fit the expectations licensed by the
theory.
From a computational perspective, we have demonstrated that the network is a highly competent
associative memory, correctly recalling both binary and analog information, along with certainty
about it, and degrading gracefully in the face of overload. In fact, compared with the representation
of other analogue quantities (such as the orientation of a visually preseted bar), analogue memory
actually poses a particularly tough problem for the representation of uncertainty. This is because
for variables like orientation, a whole population is treated as being devoted to the representation
of the distribution of a single scalar value. By contrast, for analogue memory, each neuron has an
independent analogue value, and so the dimensionality of the distribution scales with the number of
neurons involved. This extra representational power comes from the ability of neurons to distribute

their spikes within a cycle to indicate their uncertainty about phase (using the dimension of time in
just the same way that distributional population codes [12] used the dimension of neural space).
This dimension for representing analogue uncertainty is coupled to that of the firing rate for representing binary uncertainty, since neurons have to fire multiple times in a cycle to have a measurable
lack of concentration. However, this coupling is exactly appropriate given the form of the distribution assumed in equation 2, since weakly firing neurons express only weak certainty about phase
in any case. In fact, it is conceivable that we could combine a different model for the firing rate
uncertainty with this model for analogue uncertainty, if, for instance, it is found that neuronal firing
rates covary in ways that are not anticipated from equation 2.
Finally, the most important direction for future work is understanding the uncertainty-sensitive coupling between multiple oscillating memories, where the oscillations, though dynamically coordinated, need not have the same frequencies. Exactly this seems to characterize the interaction between the hippocampus and the necortex during both consolidation and retrieval [18, 19].
Acknowledgments
Funding from the Gatsby Charitable Foundation. We are very grateful to Francesco Battaglia for
allowing us to use his data to produce figure 3C, and to him, and Ole Paulsen and Jeehyun Kwag for
very helpful discussions.
References
[1]
[2]
[3]
[4]
[5]
[6]
[7]
[8]
[9]
[10]
[11]
[12]
[13]
[14]
[15]
[16]
[17]
[18]
[19]

?
Szaliszny?o K, Erdi
P. In The Handbook of Brain Theory and Neural Networks, 533, 2003.
Hopfield JJ. Nature 376:33, 1995.
Yoshioka M. Physical Review E 65, 2001.
Lengyel M, Dayan P. In Advances in Neural Information Processing Systems 17, 769, Cambridge, MA,
2005. MIT Press.
O?Keefe J, Recce ML. Hippocampus 3:317, 1993.
Huxter J, et al. Nature 425:828, 2003.
Ernst M, Banks M. Nature 415:429, 2002.
K?ording K, Wolpert D. Nature 427:244, 2004.
Gold JI, Shadlen MN. Neuron 36:299, 2002.
Hinton G. Neural Comput 1:143, 1990.
Peterson C, Anderson J. Complex Systems 1:995, 1987.
Pouget A, et al. Annu Rev Neurosci 26:381, 2003.
MacKay DJC. In Maximum Entropy and Bayesian Methods, Laramie, 1990, 237, 1991.
Sommer FT, Dayan P. IEEE Trans Neural Netw 9:705, 1998.
Fisher NI. Statistical analysis of circular data. Cambridge University Press, 1995.
Lengyel M, et al. Nat Neurosci 8:1677, 2005.
Dayan P, Abbott LF. Theoretical Neuroscience. MIT Press, 2001.
Siapas AG, Wilson MA. Neuron 21:1123, 1998.
Jones M, Wilson M. PLoS Biol 3:e402, 2005.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4872-a-memory-frontier-for-complex-synapses.pdf

A memory frontier for complex synapses

Subhaneil Lahiri and Surya Ganguli
Department of Applied Physics, Stanford University, Stanford CA
sulahiri@stanford.edu, sganguli@stanford.edu

Abstract
An incredible gulf separates theoretical models of synapses, often described solely
by a single scalar value denoting the size of a postsynaptic potential, from the
immense complexity of molecular signaling pathways underlying real synapses.
To understand the functional contribution of such molecular complexity to learning and memory, it is essential to expand our theoretical conception of a synapse
from a single scalar to an entire dynamical system with many internal molecular
functional states. Moreover, theoretical considerations alone demand such an expansion; network models with scalar synapses assuming finite numbers of distinguishable synaptic strengths have strikingly limited memory capacity. This raises
the fundamental question, how does synaptic complexity give rise to memory? To
address this, we develop new mathematical theorems elucidating the relationship
between the structural organization and memory properties of complex synapses
that are themselves molecular networks. Moreover, in proving such theorems, we
uncover a framework, based on first passage time theory, to impose an order on
the internal states of complex synaptic models, thereby simplifying the relationship between synaptic structure and function.

1

Introduction

It is widely thought that our very ability to remember the past over long time scales depends crucially
on our ability to modify synapses in our brain in an experience dependent manner. Classical models
of synaptic plasticity model synaptic efficacy as an analog scalar value, denoting the size of a postsynaptic potential injected into one neuron from another. Theoretical work has shown that such
models have a reasonable, extensive memory capacity, in which the number of long term associations
that can be stored by a neuron is proportional its number of afferent synapses [1?3]. However,
recent experimental work has shown that many synapses are more digital than analog; they cannot
robustly assume an infinite continuum of analog values, but rather can only take on a finite number
of distinguishable strengths, a number than can be as small as two [4?6] (though see [7]). This
one simple modification leads to a catastrophe in memory capacity: classical models with digital
synapses, when operating in a palimpset mode in which the ongoing storage of new memories can
overwrite previous memories, have a memory capacity proportional to the logarithm of the number
of synapses [8, 9]. Intuitively, when synapses are digital, the storage of a new memory can flip
a population of synaptic switches, thereby rapidly erasing previous memories stored in the same
synaptic population. This result indicates that the dominant theoretical basis for the storage of long
term memories in modifiable synaptic switches is flawed.
Recent work [10?12] has suggested that a way out of this logarithmic catastrophe is to expand our
theoretical conception of a synapse from a single scalar value to an entire stochastic dynamical system in its own right. This conceptual expansion is further necessitated by the experimental reality
that synapses contain within them immensely complex molecular signaling pathways, with many internal molecular functional states (e.g. see [4, 13, 14]). While externally, synaptic efficacy could be
digital, candidate patterns of electrical activity leading to potentiation or depression could yield transitions between these internal molecular states without necessarily inducing an associated change in
1

synaptic efficacy. This form of synaptic change, known as metaplasticity [15, 16], can allow the
probability of synaptic potentiation or depression to acquire a rich dependence on the history of
prior changes in efficacy, thereby potentially improving memory capacity.
Theoretical studies of complex, metaplastic synapses have focused on analyzing the memory performance of a limited number of very specific molecular dynamical systems, characterized by a
number of internal states in which potentiation and depression each induce a specific set of allowable transitions between states (e.g. see Figure 1 below). While these models can vastly outperform
simple binary synaptic switches, these analyses leave open several deep and important questions.
For example, how does the structure of a synaptic dynamical system determine its memory performance? What are the fundamental limits of memory performance over the space of all possible
synaptic dynamical systems? What is the structural organization of synaptic dynamical systems that
achieve these limits? Moreover, from an experimental perspective, it is unlikely that all synapses
can be described by a single canonical synaptic model; just like the case of neurons, there is an
incredible diversity of molecular networks underlying synapses both across species and across brain
regions within a single organism [17]. In order to elucidate the functional contribution of this diverse molecular complexity to learning and memory, it is essential to move beyond the analysis of
specific models and instead develop a general theory of learning and memory for complex synapses.
Moreover, such a general theory of complex synapses could aid in development of novel artificial
memory storage devices.
Here we initiate such a general theory by proving upper bounds on the memory curve associated with
any synaptic dynamical system, within the well established ideal observer framework of [10, 11, 18].
Along the way we develop principles based on first passage time theory to order the structure of
synaptic dynamical systems and relate this structure to memory performance. We summarize our
main results in the discussion section.

2

Overall framework: synaptic models and their memory curves

In this section, we describe the class of models of synaptic plasticity that we are studying and how
we quantify their memory performance. In the subsequent sections, we will find upper bounds on
this performance.
We use a well established formalism for the study of learning and memory with complex synapses
(see [10, 11, 18]). In this approach, electrical patterns of activity corresponding to candidate potentiating and depressing plasticity events occur randomly and independently at all synapses at a
Poisson rate r. These events reflect possible synaptic changes due to either spontaneous network
activity, or the storage of new memories. We let f pot and f dep denote the fraction of these events that
are candidate potentiating or depressing events respectively. Furthermore, we assume our synaptic
model has M internal molecular functional states, and that a candidate potentiating (depotentiating) event induces a stochastic transition in the internal state described by an M ? M discrete time
Markov transition matrix Mpot (Mdep ). In this framework, the states of different synapses will be
independent, and the entire synaptic population can be fully described by the probability distribution
across these states, which we will indicate with the row-vector p(t). Thus the i?th component of
p(t) denotes the fraction of the synaptic population in state i. Furthermore, each state i has its own
synaptic weight, wi , which we take, in the worst case scenario, to be restricted to two values. After
shifting and scaling these two values, we can assume they are ?1, without loss of generality.
We also employ an ?ideal observer? approach to the memory readout, where the synaptic weights
are read directly. This provides an upper bound on the quality of any readout using neural activity.
For any single memory, stored at time t = 0, we assume there will be an ideal pattern of synaptic
weights across a population of N synapses, the N -element vector w
~ ideal , that is +1 at all synapses
that experience a candidate potentiation event, and ?1 at all synapses that experience a candidate
depression event at the time of memory storage. We assume that any pattern of synaptic weights
close to w
~ ideal is sufficient to recall the memory. However, the actual pattern of synaptic weights at
some later time, t, will change to w(t)
~
due to further modifications from the storage of subsequent
memories. We can use the overlap between these, w
~ ideal ? w(t),
~
as a measure of the quality of the
memory. As t ? ?, the system will return to its steady state distribution which will be uncorrelated
2

Cascade model

(b)

Serial model

(c)

?1

10

SNR

(a)

?2

10

Cascade
Serial

?3

10

?1

10

0

10

1

10
Time

2

10

3

10

Figure 1: Models of complex synapses. (a) The cascade model of [10], showing transitions between
states of high/low synaptic weight (red/blue circles) due to potentiation/depression (solid red/dashed
blue arrows). (b) The serial model of [12]. (c) The memory curves of these two models, showing
the decay of the signal-to-noise ratio (to be defined in ?2) as subsequent memories are stored.
with the memory stored at t = 0. The probability distribution of the quantity w
~ ideal ? w(?)
~
can be
used as a ?null model? for comparison.
The extent to which the memory has been stored is described by a signal-to-noise ratio (SNR)
[10, 11]:
hw
~ ideal ? w(t)i
~
? hw
~ ideal ? w(?)i
~
p
SNR(t) =
.
(1)
Var(w
~ ideal ? w(?))
~
?
The noise in the denominator is essentially N . There is a correction when potentiation and depression are imbalanced, but this will not affect the upper bounds that we will discuss below and
will be ignored in the subsequent formulae.
A simple average memory curve can be derived as follows. All of the preceding plasticity events,
prior to t = 0, will put the population of synapses in its steady-state distribution, p? . The memory we are tracking at t = 0 will change the internal state distribution to p? Mpot (or p? Mdep )
in those synapses that experience a candidate potentiation (or depression) event. As the potentiating/depressing nature of the subsequent memories is independent of w
~ ideal , we can average over all
sequences, resulting in the evolution of the probability distribution:
dp(t)
= rp(t)WF ,
where WF = f pot Mpot + f dep Mdep ? I.
(2)
dt
Here WF is a continuous time transition matrix that models the process of forgetting the memory
stored at time t = 0 due to random candidate potentiation/depression events occurring at each
synapse due to the storage of subsequent memories. Its stationary distribution is p? .
This results in the following SNR
?


F
(3)
SNR(t) = N 2f pot f dep p? Mpot ? Mdep ertW w.
A detailed derivation of this formula can be found in the supplementary material. We will frequently
refer to this function as the memory curve. It can be thought of as the excess fraction of synapses
(relative to equilibrium) that maintain their ideal synaptic strength at time t, as dictated by the stored
memory at time t = 0.
Much of the previous work on these types of complex synaptic models has focused on understanding
the memory curves of specific models, or choices of Mpot/dep . Two examples of these models are
shown in Figure 1. We see that they have different memory properties. The serial model performs
relatively well at one particular timescale, but it performs poorly at other times. The cascade model
does not perform quite as well at that time, but it maintains its performance over a wider range of
timescales.
In this work, rather than analyzing specific models, we take a different approach, in order to obtain
a more general theory. We consider the entire space of these models and find upper bounds on the
memory capacity of any of them. The space of models with a fixed number of internal states M is
parameterized by the pair of M ? M discrete time stochastic transition matrices Mpot and Mdep , in
addition to f pot/dep . The parameters must satisfy the following constraints:
Mpot/dep
? [0, 1],
ij
X

Mpot/dep
ij

= 1,

f pot/dep ? [0, 1],
f pot + f dep = 1,

j

p? WF = 0,
X
p?
i = 1.
i

3

wi = ?1,
(4)

and f pot/dep follow automatically from the other constraints.
The upper bounds on Mpot/dep
ij
The critical question is: what do these constraints imply about the space of achievable memory
curves in (3)? To answer this question, especially for limits on achievable memory at finite times, it
will be useful to employ the eigenmode decomposition:
X
WF =
?qa ua va , va ub = ?ab , WF ua = ?qa ua , va WF = ?qa va .
(5)
a

Here qa are the negative of the eigenvalues of the forgetting process WF , ua are the right (column)
eigenvectors and va are the left (row) eigenvectors. This decomposition allows us to write the
memory curve as a sum of exponentials,
? X
SNR(t) = N
Ia e?rt/?a ,
(6)
a

where Ia = (2f pot f dep )p? (Mpot ? Mdep )ua va w and ?a = 1/qa . We can then ask the question:
what are the constraints on these quantities, namely eigenmode initial SNR?s, Ia , and time constants,
?a , implied by the constraints in (4)? We will derive some of these constraints in the next section.

3

Upper bounds on achievable memory capacity

In the previous section, in (3) we have described an analytic expression for a memory curve as a
function of the structure of a synaptic dynamical system, described by the pair of stochastic transition
matrices Mpot/dep . Since the performance measure for memory is an entire memory curve, and not
just a single number, there is no universal scalar notion of optimal memory in the space of synaptic
dynamical systems. Instead there are tradeoffs between storing proximal and distal memories; often
attempts to increase memory at late (early) times by changing Mpot/dep , incurs a performance loss
in memory at early (late) times in specific models considered so far [10?12]. Thus our end goal,
achieved in ?4, is to derive an envelope memory curve in the SNR-time plane, or a curve that forms
an upper-bound on the entire memory curve of any model. In order to achieve this goal, in this
section, we must first derive upper bounds, over the space of all possible synaptic models, on two
different scalar functions of the memory curve: its initial SNR, and the area under the memory curve.
In the process of upper-bounding the area, we will develop an essential framework to organize the
structure of synaptic dynamical systems based on first passage time theory.
3.1

Bounding initial SNR

We now give an upper bound on the initial SNR,
?


SNR(0) = N 2f pot f dep p? Mpot ? Mdep w,

(7)

over all possible models and also find the class of models that saturate this bound. A useful quantity
is the equilibrium probability flux between two disjoint sets of states, A and B:
XX
F
?AB =
rp?
(8)
i Wij .
i?A j?B

The initial SNR is closely related to the flux from the states with wi = ?1 to those with wj = +1
(see supplementary material):
?
4 N ??+
SNR(0) ?
.
(9)
r
This inequality becomes an equality if potentiation never decreases the synaptic weight and depression never increases it, which should be a property of any sensible model.
To maximize this flux, potentiation from a weak state must be guaranteed to end in a strong state,
and depression must do the reverse. An example of such a model is shown in Figure 2(a,b). These
models have a property known as ?lumpability? (see [19, ?6.3] for the discrete time version and
[20, 21] for continuous time). They are completely equivalent (i.e. have the same memory curve) as
a two state model with transition probabilities equal to 1, as shown in Figure 2(c).
4

(a)

(b)

(c)

1
1

Figure 2: Synaptic models that maximize initial SNR. (a) For potentiation, all transitions starting
from a weak state lead to a strong state, and the probabilities for all transitions leaving a given weak
state sum to 1. (a) Depression is similar to potentiation, but with strong and weak interchanged.
(c) The equivalent two state model, with transition probabilities under potentiation and depression
equal to one.
This two state model has the equilibrium distribution p? = (f dep , f pot ) and its flux is given by
??+ = rf pot f dep . This is maximized when f pot = f dep = 12 , leading to the upper bound:
?
SNR(0) ? N .
(10)
We note that while this model has high initial SNR, it also has very fast memory decay ? with a
timescale ? ? 1r . As the synapse is very plastic, the initial memory is encoded very easily, but
the subsequent memories also overwrite it rapidly. This is one example of the tradeoff between
optimizing memory at early versus late times.
3.2

Imposing order on internal states through first passage times

Our goal of understanding the relationship between structure and function in the space of all possible
synaptic models is complicated by the fact that this space contains many different possible network
topologies, encoded in the nonzero matrix elements of Mpot/dep . To systematically analyze this
entire space, we develop an important organizing principle using the theory of first passage times
in the stochastic process of forgetting, described by WF . The mean first passage time matrix, Tij ,
is defined as the average time it takes to reach state j for the first time, starting from state i. The
diagonal elements are defined to be zero.
A remarkable theorem we will exploit is that the quantity
X
??
Tij p?
j ,

(11)

j

known as Kemeny?s constant (see [19, ?4.4]), is independent of the starting state i. Intuitively, (11)
states that the average time it takes to reach any state, weighted by its equilibrium probability, is
independent of the starting state, implying a hidden constancy inherent in any stochastic process.
In the context of complex synapses, we can define the partial sums
X
X
?i+ =
Tij p?
?i? =
Tij p?
j ,
j .
j?+

(12)

j??

These can be thought of as the average time it takes to reach the strong/weak states respectively.
Using these definitions, we can then impose an order on the states by arranging them in order of
decreasing ?i+ or increasing ?i? . Because ?i+ + ?i? = ? is independent of i, the two orderings are
the same. In this order, which depends sensitively on the structure of Mpot/dep , states later (to the
right in figures below) can be considered to be more potentiated than states earlier (to the left in
figures below), despite the fact that they have the same synaptic efficacy. In essence, in this order, a
state is considered to be more potentiated if the average time it takes to reach all the strong efficacy
states is shorter. We will see that synaptic models that optimize various measures of memory have
an exceedingly simple structure when, and only when, their states are arranged in this order.1
1
Note that we do not need to worry about the order of the ?i? changing during the optimization: necessary
conditions for a maximum only require that there is no infinitesimal perturbation that increases the area. Therefore we need only consider an infinitesimal neighborhood of the model, in which the order will not change.

5

(a)

(b)

(c)

Figure 3: Perturbations that increase the area. (a) Perturbations that increase elements of Mpot
above the diagonal and decrease the corresponding elements of Mdep . It can no longer be used
when Mdep is lower triangular, i.e. depression must move synapses to ?more depressed? states. (b)
Perturbations that decrease elements of Mpot below the diagonal and increase the corresponding
elements of Mdep . It can no longer be used when Mpot is upper triangular, i.e. potentiation must
move synapses to ?more potentiated? states. (c) Perturbation that decreases ?shortcut? transitions
and increases the bypassed ?direct? transitions. It can no longer be used when there are only nearestneighbor ?direct? transitions.
3.3

Bounding area

Now consider the area under the memory curve:
Z ?
A=
dt SNR(t).

(13)

0

We will find an upper bound on this quantity as well as the model that saturates this bound.
First passage time theory introduced in the previous section becomes useful because the area has a
simple expression in terms of quantities introduced in (12) (see supplementary material):


X
?

pot
dep
A = N (4f pot f dep )
p?
?i+ ? ?j+
M
?
M
i
ij
ij
ij

?
=

N (4f

pot dep

f

)

X




dep
p?
?j? ? ?i? .
Mpot
i
ij ? Mij

(14)

ij

With the states in the order described above, we can find perturbations of Mpot/dep that will always
increase the area, whilst leaving the equilibrium distribution, p? , unchanged. Some of these perturbations are shown in Figure 3, see supplementary material for details. For example, in Figure 3(a),
for two states i on the left and j on the right, with j being more ?potentiated? than i (i.e. ?i+ > ?j+ ),
dep
we have proven that increasing Mpot
ij and decreasing Mij leads to an increase in area. The only
thing that can prevent these perturbations from increasing the area is when they require the decrease
of a matrix element that has already been set to 0. This determines the topology (non-zero transition
probabilities) of the model with maximal area. It is of the form shown in Figure 4(c),with potentiation moving one step to the right and depression moving one step to the left. Any other topology
would allow some class of perturbations (e.g. in Figure 3) to further increase the area.
As these perturbations do not change the equilibrium distribution, this means that the area of any
model is bounded by that of a linear chain with the same equilibrium distribution. The area of
a linear chain model can be expressed directly in terms of its equilibrium state distribution, p? ,
yielding the following upper bound on the area of any model with the same p? (see supplementary
material):


?
?
?
?


X
X
X

2
N
2 N X?
?
? ?

?
k?
jp?
p
w
=
k
?
jp
A?
(15)
k
j
k
j  pk ,

r
r

j
j
k
k 
P
where we chose wk = sgn[k ? j jp?
j ]. We can then maximize this by pushing all of the equilibrium distribution symmetrically to the two end states. This can be done by reducing the transition
probabilities out of these states, as in Figure 4(c). This makes it very difficult to exit these states
once they have been entered. The resulting area is
?
N (M ? 1)
.
(16)
A?
r
This analytical result is similar to a numerical result found in [18] under a slightly different information theoretic measure of memory performance.
6

The ?sticky? end states result in very slow decay of memory, but they also make it difficult to encode
the memory in the first place, since a small fraction of synapses are able to change synaptic efficacy
during the storage of a new memory. Thus models that maximize area optimize memory at late
times, at the expense of early times.

4

Memory curve envelope

Now we will look at the implications of the upper bounds found in the previous section for the SNR
at finite times. As argued in (6), the memory curve can be written in the form
? X
SNR(t) = N
Ia e?rt/?a .
(17)
a

The upper bounds on the initial SNR, (10), and the area, (16), imply the following constraints on the
parameters {Ia , ?a }:
X
X
Ia ? 1,
Ia ?a ? M ? 1.
(18)
a

a

We are not claiming that these are a complete set of constraints: not every set {Ia , ?a } that satisfies
these inequalities will actually be achievable by a synaptic model. However, any set that violates
either inequality will definitely not be achievable.
Now we can pick some fixed time, t0 , and maximize the SNR at that time wrt. the parameters
{Ia , ?a }, subject to the constraints above. This always results in a single nonzero Ia ; in essence,
optimizing memory at a single time requires a single exponential. The resulting optimal memory
curve, along with the achieved memory at the chosen time, depends on t0 as follows:
?
?
M ?1
t0 ?
=? SNR(t) = N e?rt/(M ?1)
=? SNR(t0 ) = N e?rt0 /(M ?1) ,
r
?
?
(19)
M ?1
N (M ? 1)e?t/t0
N (M ? 1)
t0 ?
=? SNR(t) =
=? SNR(t0 ) =
.
r
rt0
ert0
Both the initial SNR bound and the area bound are saturated at early times. At late times, only
the area bound is saturated. The function SNR(t0 ), the green curve in Figure 4(a), above forms a
memory curve envelope with late-time power-law decay ? t?1
0 . No synaptic model can have an
SNR that is greater than this at any time. We can use this to find an upper bound on the memory
lifetime, ? (), by finding the point at which the envelope crosses :
?
N (M ? 1)
,
(20)
? () ?
er
where we assume N > (e)2 . Intriguingly, both the lifetime and memory envelope expand linearly
with the number of internal states M , and increase as the square root of the number of synapses N .
This leaves the question of whether this bound is achievable. At any time, can we find a model
whose memory curve touches the envelope? The red curves in Figure 4(a) show the closest we
have come to the envelope with actual models, by repeated numerical optimization of SNR(t0 ) over
Mpot/dep with random initialization and by hand designed models.
We see that at early, but not late times, there is a gap between the upper bound that we can prove
and what we can achieve with actual models. There may be other models we haven?t found that
could beat the ones we have, and come closer to our proven envelope. However, we suspect that the
area constraint is not the bottleneck for optimizing memory at times less than O( M
r ). We believe
there is some other constraint that prevents models from approaching the envelope, and currently are
exploring several mathematical conjectures for the precise form of this constraint in order to obtain
a potentially tighter envelope. Nevertheless, we have proven rigorously that no model?s memory
curve can ever exceed this envelope, and that it is at least tight for late times, longer than O( M
r ),
where models of the form in Figure 4(c)can come close to the envelope.

5

Discussion

We have initiated the development of a general theory of learning and memory with complex
synapses, allowing for an exploration of the entire space of complex synaptic models, rather than
7

(a)

(b)

1

10

0

10
SNR

envelope
numerical search
hand designed
?1

10

(c)

?

Area bound active
Initial SNR bound active

?

?2

10 ?1
10

0

10

1

10
Time

2

10

3

10

Figure 4: The memory curve envelope for N = 100, M = 12. (a) An upper bound on the SNR
at any time is shown in green. The red dashed curve shows the result of numerical optimization of
synaptic models with random initialization. The solid red curve shows the highest SNR we have
found with hand designed models. At early times these models are of the form shown in (b) with
different numbers of states, and all transition probabilities equal to 1. At late times they are of the
form shown in (c) with different values of ?. The model shown in (c) also saturates the area bound
(16) in the limit ? ? 0.
analyzing individual models one at a time. In doing so, we have obtained several new mathematical results delineating the functional limits of memory achievable by synaptic complexity, and the
structural characterization of synaptic dynamical systems that achieve these limits. In particular,
operating within the ideal observer framework of [10, 11, 18], we have shown that for a population
?
of N synapses with M internal states, (a) the initial SNR of any synaptic model cannot exceed N ,
and any model that achieves this bound is equivalent to a binary synapse, (b) the area under the
memory curve of any model cannot exceed that of a linear chain model with the same
? equilibrium
distribution, (c) both the area and memory lifetime of any model cannot exceed O( N M ), and the
model that achieves this limit has a linear chain topology with only nearest neighbor transitions, (d)
we have derived an envelope memory curve in the SNR-time plane that cannot be exceeded by the
memory curve of any model, and models that approach this envelope for times greater ?
than O( M
r )
are linear chain models, and (e) this late-time envelope is a power-law proportional to O( N M /rt),
indicating that synaptic complexity can strongly enhance the limits of achievable memory.
This theoretical study opens up several avenues for further inquiry. In particular, the tightness of our
envelope for early times, less than O( M
r ), remains an open question, and we are currently pursuing
several conjectures. We have also derived memory constrained envelopes, by asking in the space
of models that achieve a given SNR at a given time, what is the maximal SNR achievable at other
times. If these two times are beyond a threshold separation, optimal constrained models require
two exponentials. It would be interesting to systematically analyze the space of models that achieve
good memory at multiple times, and understand their structural organization, and how they give rise
to multiple exponentials, leading to power law memory decays.
Finally, it would be interesting to design physiological experiments in order to perform optimal
systems identification of potential Markovian dynamical systems hiding within biological synapses,
given measurements of pre and post-synaptic spike trains along with changes in post-synaptic potentials. Then given our theory, we could match this measured synaptic model to optimal models to
understand for which timescales of memory, if any, biological synaptic dynamics may be tuned.
In summary, we hope that a deeper theoretical understanding of the functional role of synaptic
complexity, initiated here, will help advance our understanding of the neurobiology of learning and
memory, aid in the design of engineered memory circuits, and lead to new mathematical theorems
about stochastic processes.
Acknowledgements
We thank Sloan, Genenetech, Burroughs-Wellcome, and Swartz foundations for support. We thank
Larry Abbott, Marcus Benna, Stefano Fusi, Jascha Sohl-Dickstein and David Sussillo for useful
discussions.
8

References
[1] J. J. Hopfield, ?Neural networks and physical systems with emergent collective computational
abilities,? Proc. Natl. Acad. Sci. U.S.A. 79 (1982) no. 8, 2554?2558.
[2] D. J. Amit, H. Gutfreund, and H. Sompolinsky, ?Spin-glass models of neural networks,? Phys.
Rev. A 32 (Aug, 1985) 1007?1018.
[3] E. Gardner, ?The space of interactions in neural network models,? Journal of Physics A:
Mathematical and General 21 (1988) no. 1, 257.
[4] T. V. P. Bliss and G. L. Collingridge, ?A synaptic model of memory: long-term potentiation in
the hippocampus,? Nature 361 (Jan, 1993) 31?39.
[5] C. C. H. Petersen, R. C. Malenka, R. A. Nicoll, and J. J. Hopfield, ?All-or-none potentiation at
CA3-CA1 synapses,? Proc. Natl. Acad. Sci. U.S.A. 95 (1998) no. 8, 4732?4737.
[6] D. H. O?Connor, G. M. Wittenberg, and S. S.-H. Wang, ?Graded bidirectional synaptic
plasticity is composed of switch-like unitary events,? Proc. Natl. Acad. Sci. U.S.A. 102 (2005)
no. 27, 9679?9684.
[7] R. Enoki, Y. ling Hu, D. Hamilton, and A. Fine, ?Expression of Long-Term Plasticity at
Individual Synapses in Hippocampus Is Graded, Bidirectional, and Mainly Presynaptic:
Optical Quantal Analysis,? Neuron 62 (2009) no. 2, 242 ? 253.
[8] D. J. Amit and S. Fusi, ?Constraints on learning in dynamic synapses,? Network:
Computation in Neural Systems 3 (1992) no. 4, 443?464.
[9] D. J. Amit and S. Fusi, ?Learning in neural networks with material synapses,? Neural
Computation 6 (1994) no. 5, 957?982.
[10] S. Fusi, P. J. Drew, and L. F. Abbott, ?Cascade models of synaptically stored memories,?
Neuron 45 (Feb, 2005) 599?611.
[11] S. Fusi and L. F. Abbott, ?Limits on the memory storage capacity of bounded synapses,? Nat.
Neurosci. 10 (Apr, 2007) 485?493.
[12] C. Leibold and R. Kempter, ?Sparseness Constrains the Prolongation of Memory Lifetime via
Synaptic Metaplasticity,? Cerebral Cortex 18 (2008) no. 1, 67?77.
[13] D. S. Bredt and R. A. Nicoll, ?AMPA Receptor Trafficking at Excitatory Synapses,? Neuron
40 (2003) no. 2, 361 ? 379.
[14] M. P. Coba, A. J. Pocklington, M. O. Collins, M. V. Kopanitsa, R. T. Uren, S. Swamy, M. D.
Croning, J. S. Choudhary, and S. G. Grant, ?Neurotransmitters drive combinatorial multistate
postsynaptic density networks,? Sci Signal 2 (2009) no. 68, ra19.
[15] W. C. Abraham and M. F. Bear, ?Metaplasticity: the plasticity of synaptic plasticity,? Trends
in Neurosciences 19 (1996) no. 4, 126 ? 130.
[16] J. M. Montgomery and D. V. Madison, ?State-Dependent Heterogeneity in Synaptic
Depression between Pyramidal Cell Pairs,? Neuron 33 (2002) no. 5, 765 ? 777.
[17] R. D. Emes and S. G. Grant, ?Evolution of Synapse Complexity and Diversity,? Annual
Review of Neuroscience 35 (2012) no. 1, 111?131.
[18] A. B. Barrett and M. C. van Rossum, ?Optimal learning rules for discrete synapses,? PLoS
Comput. Biol. 4 (Nov, 2008) e1000230.
[19] J. Kemeny and J. Snell, Finite markov chains. Springer, 1960.
[20] C. Burke and M. Rosenblatt, ?A Markovian function of a Markov chain,? The Annals of
Mathematical Statistics 29 (1958) no. 4, 1112?1122.
[21] F. Ball and G. F. Yeo, ?Lumpability and Marginalisability for Continuous-Time Markov
Chains,? Journal of Applied Probability 30 (1993) no. 3, 518?528.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1783-predictive-sequence-learning-in-recurrent-neocortical-circuits.pdf

Predictive Sequence Learning in Recurrent
Neocortical Circuits*

R.P.N.Rao

T. J. Sejnowski

Computational Neurobiology Lab and
Sloan Center for Theoretical Neurobiology
The Salk Institute, La Jolla, CA 92037
rao@salk.edu

Computational Neurobiology Lab and
Howard Hughes Medical Institute
The Salk Institute, La Jolla, CA 92037
terry@salk.edu

Abstract
Neocortical circuits are dominated by massive excitatory feedback: more
than eighty percent of the synapses made by excitatory cortical neurons
are onto other excitatory cortical neurons. Why is there such massive recurrent excitation in the neocortex and what is its role in cortical computation? Recent neurophysiological experiments have shown that the plasticity of recurrent neocortical synapses is governed by a temporally asymmetric Hebbian learning rule. We describe how such a rule may allow
the cortex to modify recurrent synapses for prediction of input sequences.
The goal is to predict the next cortical input from the recent past based on
previous experience of similar input sequences. We show that a temporal
difference learning rule for prediction used in conjunction with dendritic
back-propagating action potentials reproduces the temporally asymmetric Hebbian plasticity observed physiologically. Biophysical simulations
demonstrate that a network of cortical neurons can learn to predict moving stimuli and develop direction selective responses as a consequence of
learning. The space-time response properties of model neurons are shown
to be similar to those of direction selective cells in alert monkey VI.

1 INTRODUCTION
The neocortex is characterized by an extensive system of recurrent excitatory connections
between neurons in a given area. The precise computational function of this massive recurrent excitation remains unknown. Previous modeling studies have suggested a role for
excitatory feedback in amplifying feedforward inputs [1]. Recently, however, it has been
shown that recurrent excitatory connections between cortical neurons are modified according to a temporally asymmetric Hebbian learning rule: synapses that are activated slightly
before the cell fires are strengthened whereas those that are activated slightly after are weakened [2, 3]. Information regarding the postsynaptic activity of the cell is conveyed back to
the dendritic locations of synapses by back-propagating action potentials from the soma.
In this paper, we explore the hypothesis that recurrent excitation subserves the function of
prediction and generation of temporal sequences in neocortical circuits [4, 5, 6]. We show
"This research was supported by the Sloan Foundation and Howard Hughes Medical Institute.

165

Predictive Sequence Learning in Recurrent Neocortical Circuits

that a temporal difference based learning rule for prediction applied to backpropagating action potentials reproduces the experimentally observed phenomenon of asymmetric Hebbian plasticity. We then show that such a learning mechanism can be used to learn temporal
sequences and the property of direction selectivity emerges as a consequence of learning to
predict moving stimuli. Space-time response plots of model neurons are shown to be similar
to those of direction selective cells in alert macaque VI.

2

TEMPORALLY ASYMMETRIC HEBBIAN PLASTICITY AND
TEMPORAL DIFFERENCE LEARNING

To accurately predict input sequences, the recurrent excitatory connections in a network
need to be adjusted such that the appropriate set of neurons are activated at each time step.
This can be achieved by using a "temporal-difference" (TD) learning rule [5, 7]. In this
paradigm of synaptic plasticity, an activated synapse is strengthened or weakened based on
whether the difference between two temporally-separated predictions is positive or negative. This minimizes the errors in prediction by ensuring that the prediction generated by
the neuron after synaptic modification is closer to the desired value than before (see [7] for
more details).
In order to ascertain whether temporally-asymmetric Hebbian learning in cortical neurons
can be interpreted as a fonn of temporal-difference learning, we used a two-compartment
model of a cortical neuron consisting of a dendrite and a soma-axon compartment. The compartmental model was based on a previous study that demonstrated the ability of such a
model to reproduce a range of cortical response properties [8] . The presence of voItageactivated sodium channels in the dendrite allowed back-propagation of action potentials
from the soma into the dendrite. To study plasticity, excitatory postsynaptic potentials (EPSPs) were elicited at different time delays with respect to postsynaptic spiking by presynaptic activation of a single excitatory synapse located on the dendrite. Synaptic currents were
calculated using a kinetic model of synaptic transmission with model parameters fitted to
whole-cell recorded AMPA currents (see [9] for more details). Synaptic plasticity was simulated by incrementing or decrementing the value for maximal synaptic conductance by an
amount proportional to the temporal-difference in the postsynaptic membrane potential at
time instants t + ~t and t - ~t for presynaptic activation at time t. The delay parameter
~t was set to 5 ms to yield results consistent with previous physiological experiments [2].
Presynaptic input to the model neuron was paired with postsynaptic spiking by injecting
a depolarizing current pulse (10 ms, 200 pA) into the soma. Changes in synaptic efficacy
were monitored by applying a test stimulus before and after pairing, and recording the EPSP
evoked by the test stimulus.
Figure I A shows the results of pairings in which the postsynaptic spike was triggered 5 ms
after and 5 ms before the onset of the EPSP respectively. While the peak EPSP amplitude
was increased 58.5% in the former case, it was decreased 49.4% in the latter case, qualitatively similar to experimental observations [2] . The critical window for synaptic modifications in the model depends on the parameter ~t as well as the shape ofthe back-propagating
action potential. This window of plasticity was examined by varying the time interval be5 ms). As shown in
tween presynaptic stimulation and postsynaptic spiking (with ~t
Figure IB, changes in synaptic efficacy exhibited a highly asymmetric dependence on spike
timing similar to physiological data [2]. Potentiation was observed for EPSPs that occurred
between I and 12 ms before the postsynaptic spike, with maximal potentiation at 6 ms. Maximal depression was observed for EPSPs occurring 6 ms after the peak of the postsynaptic
spike and this depression gradually decreased, approaching zero for delays greater than 10
ms. As in rat neocortical neurons, Xenopus tectal neurons, and cultured hippocampal neurons (see [2]), a narrow transition zone (roughly 3 ms in the model) separated the potentiation and depression windows.

=

R. P. N. Rao and T. J. Sejnowski

166

I~<

A

~,

before
:~

-----"
pairing

-

"-! i

:I .

IS

---.J ~

afler :

--'1

ISma
- -, - - r - - - -_ _ _ _

_ __J l__ _ ___
,

IS

~~

befote

15m.

IS
I>m.

-"'.J

....

after

I

:
I

~i
I~

~<

ISms

_____ - - - - - - r - - - -

:~
I

,
I

?

&

SI

S2

~
~

150

]-

100

.5

-50

B

i OO~

_ _ _J

~

c:

CU -100

.c
U

-40

20
o
Time of Synaptic Input (ms)

-20

40

Figure l: Synaptic Plasticity in a Model Neocortical Neuron. (A) (Left Panel) EPSP in the model
neuron evoked by a presynaptic spike (S 1) at an excitatory synapse ("before"). Pairing this presynaptic spike with postsynaptic spiking after a 5 ms delay ("pairing") induces long-term potentiation ("after"). (Right Panel) If presynaptic stimulation (S2) occurs 5 ms after postsynaptic firing. the synapse
is weakened resulting in a corresponding decrease in peak EPSP amplitude. (B) Critical window for
synaptic plasticity obtained by varying the delay between pre- and postsynaptic spiking (negative delays refer to presynaptic before postsynaptic spiking).

3 RESULTS
3.1

Learning Sequences using Temporally Asymmetric Hebbian Plasticity

To see how a network of model neurons can learn sequences using the learning mechanism
described above, consider the simplest case of two excitatory neurons N 1 and N2 connected
to each other, receiving inputs from two separate input neurons 11 and 12 (Figure 2A). Suppose input neuron 11 fires before input neuron 12, causing neuron Nl to fire (Figure 2B).
The spike from Nl results in a sub-threshold EPSP in N2 due to the synapse S2. If input
arrives from 12 any time between land 12 ms after this EPSP and the temporal summation
of these two EPSPs causes N2 to fire, the synapse S2 will be strengthened. The synapse S l,
on the other hand, will be weakened because the EPSP due to N2 arrives a few milliseconds
after Nl has fired. Thus, on a subsequent trial, when input 11 causes neuron Nl to fire, Nl
in turn causes N2 to fire several milliseconds before input 12 occurs due to the potentiation
of the recurrent synapse S2 in previous trial(s) (Figure 2C). Input neuron 12 can thus be inhibited by the predictive feedback from N2 just before the occurrence of imminent input
activity (marked by an asterisk in Figure 2C). This inhibition prevents input 12 from further
exciting N2. Similarly, a positive feedback loop between neurons Nl and N2 is avoided
because the synapse S 1 was weakened in previous trial(s) (see arrows in Figures 2B and
2C). Figure 2D depicts the process of potentiation and depression of the two synapses as a
function of the number of exposures to the 11-12 input sequence. The decrease in latency
of the predictive spike elicited in N2 with respect to the timing of input 12 is shown in Figure 2E. Notice that before learning, the spike occurs 3.2 ms after the occurrence of the input
whereas after learning, it occurs 7.7 ms before the input.

3.2

Emergence of Direction Selectivity

In a second set of simulations, we used a network of recurrently connected excitatory neurons as shown in Figure 3A receiving retinotopic sensory input consisting of moving pulses
of excitation (8 ms pulse of excitation at each neuron) in the rightward and leftward directions. The task of the network was to predict the sensory input by learning appropriate recurrent connections such that a given neuron in the network starts firing several milliseconds
before the arrival of its input pulse of excitation. The network was comprised of two parallel chains of neurons with mutual inhibition (dark arrows) between corresponding pairs of
neurons along the two chains. The network was initialized such that within a chain, a given

Predictive Sequence Learning in Recurrent Neocortical Circuits
A

167

D
SI

S2

Excitato ry Neuron N2

0 .03
6

Synapse S2

Input Neuron 11

r.

Input Neuron 12

Input I

B

66

Input 2

C

Before Learning

o

After Learning

?0000000000 0 000000

o

NI

10

20

30

40

Time (number of trials)

E
II

11

4
V)

?

??? ?

2

.. . . . ..

~

~j~
12

1

I~

N2

~~
15

illS

12

L

~

~~<
15

illS

..

0? ?

.::
.~

-2

"E

...d::

-4

0

;>, -6

... . ...

u

"

~

j

-8

0
~

..

10

20

30

40

Time (number of trials)

Figure 2: Learning to Predict using Temporally Asymmetric Hebbian Learning. (A) Network
of two model neurons Nl and N2 recurrently connected via excitatory synapses SI and S2, with input
neurons 11 and 12. Nl and N2 inhibit the input neurons via inhibitory interneurons (darkened circles).
(B) Network activity elicited by the sequence 11 followed by 12. (C) Network activity for the same
sequence after 40 trials of learning. Due to strengthening of recurrent synapse S2. recurrent excitation from Nl now causes N2 to fire several ms before the expected arrival of input 12 (dashed line).
allowing it to inhibit 12 (asterisk). Synapse SI has been weakened. preventing re-excitation of Nl
(downward arrows show decrease in EPSP). (D) Potentiation and depression of synapses S 1 and S2
respectively during the course of learning. Synaptic strength was defined as maximal synaptic conductance in the kinetic model of synaptic transmission [9]. (E) Latency of predictive spike in N2 during
the course of learning measured with respect to the time of input spike in 12 (dotted line).

excitatory neuron received both excitation and inhibition from its predecessors and successors (Figure 3B). Excitatory and inhibitory synaptic currents were calculated using kinetic
models of synaptic transmission based on properties of AMPA and GABAA receptors as
determined from whole-cell recordings [9]. Maximum conductances for all synapses were
initialized to small positive values (dotted lines in Figure 3C) with a slight asymmetry in
the recurrent excitatory connections for breaking symmetry between the two chains.
The network was exposed alternately to leftward and rightward moving stimuli for a total of
100 trials. The excitatory connections (labeled 'EXC' in Figure 3B) were modified according to the asymmetric Hebbian learning rule in Figure IB while the excitatory connections
onto the inhibitory interneuron (labeled 'INH') were modified according to an asymmetric
anti-Hebbian learning rule that reversed the polarity of the rule in Figure lB . The synaptic
conductances learned by two neurons (marked NI and N2 in Figure 3A) located at corresponding positions in the two chains after 100 trials of exposure to the moving stimuli are
shown in Figure 3C (solid line). Initially, for rightward motion, the slight asymmetry in

R. P N. Rao and T. J. Sejnowski

168

B

A

Recurrent Excitatory Connections (EXC)

l
-4

-3

-2

-I

()

2

4

Recurrent Inhibitory Connections (INH)

- - - Input Stimulus (Rightward)f----

c

Neuron NI

Neuron N2

EXC

-4

-3

-2

-l

()

2

4

D
Neuron NI

Neuron N2

(Right-Selective)

(Left-Selective)

~~
~~

Rightward

I11II111111

Motion

-.PJUL.
I11I I111111

Synapse Number

LLflward
Motion

Synapse Number

Figure 3: Direction Selectivity in the Model. (A) A model network consisting of two chains of
recurrently connected neurons receiving retinotopic inputs_ A given neuron receives recurrent excita-tiorrand recurrent inhibition (white-headed arrows) as well as inhibition (dark-headed arrows) from its
counterpart in the other chain_ (B) Recurrent connections to a given neuron (labeled '0') arise from
4 preceding and 4 succeeding neurons in its chain. Inhibition at a given neuron is mediated via a
GAB Aergic interneuron (darkened circle). (C) Synaptic strength of recurrent excitatory (EXC) and inhibitory (IN H) connections to neurons Nt and N2 before (dotted lines) and after learning (solid lines).
Synapses were adapted during 100 trials of exposure to alternating leftward and rightward moving
stimuli. (D) Responses of neurons Nt and N2 to rightward and leftward moving stimuli_ As a result
of learning, neuron N 1 has become selective for rightward motion (as have other neurons in the same
chain) while neuron N2 has become selective for leftward motion_ In the preferred direction, each
neuron starts firing several milliseconds before the actual input arrives at its soma (marked by an asterisk) due to recurrent excitation from preceding neurons_ The dark triangle represents the start of
input stimulation in the network.

the initial excitatory connections of neuron Nl allows it to fire slightly earlier than neuron
N2 thereby inhibiting neuron N2. Additionally, since the EPSPs from neurons lying on the
left of Nt occur before Nl fires, the excitatory synapses from these neurons are strengthened while the excitatory synapses from these same neurons to the inhibitory interneuron are
weakened according to the two learning rules mentioned above. On the other hand, the excitatory synapses from neurons lying on the right side ofNl are weakened while inhibitory
connections are strengthened since the EPSPs due to these connections occur after Nl has
fired. The synapses on neuron N2 and its associated interneuron remain unaltered since
there is no postsynaptic firing (due to inhibition by Nl) and hence no back-propagating action potentials in the dendrite. As shown in Figure 3C, after lOO trials, the excitatory and
inhibitory connections to neuron Nl exhibit a marked asymmetry, with excitation originating from neurons on the left and inhibition from neurons on the right. Neuron N2 exhibits
the opposite pattern of connectivity. As expected, neuron Nl was found to be selective for
rightward motion while neuron N2 was selective for leftward motion (Figure 3D). Moreover, when stimulus motion is in the preferred direction, each neuron starts firing several
milliseconds before the time of arrival of the input stimulus at its soma (marked by an asterisk) due to recurrent excitation from preceding neurons. Conversely, motion in the nonpreferred direction triggers recurrent inhibition from preceding neurons as well as inhibition

169

Predictive Sequence Learning in Recurrent Neocortical Circuits

Monkey Data

5~

__

.

~'~?~?u'~'~"_'~~

...?

.

~

.?

~3-

..

~

'Cd . . . . - , . .

_~_~_~~

rftr_-4

:dc'

............

tH1?

?

..

'

--....

?... - ...
p.!i! ,.. '. .
~

Model

____~'=
_____?_?

n.

sO' rtn

h

n ...

+

j,
~~.~ : ?jHT!:%??:
;
Q)

? ? _.

r ~.; "::n:;
;,::= :: : ::
em
6ft. 1'b'1

.....

Q. en 1

??
?

~

~

C\I

?

.

6
Stimylus

_.

0..

-",.,
? .......
_?h.e

r-'
lime (rLonds)

1?~

row
+.+'
h,

=f-

d

"'d

n h 'ft.

. . . . . . . . . 'h,tr

' ,

hzc+ no

d

??

IL ? ?

-

g

~

.

.

-

'hz ? ?

~
;::I:;
~I~

N

0

d

+

te-

_ _ _ _ _ _ _ _~

-----

stimulus

50

time (ms)

100

.......

Figure 4: Comparison of Monkey and Model Space-Time Response Plots. (Left) Sequence of
PSTHs obtained by flashing optimally oriented bars at 20 positions across the 50 -wide receptive field
(RF) of a complex cell in alert monkey V1 (from [11)). The cell's preferred direction is from the part
of the RF represented at the bottom towards the top. Flash duration = 56 ms; inter-stimulus delay =
100 ms; 75 stimulus presentations. (Right) PSTHs obtained from a model neuron after stimulating the
chain of neurons at 20 positions to the left and right side of the given neuron. Lower PSTHs represent
stimulations on the preferred side while upper PSTHs represent stimulations on the null side.

from the active neuron in the corresponding position in the other chain. Thus, the learned
pattern of connectivity allows the direction selective neurons comprising the two chains in
the network to conjointly code for and predict the moving input stimulus in each direction.
The average firing rate of neurons in the network for the preferred direction was 75.7 Hz,
which is in the range of cortical firing rates for moving bar stimuli. Assuming a 200 /-tm
separation between excitatory model neurons in each chain and utilizing known values for
the cortical magnification factor in monkey striate cortex, one can estimate the preferred
stimulus velocity of model neurons to be 3.1 ? Is in the fovea and 27.9? Is in the periphery (at
an eccentricity of 8?). Both of these values fall within the range of monkey striate cortical
velocity preferences [11].
The model predicts that the neuroanatomical connections for a direction selective neuron
should exhibit a pattern of asymmetrical excitation and inhibition similar to Figure 3C. A
recent study of direction selective cells in awake monkey VI found excitation on the preferred side of the receptive field and inhibition on the null side consistent with the pattern of
connections learned by the model [11] . For comparison with this experimental data, spontaneous background activity in the model was generated by incorporating Poisson-distributed
random excitatory and inhibitory alpha synapses on the dendrite of each model neuron. Post
stimulus time histograms (PSTHs) and space-time response plots were obtained by flashing
optimally oriented bar stimuli at random positions in the cell's activating region. As shown
in Figure 4, there is good qualitative agreement between the response plot for a complex cell
and that for the model. Both space-time plots show a progressive shortening of response
onset time and an increase in response transiency going in the preferred direction: in the
model, this is due to recurrent excitation from progressively closer cells on the preferred
side. Firing is reduced to below background rates 40-60 ms after stimulus onset in the upper part of the plots: in the model, this is due to recurrent inhibition from cells on the null
side. The response transiency and shortening of response time course appears as a slant in
the space-time maps, which can be related to the neuron's velocity sensitivity [11].

R. P. N. Rao and T. J. Sejnowski

170

4

CONCLUSIONS

Our results show that a network of recurrently connected neurons endowed with a temporaldifference based asymmetric Hebbian learning mechanism can learn a predictive model of
its spatiotemporal inputs. When exposed to moving stimuli, neurons in a simulated network learned to fire several milliseconds before the expected arrival of an input stimulus
and developed direction selectivity as a consequence of learning. The model predicts that a
direction selective neuron should start responding several milliseconds before the preferred
stimulus enters its retinal input dendritic field (such predictive neural activity has recently
been reported in retinal ganglion cells [10)). Temporally asymmetric Hebbian learning has
previously been suggested as a possible mechanism for sequence learning in the hippocampus [4] and as an explanation for the asymmetric expansion of hippocampal place fields
during route learning [12]. Some of these theories require relatively long temporal windows of synaptic plasticity (on the order of several hundreds of milliseconds) [4] while others have utilized temporal windows in the millisecond range for coincidence detection [3].
Sequence learning in our model is based on a window of plasticity in the 10 to 15 ms range
which is roughly consistent with recent physiological observations [2] (see also [13)). The
idea that prediction and sequence learning may constitute an important goal of the neocortex
has previously been suggested in the context of statistical and information theoretic models
of cortical processing [4, 5,6]. Our biophysical simulations suggest a possible implementation of such models in cortical circuitry. Given the universality ofthe problem of encoding
and generating temporal sequences in both sensory and motor domains, the hypothesis of
predictive sequence learning in recurrent neocortical circuits may help provide a unifying
principle for studying cortical structure and function.

References
[1] R. 1. Douglas et al., Science 269, 981 (1995); H. Suarez et aI., 1. Neurosci. 15,6700 (1995);
R. Maex and G. A. Orban, 1. Neurophysiol. 75, 1515 (1996); P. Mineiro and D. Zipser, Neural
Comput. 10, 353 (1998); F. S. Chance et aI., Nature Neuroscience 2, 277 (1999).
[2] H. Markram et al., Science 275, 213 (1997); W. B. Levy and O. Steward, Neuroscience 8, 791
(1983); D. Debanne et aI., Proc. Natl. Acad. Sci. U.S.A. 91, 1148 (1994); L. I. Zhang et aI., Nature 395, 37 (1998); G. Q. Bi and M. M. Poo, 1. Neurosci. 18, 10464 (1998).
[3]

w. Gerstner et al., Nature 383, 76 (1996); R. Kempter et al., in Advances in Neural Info. Proc.

Systems 11, M. S. Kearns, S. A. Solla and D. A. Cohn, Eds. (MIT Press, Cambridge, MA, 1999),
pp. 125-131.
[4] L. F. Abbott and K. I. Blum, Cereb. Cortex 6, 406 (1996); W. Gerstner and L. F. Abbott, 1. Comput. Neurosci. 4, 79 (1997); A. A. Minai and W. B. Levy, in Proceedings of the 1993 World
Congress on Neural Networks II, 505 (1993).
[5] P. R. Montague and T. J. Sejnowski, Learning and Memory 1, 1 (1994); P. R. Montague et al.,
Nature 377, 725 (1995); w. Schultz et aI., Science 275, 1593 (1997).
[6] R. P. N. Rao and D. H. Ballard, Neural Computation 9, 721 (1997); R. P. N. Rao and D. H.
Ballard, Nature Neuroscience 2, 79 (1999); H. Barlow, Perception 27, 885 (1998).
[7] R. S. Sutton, Machine Learning 3, 9 (1988); R. S. Sutton and A. G. Barto, in Learning and Computational Neuroscience: Foundations of Adaptive Networks, M. Gabriel and J. W. Moore, editors (MIT Press, Cambridge, MA, 1990).

[8] Z. F. Mainen and T. 1. Sejnowski, Nature 382, 363 (1996).
[9] A. Destexhe et al., in Methods in NeurolUll Modeling, C. Koch and I. Segev, editors, (MIT Press,
Cambridge, MA, 1998).

[10] M.1. Berry et al., Nature 398,334 (1999).
[11] M. S. Livingstone, Neuron 20, 509 (1998).
[12] M. R. Mehta et aI., Proc. Natl. Acad. Sci. U.S.A. 94,8918 (1997).
[13] L. F. Abbott and S. Song, in Advances in Neural Info. Proc. Systems 1J, M. S. Keams, S. A. Solla
and D. A. Cohn, Eds. (MIT Press, Cambridge, MA, 1999), pp. 69-75.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

