query sentence: neural network computers
---------------------------------------------------------------------
title: 235-computational-efficiency-a-common-organizing-principle-for-parallel-computer-maps-and-brain-maps.pdf

nelson bower comput effici common organ principl parallel comput map brain map mark e. nelson jame m. bower comput neural system program divis biolog california institut technolog pasadena ca abstract well-known neural respons particular brain region spatial organ general principl develop relat structur brain map natur associ comput parallel comput map sort quit similar brain map aris comput distribut across multipl processor paper discuss relationship map comput comput suggest similar consider might also appli map brain introduct great deal effort experiment theoret neurosci devot record interpret spatial pattern neural activ varieti map pattern observ differ brain region presum pattern reflect someth natur neural comput carri region date howev general principl interpret structur brain map term properti associ comput field parallel comput analog map aris comput distribut across multipl processor case relationship comput eftkienc map comput better understood paper attempt relat map principl field parallel comput organ brain map map parallel comput basic idea parallel comput distribut comput workload singl task across larg number processor dongarra fox messina principl parallel comput potenti deliv comput power equival total comput power processor construct processor machin potenti deliv time comput power singl processor practic howev perform achiev alway less effici ideal perfect effici implement processor would give factor speed comput time ratio actual speedup ideal speedup serv measur effici parallel implement given comput one factor influenc overal perform way comput map onto avail processor effici particular map analyz term two princip factor load-bal communic overhead load-bal measur uniform comput work load distribut among avail processor communic overhead hand relat cost time communic inform processor parallel comput load imbal defin term averag calcul time per processor atjg maximum calcul time requir busiest processor maz tmaz atjg atjg communic overhead defin term maximum calcul time maximum communic time tcomm maz tcomm tcomm assum calcul communic phase comput overlap time case mani parallel comput relationship effici load-imbal communicaticn overhead given fox nelson bower load-imbal communic overhead small ineffici approxim sum contribut load-imbal communic overhead when attempt achiev maximum perform parallel comput programm tri find map minim combin contribut load-imbal communic overhead case accomplish appli simpl heurist fox other requir explicit use optim techniqu like simul anneal kirkpatrick even artifici neural network approach fox furmanski case optim tradeoff load imbal communic overhead depend certain properti comput thus differ type comput give rise differ kind optim map parallel comput exampl order illustr differ map give rise differ comput effici consid simul singl neuron use multicompart model approach segev simul model neuron divid larg number compart assum isopotenti compart repres equival electr circuit embodi inform local membran properti order updat voltag individu compart necessari know local properti well membran voltag neighbor compart model give rise system differenti equat follow form em membran capacit vi membran voltag compart 9k ek local conduct revers potenti coupl conduct neighbor compart when carri simul parallel comput compart processor processor assign respons updat subset compart nelson compart repres equival comput load load-imbal proport differ maximum averag number compart per processor if comput processor fulli interconnect communic channel communic overhead proport number interprocessor messag provid voltag neighbor compart if comput effici figur tradeoff load-imbal communic overhead give rise differ effici differ map multicompart neuron model minimum-cut map minim communic overhead suffer signific load-imbal scatter map minim load-imbal larg communic overhead near-optim map simultan minim load-imbal communic overhead neighbor compart map processor inform avail without interprocessor communic thus communic overhead incur show three differ way map compart neuron model onto group processor case load-imbal communic overhead calcul use assumpt list comput effici comput use eq map 1a minim communic overhead map make minimum number cut dendrit tree rather ineffici signific load-imbal remain even optim locat cut map hand minim load-imbal use scatter map techniqu fox ineffici larg communic overhead map 1c strike balanc load-imbal communic overhead result high comput effici thus particular map make best use avail comput resourc particular comput task nelson bower figur three class map topolog found brain rat continu map tactil input somatosensori cortex patchi map tactil input cerebellar cortex scatter map olfactori input olfactori cortex repres unstructur pattern 2dg uptak singl section cortex map brain sinc parallel comput map clear effici other particular problem seem natur ask whether similar relationship might hold brain map neural comput name given comput task one particular brain map topolog make effici use avail neural comput resourc anoth if impos signific constraint evolut develop brain map topolog turn strike similar kind map aris parallel comput type map observ brain case map pattern broad group three categori continu map patchi map scatter non-topograph map show exampl brain map fall categori 2a show exampl smooth continu map repres pattern affer tactil project primari somatosensori cortex rat welker patchi map 2b repres spatial pattern tactil project granul cell layer rat cerebellar hemispher shamb bower woolston final 2c repres extrem case brain region show appar topograph organ figur show pattern metabol activ one section olfactori piriform cortex assay 2-deoxyglucos uptak respons present particular odor sharp suggest uniform label cortex discern comput eftkienc odor-specif pattern found region cortex parallel comput map differ categori aris optim solut differ class comput continu map optim comput local problem space patchi map optim comput involv mixtur local non-loc interact scatter map optim near-optim comput character high degre interact throughout problem space especi if pattern interact dynam easili predict interest turn intrins neural circuitri associ differ kind brain map also reflect pattern interact brain region continu map like somatosensori cortex tend predomin local circuitri region patchi map like cerebellar cortex tend mixtur local non-loc circuitri region scatter map like olfactori cortex tend character wide-spread connect appar correspond brain map comput map rais general question whether correl load-imbal communic overhead nervous system general factor much difficult identifi quantifi brain parallel comput parallel comput system human-engin nervous system evolv set select criteria constraint know littl furthermor fundament differ in organ digit comput brain make difficult translat idea parallel comput direct neural equival nelson exampl far clear taken neural equival singl processor depend level analysi might a local region a dendrit entir neuron assembl mani neuron thus one must consid multipl level process in nervous system when tri draw analog parallel comput first consid issu load-balanc in brain map in smooth continu obvious quit distort in particular region repres lip whisker disproportion larg in comparison rest bodi turn similar map distort aris parallel comput as a result load-balanc if differ region problem space requir comput region load-bal achiev distort map each processor end equal share workload fox in brain map distort often explain variat in densiti peripher receptor howev recent shown in monkey prolong increas use a particular finger accompani expans correspond region map in somatosensori cortex merzenich presum a consequ a chang in peripher receptor densiti instead reflect a use-depend remap tactil comput onto avail cortic circuitri although map reorgan phenomena suggest load-balanc effect push analog far know actual 6s nelson bower correspond comput load in brain one possibl it associ metabol load aris in respons neural activ yarowski ingvar sinc metabol activ necessit deliveri adequ suppli oxygen glucos via a network small capillari effici use capillari system might favor map tend avoid metabol hot spot would overload deliveri capabl system when discuss communic overhead in brain also run problem know exact correspond communic cost parallel comput communic overhead usual associ time-cost exchang inform processor in nervous system import such time-cost probabl quit depend on behavior context comput evid exampl brain region actual make use transmiss delay process inform carr konishi howev there anoth aspect communic overhead may general applic space-cost physic connect processor togeth in design modern parallel comput in design individu comput processor chip space-cost associ interconnect pose a serious constraint design engin in nervous system extrem larg number potenti connect combin rather strict limit on cranial capac like make space-cost a import factor conclus view comput effici import constraint on organ brain map provid a potenti use new perspect interpret structur map although avail evid larg circumstanti it seem like the topolog a brain map affect the effici neural resourc util furthermor it seem reason assum network effici would impos a constraint on the evolut develop map topolog would tend favor map near-optim the comput task perform the substanti task us in the case the nervous system carri experi better understand the detail relationship brain map neural architectur associ comput bower acknowledg we would like acknowledg wojtek furmanski geoffrey fox the caltech concurr comput program cccp for parallel comput support we would also like to thank geoffrey for comment on an earlier version this manuscript this effort support the nsf the lockhe corpor the depart energi
----------------------------------------------------------------

title: 4718-analog-readout-for-optical-reservoir-computers.pdf

analog readout optic reservoir comput a. smerieri1 f. duport1 y. paquot1 b. schrauwen2 m. haelterman1 s. massar3 servic opera-photoniqu universit libr de bruxell avenu f. d. roosevelt cp bruxell belgium depart electron inform system eli ghent univers sint-pietersnieuwstraat ghent belgium laboratoir inform quantiqu universit libr de bruxell avenu f. d. roosevelt cp bruxell belgium abstract reservoir comput new power flexibl machin learn techniqu easili implement hardwar recent use timemultiplex architectur hardwar reservoir comput reach perform compar digit implement oper speed allow real time inform oper reach use optoelectron system present main perform bottleneck readout layer use slow digit postprocess design analog readout suitabl time-multiplex optoelectron reservoir comput capabl work real time readout built test experiment standard benchmark task perform better non-reservoir method ampl room improv present work therebi overcom one major limit futur develop hardwar reservoir comput introduct term reservoir comput encompass rang similar machin learn techniqu independ introduc h. jaeger w. maass techniqu differ implement detail share core idea one leverag dynam recurr nonlinear network perform comput time depend signal without train network done simpli ad extern general linear readout layer train instead result power system outperform techniqu rang task exampl one report signific easier train recurr neural network furthermor quit easili implement hardwar although recent hardwar implement perform compar digit implement report one great advantag techniqu place almost requir structur recurr nonlinear network topolog network well characterist nonlinear node left user requir network suffici high dimension suitabl rich dynam last requir essenti mean dynam allow explor larg number network state new input come time retain finit time inform previous input reason reservoir comput appear literatur use wide differ nonlinear unit see exampl particular time multiplex architectur propos optic reservoir comput particular promis provid altern path optic comput could leverag inher high speed parallel grant optic without need strong nonlinear interact need mimic tradit electron compon recent optoelectron reservoir comput demonstr differ research team conjug good comput perform promis high oper speed howev one major drawback experi well preced one absenc readout mechan reservoir state collect comput post-process digit sever limit process speed obtain henc applic analog readout experiment reservoir would remov major bottleneck point modular characterist reservoir comput impli hardwar reservoir readout optim independ parallel moreov analog readout open possibl feed back output reservoir reservoir turn allow use differ train techniqu appli reservoir comput new categori task pattern generat paper present propos readout mechan opto-electron reservoir use optoelectron intens modul design propos drastic cut oper time special case long input sequenc our propos suit optoelectron all-opt reservoir concept easili extend experiment time-multiplex reservoir comput mechan test experiment use experiment reservoir report compar digit readout although result preliminari promis good report howev alreadi better non-reservoir method task reservoir comput time multiplex principl reservoir comput main compon reservoir comput recurr network nonlinear element usual call node neuron system typic work discret time state node time step function input valu time step state neighbor node previous time step network output generat readout layer set linear node provid linear combin instantan node state fix coeffici equat describ evolut reservoir comput wij state i-th node discret time total number node reservoir input time mi wij connect coeffici describ network topolog two paramet regul network dynam nonlinear function one general tune favor dynam input treat inject reservoir network output construct use set readout weight wi bias weight wb wi wb train reservoir comput involv readout layer consist find best set readout weight wi bias wb minim error desir output actual network output unlik convent recurr neural network figur scheme experiment setup includ optoelectron reservoir input reservoir layer analog readout output layer red green part repres respect optic electron compon arbitrari waveform generat lin bo3 mach-zehnd modul feedback photodiod amplifi scope ni pxi acquisit card strength connect mi wij left untouch output layer made linear unit given full set reservoir state time step train procedur basic regular linear regress time multiplex number node reservoir comput determin upper limit reservoir perform obstacl design physic implement rcs contain high number interconnect nonlinear unit solut problem propos time multiplex comput one one singl nonlinear element receiv combin input previous state addit input mask mi appli input enrich reservoir dynam valu store delay line use later time step interact differ neuron provid either slow nonlinear element coupl state previous state use instantan nonlinear element desynchron input respect delay line hardwar rc digit readout hardwar reservoir comput use present work ident one report also use time-multiplex desynchronis techniqu describ previous paragraph give brief descript experiment system repres left part figur use lin bo3 mach-zehnd modul oper constant power nm laser nonlinear compon mz modul voltag control optoelectron devic amount light transmit sine function voltag appli result state encod light intens level mz output store spool optic fiber act delay line durat while subsequ state comput mz modul when state reach end fiber spool convert voltag photodiod input multipli input mask mi encod voltag level arbitrari waveform generat two voltag correspond state end fiber spool input mi ad amplifi result voltag use drive mz modul therebi produc state valu experi report portion light come mz deviat second photodiod shown figur convert it voltag send it digit oscilloscop mach-zehnd output repres step light intens durat figur one repres valu singl node state discret time valu recov take averag measur voltag state time step optim readout weight wi bias wb calcul comput subset train set record state use ridg regress output calcul use equat state collect perform reservoir calcul compar reservoir output desir output analog readout readout scheme develop analog readout reservoir comput describ section mean design devic multipli reservoir state shown figur 2a readout weight wi sum togeth way reservoir output retriev direct output howev straightforward sinc obtain good perform requir posit negat readout weight wi optic implement state encod light intens alway posit they subtract one anoth moreov summat state must includ valu pertain discret time step reject valu this difficult time-multiplex reservoir state xn follow seamless here show resolv difficulti use scheme depict right panel figur reservoir state encod light intens optic reservoir comput repres figur 2a fed input second mz modul two output second function generat govern bias second mach-zehnd provid modul voltag modul voltag control much input light pass readout mach-zehnd sent output keep constant sum two output intens two output connect two input balanc photodiod turn give output voltag level proport differ light intens receiv it two inputs1 this allow us multipli reservoir state posit negat weight time averag output voltag photodiod obtain use capacitor characterist time analog integr proport capac role this time scale includ readout output pertin contribut exclud other final output reservoir voltag across capacitor end discret time what follow detail descript readout design multipl arbitrari weight multipl reservoir state arbitrari weight posit negat realiz second mz modul follow balanc photodiod modul voltag drive second mach zehnder piecewis constant step durat equal durat reservoir state transit voltag reservoir state synchron modul voltag also period function period reservoir state pair voltag level vi depend light intens o1 o2 two output mach-zehnd modul balanc photodiod consist two photodiod convert two light intens two electr current follow electron circuit produc output voltag proport differ two current case imped coaxial cabl match output imped photodiod rc o1 cos v vbia o2 cos v vbia light intens come reservoir vbia constant voltag drive modul arbitrari constant phase valu half-wav voltag modul neglect effect bandpass filter photodiod choos vbia appropri output photodiod written o2 sin i w constant gain factor in word set right bias drive modul voltag multipli signal arbitrari coeffici note piecewis constant well this allow us achiev multipl state encod in light intens weight wi choos right voltag shown in figur summat weight state achiev summat state pertain discret time step accord equat give us reservoir output minus bias wb use capacitor right side the output layer in figur the capacitor provid the integr the photodiod output given eq exponenti kernel time constant if signific less the amount time need the system process the node relat singl time step minim the crosstalk node state relat differ time step let us consid the input the readout let the instant the state the first node given discret time step begin encod in use equat we write the voltag the capacitor time i w ds we integr equat yield equat show time the voltag the capacitor linear combin the reservoir state the discret time node-depend coeffici plus residu the voltag time multipli extinct coeffici at time the voltag the capacitor would linear combin the state discret time multipli the coeffici plus a residu the voltag at time for valu correspond multipl a simpl procedur would encod the weight onto the voltag drive the modul provid extern constant bias wb the output the reservoir defin equat effect encod the capacitor this simpl procedur would howev unsatisfactori unavoid the would small therefor the would larg span sever order magnitud this undesir it requir a veri precis control the modul voltag in order recreat the valu leav the system vulner nois to non-id behavior the modul a readout output voltag voltag time figur reservoir output the gray line repres the output as measur a photodiod an oscilloscop we indic for
----------------------------------------------------------------

title: 256-performance-of-connectionist-learning-algorithms-on-2-d-simd-processor-arrays.pdf

nunez fort perform connectionist learn algorithm simd processor array fernando j. nunez jose a.b fort school electr engin purdu univers west lafayett abstract map back-propag mean field theori learn algorithm onto generic simd comput describ architectur prove adequ applic sinc effici close optimum attain express find learn rate given particular dap array procesor introduct digit simul connectionist learn algorithm flexibl accur howev except small network convent comput architectur spend lot time execut simul softwar parallel comput use reduc execut time vectorpipelin multiprocessor array processor import class parallel comput connectionist neural net learn algorithm map onto focus contribut map back-propag mean field theori mft learn algorithm onto subclass simd comput processor arrang squar two-dimension mesh interconnect nearest-neighbor link materi organ follow section execut cost bp mft sequenti comput found two-dimension simd processor array describ section cost two domin oper simul deriv section map bp mft i omment current address motorola inc algonquin schaumburg il perform connectionist learn algorithm express learn rate obtain express particular dap comput section section conclud work back-propag mean field theori paper two learn algorithm bp mft4 3-layer net consid number neuron input hidden output layer i respect bp use mani applic probabl nettalk8 best known mft also use learn arbitrari map two set remark find approxim solut hard optim problem much effici boltzmann machin vj output ajjvj neuron denot vi call valu oj summat repres net input receiv j'l j call activ neuron thresold oj sigmoid-lik function appli find valu weight link neuron neuron ajj sinc input pattern valu i layer neuron valu activ hand layer must comput bp activ error valu error hand layer calcul use chang weight convent comput execut time bp approxim time spent find activ back-propag activ error layer modifi i-h h-o weight result tm time requir perform multiply/accumul oper sinc net i o h connect learn rate connect per second fnbp cps mft algorithm neuron valu equilibrium end clamp free anneal phase comput weight increment assum phase anneal temperatur nd iter enough reach equilibrium temperatur these chang mft determinist algorithm ann ling phase compos ae sweep mft execut time apprl jmate time spent comput activ anneal loop j ing account clamp phase layer updat tha free phase hand layer chang valu mft lean perform found ft tmft tbp ae cps mft ae time expens bp howev learn qualiti algorithm differ direct cop'tjarison simplist nunez fort simd processor array two-dimension singl instruct multipl data stream simd comput effici simul nn learn algorithm provid massiv parallel low cost simd comput array process element pes execut instruct cycl singl control unit broadcast instruct pes simd architectur oper synchron lock-step fashion they also call array procesor raison cfetr oper vector matric exampl simd comput illiac-iv massiv parallel processor connect machin distribut array processor except cm whose pe interconnect topolog hypercub three machin sthad array pes interconnect mesh wrap-around link figur control unit pp figur simd processor array pe local memori instruct address field access array memori space seen volum volum generat pe plane depth number memori word pe address when control unit issu address plane memori volum referenc then squar block pxp element natur address unit sthad processor array activ bit regist pe disabl execut instruct use perform oper subset pes assum perform connectionist learn algorithm overlap data process data move oper word pes either perform oper data includ access local memori exchang data processor map two basic oper it characterist array processor way data alloc pes memori import effect perform purpos two data structur must consid vector matric storag vector illustr figur there two mode row column vector split p-element subvector store memori plane larg vector requir two plane storag matric also simpl they must divid squar pxp block figur shade figur indic general size vector matric fit array dimens perfect row iij column figur vector matrix storag execut time bp mft simd comput spent almost complet matrix-vector multipli mvm vector outer multiply/accumul vom oper they decompos follow simpler oper involv pxp block addit eij aij bij point multiply/accumul a-b e'ij eij aijb ij unit rotat result block element origin rotat one place one four possibl direct s row column broadcast result row column broadcast vector store row column mode block xii xj xi time requir execut denot tll tm t6 respect next let us see oper ax mvm decompos simpler step use oper assum yare p-element vector pxp block nunez fort row-broadcast vector point multipli x row addit block yi f'llij aijxj j-l requir flog2pl step step multipl rotat one addit perform figur show eight valu row ad use recurs doubl techniqu note number rotat doubl step cost pt log2pto row addit ineffici oper larg cost due communic fortun larger data import diminish use schedul describ next figur recurs doubl suppos dimens mp np nxm respect then ax must partit sequenc nonpartit block oper one explain write aijxj aij xj u aij.xj u this express repres i-th i-th p-element subvector respect ij pxp block indic block result row-broadcast store row mode final vector p-element equal note second term column addit implicit one requir third term block instead vector accumul sinc subvector subvector broadcast total cost mvm oper mter similar develop cost yom yx oper perform connectionist learn algorithm number neuron layer integ multipl storag execut effici decreas this effect less import larg network learn rate simd comput back-propag neuron val~ activ valu error activ error thresold hand layer organ vector weight group two matric i-h h-o then scalar oper origin algorithm transform matrix-vector oper size input hidden output layer ip hp op comment execut time most spent comput activ valu error chang weight comput activ back-propag activ error layer mvm oper perform chang weight requir yom oper alter substitut express previous section time requir learn pattern simul bp simd comput time spent data communic given factor tr larger they smaller effici array processor fast broadcast facil net larg enough term array dimens effici grow sinc smaller fraction total execut time dedic move data sinc net i o hp2 connect learn rate p2 time greater use singl pe i nsimd-bp cps mean field theori oper outsid anneal loop neglect small error consequ comput activ in clamp free anneal phase account o ptr log2pta under favor condit mention learn rate simd-mft i cps nunez fort learn perform on dap dap commerci simd processor array develop lcl it massiv parallel comput bit-level pes built around a single-bit full adder in addit pe interconnect mesh there row column broadcast buse allow direct transfer data from processor row column an edg regist mani instruct requir a singl clock cycl lead effici code loop bodi comput featur pes a maximum local memori 1mbit per pe pes maximum local memori 64kbit the clock cycl in machin nsl bit-level processor it possibl tailor the precis fixed-point comput the minimum requir the applic the cost in cycl requir sever basic oper given these express function the number bit the operand assum the bit the time requir the dap perform a block addit point multiplication/accumul broadcast tm 2b t6 8b clock cycl respect on the hand 2b log2p cycl the durat a row addit let us take bit ae this valu found adequ in mani applic then the maximum learn rate the mcps bp mft mcps mcps cps these figur time smaller for the it worth mention the perform decreas quadrat the two learn rate each algorithm correspond the worst best case topolog exampl let us consid a one-thousand neuron net neuron in the input hidden output layer for the the paramet the use after substitut we see the communic cost less the total demonstr the effici the dap in this type applic the learn rate bp mcps mft mcps nettalk frequent use a benchmark in order compar the perform achiev on differ comput here a network similar dimens consid input hidden output neuron these dimens fit perfect the sinc a data precis bit taken howev the fact the input pattern binari exploit obtain save the perform reach in this case mcps even though nettalk a relat small network the total execut time spent in data communic if the use somewhat less mcps would learnt sinc the output layer smaller caus ineffici perform connectionist learn algorithm final bp learn rate the with operand compar obtain machin comput vax cray-2 cm pes bit bit mcps conclus two-dimension sthfl array processor veri adequ for the simul connectionist learn algorithm like bp mft these architectur execut at near optimum speed if the network larg enough there full connect layer other much cost parallel architectur outperform the map approach describ in this paper easili extend network topolog with dens block in global interconnect matrix howev it is obvious simd array a good option to simul network with random spars connect acknow ledgement this work support the ministri educ and scienc spain
----------------------------------------------------------------

title: 2571-using-machine-learning-to-break-visual-human-interaction-proofs-hips.pdf

use machin learn break visual human interact proof hip kumar chellapilla microsoft research one microsoft way redmond wa kumarc microsoft.com patric y. simard microsoft research one microsoft way redmond wa patric microsoft.com abstract machin learn often use automat solv human task paper look task machin learn algorithm good human hope gain insight current limit studi various human interact proof hip market system design tell comput human apart pose challeng presum hard comput found hip pure recognit task easili broken use machin learn harder hip use combin segment recognit task observ found build segment task effect way confus machin learn algorithm enabl us build effect hip deploy msn passport well design challeng segment task machin learn algorithm rod ct ocr problem high resolut print text virtual solv year ago hand cursiv handwrit recognit today still poor peopl reli fundament differ two seem similar problem shed light question studi problem design difficult comput hope get insight stumbl block machin learn devis appropri test understand similar differ work distinguish comput human trace back origin ture test ask human distinguish anoth human machin ask question recent interest turn develop system allow comput distinguish anoth comput human system enabl construct automat filter use prevent autom script util servic intend human system term human interact proof hip complet autom public ture test tell comput human apart captcha overview work area found construct hip practic valu difficult suffici develop challeng human somewhat success machin cost failur automat attack minim compar cost failur human ideal hip solv human time automat script reason resourc use succeed less time latter ratio function cost automat trial divid cost human perform attack constraint generat task fail time autom algorithm generat various solut easili sampl internet seven differ hip name mailblock msn april ticketmast yahoo yahoo v2 regist googl given exampl next section show section machinelearning-bas attack far success yet hip harder other could made even harder identifi recognit segment part emphas latter section present exampl difficult hip much respect challeng machin learn yet surpris easi human final section discuss known weak machin learn algorithm suggest design simpl artifici dataset studi weak exa mp les i ps hip explor paper made charact symbol render imag present user solv hip requir identifi charact correct order follow hip sampl web mailblock while sign free email servic www.mailblocks.com find hip challeng type mailblock msn while sign free e-mail msn hotmail www.hotmail.com find hip challeng type register.com while request whoi lookup domain www.register.com hip challeng type yahoo /ez-gimpi while sign free e-mail servic yahoo www.yahoo.com receiv hip challeng type yahoo version start august yahoo introduc second generat hip three exampl present ticketmast while look concert ticket www.ticketmaster.com receiv hip challeng type google/gmail while sign free e-mail gmail www.google.com one receiv hip challeng type while solut yahoo hip common english word ticketmast googl necessarili belong english dictionari appear creat use phonet generat usi ch lea rn rea ip break hip new mori malik success broken ezgimpi success gimpi success hip cmu approach aim automat process solv multipl hip minimum human intervent use machin learn paper main goal learn common strength weak hip rather prove break one hip particular highest possibl success rate result six differ hip ez-gimpy/yahoo yahoo mailblock regist ticketmast googl simplifi studi use languag model attempt break hip exampl word ez-gimpi dictionari mean random guess attack would get success rate enough break hip greater success hip becom harder languag model use similar hip use languag model generat challeng success rate attack signific improv incorpor languag model further sinc languag model common hip studi use paper our generic method break hip write custom algorithm locat charact use machin learn recognit surpris segment find charact simpl mani hip make process break hip particular easi gimpi use singl constant predict color black letter even though background color chang quick realiz segment problem solv solv hip becom pure recognit problem trivial solv use machin learn our recognit engin base neural network yield error rate mnist databas use littl memori fast recognit import break hip hip segment step follow recognit step stress tri solv everi hip given type our goal success rate someth effici achiev much better follow experi hip hand label use follow recognit train valid test segment test segment five hip convolut neural network ident one describ train test gray level charact imag center guess charact posit train neural network becam recogn oc solv hip select red channel binar erod extract largest connect compon breakup ccs larg two three adjac ccs further vertic overlap half charact size ccs merg result rough segment work time here exampl instanc exampl nn would train test follow imag end-to-end success rate segment recognit given correct segment total note error come segment even though custom program invest regist procedur solv hip similar imag smooth binar largest connect compon identifi two exampl present end-to-end success rate segment recognit given correct segment total oo mp unlik mailblock regist hip yahoo/ez-gimpi hip richer varieti background clutter possibl though amount text warp present text color size font low variabl three simpl segment algorithm design associ rule identifi algorithm use goal keep simpl yet effect no mesh convert grayscal imag threshold black white select larg ccs size close hip char size one exampl black mesh convert grayscal imag threshold black white remov vertic horizont line pixel neighbor pixel select larg ccs size close hip char size one exampl white mesh convert grayscal imag threshold black white add black pixel white line locat exist neighbor pixel select larg ccs size close hip char size one exampl test black white mesh perform determin segment algorithm use end-to-end success rate segment came recognit given correct segment total averag length yahoo hip solut charact procedur solv yahoo hip fair success solv ticket master hip hip character cris-cross line random angl cluster around degre multiprong attack yahoo case section potenti interest simplic singl attack develop convert grayscal threshold black white up-sampl imag dilat first erod select larg ccs size close hip char size one exampl dilate-erod combin caus line remov along thin object retain solid thick charact singl attack success achiev end-to-end success rate segment recognit rate spite interf line total averag hip solut length charact oo second generat hip yahoo sever chang use word dictionari even use phonet generat use black white color use letter digit use connect line arc clutter hip somewhat similar msn/passport hip use dictionari use two color use letter digit background foreground arc clutter unlik msn/passport hip sever differ font use singl segment attack develop remov pixel border up-sampl dilat first erod select larg ccs size close hip char size attack practic ident use ticketmast hip differ preprocess stage slight modifi paramet two exampl singl attack success achiev end-to-end success rate segment recognit rate total averag hip solut length charact oog googl hip uniqu use imag warp mean distort charact similar msn/passport yahoo version hip also two color hip charact arrang close one anoth often touch follow curv baselin follow simpl attack use segment googl hip convert grayscal up-sampl threshold separ connect compon this simpl attack give end-to-end success rate segment recognit rate give total probabl break hip averag googl hip solut length charact this signific improv upon judici use dilate-erod attack direct applic well it ticketmast yahoo hip shear warp baselin word success complic attack might estim counter shear warp baselin achiev better success rate lesso lea rn ed ro rea ki ip previous section it clear error come incorrect segment even though develop time spent devis custom segment scheme this observ rais follow question whi segment hard problem devis harder hip dataset build automat segmentor compar classif algorithm base use they segment ob review segment difficult follow reason segment comput expens order find valid pattern recogn must attempt recognit mani differ candid locat segment function complex segment success system must learn identifi pattern valid among set possibl valid non-valid pattern this task intrins more difficult classif space input consider larger unlik space valid pattern space non-valid pattern typic vast sampl this problem mani learn algorithm yield mani fals posit present non-valid pattern identifi valid charact among set valid invalid candid combinatori problem exampl correct identifi charact among candid assum fals posit in choos chanc success random guess ui te de i use learn build better hip instanc hip design make segment difficult similar version deploy msn passport hotmail registr www.hotmail.com idea addit arc good candid fals charact previous segment attack would fail this hip furthermor simpl chang font distort arc type would requir extens work attack adjust we believ hip emphas segment problem as exampl much stronger hip we examin in this paper reli recognit difficult push this extrem we easili generat the follow hip despit the appar difficulti hip human surpris good solv these indic human far better comput segment this approach ad sever compet fals posit can in principl use automat creat difficult segment problem benchmark test classif algorithm ui ut build automat segmentor we could use the follow procedur label charact base correct posit train recogn appli the train recogn locat in the hip imag collect candid charact identifi high confid the recogn comput the probabl combin candid go from left right output the solut string the highest probabl this better illustr exampl consid the follow hip the right the train neural network these map warm color indic recognit show correct identifi howev the map show sever fals posit in general we would get the follow color code map the differ candid hip threshold the network output the map obtain we note sever fals posit true posit the number fals posit per true posit charact found give in in random chanc guess the correct segment the hip charact these number can improv upon constrain solut string flow sequenti from left right restrict overlap combin we comput probabl multipli the probabl the classifi for posit the combin the highest probabl the one propos the classifi we result for an automat segmentor this time it interest note such a method a classifi robust to fals posit would far better one this suggest anoth axi for compar classifi con clu si in this paper we success appli machin learn to the problem solv hip we learn decompos the hip problem segment recognit great simplifi analysi recognit even unprocess imag given segment a solv can done automat use neural network segment the hand is the difficulti differenti weaker stronger hip requir custom intervent for hip we use this observ to design new hip new test for machin learn algorithm the hope improv a ow ge we would like to acknowledg chau luu eric meltzer for help with label segment various hip we would also like to acknowledg josh benaloh cem paya for stimul discuss on hip secur
----------------------------------------------------------------

title: 383-back-propagation-implementation-on-the-adaptive-solutions-cnaps-neurocomputer-chip.pdf

back propag implement adapt solut cnap neurocomput chip hal mccartor adapt solut inc. n.w compton drive suit beaverton abstract adapt solut cn ap architectur chip general purpos neurocomput chip it processor byte local memori run megahertz it capabl implement current neural network algorithm chip learn paper discuss implement back propag algorithm array chip show perform figur clock accur hardwar simul eight chip configur one board updat billion connect per second learn mode process billion connect per second feed forward mode introduct huge comput requir neural network natur parallel led number interest hardwar innov execut network investig creat larg parallel comput special purpos chip limit small subset algorithm adapt solut cnap architectur describ general-purpos 64-processor chip support chip learn capabl implement most current algorithm implement popular back propag algorithm demonstr speed versatil new chip back propag implement hardwar resourc adapt solut cnap architectur embodi singl chip digit neurocomput processor run megahertz processor receiv instruct condit execut multipl addit perform parallel allow billion inner product step per second per chip processor adder 9-bit multipli two clock cycl shifter logic unit regist byte ofloc memori input output accomplish 8-bit input output buse common processor output bus tie input bus output one processor broadcast other when multipl chip use appear user one chip processor special circuit support find maximum valu held processor conserv weight space spars connect network accompani sequenc chip control instruct flow input output back propag algorithm implement three critic issu must address parallel implement bp effici hardwar these avail weight valu back propag error scale precis comput effici implement output transfer function bp requir weight valu differ node feed forward back propag phase comput problem solv second set weight transpos output layer weight these locat hidden node processor two matric updat ident input hidden layer weight matrix use error propag duplic bp implement typic use float point math larg elimin scale precis dynam rang issu effici hardwar implement dictat integ arithmet unit precis greater requir baker shown integ weight suffici bp train much lower valu adequ use train fix point integ math posit binari point must chosen this implement weight bit use bit right binari point four left includ sign bit they rang input output repres 8-bit unsign integ binari point left lean rate repres 8-bit integ two bit left binari point valu rang error repres bit sign integ output layer represent weight hidden layer this data represent use train benchmark bp applic result compar float point version bp sigmoid output function implement 8-bit lookup tabl dure forward pass input valu broadcast processor chip via input bus hidden node via output bus input bus dure mccartor backward error propag error valu broadcast output node hidden node typic bp network two comput layer the hidden output layer they assign the differ processor node pn depend avail memori weight pns use the hidden layer contain the transpos weight the output layer back propag error if momentum period weight updat use addit storag space alloc weight this implement bp map set contigu processor allow multipl network cnap memori simultan thus the output one algorithm direct use input anoth instanc speech recognit fourier transform perform the pn array could input seri match bp network whose hidden layer run concurr their output could direct an lvq2 network final classif this all accomplish without intermedi result leav the chip array result bp network success run hardwar clock accur simul give the follow time result this exampl an eight-chip implement processor use the network input hidden node output weight updat each input momentum use the follow calcul show bp perform train phase overhead clock cycl per input vector cycl per input vector element cycl per hidden node cycl per output node cycl per vector vector per second total forward weight weight updat per second feed forward onli overhead cycl per input vector cycl per input vector element cycl per hidden node cycl per output node output data cycl per vector vector per second connect per second back propag implement compar perform an array eight adapt solut cn ap chip would execut the preced bp network billion train weight updat per second or billion feed forward connect per second these result compar with the result comput shown in tabl machin sun ld88j sale sigma-lld88j warp cray lpgtk88j cray x-mp ld88j lwz89j adapt cn ap chip mcup mcps wts fp fp fp fp fp fp fp bit int tabl comparison bp perform various comput adapt solut cnap chip one board mcup million bp connect updat per second in train mode mcps million connect process per second in feed forward mode wts represent use for weight summari the adapt solut cn ap chip fast general purpos digit neurocomput chip it capabl execut the back propag algorithm quit effici an chip configur train billion connect per second evalu billion bp feed forward connect per second
----------------------------------------------------------------

title: 6261-visual-question-answering-with-question-representation-update-qru.pdf

visual question answer question represent updat qru ruiyu li jiaya jia chines univers hong kong ryli leojia cse.cuhk.edu.hk abstract method aim reason natur languag question visual imag given natur languag question imag model updat question represent iter select imag region relev queri learn give correct answer model contain sever reason layer exploit complex visual relat visual question answer vqa task propos network end-to-end trainabl back-propag weight initi use pre-train convolut neural network cnn gate recurr unit method evalu challeng dataset coco-qa vqa yield state-of-the-art perform introduct visual question answer vqa new research direct intersect comput vision natur languag process develop stabl system vqa attract increas interest multipl communiti possibl applic includ bidirect image-sent retriev human comput interact blind person assist etc still difficult problem due mani challeng visual object recognit ground natur languag represent common sens reason recent propos vqa model base imag caption method advanc great success deep learn build languag model imag classif visual object detect compar imag caption plausibl descript produc given imag vqa requir algorithm give correct answer specif human-rais question regard content given imag complex research problem sinc method requir answer differ type question exampl relat imag content color also question requir extra knowledg commonsens reason doe appear raini proper model question essenti solv vqa problem common employ strategi use cnn rnn extract semant vector general issu result question represent lack detail inform given imag howev vital understand visual content take question imag figur exampl answer origin question sit amongst thing abandon one need know target object locat thus question specif what discard side build near old book shelf paper propos neural network base reason model abl updat question represent iter infer imag inform new system possibl make question specif origin one focus import imag inform automat approach base neural reason recent shown remark confer neural inform process system nip barcelona spain question what sit amongst thing abandon answer toilet what sit room appear partial abandon updat what discard side build near old book shelf figur question ask human ambigu given imag contain various object updat question similar one base cosin similar origin question appli algorithm updat represent show attent mask generat model success text question answer task neural reason updat question interact support fact multipl reason layer note appli model vqa nontrivi sinc fact form imag thus imag region inform extract model determin relev question imag region employ attent mechan generat attent distribut region imag contribut follow present reason network iter updat question represent time question interact imag content model util object propos obtain candid imag region abil focus imag region relev question evalu compar perform model two challeng vqa dataset coco-qa vqa experi demonstr abil model infer imag region relev question relat work research visual question answer most driven text question answer imag caption method natur languag process question answer well-studi problem end-to-end memori network use recurr attent model larg extern memori compar origin memori network less supervis show compar result qa task neural reason system propos name neural reason util multipl support fact find answer decent perform achiev posit reason path find qa task vqa close relat imag caption set like word detect sever region imag combin togeth use languag model generat imag descript structur max-margin object use deep neural network learn emb visual languag data common multi-mod space vinyal extract high-level imag featur vector cnn took first input recurr network generat caption xu integr visual attent recurr network propos algorithm predict one word time look local imag region relev current generat word malinowski first introduc solut address vqa problem combin natur languag process semant segment bayesian framework automat question answer sinc sever neural network base model propos solv vqa problem model use cnn extract imag featur recurr neural network emb question embed imag question featur fuse concaten imag understand region imag question what play queri queri gru queri queri softmax region queri cnn region reason question encod answer figur overal architectur model singl reason layer vqa element-wis addit predict answer recent sever model integr attent mechan show abil network focus imag region relat question there also exist approach vqa exampl xiong propos improv dynam memori network fuse question imag region represent use bi-direct gru algorithm learn compos network collect compos modul ma made use cnn propos model three cnns captur inform imag question multi-mod represent model overal architectur model illustr figur model deriv neural reason abl updat represent question recurs infer multipl support fact model yet contain inher differ compon sinc vqa involv one question one imag time instead set fact use object propos obtain candid imag region serv fact model moreov pool step employ attent mechan determin relev represent origin question updat one network consist four major compon imag understand question encod reason answer layer imag understand layer imag understand layer design model imag content semant vector build layer upon vgg model weight layer pre-train imagenet network sixteen convolut layer five max-pool layer kernel size stride follow two fully-connect layer neuron use global represent imag may fail captur necessari inform answer question involv multipl object spatial configur moreov sinc question relat object util object propos generat produc set candid region like object imag choos candid region extract top detect edg box choos intersect union iou valu perform non-maximum suppress common set object detect addit whole imag region ad captur global inform imag understand layer result candid region per imag extract featur candid region mention cnn bring dimens imag region featur extract featur howev lack spatial inform object locat remedi issu follow method includ 8d represent xmin ymin xmax ymax xcenter ycenter wbox hbox wbox hbox width height imag region set imag center origin coordin normal rang then imag region repres featur denot fi model conveni use singl layer perceptron transform imag represent common latent space share question featur vi wvf fi bvf rectifi activ function question encod layer encod natur languag question resort recurr neural network demonstr great success sentenc embed question encod layer compos word embed layer gru cell given question wt wt tth word question length question first emb word wt vector space embed matrix wt then time step feed gru sequenti step gru take one input vector updat output hidden state ht final hidden state ht consid question represent also emb common latent space imag embed singl layer perceptron wqh ht bqh util pre-train network skip-thought vector model design general sentenc embed initi question encod layer use note skip-thought vector model train unsupervis manner larg languag corpus fine-tun gru transfer knowledg natur languag corpus vqa problem reason layer reason layer includ question-imag interact weight pool question-imag interact given multilay perceptron mlp abil determin relationship two input sentenc accord supervis examin imag region featur question represent acquir good understand question memori network these imag region featur akin input memori represent retriev multipl time accord question there total reason layer lth reason layer ith interact happen vi mlp result updat question represent qil qil lpl vi model paramet interact lth reason layer simplest case one singl layer lpl updat process given qil vi bl indic element-wis multipl perform better experi strategi concaten element-wis addit general speak qil contain updat network focus toward answer question interact imag featur vi properti import reason process weight pool pool aim fuse compon question interact imag featur updat represent two common strategi pool max mean pool howev answer specif question often case correct answer relat particular imag region therefor use max pool may lead unsatisfi result sinc question may involv interact human object mean pool may also caus inferior perform due nois introduc region irrelev question determin relev question imag region resort attent mechan use generat attent distribut imag region updat question qil interact ith imag region it chosen close origin question represent henc attent weight take follow form ci tanh wa qil wb bb sof tmax wp bp matrix ith column ci rm dimension vector repres attent weight number imag region set base attent distribut we calcul weight averag qil result updat question represent ql pi qil updat question represent weight pool serv question input next reason answer layer answer layer follow we model vqa classif problem pre-defin class given updat question represent last reason layer softmax layer employ classifi one possibl answer pan sof tmax wan ban note instead softmax layer predict correct answer it also possibl util lstm gru decod take input generat free-form answer experi dataset evalu metric we conduct experi coco-qa vqa coco-qa dataset base microsoft coco imag data there train question test one base total imag four type question provid includ object number color locat type take whole dataset respect vqa dataset imag coco data annot amazon mechan turk amt three question it largest vqa benchmark far there question train valid test respect question ten answer provid take consensus annot follow we choos top most frequent answer candid output constitut train+val answer sinc we formul vqa classif problem mean classif accuraci use evalu model coco-qa dataset besid wu-palm similar wup measur also report coco-qa dataset wup calcul similar two word base longest common subsequ taxonomi tree follow we use threshold evalu vqa dataset provid differ kind evalu metric sinc ten ground truth answer given predict answer consid correct three ground truth answer match it otherwis partial score given implement detail we implement network use public torch comput framework train question sentenc normal lower case question mark remov these word fed gru one one whole answer one word regard separ class for extract imag featur candid region crop resiz feed cnn for coco-qa dataset we set dimens common latent space sinc vqa dataset larger coco-qa we doubl dimens common latent space adapt data class reason layer we use one singl layer mlp we test two reason layer no improv observ use three layer method mean pool max pool w/o global w/o coord full model acc object number color locat tabl comparison ablat model model train test coco-qa one reason layer method img+bow 2vis+blstm ensembl abc-cnn dppnet san qru qru acc object number color locat wup wup tabl evalu result coco-qa dataset qru qru refer reason layer incorpor system network train end-to-end fashion use stochast gradient descent mini-batch sampl momentum learn rate start decreas factor valid accuraci stop improv we use dropout gradient clip regular train process model denot qru follow experi ablat result we conduct experi exam use compon model specif we compar differ question represent pool mechan mean pool max pool we also train two control model devoid global imag featur spatial coordin denot w/o global w/o coord tabl show result perform mean max pool model substanti wors full model use weight pool this indic model benefit attent mechan look sever imag region rather one drop accuraci observ global imag featur model confirm inclus whole imag import for captur global inform without model spatial coordin also lead drop accuraci notabl greatest deterior question type object this object type seek inform around object like what next stop sign spatial coordin help model reason spatial relationship among object comparison state-of-the-art we compar perform tabl experiment result coco-qa vqa respect tabl show model one reason layer alreadi outperform state-of-the-art 2-layer stack attent network san two reason layer give best perform we also report per-categori accuraci show strength weak model tabl best model outperform san question type color locat respect in object our analysi san model put attent coarser region obtain activ last convolut layer may includ clutter noisi background in contrast our model deal select object propos region good chanc object answer question involv object our model give reason result for question type number sinc object propos may contain sever object our count abil weaken in fact count task complet comput vision problem method bowimg lstmimg ibowimg dppnet san wr sel fda dmn qru qru open-end test-dev all y/n num test-std all multiple-choic test-dev all y/n num test-std all tabl evalu result vqa dataset qru qru refer reason layer incorpor in system origin befor updat updat one reason layer updat two reason layer what next two open laptop what next dipict smartphon what next two boy what hook two comput what next visibl pipe what next two pair shoe what there lay two remot what next depict smartphon what hook two comput what next monitor what cubicl four differnet type comput what plug wire what next monitor what open at tabl cell phone what next monitor what sit desk along monitor figur retriev question befor after updat coco-qa dataset tabl show our model yield promin improv other type when compar other model use global represent imag object propos in our model use sinc other type contain question what color what kind etc our model outperform where latter also exploit object propos compar we use less number object propos demonstr effect our approach this tabl also reveal our model two reason layer achiev state-of-the-art result for open-end multiple-choic task qualit analysi understand abil our model in updat question represent we show imag sever question in figur retriev question test set base cosin similar origin question befor after our model updat the represent it notabl befor updat the top similar question begin what next this gru act the languag model make the obtain question share similar languag structur after we updat question represent the result one relat imag content regard object comput monitor the origin retriev question contain irrelev word like boy shoe the retriev question becom even inform use two reason layer we visual attent mask generat our model in figur visual creat soft mask the imag mask creat sum weight each region the mask normal maximum valu follow small gaussian blur our model capabl put attent import region close relev the question answer the question what the color the snowboard the propos model find the snowboard for the other question the man hold what top snow cover hill it requir infer the relat among person snow cover hill snowboard with these attent mask it possibl to predict correct answer sinc irrelev imag region rule exampl shown in figur what the color the the man hold what snowboard top snow cover hill yellow snowboard figur visual attent mask our model learn to attend particular imag region relev to the question what the color what sit what the man in what hog the sunflow top tabl in stadium style seat bed themself workshop use a yellow a boat a phone a dog what next to a larg build a clock figur visual more attent mask conclus we propos an end-to-end trainabl neural network for vqa our model learn to answer question updat question represent infer a set imag region with multilay perceptron visual attent mask demonstr the abil our model to focus imag region high relat to question experiment result satisfi on the two challeng vqa dataset futur work includ improv object count abil word-region relat acknowledg this work support a grant the research grant council the hong kong sar project no by the nation scienc foundat china grant we thank nvidia for provid ruiyu li a tesla gpu acceler for this work
----------------------------------------------------------------

title: 89-neural-network-implementation-approaches-for-the-connection-machine.pdf

neural network implement approach connect machin nathan h. brown jr. mrjlperkin elmer white granit dr. suit oakton va. abslracf simd parallel connect machin allow construct neural network simul use simpl data control structur two approach describ allow parallel comput model 's nonlinear function parallel modif model 's weight parallel propag model 's activ error approach also allow model 's interconnect structur physic dynam hopfield model implement each approach six size the number cm processor provid perform comparison introducflon simul neural network model digit comput perform various comput appli linear nonlinear function defin a program weight sum integ real number retriev store array
----------------------------------------------------------------

title: 1259-are-hopfield-networks-faster-than-conventional-computers.pdf

hopfield network faster convent comput ian parberri hung-li tsengt depart comput scienc univers north texa p.o box denton tx abstract shown convent comput exponentiallx faster planar hopfield network although planar hopfield network take exponenti time converg stabl state arbitrari planar hopfield network found convent comput polynomi time theori p.cs-complet give strong evid separ unlik nonplanar hopfield network demonstr also case sever restrict class nonplanar hopfield network includ interconnect graph class bipartit graph graph degre dual knight 's graph 8-neighbor mesh hypercub butterfli cube-connect cycl shuffle-exchang graph introduct hopfield network faster convent comput appar straightforward question complic fact convent comput univers comput devic capabl simul discret comput devic includ hopfield network thus convent comput could sens cheat imit fastest hopfield network possibl email iangc unt edu url http //hercul csci unt edu/ian email ht senggpond csci unt edu i. parberri h. tseng but question remain faster comput imit hopfield network use comput method although answer like differ differ benchmark problem even differ comput architectur make result meaning long term measur scalabl run time hopfield network convent comput increas size benchmark problem solv state technic interest comput complex stabl state problem hopfield network defin succinct follow given hopfield network determin stabl configur as previous state stabl configur determin imit mean follow result known scalabl hopfield network imit ani imit algorithm stabl state problem must take exponenti time som hopfield network sinc exist hopfield network requir exponenti time converg haken lubi gole martinez it unlik even non-imit algorithm solv stabl state problem polynomi time sinc latter pes-complet papadimitriou schaffer yannakaki howev stabl state problem difficult class hopfield network other hopfield network converg polynomi time weight are bound magnitud polynomi number node expositori proof see parberri corollari contrast stabl state problem hopfield network whose interconnect graph bipartit pes-complet prove easili adapt techniqu bruck goodman strong evid it requir superpolynomi time solv even nonimit algorithm show paper although exist planar hopfield network ake exponenti time converg worst case the stabl state problem planar hopfield network solv polynomi time non-imit algorithm this demonstr imit planar hopfield network exponenti slower than use non-imit algorithm techniqu in contrast we discov the stabl state problem remain pes-complet mani simpl class nonplanar hopfield network includ bipartit network network degre network are popular in neurocomput parallel comput the main part this manuscript divid four section section contain background definit
----------------------------------------------------------------

title: 804-asynchronous-dynamics-of-continuous-time-neural-networks.pdf

asynchron dynam continu time neural network xin wang comput scienc depart univers california los angel los angel ca qingnan li depart mathemat univers southern california los angel ca edward k. blum depart mathemat univers southern california los angel ca abstract motiv mathemat model analog implement distribut simul neural network present definit asynchron dynam general ct dynam system defin ordinari differenti equat base notion local time communic time provid preliminari result global asymptot converg asynchron dynam contract monoton ct dynam system when appli result neural network obtain condit ensur additive-typ neural network asynchroniz introduct neural network massiv distribut comput system major issu parallel distribut comput synchron versus asynchron bertseka tsitsik fix idea consid much studi additive-typ model cohen grossberg hopfield hirsch continuoustim neural network neuron whose dynam govern xi ajxi wijo'j jlj xj ii wang li blum neuron state time constant decay rate extern input gain neuron activ function uj synapt connect weight wij simul implement ideal model neural network central comput limit size network import preclud exploit inher massiv parallel network comput truli faith analog implement simul neural network defin distribut network requir neuron follow a global clock communic time state xj other instantan synchron global dynam precis time xj use evolut xi time clear hardwar softwar realiti make hard sometim imposs fulfil requir mechan use enforc synchron may import effect perform network moreov absolut insist synchron contradict biolog manifest inher asynchroni caus delay nerv signal propag variabl neuron paramet refractori period adapt neuron gain on hand introduct asynchroni may chang network dynam exampl converg oscillatori therefor valid asynchron dynam neural network must assess order to ensur desir dynam a distribut environ jjj motiv issu we studi asynchron dynam general ct dynam system neural network particular asynchron dynam thorough studi context iter map discrete-tim dynam system see bertseka tsitsik
----------------------------------------------------------------

title: 313-applications-of-neural-networks-in-video-signal-processing.pdf

applic neural network video signal process john c. pearson clay d. spenc ronald sverdlov david sarnoff research center princeton nj abstract although color tv establish technolog number longstand problem neural network may suit impuls nois problem modular neural network approach present paper train analysi done convent comput real-tim simul perform massiv parallel comput call princeton engin network approach compar convent altern median filter real-tim simul quantit analysi demonstr technic superior neural system ongo work investig complex cost implement system hardwar potenti neural network consum electron neural network often consid applic emerg new technolog speech recognit machin vision robot fundament idea behind technolog still develop time product contain neural network manufactur result research area drive develop inexpens neural network hardwar could serv catalyst field neural network general contrast neural network rare consid applic matur technolog consum electron technolog base establish principl inform process communic use million product per year embed neural network within mass pearson spenc sverdlov market product would certain fuel develop oflow-cost network hardwar econom dictat rigor cost-reduct everi compon impuls nois tv color televis signal standard use u.s. adopt mcilwain dean pearson video inform first broadcast amplitud modul radio-frequ signal demodul receiv call composit video signal composit signal compris high-bandwidth mhz lumin black white signal two low-bandwidth color signal whose amplitud modul quadratur mhz subcarri signal decod red green blue signal drive display one imag frame form interlac two success field horizont line electr spark creat broad-band rf emiss transform oscillatori waveform composit video signal call am impuls see figur impuls appear televis screen short horizont multi-color streak clear stand pictur spark common creat electr motor littl spatial within frame tempor frame correl impuls general consider suggest two step approach remov impuls video signal detect sampl corrupt replac valu deriv spatio-tempor neighbor although impuls quit visibl form small fraction data sampl detect corrupt alter interpol averag sort general good estim impulse-corrupt sampl imag general smooth vari space time there number difficulti associ detection/replac approach problem there mani impulse-lik waveform present normal video caus fals posit fals alarm see figur algorithm decod composit signal rgb spread impuls onto neighbor line desir remov impuls composit signal howev color encod within composit signal complic matter sub carrier frequenc near ring frequenc impuls tend hide impuls furthermor replac function simpli averag nearest figur seven repres am impuls waveform digit display interv use digit receiv bit usec largest amplitud impuls sampl wide approxim width one line activ video sampl applic neural network video signal process figur corrupt video scan line top scan line composit video signal contain six impuls waveform bottom impuls waveform deriv subtract uncorrupt signal corrupt signal note presenc mani impulse-lik featur video signal sampl repres differ color compon impuls also wide varieti waveform figur includ variat caus clip receiv modular neural network system impuls remov system incorpor three small multi-lay perceptron network rumelhart mcclelland process confin one field data see figur replac function perform one network term i-net denot interpol input consecut sampl two line two line current line network consist unit first hidden layer second and-on output node train estim center sampl current line detect function employ network seri singl network detector tri never perform well two-stag detector input first network consecut sampl current line center sampl interest node first layer one output node train comput move averag absolut differ clean noisi signal current input thus train function filter impuls energi term e-net output e-net low-pass filter sub-sampl remov redund inform input second network line consecut sampl drawn post-process output e-net center sampl interest network like e-net node first layer one output node it train output sampl interest contamin impuls nois otherwis it thus impuls detector call d-net output d-net fed binari switch pass final system output either output i-net origin signal depend whether input exceed adjust threshold pearson spenc sverdlov origin dirti pictur small impu_ls pseudo impuls i big impuls fals negat potenti fals negal potenllaltru posit interpol origin true posit fals posit restor pictur r+smallimpuls let blur eye impuls remov figur neural network am impuls remov system cartoon face use illustr salient imag process characterist system e-net correct signal presenc larg impuls chin miss small impuls forehead incorrect identifi edg nose point eye impuls d-net correct disregard vertic correl impuls featur nose detect larg impuls chin incorrect miss small impuls forehead non-correl impulse-lik featur eye i-net produc fuzzi doubl version origin use replac segment identifi corrupt d-net experi show d-net tend produc narrow spike respons impulse-lik featur imag remov sourc fals posit output d-net averag sampl region center sampl interest reduc peak amplitud signal due impulse-lik featur much broad signal produc true impuls impuls consid present smooth signal exceed threshold level chosen strike balanc low fals posit rate high threshold high true posit rate low threshold experi also show fring impuls detect compens this sub-threshold d-net output sampl set high they within sampl super-threshold d-net sampl figur show output result train system one scan line detect network train one frame video contain impuls differ amplitud largest twenti time smallest visual these rang non-objection bright color standard increment backpropag conjug gradient nag train proceedur use complex e-net d-net reduc phase these net applic neural network video signal process input nois smooth d-net threshol figur input network signal began layer net after phase train redund node identifi remov train re-start this process repeat there redund node real-tim simul princeton engin train system simul real-tim princeton engin chin video demonstr present confer princeton engin gip imag process system consist process element simd configur processor respons output one column pixel contain arithmet unit multipli 64-word triple-port regist stack word local processor memori addit interprocessor communic bus permit exchang data neighbor processor one instruct cycl while i-net perform better convent interpol method differ signific this problem small amount signal replac whole imag replac neural net interpol gave db better perform convent method thus it implement pe i-net may valu video task such convert an interlac non-interlac display fix point arithmet use these simul bit fraction bit sigmoid function look-up tabl comparison double-precis arithmet use the convent comput show signific reduct pearson spenc sverdlov zo fals dettcnon fals dettcnon figur roc analysi neural network median detector perform current work explor the feasibl implement train the pe perform analysi the mean squar error mse well known poor measur subject imag qualiti rouf bouma better measur detect perform given the receiv oper characterist roc green swet the roc parametr plot the fraction corrupt sampl correct detect versus the fraction clean sampl fals detect this case the decis threshold the smooth output the d-net the paramet vari figur left show the neural network detector roc five differ impuls amplitud test on video frame it train this quantifi the sharp breakdown perform observ real-tim simul low impuls amplitud this breakdown observ analysi the mse median filter often suggest impuls remov task appli the remov impuls fm tv transmiss system perlman ai in order assess the relat merit the neural network detector median detector design analyz this detector comput the m~dian the current sampl it nearest neighbor the color sub-carri phase detect regist if the differ the median the current sampl threshold the addit measur taken to insur impuls fring detect as describ the neural network detector figur right show the neural network median detector roc 's for two differ video frame each contain mixtur impuls amplitud one frame use in train the network train the test this verifi the network overtrain quantifi the superior perform the network detector observ in real-tim simul applic neural network in video signal p1'ocess conclus present a system use neural network algorithm outperform a convent method median filter in remov am impuls televis signal cours an addit essenti criterion the cost complex hardwar implement median filter chip success fabric christoph we current investig the feasibl cast small neural network special purpos chip we also appli neural net to televis signal process problem acknowledg this work support thomson consum electron erich geiger dietrich westerkamp this work part of a larger team effort we acknowledg help in particular nurit binenbaum jim gibson patrick hsieh john ju
----------------------------------------------------------------

