query sentence: Nearest neighbours search algorithm for similarity comparison
---------------------------------------------------------------------
title: 6387-cliquecnn-deep-unsupervised-exemplar-learning.pdf

cliquecnn deep unsupervis exemplar learn miguel a. bautista artsiom sanakoyeu ekaterina sutter bj rn ommer heidelberg collaboratori imag process iwr heidelberg univers germani firstname.lastnam iwr.uni-heidelberg.d abstract exemplar learn power paradigm discov visual similar unsupervis manner context howev recent breakthrough deep learn could yet unfold full potenti singl posit sampl great imbal one posit mani negat unreli relationship sampl train convolut neural network impair given weak estim local distanc propos singl optim problem extract batch sampl mutual consist relat conflict relat distribut differ batch similar sampl group compact cliqu learn exemplar similar frame sequenc cliqu categor task cnn consolid transit relat within cliqu learn singl represent sampl without need label propos unsupervis approach shown competit perform detail postur analysi object classif introduct visual similar learn foundat numer comput vision subtask rang low-level imag process high-level object recognit postur analysi common paradigm category-level recognit categori similar instanc class joint model howev larg intra-class variabl recent spur exemplar method split problem simpler sub-task therefor separ exemplar classifi train learn similar individu exemplar larg set negat exemplar paradigm success employ divers area segment group instanc retriev object recognit learn similar also particular import postur analysi video pars among mani approach similar learn supervis techniqu particular popular vision communiti lead formul rank regress classif task recent advanc convolut neural network two-stream architectur rank loss shown great improv howev achiev perform gain cnn architectur requir million sampl supervis train data least fine-tun larg dataset pascal voc although amount access imag data increas enorm rate supervis label similar cost addit similar imag import especi object part annot fine-grain similar entiti hopeless complex particular larg dataset typic use train cnns unsupervis deep learn similar requir label pre-train fine-tun therefor great interest vision communiti way util larg imag dataset without limit need cost manual annot howev cnns author contribut equal confer neural inform process system nip barcelona spain exemplar-bas learn rare due limit result wide use softmax loss learn task suffer singl posit instanc high unbalanc mani negat relationship sampl unknown cf sec consequenti stochast gradient descend sgd get corrupt bias toward negat thus forfeit benefit deep learn outlin propos approach overcom limit updat similar cnns typic begin local estim dis- similar easili avail pair sampl high similar near duplic distant similar howev unknown mutual contradict transit hold therefor initi gather small compact cliqu mutual similar sampl around exemplar exemplar know neither similar dissimilar nevertheless defin balanc classif task suit cnn train formul optim problem build train batch cnn select group compact cliqu cliqu batch mutual distant thus sampl batch dis- similar defin either belong compact cliqu far away belong differ cliqu howev pair sampl reliabl similar end differ batch yield fals train signal sgd classifi sampl belong cliqu serv pretext task learn exemplar similar train network implicit reconcil transit relat sampl differ batch thus learn cnn represent imput similar initi unavail general unseen data experiment evalu propos approach signific improv state-of-the-art approach postur analysi retriev learn general featur represent human pose transfer across dataset exemplar base method similar learn exemplar support vector machin exemplar-svm one drive method exemplar base learn exemplar-svm classifi defin singl posit instanc larg set negat improv perform exemplar-svm requir sever round hard negat mine increas great comput cost approach circumv high comput cost propos train linear discrimin analysi lda histogram gradient hog featur lda whiten hog featur common covari matrix estim exemplar remov correl hog featur tend amplifi background imag recent sever cnn approach propos supervis similar learn use either pair triplet imag howev supervis formul learn similar requir supervisori inform scale quadrat pair imag cubic triplet result larg train time literatur exemplar base learn cnns scarc author exemplarcnn tackl problem unsupervis featur learn patch-bas categor problem design random extract patch imag train set defin surrog class henc sinc approach take account dis- similar exemplar fail model transit relationship result poor perform sect furthermor recent work wang doersh show tempor inform video spatial context inform imag util conveni supervisori signal learn featur represent cnns howev comput cost train algorithm enorm sinc approach need tackl possibl pair-wis imag relationship requir train set scale quadrat number sampl contrari approach leverag relationship inform compact cliqu defin multi-class classif problem train batch contain mutual distinct cliqu comput cost train algorithm great decreas approach discuss employ cnn learn similar pair larg number exemplar exemplar learn cnns relat unexplor approach multipl reason first foremost deep learn requir larg amount train data thus conflict singl posit exemplar setup abbrevi 1-sampl true posit rate fals posit rate figur averag auc postur retriev olymp sport dataset similar learnt 1-sampl cnn use nn-cnn propos approach plot show magnifi crop full similar matrix note detail fine structur cnn 1-sampl cnn face sever issu within-class varianc individu exemplar model ratio one exemplar mani negat high imbalanc softmax loss sgd batch overfit negat iii sgd batch train cnn multipl exemplar contain arbitrarili similar sampl differ label differ exemplar may similar dissimilar result label inconsist propos method overcom issu follow sect discuss simpli merg exemplar nearest neighbor data augment similar spirit cluster exemplar-svm suffici address sect compar nn-cnn approach method sect deal iii generat batch cliqu maxim intra-cliqu similar minim inter-cliqu similar show effect propos method give empir proof train cnns 1-sampl cnn nn-cnn manner show averag roc curv postur retriev olymp sport dataset refer sec detail 1-sampl cnn nn-cnn propos method clear outperform exemplar base strategi addit show excerpt similar matrix learn method becom evid propos approach captur detail similar structur diagon structur correspond repetit gait cycl within long jump initi sinc deep learn benefit larg amount data requir singl exemplar avoid bias gradient refram exemplar-bas learn similar handl cnn given singl exemplar di thus strive relat sampl enabl cnn train improv similar sampl obtain initi set mutual similar sampl exemplar briefli discuss reliabl standard featur distanc such whiten hog featur use lda hog-lda comput effect foundat estim similar sij larg number sampl sij di dj here initi hog-lda represent exemplar result kernel initi similar unreli thus major sampl proper rank similar exemplar di howev high similar sampl far away reliabl identifi stand similar distribut subsequ util reliabl relationship build group compact cliqu compact cliqu simpli assign label nearest anoth label furthest neighbor exemplar inappropri sampl group may close di distant negat group anoth due lack transit moreov mere augment exemplar synthet data add transit relat sampl therefor learn within-class similar need restrict model compact cliqu sampl sampl cliqu also mutual close anoth deserv label queri our alexnet hog-lda figur averag nearest neighbour given queri frame use similar obtain approach alexnet hog-lda build candid cliqu appli complete-linkag cluster start di merg sampl local neighborhood merg sampl mutual similar thus cliqu compact differ size may mutual overlap reduc redund high overlap cliqu subsequ merg cluster cliqu use farthest-neighbor cluster agglom group termin intra-cliqu similar cluster less half constitu let result number cluster cliqu number sampl di result assign matrix sampl cliqu select batch mutual consist cliqu set compact cliqu compris train data thus one may consid train cnn assign sampl cliqu label howev sinc highest/lowest similar reliabl sampl differ cliqu necessarili dissimilar forc differ class consequ entail incorrect similar therefor seek batch mutual distant cliqu sampl batch label consist either similar compact cliqu dissimilar differ distant cliqu sampl unreli similar end differ batch train cnn success batch formul optim problem produc set consist batch cliqu let indic matrix assign cliqu batch row xb cliqu batch s0 rk k similar cliqu enforc cliqu batch dissimilar minim tr regular diagon element matrix s0 select batch moreov batch maxim sampl coverag number distinct sampl cliqu batch kxb ckpp maxim final number distinct point cover batch k1xckpp maxim differ potenti overlap batch togeth compris much sampl possibl select penalti function rough approxim non-linear step function object optim problem becom min tr tr diag kxb ckpp k1xckpp r1b desir number cliqu one batch cnn train number batch set arbitrarili high allow mani round sgd train desir low easili spot limit coverag train data achiev last term sinc discret optim problem easier quadrat assign probl known hardm overcom issu relax binari constraint forc instead continu solut boundari feasibl rang maxim addit term kx use frobenius norm condit s0 posit semi-definit threshold eigenvector project onto result base sinc also previous object function differ convex function figur visual exampl result batch cliqu long jump categori olymp sport dataset cliqu contain least sampl repres averag tr kxb ckpp k1xckpp tr x diag kx solv use cccp algorithm iter cccp follow convex optim problem solv argmin vec vec r1b v xt 2x diag 2x denot hadamard product solv constrain optim problem mean interior-point method show visual exampl select batch cliqu cnn train success train cnn differ batch xb obtain use batch classifi sampl accord cliqu serv pretext task learn sampl similar one key properti cnns train use sgd backpropag backpropag gradient estim subset batch train sampl depend subset cliqu xb follow observ cliqu categor problem effect decoupl set smaller sub-task individu batch cliqu dure train random pick batch iter comput stochast gradient use softmax loss fw dj j x vt wt sgd batch size wt denot cnn weight iter vt denot weight updat previous iter paramet denot learn rate momentum respect comput similar exemplar simpli measur correl learn featur represent extract cnn sect detail similar imput altern differ batch contain cliqu mutual inconsist similar cnn learn singl represent sampl batch effect consolid similar cliqu differ batch general subset initi cliqu new previous unreli relat sampl differ batch util transit relationship impli cliqu train round batch imput similar use represent learn cnn result similar reliabl enabl group algorithm sect find larger cliqu mutual relat sampl fewer unreli similar frame sort exemplar similar score queri exemplar similar score frame rank figur cumul distribut spectrum similar matric obtain method hog-lda initi sort similar respect one exemplar similar end distribut trust sampl compris batch overal less batch alreadi cover fraction data consequ altern train cnn recomput cliqu batch use similar infer previous iter cnn train altern imput similar updat classifi follow idea multiple-inst learn shown converg quick less four iter evalu improv similar analyz eigenvalu spectrum olymp sport dataset see sect plot show normal cumul sum eigenvalu function number eigenvector compar initi transit relat learn approach general exemplar relat sampl therefor similar matrix becom structur random noisi relat disappear consequ it repres use basi vector experi evalu number reliabl similar dissimilar within cliqu per batch recal sampl part batch if similar reliabl so goal similar learn remov transit conflict reconcil relat sampl yield larger batch observ after iter updat similar averag number similar dissimilar batch increas factor compar batch initi experiment evalu provid quantit qualit analysi exemplar-bas approach unsupervis similar learn evalu three differ set consid postur analysi olymp sport pose estim leed sport object classif pascal voc olymp sport dataset postur analysi olymp sport dataset video compil differ sport competit evalu fine-scal pose similar sport categori independ annot manual label posit similar negat dissimilar sampl around exemplar note annot sole use test sinc follow unsupervis approach compar propos method exemplar-cnn two-stream approach doersch al 1-sampl cnn nn-cnn model similar spirit alexnet exemplar-svm hog-lda due perform object person detect use approach comput person bound box evalu investig benefit unsupervis gather batch cliqu deep learn exemplar use standard cnn architectur therefor incarn approach adopt wide use model krizhevski batch train network obtain solv optim problem fine-tun model iter thereaft comput similar use featur extract layer fc7 caff implement exemplar-cnn train use best perform paramet report architectur use output fc4 comput 4-quadrant max pool iii exemplar-svm train exemplar frame use hog descriptor sampl hard negat mine come categori except one exemplar perform cross-valid find optim number negat mine round less three class weight linear svm set c1 c2 lda whiten hog hog-lda ex-svm ex-cnn alexnet cnn nn-cnn doersch al our tabl avg auc method olymp sport dataset comput specifi 1-sampl cnn train defin separ class exemplar sampl plus negat categori contain sampl similar fashion nn-cnn train use exemplar plus nearest neighbour obtain use whiten hog similar implement both cnns we use model fine-tun iter imag train set augment transform version perform random translat scale rotat color transform improv invari respect tab report averag auc method categori olymp sport dataset approach obtain perform improv least method particular experi show 1-sampl cnn fail model posit distribut due high imbal posit negat result bias gradient comparison addit nearest neighbour exemplar nn-cnn yield better model withinclass variabl exemplar lead perform increas 1-sampl cnn howev nn-cnn also see larg set negat partial similar dissimilar due unstructured negat set approach fail thorough captur fine-grain similar structur negat sampl circumv issu we comput set mutual distant compact cliqu result in relat perform increas nn-cnn furthermor present similar structur differ approach extract analyz human postur highlight similar relat neighbor each method top nearest neighbour random chosen exemplar frame in olymp sport dataset blend we see neighbor obtain approach depict sharper averag postur sinc result compact cliqu mutual similar sampl therefor retain detail similar origin in case method leed sport dataset pose estim leed sport dataset most wide use benchmark pose estim train we employ imag dataset combin imag extend version dataset each imag annot joint locat we use visual similar learn approach to find frame similar in postur to queri frame sinc train unsupervis joint label avail at test time we therefor estim pose queri person identifi nearest neighbor train set to compar supervis method pose nearest neighbor then compar ground-truth we evalu visual similar learn result identif nearest postur comparison similar postur also retriev use hog-lda alexnet in addit we also report upper bound perform achiev nearest neighbor use ground-truth similar therefor nearest train pose queri identifi minim averag distanc ground-truth pose annot this best one find most similar frame provid supervis parametr model perform gap to show differ train test pose complet we compar fulli supervis state-of-the-art approach pose estim we use experiment set describ in sect tab report percentag correct part pcp differ method predict part consid correct endpoint within part length correspond ground truth endpoint approach signific improv visual similar learn use alexnet hog-lda it note-worthi even though approach estim pose fulli unsupervis it attain competit perform compar to upper-bound supervis ground truth similar in addit present success failur case method in we see pose correct transfer nearest neighbor train set result in pcp score particular imag moreov show represent learnt method invari to front-back flip match person face away camera to one method our hog-lda alexnet ground truth pose machin torso upper leg lower leg upper arm lower arm head total tabl pcp measur each method leed sport dataset figur pose predict result test imag with the superimpos ground truth skeleton depict in red the predict skeleton in green correspond nearest neighbour use to transfer pose face the camera sinc approach learn pose similar in unsupervis manner it becom invari to chang in appear as long as the shape similar thus explain this confus ad addit train data direct incorpor face detection-bas featur could resolv this pascal voc object classif the previous section analyz the learn pose similar now we evalu the learn similar object categori therefor we classifi object bound box the pascal voc dataset to initi model we now use the visual similar wang without appli fine tune pascal also compar this approach thus neither imagenet pascal voc label util comparison we evalu hog-lda r-cnn our method hog-lda we use the experiment set as describ in sect initi our method network with the similar obtain for method the nearest neighbor comput use similar pearson correl base in tab we show the classif accuraci for approach for our approach improv upon the initi similar the unsupervis approach to yield perform gain without requir supervis inform fine-tun pascal hog-lda wang al wang al our rcnn tabl classif result for pascal voc conclus we propos an approach for unsupervis learn similar larg number exemplar use cnns cnn train made applic in this context address crucial problem result the singl posit exemplar setup the imbal exemplar negat inconsist label within sgd batch optim singl cost function yield sgd batch compact mutual dissimilar cliqu sampl learn exemplar similar then pose as a categor task on individu batch in the experiment evalu the approach shown competit perform compar to the state-of-the-art provid signific finer similar structur particular crucial for detail postur analysi this research fund in part by the ministri for scienc baden-w rttemberg the heidelberg academi scienc heidelberg germani we grate to the nvidia corpor for donat a titan gpu
----------------------------------------------------------------

title: 5425-a-multiplicative-model-for-learning-distributed-text-based-attribute-representations.pdf

multipl model learn distribut text-bas attribut represent ryan kiro richard s. zemel ruslan salakhutdinov univers toronto canadian institut advanc research rkiro zemel rsalakhu cs.toronto.edu abstract paper propos general framework learn distribut represent attribut characterist text whose represent joint learn word embed attribut correspond wide varieti concept document indic learn sentenc vector languag indic learn distribut languag represent meta-data side inform age gender industri blogger represent author describ third-ord model word context attribut vector interact multipl predict next word sequenc lead notion condit word similar mean word chang condit differ attribut perform sever experiment task includ sentiment classif cross-lingu document classif blog authorship attribut also qualit evalu condit word neighbour attribute-condit text generat introduct distribut word represent enjoy success sever nlp task recent use distribut represent extend model concept beyond word level sentenc phrase paragraph entiti relationship embed semant categori paper propos general framework learn distribut represent attribut characterist text whose represent joint learn word embed use word attribut context general tabl illustr sever experi perform along correspond notion attribut exampl attribut repres indic current sentenc languag process allow us learn sentenc languag vector similar propos model attribut also correspond side inform metadata associ text instanc collect blog may come inform age gender industri author allow us learn vector captur similar across metadata base associ bodi text goal work show notion attribut vector achiev strong perform wide varieti nlp relat task particular demonstr strong quantit perform three high divers task sentiment classif cross-lingu document classif blog authorship attribut captur kind interact attribut text propos use third-ord model attribut vector act gate unit word embed tensor word repres tensor consist sever prototyp vector given attribut vector word embed matrix comput linear combin word prototyp weight attribut represent train attribut vector resid separ lookup tabl joint learn along word featur model paramet type three-way tabl summari task attribut type use experi first three quantit second three qualit task sentiment classif cross-lingu classif authorship attribut condit text generat structur text generat condit word similar dataset sentiment treebank rcv1/rcv2 blog corpus gutenberg corpus gutenberg corpus blog europarl attribut type sentenc vector languag vector author metadata book vector part speech tag author metadata languag interact embed neural languag model three-way interact consist previous context attribut score distribut next word context use word embed tensor give rise notion condit word similar specif neighbour word embed chang depend attribut condit exampl word joy condit author industri attribut religion appear near raptur god near delight comfort condit author industri attribut scienc anoth way think model would languag analogu use factor condit restrict boltzmann machin model motion style defin real continu valu style variabl factor embed neural languag model allow us generat text condit differ attribut manner could generat motion differ style show experi attribut repres differ book sampl generat model learn captur associ write style author furthermor demonstr strong perform gain authorship attribut condit word represent use multipl interact also previous incorpor neural languag model introduc multipl model imag use gate word represent framework seen general context work attribut would correspond fix represent imag introduc multipl recurr neural network generat text charact level model charact current timestep use gate network recurr matrix led substanti improv abil generat text charact level oppos non-multipl recurr network method section describ propos model first review log-bilinear neural languag model form basi much work next describ word embed tensor show factor introduc multipl neural languag model conclud detail attribut vector learn log-bilinear neural languag model log-bilinear languag model lbl determinist model may view feedforward neural network singl linear hidden layer word vocabulari repres k-dimension real-valu vector rw rk let denot matrix word represent vector vocabulari size let tupl word context size lbl model make linear predict next word represent rwi context paramet matric thus predict represent rwn condit probabl wn wn given w1 exp rt ri bi wn pv rt rj bj exp rv bias vector learn done use backpropag nlm multipl nlm multipl nlm languag switch figur three differ formul predict next word neural languag model left standard neural languag model middl context attribut vector interact via multipl interact right word unshar across attribut one-hot attribut vector gate factors-to-vocabulari matrix word embed tensor tradit word represent matric repres matrix rv case log-bilinear model throughout work instead repres word tensor rv correspond number tensor slice given attribut vector pd rd comput attribute-g word represent word represent respect comput linear combin slice weight compon often unnecessari use fulli unfactor tensor follow re-repres term three matric wf rf wf rf wf rf wf diag wf wf diag denot matrix argument diagon matric parametr pre-chosen number factor multipl neural languag model show emb word represent tensor log-bilinear neural languag model let wf wf denot fold matrix word embed given context w1 predict next word represent given denot column word represent context matric given predict next word represent factor output wf wf component-wis product condit probabl wn wn given w1 written exp wf bi wn pv fv exp bj here wf denot column wf correspond word contrast log-bilinear model matrix word represent replac factor tensor shown unshar vocabulari across attribut formul assum word represent share across attribut case word may specif certain attribut other exampl crosslingu model necessari languag specif vocabulari run exampl consid case attribut correspond languag represent vector let tabl sampl generat model condit various attribut last exampl condit averag two vector symbol correspond number attribut bibl caesar bibl caesar sampl thus enquir unto thee say lord come unto see shall see greater name king israel tell vs pindarus short pray henc word come hither let vs exclaim fear till love caesar till kept proper deed ant caesar wise cassi let spring tiger less tuck great fellow ghost broth industri time golden glori employ far men soft bone assur set blood smell cost learn love guil word down mysteri possess denot attribut vector languag languag english french comput language-specif word represent break decomposit languag depend independ compon diag wf wf languag specif matrix matric wf wf depend languag vocabulari wherea languag specif moreov sinc languag may differ size vocabulari use denot vocabulari size languag observ model interest properti allow us share statist strength across word represent differ languag particular show experi improv cross-lingu classif perform english german larg amount parallel data exist english french small amount parallel data exist english german learn attribut represent discuss learn represent vector recal train neural languag model word represent w1 updat backpropag word embed matrix think linear layer input layer one-hot vector i-th posit activ word multipli vector embed matrix result word vector thus column word represent matrix consist word w1 non-zero gradient respect loss allow us consist modifi word represent throughout train construct attribut represent similar way suppos attribut lookup tabl option non-linear often use rectifi non-linear order keep spars posit found made train much stabl initi entri generat random train treat way word embed matrix way learn languag represent allow us measur similar attribut oppos use one-hot encod attribut similar could comput case attribut avail dure train may also avail test time exampl attribut use sentenc indic learn represent sentenc accommod use infer step similar propos test time network paramet fix stochast gradient descent use infer represent unseen attribut vector experi section describ experiment evalu result throughout section refer model attribut tensor decomposit model train use stochast gradient descent exponenti learn rate decay linear per epoch increas momentum first demonstr initi qualit result get sens task model perform use small project gutenberg corpus consist book author first train multipl neural languag model context size tabl modifi version game mad lib given initi model generat next word accord part-of-speech sequenc note hard constraint nn dt jj mean life cure bad truth good penni fourth globe modern man upon vb vbd jjs nns greatest accomplish keep sold wish make man magnific keep wound best nation allow best argument mention peopl prp nn jj nn could live without regard will tender french serious friend father good voic heart like beauti sister charact tabl classif accuraci various task left sentiment classif treebank dataset compet method includ neural bag word nbow recurs network rnn matrix-vector recurs network mv-rnn recurs tensor network rtnn dynam convolut network dcnn paragraph vector right cross-lingu classif rcv2 method includ statist machin translat imatrix bag-of-word autoencod bicvm bicvm use cross-lingu task indic use third languag french learn embed method svm binb nbow rnn mvrnn rtnn dcnn pv atd fine-grain posit negat method smt i-matrix bae-cr bae-tre bicvm bicvm bae-corr atd atd en de de en attribut repres book result learn attribut vector one book after train condit book vector generat sampl model tabl illustr generat sampl model learn captur style associ differ book furthermor condit averag book represent model generat reason sampl repres hybrid attribut even though attribut combin observ dure train next comput pos sequenc sentenc occur train corpus train multipl neural languag model context size predict next word context given knowledg pos tag next word model wn denot pos tag word wn after train gave model initi input pos sequenc proceed generat sampl tabl show result task interest model generat rather funni poetic complet initi context sentiment classif first quantit experi perform sentiment treebank common challeng sentiment classif task global sentiment sentenc need correspond local sentiment exhibit sub-phras sentenc address issu collect annot movi review corpus subphras extract sentenc parser incorpor local sentiment recurs architectur abl obtain signific perform gain recurs network bag word baselin follow experiment procedur propos evalu report two task fine-grain classif categori negat negat neutral posit posit binari classif posit negat extract subphras sentenc occur train set use train multipl neural languag model here attribut repres sentenc vector order comput subphras unseen sentenc appli infer procedur similar weight network frozen gradient descent use infer represent unseen vector train logist regress classifi use train subphras train set test time infer represent new sentenc use make review predict use context size dimension word vector initi dimension sentenc vector initi averag vector word correspond sentenc tabl left panel illustr result this task comparison propos approach result par highest perform recurs network fine-grain task outperform bag-of-word baselin recurs network except rtnn binari task method outperform two recent propos approach convolut network train sentenc paragraph vector cross-lingu document classif follow experiment procedur sever exist baselin avail compar result experi proceed follow first use europarl corpus induc word represent across languag let sentenc word languag let correspond languag vector let diag wf wf w s w s denot sentenc represent defin sum languag condit word represent s. equival defin sentenc represent translat denot optim follow rank object xx minim max ck subject constraint sentenc vector unit norm ck constrast nontransl sentenc denot model paramet this type cross-languag rank loss first use without norm constraint found signific improv stabil train europarl corpus contain rough million parallel sentenc pair english german well english french induc dimension word represent evalu perform english german section reuter rcv1/rcv2 corpora note document parallel reuter dataset contain multipl label document follow consid document assign one top categori label hierarchi ccat corporate/industri ecat econom gcat government/soci mcat market total english document german document vocabulari size english word german word consid train english evalu german vice versa repres document sum word represent word document follow unit-bal project follow use averag perceptron classifi classif accuraci evalu held-out test set in languag use monolingu valid set tune margin set five contrast term use per exampl random assign per epoch tabl right panel show result compar propos method thus far we competit current state-of-the-art approach outperform bicvm bae-corr en de bae-corr method combin reconstruct term correl regular match sentenc our method consid reconstruct we also perform experiment low resourc task we assum condit except we use parallel sentenc pair english german still incorpor english french parallel sentenc for this task we compar separ baselin our model paramet share across languag thus resembl here we achiev accuraci en de de en separ baselin obtain this indic paramet share across languag use small amount parallel data avail figur show t-sne embed english-german word pairs.1 anoth interest consider whether learn languag vector captur interest properti various languag look this we train multipl neural languag model simultan languag english french german czech slovak our knowledg this languag word represent joint learn we we note germani deutschland nearest neighbour in origin space month countri uncondit ion atd correl matrix uncondit ion atd lbl condit ion atd infer ribut es differ im provem ent init ial odel figur t-sne embed english-german word pair learn europarl docum ent housand docum ent housand effect condit embed effect infer attribut vector figur result blog classif corpus for middl right plot pair colour bar correspond non-inclus inclus infer attribut vector respect comput correl matrix languag vector illustr in interest we observ high correl czech slovak represent indic model may learn notion lexic similar said addit experiment for futur work necessari better understand similar exhibit languag vector blog authorship attribut for our final task we use blog corpus contain blog post author for our experi we break corpus two separ dataset one contain prolif author blog post contain rest author come attribut tag correspond tupl age gender industri indic age rang author whether author male femal industri author work in note industri necessari correspond topic blog post we use dataset non-prolif author train multipl languag model condit attribut tupl there uniqu tupl in total we use dimension word vector initi dimension attribut vector random initi context size classif task then perform prolif author subset evalu done use 10-fold cross-valid our initi experiment baselin found tf-idf perform well this dataset accuraci thus we consid much we improv tf-idf baselin augment word attribut featur for first experi we determin effect condit word embed classif perform assum attribut avail test time for this we comput two embed matric train atd model one without attribut knowledg uncondit atd condit atd wf wf wf diag wf wf we repres blog post sum word vector project unit norm augment tf-idf featur addit baselin we includ log-bilinear languag model figur 3b illustr result we observ condit word embed signific more discrimin word embed comput without knowledg attribut vector log-bilinear model concept attribut tabl result condit word similar task use blog attribut languag vector queri b school f/10/student m/20/tech journal f/10/student creat f/30/art f/30/internet joy m/30/religion m/20/scienc cool m/10/student f/10/student common work church colleg diari blog webpag build develop maintain happi sad pain nice funni awesom uniqu choir prom skool project book yearbook provid acquir generat raptur god heartbreak beauti amaz neat uniqu therapi tech job zine app referr compil follow analys delight comfort soul sexi hott lame english januari june octob market market intern war weapon global said state told two two-third french janvier decembr juin march march intern guerr terrorism mondail dit disait declar deux deuxiem second german januar dezemb juni markt binnenmarkt markt krieg global krieg sagt gesagt sagten zwei beiden zweier for second experi we determin effect infer attribut vector test time assum avail this we train logist regress classifi within fold for predict attribut we comput infer vector averag attribut vector weight log-prob classifi in 3c we plot differ in perform an infer vector augment these result show consist albeit small improv gain when attribut vector infer at test time get better sens attribut featur learn model supplementari materi contain a t-sne embed learn attribut vector interest model learn featur larg isol vector all teenag blogger independ gender topic condit word similar one key properti our tensor formul notion condit word similar name neighbour word represent chang depend the attribut condit in order explor the effect this we perform two qualit comparison one use blog attribut vector the languag vector these result illustr in tabl for the first comparison the left we chose two attribut the blog corpus a queri word we identifi these attribut pair a b next we comput a rank list the nearest neighbour cosin similar word condit each attribut identifi the top word in each out these word we display the top word common to rank list as well as word uniqu to a specif attribut our result illustr that the model captur distinct notion word similar depend attribut condit the right tabl we chose a queri word in english italic comput the nearest neighbour when condit on each languag vector this result in neighbour that either direct translat the queri word word that semant similar the supplementari materi includ addit exampl nearest neighbour colloc conclus there sever futur direct this work extend one applic area interest in learn represent author paper they choos to review as a way improv autom reviewer-pap match sinc author contribut to differ research topic might more use to instead consid a mixtur attribut vector that allow for distinct represent the author across research area anoth interest applic learn represent graph recent propos an approach for learn embed node in social network introduc network indic vector could allow us to potenti learn represent full graph final it would interest to train a multipl neural languag model simultan across dozen languag acknowledg we would also like to thank the anonym review for valuabl comment suggest this work support by nserc googl samsung onr grant
----------------------------------------------------------------

title: 4143-pose-sensitive-embedding-by-nonlinear-nca-regression.pdf

pose-sensit embed nonlinear nca regress graham w. taylor rob fergus georg william ian spiro christoph bregler courant institut mathemat new york univers new york usa gwtaylor fergus spiro bregler cs.nyu.edu abstract paper tackl complex problem visual match peopl similar pose differ cloth background appear chang achiev novel method learn nonlinear embed base sever extens neighborhood compon analysi nca framework method convolut enabl scale realistically-s imag cheapli label head hand larg video databas amazon mechan turk crowd-sourc servic use task local head hand proxi determin bodi pose appli method challeng real-world data show general beyond hand local infer general notion bodi pose evalu method quantit embed method also demonstr realworld perform improv use synthet data introduct determin pose human bodi one imag central problem comput vision complex multi-joint natur bodi make determin pose challeng particular natur set ambigu unusu configur may observ abil local hand particular import provid tight constraint layout upper bodi yield strong cue action intent person huge rang techniqu parametr non-parametr exist infer bodi pose 2d imag 3d dataset propos non-parametr approach figur queri imag left column eight nearest neighbour found method distanc learn embed space shown bottom right match base locat hand general bodi pose individu background estim bodi pose local hand use parametr nonlinear multi-lay embed raw pixel imag unlik mani metric learn approach design use real-world imag convolut architectur scale grace larg imag invari local geometr distort embed train real synthet data function map project imag similar head hand posit lie close-bi low-dimension output space effici nearest-neighbour search perform space find imag larg train corpus similar pose specif task design interfac obtain verifi head hand label thousand frame amazon mechan turk minim user intervent find method abl cope ters noisi label provid crowd-sourc succeed general bodi hand pose cue explicit provid label relat work applic domain relat sever approach comput vision literatur propos hand bodi pose track mani techniqu reli sliding-window part detector base color featur appli control record condit name refer complet survey domain hand might occupi pixel body-part reliabl detect human face mani techniqu propos extract learn reason entir bodi featur use combin local detector structur reason coars track person-depend track similar spirit general techniqu use pictori structur poselet part-model receiv increas attent entir new stream kinemat model-bas techniqu base humaneva dataset propos area differ domain imag consid higher qualiti less clutter close relat task nearest-neighbour locally-weight regression-bas techniqu extract shape-context edg base histogram human bodi silhouett featur shakhnarovich use hog featur boost learn paramet sensit hash function approach reli good background subtract record clear background domain contain clutter light variat low resolut imposs separ bodi featur background success instead learn relev featur direct pixel instead pre-cod edg gradient histogram featur discov implicit background invari train data sever work use synthet creat data train set show paper sever experi challeng real video crowd-sourc amazon mechan turk label synthet train data hybrid dataset final system train alway appli clutter non-background subtract real video input without label techniqu also relat distanc metric learn import area machin learn research especi due recent interest analyz complex high-dimension data subset approach dimension reduct implicit learn distanc metric learn function map high-dimension pixel space low-dimension featur space perceptu similar observ map nearbi point manifold neighbourhood compon analysi nca propos solut transform input featur space linear distanc metric euclidean nca learn transform optim perform knn featur space nca also recent extend nonlinear case use mnist class label linear 1d regress reinforc learn dimension reduct learn invari map drlim also learn nonlinear map like nca drlim use class neighbourhood structur drive optim observ class label driven close-bi featur space approach also inspir recent hash method although techniqu restrict binari code fast lookup learn invari map nonlinear embed first discuss neighbourhood compon analysi nonlinear variant propos altern object function optim perform nearest neighbour regress rather classif next describ convolut architectur map imag high-dimension low-dimension space final introduc relat differ object model base drlim neighbourhood compon analysi nca linear nonlinear drlim presuppos exist meaning comput distanc metric input space requir neighbourhood relationship defin train sampl well-suit learn metric non-parametr classif knn high-dimension data origin data contain discret class label real-valu label pose inform imag peopl one altern defin neighbourhood base distanc real-valu label space proceed usual howev classif ultim goal may wish exploit soft natur label use altern object one optim knn perform suppos given set label train case rd rl train point select anoth point neighbour probabl defin normal distanc transform featur space exp d2ij exp dik pij pii dij zj use euclidean distanc metric dij zi map parametr input space featur space nca typic linear extend nonlinear back-propag exampl multi-lay neural network nca assum label discret rather real-valu seek maxim expect number correct classifi point train data minim lnca pij j yi yj paramet found minim lnca respect back-propag case multi-lay parametr instead seek optim knn classif perform use nca regress ncar object lncar pij yj intuit state high probabl neighbour featur space also lie close-bi label space use euclidean distanc label space approach general metric may appropri differ domain keller consid linear case ncar weight matrix scalar repres bellman error map state similar bellman error close togeth similar nca extend object nonlinear multi-lay case simpli need comput deriv lncar respect output map zi backpropag remain layer network gradient comput effici lncar zi zj pij yij pji yij zi use yij yj pij yij see supplementari materi detail convolut architectur point nonlinear nca origin propos except modest success two-lay network extract 2d code explicit repres size orient face imag attempt extract complex properti use multi-lay featur extract less success due part difficulti train multi-lay network fact mani data pair requir fit larg number network paramet though success learn multi-lay nonlinear map data still fundament limit use fully-connect network must address architectur appli relat small imag patch typic less pixel scale well size input salakhutdinov hinton escap issu train mnist dataset imag digit torralba use global imag descriptor initi featur represent rather pixel howev avoid hand-craft featur may suitabl task scale realist size input model take advantag pictori natur imag input address convolut architectur exploit fact salient motif appear anywher imag employ success stage weight-shar feature-pool deep convolut architectur achiev stabl latent represent layer preserv local provid invari small variat input drastic reduc number free paramet propos method call convolut nca regress c-ncar base standard convolut architectur altern convolut subsampl layer follow singl fully-connect layer differ typic convolut net object function train minim becaus loss defin pair exampl use siames network pair frame process separ network equal weight loss comput output network hadsel also use siames convolut network yet differ object they use method visual discrimin task mobahi also recent use convolut siames network tempor coher pair frame drive regular model rather object detail train network given sec input layer layer layer layer output z convolut tanh ab averag pool convolut tanh ab averag pool fulli connect figur convolut nca regress c-ncar imag process two convolut subsampl layer one fully-connect layer loss comput distanc result code drive paramet learn ad contrast loss function like nca drlim assum discret notion similar dissimilar data pair defin similar loss ls penal similar point far apart code space dissimilar loss ld penal dissimilar point lie within user-defin margin ld dij ls d2ij dij given let indic deem similar deem dissimilar exampl label discret yj otherwis total loss defin ldrlim ls ld face real-valu label avoid explicit defin similar dissimilar via threshold defin soft notion similar exp ||yi yj exp ||yi yj replac indic variabl yield call soft drlim loss experiment result evalu approach real synthet environ perform 1-nearest neighbour regress use varieti standard learn metric describ everi queri imag test set comput distanc metric train point databas copi label posit head hand neighbour queri exampl evalu compar ground-truth label queri label nearest neighbour error report term mean pixel error queri marker head if track hand error absolut respect origin imag size acknowledg improv result could potenti obtain use one neighbour sophist techniqu local weight regress howev focus learn good metric perform task rather regress problem approach compar pixel distanc use find nearest neighbour though practic real situat due intract comput distanc high-dimension space gist descriptor global represent imag content.w motiv use gist previous use nonlinear nca imag retriev result imag represent length-512 vector note still larg effici nn search gist featur domain-adapt linear nca regress ncar describ section pre-comput gist imag use input represent learn matrix weight minim use nonlinear conjug gradient random sampl mini-batch size perform three line-search per mini-batch stop learn mini-batch found result slight improv appli form local contrast normal lcn prior comput gist pixel respons normal integr respons window neighbour pixel detail see convolut nca regress c-ncar see summari architectur imag pre-process use lcn convolut follow pixel-wis tanh absolut valu rectif ab prevent cancel local neighbourhood averag downsampl architectur paramet size filter number filter bank etc chosen produc 32-dimension output deriv paramet updat present supplementari materi soft drlim s-drlim convolut soft drlim cs-drlim also experi variant altern energy-bas method add explicit contrast loss object rather implicit normal contrast loss oper dissimilar point lie within specifi margin use suggest linear nonlinear case architectur train procedur remain ncar c-ncar respect we use differ object minim respect paramet estim 2d head hand pose synthet data we extract frame train data frame test data poser render sever hour real motion captur data synthet data similar consid howev we use varieti background rather constant background furthermor subject free move around frame render various scale train set contain differ charact superimpos differ background test set contain charact background present train set input imag label 6d vector true locat head hand result shown tabl column sy simpl linear ncar perform well compar baselin while nonlinear method c-ncar cs-drlim restrict gist descriptor signific outperform approach pixel-bas match though extrem slow surpris well this perhap artifact synthet data estim 2d hand pose real video we digit record contribut invit speaker learn workshop snowbird held april set consist speaker talk rang minut after session talk block frame distribut human intellig task tabl regress perform synthet dataset real dataset result divid baselin learn linear embed nonlinear embed error mean pixel distanc nearest neighbour ground truth label queri sy we locat head hand re we assum locat scale head given face detector locat hand imag right indic top radius pixel respect sy input bottom radius pixel respect re input imag scale plot embed none none pca pca ncar ncar s-drlim boost-ssc c-ncar cs-drlim input pixel gist gist gist gist lcn+gist gist lcn+gist lcn lcn dim error-si error-r amazon mechan turk we abl obtain accur hand head track speaker within hour talk follow experi we divid speaker train set odd number speaker test set even number speaker sinc current state-of-the-art face detect algorithm work reason well we concentr harder problem track speaker hand we first run commerci face detect algorithm all frame provid estim scale everi frame we use averag scale per video estim face detector crop rescal frame imag center head contain speaker rough scale speaker some variabl due use averag scale per video speaker move throughout talk similar preprocess step use we consid case hand lie outsid frame occlud this yield train test imag respect contain head hand sinc imag head-cent label use train 4-dimension vector contain relat offset hand head we emphas find hand extrem difficult task sometim even human subject frame low-resolut typic hand pixel diamet contain camera movement well frequent poor light while previous work assum static background we confront chang background aim learn invari scene subject ident result shown tabl column re they organ three group baselin highdimension learning-bas method linear nonlinear linear method abl achiev perform compar baselin import attribut distanc comput 32-dimension space if code made binari we could use fast approxim hash techniqu permit real-tim track use databas well million exampl nonlinear method show dramat improv linear method especi our convolut architectur learn featur pixel boost-ssc base global represent similar gist restrict domain adapt we also investig perform c-ncar code size perform impress even dimens we comput distanc reduc visual 2d embed shown show some exampl nearest-neighbour match sever differ metric most appar our method particular c-ncar develop invari background focus subject pose pixel-bas gist-batch match high driven scene includ light background though our method train relat posit hand head appear captur someth substanti bodi pose general we plan evalu this result quantit use synthet data we access articul skeleton px c1 c1 c1 c2 c2 c2 c3 c3 c3 c4 c4 figur visual 2d c-ncar embed point re train set we show data point local geometri within four exampl cluster note even 2d embed we abl captur pose similar invari subject background queri c-ncar ncar gist pixel figur nearest neighbour pose estim leftmost column show queri imag remain column left right show nearest neighbour found nonlinear c-ncar regress linear ncar gist pixel distanc circl mark pose obtain by crowd-sourc we superimpos pose estim by c-ncar onto queri cross improv real-world perform synthet data there recent interest use synthet exampl improv perform real-world vision task subtl differ real synthet data make it difficult appli exist techniqu dataset compris type exampl this problem fall domain transfer learn best our knowledg transfer learn real synthet pair relat unexplor while previous work attempt learn represent invari effect geometr distort input tempor shift we know previous work explicit attempt learn featur invari natur input real synthet relat error test pixel error test synthet ncar ncar dimens code number synthet exampl figur effect code size perform convolut nca regress ad synthet data fix dataset real exampl improv test perform measur real data error express relat train set synthet data ncar-1 re-initi weight when synthet exampl ad ncar-2 reiniti weight random seed run curv show ad synthet exampl improv perform point synthet exampl outnumb real exampl pairwis natur our approach well-suit learn invari provid we establish correspond real synthet exampl our case pose estim this come label by forc exampl similar pose regardless whether they real synthet lie close-bi code space we implicit produc represent layer invari natur input we made attempt restrict pair real synthet exampl though this may aid learn invari demonstr the effect gradual ad synthet exampl sy the re train dataset we use reduced-s set real exampl for train gradual modifi contain synthet exampl fix set real exampl for test error express relat the case no synthet exampl we use linear nca for this experi train describ we follow two differ regim ncar-1 we reset the weight the model random each time we adjust the train set add synthet exampl we simpli add synthet data continu learn ncar-2 we reset the weight the random seed for each run the overal result the for each regim the addit synthet exampl the train set improv test perform real data level the number synthet exampl doubl the number real exampl conclus we present nonparametr approach for pose estim realist challeng video dataset the core our method learn parametr map high-dimension space a low-dimension space in distanc effici comput our work differ previous attempt learn invari map in it optim for nearest neighbour regress rather classif it scale realist size imag the use convolut weightshar this permit us learn domain-adapt featur direct pixel rather reli hand-craft featur global descriptor in our experi we restrict match we plan investig more sophist approach such local weight regress use the match an initi for a gradient descent search in a parametr model though we work video our model reli type tempor coher integr tempor knowledg in the form a prior would benefit our approach altern tempor context could integr at the input level simpl frame differenc more sophist tempor featur extract our entir network train end-to-end a singl object we perform network pre-train in recent work demonstr pre-train success appli convolut architectur both in the context rbms spars code we intend investig the effect pre-train well as the use mix generat discrimin object
----------------------------------------------------------------

title: 5017-the-power-of-asymmetry-in-binary-hashing.pdf

power asymmetri binari hash behnam neyshabur payman yadollahpour yuri makarychev toyota technolog institut chicago btavakoli pyadolla yuri ttic.edu ruslan salakhutdinov depart statist comput scienc univers toronto rsalakhu cs.toronto.edu nathan srebro toyota technolog institut chicago technion haifa israel nati ttic.edu abstract approxim binari similar use ham distanc short binari hash show even similar symmetr shorter accur hash use two distinct code map i.e approxim similar ham distanc two distinct binari code rather ham distanc introduct encod high-dimension object use short binari hash use fast approxim similar comput nearest neighbor search calcul ham distanc two short binari string extrem cheap comput oper communic cost send hash string lookup server send hash featur patch imag taken mobil devic low furthermor also possibl quick look nearbi hash string popul hash tabl inde take fraction second retriev shortlist similar item corpus contain billion data point import imag video audio document retriev task moreov compact binari code remark storag effici allow one store massiv dataset memori therefor desir find short binari hash correspond well target notion similar pioneer work local sensit hash use random linear threshold obtain bit hash later work suggest learn hash function attun distribut data recent work focus learn hash function optim agreement target similar measur specif dataset import obtain accur short hash comput communic cost scale linear length hash import memori cost hash tabl scale exponenti length above-ment approach similar two object approxim ham distanc output hash function emphasi hash function appli method like lsh multipl hash might use boost accuraci comparison still output function except awar singl map object fraction vector use threshold signdf x use databas similar approxim use becom known asymmetr hash even a-symmetri map base fraction map asymmetri one side comparison get threshold fraction actual map paper propos use two distinct map approxim similar ham distanc refer hash scheme asymmetr main result even target similar function symmetr well behav even base euclidean distanc object use asymmetr binari hash much power allow better approxim target similar shorter code length particular show extrem exampl collect point euclidean space neighborhood similar realiz use asymmetr binari hash base pair distinct function length bit symmetr hash base singl function would requir least bit although actual data extrem experiment result real data set demonstr signific benefit use asymmetr binari hash asymmetr hash use almost place symmetr hash typic use usual without addit storag comput cost consid typic applic store hash vector object databas calcul similar queri comput hash queri ham distanc store databas hash use asymmetr hash mean use differ hash function databas queri neither increas size databas represent comput communic cost popul databas perform queri exact oper requir fact hash entir databas asymmetr hash provid even opportun improv argu use two differ hash function encod databas object queri allow much flexibl choos databas hash unlik queri hash store compact effici evalu queri appear databas fix arbitrari map databas object bit string may use demonstr inde increas similar accuraci reduc bit length requir minimum code length power asymmetri let binari similar function set object interpret mean similar dissimilar indic whether neighbor symmetr binari code map bitlength code interest construct code ham distanc correspond similar threshold sign hf although discuss ham distanc conveni us work inner product hu vi equival ham distanc dh sinc hu vi 2dh section consid problem captur given similar use arbitrari binari code given entir similar map matrix finit domain object sij s xi ask encod ui object threshold sij sign hui uj least equal hold mani pair possibl import emphas goal pure approxim given matrix use short binari code out-of-sampl general ask allow asymmetr code enabl approxim symmetr similar matrix shorter code length denot matrix whose column contain codeword ui minim binari code length allow exact repres given follow matrix factor problem ks min s.t sij yij 1n matrix one begin demonstr power asymmetri consid asymmetr variant problem even symmetr allow associ object two distinct binari codeword ui vi think two arbitrari map ui vi g xi sij sign hui vj minim asymmetr binari code length given ka min s.t sij yij write binari code problem matrix factor problem use understand power get asymmetri even symmetr even seek symmetr insist write squar binari matrix might tough constraint captur follow theorem establish could exponenti gap minim asymmetri binari code length minim symmetr code length even matrix symmetr well behav theorem exist set point euclidean space similar matrix kxi sij ka 2r ks 2r kxi proof let i1 i2 consid matrix defin gii gij i1 i2 gij otherwis matrix diagon domin gershgorin circl theorem posit definit therefor exist vector hxi gij everi defin kxi sij kxi note sij i1 i1 i2 i2 kxi gii gjj 2gij therefor sij final i1 kxi gii gjj 2gij therefor sij show ka let matrix whose column vector vertic cube let anr matrix defin cij i1 cij i2 let order threshold yij sij yij sij therefor ka show ks ks consid let note yij0 ks thus ks let one follow minus one yii0 yij0 yij0 j sij ks j sij j sij j sij nks nks n2 2nks n2 conclud ks construct theorem show exist data set asymmetr binari hash might much shorter symmetr hash import observ demonstr asymmetr hash could much power prompt us consid instead symmetr hash precis construct theorem cours rather extrem fact extrem construct possibl would expect actual data set exact structur show later signific gap also real data set uniform symmetr asymmetr symmetr asymmetr labelm bit bit averag precis averag precis figur number bit requir approxim two similar matric function averag precis left uniform data 10-dimension hypercub similar repres threshold euclidean distanc set similar posit right semant similar subset labelm imag threshold similar posit approxim binari code turn real data set also need depart seek binari code exact captur similar matrix rather usual satisfi mere approxim fix code length seek symmetr asymmetr k-bit code best captur similar matrix s. this captur follow optim problem min l y yij j sij j sij zero-one-error paramet allow us weight posit negat error differ weight compens sij imbalanc typic mani pair point non-similar rather similar allow us obtain differ balanc precis recal optim problem discret discontinu high non-convex problem experi replac zero-on loss continu loss perform local search greedili updat singl bit improv this object although result object let alon discret optim problem still convex even convex found benefici use loss function flat encourag move toward correct sign experi use squar root logist loss move out-of-sampl general briefli report number bit need empir find good approxim actual similar matric symmetr asymmetr code experi sever data set attempt fit symmetr asymmetr code calcul averag precis vari threshold keep fix result two similar matric one base euclidean distanc point uniform distribut hypoercub base semant similar imag shown figur out sampl general learn map far focus learn binari code fix set object associ arbitrari code word object complet ignor input represent object discuss well binari hash approxim similar consid general addit new object howev applic would like abl out-of-sampl general would like learn map infinit domain use finit train set object appli map obtain binari code futur object encount sign hf thus map usual limit constrain parametr class could repres evalu effici new object ensur good general exampl rd consid linear threshold map fw sign w rk sign oper elementwis minim loss hash could also consid complex class multilay network alreadi saw asymmetr binari code allow better approxim use shorter code natur seek asymmetr code well instead learn singl parametr map learn pair map constrain parametr class threshold sign hf this potenti allow better approxim similar thus better overal accuraci shorter code despit possibl slight harder general due increas number paramet fact typic applic databas object hash similar search futur queri asymmetri allow us go even consid follow setup given object infinit domain similar s xi object goal hash object use short binari code would allow us quick comput approxim similar object databas futur object queri would like generat store compact binari code object databas given new queri object would like effici comput compact binari code given queri retriev similar item databas fast find binari code databas within small ham distanc queri binari code recal it import ensur bit length hash small short code allow fast ham distanc calcul low communic cost code need sent remot import would like store databas hash tabl allow immedi lookup size hash tabl exponenti code length symmetr binari hash approach would find singl parametr map sign hf futur queri databas object calcul databas object store hash perhap hash tabl allow fast retriev code within short ham distanc asymmetr approach describ would find two parametr map sign hf g xi calcul store g xi databas fix go there actual need constrain parametr class need general futur object effici calcul it on-the-fli communic databas henc consid allow databas hash function arbitrari map aim find simpl parametr map arbitrari codeword v1 vn databas sign hf vi futur queri object databas this form asymmetri allow us greater approxim power thus better accuraci shorter code addit comput storag cost section evalu empir asymmetr strategi demonstr benefit but befor next section discuss local-search approach find map map code v1 vn optim focus rd linear threshold hash map form sign w rk given train point consid two model discuss learn two linear threshold function sign wq sign wd i.e need find paramet wq wd rk learn singl linear threshold function sign wq codeword v1 vn rk i.e need find wq rk well rk n vi column either case denot ui also vi g xi learn attempt minim object continu loss function squar root logist learn optim problem addit constraint sign wq possibl also sign wd rd n optim problem altern updat row wq either row wd understand updat let us first return un5 constrain consid updat row rn denot predict matrix compon subtract away it easi verifi write l u depend rn n also depend given sij yij sij yij mij depend sij this impli optim entir row concurr maxim so optimum condit row given sign m symmetr optim row condit rest case condit wq rest similar optim row wq amount optim xd arg max sign w x m arg max mi sign rd rd this weight zero-one-loss binari classif problem target sign mi weight mi approxim it weight logist regress problem updat iter attempt improv object use small number epoch stochast gradient descent logist loss in also symmetr updat row wd optim model bit-length we initi optim 1-length model we initi new bit either random threshold rank-on project unconstrain rank-on project project column in row column in in column space we take initi random rank-on base that yield lower object valu empir evalu in order empir evalu benefit asymmetri in hash we replic experi in turn base six dataset use learn symmetr linear threshold code dataset includ labelm peekaboom collect imag repres gist featur photo-tour databas imag patch repres sift featur mnist collect greyscal handwritten imag nurseri contain 8d featur similar we also construct synthet uniform dataset contain uniform sampl point hypercub we use point train test dataset we find euclidean distanc point averag neighbour this defin ground-truth similar in term neighbour non-neighbour so dataset we given set point repres vector in rd binari similar s xi point correspond neighbor otherwis base these train point present sophist optim approach learn threshold linear hash function form sign w rk this hash function appli store in databas evalu qualiti hash consid independ set test point compar sign hf test point databas object train point in experi we follow protocol but two asymmetr variat in in in use optim method discuss in sec in order obtain differ balanc precis recal we vari in obtain differ code valu uniform lin v lin lin mlh ksh bre lsh lin v lin lin mlh ksh bre lsh number bit lin v lin lin mlh ksh bre lsh nurseri number bit averag precis lin v lin lin mlh ksh bre lsh averag precis number bit lin v lin lin mlh ksh bre lsh photo-tour averag precis number bit peekaboom averag precis mnist averag precis averag precis labelm lin v lin lin mlh ksh bre lsh number bit number bit figur averag precis point retriev use ham distanc function code length six dataset five curv repres lsh bre ksh mlh two variant method asymmetr lin-lin asymmetr lin-v best view in color labelm mnist averag precis lin v lin lin mlh ksh bit requir averag precis lin v lin lin mlh ksh peekaboom bit requir bit requir lin v lin lin mlh ksh averag precis figur code length requir function averag precis three dataset howev in experi we actual learn code map map matrix use fix valu then vari threshold obtain precision-recal curv in experi in addit minim loss hash we also compar approach three wide use method kernel-bas supervis hash ksh binari reconstruct embed bre locality-sensit hash lsh in first set experi we test perform asymmetr hash code function bit length figur display averag precis data point retriev use ham distanc function code length these result similar one report mlh yield higher precis compar bre lsh observ that six dataset variant our method asymmetr in in asymmetr in consist outperform method differ binari code length gap particular larg short code exampl labelm dataset mlh ksh bit achiev ap respect wherea in alreadi achiev ap bit figur show similar perform gain appear number dataset we also note across dataset in improv upon in in short-siz code these result clear show that asymmetr binari hash much compact symmetr hash we use bre ksh mlh implement avail origin author method we follow instruct provid author specif we set number point hash function in bre number anchor in ksh default valu mlh we learn threshold shrinkag paramet cross-valid paramet initi suggest valu in the packag labelm bit mnist bit lin v lin lin mlh ksh bre lsh lin v lin lin mlh ksh bre lsh recal precis precis precis precis bit lin v lin lin mlh ksh bre lsh recal 64bit lin v lin lin mlh ksh bre lsh recal recal figur precision-recal curv for labelm mnist dataset use binari code best view in color lin v mlh ksh recal precis lin v mlh ksh recal number retriev figur left precision-recal curv for the semant labelm dataset right percentag ground-truth neighbour function retriev imag best view in color next we show in figur the full precision-recal curv for two dataset labelm mnist for two specif code length bit the perform in in in almost uniform superior that mlh ksh bre method we observ similar behavior also for the four dataset across various differ code length result previous dataset show that asymmetr binari code signific outperform state-of-the-art method relat small scale dataset we now consid much larger labelm dataset call semant labelm it contain train imag test imag imag repres gist descriptor the dataset also provid semant similar two imag base semant content object label overlap in two imag as argu hash function learn use semant label use for content-bas imag retriev compar euclidean distanc figur show that in bit substanti outperform mlh ksh bit summari the main point we would like make that when consid binari hash in order approxim similar even the similar measur entir symmetr well behav much power can gain consid asymmetr code we substanti this claim theoret analysi the possibl power asymmetr code show in fair direct experiment replic that asymmetr code outperform state-of-the-art result obtain for symmetr code the optim approach we use crude howev even use this crude approach we could find asymmetr code that outperform well-optim symmetr code it certain possibl develop much better well-found train optim procedur although we demonstr our result in specif set use linear threshold code we believ the power asymmetri far more wide applic in binari hash view the experi as mere a demonstr this power use asymmetr code instead symmetr code could much more power allow for shorter more accur code usual straightforward requir addit comput communic or signific addit memori resourc when use the code we would therefor encourag the use such asymmetr code two distinct hash map wherev binari hash use to approxim similar acknowledg this research partial support by nsf career award nsf grant
----------------------------------------------------------------

title: 251-a-self-organizing-associative-memory-system-for-control-applications.pdf

hormel sell-organ associ memori system lor control applic michael bormel depart control theori robot technic univers darmstadt schlossgraben darmstadt/w.-ger.ani abstract chac storag scheme use basi softwar implement associ emori system ah major part learn control loop lerna major disadvantag chac-concept degre local general area interpol fix paper deal algorithm self-organ variabl general ak base idea t. kohonen introduct sever year research depart control theori robot technic univers darmstadt concern design learn real-tim control loop neuron-lik associ memori lerna self-organ associ memori system control applic control unknown nonlinear process ersu toll control concept use associ memori system ah base cerebellar cortex model chac albus albus storag predict nonlinear process model appropri nonlinear control strategi e ect process respons i plann control input red setpoint co predict process opti.iud control input evalu opti. actual/past process infor. control strate actual control input i unknown process i i short ter e.ori process infor. i i lassocial lie.ori syst figur learn control loop lerna one problem adjust control loop process howev find suitabl set paramet associ memori paramet question determin degre general within memori therefor direct influenc number train step requir learn process behaviour good perform control loop desir small general around given setpoint larg general elsewher actual amount collect data small transit phase two hormel setpoint larg setpoint control therefor self-organ variabl general adapt amount avail data would advantag up work fix general find right paramet meant find best compromis perform learn time requir generat process model paper show possibl introduc self-organ variabl general capabl exist ams/cmac algorithm ams-concept associ memori syst am base cerebellar model articul control cmac present j.s albus inform process structur am divid three stage each compon n-dimension input vector stimulus activ fix number sensori cell recept field overlap n p sensori cell becom activ activ sensori cell group form n-dimension vector these vector map associ cell merg recept field sensori cell describ one vector seen hypercub n-dimension input space therefor recept field associ cell normal applic total number avail associ cell associ cell connect output cell modifi synapt weight output cell comput mean valu weight connect activ associ cell activ weight figur show basic principl associ memori system am self-organ associ memori system control applic output valu input space adjust weight figur basic aechan am train generat output compar desir output error comput equal distribut activ weight map sensori cell associ cell hash-cod mechan use self-organ featur map approach explain self-organ capabl nervous system present t. kohonen kohonen self-organ featur mapft network later interconnect neuron adapt accord densiti train point input space present n-diaension input vector network caus everi neuron produc output signal correl similar input vector templat vector may store synapt weight neuron due mexican-hat coupl function neuron one maximum output activ excit nearest neighbour inhibit neuron farther away therefor generat local respons network activ cell adapt input weight order increas similar input vector if defin recept field neuron number input vector neuron activ greater hormel neuron net yield effect area high densiti train point recept field becom small wherea area low densiti train point size recept field larg mention desir effect workin learn control loop self-organ variabl general both approach sever advantag disadvantag use real-tim control applic ak algorithm one care predefin network coupl function coupl matric among element network associ weight cell generat need train adress quiet produc memori respons one disadvantag fix general paramet eaori unit chosen unlik ah featur map allow adapt network accord input data advantag pay extens search best match neuron network therefor respons time network aay larg real-tia control work big network these problem overcom allow map sensori cell associ cell ak longer fix chang train accomplish this templat vector introduc everi associ cell this vector serv indic stimuli associ cell access previous dure an associ recal stimulus preliminari set associ cell activ hash code mechan due self-organ process dure train templat vector need correspond input vector search self-organ associ memori system control applic best aatch cell templat vector access associ cell compar stiaulus differ vector calcul l.v number search step this vector use comput virtual stimulus compens map error hash-cod mechan best match cell found ns adress virtual stimulus use hash code mechan this search mechan ensur best match cell found even if self organ effect dure train templat cell updat vector associ later distanc neuron network denot valu teaplat vector time denot stimulus is monoton decreas function time later distanc neuron network simul result figur show simul result present algorithm for the dase two dimension stimulus vector hormel figur show the expect posit input space the untrain templat vector denot untrain associ cell figur untrain etwork figur show the network train step stimuli gaussian distribut input space the posit the templat vector train cell shift the direct the better train area so associ cell use repres this area therefor the store inform exact this area figur network train step a self-organ associ memori system for control applic conclus the ney algorithm present introduc the capabl adapt the storag mechan a cmac-typ associ memori accord the arriv stimuli this result in various degre general depend the number train point in a given area therefor make it unnecessari to choos a general factor a compromis sever constraint repres nonlinear function store in this type associ memori some result test present togeth a comparison respect result for the origin am acknowledg this work sponsor the german inistri for technolog bmft grant itr research
----------------------------------------------------------------

title: 3705-an-online-algorithm-for-large-scale-image-similarity-learning.pdf

onlin algorithm larg scale imag similar learn gal chechik googl mountain view ca gal google.com varun sharma googl bengalooru karnataka india vasharma google.com uri shalit icnc hebrew univers israel uri.shalit mail.huji.ac.il sami bengio googl mountain view ca bengio google.com abstract learn measur similar pair object fundament problem machin learn stand core classif method like kernel machin particular use applic like search imag similar given imag find video relev given video task user look object visual similar also semant relat given object unfortun current approach learn similar scale larg dataset especi impos metric constraint learn similar describ oasi method learn pairwis similar fast scale linear number object number non-zero featur scalabl achiev onlin learn bilinear model spars represent use larg margin criterion effici hing loss cost oasi accur wide rang scale standard benchmark thousand imag precis state-of-the-art method faster order magnitud million imag collect web oasi train within day singl cpu nonmetr similar learn oasi transform metric similar achiev higher precis similar learn metric first place suggest approach learn metric data larger order magnitud handl introduct learn pairwis similar measur data fundament task machin learn pair distanc underli classif method like nearest neighbor kernel machin similar learn import applic query-by-exampl inform retriev instanc user may wish find imag similar ident copi imag user watch onlin video may wish find addit video subject case interest find semantically-rel sampl base visual content imag enorm search space learn related function exampl could use tool task larg number previous studi learn similar focus metric learn like case posit semidefinit matrix defin mahalanobi distanc howev similar learn algorithm often evalu context rank amount train data avail small ad posit constraint enforc metric properti use reduc overfit improv general howev suffici data avail mani modern applic ad posit semi-definit constraint cost benefit term general may limit view take approach avoid impos posit symmetri constraint learn similar measur similar learn algorithm assum avail train data contain real-valu pairwis similar distanc focus weaker supervis signal relat similar differ pair signal also easier obtain here extract similar inform pair imag share common label retriev respons common text queri imag search engin current paper present approach learn semant similar scale two order magnitud larger current publish approach three compon combin make approach fast scalabl first approach use unconstrain bilinear similar given two imag p1 p2 measur similar bilinear form p1 wp2 matrix requir posit even symmetr second use spars represent imag allow comput similar fast final train algorithm develop oasi onlin algorithm scalabl imag similar learn onlin dual approach base passive-aggress algorithm minim larg margin target function base hing loss converg high qualiti similar measur present small fraction train pair find oasi fast accur wide rang scale standard benchmark thousand imag achiev better compar result exist state-of-the-art method comput time shorter order magnitud web-scal dataset oasi train two million imag within three day singl cpu larg scale dataset human evalu oasi learn similar show ten nearest neighbor given imag semant relev imag learn relat similar consid problem learn pairwis similar function given supervis relat similar two pair imag algorithm design scale well number sampl number featur use fast onlin updat spars represent formal given set imag imag repres vector rd assum access oracl given queri imag pi locat two imag pi pi relev pi pi p. formal could write relev pi pi relev pi pi howev unlik method assum numer valu similar avail relev pi pj use weaker form supervis assum pair imag rank relev queri imag pi relev measur could reflect relev imag belong class imag queri imag reflect semant properti imag goal learn similar function sw pi pj parameter assign higher similar score pair relev imag safeti margin pi s pi pi pi pi paper consid parametr similar function bi-linear form sw pi pj pti pj rd import imag vector pi rd spars name number non-zero entri ki kpi k0 small ki valu score defin comput effici even larg specif sw comput complex o ki kj regardless dimension learn score function obey constraint defin global hing loss possibl triplet loss lw accumul train set lw loss singl triplet pi pi pi lw pi pi pi max sw pi pi sw pi pi minim global loss lw propos algorithm base passive-aggress famili algorithm first initi ident matrix w0 id algorithm iter draw random triplet pi pi solv follow convex problem soft margin wi argmin kw k2f ro lw pi pi k kf ro frobenius norm point-wis norm ith iter wi updat optim trade-off stay close previous paramet minim loss current triplet lw pi pi aggress paramet control trade-off solv problem follow deriv lw pi pi clear wi satisfi direct otherwis defin lagrangian kw k2f ro pti pi lagrang multipli optim solut obtain gradient vanish vi vi gradient matrix lw current step vi pi pi pi pi imag vector spars gradient vi also spars henc updat step cost o |pi k0 kpi k0 l0 norm kxk0 number nonzero valu differenti lagrangian respect know mean c. plug obtain back lagrangian obtain kvi pti pi final take deriv second lagrangian respect use obtain vi lwi pi pi min kvi optim updat new therefor form gradient descent step step size comput exact appli algorithm classif task shown yield small cumul onlin loss select best wi train use hold-out valid set shown achiev good general emphas oasi guarante learn paramet matrix posit even symmetr studi variant oasi enforc symmetri posit sec relat work learn similar use relat relev intens studi recent approach aim address learn larg scale small-scal data two main group similar learn approach first approach learn mahalanobi distanc view learn linear project data anoth space often lower dimension euclidean distanc defin among pair object approach includ fisher s linear discrimin analysi relev compon analysi rca supervis global metric learn larg margin nearest neighbor lmnn metric learn collaps class mlcc constraint like spars sometim induc learn metric see also review detail second famili approach learn kernel use improv perform kernel base classifi learn full kernel matrix non parametr way prohibit except small data set altern sever studi suggest learn weight sum pre-defin kernel weight learn data applic shown inferior uniform weight kernel work learn weight local distanc function everi imag train set non linear imag similar learn also studi context dimension reduct final jain al base davi al aim learn metric onlin set work one closest work respect oasi learn onlin linear model dis- similar queri imag top relev imag retriev oasi tabl oasi success case web dataset relev text queri imag shown beneath imag use train function document imag main differ jain al tri learn true distanc impos posit definit constraint make algorithm complex constrain argu paper larg scale regim impos constraint throughout could detriment learn semant similar function imag also studi there semant similar learn repres imag posterior probabl distribut predefin set semant tag comput distanc two imag distanc two under posterior distribut represent size imag therefor grow number semant class experi test oasi two dataset span wide regim scale first test scalabl million imag collect web quantit compar precis oasi small-scal metric-learn method test oasi use caltech-256 standard machin vision benchmark imag represent use spars represent base bag visual word featur systemat test found outperform featur relat task detail visual represent outsid focus paper broad speak featur extract divid imag overlap squar block repres block edg color histogram find nearest block predefin set dictionari vector featur imag thus repres number time dictionari visual word present yield vector rd averag non-zero valu evalu protocol evalu perform algorithm use precision-at-top-k standard rank precis measur base nearest neighbor queri imag test set test imag rank accord similar queri imag number same-class imag among top imag nearest neighbor comput averag across test imag also calcul mean averag precis measur wide use inform retriev communiti web-scal experi first test oasi set million imag scrape googl imag search engin collect set anonym text queri queri access set relev imag comput image-imag relev measur first obtain measur relev imag text queri achiev collect anonym click imag collect set text queri use query-imag click count c queri imag comput unnorm probabl two imag co-queri relev imag imag c. relev matrix threshold keep top percent valu train oasi train set million imag test perform million imag number train iter correspond sampl one triplet select use second valid set around imag perform satur million iter overal train took total minut singl cpu standard modern machin tabl show top five imag rank oasi two exampl query-imag test set these exampl oasi captur similar goe beyond visual appear top rank imag concept queri imag even though concept never provid textual form infer viewer mind show learn similar across co-queri imag inde captur semant queri even queri explicit use train obtain quantit evalu rank obtain oasi creat evalu benchmark ask human evalu mark set candid imag semant relev set popular imag queri queri imag evalu present imag rank oasi mix random imag given relev rank evalu we comput precis oasi rank fraction peopl mark imag relev queri imag averag across queri evalu oasi rank yield precis top rank imag estim upper bound difficulti task we also comput precis obtain human evalu everi evalu we use rank evalu ground truth comput precis rank oasi we comput fraction evalu mark imag relev repeat separ everi queri human evalu provid measur coher per queri show mean precis obtain oasi human evalu everi queri data queri oasi achiev precis close mean human evalu mani case oasi achiev precis good better evalu human precis oasi precis fast lmnn mnist categori day nd project extrapol poli oasi web data runtim min precis 2day hrs 5min day hrs 3hrs min 37sec 9sec queri id sort precis 2m number imag log scale figur precis oasi human evalu per queri use rank remain human evalu ground truth comparison runtim oasi fast-lmnn wide rang scale lmnn result mnist data faster oasi result subset web data howev lmnn scale quadrat number sampl henc three time slower imag may infeas handl million imag we studi runtim oasi scale size train set figur show runtim oasi found earli stop separ valid set grow linear train set size we compar fastest result we found literatur base fast implement lmnn lmnn algorithm scale quadrat number object although experi mnist data show activ set constraint grow linear this could mnist class class class class precis precis precis oasi mcml lego lmnn euclidean random number neighbor oasi mcml lego lmnn euclidean random number neighbor oasi lego lmnn euclidean random number neighbour figur comparison perform oasi lmnn mcml lego euclidean metric featur space curv show precis top function neighbor result averag across train/test partit train imag test imag per class error bar standard error mean black dash line denot chanc perform caltech256 dataset compar oasi small-scal method we use caltech256 dataset contain imag collect googl imag search picsearch.com imag assign categori evalu human order ensur imag qualiti relev we pre-process imag filter imag small we left imag categori allow comparison method optim spars represent we also reduc block vocabulari size we compar oasi follow metric learn method euclidean standard euclidean distanc featur space equival use ident matrix id mcml learn mahalanobi distanc same-class sampl map point formul convex problem lmnn learn mahalanobi distanc aim k-nearest neighbor given sampl belong class separ different-class sampl larg margin preprocess phase imag project basi princip compon pca data dimension reduct lego onlin learn mahalanobi distanc use log-det regular per instanc loss guarante yield posit semidefinit matrix we use variant lego like oasi learn relat distances.1 we test method subset class taken caltech256 repositori oasi imag class treat similar subset built includ semant divers categori control classif difficulti we test set contain class span rang difficulti we use two level 5-fold cross valid one train model second select hyper paramet each method earli stop time oasi paramet lmnn regular paramet lego result report obtain select best valu hyper paramet then train full train set imag per class figur compar precis obtain oasi four compet approach oasi achiev consist superior result throughout full rang number neighbor test four set studi lmnn perform train set often high suggest overfit train set also observ sometim tabl show total cpu time minut train algorithm compar four subset class size data given runtim longer day perform wors euclidean baselin for purpos fair comparison we test two implement oasi first fulli implement matlab second core loop algorithm implement call matlab method use we also experi method we found slow rca whose precis lower method these result includ evalu tabl runtim minut standard cpu compar method num class oasi matlab oasi matlab+c mcml matlab+c lego matlab lmnn matlab+c fastlmnn matlab+c code suppli author implement matlab core part implement c. due compat issu fast-lmnn run differ machin given time rescal time scale algorithm lego fulli implement matlab code compil mex c. implement oasi signific faster sinc matlab use potenti speedup gain spars imag oasi signific faster runtim shorter order magnitud mcml even small set one order magnitud faster lmnn run time oasi lego measur point earli stop oasi memori requir grow quadrat size dictionari for larg dictionari paramet matrix take float giga byte memori mean averag precis precis oasi proj oasi onlin proj oasi dissim oasi euclidean random number neighbor proj everi proj everi proj complet learn step figur compar symmetr variant oasi 20-class subset similar result obtain set map along train for three psd project scheme symmetri posit similar matrix learn oasi guarante posit even symmetr some applic like rank imag semant relev given imag queri known non-symmetr base human judgement howev some applic symmetri posit constraint reflect prior knowledg may help avoid overfit we discuss variant oasi learn symmetr posit matric symmetr similar simpl approach enforc symmetri project oasi model onto set symmetr matric sym w wt project done each updat denot online-proj-oasi learn complet proj-oasi altern asymmetr score function sw pi pj lw replac symmetr score sw pi pj pj pi pj use deriv oasis-lik algorithm we name dissim-oasi optim updat for this loss symmetr gradient v pi pi pi pi pi therefor initi symmetr matrix ident all guarante remain symmetr dissim-oasi close relat lmnn this seen cast batch object lmnn onlin setup form err w sw pi lw pi pi pi this onlin version lmnn becom equival dissim-oasi for figur compar precis differ symmetr variant origin oasi all symmetr variant perform slight wors equal origin asymmetr oasi precis proj-oasi equival oasi like sinc asymmetr oasi actual converg almost-symmetr model as measur symmetri index ksym w k kwk2 posit similar most similar learn approach focus learn metric context oasi when posit semi definit defin mahalanobi distanc imag matrix squareroot at then use project data new space in euclidean distanc equival distanc in the origin space we experi posit variant oasi we repeat project the learn model onto the set psd matric everi iter project done take the eigen decomposit vt the eigenvector matrix the diagon eigenvalu matrix limit posit eigenvalu figur trace precis the test set throughout learn for various valu the effect posit project complex first continu project at everi step help reduc overfit as observ the slower declin the blue curv upper smooth curv compar the orang curv lowest curv howev when project perform mani step instead continu perform the project model actual outperform the continuous-project model upper jitteri curv the reason for this effect like estim the posit sub-spac noisi when base on sampl inde accur estim the negat subspac known hard problem in the estim eigenvalu eigenvector near zero relat larg we found this effect strong the optim project strategi avoid project throughout learn complet instead project psd learn name model chosen use earli stop provid the best perform in our experi an interest altern obtain psd matrix explor use logdet diverg two matric dld tr xy log det xy ensur given an initi psd matrix all subsequ matric psd as well interest test the effect use logdet regular in the oasi setup discuss we present oasi scalabl algorithm for learn imag similar captur semant visual aspect imag similar three key factor contribut the scalabl oasi first use larg margin onlin approach allow train converg even after see small fraction potenti pair second the object function oasi requir the similar measur metric train although it appear to converg to near-symmetr solut whose posit project good metric final we use spars represent low level featur allow to comput score effici oasi learn class-independ model it awar queri categori share two similar imag as such it limit in descript power it like classdepend similar model could improv precis on the other hand class-independ model could general to handl class observ train as in transfer learn larg scale similar learn appli to imag larg varieti class could therefor a use tool to address real-world problem with a larg number class this paper focus on the train part metric learn to use the learn metric for rank an effici procedur for score a larg set imag need techniqu base on locality-sensit hash could use to speed evalu this outsid the scope this paper
----------------------------------------------------------------

title: 2566-neighbourhood-components-analysis.pdf

neighbourhood compon analysi jacob goldberg sam rowei geoff hinton ruslan salakhutdinov depart comput scienc univers toronto jacob rowei hinton rsalakhu cs.toronto.edu abstract paper propos novel method learn mahalanobi distanc measur use knn classif algorithm algorithm direct maxim stochast variant leave-one-out knn score train set also learn low-dimension linear embed label data use data visual fast classif unlik method classif model non-parametr make assumpt shape class distribut boundari perform method demonstr sever data set metric learn linear dimension reduct introduct nearest neighbor knn extrem simpl yet surpris effect method classif appeal stem fact decis surfac nonlinear singl integ paramet easili tune cross-valid expect qualiti predict improv automat amount train data increas advantag share mani non-parametr method reflect fact although final classif machin quit high capac sinc access entir reservoir train data test time trivial learn procedur rare caus overfit howev knn suffer two serious drawback first comput sinc must store search entir train set order classifi singl test point storag potenti reduc edit thin train data low dimension input space search problem mitig employ data structur kd-tree ball-tre second model issu distanc metric use defin nearest neighbour test point defin paper attack difficulti learn quadrat distanc metric optim expect leave-one-out classif error train data use stochast neighbour select rule furthermor forc learn distanc metric low rank thus substanti reduc storag search cost test time stochast nearest neighbour distanc metric learn begin label data set consist real-valu input vector rd correspond class label c1 cn want find distanc metric maxim perform nearest neighbour classif ideal would like optim perform futur test data sinc know true data distribut instead attempt optim leave-one-out loo perform train data follow restrict learn mahalanobi quadrat distanc metric alway repres symmetr posit semi-definit matric estim metric invers squar root learn linear transform input space transform space knn perform well denot transform matrix effect learn metric q x ax ax ay actual leave-one-out classif error knn quit discontinu function transform sinc infinitesim chang may chang neighbour graph thus affect loo classif perform finit amount instead adopt well behav measur nearest neighbour perform introduc differenti cost function base stochast neighbour assign transform space particular point select anoth point neighbour probabl pij inherit class label point select defin pij use softmax euclidean distanc transform space exp kaxi axj exp kaxi axk pij pii stochast select rule comput probabl pi point correct classifi denot set point class ci j|ci cj pij pi j ci object maxim expect number point correct classifi scheme xx pi pij j ci differenti respect transform matrix yield gradient rule use learn denot xij xx pij xij pik xik ij ik j ci reorder term obtain effici comput express pi 2a pik xik pij xij ik ij j ci algorithm dub neighbourhood compon analysi extrem simpl maxim object use gradient base optim deltabar-delta conjug gradient cours sinc cost function convex care must taken avoid local maxima train howev unlik mani object function good optima necessarili deep rather broad experi larger drive train better test perform word never observ overtrain effect notic learn overal scale well relat direct row also effect learn real-valu estim optim number neighbour estim appear effect perplex distribut pij learn procedur want reduc effect perplex consult fewer neighbour scale uniform similar scale entri increas perplex effect averag neighbour stochast select maxim object function equival minim l1 norm true class distribut probabl one true class stochast class distribut induc pij via natur altern distanc kl-diverg induc follow object function log pij log pi j ci maxim object would correspond maxim probabl obtain perfect error free classif entir train set gradient even simpler j ci pij xij xij 2a pik xik xik j ci pij experi optim cost function well found transform learn perform result train test data similar obtain origin cost function speed gradient comput sum appear equat data point neigbour point truncat one stochast gradient rather exact gradient pij drop quick low rank distanc metric nonsquar project often use reduc dimension input data either comput save regular subsequ learn algorithm linear dimension reduct techniqu appli linear oper origin data order arriv reduc represent popular fast relat immun overfit becaus implement affin map linear project also preserv essenti topolog origin data mani approach exist linear dimension reduct rang pure unsupervis approach factor analysi princip compon analysi independ compon analysi method make use class label addit input featur linear discrimin analysi possibl combin relev compon analysi restrict nonsquar matrix size nca also linear dimension reduct case learn metric low rank transform input lie rd sinc transform linear without loss general consid case d. make restrict potenti reap mani benefit beyond alreadi conveni method learn knn distanc metric particular choos vast reduc storag search-tim requir knn select also comput use low dimension visual label dataset use linear project algorithm exact optim cost function use gradient descent nonsquar method requir matrix invers assum parametr model gaussian otherwis class distribut boundari dimension reduc represent number row must set user use high rectangular signific reduc comput load knn expens restrict allow metric rank achiev appli nca learn algorithm find optim transform store project train point yn axn well label test time classifi new point xtest first comput project ytest axtest knn classif ytest use yn simpl euclidean metric if relat small say less preprocess yn build kd-tree ball-tre increas speed search test time storag requir method o dn dd compar o dn knn origin input space experi metric learn dimension reduct evalu nca algorithm standard distanc metric knn method linear dimension reduct experi use data set uc irvin repositori compar nca transform obtain optim squar train set default euclidean distanc i whiten transform sampl data covari matrix rca transform averag within-class covari matric also investig behaviour nca restrict diagon allow axi align mahalanobi measur figur show train import test perform nca consist better mahalanobi distanc measur knn despit relat simplic nca object function fact distanc metric learn noth posit definit matrix also investig use linear dimension reduct use nca nonsquar visual well reduced-complex classif sever dataset figur show exampl visual first generat synthet threedimension dataset shown top row figur consist class shown differ color two dimens class distribut concentr circl third dimens gaussian nois uncorrel dimens class label if nois varianc larg enough project found pca forc includ nois shown top left figur full rank euclidean metric would also misl dimens class convex linear separ henc result obtain lda inappropri shown figur contrast nca adapt find best project without assum parametr structur low dimension represent also appli nca uci wine dataset consist point label class databas gray-scal imag face consist class separ individu dimens imag size face dataset consist imag person final appli our algorithm subset usp dataset handwritten digit imag consist first five digit class grayscal imag downsampl pixel resolut result dimens seen figur two-dimension project use class consist much better separ nca transform either pca unsupervis lda access class label cours nca transform still linear project optim cost function explicit encourag local separ quantifi project result we appli nearest-neighbor classif project space use project learn train time we project train set futur test point perform knn low-dimension space use euclidean measur result pca lda lda follow rca nca transform use appear figur nca project consist give superior perform high constrain low distanc metric learn train distanc metric learn test nca diag nca rca whiten euclidean bal ion iri wine nca diag nca rca whiten euclidean hous digit bal rank transform train iri wine hous digit rank transform test nca lda+rca lda pca bal ion iri wine hous digit nca lda+rca lda pca ion bal ion iri wine hous digit figur knn classif accuraci left train right test uci dataset balanc ionospher iri wine hous usp handwritten digit result averag realize split dataset train test subset usp imag digit class use train test top panel show distanc metric learn squar bottom panel show linear dimension reduct rank knn set summari we found label data avail nca perform better term classif perform project represent term visual class separ compar standard method pca lda extens continu label semi-supervis learn although we focus discret class linear transform fulli supervis learn mani extens basic idea possibl clear nonlinear transform function could learn use architectur multilay perceptron trainabl gradient method furthermor possibl extend classif framework present case real valu continu supervis signal defin set correct match ci point point similar continu target natur lead idea soft match object function becom sum pair weight agreement accord target learn under object still proceed even set target explicit provid long inform identifi close pair pca lda nca figur dataset visual result pca lda nca appli top concentr ring wine face digit dataset data reduc origin dimension respect dimens show figur two dimension output neural network set test case left point shown use line segment orient input face right point shown size circl repres size face avail such semi-supervis task often aris domain strong spatial tempor continu constraint supervis in video a person face we may assum pose express vari slowli in time even if individu frame ever label explicit numer pose express valu illustr we generat pair face in follow way first we choos two face random feret-b dataset isol face a standard orient scale first face rotat by angl uniform distribut scale a height uniform distribut pixel second face a differ person given rotat scale gaussian nois pixel pair given a weight wab probabl densiti ad nois divid by maximum possibl valu we train a neural network one hidden layer logist unit map pixel intens a face a point in a output space backpropag use minim cost function in encourag face in a pair place close togeth exp ||ya yb cost wab log c exp ||yc yd pair a b indic face one form a pair four exampl face shown right horizont pair agre vertic figur show feedforward neural network discov polar coordin without user decid repres scale orient in output space relationship other method conclus sever paper recent address problem learn mahalanobi distanc function given label data least side-inform form equival constraint two relat method rca a convex optim base algorithm rca implicit assum a gaussian distribut class describ use first two moment class-condit distribut xing al attempt find a transform minim pairwis squar distanc point in class implicit assum class form a singl compact connect set high multimod class distribut this cost function sever penal low propos a method similar use a limit idea learn a nearest neighbour distanc metric in approach metric constrain diagon well it somewhat redund parameter object function correspond the averag squar error the true class distribut the predict distribut entir appropri in a probabilist set in parallel work learn low rank transform fast classif visual the classic lda algorithm optim if class distribut gaussian a singl share covari this assumpt howev rare true lda also suffer a small sampl size problem deal high-dimension data the within-class scatter matrix near singular recent variant lda make the transform robust to outlier to numer instabl enough datapoint avail this problem exist in our method sinc need a matrix invers in general two class regular assumpt common in linear method classif the first a strong parametr assumpt the structur the class distribut typic enforc connect even convex structur the second assumpt the decis boundari typic enforc a hyperplan our method make neither these assumpt reli instead the strong regular impos by restrict to a linear transform the origin input futur research on the nca model investig use local estim as deriv the entropi the distribut pij the possibl use a stochast classif rule at test time systemat comparison the object function to conclud we introduc a novel non-parametr learn method nca handl the task of distanc learn dimension reduct in a unifi manner although much recent effort focus on non-linear method we feel linear embed still fulli fulfil it potenti for either visual learn acknowledg thank to david heckerman paul viola for suggest we investig the altern cost the case of diagon a
----------------------------------------------------------------

title: 1357-the-canonical-distortion-measure-in-feature-space-and-1-nn-classification.pdf

canon distort measur featur space i-nn classif jonathan baxter*and peter bartlett depart system engin australian nation univers canberra australia jon bartlett syseng.anu.edu.au abstract prove canon distort measur cdm optim distanc measur use nearest-neighbour classif show reduc squar euclidean distanc featur space function class express linear combin fix set featur pac-lik bound given samplecomplex requir learn cdm experi present neural network cdm learnt japanes ocr environ use i-nn classif introduct let input space distribut class function map call environ distribut function canon distort measur cdm two input xl defin xl f x throughout paper consid real-valu function squar loss yl cdm introduc analys primarili vector quantize perspect particular cdm prove optim distort measur use vector quantize sens produc best approxim function environ f. experiment result also present toy domain show cdm may learnt purpos paper investig util cdm classif tool section show cdm class function possess common featur first author support part epsrc grant baxter p. bartlett set reduc via chang variabl squar euclidean distanc featur space lemma given show cdm optim distanc measur use 1nearest-neighbour classif thus function possess common featur set optimall-nn classif achiev use squar euclidean distanc featur space general cdm unknown section present techniqu learn cdm minim squar loss give pac-lik bound sample-s requir good generalis section present experiment result set featur learnt machine-print japanes ocr environ squar euclidean distanc use i-nn classif featur space experi provid strong empir support theoret result difficult real-world applic cdm featur space express linear combin fix set featur exist wk suppos wi i case distribut environ distribut weight vector measur distanc function valu cdm becom ie.k dq w fw w'w matrix make chang variabl thus assumpt function environ express linear combin fix set featur mean cdm simpli squar euclidean distanc featur space relat origin linear transform i-nn classif cdm suppos environ consist classifi -valu function let function f x train set exampl i-nn classif classif novel comput argmin classif classif nearest train point distanc measur chosen random expect misclassif error scheme use train point xn er x ef ex nearest neighbour follow lemma immedi definit lemma sequenc er x minim ifd cdm remark lemma combin result last section show function class possess common featur set optimall-nn classif achiev use squar euclidean distanc featur space section experiment result japanes ocr present support conclus properti optim cdm i-nn classif may stabl small perturb learn approximationg even ife xxx canon distort measur featur space i-nn classif small may case l-nn classif use also small howev one show stabil maintain classifi environ posit exampl differ function overlap signific case japanes ocr environ section face recognit environ speech recognit environ current investig general condit stabil maintain learn cdm environ encount practic speech recognit imag recognit unknown section shown may estim learnt use function approxim techniqu feedforward neural network sampl environ learn cdm learner provid class function neural network m goal learner find error cdm small sake argument error measur expect squar loss map erp g exxx expect respect ordinarili learner would provid train data form would use data minim empir version howev unknown generat data form must estim train pair henc generat train set learn cdm distribut environ distribut input space must sampl let sampl accord let sampl accord p. pair xj estim xj given p xi xj j fdxd fk xj k=l give train tripl use data generat empir estim er n n possibl train tripl use function assum alreadi symmetr satisfi case set use instead experi present neural network class minim direct gradient descent section present altern techniqu set featur first learnt environ estim featur space construct explicit j. baxter p. bartlett uniform converg wish ensur good generalis minim small pr lerx f g i erp g e~r sens follow theorem show occur number function number input sampl suffici larg some exot nonetheless benign measur restrict ignor statement theorem statement theorem denot smallest 6-cover norm gl gn 6-cover of9 iffor exist gi ilgi gil theorem assum rang function environ class use approxim cdm vb log log proof defin erx g l~i j~n pr sup ler erx g i ge9 pr sup lerx g erp g ge9 triangl inequ hold we treat separ equat simplifi notat let gij pij pij denot xj p xi xj respect now ij pij l~i j~n n n 4b n n pij pij ij pij pij pij pij e.rx j x jk k=l gij pij l~i j~n canon distort measur featur space j-nn classif defin 4b n n thus pr i si j s pr ej'x f exp hoeffd 's inequ set less give bound theorem equat without loss general suppos even trick split sum pair xj appear definit er doubl sum erx g xj p xi i=l g xo j=l permut empti exist permut properti sum broken way proven easili induct now condit pair sampl accord so standard result real-valu function learn squar loss pr su geq erp g j=l 4n exp henc union bound pr erx g erp g i l n exp set statement theorem ensur less remark bound number function need sampl environ independ complex class contrast relat bias learn equival learn learn result number function depend complex heurist explan we learn distanc function input space cdm wherea bias learn we learn entir hypothesi space appropri environ howev we shall see next section certain class problem cdm also use learn function environ henc case learn cdm effect method learn learn experi japanes ocr verifi optim cdm i-nn classif also show learnt non-trivi domain toy exampl given baxter bartlett com learnt japanes ocr environ specif function i environ one classifi differ kanji charact databas contain segment machine-print kanji charact scan various sourc purchas cedar group state univers new york buffalo qualiti imag rang clean degrad http //www cedar buffalo edu/databases/jocr main reason choos japanes ocr rather english ocr test-b larg number distinct charact japanes recal theorem get good generalis learnt com suffici mani function must sampl environ if environ consist english charact like suffici mani charact would mean charact so would imposs test learnt com novel charact seen train instead learn com direct minim learnt implicit first learn set neural network featur function environ featur learnt use method outlin essenti involv learn set classifi common final hidden layer featur learnt classifi environ use data train test result classifi linear combin neural network featur averag error classifi test set accur estim test exampl recal section if express i fix featur set com reduc i w/w result learn procedur set featur ci weight vector charact classifi fi use train ii wi thus empir estim true cdm w wi linear chang variabl ci ci vw becom use i-nn classif test exampl two differ experi fw first experi test train exampl exampl one train charact lump extra categori purpos classif test exampl given label nearest neighbour in train set initi train exampl map featur space give test exampl map featur space assign label argminx.llci total misclassif error direct compar misclassif error origin classifi com better use train data explicit inform store in network make comparison wherea classifi onli use inform in network learnt com also use k-nn classif howev afford improv for exampl error classifi error the classifi this provid indic that the com may the optim distort measur use if nn classif the aim in the second experi use i-nn classif the test set this time charact distinguish so in this case the learnt com ask distinguish charact that treat singl charact train the misclassif error surpris low the error compar favour with the error achiev the data the cedar group use care select featur set hand-tailor nearest-neighbour routin in case the distanc measur learnt raw-data input the subject optim tweak the canon distort measur in featur space i-nn classif figur six kanji charact first charact in row exampl four nearest neighbour remain four charact in row final qualit assess the learnt cdm use comput the distanc everi pair test exampl the distanc pair charact an individu charact repres number test exampl comput averag the distanc constitu exampl the nearest neighbour each charact calcul with this measur everi charact turn to nearest neighbour in mani case the next-nearest neighbour bore strong subject similar to the origin some repres exampl shown in figur conclus we shown the canon distort measur cdm the optim distort measur for i-nn classif that for environ in all the function express linear combin fix set featur the canon distort measur squar euclidean distanc in featur space techniqu for learn the cdm present pac-lik bound the sampl complex requir for good generalis prove experiment result present in the cdm for japanes ocr environ learnt first learn a common set featur for a subset the charact classifi in the environ the learnt cdm then use as a distanc measur in i-nn neighbour classif perform remark well the charact use to train and entir novel charact
----------------------------------------------------------------

title: 4441-generalized-lasso-based-approximation-of-sparse-coding-for-visual-recognition.pdf

general lasso base approxim spars code visual recognit nobuyuki morioka univers new south wale nicta sydney australia nmorioka cse.unsw.edu.au shin ichi satoh nation institut informat tokyo japan satoh nii.ac.jp abstract spars code method explain sensori data dictionari base possibl attract much attent comput vision visual object categori recognit regular spars code combin spatial pyramid represent obtain state-of-the-art perform howev iter optim appli spars code onto everi local featur descriptor extract imag databas becom major bottleneck overcom comput challeng paper present general lasso base approxim spars code glas repres distribut spars coeffici slice transform fit piece-wis linear map function general lasso also propos effici post-refin procedur perform mutual inhibit base essenti overcomplet set experi show glas obtain compar perform regular spars code yet achiev signific speed demonstr effect large-scal visual recognit problem introduct recent spars code attract much attent comput vision research applic rang imag denois imag segment imag classif achiev state-of-the-art result spars code interpret input signal spars vector whose linear combin overcomplet set base also known dictionari rd k reconstruct input precis possibl enforc spars norm popular choic due comput conveni interest connect np-hard norm compress sens sever effici regular spars code algorithm propos adopt visual recognit particular yang comput spare code mani local featur descriptor spars code howev due norm non-smooth convex spars code algorithm need optim iter converg therefor local featur descriptor code step becom major bottleneck large-scal problem like visual recognit goal paper achiev state-of-the-art perform large-scal visual recognit compar work yang signific improv effici end propos general lasso base approxim spars code glas short specif encod distribut dimens spars code slice transform represent learn piece-wis linear map function general lasso obtain best fit approxim regular spars code propos effici post-refin procedur captur depend overcomplet base effect approach demonstr sever challeng object scene categori dataset show compar perform yang perform better fast algorithm obtain spars code while sever supervis dictionari learn method spars code obtain discrimin spars represent evalu visual recognit mani object categori due comput challeng furthermor ranzato empir shown unsupervis learn visual featur obtain general effect represent therefor paper focus learn fast approxim spars code unsupervis manner paper organ follow section review relat work includ linear spatial pyramid combin spars code fast algorithm obtain spars code section present glas follow experiment result sever challeng categor dataset section section conclud paper discuss futur work relat work linear spatial pyramid match use spars code section review linear spatial pyramid match base spars code yang given collect local featur descriptor random sampl train imag xn rd n over-complet dictionari b2 bk rd k learn min b u kxi bui kui k1 kbk k. cost function combin reconstruct error sparsiti penalti control norm bk constrain less equal avoid trival solut sinc u2 un unknown priori altern optim techniqu often use optim two paramet set spatial pyramid match framework imag divid set sub-region r2 rr exampl partit use imag sub-region comput spars solut local featur descriptor denot urj appear sub-region rj min kxrj burj kurj k1 urj spars solut max pool sub-region concaten sub-region build statist imag max |ur1 max |ur2 max |urr function find maximum valu row matrix return column vector final linear svm train set imag statist classif main advantag use spars code state-of-the-art result achiev simpl linear classifi report compar kernel-bas method dramat speed train test time classifi howev step find spars code local descriptor spars code becom major bottleneck use effici spars code algorithm base feature-sign search time comput solut one local descriptor o kz number non-zero paper propos approxim method whose time complex reduc post-refin procedur time complex o k still much lower predict spars decomposit predict spars decomposit psd describ feedforward network appli non-linear map function linear transform input data match optim spars code gg wxi solut accur possibl feedfoward network defin denot non-linear parametr map function form name hyperbol tangent tanh z soft shrinkag sign z max |z function appli linear transform data wxi subsequ scale diagon matrix g. given train sampl paramet estim either joint separ dictionari b learn joint minim cost function given min kxi bui kui k1 kui gg wxi learn separ obtain eqn first remain paramet estim solv last term eqn gregor lecun later propos better iter approxim scheme regular spars code one downsid parametr approach accuraci larg depend well parametr function fit target statist distribut argu hel-or shake paper explor non-parametr approach fit distribut long data sampl avail repres advantag approach parametr approach need seek appropri parametr function distribut particular use visual recognit use multipl featur type automat estim function form featur type data demonstr two differ local descriptor type experi locality-constrain linear code anoth notabl work overcom bottleneck local descriptor code step localityconstrain linear code llc propos wang fast version local coordin code given local featur descriptor llc search nearest dictionari base local descriptor nearest base stack column denot b rd m indic index list base then coeffici u rm whose linear combin b reconstruct solv min kxi b u u u least squar problem solv quit effici final spars code ui obtain set element index u time complex llc o k exclud time requir find nearest neighbour while fast result spars solut obtain discrimin one obtain spars code may due fact fix across local featur descriptor descriptor may need base accur represent other may need less base distinct contrast number base select post-refin procedur handl mutual inhibit differ local descriptor general lasso base approxim spars code section describ glas first learn dictionari collect local featur descriptor given eqn then base slice transform represent fit piece-wis linear map function general lasso approxim optim spars solut local featur descriptor under regular spars code final propos effici post-refin procedur perform mutual inhibit slice transform represent slice transform represent introduc way discret function space fit piecewis linear function purpos imag denois hel-or shake later adopt adler singl imag super resolut this paper utilis represent approxim spars code obtain spars code local featur descriptor fast possibl given local descriptor linear combin obtain moment consid one dimens denot real valu lie half open interv interv divid equal-s bin whose boundari form vector q2 qq q1 q2 qq data rls l1 sc glas data rls l1 sc glas data rls l1 sc glas figur differ approach fit piece-wis linear map function regular least squar rls red eqn regular spars code magenta eqn glas green eqn three method achiev good fit case l1-sc fail extrapol well end rls tend align black case data sampl around remov artifici illustr rls fail interpol neighor prior use contrast glas interpol extrapol well case miss noisi data interv valu fall express qj correspond residu calcul base re-express sq sq come back multivari case then follow sq sq sq zk zk impli th dimens then replac boundari vector p2 pk result vector approxim optim spars solut obtain regular spars code much possibl this written sq sq sq zk pk hel-or shake formul problem learn pk regular least squar either independ transform domain joint spatial domain unlik set signific larg number base make joint optim pk difficult moreov sinc interest approxim spars solut transform domain learn pk independ given local descriptor xn rd n correspond spars solut u2 un y2 yk rk n obtain regular spars code optim problem given min kyk sk pk kq pk pk sk sq zk regular second term essenti avoid singular comput invers consequ pk encourag align mani data sampl avail this might reason prior imag denois desir purpos approxim spars co would like suppress coeffici zero figur show distribut one dimens spars coeffici obtain collect sift descriptor look similar distribut this motiv us look general lasso altern obtain better fit distribut coeffici general lasso previous section argu regular least squar state eqn give desir result instead interv need set zero this natur lead us consid regular spars code also known lasso formul min kyk sk pk kpk k1 pk howev drawback this learnt piece-wis linear function may becom unstabl case train data noisi miss illustr figur turn trend filter general known general lasso overcom this problem this express min kyk sk pk kdpk k1 pk refer penalti matrix defin solv optim problem turn spars code problem sinc invert key augment build squar matrix q q row orthogon row d. satisfi rank d constraint exampl set if let dp dpk apk then sk pk sk sk1 sk2 substitut sk2 yk sk1 given solv alreadi now see solv sk2 solv follow spars code problem min k i p yk i p sk1 k1 sk2 have comput recov solut pk sk2 sk2 detail found given learnt approxim spars solut eqn howev explicit comput sq multipli somewhat redund thus altern comput follow compon r zk pk r zk pk whose time complex becom eqn sinc essenti use pk lookup tabl complex independ q this follow normal readili use spatial max pool state eqn yet captur while explain away effect correspond coeffici correl base mutual inhibit remov redund this pk estim independ transform domain next section propos effici post-refin techniqu mutual inhibit base captur depend base handl mutual inhibit overcomplet base this section explain refin spars code solv regular least squar signific small activ basi set given estim method set non-zero local descriptor initi spars code compon code activ denot set activ compon subset spars code dictionari base respect goal denot such reconstruct accur comput refin code possibl formul this regularis least squar given min kx weight paramet regularis this convex follow analyt solut consid good intuit behind formul initi spars code start point refin reduc reconstruct error allow redund base substanti compet empir number activ compon small compar whole basi set henc linear system solv becom much smaller method train train time sec km method train train time sec km sift dim llc psd sc glas glas local self-similar dim llc psd sc glas glas tabl recognit accuraci caltech-101 dictionari size method set also report time taken process local descriptor method comput cheap also make sure deviat much initi solut introduc regular this refin procedur may similar llc howev case we preset number activ base determin non-zero import we base final solut perform nearest compon neighbor search this refin procedur total time complex becom o k we refer glas this post-refin procedur glas experiment result this section evalu glas glas sever challeng categor dataset learn map function we use local descriptor data sampl paramet fix respect experi unless otherwis state comparison we implement method discuss section sc re-implement yang llc locality-constrain linear code propos wang number nearest neighor consid set psd predict spars decomposit shrinkag function use parametr map function we also includ km build codebook k-mean cluster adopt hard-assign local descriptor code method exact local featur descriptor spatial max pool techniqu linear svm use compar differ local featur descriptor code techniqu descriptor sift local self-similar use sift histogram gradient direct comput imag patch captur appear inform we sampl patch everi pixel step contrast local self-similar comput correl small imag patch interest surround region captur geometr layout local region spatial max pool imag partit use implement done matlab fair comparison caltech-101 caltech-101 dataset consist imag divid object categori imag scale preserv aspect ratio we train imag per class test imag per class dictionari size method set sift local self-similar result averag eight random train test split report tabl sift glas consist better glas demonstr effect mutual inhibit post-refin procedur glas glas perform better fast algorithm produc spars code addit glas glas perform competit sc fact glas slight better when train imag per class use while spars code glas glas learn solut sc approxim code exact one sc moreov sc sometim produc unstabl code due non-smooth convex properti norm previous observ contrast glas sc glas glas averag recognit averag recognit averag recognit sc glas glas alpha sc rls glas glas miss data figur number bin quantiz interv spars code compon paramet control weight norm use general lasso when data sampl miss glas robust regular least squar given eqn approxim spars code a relat smooth piece-wis linear map function learn general lasso note norm penal chang shape function perform smooth post-refin we suspect differ may contribut slight better result glas this dataset although psd perform quit close glas sift this case local self-similar glas outperform psd probabl due distribut spars code captur well a simpl shrinkag function therefor glas might effect a wide rang distribut this use recognit use multipl featur type speed critic glas perform wors sc glas close gap glas sc we suspect due local self-similar dim relat low-dimension sift mutual inhibit becom import this might also explain llc perform reason well this descriptor tabl also report comput time taken process local descriptor method glas glas slower km psd slight faster llc signific faster sc this demonstr the practic import approach competit recognit result achiev fast comput differ valu evalu one paramet a time figur show the result differ q the result stabl after bin spars code comput eqn the time complex affect chosen figur show the result differ look stabl we also observ similar stabil we also valid if the general lasso given eqn more robust the regular least squar solut given in eqn when some data sampl miss when learn qk we artifici remov data sampl interv center around a random sampl point also illustr in figur we evalu differ number data sampl remov in term percentag the whole data sampl set the result shown in figur the perform rls signific drop as the number miss data increas howev both glas glas affect much caltech-256 caltech-256 contain imag object categori in total like caltech-101 we scale the imag preserv aspect ratio the result averag eight random train test split report in tabl we use test imag per class this time sift glas perform slight wors sc glas outperform sc probabl due the argument given in the previous experi caltech-101 for local self-similar result similar caltech-101 obtain the perform psd close km outperform glas suggest the inadequ fit spars code llc perform slight better glas could perform better glas while sc perform the best the perform glas quit close sc we also plot a graph the comput time taken for method it achiev accuraci sift local self-similar in figur respect method train train km method train train km sift dim llc psd sc glas glas local self-similar dim llc psd sc glas glas tabl recognit accuraci caltech-256 the dictionari size all set for sift for local self-similar km llc psd sc glas glas comput time averag recognit averag recognit averag recognit km llc psd sc glas glas comput time km llc psd sc glas glas comput time figur plot comput time averag recognit sift local-self similar respect evalu caltech-256 train imag the dictionari size set sift evalu scene the dictionari size set scene the scene dataset contain imag divid scene class rang indoor scene to outdoor scene train imag per class use for train the rest for test we use sift to learn dictionari base for method the result plot with comput time taken in figur the result glas similar to sc yet the former signific faster in summari we show approach work well three differ challeng dataset conclus this paper present approxim spars code base the general lasso call glas this further extend with the post-refin procedur to handl mutual inhibit between base essenti in overcomplet set the experi shown competit perform glas sc achiev signific comput speed we also demonstr the effect glas two local descriptor type name sift local self-similar llc psd perform well one type glas restrict to approxim spars code applic to variat spars code in general for exampl it may interest to tri glas laplacian spars code achiev smoother spars code spars code acknowledg nicta fund by the australian govern as repres by the depart broadband communic the digit economi the australian research council the ict centr excel program
----------------------------------------------------------------

title: 5950-skip-thought-vectors.pdf

skip-thought vector ryan kiro yukun zhu ruslan salakhutdinov richard s. zemel antonio torralba raquel urtasun sanja fidler univers toronto canadian institut advanc research massachusett institut technolog abstract describ approach unsupervis learn generic distribut sentenc encod use continu text book train encoderdecod model tri reconstruct surround sentenc encod passag sentenc share semant syntact properti thus map similar vector represent next introduc simpl vocabulari expans method encod word seen part train allow us expand vocabulari million word train model extract evalu vector linear model task semant related paraphras detect image-sent rank question-typ classif benchmark sentiment subject dataset end result off-the-shelf encod produc high generic sentenc represent robust perform well practic introduct develop learn algorithm distribut composit semant word longstand open problem intersect languag understand machin learn recent year sever approach develop learn composit oper map word vector sentenc vector includ recurs network recurr network convolut network recursive-convolut method among other method produc sentenc represent pass supervis task depend class label order backpropag composit weight consequ method learn highqual sentenc represent tune respect task paragraph vector altern model learn unsupervis sentenc represent introduc distribut sentenc indic part neural languag model downsid test time infer need perform comput new vector paper abstract away composit method consid altern loss function appli composit oper consid follow question task correspond loss allow us learn high generic sentenc represent give evid propos model learn high-qual sentenc vector without particular supervis task mind use word vector learn inspir propos object function abstract skip-gram model sentenc level instead use word predict surround context instead encod sentenc predict sentenc around thus composit oper substitut sentenc encod object function becom modifi figur illustr model call model skip-thought vector induc model call skip-thought vector model depend train corpus contigu text chose use larg collect novel name bookcorpus dataset train model free book written yet unpublish author dataset book differ genr romanc book fantasi scienc fiction teen etc tabl highlight summari statist book corpus along narrat book contain dialogu emot wide rang interact charact furthermor larg enough collect train set bias toward particular domain applic tabl show nearest neighbour figur skip-thought model given tupl si contigu sentenc si i-th sentenc book sentenc si encod tri reconstruct previous sentenc next sentenc exampl input sentenc triplet i got back home i could see cat step strang unattach arrow connect encod output color indic compon share paramet heosi end sentenc token book sentenc word uniqu word mean word per sentenc tabl summari statist bookcorpus dataset use corpus train model sentenc model train bookcorpus dataset result show skip-thought vector learn accur captur semant syntax sentenc encod evalu vector newli propos set learn skip-thought freez model use encod generic featur extractor arbitrari task experi consid task semantic-related paraphras detect image-sent rank standard classif benchmark experi extract skip-thought vector train linear model evalu represent direct without addit fine-tun turn skip-thought yield generic represent perform robust across task consid one difficulti aris experiment setup abl construct larg enough word vocabulari encod arbitrari sentenc exampl sentenc wikipedia articl might contain noun high unlik appear book vocabulari solv problem learn map transfer word represent one model anoth use pretrain word2vec represent learn continu bag-of-word model learn linear map word word2vec space word encod vocabulari space map learn use word share vocabulari train word appear word2vec get vector encod word embed space approach induc skip-thought vector treat skip-thought framework encoder-decod model encod map word sentenc vector decod use generat surround sentenc encoderdecod model gain lot traction neural machin translat set encod use map english sentenc vector decod condit vector generat translat sourc english sentenc sever choic encoder-decod pair explor includ convnet-rnn rnn-rnn lstm-lstm sourc sentenc represent also dynam chang use attent mechan take account relev word translat given time model use rnn encod gru activ rnn decod condit gru model combin near ident rnn encoder-decod use neural machin translat gru shown perform well lstm sequenc model task conceptu simpler gru unit gate requir use cell use rnns model encod decod use long backpropag assum given sentenc tupl si let wit denot t-th word sentenc si let xti denot word embed describ model three part encod decod object function encod let wi1 win word sentenc si number word sentenc time step encod produc hidden state hti interpret represent sequenc wi1 wit hidden state hn thus repres full sentenc preliminari version model develop context comput vision applic queri nearest sentenc ran hand insid coat double-check unopen letter still slip hand coat shirt fold copi lay brown envelop im sure youll glamor even said give exagger wink im realli glad came parti tonight said turn although could tell n invest chitchat seem genuin curious although n follow career microscop definit taken notic appear annoy buzz start ring ear becom louder louder vision began swim weighti pressur land lung vision blur edg threaten conscious altogeth weapon could mayb take last imp beat errol vanessa could ram behind send sail far side leve chanc stop stroke luck saw pair head togeth toward portaloo back hous heard hors scream probabl answer pair sharp spur dig deep flank take care goodman said take phonebook julia said come finish roll scroll place one side began urgent task find ale tankard right tabl set candl piec broken plate reach flint steel tinder tabl exampl first sentenc queri second sentenc nearest neighbour nearest neighbour score cosin similar random sampl sentenc corpus encod sentenc iter follow sequenc equat drop subscript rt ur uz ht tanh wx u r ht zt zt propos state updat time zt updat gate rt reset gate denot component-wis product updat gate take valu zero one decod decod neural languag model condit encod output hi comput similar encod except introduc matric cz cr use bias updat gate reset gate hidden state comput sentenc vector one decod use next sentenc second decod use previous sentenc separ paramet use decod except vocabulari matrix weight matrix connect decod hidden state comput distribut word follow describ decod next sentenc although analog comput use previous sentenc let hti+1 denot hidden state decod time decod involv iter follow sequenc equat drop subscript rt ht hti+1 wrd udr cr hi wzd udz tanh w cz hi chi zt zt given hti+1 probabl word given previous word encod vector hi exp vwi+1 hti+1 vwi+1 denot row correspond word analog comput perform previous sentenc object given tupl si object optim sum log-prob forward backward sentenc condit encod represent logp hi logp hi total object sum train tupl vocabulari expans describ expand encod vocabulari word seen train suppos model train induc word represent word2vec let vw2v denot word embed space word represent let vrnn denot rnn word embed space assum vocabulari vw2v much larger vrnn goal construct map vw2v vrnn parameter matrix v0 wv vw2v v0 vrnn inspir learn linear map translat word space solv un-regular linear regress loss matrix w. thus word vw2v map vrnn encod sentenc experi experi evalu capabl encod generic featur extractor after train bookcorpus dataset experiment setup task follow use learn encod featur extractor extract skip-thought vector sentenc task involv comput score pair sentenc comput component-wis featur pair describ detail specif experi train linear classifi top extract featur addit fine-tun backpropag skip-thought model restrict linear classifi two reason first direct evalu represent qualiti comput vector possibl addit perform gain made throughout experi non-linear model fall scope goal furthermor allow us better analyz strength weak learn represent second reason reproduc becom straightforward detail train induc skip-thought vector train two separ model book corpus one unidirect encod dimens subsequ refer uni-skip bidirect model forward backward encod dimens model contain two encod differ paramet one encod given sentenc correct order given sentenc revers output concaten form dimension vector refer model bi-skip train initi recurr matrici orthogon initi non-recurr weight initi uniform distribut mini-batch size use gradient clip norm paramet vector exceed use adam algorithm optim both model train rough two week addit experi also report experiment result use combin model consist concaten vector uni-skip bi-skip result dimension vector refer model throughout combine-skip after model train employ vocabulari expans map word embed rnn encod space public avail cbow word vector use purpos skip-thought model train vocabulari size word after remov multipl word exampl cbow model result vocabulari size word thus even though skip-thought model train word after vocabulari expans success encod possibl word sinc goal evalu skip-thought general featur extractor keep text pre-process minimum encod new sentenc addit preprocess done basic token done test robust vector addit baselin also consid mean word vector learn uni-skip model refer baselin bow determin effect standard baselin train bookcorpus semant related first experi semev task semant related sick dataset given two sentenc goal produc score semant relat sentenc base human generat score score averag differ human annot score take valu score indic sentenc pair relat http //code.google.com/p/word2vec mse method acc illinois-lh unal-nlp mean factori ecnu feat rae+dp rae+feat rae+dp+feat mean vector dt-rnn sdt-rnn lstm bidirect lstm depend tree-lstm fhs pe wddp mtmetric tf-kld bow uni-skip bi-skip combine-skip combine-skip+coco bow uni-skip bi-skip combine-skip combine-skip feat method f1 tabl left test set result sick semant related subtask evalu metric pearson spearman mean squar error first group result semev submiss second group result report right test set result microsoft paraphras corpus evalu metric classif accuraci f1 score top recurs autoencod variant middl best publish result dataset score indic high relat dataset come predefin split train pair develop pair test pair sentenc deriv exist imag video annot dataset evalu metric pearson spearman mean squar error given difficulti task mani exist system employ larg amount featur engin addit resourc thus test well learn represent fair heavili engin pipelin recent show learn represent lstm tree-lstm task hand abl outperform exist system take one step see well vector learn complet differ task abl captur semant related linear model use top predict score repres sentenc pair use two featur given two skip-thought vector comput component-wis product absolut differ concaten togeth two featur also use predict score use setup let integ vector comput distribut function predict score given pi byc byc pi byc byc otherwis these becom target logist regress classifi test time given new sentenc pair first comput target comput relat score addit comparison we also explor append featur deriv image-sent embed model train coco section given vector we obtain vector u0 learn linear embed model comput featur u0 these concaten exist featur tabl left present result first we observ model abl outperform previous system semev competit highlight skip-thought vector learn represent well suit semant related result compar lstms whose represent train scratch task depend tree-lstm perform better result we note depend tree-lstm reli parser whose train data expens collect exist languag we also observ use featur learn image-sent embed model coco give addit perform boost result model perform par depend tree-lstm get feel model output tabl show exampl case test set pair model abl accur predict related mani challeng case exampl fail pick small distinct drastic chang sentenc mean trick motorcycl versus trick person motorcycl paraphras detect next task we consid paraphras detect microsoft research paraphras corpus task two sentenc given one must predict whether sentenc sentenc gt pred littl girl look woman costum littl girl look woman costum littl girl look woman costum young girl look woman costum littl girl look man costum littl girl costum look like woman sea turtl hunt fish sea turtl hunt fish sea turtl hunt food sea turtl hunt fish man drive car there man drive car car driven man man drive car larg duck fli rocki stream larg duck fli rocki stream duck larg fli rocki stream larg stream full rock duck fli person perform acrobat motorcycl person perform trick motorcycl person perform trick motorcycl perform trick person motorcycl someon pour ingredi pot nobodi pour ingredi pot someon pour ingredi pot someon ad ingredi pot someon pour ingredi pot a man remov veget a pot tabl exampl predict sick test set gt ground truth related score last result show exampl slight chang sentenc structur result larg chang in related model unabl score correct model random rank dvsa gmm+hglmm m-rnn bow uni-skip bi-skip combine-skip r coco retriev imag annot r med r imag search r med tabl coco test-set result image-sent retriev experi r k recal k high good med median rank low good paraphras train set consist sentenc pair posit test set pair posit we comput a vector repres pair sentenc in way sick dataset use component-wis product absolut differ concaten togeth we train logist regress top predict whether sentenc paraphras cross-valid use tune penalti in semant related task paraphras detect larg domin extens featur engin a combin featur engin semant space we report experi in two set one use featur incorpor basic statist sentenc pair featur use these refer feat in result we isol result baselin use in well top publish result this task tabl right present result we observ follow skip-thought alon outperform recurs net dynam pool hand-craft featur use featur use recurs net dynam pool work better when skipthought combin basic pairwis statist it becom competit state-of-the-art incorpor much complic featur hand-engin this a promis result mani sentenc pair fine-grain detail signal if paraphras image-sent rank we next consid task retriev imag sentenc descript this experi we use microsoft coco dataset largest public avail dataset imag high-qual sentenc descript imag annot caption differ annot follow previous work we consid two task imag annot imag search imag annot imag present sentenc rank base well describ queri imag imag search task revers given a caption we retriev imag a good fit queri train set come imag caption develop test we use split develop test set contain imag caption evalu perform use recal k name mean number imag correct caption rank within top-k retriev result vice-versa sentenc we also report median rank closest ground truth result the rank list the best perform result image-sent rank use rnns encod sentenc the sentenc represent learn joint recent show use fisher vector repres sentenc linear cca appli obtain perform strong use rnns this task thus the method a strong baselin compar sentenc represent experi we repres imag use 4096-dimension oxfordnet featur 19-layer model sentenc we simpli extract skip-thought vector caption the train object we use a pairwis rank loss previous use mani method the differ the score comput use linear transform imag sentenc input the loss given xx xx ux vy ux vyk vy ux vy uxk imag vector the skip-thought vector the groundtruth sentenc yk vector constrast incorrect sentenc the image-sent score cosin similar use score the model paramet the imag embed matrix the sentenc embed matrix in experi we use a dimension embed margin contrast term we train epoch save our model anytim the perform improv the develop set tabl illustr our result this task use skip-thought vector sentenc we get perform par both except r imag annot method perform much better our result indic skip-thought vector repres enough captur imag descript without learn represent scratch combin the result it also highlight simpl scalabl embed techniqu perform well provid high-qual imag sentenc vector avail classif benchmark our final quantit experi we report result sever classif benchmark common use evalu sentenc represent learn method we use dataset movi review sentiment custom product review subjectivity/object classif subj opinion polar mpqa question-typ classif trec all dataset we simpli extract skip-thought vector train a logist regress classifi top 10-fold cross-valid use evalu the first dataset trec a pre-defin train/test split we tune the penal use cross-valid thus use a nest cross-valid the first dataset method mr cr subj mpqa trec nb-svm mnb cbow grconv rnn brnn cnn adas paragraph-vector bow uni-skip bi-skip combine-skip combine-skip nb these task proper tune bag-ofword model shown perform except well in particular the nb-svm a fast robust perform these task skipthought vector potenti give altern these baselin fast easi use for addit comparison we also see effect augment skip-thought bigram naiv bay featur improv perform tabl present our result task skip-thought perform as well as the bag-of-word baselin tabl classif accuraci sever standard bench fail to improv method whose mark result group as follow bag-of-word mod sentenc represent learn diel supervis composit model paragraph vector rect for the task at hand this indic unsupervis learn sentenc represent for task like sentiment classificabest result overal bold while best result outsid group tion tune the represent even underlin small dataset like to perform better learn a generic unsupervis we use the code avail at https //github.com/mesnilgr/nbsvm trec subj sick figur t-sne embed skip-thought vector differ dataset point color base label question type for trec subjectivity/object for subj the sick dataset each point repres a sentenc pair point color on a gradient base on related label result best seen in electron form sentenc vector on much bigger dataset final we observ the skip-thoughts-nb combin effect particular on mr this result in a strong new baselin for text classif combin skip-thought bag-of-word train a linear model visual skip-thought as a final experi we appli t-sne to skip-thought vector extract trec subj sick dataset the visual shown in figur for the sick visual each point repres a sentenc pair comput use the concaten component-wis absolut differ featur even without the use related label skip-thought vector learn to accur captur this properti conclus we evalu the effect skip-thought vector as an off-the-shelf sentenc represent linear classifi across task mani the method we compar evalu on task the fact that skip-thought vector perform well on all task consid highlight the robust our represent we believ our model for learn skip-thought vector onli scratch the surfac possibl object mani variat yet to explor includ deep encod decod larger context window encod decod paragraph encod as convnet it like the case that explor this space result in even higher qualiti represent acknowledg we thank geoffrey hinton for suggest the name skip-thought we also thank felix hill kelvin xu kyunghyun cho ilya sutskev for valuabl comment discuss this work support nserc samsung cifar googl onr grant
----------------------------------------------------------------

