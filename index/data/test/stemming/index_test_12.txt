query sentence: Nearest neighbours search algorithm for similarity comparison
---------------------------------------------------------------------
title: 2566-neighbourhood-components-analysis.pdf

Neighbourhood Components Analysis

Jacob Goldberger, Sam Roweis, Geoff Hinton, Ruslan Salakhutdinov
Department of Computer Science, University of Toronto
{jacob,roweis,hinton,rsalakhu}@cs.toronto.edu

Abstract
In this paper we propose a novel method for learning a Mahalanobis
distance measure to be used in the KNN classification algorithm. The
algorithm directly maximizes a stochastic variant of the leave-one-out
KNN score on the training set. It can also learn a low-dimensional linear embedding of labeled data that can be used for data visualization
and fast classification. Unlike other methods, our classification model
is non-parametric, making no assumptions about the shape of the class
distributions or the boundaries between them. The performance of the
method is demonstrated on several data sets, both for metric learning and
linear dimensionality reduction.

1

Introduction

Nearest neighbor (KNN) is an extremely simple yet surprisingly effective method for classification. Its appeal stems from the fact that its decision surfaces are nonlinear, there
is only a single integer parameter (which is easily tuned with cross-validation), and the
expected quality of predictions improves automatically as the amount of training data increases. These advantages, shared by many non-parametric methods, reflect the fact that
although the final classification machine has quite high capacity (since it accesses the entire
reservoir of training data at test time), the trivial learning procedure rarely causes overfitting
itself.
However, KNN suffers from two very serious drawbacks. The first is computational, since
it must store and search through the entire training set in order to classify a single test point.
(Storage can potentially be reduced by ?editing? or ?thinning? the training data; and in low
dimensional input spaces, the search problem can be mitigated by employing data structures
such as KD-trees or ball-trees[4].) The second is a modeling issue: how should the distance
metric used to define the ?nearest? neighbours of a test point be defined? In this paper, we
attack both of these difficulties by learning a quadratic distance metric which optimizes the
expected leave-one-out classification error on the training data when used with a stochastic
neighbour selection rule. Furthermore, we can force the learned distance metric to be low
rank, thus substantially reducing storage and search costs at test time.

2

Stochastic Nearest Neighbours for Distance Metric Learning

We begin with a labeled data set consisting of n real-valued input vectors x1 , . . . , xn in RD
and corresponding class labels c1 , ..., cn . We want to find a distance metric that maximizes

the performance of nearest neighbour classification. Ideally, we would like to optimize
performance on future test data, but since we do not know the true data distribution we
instead attempt to optimize leave-one-out (LOO) performance on the training data.
In what follows, we restrict ourselves to learning Mahalanobis (quadratic) distance metrics,
which can always be represented by symmetric positive semi-definite matrices. We estimate such metrics through their inverse square roots, by learning a linear transformation
of the input space such that in the transformed space, KNN performs well. If we denote
the transformation by a matrix A we are effectively learning a metric Q = A> A such that
d(x, y) = (x ? y)> Q(x ? y) = (Ax ? Ay)> (Ax ? Ay).
The actual leave-one-out classification error of KNN is quite a discontinuous function of the
transformation A, since an infinitesimal change in A may change the neighbour graph and
thus affect LOO classification performance by a finite amount. Instead, we adopt a more
well behaved measure of nearest neighbour performance, by introducing a differentiable
cost function based on stochastic (?soft?) neighbour assignments in the transformed space.
In particular, each point i selects another point j as its neighbour with some probability pij ,
and inherits its class label from the point it selects. We define the pij using a softmax over
Euclidean distances in the transformed space:
exp(?kAxi ? Axj k2 )
2
k6=i exp(?kAxi ? Axk k )

pij = P

,

pii = 0

(1)

Under this stochastic selection rule, we can compute the probability pi that point i will be
correctly classified (denote the set of points in the same class as i by Ci = {j|ci = cj }):
X
pij
(2)
pi =
j?Ci

The objective we maximize is the expected number of points correctly classified under this
scheme:
XX
X
pi
(3)
f (A) =
pij =
i

j?Ci

i

Differentiating f with respect to the transformation matrix A yields a gradient rule which
we can use for learning (denote xij = xi ? xj ):
XX
X
?f
= ?2A
pij (xij x>
pik xik x>
ij ?
ik )
?A
i
j?Ci

Reordering the terms we obtain a more efficiently computed expression:
?
?
X
X
X
?f
? pi
?
= 2A
pik xik x>
pij xij x>
ik ?
ij
?A
i
k

(4)

k

(5)

j?Ci

Our algorithm ? which we dub Neighbourhood Components Analysis (NCA)? is extremely
simple: maximize the above objective (3) using a gradient based optimizer such as deltabar-delta or conjugate gradients. Of course, since the cost function above is not convex,
some care must be taken to avoid local maxima during training. However, unlike many
other objective functions (where good optima are not necessarily deep but rather broad) it
has been our experience that the larger we can drive f during training the better our test
performance will be. In other words, we have never observed an ?overtraining? effect.
Notice that by learning the overall scale of A as well as the relative directions of its rows
we are also effectively learning a real-valued estimate of the optimal number of neighbours
(K). This estimate appears as the effective perplexity of the distributions pij . If the learning

procedure wants to reduce the effective perplexity (consult fewer neighbours) it can scale
up A uniformly; similarly by scaling down all the entries in A it can increase the perplexity
of and effectively average over more neighbours during the stochastic selection.
Maximizing the objective function f (A) is equivalent to minimizing the L1 norm between
the true class distribution (having probability one on the true class) and the stochastic class
distribution induced by pij via A. A natural alternative distance is the KL-divergence which
induces the following objective function:
X
X
X
g(A) =
log(
pij ) =
log(pi )
(6)
i

j?Ci

i

Maximizing this objective would correspond to maximizing the probability of obtaining a
perfect (error free) classification of the entire training set. The gradient of g(A) is even
simpler than that of f (A):
!
P
>
X X
?g
j?Ci pij xij xij
>
P
= 2A
pik xik xik ?
(7)
?A
j?Ci pij
i
k

We have experimented with optimizing this cost function as well, and found both the transformations learned and the performance results on training and testing data to be very
similar to those obtained with the original cost function.

To speed up the gradient computation, the sums that appear in equations (5) and (7) over
the data points and over the neigbours of each point, can be truncated (one because we
can do stochastic gradient rather than exact gradient and the other because pij drops off
quickly).

3

Low Rank Distance Metrics and Nonsquare Projection

Often it is useful to reduce the dimensionality of input data, either for computational savings or for regularization of a subsequent learning algorithm. Linear dimensionality reduction techniques (which apply a linear operator to the original data in order to arrive
at the reduced representation) are popular because they are both fast and themselves relatively immune to overfitting. Because they implement only affine maps, linear projections
also preserve some essential topology of the original data. Many approaches exist for linear dimensionality reduction, ranging from purely unsupervised approaches (such as factor
analysis, principal components analysis and independent components analysis) to methods
which make use of class labels in addition to input features such as linear discriminant
analysis (LDA)[3] possibly combined with relevant components analysis (RCA)[1].
By restricting A to be a nonsquare matrix of size d?D, NCA can also do linear dimensionality reduction. In this case, the learned metric will be low rank, and the transformed inputs
will lie in Rd . (Since the transformation is linear, without loss of generality we only consider the case d ? D. ) By making such a restriction, we can potentially reap many further
benefits beyond the already convenient method for learning a KNN distance metric. In particular, by choosing d  D we can vastly reduce the storage and search-time requirements
of KNN. Selecting d = 2 or d = 3 we can also compute useful low dimensional visualizations on labeled datasets, using only a linear projection. The algorithm is exactly the
same: optimize the cost function (3) using gradient descent on a nonsquare A. Our method
requires no matrix inversions and assumes no parametric model (Gaussian or otherwise)
for the class distributions or the boundaries between them. For now, the dimensionality of
the reduced representation (the number of rows in A) must be set by the user.
By using an highly rectangular A so that d  D, we can significantly reduce the computational load of KNN at the expense of restricting the allowable metrics to be those of

rank at most d. To achieve this, we apply the NCA learning algorithm to find the optimal
transformation A, and then we store only the projections of the training points yn = Axn
(as well as their labels). At test time, we classify a new point xtest by first computing its
projection ytest = Axtest and then doing KNN classification on ytest using the yn and
a simple Euclidean metric. If d is relatively small (say less than 10), we can preprocess
the yn by building a KD-tree or a ball-tree to further increase the speed of search at test
time. The storage requirements of this method are O(dN ) + Dd compared with O(DN )
for KNN in the original input space.

4

Experiments in Metric Learning and Dimensionality Reduction

We have evaluated the NCA algorithm against standard distance metrics for KNN and other
methods for linear dimensionality reduction. In our experiments, we have used 6 data sets
(5 from the UC Irvine repository). We compared the NCA transformation obtained from
optimizing f (for square A) on the training set with the default Euclidean distance A = I,
1
the ?whitening? transformation , A = ?? 2 (where ? is the sample data covariance matrix),
?1
and the RCA [1] transformation A = ?w 2 (where ?w is the average of the within-class
covariance matrices). We also investigated the behaviour of NCA when A is restricted to
be diagonal, allowing only axis aligned Mahalanobis measures.
Figure 1 shows that the training and (more importantly) testing performance of NCA is
consistently the same as or better than that of other Mahalanobis distance measures for
KNN, despite the relative simplicity of the NCA objective function and the fact that the
distance metric being learned is nothing more than a positive definite matrix A>A.
We have also investigated the use of linear dimensionality reduction using NCA (with nonsquare A) for visualization as well as reduced-complexity classification on several datasets.
In figure 2 we show 4 examples of 2-D visualization. First, we generated a synthetic threedimensional dataset (shown in top row of figure 2) which consists of 5 classes (shown by
different colors). In two dimensions, the classes are distributed in concentric circles, while
the third dimension is just Gaussian noise, uncorrelated with the other dimensions or the
class label. If the noise variance is large enough, the projection found by PCA is forced
to include the noise (as shown on the top left of figure 2). (A full rank Euclidean metric
would also be misled by this dimension.) The classes are not convex and cannot be linearly separated, hence the results obtained from LDA will be inappropriate (as shown in
figure 2). In contrast, NCA adaptively finds the best projection without assuming any parametric structure in the low dimensional representation. We have also applied NCA to the
UCI ?wine? dataset, which consists of 178 points labeled into 3 classes and to a database
of gray-scale images of faces consisting of 18 classes (each a separate individual) and 560
dimensions (image size is 20 ? 28). The face dataset consists of 1800 images (100 for each
person). Finally, we applied our algorithm to a subset of the USPS dataset of handwritten
digit images, consisting of the first five digit classes (?one? through ?five?). The grayscale
images were downsampled to 8 ? 8 pixel resolution resulting in 64 dimensions.
As can be seen in figure 2 when a two-dimensional projection is used, the classes are consistently much better separated by the NCA transformation than by either PCA (which is
unsupervised) or LDA (which has access to the class labels). Of course, the NCA transformation is still only a linear projection, just optimized with a cost function which explicitly
encourages local separation. To further quantify the projection results we can apply a
nearest-neighbor classification in the projected space. Using the same projection learned
at training time, we project the training set and all future test points and perform KNN in
the low-dimensional space using the Euclidean measure. The results under the PCA, LDA,
LDA followed by RCA and NCA transformations (using K=1) appear in figure 1. The
NCA projection consistently gives superior performance in this highly constrained low-

distance metric learning ? training

distance metric learning ? testing

1

1

0.95

0.95

0.9

0.9

0.85

0.85

0.8

0.8

0.75

0.75

0.7

0.7

0.65

0.65

NCA
diag?NCA
RCA
whitened
Euclidean

0.6

0.55

0.5

bal

ion

iris

wine

NCA
diag?NCA
RCA
whitened
Euclidean

0.6

0.55

hous

digit

0.5

bal

rank 2 transformation ? training
1

iris

wine

hous

digit

rank 2 transformation ? testing
1

NCA
LDA+RCA
LDA
PCA

0.9

0.8

0.7

0.7

0.6

0.6

0.5

0.5

0.4

0.4

bal

ion

iris

wine

hous

digit

NCA
LDA+RCA
LDA
PCA

0.9

0.8

0.3

ion

0.3

bal

ion

iris

wine

hous

digit

Figure 1: KNN classification accuracy (left train, right test) on UCI datasets balance, ionosphere, iris, wine and housing and on the USPS handwritten digits. Results are averages
over 40 realizations of splitting each dataset into training (70%) and testing (30%) subsets
(for USPS 200 images for each of the 10 digit classes were used for training and 500 for
testing). Top panels show distance metric learning (square A) and bottom panels show
linear dimensionality reduction down to d = 2.
rank KNN setting. In summary, we have found that when labeled data is available, NCA
performs better both in terms of classification performance in the projected representation
and in terms of visualization of class separation as compared to the standard methods of
PCA and LDA.

5

Extensions to Continuous Labels and Semi-Supervised Learning

Although we have focused here on discrete classes, linear transformations and fully supervised learning, many extensions of this basic idea are possible. Clearly, a nonlinear
transformation function A(?) could be learned using any architecture (such as a multilayer
perceptron) trainable by gradient methods. Furthermore, it is possible to extend the classification framework presented above to the case of a real valued (continuous) supervision
signal by defining the set of ?correct matches? Ci for point i to be those points j having
similar (continuous) targets. This naturally leads to the idea of ?soft matches?, in which
the objective function becomes a sum over all pairs, each weighted by their agreement according to the targets. Learning under such an objective can still proceed even in settings
where the targets are not explicitly provided as long as information identifying close pairs

PCA

LDA

NCA

Figure 2: Dataset visualization results of PCA, LDA and NCA applied to (from top) the
?concentric rings?, ?wine?, ?faces? and ?digits? datasets. The data are reduced from their
original dimensionalities (D=3,D=13,D=560,D=256 respectively) to the d=2 dimensions
show.

Figure 3: The two dimensional outputs of the neural network on a set of test cases. On the left, each
point is shown using a line segment that has the same orientation as the input face. On the right, the
same points are shown again with the size of the circle representing the size of the face.

is available. Such semi-supervised tasks often arise in domains with strong spatial or temporal continuity constraints on the supervision, e.g. in a video of a person?s face we may
assume that pose, and expression vary slowly in time even if no individual frames are ever
labeled explicitly with numerical pose or expression values.
To illustrate this, we generate pairs of faces in the following way: First we choose two faces
at random from the FERET-B dataset (5000 isolated faces that have a standard orientation
and scale). The first face is rotated by an angle uniformly distributed between ?45o and
scaled to have a height uniformly distributed between 25 and 35 pixels. The second face
(which is of a different person) is given the same rotation and scaling but with Gaussian
noise of ?1.22o and ?1.5 pixels. The pair is given a weight, wab , which is the probability
density of the added noise divided by its maximum possible value. We then trained a neural
network with one hidden layer of 100 logistic units to map from the 35?35 pixel intensities
of a face to a point, y, in a 2-D output space. Backpropagation was used to minimize the
cost function in Eq. 8 which encourages the faces in a pair to be placed close together:
!
X
exp(?||ya ? yb ||2 )
(8)
Cost = ?
wab log P
2
c,d exp(?||yc ? yd || )
pair(a,b)

where c and d are indices over all of the faces, not just the ones
that form a pair. Four example faces are shown to the right; horizontally the pairs agree and vertically they do not. Figure 3 above
shows that the feedforward neural network discovered polar coordinates without the user having to decide how to represent scale
and orientation in the output space.

6

Relationships to Other Methods and Conclusions

Several papers recently addressed the problem of learning Mahalanobis distance functions
given labeled data or at least side-information of the form of equivalence constraints. Two
related methods are RCA [1] and a convex optimization based algorithm [7]. RCA is
implicitly assuming a Gaussian distribution for each class (so it can be described using
only the first two moments of the class-conditional distribution). Xing et. al attempt to
find a transformation which minimizes all pairwise squared distances between points in the

same class; this implicitly assumes that classes form a single compact connected set. For
highly multimodal class distributions this cost function will be severely penalized. Lowe[6]
proposed a method similar to ours but used a more limited idea for learning a nearest
neighbour distance metric. In his approach, the metric is constrained to be diagonal (as
well, it is somewhat redundantly parameterized), and the objective function corresponds to
the average squared error between the true class distribution and the predicted distribution,
which is not entirely appropriate in a more probabilistic setting.
In parallel there has been work on learning low rank transformations for fast classification
and visualization. The classic LDA algorithm[3] is optimal if all class distributions are
Gaussian with a single shared covariance; this assumption, however is rarely true. LDA
also suffers from a small sample size problem when dealing with high-dimensional data
when the within-class scatter matrix is nearly singular[2]. Recent variants of LDA (e.g.
[5], [2]) make the transformation more robust to outliers and to numerical instability when
not enough datapoints are available. (This problem does not exist in our method since there
is no need for a matrix inversion.)
In general, there are two classes of regularization assumption that are common in linear
methods for classification. The first is a strong parametric assumption about the structure of
the class distributions (typically enforcing connected or even convex structure); the second
is an assumption about the decision boundary (typically enforcing a hyperplane). Our
method makes neither of these assumptions, relying instead on the strong regularization
imposed by restricting ourselves to a linear transformation of the original inputs.
Future research on the NCA model will investigate using local estimates of K as derived
from the entropy of the distributions pij ; the possible use of a stochastic classification rule
at test time; and more systematic comparisons between the objective functions f and g.
To conclude, we have introduced a novel non-parametric learning method ? NCA ? that
handles the tasks of distance learning and dimensionality reduction in a unified manner.
Although much recent effort has focused on non-linear methods, we feel that linear embedding has still not fully fulfilled its potential for either visualization or learning.
Acknowledgments
Thanks to David Heckerman and Paul Viola for suggesting that we investigate the alternative cost g(A) and the case of diagonal A.

References
[1] A. Bar-Hillel, T. Hertz, N. Shental, and D. Weinshall. Learning distance functions using equivalence relation. In International Conference on Machine Learning, 2003.
[2] L. Chen, H. Liao, M. Ko, J. Lin, and G. Yu. A new lda-based face recognition system which can
solve the small sample size problem. In Pattern Recognition, pages 1713?1726, 2000.
[3] R. A. Fisher. The use of multiple measurements in taxonomic problems. In Annual of Eugenic,
pages 179?188, 1936.
[4] J. Friedman, J.bentley, and R. Finkel. An algorithm for finding best matches in logarithmic
expected time. In ACM, 1977.
[5] Y. Koren and L. Carmel. Robust linear dimensionality reduction. In IEEE Trans. Vis. and Comp.
Graph., pages 459?470, 2004.
[6] D. Lowe. Similarity metric learning for a variable kernel classifier. In Neural Computation,
pages 72?85, 1995.
[7] E.P. Xing, A. Y. Ng, M.I. Jordan, and S. Russell. Distance learning metric. In Proc. of Neural
Information Processing Systems, 2003.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4143-pose-sensitive-embedding-by-nonlinear-nca-regression.pdf

Pose-Sensitive Embedding
by Nonlinear NCA Regression

Graham W. Taylor, Rob Fergus, George Williams, Ian Spiro and Christoph Bregler
Courant Institute of Mathematics, New York University
New York, USA 10003
gwtaylor,fergus,spiro,bregler@cs.nyu.edu

Abstract
This paper tackles the complex problem of visually matching people in similar
pose but with different clothes, background, and other appearance changes. We
achieve this with a novel method for learning a nonlinear embedding based on
several extensions to the Neighborhood Component Analysis (NCA) framework.
Our method is convolutional, enabling it to scale to realistically-sized images. By
cheaply labeling the head and hands in large video databases through Amazon
Mechanical Turk (a crowd-sourcing service), we can use the task of localizing
the head and hands as a proxy for determining body pose. We apply our method
to challenging real-world data and show that it can generalize beyond hand localization to infer a more general notion of body pose. We evaluate our method
quantitatively against other embedding methods. We also demonstrate that realworld performance can be improved through the use of synthetic data.

1

Introduction

Determining the pose of a human body from one or more images is a central problem in Computer
Vision. The complex, multi-jointed nature of the body makes the determination of pose challenging,
particularly in natural settings where ambiguous and unusual configurations may be observed. The
ability to localize the hands is particularly important: they provide tight constraints on the layout of
the upper body, yielding a strong cue as to the action and intent of a person.
A huge range of techniques, both parametric and non-parametric, exist for inferring body pose from
2D images and 3D datasets [10, 39, 4, 28, 33, 8, 3, 6, 11]. We propose a non-parametric approach to

d=3.20

d=3.65

d=3.88

d=3.90

d=3.91

d=4.02

d=4.17

d=4.31

d=3.93

d=4.58

d=5.05

d=5.24

d=5.35

d=5.40

d=5.47

d=5.49

d=4.29

d=5.00

d=5.09

d=5.21

d=5.29

d=5.51

d=5.57

d=5.60

Figure 1: Query image (in left column) and the eight nearest neighbours found by our method.
Distance in the learned embedded space is shown bottom right. Matches are based on the location
of the hands, and more generally body pose - not the individual or the background.

1

estimating body pose by localizing the hands using a parametric, nonlinear multi-layered embedding
of the raw pixel images. Unlike many other metric learning approaches, ours is designed for use with
real-world images, having a convolutional architecture that scales gracefully to large images and is
invariant to local geometric distortions.
Our embedding, trained on both real and synthetic data, is a functional mapping that projects images
with similar head and hand positions to lie close-by in a low-dimensional output space. Efficient
nearest-neighbour search can then be performed in this space to find images in a large training
corpus that have similar pose. Specifically for this task, we have designed an interface to obtain
and verify head and hand labels for thousands of frames through Amazon Mechanical Turk with
minimal user intervention. We find that our method is able to cope with the terse and noisy labels
provided by crowd-sourcing. It succeeds in generalizing to body and hand pose when such cues are
not explicitly provided in the labels (see Fig. 1).

2

Related work

Our application domain is related to several approaches in the computer vision literature that propose
hand or body pose tracking. Many techniques rely on sliding-window part detectors based on color
and other features applied to controlled recording conditions ([10, 39, 4, 28] to name a few, we
refer to [32] for a complete survey). In our domain, hands might only occupy a few pixels, and the
only body-part that can reliably be detected is the human face ([26, 13]). Many techniques have
been proposed that extract, learn, or reason over entire body features. Some use a combination of
local detectors and structural reasoning (see [33] for coarse tracking and [8] for person-dependent
tracking). In a similar spirit, more general techniques using pictorial structures [3, 12, 35], ?poselets?
[6], and other part-models [11] have received increased attention. An entire new stream of kinematic
model-based techniques based on the HumanEva dataset has been proposed [37], but this area differs
from our domain in that the images considered are of higher quality and less cluttered.
More closely related to our task are nearest-neighbour and locally-weighted regression-based techniques. Some extract ?shape-context? edge based histograms from the human body [25, 1] or just
silhouette features [15]. Shakhnarovich et al. [36] use HOG [9] features and boosting for learning a parameter sensitive hash function. All these approaches rely on good background subtraction
or recordings with clear backgrounds. Our domain contains clutter, lighting variations and low
resolution such that it is impossible to separate body features from background successfully. We
instead learn relevant features directly from pixels (instead of pre-coded edge or gradient histogram
features), and discover implicitly background invariance from training data.
Several other works [36, 9, 4, 15] have used synthetically created data as a training set. We show in
this paper several experiments with challenging real video (with crowd-sourced Amazon Mechanical
Turk labels), synthetic training data, and hybrid datasets. Our final system (after training) is always
applied to the cluttered non-background subtracted real video input without any labels.
Our technique is also related to distance metric learning, an important area of machine learning
research, especially due to recent interest in analyzing complex high-dimensional data. A subset
of approaches for dimensionality reduction [17, 16] implicitly learn a distance metric by learning
a function (mapping) from high-dimensional (i.e. pixel) space to low-dimensional ?feature? space
such that perceptually similar observations are mapped to nearby points on a manifold. Neighbourhood Components Analysis (NCA) [14] proposes a solution where the transformation from input
to feature space is linear and the distance metric is Euclidean. NCA learns the transformation that
is optimal for performing KNN in the feature space. NCA has also been recently extended to the
nonlinear case [34] using MNIST class labels and to linear 1D regression for reinforcement learning
[20]. Dimensionality Reduction by Learning an Invariant Mapping (DrLIM) [16] also learns a nonlinear mapping. Like NCA, DrLIM uses class neighbourhood structure to drive the optimization:
observations with the same class label are driven to be close-by in feature space. Our approach
is also inspired by recent hashing methods [2, 34, 38], although those techniques are restricted to
binary codes for fast lookup.

3

Learning an invariant mapping by nonlinear embedding

We first discuss Neighbourhood Components Analysis [14] and its nonlinear variants. We then propose an alternative objective function optimized for performing nearest neighbour (NN) regression
rather than classification. Next, we describe our convolutional architecture which maps images from
2

high-dimensional to low-dimensional space. Finally we introduce a related but different objective
for our model based on DrLIM.
3.1

Neighbourhood Components Analysis

NCA (both linear and nonlinear) and DrLIM do not presuppose the existence of a meaningful and
computable distance metric in the input space. They only require that neighbourhood relationships
be defined between training samples. This is well-suited for learning a metric for non-parametric
classification (e.g. KNN) on high-dimensional data. If the original data does not contain discrete
class labels, but real-valued labels (e.g. pose information for images of people) one alternative is to
define neighbourhoods based on the distance in the real-valued label space and proceed as usual.
However, if classification is not our ultimate goal, we may wish to exploit the ?soft? nature of the
labels and use an alternative objective (i.e. one that does not optimize KNN performance).
Suppose we are given a set of N labeled training cases {xi , yi }, i = 1, 2, . . . , N , where xi ? RD ,
and yi ? RL . Each training point, i, selects another point, j, as its neighbour with some probability
defined by normalizing distances in the transformed feature space [14]:
exp(?d2ij )
2 ,
k6=i exp(?dik )

pij = P

pii = 0,

dij = ||zi ? zj ||2

(1)

where we use a Euclidean distance metric dij and zi = f (xi |?) is the mapping (parametrized
by ?) from input space to feature space. For NCA this is typically linear, but it can be extended
to be nonlinear through back-propagation (for example in [34] it is a multi-layer neural network).
NCA assumes that the labels, yi , are discrete yi ? 1, 2, . . . , C rather than real-valued and seeks to
maximize the expected number of correctly classified points on the training data which minimizes:
N
X
X
LNCA = ?
pij .
(2)
i=1 j:yi =yj

The parameters are found by minimizing LNCA with respect to ?; back-propagating in the case of
a multi-layer parametrization. Instead of seeking to optimize KNN classification performance, we
can use the NCA regression (NCAR) objective [20]:
N X
X
LNCAR =
pij ||yi ? yj ||22 .
(3)
i=1 j6=i

Intuitively, this states that if, with high probability, i and j are neighbours in feature space, then
they should also lie close-by in label space. While we use the Euclidean distance in label space, our
approach generalizes to other metrics which may be more appropriate for a different domain.
Keller et al. [20] consider the linear case of NCAR, where ? is a weight matrix and y is a scalar
representing Bellman error to map states with similar Bellman errors close together. Similar to
NCA, we can extend this objective to the nonlinear, multi-layer case. We simply need to compute
the derivative of LNCAR with respect to the output of the mapping, zi , and backpropagate through
the remaining layers of the network. The gradient can be computed efficiently as:
X



?LNCAR
2
2
= ?2
(zi ? zj ) pij yij
? ?i + pji yij
? ?j .
(4)
?zi
j6=i
P
2
2
where we use yij
= ||yi ? yj ||22 and ?i = j pij yij
. See the supplementary material for details.
3.2 Convolutional architectures
As [34] points out, nonlinear NCA was originally proposed in [14] but with the exception of a
modest success with a two-layer network in extracting 2D codes that explicitly represented the
size and orientation of face images, attempts to extract more complex properties using multi-layer
feature extraction were less successful. This was due, in part, to the difficulty in training multi-layer
networks and the fact that many data pairs are required to fit the large number of network parameters.
Though both [34] and [38] were successful in learning a multi-layer nonlinear mapping of the data,
there is still a fundamental limitation of using fully-connected networks that must be addressed.
Such an architecture can only be applied to relatively small image patches (typically less than 64
? 64 pixels), because they do not scale well with the size of the input. Salakhutdinov and Hinton
3

escaped this issue by training only on the MNIST dataset (28 ? 28 images of digits) and Torralba
et al. used a global image descriptor [29] as an initial feature representation rather than pixels.
However, to avoid such hand-crafted features which may not be suitable for the task, and to scale to
realistic sized inputs, models should take advantage of the pictorial nature of the image input. This is
addressed by convolutional architectures [21], which exploit the fact that salient motifs can appear
anywhere in the image. By employing successive stages of weight-sharing and feature-pooling,
deep convolutional architectures can achieve stable latent representations at each layer, that preserve
locality, provide invariance to small variations of the input, and drastically reduce the number of free
parameters.
Our proposed method which we call Convolutional NCA regression (C-NCAR) is based on a standard convolutional architecture [21, 18]: alternating convolution and subsampling layers followed
by a single fully-connected layer (see Fig. 2). It differs from typical convolutional nets in the objective function with which it is trained (i.e. minimizing Eq. 3). Because the loss is defined on pairs of
examples, we use a siamese network [5]. Pairs of frames are processed by separate networks with
equal weights. The loss is then computed on the output of both networks. Hadsell et al. [16] also
use a siamese convolutional network with yet a different objective. They use their method for visualization but not any discriminative task. Mobahi et al. [24] have also recently used a convolutional
siamese network in which temporal coherence between pairs of frames drives the regularization of
the model rather than the objective. More details of training our network are given in Sec. 4.
Input:
128?128

Layer 1:
16?120?120

Layer 2:
16?24?24

Layer 3:
32?16?16

Layer 4:
32?4?4

xi

xj

Output:
32?1?1

d(z i ,z j )

Convolutions,
tanh(), abs()

Average
pooling

Convolutions,
tanh(), abs()

Average
pooling

Fully
connected

Figure 2: Convolutional NCA regression (C-NCAR). Each image is processed by two convolutional
and subsampling layers and one fully-connected layer. A loss (Eq. 3) computed on the distance
between resulting codes drives parameter learning.
3.3 Adding a contrastive loss function
Like NCA, DrLIM assumes a discrete notion of similarity or dissimilarity between data pairs, xi
and xj . It defines both a ?similarity? loss, Ls , which penalizes similar points which are far apart
in code space, and a ?dissimilarity? loss, LD , which penalizes dissimilar points which lie within a
user-defined margin, m, of each other:
1
1
LD (xi , xj ) = {max(0, m ? dij )}2
(5)
LS (xi , xj ) = d2ij
2
2
where dij is given by Eq. 1. Let ?ij be an indicator such that ?ij = 1 if xi and xj are deemed
similar and ?ij = 1 if xi and xj are deemed dissimilar. For example, if labels yi are discrete
yi ? 1, 2, . . . , C, then ?ij = 1 for yi = yj and ?ij = 0 otherwise. The total loss is defined by:
N X
X
LDrLIM =
?ij Ls (xi , xj ) + (1 ? ?ij )LD (xi , xj ).
(6)
i=1 j6=i

When faced with real-valued labels, yi , we can avoid explicitly defining similarity and dissimilarity
(e.g. via thresholding) by defining a ?soft? notion of similarity:
exp(?||yi ? yj ||22 )
(7)
??ij = P
2 .
k6=i exp(?||yi ? yj ||2 )
Replacing the indicator variables ?ij with ??ij in Eq. 6 yields what we call the soft DrLIM loss.
4

4

Experimental results

We evaluate our approach in real and synthetic environments by performing 1-nearest neighbour
(NN) regression using a variety of standard and learned metrics described below. For every query
image in a test set, we compute its distance (under the metric) to each of the training points in a
database. We then copy the label (e.g. (x,y) position of the head and hands) of the neighbour to the
query example. For evaluation, we compare the ground-truth label of the query to the label of the
nearest neighbour. Errors are reported in terms of mean pixel error over each query and each marker:
the head (if it is tracked) and each hand. Errors are absolute with respect to the original image size.
We acknowledge that improved results could potentially be obtained by using more than one neighbour or with more sophisticated techniques such as locally weighted regression [36]. However, we
focus on learning a good metric for performing this task rather than the regression problem. The
approaches compared are:
Pixel distance can be used to find nearest neighbours though it is not practical in real situations due
to the intractability of computing distances in such a high-dimensional space.
GIST descriptors [29] are a global representation of image content.We are motivated to use GIST
by its previous use in nonlinear NCA for image retrieval [38]. The resulting image representation
is a length-512 vector. We note that this is still too large for efficient NN search and that the GIST
features are not domain-adaptive.
Linear NCA regression (NCAR) is described in Section 3. We pre-compute GIST for each image
and use that as our input representation. We learn a 512 ? 32 matrix of weights by minimizing
Eq. 3 using nonlinear conjugate gradients with randomly sampled mini-batches of size 512. We
perform three line-searches per mini-batch and stop learning after 500 mini-batches. We found that
our results slightly improved when we applied a form of local contrast normalization (LCN) prior
to computing GIST. Each pixel?s response was normalized by the integrated response of a 9 ? 9
window of neighbouring pixels. For more details see [30].
Convolutional NCA regression (C-NCAR) See Fig. 2 for a summary of our architecture. Images
are pre-processed using LCN. Convolutions are followed by pixel-wise tanh and absolute value
rectification. The abs prevents cancellations in local neighbourhoods during average downsampling
[18]. Our architectural parameters (size of filters, number of filter banks, etc.) are chosen to produce
a 32-dimensional output. Derivations of parameter updates are presented as supplementary material.
Soft DrLIM (S-DrLIM) and Convolutional soft DrLIM (CS-DrLIM) We also experiment with a
variant of an alternative, energy-based method that adds an explicit contrastive loss to the objective
rather than implicitly through normalization. The contrastive loss only operates on dissimilar points
which lie within a specified margin, m, of each other. We use m = 1.25 as suggested by [16].
In both the linear and nonlinear case, the architecture and training procedure remains the same as
NCAR and C-NCAR, respectively. We use a different objective: minimizing Eq. 6 with respect to
the parameters.
4.1 Estimating 2D head and hand pose from synthetic data
We extracted 10,000 frames of training data and 5,000 frames of test data from Poser renderings
of several hours of real motion capture data. Our synthetic data is similar to that considered in [36],
however, we use a variety of backgrounds rather than a constant background. Furthermore, subjects
are free to move around the frame and are rendered at various scales. The training set contains 6
different characters superimposed on 9 different backgrounds. The test set contains 6 characters and
8 backgrounds not present in the training set. The inputs, x, are 320 ? 240 images, and the labels,
y, are 6D vectors - the true (x,y) locations of the head and hands.
Results are shown in Table 1 (column SY). Simple linear NCAR performs well compared to the
baselines, while our nonlinear methods C-NCAR and CS-DrLIM (which are not restricted to the
GIST descriptor) significantly outperform all other approaches. Pixel-based matching (though extremely slow) does surprisingly well. This is perhaps an artifact of the synthetic data.
4.2

Estimating 2D hand pose from real video

We digitally recorded all of the contributing and invited speakers at the Learning Workshop (Snowbird) held in April 2010. The set consisted of 30 speakers, with talks ranging from 10-40 minutes
each. After each session of talks, blocks of 150 frames were distributed as Human Intelligence Tasks
5

Table 1: 1-NN regression performance on the synthetic (SY) dataset and the real (RE) dataset. Results are divided into baselines (no learning), linear embeddings and nonlinear embeddings. Errors
are the mean pixel distance between the nearest neighbour and the ground truth label of the query.
For SY we locate the head and both hands. For RE we assume the location and scale of the head is
given by a face detector and only locate the hands. The images at right indicate: (top) a radius of
25.40 pixels with respect to the 320?240 SY input; (bottom) a radius of 16.41 pixels with respect to
the 128?128 RE input. Images have been scaled for the plot.
Embedding
None
None
PCA
PCA
NCAR
NCAR
S-DrLIM
Boost-SSC [36]
C-NCAR
CS-DrLIM

Input
Pixels
GIST
GIST
GIST
GIST
LCN+GIST
GIST
LCN+GIST
LCN
LCN

Dim
16384
512
128
32
32
32
32
32
32
32

Error-SY
32.86
47.41
47.17
48.99
34.21
32.90
37.80
34.80
28.95
25.40

Error-RE
25.12
25.13
24.85
25.74
24.93
23.15
25.19
22.65
16.41
19.61

on Amazon Mechanical Turk. We were able to obtain accurate hand and head tracks for each of the
speakers within a few hours of their talks. For the following experiments, we divided the 30 speakers
into a training set (odd numbered speakers) and test set (even numbered speakers).
Since current state-of-the-art face detection algorithms work reasonably well, we concentrate on the
harder problem of tracking the speakers? hands. We first run a commercial face detection algorithm
[26] on all frames which provides an estimate of scale for every frame. We use the average scale (per
video) estimated by the face detector to crop and rescale each frame to a 128x128 image (centered
on the head) that contains the speaker at roughly the same scale as other speakers (there is some
variability due to using average scale per video as speakers move throughout their talks). A similar
preprocessing step was used in [12]. We do not consider cases in which the hands lie outside
the frame or are occluded. This yields 39,792 and 37,671 training and test images, respectively,
containing the head and both hands. Since the images are head-centered, the labels, y, used during
training are the 4-dimensional vector containing the relative offset of each hand from the head.
We emphasize that finding the hands is an extremely difficult task (sometimes even for human subjects). Frames are low-resolution (typically the hands are 10-15 pixels in diameter) and contain
camera movement as well as frequently poor lighting. While previous work has assumed static
backgrounds, we confront the changing backgrounds and aim to learn invariance to both scene and
subject identity.
Results are shown in Table 1 (column RE). They are organized into three groups: baselines (highdimensional), and learning-based methods both linear and nonlinear. The linear methods are able
to achieve performance comparable to the baseline with the important attribute that distances are
computed in a 32-dimensional space. If the codes are made binary (as in [38]) we could use fast
approximate hashing techniques to permit real-time tracking using a database of well over 1 million
examples. The nonlinear methods show a dramatic improvement over the linear methods, especially
our convolutional architectures which learn features from pixels. Boost-SSC [36] is based on a
global representation similar to GIST, and so it is restricted in domain adaptivity. We also investigate
the performance of C-NCAR on code size (Fig. 5(a)). Performance is impressive even when the
dimension in which we compute distances is reduced from 32 to 2. A visualization of the 2D
embedding is shown in Fig. 3.
Fig. 4 shows some examples of nearest-neighbour matches under several different metrics. Most
apparent is that our methods, and in particular C-NCAR, develop invariance to background and focus
on the subject?s pose. Both pixel-based and GIST-batch matching are highly driven by the scene
(including lighting and background). Though our method is trained only on the relative positions
of the hands from the head, it appears to capture something more substantial about body pose in
general. We plan on evaluating this result quantitatively, using synthetic data in which we have
access to an articulated skeleton.
6

16.41 px

c1
c1

c1

3

2

1

c2

c2
c2

7

5
4 6

1

2

3
4

5
6

7
2

c3
c3
c3

1

3
5

c4

1
2

c4

5

4

4

3
6

Figure 3: Visualization of the 2D C-NCAR embedding of 1024 points from the RE training set. We
show the data points and their local geometry within four example clusters: C1-C4. Note that even
with a 2D embedding, we are able to capture pose similarity invariant of subject and background.

Query

C-NCAR

NCAR

GIST

Pixels

E=1.53

E=10.55

E=9.91

E=9.91

E=1.88

E=27.55

E=10.02

E=23.42

E=2.41

E=20.00

E=19.70

E=20.64

E=2.61

E=8.97

E=18.84

E=30.54

Figure 4: Nearest neighbour pose estimation. The leftmost column shows the query image, and
the remaining columns (left to right) show the nearest neighbour found by: nonlinear C-NCAR
regression, linear NCAR, GIST, pixel distance. Circles mark the pose obtained by crowd-sourcing;
we superimpose the pose estimated by C-NCAR onto the query with crosses.

4.3

Improving real-world performance with synthetic data

There has been recent interest in using synthetic examples to improve performance on real-world
vision tasks (e.g. [31]). The subtle differences between real and synthetic data make it difficult to
apply existing techniques to a dataset comprised of both types of examples. This problem falls under
the domain of transfer learning, but to the best of our knowledge, transfer learning between real and
synthetic pairings is relatively unexplored. While previous work has attempted to learn representations that are invariant to such effects as geometric distortions of the input [16] and temporal shifts
[5, 24] we know of no previous work that has explicitly attempted to learn features that are invariant
to the nature of the input, that is, real or synthetic.
7

1.06

18.5

1.04
Relative error (test)

Pixel error (test)

19

18
17.5
17

1
0.98
0.96
No synthetic
NCAR?1
NCAR?2

0.94

16.5
16
2

1.02

4

8
Dimension of code

16

0.92
256

32

(a)

512
1024
2048
Number of Synthetic Examples

4096

(b)

Figure 5: (a) Effect of code size on the performance of Convolutional NCA regression. (b) Adding
synthetic data to a fixed dataset of 1024 real examples to improve test performance measured on
real data. Error is expressed relative to a training set with no synthetic data. NCAR-1 does not
re-initialize weights when more synthetic examples are added. NCAR-2 reinitializes weights to
the same random seed for each run. The curves show that adding synthetic examples improve
performance up to a point at which the synthetic examples outnumber the real examples 2:1.
The pairwise nature of our approach is well-suited to learning such invariance, provided that we have
established correspondences between real and synthetic examples. In our case of pose estimation,
this comes from the labels. By forcing examples with similar poses (regardless of whether they are
real or synthetic) to lie close-by in code space we can implicitly produce a representation at each
layer that is invariant to the nature of the input. We have not made an attempt to restrict pairings to
be only between real and synthetic examples, though this may further aid in learning invariance.
Fig. 5(b) demonstrates the effect of gradually adding synthetic examples from SY to the RE training
dataset. We use a reduced-size set of 1024 real examples for training which is gradually modified
to contain synthetic examples and a fixed set of 1024 real examples for testing. Error is expressed
relative to the case of no synthetic examples. We use Linear NCA for this experiment and train as
described above. We follow two different regimes. In NCAR-1 we do not reset the weights of the
model to random each time we adjust the training set to add more synthetic examples. We simply
add more synthetic data and continue learning. In NCAR-2 we reset the weights to the same random
seed for each run. The overall result is the same for each regime: the addition of synthetic examples
to the training set improves test performance on real data up to a level at which the number of
synthetic examples is double the number of real examples.

5

Conclusions

We have presented a nonparametric approach for pose estimation in realistic, challenging video
datasets. At the core of our method is a learned parametric mapping from high-dimensional space to
a low-dimensional space in which distance is efficiently computed. Our work differs from previous
attempts at learning invariant mappings in that it is optimized for nearest neighbour regression rather
than classification and it scales to realistic sized images through the use of convolution and weightsharing. This permits us to learn domain-adaptive features directly from pixels rather than relying
on hand-crafted features or global descriptors.
In our experiments, we have restricted ourselves to 1-NN matching, but we plan to investigate other
more sophisticated approaches such as locally weighted regression, or using the match as an initialization for a gradient descent search in a parametric model. Though we work with video, our model
does not rely on any type of temporal coherence. Integrating temporal knowledge in the form of a
prior would benefit our approach. Alternatively, temporal context could be integrated at the input
level, from simple frame differencing to more sophisticated temporal feature extraction (e.g. [23]).
Our entire network is trained end-to-end with a single objective, and we do not perform any network pre-training as in [34, 38]. Recent work has demonstrated that pre-training can successfully
be applied to convolutional architectures, both in the context of RBMs [22, 27] and sparse coding [19]. We intend to investigate the effect of pre-training, as well as the use of mixed generative
and discriminative objectives.

8

References
[1] A. Agarwal, B. Triggs, I. Rhone-Alpes, and F. Montbonnot. Recovering 3D human pose from monocular images. IEEE Transactions on
Pattern Analysis and Machine Intelligence, 28(1):44?58, 2006.
[2] A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in high dimensions. In FOCS, pages
459?468, 2006.
[3] M. Andriluka, S. Roth, and B. Schiele. Pictorial structures revisited: People detection and articulated pose estimation. In CVPR, 2009.
[4] V. Athitsos, J. Alon, S. Sclaroff, and G. Kollios. Boostmap: A method for efficient approximate similarity rankings. CVPR, 2004.
[5] S. Becker and G. Hinton. Self-organizing neural network that discovers surfaces in random-dot stereograms. Nature, 355(6356):161?163,
1992.
[6] L. Bourdev and J. Malik. Poselets: Body part detectors trained using 3d human pose annotations. In ICCV, sep 2009.
[7] J. Bouvrie. Notes on convolutional neural networks. Unpublished, 2006.
[8] P. Buehler, A. Zisserman, and M. Everingham. Learning sign language by watching TV (using weakly aligned subtitles). CVPR, 2009.
[9] N. Dalal, B. Triggs, and C. Schmid. Human detection using oriented histograms of flow and appearance. ECCV, 2006.
[10] A. Farhadi, D. Forsyth, and R. White. Transfer Learning in Sign language. In CVPR, 2007.
[11] P. Felzenszwalb, D. McAllester, and D. Ramanan. A discriminatively trained, multiscale, deformable part model. In CVPR, 2008.
[12] V. Ferrari, M. Marin-Jimenez, and A. Zisserman. Pose search: Retrieving people using their pose. In CVPR, 2009.
[13] A. Frome, G. Cheung, A. Abdulkader, M. Zennaro, B. Wu, A. Bissacco, H. Adam, H. Neven, and L. Vincent. Large-scale Privacy
Protection in Google Street View. In ICCV, 2009.
[14] J. Goldberger, S. Roweis, G. Hinton, and R. Salakhutdinov. Neighbourhood components analysis. In NIPS, 2004.
[15] K. Grauman, G. Shakhnarovich, and T. Darrell. Inferring 3d structure with a statistical image-based shape model. In ICCV, pages
641?648, 2003.
[16] R. Hadsell, S. Chopra, and Y. LeCun. Dimensionality reduction by learning an invariant mapping. In CVPR, pages 1735?1742, 2006.
[17] G. Hinton and R. Salakhutdinov. Reducing the dimensionality of data with neural networks. Science, 313(5786):504 ? 507, 2006.
[18] K. Jarrett, K. Kavukcuoglu, M-A Ranzato, and Y. LeCun. What is the best multi-stage architecture for object recognition? In ICCV,
2009.
[19] K. Kavukcuoglu, M-A Ranzato, and Y. LeCun. Fast inference in sparse coding algorithms with applications to object recognition.
Technical report, NYU, 2008. CBLL-TR-2008-12-01.
[20] P. Keller, S. Mannor, and D. Precup. Automatic basis function construction for approximate dynamic programming and reinforcement
learning. In ICML, pages 449?456, 2006.
[21] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proc. IEEE, 86(11):2278?
2324, 1998.
[22] H. Lee, R. Grosse, R. Ranganath, and A. Y. Ng. Convolutional deep belief networks for scalable unsupervised learning of hierarchical
representations. In ICML, pages 609?616, 2009.
[23] R. Memisevic and G. Hinton. Unsupervised learning of image transformations. In CVPR, 2007.
[24] H. Mobahi, R. Collobert, and J. Weston. Deep learning from temporal coherence in video. In ICML, pages 737?744, 2009.
[25] G. Mori and J. Malik. Estimating human body configurations using shape context matching. ECCV, 2002.
[26] M. Nechyba, L. Brandy, and H. Schneiderman. Pittpatt face detection and tracking for the CLEAR 2007 evaluation. Multimodal
Technologies for Perception of Humans, 2008.
[27] M. Norouzi, M. Ranjbar, and G. Mori. Stacks of convolutional restricted boltzmann machines for shift-invariant feature learning. In
CVPR, 2009.
[28] S.J. Nowlan and J.C. Platt. A convolutional neural network hand tracker. In NIPS, 1995.
[29] A. Oliva and A. Torralba. Modeling the shape of the scene: A holistic representation of the spatial envelope. International Journal of
Computer Vision, 42(3):145?175, 2001.
[30] N. Pinto, D. Cox, and J. DiCarlo. Why is real-world visual object recognition hard? PLoS Comput Biol, 4(1), 2008.
[31] N. Pinto, D. Doukhan, J. DiCarlo, and David D. Cox. A high-throughput screening approach to discovering good forms of biologically
inspired visual representation. PLoS Comput Biol, 5(11), 11 2009.
[32] R. Poppe. Vision-based human motion analysis: An overview. Computer Vision and Image Understanding, 108(1-2):4?18, 2007.
[33] D. Ramanan, D. Forsyth, and A. Zisserman. Strike a pose: Tracking people by finding stylized poses. In CVPR, 2005.
[34] R. Salakhutdinov and G. Hinton. Learning a nonlinear embedding by preserving class neighbourhood structure. In AISTATS, volume 11,
2007.
[35] B. Sapp, C. Jordan, and B.Taskar. Adaptive pose priors for pictorial structures. In CVPR, 2010.
[36] G. Shakhnarovich, P. Viola, and T. Darrell. Fast pose estimation with parameter-sensitive hashing. In ICCV, pages 750?759, 2003.
[37] L. Sigal, A. Balan, and Black. M. J. HumanEva: Synchronized video and motion capture dataset and baseline algorithm for evaluation
of articulated human motion. IJCV, 87(1/2):4?27, 2010.
[38] A. Torralba, R. Fergus, and Y. Weiss. Small codes and large image databases for recognition. In CVPR, 2008.
[39] C. Wren, A. Azarbayejani, T. Darrell, and A. Pentland. Pfinder: Real-time tracking of the human body. IEEE Transactions on Pattern
Analysis and Machine Intelligence, 19(7):780?785, 1997.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 3475-online-prediction-on-large-diameter-graphs.pdf

Online Prediction on Large Diameter Graphs

Mark Herbster, Guy Lever, Massimiliano Pontil
Department of Computer Science
University College London
Gower Street, London WC1E 6BT, England, UK
{m.herbster, g.lever, m.pontil}@cs.ucl.ac.uk

Abstract
We continue our study of online prediction of the labelling of a graph. We show a
fundamental limitation of Laplacian-based algorithms: if the graph has a large diameter then the number of mistakes made by such algorithms may be proportional
to the square root of the number of vertices, even when tackling simple problems.
We overcome this drawback by means of an efficient algorithm which achieves
a logarithmic mistake bound. It is based on the notion of a spine, a path graph
which provides a linear embedding of the original graph. In practice, graphs may
exhibit cluster structure; thus in the last part, we present a modified algorithm
which achieves the ?best of both worlds?: it performs well locally in the presence
of cluster structure, and globally on large diameter graphs.

1

Introduction

We study the problem of predicting the labelling of a graph in the online learning framework. Consider the following game for predicting the labelling of a graph: Nature presents a graph; nature
queries a vertex vi1 ; the learner predicts y?1 ? {?1, 1}, the label of the vertex; nature presents a
label y1 ; nature queries a vertex vi2 ; the learner predicts y?2 ; and so forth. The learner?s goal is to
minimise the total number of mistakes M = |{t : y?t 6= yt }|. If nature is adversarial, the learner
will always mispredict, but if nature is regular or simple, there is hope that a learner may make only
a few mispredictions. Thus, a central goal of online learning is to design algorithms whose total
mispredictions can be bounded relative to the complexity of nature?s labelling. In [9, 8, 7], the cut
size (the number of edges between disagreeing labels) was used as a measure of the complexity of a
graph?s labelling, and mistake bounds relative to this and the graph diameter were derived.
The strength of the methods in [8, 7] is in the case when the graph exhibits ?cluster structure?. The
apparent deficiency of these methods is that they have poor bounds when the graph diameter is large
relative to the number of vertices. We observe that this weakness is not due to insufficiently tight
bounds, but is a problem in their performance. In particular, we discuss an example of a n-vertex
labelled graph with a single edge between disagreeing label sets. On this graph, sequential prediction
using the common method
based upon minimising the Laplacian semi-norm of a labelling, subject to
?
constraints, incurs ?( n) mistakes (see Theorem 3). The expectation is that the number of mistakes
incurred by an optimal online algorithm is bounded by O(ln n).
We solve this problem by observing that there exists an approximate structure-preserving embedding
of any graph into a path graph. In particular the cut-size of any labelling is increased by no more than
a factor of two. We call this embedding a spine of the graph. The spine is the foundation on which we
build two algorithms. Firstly we predict directly on the spine with the 1-nearest-neighbor algorithm.
We demonstrate that this equivalent to the Bayes-optimal classifier for a particular Markov random
field. A logarithmic mistake bound for learning on a path graph follows by the Halving algorithm
analysis. Secondly, we use the spine of the graph as a foundation to add a binary support tree to the
original graph. This enables us to prove a bound which is the ?best of both worlds? ? if the predicted
set of vertices has cluster-structure we will obtain a bound appropriate for that case, but if instead,
the predicted set exhibits a large diameter we will obtain a polylogarithmic bound.

Previous work. The seminal approach to semi-supervised learning over graphs in [3] is to predict
with a labelling which is consistent with a minimum label-separating cut. More recently, the graph
Laplacian has emerged as a key object in semi-supervised learning, for example the semi-norm
induced by the Laplacian is commonly either directly minimised subject to constraints, or used as
a regulariser [14, 2]. In [8, 7] the online graph labelling problem was studied. An aim of those
papers was to provide a natural interpretation of the bound on the cumulative mistakes of the kernel
perceptron when the kernel is the pseudoinverse of the graph Laplacian ? bounds in this case being
relative to the cut and (resistance) diameter of the graph. In this paper we necessarily build directly
on the very recent results in [7] as those results depend on the resistance diameter of the predicted
vertex set as opposed to the whole graph [8]. The online graph labelling problem is also studied in
[13], and here the graph structure is not given initially. A slightly weaker logarithmic bound for the
online graph labelling problem has also been independently derived via a connection to an online
routing problem in the very recent [5].

2

Preliminaries

We study the process of predicting a labelling defined on the vertices of a graph. Following the
classical online learning framework, a sequence of labelled vertices {(vi1 , y1 ), (vi2 , y2 ), . . . }, the
trial sequence, is presented to a learning algorithm such that, on sight of each vertex vit , the learner
makes a prediction y?t for the label value, after which the correct label is revealed. This feedback
information is then used by the learning algorithm to improve its performance on further examples.
We analyse the performance of a learning algorithm in the mistake bound framework [12] ? the aim
is to minimise the maximum possible cumulative number of mistakes made on the training sequence.
A graph G = (V, E) is a collection of vertices V = {v1 , . . . , vn } joined by connecting (possibly
weighted) edges. Denote i ? j whenever vi and vj are connected so that E = {(i, j) : i ? j} is the
set of unordered pairs of connected vertex indices. Associated with each edge (i, j) ? E is a weight
Aij , so that A is the n ? n symmetric adjacency matrix. We say that G is unweighted if Aij = 1
for every (i, j) ? E and is 0 otherwise. In this paper, we consider only connected graphs ? that is,
graphs such that there exists a path between any two vertices. The Laplacian G of a graph
P G is the
n ? n matrix G = D ? A, where D is the diagonal degree matrix such that Dii = j Aij . The
quadratic form associated with the Laplacian relates to the cut size of graph labellings.
Definition 1. Given a labelling u ? IRn of G = (V, E) we define the cut size of u by
1 T
1 X
?G (u) =
u Gu =
Aij (ui ? uj )2 .
(1)
4
4
(i,j)?E

n

In particular, if u ? {?1, 1} we say that a cut occurs on edge (i, j) if ui 6= uj and ?G (u) measures
the number of cuts.
We evaluate the performance of prediction algorithms in terms of the cut size and the resistance
diameter of the graph. There is an established natural connection between graphs and resistive
networks where each edge (i, j) ? E is viewed as a resistor with resistance 1/Aij [4]. Thus the
effective resistance rG (vi , vj ) between vertex vi and vj is the potential difference needed to induce a
unit current flow between vi and vj . The effective resistance may be computed by the formula [11]
rG (vi , vj ) = (ei ? ej )T G+ (ei ? ej ),
(2)
+
n
where ? ? denotes the pseudoinverse and e1 , . . . , en are the canonical basis vectors of IR . The
resistance diameter of a graph RG := maxvi ,vj ?V rG (vi , vj ) is the maximum effective resistance
between any pair of vertices on the graph.

3

Limitations of online minimum semi-norm interpolation

As we will show, it is possible to develop online algorithms for predicting the labelling of a graph
which have a mistake bound that is a logarithmic function of the number of vertices. Conversely, we
first highlight a deficiency in a standard Laplacian based method for predicting a graph labelling.
Given a partially labelled graph G = (V, E) with |V | = n ? that is, such that for some ` ? n,
y` ? {?1, 1}` is a labelling defined on the ` vertices V` = {vi1 , vi2 , . . . , vi` } ? the minimum
semi-norm interpolant is defined by
y? = argmin{uT Gu : u ? IRn , uik = yk , k = 1, . . . , `}.

We then predict using y?i = sgn(?
yi ), for i = 1, . . . , n.
The common justification behind the above learning paradigm [14, 2] is that minimizing the cut (1)
encourages neighbouring vertices to be similarly labelled. However, we now demonstrate that in the
online setting such a regime will perform poorly on ?
certain graph constructions ? there exists a trial
sequence on which the method will make at least ?( n) mistakes.
Definition 2. An octopus graph of size d is defined to be d path graphs (the tentacles) of length d
(that is, with d + 1 vertices) all adjoined at a common end vertex, to which a further single head
vertex is attached, so that n = |V | = d2 + 2. This corresponds to the graph O1,d,d discussed in [8].
Theorem 3. Let G = (V, E) be an octopus graph of size d and y = (y1 , . . . , y|V | ) the labelling
such that yi = 1 if vi is the head vertex and yi = ?1 otherwise.
There exists a trial sequence for
p
which online minimum semi-norm interpolation makes ?( |V |) mistakes.
Proof. Let the first query vertex be the head vertex, and let the end vertex of a tentacle be queried at
each subsequent trial. We show that this strategy forces at least d mistakes. The solution to the minimum semi-norm interpolation with boundary
Pn values problem is precisely the harmonic solution [4]
y? (that is, for every unlabeled vertex vj , i=1 Aij (?
yi ? y?j ) = 0). If the graph is connected y? is
unique and the graph labelling problem is identical to that of identifying the potential at each vertex
of a resistive network defined on the graph where each edge corresponds to a resistor of 1 unit; the
harmonic principle corresponds to Kirchoff?s current law in this case. Using this analogy, suppose
that the end points of k < d tentacles are labelled and that the end vertex vq of an unlabelled tentacle
is queried. Suppose a current of k? flows from the head to the body of the graph. By Kirchoff?s
law, a current of ? flows along each labelled tentacle (in order to obey the harmonic principle at
2
every vertex it is clear that no current flows along the unlabelled tentacles). By Ohm?s law ? = d+k
.
Minimum semi-norm interpolation therefore results in the solution
2k
y?q = 1 ?
? 0 iff k ? d.
d+k
Hence the minimum semi-norm solution predicts incorrectly whenever k < d and the algorithm
makes at least d mistakes.
The above demonstrates a limitation in the method of online Laplacian minimum semi-norm interpolation for predicting a graph labelling ? the mistake bound can be proportional to the square root
of the number of data points. We solve these problems in the following section.

4

A linear graph embedding

We demonstrate a method of embedding data represented as a connected graph G into a path graph,
we call it a spine of G, which partially preserves the structure of G. Let Pn be the set of path graphs
with n vertices. We would like to find a path graph with the same vertex set as G, which solves
?P (u)
.
min
max
P?Pn u?{?1,1}n ?G (u)
If a Hamiltonian path H of G (a path on G which visits each vertex precisely once) exists, then
(u)
the approximation ratio is ??H
? 1. The problem of finding a Hamiltonian path is NP-complete
G (u)
however, and such a path is not guaranteed to exist. As we shall see, a spine S of G may be found
S (u)
efficiently and satisfies ?
?G (u) ? 2.
We now detail the construction of a spine of a graph G = (V, E), with |V | = n. Starting from
any node, G is traversed in the manner of a depth-first search (that is, each vertex is fully explored
before backtracking to the last unexplored vertex), and an ordered list VL = {vl1 , vl2 , . . . , vl2m+1 }
of the vertices (m ? |E|) in the order that they are visited is formed, allowing repetitions when
a vertex is visited more than once. Note that each edge in EG is traversed no more than twice
when forming VL . Define an edge multiset EL = {(l1 , l2 ), (l2 , l3 ), . . . , (l2m , l2m+1 )} ? the set
of pairs of consecutive
vertices in VL . Let u be an P
arbitrary labelling of G and denote, as usual,
P
?G (u) = 41 (i,j)?EG (ui ? uj )2 and ?L (u) = 14 (i,j)?EL (ui ? uj )2 . Since the multiset EL
contains every element of EG no more than twice, ?L (u) ? 2?G (u).
We then take any subsequence VL0 of VL containing every vertex in V exactly once. A spine
S = (V, ES ) is a graph formed by connecting each vertex in V to its immediate neighbours in

the subsequence VL0 with an edge. Since a cut occurs between connected vertices vi and vj in S
only if a cut occurs on some edge in EL located between the corresponding vertices in the list VL
we have
?S (u) ? ?L (u) ? 2?G (u).

(3)

Thus we have reduced the problem of learning the cut on a generic graph to that of learning the
cut on a path graph. In the following we see that 1-nearest neighbour (1-NN) algorithm is a Bayes
optimal algorithm for this problem. Note that the 1-NN algorithm does not perform well
? on general
graphs; on the octopus graph discussed above, for example, it can make at least ?( n) mistakes,
and even ?(n) mistakes on a related graph construction [8].

5

Predicting with a spine

We consider implementing the 1-NN algorithm on a path graph and demonstrate that it achieves a
mistake bound which is logarithmic in the length of the line. Let G = (V, E) be a path graph, where
V = {v1 , v2 , . . . , vn } is the set of vertices and E = {(1, 2), (2, 3), . . . , (n ? 1, n)}. The nearest
neighbour algorithm, in the standard online learning framework described above, attempts to predict
a graph labelling by producing, for each query vertex vit , the prediction y?t which is consistent with
the label of the closest labelled vertex (and predicts randomly in the case of a tie).
Theorem 4. Given the task of predicting the labelling of any unweighted, n-vertex path graph P in
the online framework, the number of mistakes, M , incurred by the 1-NN algorithm satisfies


n?1
?P (u)
M ? ?P (u) log2
+
+ 1,
(4)
?P (u)
ln 2
where u ? {?1, 1}n is any labelling consistent with the trial sequence.
Proof. We shall prove the result by noting that the Halving algorithm [1] (under certain conditions
on the probabilities assigned to each hypothesis) implements the nearest neighbour algorithm on a
path graph. Given any input space X and finite binary concept class C ? {?1, 1}|X| , the Halving
algorithm learns any target concept c? ? C as follows. Each hypothesis c ? C is given an associated
probability p(c). A sequence of labelled examples {(x1 , y1 ), . . . , (xt?1 , yt?1 )} ? X ? {?1, 1}, is
revealed in accordance with the usual online framework. Let Ft be the set of feasible hypotheses at
trial t; Ft = {c : c(xs ) = ys ?s < t}. Given an unlabelled example xtP? X at trial t the predicted
label y?t is that which agrees with the majority vote ? that is, such that
it predicts randomly if this is equal to
most MH mistakes with

1
2 ).

c?Ft ,c(xt )=y
?t

P

c?Ft

p(c)

p(c)

>

1
2

(and

It is well known [1] that the Halving algorithm makes at


MH ? log2

1
p(c? )


.

(5)

We now define a probability distribution over the space of all labellings u ? {?1, 1}n of P such that
the Halving algorithm with these probabilities implements the nearest neighbour algorithm. Let a cut
occur on any given edge with probability ?, independently of all other cuts; Prob(ui+1 6= ui ) = ?
?i < n. The position of all cuts fixes the labelling up to flipping every label, and each of these
two resulting possible arrangements are equally likely. This recipe associates with each possible
labelling u ? {?1, 1}n a probability p(u) which is a function of the labelling?s cut size
1 ?P (u)
?
(1 ? ?)n?1??P (u) .
(6)
2
This induces a full joint probability distribution on the space of vertex labels. In fact (6) is a Gibbs
measure and as such defines a Markov random field over the space of vertex labels [10]. The mass
function p therefore satisfies the Markov property
p(u) =

p(ui = ? | uj = ?j ?j 6= i) = p(ui = ? | uj = ?j ?j ? Ni ),

(7)

where here Ni is the set of vertices neighbouring vi ? those connected to vi by an edge. We will
give an equivalent Markov property which allows a more general conditioning to reduce to that over
boundary vertices.

Definition 5. Given a path graph P = (V, E), a set of vertices V 0 ? V and a vertex vi ? V , we
define the boundary vertices v` , vr (either of which may be vacuous) to be the two vertices in V 0 that
are closest to vi in each direction along the path; its nearest neighbours in each direction.
The distribution induced by (6) satisfies the following Markov property; given a partial labelling of
P defined on a subset V 0 ? V , the label of any vertex vi is independent of all labels on V 0 except
those on the vertices v` , vr (either of which could be vacuous)
p(ui = ? | uj = ?j , ?j : vj ? V 0 )

= p(ui = ? | u` = ?` , ur = ?r ).

(8)

Given the construction of the probability distribution formed by independent cuts on graph edges,
we can evaluate conditional probabilities. For example, p(uj = ? | uk = ?) is the probability of an
even number of cuts between vertex vj and vertex vk . Since cuts occur with probability ? and there

are |k?j|
possible arrangements of s cuts we have
s

p(uj = ? | uk = ?) =

X |k ? j|
1
?s (1 ? ?)|k?j|?s = (1 + (1 ? 2?)|k?j| ).
s
2
s even

(9)

X |k ? j|
1
?s (1 ? ?)|k?j|?s = (1 ? (1 ? 2?)|k?j| ).
s
2

(10)

Likewise we have that
p(uj 6= ? | uk = ?) =

s odd

Note also that for any single vertex we have p(ui = ?) = 12 for ? ? {?1, 1}.
Lemma 6. Given the task of predicting the labelling of an n-vertex path graph online, the Halving
algorithm, with a probability distribution over the labellings defined as in (6) and such that 0 <
? < 12 , implements the nearest neighbour algorithm.
Proof. Suppose that t ? 1 trials have been performed so that we have a partial labelling of a subset
V 0 ? V , {(vi1 , y1 ), (vi2 , y2 ), . . . , (vit?1 , yt?1 )}. Suppose the label of vertex vit is queried so that
the Halving algorithm makes the following prediction y?t for vertex vit : y?t = y if p(uit = y | uij =
yj ? 1 ? j < t) > 21 , y?t = ?y if p(uit = y | uij = yj ? 1 ? j < t) < 21 (and predicts randomly
if this probability is equal to 12 ). We first consider the case where the conditional labelling includes
vertices on both sides of vit . We have, by (8), that
p(uit = y | uij = yj ? 1 ? j < t)

= p(uit = y | u` = y? (`) , ur = y? (r) )
=

p(u` = y? (`) | ur = y? (r) , uit = y)p(ur = y? (r) , uit = y)
p(u` = y? (`) , ur = y? (r) )

=

p(u` = y? (`) | uit = y)p(ur = y? (r) | uit = y)
p(u` = y? (`) | ur = y? (r) )

(11)

where v` and vr are the boundary vertices and ? (`) and ? (r) are trials at which vertices v` and vr
are queried, respectively. We can evaluate the right hand side of this expression using (9, 10). To
show equivalence with the nearest neighbour method whenever ? < 12 , we have from (9, 10, 11)
p(uit = y | u` = y, ur 6= y)

=

(1 + (1 ? 2?)|`?it | )(1 ? (1 ? 2?)|r?it | )
2(1 ? (1 ? 2?)|`?r| )

which is greater than 12 if |` ? it | < |r ? it | and less than 21 if |` ? it | > |r ? it |. Hence, this
produces predictions exactly in accordance with the nearest neighbour scheme. We also have more
simply that for all it , ` and r and ? < 12
p(uit = y | u` = y, ur = y) >

1
1
, and p(uit = y | u` = y) > .
2
2

This proves the lemma for all cases.
A direct application of the Halving algorithm mistake bound (5) now gives




1
2
M ? log2
= log2
p(u)
??P (u) (1 ? ?)n?1??P (u)

P (u) 1
where u is any labelling consistent with the trial sequence. We choose ? = min( ?n?1
, 2 ) (note
P (u)
that the bound is vacuous when ?n?1
> 12 since M is necessarily upper bounded by n) giving




?P (u)
n?1
+ (n ? 1 ? ?P (u)) log2 1 +
+1
M ? ?P (u) log2
?P (u)
n ? 1 ? ?P (u)


n?1
?P (u)
? ?P (u) log2
+
+ 1.
?P (u)
ln 2

This proves the theorem.
The nearest neighbour algorithm can predict the labelling of any graph G = (V, E), by first transferring the data representation to that of a spine S of G, as presented in Section 4. We now apply the
above argument to this method and immediately deduce our first main result.
Theorem 7. Given the task of predicting the labelling of any unweighted, connected, n-vertex graph
G = (V, E) in the online framework, the number of mistakes, M , incurred by the nearest neighbour
algorithm operating on a spine S of G satisfies



n?1
2?G (u)
M ? 2?G (u) max 0, log2
+ 1,
(12)
+
2?G (u)
ln 2
where u ? {?1, 1}n is any labelling consistent with the trial sequence.
Proof. Theorem 4 gives bound (4) for predicting on any path, hence M ? ?S (u) log2
?S (u)
ln 2 + 1. Since this is an increasing function of ?S (u) for ?S (u) ? n
?S (u) ? n ? 1 (M is necessarily upper bounded by n) we upper bound



n?1
?S (u)



+

? 1 and is vacuous at
substituting ?S (u) ?

2?G (u) (equation (3)).
We observe that predicting with the spine is a minimax improvement over Laplacian minimal seminorm interpolation. Recall Theorem 3, there we showed
? that there exists a trial sequence such that
Laplacian
p minimal semi-norm interpolation incurs ?( n) mistakes. In fact this trivially generalizes
to ?( ?G (u)n) mistakes by creating a colony of ?G (u) octopi then identifying each previously
separate head vertex as a single central vertex. The upper bound (12) is smaller than the prior lower
bound.
The computational complexity for this algorithm is O(|E| + |V | ln |V |) time. We compute the spine
in O(|E|) time by simply listing vertices in the order in which they are first visited during a depthfirst search traversal of G. Using online 1-NN requires O(|V | ln |V |) time to predict an arbitrary
vertex sequence using a self-balancing binary search tree (e.g., a red-black tree) as the insertion of
each vertex into the tree and determination of the nearest left and right neighbour is O(ln |V |).

6

Prediction with a binary support tree

The Pounce online label prediction algorithm [7] is designed to exploit cluster structure of a graph
G = (V, E) and achieves the following mistake bound
M ? N (X, ?, rG ) + 4?G (u)? + 1,

(13)

for any ? > 0. Here, u ? IRn is any labelling consistent with the trial sequence, X =
{vi1 , vi2 , . . . } ? V is the set of inputs and N (X, ?, rG ) is a covering number ? the minimum
number of balls of resistance diameter ? (see Section 2) required to cover X. The mistake bound
(13) can be preferable to (12) whenever the inputs are sufficiently clustered and so has a cover of
small diameter sets. For example, consider two (m + 1)-cliques, one labeled ?+1?, one ??1? with
cm arbitrary interconnecting edges (c ? 1) here the bound (12) is vacuous while (13) is M ? 8c + 3
2
(with ? = m
, N (X, ?, rG ) = 2, and ?G (u) = cm). An input space V may have both local cluster structure yet have a large diameter. Imagine a ?universe? such that points are distributed into
many dense clusters such that some sets of clusters are tightly packed but overall the distribution is
quite diffuse. A given ?problem? X ? V may then be centered on a few clusters or alternatively
encompass the entire space. Thus, for practical purposes, we would like a prediction algorithm

which achieves the ?best of both worlds?, that is a mistake bound which is no greater, in order of
magnitude, than the maximum of (12) and (13). The rest of this paper is directed toward this goal.
We now introduce the notion of binary support tree, formalise the Pounce method in the support tree
setting and then prove the desired result.
Definition 8. Given a graph G = (V, E), with |V | = n, and spine S, we define a binary support tree
of G to be any binary tree T = (VT , ET ) of least possible depth, D, whose leaves are the vertices
of S, in order. Note that D < log2 (n) + 1.
We show that there is a weighting of the support tree which ensures that the resistance diameter of
the support tree is small, but also such that any labelling of the leaf vertices can be extended to the
support tree such that its cut size remains small. This enables effective learning via the support tree.
A related construction has been used to build preconditioners for solving linear systems [6].
Lemma 9. Given any spine graph S = (V, E) with |V | = n, and labelling u ? {?1, 1}n , with
? ? [?1, 1]|VT |
support tree T = (VT , ET ), there exists a weighting A of T , and a labelling u
? and u are identical on V , ?T (u)
? < ?S (u) and RT ? (log2 n + 1)(log2 n +
of T such that u
4)(log2 (log2 n + 2))2 .
Proof. Let vr be the root vertex of T . Suppose each edge (i, j) ? ET has a weight Aij , which
is a function of the edge?s depth d = max{dT (vi , vr ), dT (vj , vr )}, Aij = W (d) where dT (v, v 0 )
? such
is the number of edges in the shortest path from v to v 0 . Consider the unique labelling u
that, for 1 ? i ? n we have u
?i = ui and such that for every other vertex vp ? VT , with child
u
? +?
u
vertices vc1 , vc2 , we have u
?p = c1 2 c2 , or u
?p = u
?c in the case where vp has only one child, vc .
Suppose the edges (p, c1 ), (p, c2 ) ? ET are at some depth d in T , and let V 0 ? V correspond to
the leaf vertices of T descended from vp . Define ?S (uV 0 ) to be the cut of u restricted to vertices
in V 0 . If u
? c1 = u
?c2 then (?
up ? u
?c1 )2 + (?
up ? u
?c2 )2 = 0 ? 2?S (uV 0 ), and if u
?c1 6= u
?c2 then
2
2
(?
up ? u
?c1 ) + (?
up ? u
?c2 ) ? 2 ? 2?S (uV 0 ). Hence

W (d) (?
up ? u
?c1 )2 + (?
up ? u
?c2 )2 ? 2W (d)?S (uV 0 )
(14)
(a similar inequality is trivial in the case that vp has only one child). Since the sets of leaf descendants
of all vertices at depth d form a partition of V , summing (14) first over all parent nodes at a given
depth and then over all integers d ? [1, D] gives
? ?2
4?T (u)

D
X

W (d)?S (u).

d=1

(15)
We then choose
1
(d + 1)(log2 (d + 1))2
R?
? 21 + ln2 2 2 x ln12 x dx =

W (d) =
and note that

P?

1
d=1 (d+1)(log2 (d+1))2

(16)
1
2

+ ln 2 < 2.

PD
Further, RT = 2 d=1 (d + 1)(log2 (d + 1))2 ? D(D + 3)(log2 (D + 1))2 and so D ? log2 n + 1
gives the resistance bound.
Definition 10. Given the task of predicting the labelling of an unweighted graph G = (V, E) the
? is formed
augmented Pounce algorithm proceeds as follows: An augmented graph G? = (V? , E)
by attaching a binary support tree of G, with weights defined as in (16), to G; formally let T =
(VT , ET ) be such a binary support tree of G, then G? = (VT , E ? ET ). The Pounce algorithm is
?
then used to predict the (partial) labelling defined on G.
Theorem 11. Given the task of predicting the labelling of any unweighted, connected, n-vertex
graph G = (V, E) in the online framework, the number of mistakes, M , incurred by the augmented
Pounce algorithm satisfies
M ? min{N (X, ?, rG ) + 12?G (u)?} + 1,
(17)
?>0

where N (X, ?, rG ) is the covering number of the input set X = {vi1 , vi2 , . . . } ? V relative to
the resistance distance rG of G and u ? IRn is any labelling consistent with the trial sequence.
Furthermore,
M ? 12?G (u)(log2 n + 1)(log2 n + 4)(log2 (log2 n + 2))2 + 2.
(18)

Proof. Let u be some labelling consistent with the trial sequence. By (3) we have that ?S (u) ?
2?G (u) for any spine S of G. Moreover, by the arguments in Lemma 9 there exists some labelling
? of the weighted support tree T of G, consistent with u on V , such that ?T (u)
? < ?S (u). We then
u
have
? = ?T (u)
? + ?G (u) < 3?G (u).
?G?(u)

(19)

By Rayleigh?s monotonicity law the addition of the support tree does not increase the resistance
between any vertices on G, hence
N (X, ?, rG?) ? N (X, ?, rG ).

(20)

? yields
? on G,
Combining inequalities (19) and (20) with the pounce bound (13) for predicting u
? + 1 ? N (X, ?, rG ) + 12?G (u)? + 1.
M ? N (X, ?, rG?) + 4?G?(u)?
? G? + 2 ?
which proves (17). We prove (18) by covering G? with single ball so that M ? 4?G?(u)R
12?G (u)RT + 2 and the result follows from the bound on RT in Lemma 9.

7

Conclusion

We have explored a deficiency with existing online techniques for predicting the labelling of a graph.
As a solution, we have presented an approximate cut-preserving embedding of any graph G =
(V, E) into a simple path graph, which we call a spine, such that an implementation of the 1nearest-neighbours algorithm is an efficient realisation of a Bayes optimal classifier. This therefore
achieves a mistake bound which is logarithmic in the size of the vertex set for any graph, and the
complexity of our algorithm is of O(|E| + |V | ln |V |). We further applied the insights gained to
a second algorithm ? an augmentation of the Pounce algorithm, which achieves a polylogarithmic
performance guarantee, but can further take advantage of clustered data, in which case its bound is
relative to any cover of the graph.

References
[1] J. M. Barzdin and R. V. Frievald. On the prediction of general recursive functions. Soviet Math. Doklady,
13:1224?1228, 1972.
[2] M. Belkin and P. Niyogi. Semi-supervised learning on riemannian manifolds. Machine Learning, 56:209?
239, 2004.
[3] A. Blum and S. Chawla. Learning from labeled and unlabeled data using graph mincuts. In Proc. 18th
International Conf. on Machine Learning, pages 19?26. Morgan Kaufmann, San Francisco, CA, 2001.
[4] P. Doyle and J. Snell. Random walks and electric networks. Mathematical Association of America, 1984.
[5] J. Fakcharoenphol and B. Kijsirikul. Low congestion online routing and an improved mistake bound for
online prediction of graph labeling. CoRR, abs/0809.2075, 2008.
[6] K. Gremban, G. Miller, and M. Zagha. Performance evaluation of a new parallel preconditioner. Parallel
Processing Symposium, International, 0:65, 1995.
[7] M. Herbster. Exploiting cluster-structure to predict the labeling of a graph. In The 19th International
Conference on Algorithmic Learning Theory, pages 54?69, 2008.
[8] M. Herbster and M. Pontil. Prediction on a graph with a perceptron. In B. Sch?olkopf, J. Platt, and
T. Hoffman, editors, Advances in Neural Information Processing Systems 19, pages 577?584. MIT Press,
Cambridge, MA, 2007.
[9] M. Herbster, M. Pontil, and L. Wainer. Online learning over graphs. In ICML ?05: Proceedings of the
22nd international conference on Machine learning, pages 305?312, New York, NY, USA, 2005. ACM.
[10] R. Kinderman and J. L. Snell. Markov Random Fields and Their Applications. Amer. Math. Soc., Providence, RI, 1980.
[11] D. Klein and M. Randi?c. Resistance distance. Journal of Mathematical Chemistry, 12(1):81?95, 1993.
[12] N. Littlestone. Learning when irrelevant attributes abound: A new linear-threshold algorithm. Machine
Learning, 2:285?318, 1988.
[13] K. Pelckmans and J. A. Suykens. An online algorithm for learning a labeling of a graph. In In Proceedings
of the 6th International Workshop on Mining and Learning with Graphs, 2008.
[14] X. Zhu, Z. Ghahramani, and J. Lafferty. Semi-supervised learning using gaussian fields and harmonic
functions. In 20-th International Conference on Machine Learning (ICML-2003), pages 912?919, 2003.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4447-exploiting-spatial-overlap-to-efficiently-compute-appearance-distances-between-image-windows.pdf

Exploiting spatial overlap to efficiently compute
appearance distances between image windows
Bogdan Alexe
ETH Zurich

Viviana Petrescu
ETH Zurich

Vittorio Ferrari
ETH Zurich

Abstract
We present a computationally efficient technique to compute the distance of highdimensional appearance descriptor vectors between image windows. The method
exploits the relation between appearance distance and spatial overlap. We derive
an upper bound on appearance distance given the spatial overlap of two windows
in an image, and use it to bound the distances of many pairs between two images.
We propose algorithms that build on these basic operations to efficiently solve
tasks relevant to many computer vision applications, such as finding all pairs of
windows between two images with distance smaller than a threshold, or finding
the single pair with the smallest distance. In experiments on the PASCAL VOC 07
dataset, our algorithms accurately solve these problems while greatly reducing the
number of appearance distances computed, and achieve larger speedups than approximate nearest neighbour algorithms based on trees [18] and on hashing [21].
For example, our algorithm finds the most similar pair of windows between two
images while computing only 1% of all distances on average.

1

Introduction

Computing the appearance distance between two windows is a fundamental operation in a wide
variety of computer vision techniques. Algorithms for weakly supervised learning of object
classes [7, 11, 16] typically compare large sets of windows between images trying to find recurring
patterns of appearance. Sliding-window object detectors based on kernel SVMs [13, 24] compute
appearance distances between the support vectors and a large number of windows in the test image.
In human pose estimation, [22] computes the color histogram dissimilarity between many candidate
windows for lower and upper arms. In image retrieval the user can search a large image database for
a query object specified by an image window [20]. Finally, many tracking algorithms [4, 5] compare
a window around the target object in the current frame to all windows in a surrounding region of the
next frame.
In most cases one is not interested in computing the distance between all pairs of windows from two
sets, but in a small subset of low distances, such as all pairs below a given threshold, or the single
best pair. Because of this, computer vision researchers often rely on efficient nearest neighbour
algorithms [2, 6, 10, 17, 18, 21]. Exact nearest neighbour algorithms organize the appearance
descriptors into trees which can be efficiently searched [17]. However, these methods work well only
for descriptors of small dimensionality n (typically n < 20), and their speedup vanishes for larger
n (e.g. the popular GIST descriptor [19] has n = 960). Locality sensitive hashing (LSH [2, 10, 21])
techniques hash the descriptors into bins, so that similar descritors are mapped to the same bins with
high probability. LSH is typically used for efficiently finding approximate nearest neighbours in
high dimensions [2, 6].
All the above methods consider windows only as points in appearance space. However, windows
exist also as points in the geometric space defined as their 4D coordinates in the image they lie in. In
this geometric space, a natural distance between two windows is their spatial overlap (fig. 1). In this
paper we propose to take advantage of an important relation between the geometric and appearance
spaces: the apparance distance between two windows decreases as their spatial overlap increases.
We derive an upper bound on the appearance distance between two windows in the same image,
1

Fig. 1: Relation between spatial overlap and appearance distance. Windows w1 , w2 in an image I are
embedded in geometric space and in appearance space. All windows overlapping more than r with w1 are at
most at distance B(r) in appearance space. The bound B(r) decreases as overlap increases (i.e. r decreases).

given their spatial overlap (sec. 2). We then use this bound in conjuction with the triangle inequality
to bound the appearance distances of many pairs of windows between two images, given the distance
of just one pair. Building on these basic operations, we design algorithms to efficiently find all pairs
with distance smaller than a threshold (sec. 3) and to find the single pair with the smallest distance
(sec. 4).
The techniques we propose reduce computation by minimizing the number of times appearance
distances are computed. They are complementary to methods for reducing the cost of computing
one distance, such as dimensionality reduction [15] or Hamming embeddings [14, 23].
We experimentally demonstrate in sec. 5 that the proposed algorithms accurately solve the above
problems while greatly reducing the number of appearance distances computed. We compare to
approximate nearest neighbour algorithms based on trees [18], as well as on the recent LSH technique [21]. The results show our techniques outperform them in the setting we consider, where the
datapoints are embedded in a space with additional overlap structure.

2

Relation between spatial overlap and appearance distance

Windows w in an image I are emdebbed in two spaces at the same time (fig. 1). In geometric
space, w is represented by its 4 spatial coordinates (e.g. x, y center, width, height). The distance
1 \w2 |
between two windows is defined based on their spatial overlap o(w1 , w2 ) = |w
|w1 [w2 | 2 [0, 1],
where \ denotes the area of the intersection and [ the area of the union. In appearance space, w
is represented by a high dimensional vector describing the pixel pattern inside it, as computed by
a function fapp (w) : I ! Rn (e.g. the GIST descriptor has n = 960 dimensions). In appearance
space, two windows are compared using a distance d(fapp (w1 ), fapp (w2 )).
Two overlapping windows w1 , w2 in an image I share the pixels contained in their intersection
(fig. 1). The spatial overlap of the two windows correlates with the proportion of common pixels
input to fapp when computing the descriptor for each window. In general, fapp varies smoothly with
the geometry of w, so that windows of similar geometry are close in appearance space. Consequently, the spatial overlap o and appearance distance d are related. In this paper we exploit this
relation to derive an upper bound B(o(w1 , w2 )) on the appearance distance between two overlapping
windows.
We present here the general form of the bound B, its main properties and explain why it is useful. In
subsections 2.1 and 2.2 we derive the actual bound itself. To simplify the notation we use d(w1 , w2 )
to denote the appearance distance d(fapp (w1 ), fapp (w2 )). We refer to it simply as distance and we
say overlap for spatial overlap. The upper bound B is a function of the overlap o(w1 , w2 ), and has
the following property
d(w1 , w2 ) ? B(o(w1 , w2 ))

8w1 , w2

(1)

o2

(2)

Moreover, B is a monotonic decreasing function
B(o1 ) ? B(o2 )
2

8o1

(a)

(b)

(c)

Fig. 2: Triangle inequality in appearance space. The triangle inequality (4) holds for any three
points fapp (w1 ), fapp (w2 ) and fapp (w3 ) in appearance space. (a) General case; (b) Lower bound case:
|d(w1 , w2 ) d(w2 , w3 )| = d(w1 , w3 ); (c) Upper bound case: d(w1 , w3 ) = d(w1 , w2 ) + d(w2 , w3 ).

This property means B continuously decreases as overlap increases. Therefore, all pairs of windows
within an overlap radius r (i.e. o(w1 , w2 ) r) have distance below B(r) (fig. 1)
d(w1 , w2 ) ? B(o(w1 , w2 )) ? B(r)

8w1 , w2 , o(w1 , w2 )

r

(3)

As defined above, B bounds the appearance distance between two windows in the same image.
Now we show how it can be used to derive a bound on the distances between windows in two
different images I 1 , I 2 . Given two windows w1 , w2 in I 1 and a window w3 in I 2 , we use the
triangle inequality to derive (fig. 2)
|d(w1 , w2 )

d(w2 , w3 )| ? d(w1 , w3 ) ? d(w1 , w2 ) + d(w2 , w3 )

Using the bound B in eq. (4) we obtain
max(0, d(w2 , w3 )

B(o(w1 , w2 ))) ? d(w1 , w3 ) ? B(o(w1 , w2 )) + d(w2 , w3 )

(4)

(5)

Eq. (5) delivers lower and upper bounds for d(w1 , w3 ) without explicitly computing it (given that
d(w2 , w3 ) and o(w1 , w2 ) are known). These bounds will form the basis of our algorithms for reducing the number of times the appearance distance is computed when solving two classic tasks (sec. 3
and 4).
In the next subsection we estimate B for arbitrary window descriptors (e.g. color histograms, bag of
visual words, GIST [19], HOG [8]) from a set of images (no human annotation required). In subsection 2.2 we derive exact bounds in closed form for histogram descriptors (e.g. color histograms,
bag of visual words [25]).
2.1

Statistical bounds for arbitrary window descriptors

We estimate B? from training data so that eq. (1) holds with probability ?
P ( d(w1 , w2 ) ? B? (o(w1 , w2 )) ) = ?

8w1 , w2

(6)

B? is estimated from a set of M training images I = {I m }. For each image I m we sample N
m
m
windows {wim }, and then compute for all window pairs their overlap om
ij = o(wi , wj ) and distance
m
m
m
m
m
dij = d(wi , wj ). The overall training dataset D is composed of (oij , dij ) for every window pair
m
D = { (om
ij , dij ) | k 2 {1, M } , i, j 2 {1, N }}

(7)

We now quantize the overlap values into 100 bins and estimate B? (o) for each bin o separately. For
m
a bin o, we consider the set Do of all distances dm
ij for which oij is in the bin. We choose B? (o) as
the ?-quantile of D(o) (fig. 3a)
B? (o) = q? (Do )

(8)

m
B1 (o) is the largest distance dm
ij for which oij is in bin o. Fig. 3a shows the binned distanceoverlap pairs and the bound B0.95 for GIST descriptors [19]. The data comes from 100 windows
sampled from more than 1000 images (details in sec. 5). Each column of this matrix is roughly
Gaussian distributed, and its mean continuously decreases with increasing overlap, confirming our
assumptions about the relation between overlap and distance (sec. 2). In particular, note how the
mean distance decrease fastest for 50% to 80% overlap.

3

(a)

(b)

Fig. 3: Estimating B0.95 (o) and omin (?). (a) The estimated B0.95 (o) (white line) for the GIST [19] appearance descriptor. (b) Using B0.95 (o) we derive omin (?).

Given a window w1 and a distance ? we can use B? to find windows w2 overlapping with w1
that are at most distance ? from w1 . This will be used extensively by our algorithms presented in
secs. 3 and 4. From B? we can derive what is the smallest overlap omin (?) so that all pairs of
windows overlapping more than omin (?) have distance smaller than ? (with probability more than
?). Formally
P ( d(w1 , w2 ) ? ? )

?

8w1 , w2 , o(w1 , w2 )

omin (?)

(9)

and omin (?) is defined as the smallest overlap o for which the bound is smaller than ? (fig. 3b)
omin (?) = min{o | B? (o) ? ?}
2.2

(10)

Exact bounds for histogram descriptors

The statistical bounds of the previous subsection can be estimated from images for any appearance
descriptor. In contrast, in this subsection we derive exact bounds in closed form for histogram descriptors (e.g. color histograms, bag of visual words [25]). Our derivation applies to L1 -normalized
histograms and the 2 distance. For simplicity of presentation, we assume every pixel contributes
one feature to the histogram of the window (as in color histograms). The derivation is very similar
for features computed on another regular grid (e.g. dense SURF bag-of-words [11]). We present
here the main idea behind the bound and give the full derivation in the supplementary material [1].
The upper bound B for two windows w1 and w2 corresponds to the limit case where the three
regions w1 \ w2 , w1 \ w2 and w2 \ w1 contain three disjoint sets of colors (or visual word in
general). Therefore, the upper bound B is
?
?
|w1 \ w2 | |w2 \ w1 |
+
+ |w1 \ w2 | ?
B(w1 , w2 ) =
|w1 |
|w2 |

1
|w1 |
1
|w1 |

1
|w2 |
+ |w12 |

Expressing the terms in (11) based on the windows overlap o = o(w1 , w2 ) =
closed form for the upper bound B that depends only on o
o
B(w1 , w2 ) = B(o(w1 , w2 )) = B(o) = 2 4 ?
o+1

2

|w1 \w2 |
|w1 [w2 | ,

(11)

we obtain a
(12)

In practice, this exact bound is typically much looser than its corresponding statistical bound learned
from data (sec. 2.1). Therefore, we use the statistical bound for the experiments in sec. 5.

3

Efficiently computing all window pairs with distance smaller than ?

In this section we present an algorithm to efficiently find all pairs of windows with distance smaller
than a threshold ? between two images I 1 , I 2 . Formally, given an input set of windows W 1 = {wi1 }
in image I 1 and a set W 2 = {wj2 } in image I 2 , the algorithm should return the set of pairs P? =
{ (wi1 , wj2 ) | d(wi1 , wj2 ) ? ? }.
Algorithm overview. Algorithm 1 summarizes our technique. Block 1 randomly samples a small
set of seed pairs, for which it explicly computes distances. The core of the algorithm (Block 3)
explores pairs overlapping with a seed, looking for all appearance distances smaller than ?. When
4

Algorithm 1 Efficiently computing all distances smaller than ?
Input: windows W m = {wim }, threshold ?, lookup table omin , number of initial samples F
Output: set P? of all pairs p with d(p) ? ?
1. Compute seed pairs PF

(a) sample F random pairs pij = (wi1 , wj2 ) from P = W 1 ? W 2 , giving PF

(b) compute dij = d(wi1 , wj2 ), 8pij 2 PF

2. Determine a sequence S of all pairs from P (gives schedule of block 3 below)
(a) sort the seed pairs in PF in order of decreasing distance
(b) set S(1 : F ) = PF
(c) fill S((F + 1) : end) with random pairs from P \ PF

3. For pc = S(1 : end) (explore the pairs in the S order)
(a) compute d(pc )
(b) if d(pc ) ? ?
i. let r = omin (? d(pc ))
ii. let N = overlap neighborhood(pc , r)
iii. for all pairs p 2 N : compute d(p)
iv. update P?
P? [ {p 2 N | d(p) ? ?}
(c) else
i. let r = omin (d(pc ) ?)
ii. let N = overlap neighborhood(pc , r)
iii. discard all pairs in N from S: S
S\N
overlap neighborhood
Input: pair pij = (wi1 , wj2 ), overlap radius r
Output: overlap neighborhood N of pij
N = { (wi1 , wv2 ) | o(wj2 , wv2 )

r } [ {(wu1 , wj2 ) | o(wi1 , wu1 )

r}

compute
Input: pair pij
Output: If d(wi1 , wj2 ) was never computed before, then compute it and store it in a table D. If
d(wi1 , wj2 ) is already in D, then directly return it.
exploring a seed, the algorithm can decide to discard many pairs overlapping with it, as the bound
predicts that their distance cannot be lower than ?. This causes the computational saving (step 3.c).
Before starting Block 3, Block 2 establishes the sequence in which to explore the seeds, i.e. in order
of decreasing distance. The remaining pairs are appended in random order afterwards.
Algorithm core. Block 3 takes one of two actions based on the distance of the pair pc currently
being explored. If d(pc ) ? ?, then all pairs in the overlap neighborhood N of pc have distance
smaller than ?. This overlap neighborhood has a radius r = omin (? d(pc )) predicted by the
bound lookup table omin (fig. 4a). Therefore, Block 3 computes the distance of all pairs in N
(step 3.b). Instead, if d(pc ) > ?, Block 3 determines the radius r = omin (d(pc ) ?) of the overlap
neighborhood containing pairs with distance greater than ?, and then discards all pairs in it (step 3.c).
Overlap neighborhood. The overlap neighborhood of a pair pij = (wi1 , wj2 ) with radius r contains all pairs (wi1 , wv2 ) such that o(wj2 , wv2 )
r, and all pairs (wu1 , wj2 ) such that o(wi1 , wu1 )
r
(fig. 4a).

4

Efficiently computing the single window pair with the smallest distance

We give an algorithm to efficiently find the single pair of windows with the smallest appearance
distance between two images. Given as input the two sets of windows W 1 , W 2 , the algorithm
should return the pair p? = (wi1? , wj2? ) with the smallest distance: d(wi1? , wj2? ) = minij d(wi1 , wj2 ).
5

(a)

(b)

Fig. 4: Overlap neighborhoods. (a) The overlap neighborhood of radius r of a pair (wi1 , wj2 ) contains all
blue pairs. (b) The joint overlap neighborhood of radius s of a pair (wi1 , wj2 ) contains all blue and green pairs.

Algorithm overview. Algorithm 2 is analog to Algorithm 1. Block 1 computes distances for the
seed pairs and it selectes the pair with the smallest distance as initial approximation to p? . Block 3
explores pairs overlapping with a seed, looking for a distance smaller than d(p? ). When exploring a
seed, the algorithm can decide to discard many pairs overlapping with it, as the bound predicts they
cannot be better than p? . Block 2 organizes the seeds in order of increasing distance. In this way,
the algorithm can rapidly refine p? towards smaller and smaller values. This is useful because in
step 3.c, the amount of discarded pairs is greater as d(p? ) gets smaller. Therefore, this seed ordering
maximises the number of discarded pairs (i.e. minimizes the number of distances computed).
Algorithm core. Block 3 takes one of two actions based on d(pc ). If d(pc ) ? d(p? ) + B? (s),
then there might be a better pair than d(p? ) within radius s in the joint overlap neighborhood of
pc . Therefore, the algorithm computes the distance of all pairs in this neighborhood (step 3.b). The
radius s is an input parameter. Instead, if d(pc ) > d(p? ) + B? (s), the algorithm determines the
radius r = omin (d(pc ) d(p? )) of the overlap neighborhood that contains only pairs with distance
greater than d(p? ), and then discards all pairs in it (step 3.c).
Joint overlap neighborhood. The joint overlap neighborhood of a pair pij = (wi1 , wj2 ) with
radius s contains all pairs (wu1 , wv2 ) such that o(wi1 , wu1 ) s and o(wj2 , wv2 ) s.

5

Experiments and conclusions

We present experiments on a test set composed of 1000 image pairs from the PASCAL VOC 07
dataset [12], randomly sampled under the constraint that two images in a pair contain at least one
object of the same class (out of 6 classes: aeroplane, bicycle, bus, boat, horse, motorbike). This
setting is relevant for various applications, such as object detection [13, 24], and ensures a balanced
distribution of appearance distances in each image pair (some pairs of windows will have a low
distance while others high distances). We experiment with three appearance descriptors: GIST [19]
(960D), color histograms (CHIST, 4000D), and bag-of-words [11, 25] on the dense SURF descriptor [3] (BOW, 2000D). As appearance distances we use the Euclidean for GIST, and 2 for CHIST
and SURF BOW. The bound tables B? for each descriptor were estimated beforehand from a separate set of 1300 images of other classes (sec. 2.1).
Task 1: all pairs of windows with distance smaller than ?. The task is to find all pairs of windows with distance smaller than a user-defined threshold ? between two images I 1 , I 2 (sec. 3). This
task occurs in weakly supervised learning of object classes [7, 11, 16], where algorithms search for
recurring patterns over training images containing thousands of overlapping windows, and in human
pose estimation [22], which compares many overlapping candidate body part locations.
We random sample 3000 windows in each image (|W 1 | = |W 2 | = 3000) and set ? so that 10%
of all distances are below it. This makes the task meaningful for any image pair, regardless of the
range of distances it contains. For each image pair we quantify performance with two measures: (i)
cost: the number of P
computed distances divided by the total number of window pairs (9 millions);
p2P? (? d(p))
(i) accuracy: P
, where P? is the set of window pairs returned by the algo{p2W 1 ?W 2 |d(p)??} (? d(p))
rithm, and the denominator sums over all distances truly below ?. The lowest possible cost while
still achieving 100% accuracy is 10%.
We compare to LSH [2, 6, 10] using [21] as a hash function. It maps descriptors to binary strings,
such that the Hamming distance between two strings is related to the value of a Gaussian kernel
between the original descriptors [21]. As recommended in [6, 10], we generate T separate (random)
encodings and build T hash tables, each with 2C bins, where C is the number of bits in the encoding.
6

Algorithm 2 Efficiently computing the smallest distance
Input: windows W m = {wim }, lookup table omin , search radius s, number of initial samples F
Output: pair p? with the smallest distance
1. Compute seed pairs PF (as Block 1 of Algorithm 1) and
estimate current best pair: p? = arg minpij 2PF dij

2. Determine a sequence S of all pairs (as Block 2 of Algorithm 1)
3. For pc = S(1 : end) (explore the pairs in the S order)
(a) compute d(pc )
(b) if d(pc ) ? d(p? ) + B? (s)
i. let N = joint overlap neighborhood(pc , s)
ii. for all pairs p 2 N : compute d(p)
iii. update p?
arg min {{d(p? )} [ {d(p) | p 2 N }}
(c) else
i. let r = omin (d(pc ) d(p? ))
ii. let N = overlap neighborhood(pc , r)
iii. discard all pairs in N from S: S
S\N
joint overlap neighborhood
Input pair pij = (wi1 , wj2 ), overlap radius s
Output: joint overlap neighborhood N of pij
N = { (wu1 , wv2 ) | o(wi1 , wu1 )

s, o(wj2 , wv2 )

s}

To perform Task 1, we loop over each table t and do: (H1) hash all wj2 2 W 2 into table t; (H2) for
each wi1 2 W 1 do: (H2.1) hash wi1 into its bin b1t,i ; (H2.2) compute all distances d in the original
space between wi1 and all windows wj2 2 b1t,i (unless already computed when inspecting a previous
table); (H3) return all computed d(wi1 , wj2 ) ? ?.
We also compare to approximate nearest-neighbors based on kd-trees, using the ANN library [18].
To perform Task 1, we do: (A1) for each wi1 2 W 1 do: (A1.1) compute the ?-NN between wi1
and all windows wj2 2 W 2 and return them all. The notion of cost above is not defined for ANN
methods based on trees. Instead, we measure wall clock runtime. Instead, we report as cost the ratio
of the runtime of approximate NN over the runtime of exact NN (also computed using the ANN
library [18]). This gives a meaningful indication of speedup, which can be compared to the cost we
report for our method and LSH. As the ANN library supports only the Euclidean distance, we report
results only for GIST.

The results table reports cost and accuracy averaged over the test set. Our method from sec. 3
performs very well for all three descriptors. On average it achieves 98% accuracy at 16% cost. This
is a considerable speedup over exhaustive search, as it means only 7% of the 90% distances greater
than ? have been computed. The behavior of LSH depends on T and C. The higher the T , the
higher the accuracy, but also the cost (because there are more collisions; the same holds for lower
C). To compare fairly, we evaluate LSH over T 2 {1, 20} and C 2 {2, 30} and report results for
the T, C that deliver the closest accuracy to our method. As the table shows, on average over the
three descriptors, for same accuracy LSH has cost 92%, substantially worse than our method. The
behavior of ANN depends on the degree of approximation which we set so as to get accuracy closest
to our method. At 92% accuracy, ANN has 72% of the runtime of exact NN. This shows that, if high
accuracy is desired, ANN offers only a modest speedup (compared to our 18% cost for GIST).
Task 2: all windows closer than ? to a query. This is a special case of Task 1, where W 1 contains
just one window. Hence, this becomes a ?-nearest-neighbours task where W 1 acts as a query and
W 2 as the retrieval database. This task occurs in many applications, e.g. object detectors based
on kernel SVMs compare a support vector (query) to a large set of overlapping windows in the test
image [13, 24]. As this is expensive, many detectors resort to linear kernels [9]. Our algorithms
7

GIST + Euclidean distance
method
cost
accuracy
our
18.0%
97.3%
LSH
86.2%
95.4%
ANN
71.8%
91.9%
method
our
LSH
ANN

cost
30.2%
73.4%
72.6%

method
our
LSH
ANN

cost
2.3%
16.4%
58.6%

accuracy
87.1%
83.5%
87.7%
ratio
1.02
1.03
1.01

rank
1.39
2.72
1.48

Task 1
CHIST + 2 distance
method
cost
accuracy
our
15.7%
97.7%
LSH
93.7%
97.2%
ANN
Task 2
method
cost
accuracy
our
30.3%
96.2%
LSH
96.9%
95.1%
ANN
Task 3
method
cost
ratio rank
our
0.4%
1.01 1.12
LSH
37.5% 1.02 33.5
ANN
-

SURF BOW +
method
cost
our
15.2%
LSH
96.8%
ANN
method
our
LSH
ANN

cost
28.6%
88.7%
-

method
our
LSH
ANN

cost
0.7%
46.5%
-

2

distance
accuracy
98.5%
98.5%
accuracy
94.0%
92.1%
-

ratio
1.01
1.01
-

rank
1.19
9.62
-

offer the option to use more complex kernels while retaining a practical speed. Other applications
include tracking in video [4, 5] and image retrieval [20] (see beginning of sec. 1).
As the table shows, our method is somewhat less efficient than on Task 1. This makes sense, as it
can only exploit overlap structure in one of the two input sets. Yet, for a similar accuracy it offers
greater speedup than LSH and ANN.
Task 3: single pair of windows with smallest distance. The task is to find the single pair of
windows with the smallest distance between I 1 and I 2 , out of 3000 windows in each image (sec. 4),
and has similar applications as Task 1.
We quantify performance with three measures: (i) cost: as in all other tasks. (ii) distance ratio: the
ratio between the smallest distance returned by the algorithm and the true smallest distance. The
best possible value is 1, and higher values are worse; (iii) rank: the rank of the returned distance
among all 9 million.
To perform Task 3 with LSH, we simply modify step (H3) of the procedure given for Task 1 to:
return the smallest distance among all those computed. To perform Task 3 with ANN we replace
step (A1.1) with: compute the NN of wi1 in W 2 . At the end of loop (A1) return the smallest distance
among all those computed.
As the table shows, on average over the three descriptors, our method from sec. 4 achieves a distance
ratio of 1.01 at 1.1% cost, which is almost a 100? faster than exhaustive search. The average rank of
the returned distance is 1.25 out of 9 millions, which is almost a perfect result. When compared at a
similar distance ratio, our method is considerably more efficient than LSH and ANN. LSH computes
33.3% of all distances, while ANN brings only a speedup of factor 2 over exact NN.
Runtime considerations. While we have measured only the number of computed appearance distances, our algorithms also compute spatial overlaps. Crucially, spatial overlaps are computed in the
4D geometric space, compared to 1000+ dimensions for the appearance space. Therefore, computing spatial overlaps has negligible impact on the total runtime of the algorithms. In practice, when
using 5000 windows per image with 4000D dense SURF BOW descriptors, the total runtime of our
algorithms is 71s for Task 1 or 16s for Task 3, compared to 335s for exhaustive search. Importantly, the cost of computing the descriptors is small compared to the cost of evaluating distances,
as it is roughly linear in the number of windows and can be implemented very rapidly. In practice,
computing dense SURF BOW for 5000 windows in two images takes 5 seconds.
Conclusions. We have proposed efficient algorithms for computing distances of appearance descriptors between two sets of image windows, by taking advantage of the overlap structure in the
sets. Our experiments demonstrate that these algorithms greatly reduce the number of appearance
distances computed when solving several tasks relevant to computer vision and outperform LSH
and ANN for these tasks. Our algorithms could be useful in various applications. For example,
improving the spatial accuracy of weakly supervised learners [7, 11] by using thousands of windows per image, using more complex kernels and detecting more classes in kernel SVM object
detectors [13, 24], and enabling image retrieval systems to search at the window level with any descriptor, rather than returning entire images or be constrained to bag-of-words descriptors [20]. To
encourage these applications, we release our source code at http://www.vision.ee.ethz.ch/?calvin.
8

References
[1] B. Alexe, V. Petrescu, and V. Ferrari. Exploiting spatial overlap to efficiently compute appearance distances between image windows - supplementary material. In NIPS, 2011. Also
available at http://www.vision.ee.ethz.ch/ calvin/publications.html.
[2] A. Andoni and P. Indyk. Near-optimal hashing algorithms for approximate nearest neighbor in
high dimensions. In Communications of the ACM, 2008.
[3] H. Bay, A. Ess, T. Tuytelaars, and L. van Gool. SURF: Speeded up robust features. CVIU,
110(3):346?359, 2008.
[4] C. Bibby and I. Reid. Robust real-time visual tracking using pixel-wise posteriors. In ECCV,
2008.
[5] S. Birchfield. Elliptical head tracking using intensity gradients and color histograms. In CVPR,
1998.
[6] O. Chum, J. Philbin, M. Isard, and A. Zisserman. Scalable near identical image and shot
detection. In CIVR, 2007.
[7] O. Chum and A. Zisserman. An exemplar model for learning object classes. In CVPR, 2007.
[8] N. Dalal and B. Triggs. Histogram of Oriented Gradients for Human Detection. In CVPR,
volume 2, pages 886?893, 2005.
[9] N. Dalal and B. Triggs. Histogram of oriented gradients for human detection. In CVPR, 2005.
[10] M. Datar, N. Immorlica, P. Indyk, and V. Mirrokni. Locality-sensitive hashing scheme based
on p-stable distributions. In SCG, 2004.
[11] T. Deselaers, B. Alexe, and V. Ferrari. Localizing objects while learning their appearance. In
ECCV, 2010.
[12] M. Everingham, L. Van Gool, C. Williams, J. Winn, and A. Zisserman. The PASCAL Visual
Object Classes Challenge 2007 Results, 2007.
[13] H. Harzallah, F. Jurie, and C. Schmid. Combining efficient object localization and image
classification. In ICCV, 2009.
[14] H. Jegou, M. Douze, and C. Schmid. Hamming embedding and weak geometric consistency
for large-scale image search. In ECCV, 2008.
[15] Y. Ke and R. Sukthankar. Pca-sift: A more distinctive representation for local image descriptors. In CVPR, 2004.
[16] G. Kim and A. Torralba. Unsupervised detection of regions of interest using iterative link
analysis. In NIPS, 2009.
[17] N. Kumar, L. Zhang, and S. Nayar. What is a good nearest neighbors algorithm for finding
similar patches in images? In ECCV, 2008.
[18] D. M. Mount and S. Arya. Ann: A library for approximate nearest neighbor searching, August
2006.
[19] A. Oliva and A. Torralba. Modeling the shape of the scene: a holistic representation of the
spatial envelope. IJCV, 42(3):145?175, 2001.
[20] J. Philbin, O. Chum, M. Isard, J. Sivic, and A. Zisserman. Object retrieval with large vocabularies and fast spatial matching. In CVPR, 2007.
[21] M. Raginski and S. Lazebnik. Locality sensitive binary codes from shift-invariant kernels. In
NIPS, 2009.
[22] B. Sapp, A. Toshev, and B. Taskar. Cascaded models for articulated pose estimation. In ECCV,
2010.
[23] A. Torralba, R. Fergus, and Y. Weiss. Small codes and large image databases for recognition.
In CVPR, 2008.
[24] A. Vedaldi, V. Gulshan, M. Varma, and A. Zisserman. Multiple kernels for object detection.
In ICCV, 2009.
[25] J. Zhang, M. Marszalek, S. Lazebnik, and C. Schmid. Local features and kernels for classification of texture and object categories: a comprehensive study. IJCV, 2007.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 585-fast-robust-adaptive-control-by-learning-only-forward-models.pdf

Fast, Robust Adaptive Control by Learning only
Forward Models

Andrew W. Moore
MIT Artificial Intelligence Laboratory
545 Technology Square, Cambridge, MA 02139
awmGai.JD.it.edu

Abstract
A large class of motor control tasks requires that on each cycle the controller is told its current state and must choose an action to achieve a
specified, state-dependent, goal behaviour. This paper argues that the
optimization of learning rate, the number of experimental control decisions before adequate performance is obtained, and robustness is of prime
importance-if necessary at the expense of computation per control cycle and memory requirement. This is motivated by the observation that
a robot which requires two thousand learning steps to achieve adequate
performance, or a robot which occasionally gets stuck while learning, will
always be undesirable, whereas moderate computational expense can be
accommodated by increasingly powerful computer hardware. It is not unreasonable to assume the existence of inexpensive 100 Mflop controllers
within a few years and so even processes with control cycles in the low
tens of milliseconds will have millions of machine instructions in which to
make their decisions. This paper outlines a learning control scheme which
aims to make effective use of such computational power.

1

MEMORY BASED LEARNING

Memory-based learning is an approach applicable to both classification and function learning in which all experiences presented to the learning box are explicitly remembered. The memory, Mem, is a set of input-output pairs, Mem =
{(Xl, YI), (X21 Y2), ... , (Xb Yk)}. When a prediction is required of the output of a
novel input Xquery, the memory is searched to obtain experiences with inputs close to
Xquery. These local neighbours are used to determine a locally consistent output for
the query. Three memory-based techniques, Nearest Neighbour, Kernel Regression,
and Local Weighted Regression, are shown in the accompanying figure.

571

572

Moore

j.

?

?

?

I

?

I

?

,

?

,

w

laput

Nearest

Neighbour:
Yi where
i minimizes {( Xi - x query) 2 :
(Xi, Yi) E Mem}.
There
is a general introduction
in [5], some recent applications in [11], and recent
robot learning work in [9, 3].
Ypredict(Xquery)

2

j.

i?

o? ?

o? ?

=

?

o? ?

,

?

?

?

?

?

,

?

,

.e

?

,

lap.t

?

I

?

I

?

Y

?

?

M

lap.t

Kernel Regression: Also Local Weighted Regresknown as Shepard's interpo- sion: finds the linear maplation or Local Weighted Av- ping Y = Ax to minimize
erages. Y;.;edict(Xquery) = the sum of weighted squares
C? w.y.)/ L w. where Wi = of residua!s E Wj(Yi - AXi)2.
exp( -(Xi - Xquery )2 / K width 2)Yp!~dict IS ~hen AXquery.
[6] describes some variants
LWR was mtroduced for
. robot learning control by [1].

A MEMORY-BASED INVERSE MODEL

An inverse model maps State x Behaviour ~ Action (8 x b ~ a). Behaviour is
the output of the system, typically the next state or time derivative of state. The
learned inverse model provides a conceptually simple controller:
1. Observe 8 and b goa1 .
2. a : - inverse-model(s, bgoal)
3. Perform action a and observe actual behaviour bactual.
4. Update MEM with (8, b actual - a): If we are ever again in state 8 and
require behaviour bactual we should apply action a.

Memory-based versions of this simple algorithm have used nearest neighbour [9]
and LWR [3]. bgoal is the goal behaviour: depending on the task it may be fixed
or it may vary between control cycles, perhaps as a function of state or time. The
algorithm provides aggressive learning: during repeated attempts to achieve the
same goal behaviour, the action which is applied is not an incrementally adjusted
version of the previous action, but is instead the action which the memory and the
memory-based learner predicts will directly achieve the required behaviour. If the
function is locally linear then the sequence of actions which are chosen are closely
related to the Secant method [4] for numerically finding the zero of a function by
bisecting the line between the closest approximations that bracket the y = 0 axis. If
learning begins with an initial error Eo in the action choice, and we wish to reduce
this error to Eo/I<, the number of learning steps is O(log log I<): subject to benign
conditions, the learner jumps to actions close to the ideal action very quickly.
A common objection to learning the inverse model is that it may be ill-defined. For
a memory-based method the problems are particularly serious because of its update
rule. It updates the inverse model near bactual and therefore in those cases in which
bgoal and bactual differ greatly, the mapping near bgoal may not change. As a result,

Fast, Robust Adaptive Control by Learning only Forward Models

subsequent cycles will make identical mistakes. [10] discusses this further.

3

A MEMORY-BASED FORWARD MODEL

One fix for the problem of inverses becoming stuck is the addition of random noise
to actions prior to their application. However, this can result in a large proportion
of control cycles being wasted on experiments which the robot should have been able
to predict as valueless, defeating the initial aim of learning as quickly as possible.
An alternative technique using multilayer neural nets has been to learn a forward
model, which is necessarily well defined, to train a partial inverse. Updates to the
forward model are obtained by standard supervised training, but updates to the
inverse model are more sophisticated. The local Jacobian of the forward model
is obtained and this value is used to drive an incremental change to the inverse
model [8]. In conjunction with memory-based methods such an approach has the
disadvantage that incremental changes to the inverse model loses the one-shot learning behaviour, and introduces the danger of becoming trapped in a local minimum.
Instead, this investigation only relies on learning the forward model. Then the
inverse model is implicitly obtained from it by online numerical inversion instead of
direct lookup. This is illustrated by the following algorithm:
1. Observe sand bgoal.
2. Perform numerical inversion:

Search among a series of candidate actions
a1, a2 .. , ak:
brredict : _ forvard-llodel( s, a1, MEM)
b~redict : = forvard-llodel(s, a2, MEM)

Until

I

ITIME-OUT I

or beredict

= bgoal

I

beredict : _ forvard-llodel( s, ak, MEM)
3. If TIME-OUT then perform experimental action else perform ak.
4. Update MEM with (s, ak - bactual)

A nice feature of this method is the absence of a preliminary training phase such
as random flailing or feedback control. A variety of search techniques for numerical
inversion can be applied. Global random search avoids local minima but is very slow
for obtaining accurate actions, hill climbing is a robust local procedure and more
aggressive procedures such as Newton's method can use partial derivative estimates
from the forward model to make large second-order steps. The implementation used
for subsequent results had a combination of global search and local hill climbing.
In very high speed applications in which there is only time to make a small number
of forward model predictions, it is not difficult to regain much of the speed advantage
of directly using an inverse model by commencing the action search with ao as the
action predicted by a learned inverse model.

4

OTHER CONSIDERATIONS

Actions selected by a forward memory-based learner can be expected to converge
very quickly to the correct action in benign cases, and will not become stuck in difficult cases, provided that the memory based representation can fit the true forward

573

574

Moore

model. This proviso is weak compared with incremental learning control techniques
which typically require stronger prior assumptions about the environment, such as
near-linearity, or that an iterative function approximation procedure will avoid local
minima. One-shot methods have an advantage in terms of number of control cycles before adequate performance whereas incremental methods have the advantage
of only requiring trivial amounts of computation per cycle. However, the simple
memory-based formalism described so far suffers from two major problems which
some forms of adaptive and neural controllers may avoid .
? Brittle behaviour in the presence of outliers.
? Poor resistance to non-stationary environments.
Many incremental methods implicitly forget all experiences beyond a certain horizon. For example, in the delta rule ~Wij = lI(y~ctual - yrredict) X j, the age beyond
which experiences have a negligible effect is determined by the learning rate 1I. As
a result, the detrimental effect of misleading experiences is presen t for only a fixed
amount of time and then fades awayl . In contrast, memory-based methods remember everything for ever. Fortunately, two statistical techniques: robust regression
and cross-validation allow extensions to the numerical inversion method in which
we can have our cake and eat it too.

5

USING ROBUST REGRESSION

We can judge the quality of each experience (Xi, yd E Mem by how well it is
predicted by the rest of the experiences. A simple measure of the ith error is the
cross validation error, in which the experience is first removed from the memory
before prediction. efve =1 Predict(xi, Mem - {(Xi, Yin) I. With the memorybased formalism, in which all work takes place at prediction time, it is no more
expensive to predict a value with one datapoint removed than with it included.
Once we have the measure efve of the quality of each experience, we can decide
if it is worth keeping. Robust statistics [7] offers a wide range of methods: this
implementation uses the Median Absolute Deviation (MAD) procedure.

6

FULL CROSS VALIDATION

=

The value e~~ial L.: efve, summed over all "good" experiences, provides a measure
of how well the current representation fits the data. By optimizing this value with
respect to internal learner parameters, such as the width of the local weighting
function [(width used by kernel regression and LWR, the internal parameters can be
found automatically. Another important set of parameters that can be optimized is
the relative scaling of each input variable: an example of this procedure applied to a
two-joint arm task may be found in Reference [2]. A useful feature of this procedure
is its quick discovery (and subsequent ignoring) of irrelevant input variables.
Cross-validation can also be used to selectively forget old inaccurate experiences
caused by a slowly drifting or suddenly changing environment. We have already
seen that adaptive control algorithms such as the LMS rule can avoid such problems
because the effects of experiences decay with time. Memory based methods can also
forget things according to a forgetfulness parameter: all observations are weighted
IThis also has disadvantages: persistence of excitation is required and multiple tasks
can often require relearning if they have not been practised recently.

Fast, Robust Adaptive Control by Learning only Forward Models

by not only the distance to the
Wi

= exp( -(Xi -

Xquery

but also by their age:

Xquery)2 / Kwidth 2 -

(n - i)/ Krecau)

(1)

where we assume the ordering of the experiences' indices i is temporal, with experience n the most recent.
We find the K recall that minimizes the recen t weighted average cross validation error
L:?=o efve exp(
i)/,), where, is a human assigned 'meta-forgetfulness' constant, reflecting how many experiences the learner would need in order to benefit
from observation of an environmental change. It should be noted that, is a substantially less task dependent prescription of how far back to forget than would be
a human specified Krecall. Some initial tests of this technique are included among
the experiments of Section 8.

-en -

Architecture selection is another use of cross validation. Given a family of learners,
the member with the least cross validation error is used for subsequent predictions.

7

COMPUTATIONAL CONSIDERATIONS

Unless the real time between control cycles is longer than a few seconds, cross validation is too expensive to perform after every cycle. Instead it can be performed as
a separate parallel process, updating the best parameter values and removing outliers every few real control cycles. The usefulness of breaking a learning control task
into an online realtime processes and offline mental simulation was noted by [12].
Initially, the small number of experiences means that cross validation optimizes
the parameters very frequently, but the time between updates increases with the
memory size. The decreasing frequency of cross validation updates is little cause
for concern, because as time progresses, the estimated optimal parameter values are
expected to become decreasingly variable.
If there is no time to make more than one memory based query per cycle, then
memory based learning can nevertheless proceed by pushing even more of the computation into the offline component. If the offline process can identify meaningful
states relevant to the task, then it can compute, for each of them, what the optimal
action would be. The resulting state-action pairs are then used as a policy. The
online process then need only look up the recommended action in the policy, apply
it and then insert (s, a, b) into the memory.

8

COMPARATIVE TESTS

The ultimate goal of the investigation is to produce a learning control algorithm
which can learn to control a fairly wide family of different tasks. Some basic, very
different, tasks have been used for the initial tests.
The HARD task, graphed in Figure 1, is a one-dimensional direct relationship between
action and behaviour which is both non-monotonic and discontinuous. The VARIER
task (Figure 2) is a sinusoidal relation for which the phase continuously drifts, and
occasionally alters catastrophically.
LINEAR is a noisy linear relation between 4-d states, 4-d actions and 4-d behaviours.

For these first three tasks, the goal behaviour is selected randomly on each control
cycle. ARM (Figure 3) is a simulated noisy dynamic two-joint arm acting under
gravity in which state is perceived in cartesian coordinates and actions are produced

575

576

Moore

in joint-torque coordinates. Its task is to follow the circular trajectory. BILLIARDS is
a simulation of the real billiards robot described shortly in which 5% of experiences
are entirely random outliers.

-.-----------------,

.. ..

. ..

G1I ?

G1I ?

Goal Trajectory

~

~

o

o

J

J

01114"'.'.
Action

Figure 1: The HARD relation.

Figure 2: VARIER relation.

Figure 3: The ARM task.

The following learning methods were tested: nearest neighbour, kernel regression
and LWR, all searching the forward model and using a form of uncertainty-based intelligent experimentation [10] when the forward search proved inadequate. Another
method under test was sole use of the inverse, learned by LWR. Finally a "bestpossible" value was obtained by numerically inverting the real simulated forward
model instead of a learned model.
All tasks were run for only 200 control cycles. In each case the quality of the learner
was measured by the number of successful actions in the final hundred cycles, where
"successful" was defined as producing behaviour within a small tolerance of b goal .
Results are displayed in Table 1. There is little space to discuss them in detail,
but they generally support the arguments of the previous sections. The inverse
model on its own was generally inferior to the forward method, even in those cases
in which the inverse is well-defined. Outlier removal improved performance on
the BILLIARDS task over non-robustified versions. Interestingly, outlier removal
also greatly benefited the inverse only method. The selectively forgetful methods
performed better than than their non-forgetful counterparts on the VARIER task, but
in the stationary environments they did not pay a great penalty. Cross validation
for K width was useful: for the HARD task, LWR found a very small K width but in the
LINEAR task it unsurprisingly preferred an enormous Kwidth.
Some experiments were also performed with a real billiards robot shown in Figure 4.
Sensing is visual: one camera looks along the cue stick and the other looks down
at the table. The cue stick swivels around the cue ball, which starts each shot
at the same position. At the start of each attempt the object ball is placed at a
random position in the half of the table opposite the cue stick. The camera above
the table obtains the (x, y) image coordinates of the object ball, which constitute
the state. The action is the x-coordinate of the image of the object ball on the cue
stick camera. A motor swivels the cue stick until the centroid of the actual image
of the object ball coincides with the chosen x-coordinate value. The shot is then
performed and observed by the overhead camera. The behaviour is defined as the
cushion and position on the cushion with which the object ball first collides.

Fast, Robust Adaptive Control by Learning only Forward Models

Controller type. (K = use MAD
outlier removal, X
use crossvalidation for K width, R = use crossvalidation for K recall , IF
obtain

=

VARIER

HARD

LINEAR

ARM

BIL'DS

100 ?O

100 ?O

75 ? 3

94? 1

82 ? 4

15 ? 9
48 ? 16
14? 10
19? 9
22 ? 15
54? 8
56 ? 9
8?2
15 ? 8
22? 4
26 ? 10
44? 8
43 ? 8

24 ? 11
72? 8
11 ? 5
72? 4
51 ? 27
65 ?28
53 ? 17
6?2
42 ? 21
92? 2
69? 4
68? 3
66? 5

7?6
70 ? 4
58 ? 4
70 ? 4
73 ? 3
70 ? 5
73 ? 1
13 ? 3
14? 2
O?O
O?O
O?O
O?O

76 ? 28
89? 4
83 ? 4
89 ? 3
90? 3
89? 2
89? 1
3?2
23 ? 10
44? 6
40? 6
40? 7
37 ? 3

71 ? 5
70? 10
55? 12
61 ? 9
75 ? 7
69 ? 7
69? 7
1?1
30? 5
10 ? 2
9?3
11 ? 3
8?1

=

initial candidate action from the inverse model then search the forward
model.)
Best Possible: Obtamed from numerically inverting simulated world
Inverse only, learned WIth LWR
Inverse only, learned WIth LW R, KRX
LWR: IF
LWR: IF X
LWK: IF KX
LWK: IF KRX
L WK: r'orward only, KRX
Kernel KegresslOn: IF
Kernel RegreSSion: IF KRX
Nearest Neigh bour: IF
Nearest Nelghbour: IF K
Nearest Neigh bour: IF KR
Nearest Neighbour: Forward only,
KR

Global Lmear RegresslOn: IF
74? 5 60 ? 17
23 ? 6
8?3
7?3
Global Lmear RegresslOn: IF KR
20 ? 13
73 ? 4
9?2
72? 3
21 ? 4
Global Quadrattc RegresslOn: IF
14?7
5?3
64? 2 70 ? 22 40? 11
Table 1: Relative p erformance of a family o learners on a famil y of tasks. Each
combination of learner and task was run ten times to provide the mean number
of successes and standard deviation shown in the table.
The controller uses the memory based learner to choose the action to maximize the
probability that the ball will enter the nearer of the two pockets at the end of the
table. A histogram of the number of successes against trial number is shown in
Figure 5. In this experiment, the learner was LWR using outlier removal and cross
validation for [(width. After 100 experiences, control choice running on a Sun-4 was
taking 0.8 seconds 2 . Sinking the ball requires better than 1% accuracy in the choice
of action, the world contains discontinuities and there are random outliers in the
data and so it is encouraging that within less than 100 experiences the robot had
reached a 70% success rate--substantially better than the author can achieve.

ACKNOWLEDGEMENTS
Some of the work discussed in this paper is being performed in collaboration with Chris
Atkeson. The robot cue stick was designed and built by Wes Huang with help from Gerrit van Zyl. Dan Hill also helped considerably with the billiards robot. The author is
supported by a Postdoctoral Fellowship from SERC/NATO. Support was provided under Air Force Office of Scien tific Research gran t AFOSR-89-0500 and a National Science
Foundation Presidential Young Investigator Award to Christopher G. Atkeson.
2This could have been greatly improved with more appropriate hardware or better
software techniques such as kd-trees for structuring data [11, 9].

577

578

Moore

10
9

!

8

7

&"
r- 5

J ..

e::I 3

Z :z
1

o

o

1

:zo

40

60

80

100

Trial number (batches of 10)
Figure 4: The billiards robot. In the
foreground is the cue stick which attempts to sink balls in the far pockets.

Figure 5: Frequency of successes versus
con trol cycle for the billiards task.

References
[1] C. G. Atkeson. Using Local Models to Control Movement. In Proceedings of Neural
Information Processing Systems Conference, November 1989.
[2] C. G. Atkeson. Memory-Based Approaches to Approximating Continuous Functions.
Technical report, M. I. T. Artificial Intelligence Laboratory, 1990.
[3] C. G. Atkeson and D. J. Reinkensmeyer. Using Associative Content-Addressable
Memories to Control Robots. In Miller, Sutton, and Werbos, editors, Neural Networks
for Control. MIT Press, 1989.
[4] S. D. Conte and C. De Boor. Elementary Numerical Analysis. McGraw Hill, 1980.

[5] R. O. Duda and P. E. Hart. Pattern Classification and Scene Analysis. John Wiley
& Sons, 1973.

[6] R. Franke. Scattered Data Interpolation: Tests of Some Methods. Mathematics of
Computation, 38(157), January 1982.

[7] F. Hampbell, P. Rousseeuw, E. Ronchetti, and W. Stahel. Robust Statistics. Wiley
International, 1985.

[8] M. 1. Jordan and D. E. Rumelhart. Forward Models: Supervised Learning with a
Distal Teacher. Technical report, M. I. T., July 1990.
[9] A. W. Moore. Efficient Memory-based Learning for Robot Control. PhD. Thesis;
Technical Report No. 209, Computer Laboratory, University of Cambridge, October
1990.
[10] A. W. Moore. Knowledge of Knowledge and Intelligent Experimentation for Learning
Control. In Proceedings of the 1991 Seattle International Joint Conference on Neural
Networks, July 1991.
[11] S. M. Omohundro. Efficient Algorithms with Neural Network Behaviour. Journal of
Complex Systems, 1(2):273-347, 1987.
[12] R. S. Sutton. Integrated Architecture for Learning, Planning, and Reacting Based
on Approximating Dynamic Programming. In Proceedings of the 7th International
Conference on Machine Learning. Morgan Kaufman, June 1990.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 225-maximum-likelihood-competitive-learning.pdf

574

Nowlan

Maximum Likelihood Competitive Learning
Steven J. Nowlan 1
Department of Computer Science
University of Toronto
Toronto, Canada
M5S lA4

ABSTRACT
One popular class of unsupervised algorithms are competitive algorithms. In the traditional view of competition, only one competitor,
the winner, adapts for any given case. I propose to view competitive adaptation as attempting to fit a blend of simple probability
generators (such as gaussians) to a set of data-points. The maximum likelihood fit of a model of this type suggests a "softer" form
of competition, in which all competitors adapt in proportion to
the relative probability that the input came from each competitor.
I investigate one application of the soft competitive model, placement of radial basis function centers for function interpolation, and
show that the soft model can give better performance with little
additional computational cost.

1

INTRODUCTION

Interest in unsupervised learning has increased recently due to the application of
more sophisticated mathematical tools (Linsker, 1988; Plumbley and Fallside, 1988;
Sanger, 1989) and the success of several elegant simulations of large scale selforganization (Linsker, 1986; Kohonen, 1982). One popular class of unsupervised
algorithms are competitive algorithms, which have appeared as components in a
variety of systems (Von der Malsburg, 1973; Fukushima, 1975; Grossberg, 1978).
Generalizing the definition of Rumelhart and Zipser (1986), a competitive adaptive
system consists of a collection of modules which are structurally identical except,
possibly, for random initial parameter variation. A set of rules is defined which
allow the modules to compete in some way for the right to respond to some subset
lThe author is visiting the University of Toronto while completing a PhD at Carnegie Mellon
University.

Maximum Likelihood Competitive Learning

of the inputs. Typically a module is a single unit, but this need not be the case.
Often, parameter restrictions are used to prevent "uninteresting" representations in
which the entire set of input patterns are represented by one module.
Most of the work on competitive systems, especially within the neural network literature, has focused on a fairly extreme form of competition in which only the winner
of the competition for a particular case is updated. Variants on this theme are
the schemes in which, in addition to the winner, all of the losers are updated in
some uniform fashion 2 ? Within the statistical pattern recognition literature (Duda
and Hart, 1973; McLachlan and Basford, 1988) a rather different form of competition is frequently encountered. In this form, which will be referred to as "soft"
competition, all competitors are updated but the amount of update is proportional
to how well each competitor did in the competition for the current case. Under a
statistical model, this "soft" form of competition performs exact gradient descent
in likelihood, while the more traditional winner-take-all, or "hard" competition, is
an approximation to gradient descent in likelihood.
In this paper I demonstrate the superiority of "soft" competitive learning by comparing "hard" and "soft" algorithms in a classification application. The classification network consists of a layer of Radial Basis Functions (RBF's) followed by a
layer of linear units which attempt to find a least mean square (LMS) fit to the
desired output function (Broomhead and Lowe, 1988; Lee and Kill, 1988; Niranjan
and Fallside, 1988). A network of this type can form a smooth approximation to
an arbitrary function, with the RBF centers serving as control points for fitting
the function (Keeler and Kowalski, 1989; Poggio and Girosi, 1989). A competitive
learning component adjusts the centers of the RBF's in an unsupervised fashion,
before the weights to the output units are adapted. Comparisons of hard and soft
algorithms for placing the RBF's on a hand-drawn digit recognition problem and
a subset of a speaker independant vowel recognition problem suggest that the soft
algorithm is superior. Comparisons are also made with more traditional classifiers
on the same problems.

2

COMPETITIVE PLACEMENT OF RBF'S

Radial Basis Function networks have been shown to be quite effective for some tasks,
however a major limitation is that a very large number of RBF's may be required
in high dimensional spaces. One method for using RBF's places the centers of the
RBF's at the interstices of some coarse lattice defined over the input space (Broomhead and Lowe, 1988). If we assume the lattice is uniform with k divisions along
each dimension, and the dimensionality of the input space is d, a uniform lattice
would require k d RBF's. This exponential growth makes the use of such a uniform
lattice impractical for any high dimensional space. Another choice is to center the
RBF's on the first n training samples, but this method is subject to sampling error,
2The feature maps of Kohonen (1982) are actually a special case in which a few units are
adapted at once, however the units which are adapted in addition to the winner are selected by a
neighbourhood function rather than by how well they represent the current data.

575

576

Nowlan

and a very large number of samples can be required to adequately represent the
distribution of inputs. This is particularly true in high dimensional spaces where it
is extremely difficult to visualize the input distribution and determine whether the
training examples adequately represent this distribution.
Moody and Darken (1988) have suggested a method in which a much smaller number
of RBF's are used, however the centers of these RBF's are allowed to adapt to the
input samples, so they learn to represent only the part of the input space actually
represented by the data. The adaptive strategy also allows the center of each RBF
to be determined by a large number of training samples, greatly reducing sampling
error. In their method, an unsupervised algorithm (a version of k-means) is used
to select the centers of the RBF's and some ad hoc heuristics are suggested for
adjusting the size of the RBF's to get a smooth interpolator. The weights from the
hidden to the output layer are adapted to minimize a Least Mean Square (LMS)
criterion. Moody and Darken were able to attain performance levels equivalent to a
multi-layer Back Propagation network on a chaotic time series prediction task and
a vowel discrimination task. Significant savings in training time were also reported.
The k-means algorithm used by Moody and Darken can be easily reformulated as a
form of competitive adaptation. In the basic k-means algorithm (Duda and Hart,
1973) the training samples are first assigned to the class of the closest mean. The
means are then recomputed as the average of the samples in their class. This two
step process is repeated until the means stop changing. This is simply the "batch"
version of a competitive learning scheme in which the activity of each competing
unit is proportional to the distance between its weight vector and the current input
vector, and the winning unit on each case adapts by adding a portion of the current
input to its weight vector (with appropriate normalization).
We will now consider a statistical formalization of a competitive process for placing
the centers of RBF's. Let each competing unit represent a radially symmetric
(spherical) gaussian probability distribution, with the weight vector of the unit jIj
representing the center or mean of the gaussian. The probability that the gaussian
associated with unit j generated an input vector Xle is
_ )
1 P( Xle = - e

(~k -/I i )l
l ... ~

(1)

1

KUj

where K is a normalization constant, and the covariance matrix is

uJ f.

A collection of M such units is a model of the input distribution. The parameters
of these M gaussians can be adjusted so that the overall average likelihood of generating the training examples is maximized. The likelihood of generating a set of
observations {Xl, X2,"" xn} from the current model is

L=

II P(lle)

(2)

Ie

where P( lie) is the probability of generating observation lie under the current model.
(For mathematical convenience we usually work with log L.) If gaussian i is selected

Maximum Likelihood Competitive Learning

with probability 'lri and a sample is drawn from the selected gaussian, the probability
of observing xJ: is
N

P(xJ:)

=

L 'lri p.(iJ:)

(3)

;=1

where Pi(iJ:) is the probability of observing il: under gaussian distribution i. The
summation in (3) is awkward to work with, and frequently one of the p.(iJ:) is much
larger than any of the others. Therefore, a convenient approximation for (3) is
(4)

This is equivalent to assigning all of the responsibility for an observation to the
gaussian with the highest probability of generating that observation. This approximation is frequently referred to as the "winner-take-all" assumption. It may also be
regarded as a "hard" competitive decision among the gaussians. When we use (3)
directly, all of the gaussians share responsibility for each observation in proportion
to their probability of generating the observation. This sharing of responsibility can
be regarded as a "soft" competitive decision among the gaussians.
The maximum likelihood estimate for the mean of each gaussian in our model can
be found by evaluating Blog L/ BPj = O. We will consider a simple model in which
we assume that 'lrj and Uj are the same for all of the gaussians, and compare the
hard and soft estimates for ilj.
With the hard approximation, substituting (4) in (2), the maximum likelihood
estimate of ilj has the simple form
:.
I-'j

=

EJ:EC; xJ:
N.

(5)

1

where Cj is the set of cases closest to gaussian j, and Nj is the size of this set. This
is identical to the expression for Pj in the k-means algorithm.
Rather than using the approximation in (4) we can find the exact maximum likelihood estimates for ilj by substituting (3) in (2). The estimate for the mean is
now
(6)

where pOlxJ:) is the probability, given that we have observed ?1:, of gaussian j
having generated XI:. For the simple model used here

Comparing (6) and (5), the hard competitive model uses the average of the cases
unit j is closest to in recomputing its mean, while the soft competitive model uses
the average of all the cases weighted by p(jlil:).

577

578

Nowlan

We can use either the approximate or exact likelihood algorithm to position the
RBF's in an interpolation network. If X" is the current input, each RBF unit
computes Pj(x,,) as its output activation aj. For the hard competitive model, a
winner-take-all operation then sets aj = 1 for the most active unit and ai = 0
for all other units. Only the winning unit will update its mean vector, and for
this update we use the iterative version of (5). In the soft competitive model we
normalize each aj by dividing it by the sum of aJ over all RBF's. In this case the
mean vectors of all of the hidden units are updated according to the iterative version
of (6). The computational cost difference between the winner-take-all operation in
the hard model and the normalization in the soft model is negligible; however, if the
algorithms are implemented sequentially, the soft model requires more computation
because all of the means, rather than just the mean of the winner, are updated for
each case.
The two models described in this section are easily extended to allow each spherical gaussian to have a different variance O'J. The activation of each RBF unit is
now a function of (ik - j1J)/O'j, but the expressions for the maximum likelihood
estimates of iIj are the same. Expressions for updating O'J can be found by solvO. Some simulations have also been performed with a network
ing 810gL/8O'J
in which each RBF had a diagonal covariance matrix, and each of the d variance
components was estimated separately (Nowlan, 1990).

=

3

APPLICATION TO TWO CLASSIFICATION TASKS

The architecture described above was used for a digit classification and a vowel
discrimination task. The networks were trained by first using the soft or hard
competitive algorithm to determine the means and variances of the RBF's, and,
once these were learned, then training the output layer of weights. The weights
from the RBF's to the output layer were trained using a recursive least squares
algorithm, allowing an exact LMS solution to be found with one pass through the
training set. (A target of +1 was used for the correct output category and -1
for all of the other categories.) For the hard competitive model the unnormalized
probabilities Pj (x) were used as the RBF unit outputs, while the soft competitive
model used the normalized probabilities pUli).
The first task required the classification of a set of hand drawn digits from 12
subjects. There were 480 input patterns, divided into 320 training patterns and
160 testing patterns, with examples from all subjects in both groups. Each pattern
was digitized on a 16 by 16 grid. These 256 dimensional binary vectors were used
as input to the classification network, and there were 10 output units.
Networks with 40 and 150 spherical gaussians were simulated. Both hard and soft
algorithms were used with all configurations. The performance of these networks
on the testing set is summarized in Table 1. This table also contains performance
results for a multi-layer back propagation network, a two layer linear network, and
a nearest neighbour classifier on the same task. The nearest neighbour classifier
used all 320 labeled training samples and based its decision on the class of the

Maximum Likelihood Competitive Learning

Type of Classifier
40 Sph. Gauss. - Hard
40 Sph. Gauss. - Soft
150 Sph. Gauss. - Hard
150 Sph. Gauss. - Soft
Layered BP Net
Linear Net
Nearest Neighbour

% Correct on Test Set
87.6%
91.8%
90.1%
94.0%
94.5%
60.0%
83.1%

Table 1: Summary of Performance for Digit Classification
nearest neighbour only3. The relatively poor performance of the nearest neighbour
classifier is one indication of the difficulty of this task. The two layer linear network
was trained with a recursive least squares algorithm4. The back propagation network was developed specifically for this task (Ie Cun, 1987), and used a specialized
architecture with three layers of hidden units, localized receptive fields, and weight
sharing to reduce the number of free parameters in the system.
Table 1 reveals that the networks were trained using the soft competitive algorithm
to determine means and variances of the RBF's were superior in performance to
identical networks trained with the hard competitive algorithm. The RBF network
using 150 spherical gaussians was able to equal the performance level of the sophisticated back propagation network, and a network with 40 spherical RBF's performed
considerably better than the nearest neighbour classifier.
The second task was a speaker independent vowel recognition task. The data consisted of a digitized version of the first and second formant frequencies of 10 vowels
for multiple male and female speakers (Peterson and Barney, 1952). Moody and
Darken (1988) have previously applied to this data an architecture which is very
similar to the one suggested here, and Huang and Lippmann (1988) have compared
the performance of a number of different classifiers on this same data. More recently, Bridle (1989) has applied a supervised algorithm which uses a "softmax"
output function to this data. This softmax function is very similar to the equation for P(j\Zk) used in the soft competitive model. The results from these studies
are included in Table 2 along with the results for RBF networks using both hard
and soft competition to determine the RBF parameters. All of the classifiers were
trained on a set of 338 examples and tested on a separate set of 333 examples.
As with the digit classification task, the RBF networks trained using the soft adaptive procedure show uniformly better performance than equivalent networks trained
using the hard adaptive procedure. The results obtained for the hard adaptive pro3Two, three, and five nearest neighbour classifiers were also tried, but they all perfonned worse
than nearest neighbour.
fThis network was included to show that the linear layer is not doing all of the work in the
hybrid RBF networks.

579

580

Nowlan
Type of Classifier
20 Sph. Gauss. - Hard
20 Sph. Gauss. - Soft
100 Sph. Gauss. - Hard
100 Sph. Gauss. - Soft
20 RBF's (Moody et al)
100 RBF's (Moody et al)
K Nearest Neighbours (Lippmann et al)
Gaussian Classifier (Lippmann et al)
2 Layer BP Net (Lippmann et al)
Feature Map (Lippmann et al)
2 Layer Softmax (Bridle)

% Correct on Test Set
75.1%
82.6%
82.6%
87.1%
73.3%
82.0%
82.0%
79.7%
80.2%
77.2%
78.0%

Table 2: Summary of Performance for Vowel Classification
cedure with 20 and 100 spherical gaussians are very close to Moody and Darken's
results, which is expected since the procedures are identical except for the manner
in which the variances are obtained. Table 2 also reveals that the RBF network
with 100 spherical gaussians, trained with the soft adaptive procedure, performed
better than any of the other classifiers that have been applied to this data.

4

DISCUSSION

The simulations reported in the previous section provide strong evidence that the
exact maximum likelihood (or soft) approach to determining the centers and sizes of
RBF's leads to better classification performance than the winner-take-all approximation. In both tasks, for a variety of numbers of RBF's, the exact maximum
likelihood approach outperformed the approximate method. Comparing (5) and
(6) reveals that this improved performance can be obtained with little additional
computational burden.
The performance of the RBF networks on these two classification tasks also shows
that hybrid approaches which combine unsupervised and supervised procedures are
capable of competent levels of performance on difficult problems. In the digit classification task the hybrid RBF network was able to equal the performance level of
a sophisticated multi-layer supervised network, while in the vowel recognition task
the hybrid network obtained the best performance level of any of the classification
networks. One reason why the hybrid model is interesting is that since the hidden unit representation is independent of the classification task, it may be used
for many different tasks without interference between the tasks. (This is actually
demonstrated in the simulations described, since each category in the two tasks can
be regarded as a separate classification problem.) Even if we are only interested in
using the network for one task, there are still advantages to the hybrid approach.
In many domains, such as speech, unlabeled samples can be obtained much more

Maximum Likelihood Competitive Learning

cheaply than labeled samples. To avoid over-fitting, the amount of training data
must generally be considerably greater than the number of free parameters in the
model. In the hybrid models, especially in high dimensional input spaces, most of
the parameters are in the unsupervised part of the modelS. The unsupervised stage
may be trained with a large body of unlabeled samples, and a much smaller body
of labeled samples can be used to train the output layer.
The performance on the digit classification task also shows that RBF networks can
deal effectively with tasks with high (256) dimensional input spaces and highly
non-gaussian input distributions. The competitive network was able to succeed on
this task with a relatively small number of RBF's because the data was actually
distributed over a much lower dimensional subspace of the input space. The soft
competitive network automatically concentrates its representation on this subspace,
and in this fashion performs a type of implicit dimensionality reduction. Moody
(1989) has also mentioned this type of dimensionality reduction as a factor in the
success of some of the models he has worked with.
The success of the soft adaptive strategy in these interpolation networks encourages
one to extend the soft interpretation in other directions. The feature maps of
Kohonen (1982) incorporate a hard competitive process, and a soft version of the
feature map algorithm could be developed. In addition, there is a class of decisiondirected, or "bootstrap" , learning algorithms which use their own outputs to provide
a training signal. These algorithms can be regarded as hard competitive processes,
and new algorithms which use the soft assumption may be developed from the
bootstrap procedure (Nowlan and Hinton, 1989). Bridle (1989) has suggested a
different type of output unit for supervised networks, which incorporates the idea
of a "soft max" type of competition. Finally, the maximum likelihood approach is
easily extended to non-gaussian models, and one model of particular interest would
be the Boltzmann machine.
Acknowledgements
I would like to thank Richard Lippmann of Lincoln Laboratories and John Moody of Yale University for making the vowel formant data available to me. I would also like to thank Geoff Hinton,
and the members of the Connectionist Research Group of the University of Toronto, for many
helpful comments and suggestions while conducting this research and preparing this paper.

References
Bridle, J. (1989). Probabilistic interpretation of feedforward classification network outputs, with
relationships to statistical pattern recognition. In Fougelman-Soulie, F . and Herault, J.,
editors, Neuro-computing: algorithm!, architecture! and application!. Springer-Verlag.
Broomhead, D. and Lowe, D. (1988). Multivanable functional interpolation and adaptive networks.
Complex Sy!tem&, 2:321-355.
Duda, R. and Hart, P. (1913). Pattern Clauijication And Scene Analy&i&. Wiley and Son.
Fukushima, K. (1915). Cognitron: A self-organizing multilayered neural network.
Cybernetic!, 20:121-136.

Biological

Sin the digit task, there are over 25 times as many parameters in the unsupervised part of the
network as there are in the supervised part.

581

582

Nowlan
Grossberg, S. (1978). A theory of visual coding, memory, and development. In Formal theorie$ oj
'IIi!.al perception. John Wiley and SOIUl, New York.
Huang, W. and Lippmann, R. (1988). Neural net and traditional classifiers. In Anderson, D.,
editor, Ne.ra.lInJormation Proceuing S1J!tem!. American lnatitute of Physics.
Keeler, E. H. J. and Kowalski, J. (1989). Layered neural networks with gaussian hidden units as
universal approximators. MCC Technical Report ACT-ST-272-89, MCC.
Kohonen, T. (1982). Self-organized formation of topologically correct feature maps. Biological
Cybernetic!, 43:59-69.
Ie Cun, Y. (1987). Modele! Connexionni!te$ de l'Apprentiuage. PhD thesis,
Marie Curie, Paris, France.

Universit~

Pierre et

Lee, S. and Kill, R. (1988). Multilayer feedfo.,ward potential function networks. In Proceeding!
IEEE Second International ConJerence on Ne.ral Network!, page 1:161, San Diego, Califorma.
Linsker, R. (1986). From basic network principles to neural architecture: Emergence of spatial
opponent cells. Proceeding! oj the Nationa.l Academ1J oj Science! USA, 83:7508-7512.
Linsker, R. (1988). Self-organization in a perceptual network. IEEE Computer Society, pages
105-117.
McLachlan, G. and Basford, K. (1988). Mixture Model!: InJerence and Application! to Clu!tering.
Marcel Dekker, New York.
Moody,

J. (1989).

Fast learning in multi-resolution hierarchies.
Yale University.

Technical Report

YALEU/DCS/R~681,

Moody, J. and Darken, C. (1988). Learning with localized receptive fields. In D. Touretzky,
G. Hinton, T. S., editor, Proceeding. oj the 1988 Connectioni!t Model! Summer School,
pages 133-143. Morgan Kauffman.
Niranjan, M. and Fallside, F. (1988). Neural networks and radial basis functions in classifying static
speech patterIUI. Technical Report CUEDIF-INFENGI7R22, Engineering Dept., Cambridge
University. to appear in Computers Speech and Language.
Nowlan, S. (1990). Maximum likelihood competition in RBF networks. Technical Report CRGT~90-2, University of Toronto Connectionist Research Group.
Nowlan, S. and Hinton, G. (1989). Maximum likelihood decision-directed adaptive equalization.
Technical Report CRG-TR-89-8, University of Toronto Connectionist Research Group.
Peterson, G. and Barney, H. (1952). Control methods used in a study of vowels. The Journal oj
the Acou!tical Society oj America, 24:175-184.
Plumbley, M. and Fallside, F. (1988). An information theoretic approach to unsupervised connectionist models. In D. Touretzky, G Hinton, T. S., editor, Proceeding! oj the 1988 Connec.
tioni$t Model! Summer School, pages 239-245. Morgan Kauffmann.
Poggio, G. and Girosi, F. (1989). A theory of networks for approximation and learning. A.I. Memo
1140, MIT.
Rumelhart, D. E. and Zipser, D. (1986). Feature discovery by competitive learning. In Parallel
di6trib.ted proceuing: Exploration. in the micro!tructure of cognition, volume I. Bradford
Books, Cambridge, MA.
Sanger, T. (1989). An optimality principle for unsupervised learning. In Touretzky, D., editor,
Advance! in Neural InJormation Proceuing Sy!tem$ 1, pages 11-19. Morgan Kauffman.
Von der Malsburg, C. (1973). Self-organization of orientation sensitive cells in striate cortex.
K ybernetik, 14:85-100.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1357-the-canonical-distortion-measure-in-feature-space-and-1-nn-classification.pdf

The Canonical Distortion Measure in Feature
Space and I-NN Classification

Jonathan Baxter*and Peter Bartlett
Department of Systems Engineering
Australian National University
Canberra 0200, Australia
{jon,bartlett}@syseng.anu.edu.au

Abstract
We prove that the Canonical Distortion Measure (CDM) [2, 3] is the
optimal distance measure to use for I nearest-neighbour (l-NN) classification, and show that it reduces to squared Euclidean distance in feature
space for function classes that can be expressed as linear combinations
of a fixed set of features. PAC-like bounds are given on the samplecomplexity required to learn the CDM. An experiment is presented in
which a neural network CDM was learnt for a Japanese OCR environment and then used to do I-NN classification.

1 INTRODUCTION
Let X be an input space, P a distribution on X, F a class of functions mapping X into Y
(called the "environment"), Q a distribution on F and (J' a function (J': Y X Y -t [0 , ."1].
The Canonical Distortion Measure (CDM) between two inputs x, Xl is defined to be:

p(x, Xl) =

L

(J'(f(x) , f(x l )) dQ(f).

(1)

Throughout this paper we will be considering real-valued functions and squared loss, so
Y = ~ and (J'(y, yl) := (y - yl)2. The CDM was introduced in [2, 3], where it was
analysed primarily from a vector quantization perspective. In particular, the CDM was
proved to be the optimal distortion measure to use in vector quantization, in the sense of
producing the best approximations to the functions in the environment F. In [3] some
experimental results were also presented (in a toy domain) showing how the CDM may be
learnt.
The purpose of this paper is to investigate the utility of the CDM as a classification tool.
In Section 2 we show how the CDM for a class of functions possessing a common feature
*The first author was supported in part by EPSRC grants #K70366 and #K70373

1. Baxter and P. Bartlett

246

set reduces, via a change of variables, to squared Euclidean distance in feature space. A
lemma is then given showing that the CDM is the optimal distance measure to use for 1nearest-neighbour (l-NN) classification. Thus, for functions possessing a common feature
set, optimall-NN classification is achieved by using squared Euclidean distance in feature
space.
In general the CDM will be unknown, so in Section 4 we present a technique for learning
the CDM by minimizing squared loss, and give PAC-like bounds on the sample-size required for good generalisation. In Section 5 we present some experimental results in which
a set of features was learnt for a machine-printed Japanese OCR environment, and then
squared Euclidean distance was used to do I-NN classification in feature space. The experiments provide strong empirical support for the theoretical results in a difficult real-world
application.

2 THE CDM IN FEATURE SPACE

f

E F can be expressed as a linear combination of a fixed set of features
~ := (?l, ... , ?k). That is, for all f E F, there exists w := (WI,???, Wk) such that

Suppose each

w . ~ = 2:7=1 Wi?i. In this case the distribution Q over the environment F is a
distribution over the weight vectors w. Measuring the distance between function values by
()(y, y') := (y - yl)2, the CDM (1) becomes:

f =

p(x, x')

=

r

iE.k

[w? ~(x) - w?

~(X,)]2

dQ(w)

= (~(x) - ~(X'))W(~(x) - ~(X'))'
(2)

where W =

fw w'w dQ(w).

is a k x k matrix. Making the change of variable ~ -t

~JW, we have p(x, x') = 11~(x) - ~(x')112 . Thus, the assumption that the functions in
the environment can be expressed as linear combinations of a fixed set of features means
that the CDM is simply squared Euclidean distance in a feature space related to the original
by a linear transformation.

3

I-NN CLASSIFICATION AND THE CDM

Suppose the environment F consists of classifiers, i.e. {O, 1}-valued functions. Let f be
some function in F and z := (Xl, f(Xl)), ... , (Xn, f(x n )) a training set of examples of
f. In I-NN classification the classification of a novel x is computed by f(x*) where X* =
argmin x ? d(x, Xi)), i.e. the classification of X is the classification of the nearest training
point to x under some distance measure d. If both f and x are chosen at random, the
expected misclassification error of the 1-NN scheme using d and the training points x :=

(xl, ... ,xn)is
er(x, d) := EF Ex [J(x) - f(x* )]2 ,

(3)

where x* is the nearest neighbour to x from {Xl, . . . , x n }. The following lemma is now
immediate from the definitions.

Lemma 1. For all sequences x

= (Xl, . .. , X n ). er{x, d) is minimized ifd is the CDM p.

Remarks. Lemma 1 combined with the results of the last section shows that for function
classes possessing a common feature set, optimall-NN classification is achieved by using
squared Euclidean distance in feature space. In Section 5 some experimental results on
Japanese OCR are presented supporting this conclusion.
The property of optimality of the CDM for I-NN classification may not be stable to small
perturbations. That is, if we learn an approximationg to p, then even ifE xxx (g(x, x') -

The Canonical Distortion Measure in Feature Space and I-NN Classification

247

p(x, x ' ))2 is small it may not be the case that l-NN classification using 9 is also small.
However, one can show that stability is maintained for classifier environments in which
positive examples of different functions do not overlap significantly (as is the case for the
Japanese OCR environment of Section 5, face recognition environments, speech recognition environments and so on). We are currently investigating the general conditions under
which stability is maintained.

4

LEARNING THE CDM

For most environments encountered in practice (e.g speech recognition or image recognition), P will be unknown. In this section it is shown how p may be estimated or learnt using
function approximation techniques (e.g. feedforward neural networks).

4.1

SAMPLING THE ENVIRONMENT

To learn the CDM p, the learner is provided with a class of functions (e.g. neural networks)
~ [0, M]. The goal of the learner is to find a 9 such
that the error between 9 and the CDM p is small. For the sake of argument this error will
be measured by the expected squared loss:

9 where each 9 E 9 maps X x X

erp(g) := Exxx [g(x, x') - p(x, x')f ,

(4)

where the expectation is with respect to p2.
Ordinarily the learner would be provided with training data in the form (x, x', p( x, x'})
and would use this data to minimize an empirical version of (4). However, p is unknown
so to generate data of this form p must be estimated for each training pair x, x'. Hence to
generate training sets for learning the CDM, both the distribution Q over the environment
:F and the distribution P over the input space X must be sampled. So let f := (it, ... , f m)
be m i.i.d. samples from :F according to Q and let x := (Xl, ... , x n ) be n i.i.d. samples
from X according to P. For any pair Xi, Xj an estimate of p( Xi, Xj) is given by
1

P(Xi' Xj} :=

m

m

~ (J'(fdxd,fk(Xj )).

(5)

k=l

This gives n (n - 1) /2 training triples,

{(xi,Xj,p(xi,xj)),l::; i

< j::; n} ,

which can be used as data to generate an empirical estimate of er p (g):
(6)

Only n(n - 1)/2 of the possible n 2 training triples are used because the functions 9 E 9
are assumed to already be symmetric and to satisfy 9 (x, x) = 0 for all x (if this is not
the case then set g'(X, x') := (g(x, x') + g(x', x))/2 if x =j:. x' and g'(X, x) = 0 and use
g' := {g': 9 E g} instead).
In [3] an experiment was presented in which 9 was a neural network class and (6) was
minimized directly by gradient descent. In Section 5 we present an alternative technique
in which a set of features is first learnt for the environment and then an estimate of p in
feature space is constructed explicitly.

J. Baxter and P. Bartlett

248

4.2

UNIFORM CONVERGENCE

We wish to ensure good generalisation from a 9 minimizing
small 6, 5),
Pr { x, r :

:~~ lerx,f(g) -

I

erp(g) >

e~r

r,

x,

6} <

in the sense that (for

5,

The following theorem shows that this occurs if both the number of functions m and the
number of input samples n are sufficiently large. Some exotic (but nonetheless benign)
measurability restrictions have been ignored in the statement of the theorem. In the statement of the theorem, N (E , 9) denotes the smallest 6-cover of 9 under the L 1 ( P 2 ) norm,
where {gl , . . . , gN} is an 6-cover of9 iffor all 9 E 9 there exists gi such that Ilgi - gil ~ 6.
Theorem 2. Assume the range of the functions in the environment :F is no more than
B /2, B /2) and in the class 9 (used to approximate the CDM) is no more than
[0 , VB). For all 6 > 0 and 0 < 5 ~ 1. if
32B 4
4
m> --log(7)
62
5
and
512B 2 (
512B 2
8)
(8)
n 2: 6 2
logN(6,9) + log 6 2 + log;5

[- J

J

then
(9)

Proof For each 9 E 9 , define

erx(g) := (2 )
nn-1
If for any x

= (Xl, . . . , X n ),

(10)
l~i<j~n

~}
~ ~2 ,
2

(II)

> ~} ~ ~ ,

(12)

Pr {r: sup ler r(g) - erx(g) I >
gE9

and
Pr

{x:

x,

sup lerx(g) - erp(g)1
gE9

2

2

then by the triangle inequality (9) will hold. We treat (11) and (12) separately.

Equation (11). To simplify the notation let gij , Pij and Pij denote 9 (Xi, Xj), p( Xi, Xj) and
p(Xi' Xj) respectively. Now,

L

(g ij - pij )2 -

l~i<j~n

2
n(n - 1)

4B
- n(n - 1)

< -,----:-

2:

(Pij - Pij) (2g ij - Pij - Pij)

(Pij - Pij)

19<j~n

1

E.rx(J) -

m

m

2: X(Jk)
k=l

(gij - Pij)2

19<j~n

l~i<j~n

L

2:

249

The Canonical Distortion Measure in Feature Space and J-NN Classification

where x: :F -+ [0, 4B2] is defined by

4B
n(n - 1)

x (f) := ----,-----

Thus,

Pr

{f: :~g I"r.,f(g) - e-r.(g) I >

1 :Si<J:S n

n

S Pr

{f

EJ'x(f) -

~

t,

xU,) >

~}

which is ~ 2 exp (_m?2/ (32B4)) by Hoeffding's inequality. Setting this less than 6/2
gives the bound on m in theorem 2.

Equation (12). Without loss of generality, suppose that n is even. The trick here is to split
the sum over all pairs (Xi, Xj) (with i < j) appearing in the definition of er x (g) into a
double sum:
~
2
erx(g)
[g(Xj, Xj) - p(Xi, Xj)]2
nn-1
6

= (

)"

1 ::;i<j:S n

1

n-1

= n_ 1

2

n /2

L ;; L
i=l

2

[g(xo ,U), xO:(j)) - p(xo.(j), xO:(j))]

,

j=l

where for each i = 1, ... , n - 1, (J"i and (J"~ are permutations on {I, ... , n} such that
{(J"d 1) , ... , (J"i (n/2)) n {(J"H 1), ... , (J"~( n/2)} is empty. That there exist permutations with
this property such that the sum can be broken up in this way can be proven easily by induction. Now, conditional on each (J"i, the n/2 pairs Xi := {(Xo.(j), xO:(j)), j = 1, ... , n/2}
are an i.i.d. sample from X x X according to p2. So by standard results from real-valued
function learning with squared loss [4]:
Pr {

;;?=
2

Xi:

su P
gEQ

n/2

[g(XO.(j), Xo:u)) - p(xo.U). XO:(j))]2 - erp(g)

>~

}

J=l

~ 4N (48~2 ' g) exp ( - 2;:~2 ).
Hence, by the union bound,
Pr { x:

~~g /erx(g) -

erp(g) I >

~} ~ 4(n -

l)N

(48~2 ' g) exp ( - 2;:~2

Setting n as in the statement of the theorem ensures this is less than 6/2.

).
D

Remark. The bound on m (the number of functions that need to be sampled from the
environment) is independent of the complexity of the class g. This should be contrasted
with related bias learning (or equivalently, learning to learn) results [1] in which the number
of functions does depend on the complexity. The heuristic explanation for this is that here
we are only learning a distance function on the input space (the CDM), whereas in bias
learning we are learning an entire hypothesis space that is appropriate for the environment.
However, we shall see in the next section how for certain classes of problems the CDM can
also be used to learn the functions in the environment. Hence in these cases learning the
CDM is a more effective method of learning to learn.

5

EXPERIMENT: JAPANESE OCR

To verify the optimality of the CDM for I-NN classification, and also to show how
it can be learnt in a non-trivial domain (only a toy example was given in [3]), the

1. Baxter and P Bartlett

250

COM was learnt for a Japanese OCR environment. Specifically, there were 3018 functions I in the environment F, each one a classifier for a different Kanji character. A
database containing 90,918 segmented, machine-printed Kanji characters scanned from
various sources was purchased from the CEDAR group at the State University of New
York, Buffalo The quality of the images ranged from clean to very degraded (see
http://www . cedar .buffalo. edu/Databases/JOcR/).
The main reason for choosing Japanese OCR rather than English OCR as a test-bed was
the large number of distinct characters in Japanese. Recall from Theorem 2 that to get good
generalisation from a learnt COM, sufficiently many functions must be sampled from the
environment. If the environment just consisted of English characters then it is likely that
"sufficiently many" characters would mean all characters, and so it would be impossible to
test the learnt COM on novel characters not seen in training.
Instead of learning the COM directly by minimizing (6), it was learnt implicitly by first
learning a set of neural network features for the functions in the environment. The features
were learnt using the method outlined in [1], which essentially involves learning a set of
classifiers with a common final hidden layer. The features were learnt on 400 out of the
3000 classifiers in the environment, using 90% of the data in training and 10% in testing.
Each resulting classifier was a linear combination of the neural network features. The
average error of the classifiers was 2.85% on the test set (which is an accurate estimate as
there were 9092 test examples).
Recall from Section 2 that if all f E F can be expressed as I = W . 4> for a fixed feature
set 4>, then the COM reduces to p{x, x') = (4)(x) - 4>(x ' ))W(4>{x) - 4>(X I ) ) ' where
W =
w/w dQ(w). The result of the learning procedure above is a set of features
ci> and 400 weight vectors w l, . . . , W 400, such that for each of the character classifiers fi
used in training, Ii :: Wi . ci>. Thus, g(x, x') := (ci>(x) - ci>(X'))W(ci>(x) - 4>(X'))' is
an empirical estimate of the true CDM, where W := L;~~ W:Wi. With a linear change
of variable ci> -+ ci>VW, 9 becomes g(x, x') = 114>(x) - ci>(x')112. This 9 was used to do
I-NN classification on the test examples in two different experiments.

fw

In the first experiment, all testing and training examples that were not an example of one
of the 400 training characters were lumped into an extra category for the purpose of classification. All test examples were then given the label of their nearest neighbour in the
training set under 9 (i.e. , initially all training examples were mapped into feature space
to give {ci>( Xl)' ... , ci>( X n )}. Then each test example was mapped into feature space and
assigned the same label as argminx.llci>( x) - ci>( Xi) 11 2 ).The total misclassification error was
2.2%, which can be directly compared with the misclassification error of the original classifiers of 2.85%. The COM does better because it uses the training data explicitly and the
information stored in the network to make a comparison, whereas the classifiers only use
the information in the network. The learnt COM was also used to do k-NN classification
with k > 1. However this afforded no improvement. For example, the error of the 3-NN
classifier was 2.54% and the error of the 20-NN classifier was 3.99%. This provides an
indication that the COM may not be the optimal distortion measure to use if k- NN classification (k > 1) is the aim.
In the second experiment 9 was again used to do I-NN classification on the test set, but
this time all 3018 characters were distinguished. So in this case the learnt COM was being
asked to distinguish between 2618 characters that were treated as a single character when
it was being trained. The misclassification error was a surprisingly low 7.5%. The 7.5%
error compares favourably with the 4.8% error achieved on the same data by the CEDAR
group, using a carefully selected feature set and a hand-tailored nearest-neighbour routine
[5]. In our case the distance measure was learnt from raw-data input, and has not been the
subject of any optimization or tweaking.

The Canonical Distortion Measure in Feature Space and I-NN Classification

251

Figure 1: Six Kanji characters (first character in each row) and examples of their four
nearest neighbours (remaining four characters in each row).

As a final, more qualitative assessment, the learnt CDM was used to compute the distance between every pair of testing examples, and then the distance between each pair of
characters (an individual character being represented by a number of testing examples)
was computed by averaging the distances between their constituent examples. The nearest neighbours of each character were then calculated. With this measure, every character
turned out to be its own nearest neighbour, and in many cases the next-nearest neighbours
bore a strong subjective similarity to the original. Some representative examples are shown
in Figure 1.

6

CONCLUSION

We have shown how the Canonical Distortion Measure (CDM) is the optimal distortion
measure for I-NN classification, and that for environments in which all the functions can
be expressed as a linear combination of a fixed set of features, the Canonical Distortion
Measure is squared Euclidean distance in feature space. A technique for learning the CDM
was presented and PAC-like bounds on the sample complexity required for good generalisation were proved.
Experimental results were presented in which the CDM for a Japanese OCR environment
was learnt by first learning a common set of features for a subset of the character classifiers
in the environment. The learnt CDM was then used as a distance measure in I-NN neighbour classification, and performed remarkably well, both on the characters used to train it
and on entirely novel characters.

References
[1] Jonathan Baxter. Learning Internal Representations. In Proceedings of the Eighth
International Conference on Computational Learning Theory, pages 311-320. ACM
Press, 1995.
[2] Jonathan Baxter. The Canonical Metric for Vector Quantisation. Technical Report
NeuroColt Technical Report 047, Royal Holloway College, University of London, July
1995.
[3] Jonathan Baxter. The Canonical Distortion Measure for Vector Quantization and Function Approximation. In Proceedings of the Fourteenth International Conference on
Machine Learning, July 1997. To Appear.
[4] W S Lee, P L Bartlett, and R C Williamson. Efficient agnostic learning of neural
networks with bounded fan-in. IEEE Transactions on Information Theory, 1997.
[5] S.N. Srihari, T. Hong, and Z. Shi. Cherry Blossom: A System for Reading Unconstrained Handwritten Page Images. In Symposium on Document Image Understanding
Technology (SDIUT), 1997.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 6387-cliquecnn-deep-unsupervised-exemplar-learning.pdf

CliqueCNN: Deep Unsupervised Exemplar Learning

Miguel A. Bautista? , Artsiom Sanakoyeu? , Ekaterina Sutter, Bj?rn Ommer
Heidelberg Collaboratory for Image Processing
IWR, Heidelberg University, Germany
firstname.lastname@iwr.uni-heidelberg.de

Abstract
Exemplar learning is a powerful paradigm for discovering visual similarities in
an unsupervised manner. In this context, however, the recent breakthrough in
deep learning could not yet unfold its full potential. With only a single positive
sample, a great imbalance between one positive and many negatives, and unreliable
relationships between most samples, training of Convolutional Neural networks is
impaired. Given weak estimates of local distance we propose a single optimization
problem to extract batches of samples with mutually consistent relations. Conflicting relations are distributed over different batches and similar samples are grouped
into compact cliques. Learning exemplar similarities is framed as a sequence of
clique categorization tasks. The CNN then consolidates transitivity relations within
and between cliques and learns a single representation for all samples without
the need for labels. The proposed unsupervised approach has shown competitive
performance on detailed posture analysis and object classification.

1

Introduction

Visual similarity learning is the foundation for numerous computer vision subtasks ranging from
low-level image processing to high-level object recognition or posture analysis. A common paradigm
has been category-level recognition, where categories and the similarities of all their instances
to other classes are jointly modeled. However, large intra-class variability has recently spurred
exemplar methods [15, 11], which split this problem into simpler sub-tasks. Therefore, separate
exemplar classifiers are trained by learning the similarities of individual exemplars against a large
set of negatives. The exemplar paradigm has been successfully employed in diverse areas such as
segmentation [11], grouping [10], instance retrieval [2, 19], and object recognition [15, 5]. Learning
similarities is also of particular importance for posture analysis [8] and video parsing [17].
Among the many approaches for similarity learning, supervised techniques have been particularly
popular in the vision community, leading to the formulation as a ranking [23], regression [6], and
classification [17] task. With the recent advances of convolutional neural networks (CNN), two-stream
architectures [25] and ranking losses [21] have shown great improvements. However, to achieve their
performance gain, CNN architectures require millions of samples of supervised training data or at
least the fine-tuning [3] on large datasets such as PASCAL VOC. Although the amount of accessible
image data is increasing at an enormous rate, supervised labeling of similarities is very costly. In
addition, not only similarities between images are important, but especially between objects and their
parts. Annotating the fine-grained similarities between all these entities is hopelessly complex, in
particular for the large datasets typically used for training CNNs.
Unsupervised deep learning of similarities that does not requiring any labels for pre-training or
fine-tuning is, therefore, of great interest to the vision community. This way we can utilize large
image datasets without being limited by the need for costly manual annotations. However, CNNs for
?

Both authors contributed equally

30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.

exemplar-based learning have been rare [4] due to limitations resulting from the widely used softmax
loss. The learning task suffers from only a single positive instance, it is highly unbalanced with many
more negatives, and the relationships between samples are unknown, cf. Sec. 2. Consequentially,
stochastic gradient descend (SGD) gets corrupted and has a bias towards negatives, thus forfeiting
the benefits of deep learning.
Outline of the proposed approach: We overcome these limitations by updating similarities and
CNNs. Typically at the beginning only a few, local estimates of (dis-)similarity are easily available,
i.e., pairs of samples that are highly similar (near duplicates) or that are very distant. Most of the
similarities are, however, unknown or mutually contradicting, so that transitivity does not hold.
Therefore, we initially can only gather small, compact cliques of mutually similar samples around an
exemplar, but for most exemplars we know neither if they are similar nor dissimilar. To nevertheless
define balanced classification tasks suited for CNN training, we formulate an optimization problem
that builds training batches for the CNN by selecting groups of compact cliques, so that all cliques in
a batch are mutually distant. Thus for all samples of a batch (dis-)similarity is defined?they either
belong to the same compact clique or are far away and belong to different cliques. However, pairs of
samples with no reliable similarities end up in different batches so they do not yield false training
signal for SGD. Classifying if a sample belongs to a clique serves as a pretext task for learning
exemplar similarity. Training the network then implicitly reconciles the transitivity relations between
samples in different batches. Thus, the learned CNN representations impute similarities that were
initially unavailable and generalize them to unseen data.
In the experimental evaluation the proposed approach significantly improves over state-of-the-art
approaches for posture analysis and retrieval by learning a general feature representation for human
pose that can be transferred across datasets.
1.1 Exemplar Based Methods for Similarity Learning
The Exemplar Support Vector Machine (Exemplar-SVM) has been one of the driving methods for
exemplar based learning [15]. Each Exemplar-SVM classifier is defined by a single positive instance
and a large set of negatives. To improve performance, Exemplar-SVMs require several round of hard
negative mining, increasing greatly the computational cost of this approach. To circumvent this high
computational cost [10] proposes to train Linear Discriminant Analysis (LDA) over Histogram of
Gradient (HOG) features [10]. LDA whitened HOG features with the common covariance matrix
estimated for all the exemplars removes correlations between the HOG features, which tend to amplify
the background of the image.
Recently, several CNN approaches have been proposed for supervised similarity learning using either
pairs [25], or triplets [21] of images. However, supervised formulations for learning similarities
require that the supervisory information scales quadratically for pairs of images, or cubically for
triplets. This results in very large training times.
Literature on exemplar based learning in CNNs is very scarce. In [4] the authors of ExemplarCNN tackle the problem of unsupervised feature learning. A patch-based categorization problem is
designed by randomly extracting patch for each image in the training set and defining it as surrogate
class. Hence, since this approach does not take into account (dis-)similarities between exemplars, it
fails to model their transitivity relationships, resulting in poor performances (see Sect. 3.1).
Furthermore, recent works by Wang et al. [22] and Doersh et al. [3] showed that temporal information
in videos and spatial context information in images can be utilized as a convenient supervisory
signal for learning feature representation with CNNs. However, the computational cost of the
training algorithm is enormous since the approach in [3] needs to tackle all possible pair-wise image
relationships requiring training set that scales quadratically with the number of samples. On the
contrary, our approach leverages the relationship information between compact cliques, defining
a multi-class classification problem. As each training batch contains mutually distinct cliques the
computational cost of the training algorithm is greatly decreased.

2

Approach

We will now discuss how we can employ a CNN for learning similarities between all pairs of a large
number of exemplars. Exemplar learning in CNNs has been a relatively unexplored approach for
multiple reasons. First and foremost, deep learning requires large amounts of training data, thus
conflicting with having only a single positive exemplar in a setup that we now abbreviate as 1-sample
2

0.9
0.8

True positive rate

0.7
0.6
0.5
0.4
0.3
0.2

1-sample-CNN(0.62)
NN-CNN(0.65)
Ours(0.79)

0.1
0

0

0.2

0.4

0.6

0.8

1

False positive rate

(a)

(b)

(c)

(d)

Figure 1: (a) Average AUC for posture retrieval in the Olympic Sports dataset. Similarities learnt
by (b) 1-sample CNN, (c) using NN-CNN, and (d) for the proposed approach. The plots show a
magnified crop of the full similarity matrix. Note the more detailed fine structure in (d).

CNN. Such a 1-sample CNN faces several issues. (i) The within-class variance of an individual
exemplar cannot be modeled. (ii) The ratio of one exemplar and many negatives is highly imbalanced,
so that the softmax loss over SGD batches overfits against the negatives. (iii) An SGD batch for
training a CNN on multiple exemplars can contain arbitrarily similar samples with different label (the
different exemplars may be similar or dissimilar), resulting in label inconsistencies. The proposed
method overcomes these issues as follows. In Sect. 2.2 we discuss why simply merging an exemplar
with its nearest neighbors and data augmentation (similar in spirit to the Clustered Exemplar-SVM
[20]) is not sufficient to address (i). Sect. 3.1 compares this NN-CNN approach against other methods.
Sect. 2.3 deals with (ii) and (iii) by generating batches of cliques that maximize the intra-clique
similarity while minimizing inter-clique similarity.
To show the effectiveness of the proposed method we give empirical proof by training CNNs in both
1-sample CNN and NN-CNN manners. Fig. 1(a) shows the average ROC curve for posture retrieval
in the Olympic Sports dataset [16] (refer to Sec. 3.1 for further details) for 1-sample CNN, NN-CNN
and the proposed method, which clearly outperforms both exemplar based strategies. In addition,
Fig. 1(b-d) show an excerpt of the similarity matrix learned for each method. It becomes evident
that the proposed approach captures more detailed similarity structures, e.g., the diagonal structures
correspond to repetitions of the same gait cycle within a long jump.
2.1

Initialization

Since deep learning benefits from large amounts of data and requires more than a single exemplar
to avoid biased gradients, we now reframe exemplar-based learning of similarities so that it can
be handled by a CNN. Given a single exemplar di we thus strive for related samples to enable a
CNN training that then further improves the similarities between samples. To obtain this initial
set of few, mutually similar samples for an exemplar, we now briefly discuss the reliability of
standard feature distances such as whitening HOG features using LDA [10]. HOG-LDA is a
computationally effective foundation for estimating similarities sij between large numbers of samples,
sij = s(di , dj ) = ?(di )> ?(dj ). Here ?(di ) is the initial HOG-LDA representation of the exemplar
and S is the resulting kernel.
Most of these initial similarities are unreliable (cf. Fig. 4(b)) and, thus, the majority of samples
cannot be properly ranked w.r.t. their similarity to an exemplar di . However, highly similar samples
and those that are far away can be reliably identified as they stand out from the similarity distribution.
Subsequently we utilize these few reliable relationships to build groups of compact cliques.
2.2

Compact Cliques

Simply assigning the same label to all the nearest and another label to all the furthest neighbors
of an exemplar is inappropriate. The samples in these groups may be close to di (or distant for
the negative group) but not to another due to lacking transitivity. Moreover, mere augmentation of
the exemplar with synthetic data does not add transitivity relations to other samples. Therefore, to
learn within-class similarities we need to restrict the model to compact cliques of samples so that all
samples in a clique are also mutually close to another and deserve the same label.
3

Query

Ours

Alexnet [13]

HOG-LDA [10]

Figure 2: Averaging of the 50 nearest neighbours for a given query frame using similarities obtained
by our approach, Alexnet[13] and HOG-LDA [10].

To build candidate cliques we apply complete-linkage clustering starting at each di to merge the
sample with its local neighborhood, so that all merged samples are mutually similar. Thus, cliques are
compact, differ in size, and may be mutually overlapping. To reduce redundancy, highly overlapping
cliques are subsequently merged by clustering cliques using farthest-neighbor clustering. This
agglomerative grouping is terminated if intra-clique similarity of a cluster is less than half that of its
constituents. Let K be the resulting number of clustered cliques and N the number of samples di .
Then C ? {0, 1}K?N is the resulting assignment matrix of samples to cliques.

2.3

Selecting Batches of Mutually Consistent Cliques

We now have a set of compact cliques that comprise all training data. Thus, one may consider to train
a CNN to assign all samples of a clique with the same label. However, since only the highest/lowest
similarities are reliable, samples in different cliques are not necessarily dissimilar. Forcing them into
different classes can consequently entail incorrect similarities. Therefore, we now seek batches of
mutually distant cliques, so that all samples in a batch can be labeled consistently because they are
either similar (same compact clique) or dissimilar (different, distant clique). Samples with unreliable
similarity then end up in different batches and we train a CNN successively on these batches.
We now formulate an optimization problem that produces a set of consistent batches of cliques. Let
X ? {0, 1}B?K be an indicator matrix that assigns K cliques to B batches (the rows xb of X are the
cliques in batch b) and S0 ? RK?K be the similarity between cliques. We enforce cliques in the same
batch to be dissimilar by minimizing tr (XS0 X> ), which is regularized for the diagonal elements of
the matrix S0 selected for each batch (see Eq. (1)). Moreover, each batch should maximize sample
coverage, i.e., the number of distinct samples in all cliques of a batch kxb Ckpp should be maximal.
Finally, the number of distinct points covered by all batches, k1XCkpp , should be maximal, so that
the different (potentially overlapping) batches together comprise as much samples as possible. We
select p = 1/16 so that our penalty function roughly approximate the non-linear step function. The
objective of the optimization problem then becomes

min

X?{0,1}B?K

s.t.

tr (XS0 X> )? tr (X diag (S0 )X> ) ? ?1

B
X

kxb Ckpp ??2 k1XCkpp

(1)

b=1
>
X1>
K = r1B

(2)

where r is the desired number of cliques in one batch for CNN training. The number of batches, B,
can be set arbitrarily high to allow for as many rounds of SGD training as desired. If it is too low,
this can be easily spotted as only limited coverage of training data can be achieved in the last term of
Eq. (1). Since X is discrete, the optimization problem (1) is not easier than the Quadratic Assignment
Proble which is known to be N P -hardm [1]. To overcome this issue we relax the binary constraints
and force instead the continuous solution to the boundaries of the feasible range by maximizing the
additional term ?3 kX ? 0.5k2F using the Frobenius norm.
We condition S0 to be positive semi-definite by thresholding its eigenvectors and projecting onto the
resulting base. Since also p < 1 the previous objective function is a difference of convex functions
4

Figure 3: Visual example of a resulting batch of cliques for long jump category of Olympic Sports
dataset. Each clique contains at least 20 samples and is represented as their average.
u(X) ? v(X), where
u(X) = tr (XS0 X> ) ? ?1

B
X

kxb Ckpp ? ?2 k1XCkpp

(3)

b=1

v(X) = tr(X diag (S0 )X> ) + ?3 kX ? 0.5k2F

(4)

It can be solved using the CCCP Algorithm [24]. In each iteration of CCCP the following convex
optimization problem is solved,
>

argmin u(X) ? vec (X) vec (?v(Xt )),

(5)

X?[0,1]B?K

s.t.

>
X1>
K = r1B

(6)

where ?v(Xt ) = 2X  (1 diag (S0 )) + 2X ? 1 and  denotes the Hadamard product. We solve
this constrained optimization problem by means of the interior-point method. Fig. 3 shows a visual
example of a selected batch of cliques.
2.4

CNN Training

We successively train a CNN on the different batches xb obtained using Eq. (1). In each batch,
classifying samples according to the clique they are in then serves as a pretext task for learning
sample similarities. One of the key properties of CNNs is the training using SGD and backpropagation
[14]. The backpropagated gradient is estimated only over a subset (batch) of training samples, so it
depends only on the subset of cliques in xb . Following this observation, the clique categorization
problem is effectively decoupled into a set of smaller sub-tasks?the individual batches of cliques.
During training, we randomly pick a batch b in each iteration and compute the stochastic gradient,
using the softmax loss L(W),
1 X
L(W) ?
fW (dj ) + ?r(W)
(7)
M
b
j?x

Vt+1 = ?Vt ? ??L(Wt ),

Wt+1 = Wt + Vt+1 ,

(8)

where M is the SGD batch size, Wt denotes the CNN weights at iteration t, and Vt denotes the
weight update of the previous iteration. Parameters ? and ? denote the learning rate and momentum,
respectively. We then compute similarities between exemplars by simply measuring correlation on
the learned feature representation extracted from the CNN (see Sect. 3.1 for details).
2.5

Similarity Imputation

By alternating between the different batches, which contain cliques with mutually inconsistent
similarities, the CNN learns a single representation for samples from all batches. In effect, this
consolidates similarities between cliques in different batches. It generalizes from a subset of initial
cliques to new, previously unreliable relations between samples in different batches by utilizing
transitivity relationships implied by the cliques.
After a training round over all batches we impute the similarities using the representation learned
by the CNN. The resulting similarities are more reliable and enable the grouping algorithm from
Sect. 2.2 to find larger cliques of mutually related samples. As there are fewer unreliable similarities,
5

Frames sorted by exemplar similarity score

Query exemplar

200
180
160

Similarity score

140
120
100
80
60
40
20
0

1000

2000

3000

4000

5000

Frame ranking

(a)

(b)

6000

7000

Figure 4: (a) Cumulative distribution of the spectrum of the similarity matrices obtained by our
method and the HOG-LDA initialization. (b) Sorted similarities with respect to one exemplar,
where only similarities at the ends
of the distribution can be trusted.

more samples can be comprised in a batch and overall less batches already cover the same fraction of
data as before. Consequently, we alternately train the CNN and recompute cliques and batches using
the similarities inferred in the previous iteration of CNN training. This alternating imputation of
similarities and update of the classifier follows the idea of multiple-instance learning and has shown
to converge quickly in less than four iterations.
To evaluate the improvement of the similarities Fig. 4 analyzes the eigenvalue spectrum of S on
the Olympic Sports dataset, see Sect. 3.1. The plot shows the normalized cumulative sum of the
eigenvalues as the function of the number of eigenvectors. Compared to the initialization, transitivity
relations are learned and the approach can generalize from an exemplar to more related samples.
Therefore, the similarity matrix becomes more structured (cf. Fig. 1) and random noisy relations
disappear. As a consequence it can be represented using very few basis vectors. In a further
experiment we evaluate the number of reliable similarities and dissimilarities within and between
cliques per batch. Recall that samples can only be part of the same batch, if their similarity is
reliable. So the goal of similarity learning is to remove transitivity conflicts and reconcile relations
between samples to yield larger batches. We now observe that after the iterative update of similarities,
the average number of similarities and dissimilarities in a batch has increased by a factor of 2.34
compared to the batches at initialization.

3

Experimental Evaluation

We provide a quantitative and qualitative analysis of our exemplar-based approach for unsupervised
similarity learning. For evaluation, three different settings are considered: posture analysis on
Olympic Sports [16], pose estimation on Leeds Sports [12], and object classification on PASCAL
VOC 2007.
3.1

Olympic Sports Dataset: Posture Analysis

The Olympic Sports dataset [16] is a video compilation of different sports competitions. To evaluate
fine-scale pose similarity, for each sports category we had independent annotators manually label
20 positive (similar) and negative (dissimilar) samples for around 1200 exemplars. Note that these
annotations are solely used for testing, since we follow an unsupervised approach.
We compare the proposed method with the Exemplar-CNN [4], the two-stream approach of Doersch
et. al [3], 1-sample CNN and NN-CNN models (in a very similar spirit to [20]), Alexnet [13],
Exemplar-SVMs [15], and HOG-LDA [10]. Due to its performance in object and person detection,
we use the approach of [7] to compute person bounding boxes. (i) The evaluation should investigate
the benefit of the unsupervised gathering of batches of cliques for deep learning of exemplars using
standard CNN architectures. Therefore we incarnate our approach by adopting the widely used model
of Krizhevsky et al. [13]. Batches for training the network are obtained by solve the optimization
problem in Eq. (1) with B = 100, K = 100, and r = 20 and fine-tuning the model for 105 iterations.
Thereafter we compute similarities using features extracted from layer fc7 in the caffe implementation
of [13]. (ii) Exemplar-CNN is trained using the best performing parameters reported in [4] and the
64c5-128c5-256c5-512f architecture. Then we use the output of fc4 and compute 4-quadrant max
pooling. (iii) Exemplar-SVM was trained on the exemplar frames using the HOG descriptor. The
samples for hard negative mining come from all categories except the one that an exemplar is from.
We performed cross-validation to find an optimal number of negative mining rounds (less than three).
The class weights of the linear SVM were set as C1 = 0.5 and C2 = 0.01. (iv) LDA whitened HOG
6

HOG-LDA [10]
0.58

Ex-SVM [15]
0.67

Ex-CNN [4]
0.56

Alexnet [13]
0.65

1-s CNN
0.62

NN-CNN
0.65

Doersch et. al [3]
0.58

Ours
0.79

Table 1: Avg. AUC for each method on Olympic Sports dataset.

was computed as specified in [10]. (v) The 1-sample CNN was trained by defining a separate class for
each exemplar sample plus a negative category containing all other samples. (vi) In a similar fashion,
the NN-CNN was trained using the exemplar plus 10 nearest neighbours obtained using the whitened
HOG similarities. As implementation for both CNNs we again used the model of [13] fine-tuned
for 105 iterations. Each image in the training set is augmented with 10 transformed versions by
performing random translation, scaling, rotation and color transformation, to improve invariance with
respect to these.
Tab. 1 reports the average AuC for each method over all categories of the Olympic Sports dataset.
Our approach obtains a performance improvement of at least 10% w.r.t. the other methods. In
particular, the experiments show that the 1-sample CNN fails to model the positive distribution,
due to the high imbalance between positives and negatives and the resulting biased gradient. In
comparison, additional nearest neighbours to the exemplar (NN-CNN) yield a better model of withinclass variability of the exemplar leading to a 3% performance increase over the 1-sample CNN.
However NN-CNN also sees a large set of negatives, which are partially similar and dissimilar. Due
to this unstructuredness of the negative set, the approach fails to thoroughly capture the fine-grained
similarity structure over the negative samples. To circumvent this issue we compute sets of mutually
distant compact cliques resulting in a relative performance increase of 12% over NN-CNN.
Furthermore, Fig. 1 presents the similarity structures, which the different approaches extract when
analyzing human postures. Fig. 2 further highlights the similarities and the relations between
neighbors. For each method the top 50 nearest neighbours for a randomly chosen exemplar frame in
the Olympic Sports dataset are blended. We can see how the neighbors obtained by our approach
depict a sharper average posture, since they result from compact cliques of mutually similar samples.
Therefore they retain more details and are more similar to the original than in case of the other
methods.
3.2

Leeds Sports Dataset: Pose Estimation

The Leeds Sports Dataset [12] is the most widely used benchmark for pose estimation. For training
we employ 1000 images from the dataset combined with 4000 images from the extended version of
this dataset, where each image is annotated with 14 joint locations. We use the visual similarities
learned by our approach to find frames similar in posture to a query frame. Since our training is
unsupervised, joint labels are not available. At test time we therefore estimate the pose of a query
person by identifying the nearest neighbor from the training set. To compare against the supervised
methods, the pose of the nearest neighbor is then compared against ground-truth.
Now we evaluate our visual similarity learning and the resulting identification of nearest postures.
For comparison, similar postures are also retrieved using HOG-LDA [10] and Alexnet [13]. In
addition, we also report an upper bound on the performance that can be achieved by the nearest
neighbor using ground-truth similarities. Therefore, the nearest training pose for a query is identified
by minimizing the average distance between their ground-truth pose annotation. This is the best one
can do by finding the most similar frame, when not provided with a supervised parametric model (the
performance gap to 100% shows the difference between training and test poses). For completeness,
we compare with a fully supervised state-of-the-art approach for pose estimation [18]. We use the
same experimental settings described in Sect. 3.1. Tab. 2 reports the Percentage of Correct Parts
(PCP) for the different methods. The prediction for a part is considered correct when its endpoints
are within 50% part length of the corresponding ground truth endpoints. Our approach significantly
improves the visual similarities learned using Alexnet and HOG-LDA. It is note-worthy that even
though our approach for estimating the pose is fully unsupervised it attains a competitive performance
when compared to the upper-bound of supervised ground truth similarities.
In addition, Fig. 5 presents success (a) and failure (c) cases of our method. In Fig.5(a) we can see
that the pose is correctly transferred from the nearest neighbor (b) from the training set, resulting in a
PCP score of 0.6 for that particular image. Moreover, Fig.5(c), (d) show that the representation learnt
by our method is invariant to front-back flips (matching a person facing away from the camera to one
7

Method
Ours
HOG-LDA[10]
Alexnet[13]
Ground Truth
Pose Machines [18]

Torso
80.1
73.7
76.9
93.7
93.1

Upper legs
50.1
41.8
47.8
78.8
83.6

Lower legs
45.7
39.2
41.8
74.9
76.8

Upper arms
27.2
23.2
26.7
58.7
68.1

Lower arms
12.6
10.3
11.2
36.4
42.2

Head
45.5
42.2
42.4
72.4
85.4

Total
43.5
38.4
41.1
69.2
72.0

Table 2: PCP measure for each method on Leeds Sports dataset.

(a)

(b)

(c)

(d)

Figure 5: Pose prediction results. (a) and (c) are test images with the superimposed ground truth
skeleton depicted in red and the predicted skeleton in green. (b) and (d) are corresponding nearest
neighbours, which were used to transfer pose.

facing the camera). Since our approach learns pose similarity in an unsupervised manner, it becomes
invariant to changes in appearance as long as the shape is similar, thus explaining this confusion.
Adding additional training data or directly incorporating face detection-based features could resolve
this.
3.3

PASCAL VOC 2007: Object Classification

The previous sections have analyzed the learning of pose similarities. Now we evaluate the learning
of similarities over object categories. Therefore, we classify object bounding boxes of the PASCAL
VOC 2007 dataset. To initialize our model we now use the visual similarities of Wang et al. [22]
without applying any fine tuning on PASCAL and also compare against this approach. Thus, neither
ImageNet nor Pascal VOC labels are utilized. For comparison we evaluate against HOG-LDA [10],
[22], and R-CNN [9]. For our method and HOG-LDA we use the same experimental settings as
described in Sect. 3.1, initializing our method and network with the similarities obtained by [22].
For all methods, the k nearest neighbors are computed using similarities (Pearson correlation) based
on fc6. In Tab. 3 we show the classification accuracies for all approaches for k = 5. Our approach
improves upon the initial similarities of the unsupervised approach of [22] to yield a performance
gain of 3% without requiring any supervision information or fine-tuning on PASCAL.
HOG-LDA
0.1180

Wang et. al [22]
0.4501

Wang et. al [22] + Ours
0.4812

RCNN
0.6825

Table 3: Classification results for PASCAL VOC 2007

4

Conclusion

We have proposed an approach for unsupervised learning of similarities between large numbers
of exemplars using CNNs. CNN training is made applicable in this context by addressing crucial
problems resulting from the single positive exemplar setup, the imbalance between exemplar and
negatives, and inconsistent labels within SGD batches. Optimization of a single cost function yields
SGD batches of compact, mutually dissimilar cliques of samples. Learning exemplar similarities is
then posed as a categorization task on individual batches. In the experimental evaluation the approach
has shown competitive performance compared to the state-of-the-art, providing significantly finer
similarity structure that is particularly crucial for detailed posture analysis. 2
2
This research has been funded in part by the Ministry for Science, Baden-W?rttemberg and the Heidelberg
Academy of Sciences, Heidelberg, Germany. We are grateful to the NVIDIA corporation for donating a Titan X
GPU.

8

References
[1] R. E. Burkard, E. ?ela, P. M. Pardalos, and L. Pitsoulis. The quadratic assignment problem. In P. M.
Pardalos and D.-Z Du, editors, Handbook of Combinatorial Optimization. 1998.
[2] C. Doersch, S. Singh, A. Gupta, J. Sivic, and A. Efros. What makes paris look like paris? ACM TOG,
31(4), 2012.
[3] Carl Doersch, Abhinav Gupta, and Alexei A Efros. Unsupervised visual representation learning by context
prediction. In ICCV, pages 1422?1430, 2015.
[4] Alexey Dosovitskiy, Jost Tobias Springenberg, Martin Riedmiller, and Thomas Brox. Discriminative
unsupervised feature learning with convolutional neural networks. In NIPS, pages 766?774, 2014.
[5] A. Eigenstetter, M. Takami, and B. Ommer. Randomized max-margin compositions for visual recognition.
In CVPR ?14.
[6] I. El-Naqa, Y. Yang, N. P. Galatsanos, R. M. Nishikawa, and M. N. Wernick. A similarity learning approach
to content-based image retrieval: application to digital mammography. TMI, 23(10):1233?1244, 2004.
[7] Pedro Felzenszwalb, David McAllester, and Deva Ramanan. A discriminatively trained, multiscale,
deformable part model. In CVPR, pages 1?8. IEEE, 2008.
[8] V. Ferrari, M. Marin-Jimenez, and A. Zisserman. Pose search: retrieving people using their pose. In CVPR,
pages 1?8. IEEE, 2009.
[9] Ross Girshick, Jeff Donahue, Trevor Darrell, and Jitendra Malik. Rich feature hierarchies for accurate
object detection and semantic segmentation. In CVPR, pages 580?587, 2014.
[10] Bharath Hariharan, Jitendra Malik, and Deva Ramanan. Discriminative decorrelation for clustering and
classification. In ECCV, pages 459?472. Springer, 2012.
[11] X. He and S. Gould. An exemplar-based crf for multi-instance object segmentation. In CVPR. IEEE, 2014.
[12] Sam Johnson and Mark Everingham. Learning effective human pose estimation from inaccurate annotation.
In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 2011.
[13] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional
neural networks. In NIPS, pages 1097?1105, 2012.
[14] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. Backpropagation applied to handwritten zip code recognition. Neural computation, 1(4):541?551, 1989.
[15] Tomasz Malisiewicz, Abhinav Gupta, and Alexei A Efros. Ensemble of exemplar-svms for object detection
and beyond. In ICCV, pages 89?96. IEEE, 2011.
[16] Juan Carlos Niebles, Chih-Wei Chen, and Li Fei-Fei. Modeling temporal structure of decomposable motion
segments for activity classification. In ECCV, pages 392?405. Springer, 2010.
[17] H. Pirsiavash and D. Ramanan. Parsing videos of actions with segmental grammars. In CVPR, 2014.
[18] V. Ramakrishna, D. Munoz, M. Hebert, J. A. Bagnell, and Y. Sheikh. Pose machines: Articulated pose
estimation via inference machines. In ECCV ?14. Springer, 2014.
[19] J. Rubio, A. Eigenstetter, and B. Ommer. Generative regularization with latent topics for discriminative
object recognition. PR, 48:3871?3880, 2015.
[20] Nataliya Shapovalova and Greg Mori. Clustered exemplar-svm: Discovering sub-categories for visual
recognition. In ICIP, pages 93?97. IEEE, 2015.
[21] Jiang Wang, Yang Song, Thomas Leung, Chuck Rosenberg, Jingbin Wang, James Philbin, Bo Chen, and
Ying Wu. Learning fine-grained image similarity with deep ranking. In CVPR, pages 1386?1393, 2014.
[22] X. Wang and A. Gupta. Unsupervised learning of visual representations using videos. In ICCV, 2015.
[23] Hao Xia, Steven CH Hoi, Rong Jin, and Peilin Zhao. Online multiple kernel similarity learning for visual
search. TPAMI, 36(3):536?549, 2014.
[24] A. L. Yuille and Anand Rangarajan. The concave-convex procedure (CCCP). Neural computation,
15(4):915?936, 2003.
[25] S. Zagoruyko and N. Komodakis. Learning to compare image patches via convolutional neural networks.
In CVPR ?14.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 414-real-time-autonomous-robot-navigation-using-vlsi-neural-networks.pdf

Real-time autonomous robot navigation using
VLSI neural networks

Lionel Tarassenko Michael Brownlow Gillian Marshall?
Department of Engineering Science
Oxford University, Oxford, OXl 3PJ, UK

Jon Tombs

Alan Murray
Department of Electrical Engineering
Edinburgh University, Edinburgh, EH9 3JL, UK

Abstract
We describe a real time robot navigation system based on three VLSI
neural network modules. These are a resistive grid for path planning, a
nearest-neighbour classifier for localization using range data from a timeof-flight infra-red sensor and a sensory-motor associative network for dynamic obstacle avoidance .

1

INTRODUCTION

There have been very few demonstrations ofthe application ofVLSI neural networks
to real world problems. Yet there are many signal processing, pattern recognition
or optimization problems where a large number of competing hypotheses need to
be explored in parallel, most often in real time. The massive parallelism of VLSI
neural network devices, with one multiplier circuit per synapse, is ideally suited to
such problems. In this paper, we present preliminary results from our design for a
real time robot navigation system based on VLSI neural network modules. This is a
? Also: RSRE, Great Malvern, Worcester, WR14 3PS

422

Real-time Autonomous Robot Navigation Using VLSI Neural Networks
real world problem which has not been fully solved by traditional AI methods; even
when partial solutions have been proposed and implemented, these have required
vast computational resources, usually remote from the robot and linked to it via an
umbilical cord.

2

OVERVIEW

The aim of our work is to develop an autonomous vehicle capable of real-time
navigation, including obstacle avoidance, in a known indoor environment. The
obstacles may be permanent (static) or unexpected and dynamic (for example,
in an automated factory environment, the walls and machines are permanent but
people, other moving vehicles and packages are not.) There are three neural network
modules at the heart of our navigation system: a localization module (to determine,
at any time, the robot's position within the environment), an obstacle detection
module and a path planning module (to compute a path to the goal which avoids
obstacles). These modules perform low-level processing in real time which can then
be decoupled from higher level processing to be carried out by a simple controller.
It is our view that such a hybrid system is the best way to realise the computational
potential of artificial neural networks for solving a real world problem such as this
without compromising overall system performance.
A short description of each module is now given. In each case, the general principles
are first outlined and, where applicable, the results of our preliminary work are then
reported.

3

PATH PLANNING

The use ofresistive grids for parallel analog computation was first suggested by Horn
in the mid-seventies (Horn, 1974) and the idea has since been exploited by Mead and
co-workers, for example in a silicon retina (Mead and Mahowald, 1988). Although
these resistive grids cannot be said to be neural networks in the conventional sense,
they also perform parallel analog computation and they have the same advantages,
in terms of speed and fault-tolerance, as any hardware realisation of neural networks.
We have taken the resistive grid concept and applied it to the path planning problem, here taken to be the computation of an obstacle-avoiding path, in a structured
environment, from the robot's initial (or present) position (P) to its goal (G). In our
approach, the robot's working domain is discretized and mapped onto a resistive
grid of hexagonal or rectangular cells - see Figure 1 which shows the test environment for Autonomous Guided Vehicles (AGV's) in the Oxford Robotics Laboratory.
Each resistor in the grid has a value of flo, unless it is part of a region of the grid
corresponding to an obstacle, in which case its resistance is infinite (Roo).
The principle of the method is perhaps best understood by considering a continuous
analog of the resistive grid (for example, a sheet of material of uniform resistivity in
which holes have been cut to represent the obstacles). The current streamlines resulting from the application of an external source between P and G skirt around the
obstacles; if we follow one of these streamlines from P to G, we will obtain a guaranteed collision-free path since current cannot flow into the obstacles (Tarassenko and

423

424

Tarassenko, Brownlow, Marshall, Tombs, and Murray
Blake, 1991). For simple cases such as circularly symmetric conductivity distributions in 2D, Laplace's equation can be solved in order to calculate the value of the
potential V at every point within the workspace. Following a current streamline is
then simply a matter of performing gradient descent in V.

Figure 1: The Oxford test environment for AGV's mapped out as a hexagonal
resistive grid. The resistors corresponding to the four pillars in the middle are open
circuits. Note that the pillars are enlarged in their grid representation in order to
take into account the mobile robot's finite size.
It is not possible, however, to solve Laplace's equation analytically for realistic environments. With the resistive grid, the problem is discretized and mapped onto a
hardware representation which can be implemented in VLSI. As soon as an external
source of power is connected between P and G, the resistive network settles into
the state of least power dissipation and the node voltages can be read out (hardware computation of Kirchhoff's equations). The path from P to G is computed
incrementally from local voltage measurements: for each node, the next move is
identified by measuring the voltage drop ~ Vn between that node and each of its
nearest neighbours (n = 6 for a hexagonal grid) and then selecting the node corresponding to (~Vn)max. This is illustrated by the example of a robot in a maze
(Figure 2). As above, the resistors shown shaded are open circuits whilst all other
resistors are set to be equal to Ro. The robot is initially placed at the centre of the
maze (P) and a path has to be found to the goal in the top left-hand corner (G). The
solid line shows the path resulting from a single application of the voltage between
P and G. The dotted line shows the (optimal) path computed by re-applying the

Real-time Autonomous Robot Navigation Using VLSI Neural Networks
voltage at every node as the robot moves towards the goal. As already indicated,
this is actually how we intend to use the resistive grid planner in practice, since
this approach also allows us to re-compute the robot's path whenever unexpected
obstacles appear in the environment (see Section 5) .

..:~:::.~~::~.::~.~: ::~::~~:::~:::.~.::~::~.~::.::~.::::~~::~::~;;':X
~---;~~~~-*" ~I.: :x.........'?){ .... ) <?.... )<. . ?::x
x ..........
?x.
..'......

)E ...... ? ?~)( .... ???) (?????? ..

,?????.... ?~?? ...... ?x.. ??.. ? ?: ~: .. ???? ? :~::???? ??:~: .. ?? .. ?:x

..>ot~?? ....?:'X':.. ?.... ?';I(...... ?:~~~~'"*-*-'*?.? . . .?.:X: .. ..??

x:?

* .........,>0:: .

x;~?.~:~:~?:::?~:~?:~: ?. ~~: ~?:::~:::~::. . . :~:: .?~:.: ~.: .~:::~:::.~::.:~::~~~ ;~:.: .:~:.: ~: :~:.: ~:::~.:x

Figure 2: Path from middle of maze (P) to top left-hand corner (G)

3.1

VLSI IMPLEMENTATION

The VLSI implementation of the resistive grid method will allow us to solve the path
planning for complex environments in real time. MOS switches are ideal implementations of the binary resistors in the grid. Each transistor can be programmed to
be either open (Roo) or closed (Ro) from a RAM cell connected to its gate. With
the incremental computation of the path described above , the selection of the next
move is a matter of identifying the largest of six voltages. Of course, the nearest
neighbour voltages and that of the P node could be read out through an AID converter and the decision made off-chip. We favour a full hardware solution instead,
whereby the maximum voltage difference is directly identified on-chip.

4

LOCALIZATION

The autonomous robot should at any time be able to work out its position in
the workspace so that the path to the goal can be updated if required. The grid
representation of the environment used for the path planner can also be employed

425

426

Tarassenko, Brownlow, Marshall, Tombs, and Murray
for localization purposes, in which case localization becomes, in the first instance,
a matter of identifying the nearest node in the grid at any time during navigation.
This task can be performed by harnessing the pattern recognition capabilities of
neural networks. The room environment is learnt by recording a 3600 range scan
at every node during a training phase prior to navigation. During navigation, the
nearest node is identified using a minimum-distance classifier implemented on a
single-layer neural network working on dense input data (one range value every 30 ,
say). In order to solve the localization problem in real-time, we have designed a timeof-flight optical rangefinder, which uses near infra-red light, amplitude-modulated
at a frequency of just above 5 MHz, together with a heterodyne mixing technique.
Our design is capable of resolving phase shifts in the received light signal of the
order of 0.10 over a 50 dB dynamic range.
The rotating optical scanner gives a complete 360 0 scan approximately every second
during navigation. The minimum-distance classifier is used to compare this scan x
with the k patterns Uj recorded at each node during training. If we use a Euclidean
metric for the comparison, this is equivalent to identifying the pattern Uj for which:

(1)
is a minimum. The first term in the above equation is the same for all i and can be
ignored. We can therefore write:

= - '12 (- 2wT x +

= WiT +
where gj(x) is a linear discriminant function, Wi = Uj and
= -~u;,
gj

( x)

j

2
Uj)

X

WjQ

(2)

WjQ
Thus each
vector is one of the learnt patterns Ui and the discriminant gi(X) matches the
input x with Uj, point by point. If we let W j
{Iij} and x = {Vj} and assume
that there are n range values in each scan, then we can write:

Wj

=

j=n

gj(x)

= E Iij Vj +

WiO

(3)

j=l

Thus the synaptic weights are an exact copy of the patterns recorded at each grid
point during learning and the neurons can be thought of as processors which compute distances to those patterns. During navigation, the nearest node is identified
with a network of k neurons evaluating k discriminant functions in parallel, followed
by a ''winner-take-all'' network to pick the maximum gj(x). This is the well-known
implementation of the nearest-neighbour classifier on a neural network architecture.
Since the ui's are analog input vectors, then the synaptic weights Iij will also be
analog quantities and this leads to a very efficient use of the pulse-stream analog
VLSI technology which we have recently developed for the implementation of neural
networks (Murray et ai, 1990).
With pulse-stream arithmetic, analog computation is performed under digital control. The neural states are represented by pulse rates and synaptic multiplication is achieved by pulse width modulation. This allows very compact, fully-

Real-time Autonomous Robot Navigation Using VLSI Neural Networks
programmable, synapse circuits to be designed (3 or 4 transistors per synapse).
We have already applied one set of our working chips to the nearest-neighbour classification task described in this Section. They were evaluated on a 24-node test
environment and full results have been reported elsewhere (Brownlow, Tarassenko
and Murray, 1990). It was found that the E Iij Vi scalar products evaluated by our
VLSI chips on this test problem were always within 1.2% of those computed on a
SUN 3/80 workstation.

5

OBSTACLE DETECTION/AVOIDANCE

A more appropriate name for this module may be that of local navigation. The
module will rely on optical flow information derived from a number of fixed optical
sensors mounted on the robot platform. Each sensor will include a pulsed light
source to illuminate the scene locally and the light reflected from nearby objects
will be focussed onto a pair of gratings at right angles to each other, before being
detected by a photodiode array. From the time derivatives of the received signals,
it is possible to compute the relative velocities of nearby objects such as moving
obstacles. We plan to use previous work on structure from motion to pre-process
these velocity vectors and derive from them appropriate feature vectors to be used
as inputs to a low-level neural network for motor control (see Figure 3 below).

sensors~ intended path,...."'"

""

"

"q'

un
Measurement
flow from

of optic
sensors

w
Velocity signal of
approaching objects.

Low level network

Direct motor
control

Figure 3: Sensory-motor associative network for obstacle avoidance

427

428

Tarassenko, Brownlow, Marshall, Tombs, and Murray
The obstacle avoidance network will be taught to associate appropriate motor behaviours with different types of sensory input data, for example the taking of the
correct evasive action when a moving object is approaching the robot from a particular direction. This module will therefore be responsible for path adjustment in
response to dynamic obstacles (with a bandwidth of around 100 Hz), but the path
planner of Section 3 will continue to deal with path reconfiguration at a much lower
data rate (1 Hz), once the dynamic obstacle has been avoided. Our work on this
module has, so far, been mainly concerned with the design of the input sensors and
associated electronics.

6

CONCLUSION

We have implemented the path planning and localization modules described in this
paper on a SUN 4 workstation and used them to control a mobile robot platform
via a radio link. This capability was demonstrated at the NIPS'90 Conference with
a videotape recording of our mobile robot navigating around static obstacles in
a laboratory environment, using real-time infra-red data for localization. It was
possible to run the path planner in near real-time in simulation because no resistor
value need be changed in a static environment; in order to achieve real-time path
planning in a dynamic environment, however, the hardware solution of Section 3
will be mandatory. Our aim remains the implementation of all 3 modules in VLSI
in order to demonstrate a fully autonomous real-time navigation system with all
the sensors and hardware mounted on the robot platform.
Acknowledgements

We gratefully acknowledge the financial support of UK Science and Engineering
Research Council and of the EEC (ESPRIT BRA). We have benefitted greatly
from the help and advice of members of the Robotics Research Group, most notably
Martin Adams, Gabriel Hamid and Jake Reynolds.
References

M.J. Brownlow, L. Tarassenko & A.F. Murray. (1990) Analogue computation using
VLSI neural network devices. Electronics Letters, 26(16):1297-1299.
B.K.P. Horn. (1974) Determining lightness from an image. Computational Graphics
fj Image Processing, 3:277-299.
C.A. Mead & M.A. Mahowald. (1988) A silicon model of early visual processing.
Neural Networks, 1(1 ):91-97.
A.F. Murray, M.J. Brownlow, L. Tarassenko, A. Hamilton, I.S. Han & H.M. Reekie.
(1990) Pulse-Firing Neural Chips for Hundreds of Neurons. In D.S. Touretzky (ed.),
Advances in Neural Information Processing Systems 2, 785-792. San Mateo, CA:
Morgan Kaufmann.
L. Tarassenko & A. Blake. (1991). Analogue computation of collision-free paths. To
be published in: Proceedings of 1991 IEEE Int. Conf. on Robotics fj Automation,
Sacramento, CA:


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 5950-skip-thought-vectors.pdf

Skip-Thought Vectors

Ryan Kiros 1 , Yukun Zhu 1 , Ruslan Salakhutdinov 1,2 , Richard S. Zemel 1,2
Antonio Torralba 3 , Raquel Urtasun 1 , Sanja Fidler 1
University of Toronto 1
Canadian Institute for Advanced Research 2
Massachusetts Institute of Technology 3

Abstract
We describe an approach for unsupervised learning of a generic, distributed sentence encoder. Using the continuity of text from books, we train an encoderdecoder model that tries to reconstruct the surrounding sentences of an encoded
passage. Sentences that share semantic and syntactic properties are thus mapped
to similar vector representations. We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training, allowing us
to expand our vocabulary to a million words. After training our model, we extract and evaluate our vectors with linear models on 8 tasks: semantic relatedness,
paraphrase detection, image-sentence ranking, question-type classification and 4
benchmark sentiment and subjectivity datasets. The end result is an off-the-shelf
encoder that can produce highly generic sentence representations that are robust
and perform well in practice.

1

Introduction

Developing learning algorithms for distributed compositional semantics of words has been a longstanding open problem at the intersection of language understanding and machine learning. In recent
years, several approaches have been developed for learning composition operators that map word
vectors to sentence vectors including recursive networks [1], recurrent networks [2], convolutional
networks [3, 4] and recursive-convolutional methods [5, 6] among others. All of these methods
produce sentence representations that are passed to a supervised task and depend on a class label in
order to backpropagate through the composition weights. Consequently, these methods learn highquality sentence representations but are tuned only for their respective task. The paragraph vector
of [7] is an alternative to the above models in that it can learn unsupervised sentence representations
by introducing a distributed sentence indicator as part of a neural language model. The downside is
at test time, inference needs to be performed to compute a new vector.
In this paper we abstract away from the composition methods themselves and consider an alternative loss function that can be applied with any composition operator. We consider the following
question: is there a task and a corresponding loss that will allow us to learn highly generic sentence
representations? We give evidence for this by proposing a model for learning high-quality sentence
vectors without a particular supervised task in mind. Using word vector learning as inspiration, we
propose an objective function that abstracts the skip-gram model of [8] to the sentence level. That
is, instead of using a word to predict its surrounding context, we instead encode a sentence to predict
the sentences around it. Thus, any composition operator can be substituted as a sentence encoder
and only the objective function becomes modified. Figure 1 illustrates the model. We call our model
skip-thoughts and vectors induced by our model are called skip-thought vectors.
Our model depends on having a training corpus of contiguous text. We chose to use a large collection
of novels, namely the BookCorpus dataset [9] for training our models. These are free books written
by yet unpublished authors. The dataset has books in 16 different genres, e.g., Romance (2,865
books), Fantasy (1,479), Science fiction (786), Teen (430), etc. Table 1 highlights the summary
statistics of the book corpus. Along with narratives, books contain dialogue, emotion and a wide
range of interaction between characters. Furthermore, with a large enough collection the training
set is not biased towards any particular domain or application. Table 2 shows nearest neighbours
1

Figure 1: The skip-thoughts model. Given a tuple (si?1 , si , si+1 ) of contiguous sentences, with si
the i-th sentence of a book, the sentence si is encoded and tries to reconstruct the previous sentence
si?1 and next sentence si+1 . In this example, the input is the sentence triplet I got back home. I
could see the cat on the steps. This was strange. Unattached arrows are connected to the encoder
output. Colors indicate which components share parameters. heosi is the end of sentence token.
# of books
11,038

# of sentences
74,004,228

# of words
984,846,357

# of unique words
1,316,420

mean # of words per sentence
13

Table 1: Summary statistics of the BookCorpus dataset [9]. We use this corpus to training our
model.
of sentences from a model trained on the BookCorpus dataset. These results show that skip-thought
vectors learn to accurately capture semantics and syntax of the sentences they encode.
We evaluate our vectors in a newly proposed setting: after learning skip-thoughts, freeze the model
and use the encoder as a generic feature extractor for arbitrary tasks. In our experiments we consider 8 tasks: semantic-relatedness, paraphrase detection, image-sentence ranking and 5 standard
classification benchmarks. In these experiments, we extract skip-thought vectors and train linear
models to evaluate the representations directly, without any additional fine-tuning. As it turns out,
skip-thoughts yield generic representations that perform robustly across all tasks considered.
One difficulty that arises with such an experimental setup is being able to construct a large enough
word vocabulary to encode arbitrary sentences. For example, a sentence from a Wikipedia article
might contain nouns that are highly unlikely to appear in our book vocabulary. We solve this problem
by learning a mapping that transfers word representations from one model to another. Using pretrained word2vec representations learned with a continuous bag-of-words model [8], we learn a
linear mapping from a word in word2vec space to a word in the encoder?s vocabulary space. The
mapping is learned using all words that are shared between vocabularies. After training, any word
that appears in word2vec can then get a vector in the encoder word embedding space.

2

Approach

2.1

Inducing skip-thought vectors

We treat skip-thoughts in the framework of encoder-decoder models 1 . That is, an encoder maps
words to a sentence vector and a decoder is used to generate the surrounding sentences. Encoderdecoder models have gained a lot of traction for neural machine translation. In this setting, an
encoder is used to map e.g. an English sentence into a vector. The decoder then conditions on this
vector to generate a translation for the source English sentence. Several choices of encoder-decoder
pairs have been explored, including ConvNet-RNN [10], RNN-RNN [11] and LSTM-LSTM [12].
The source sentence representation can also dynamically change through the use of an attention
mechanism [13] to take into account only the relevant words for translation at any given time. In our
model, we use an RNN encoder with GRU [14] activations and an RNN decoder with a conditional
GRU. This model combination is nearly identical to the RNN encoder-decoder of [11] used in neural
machine translation. GRU has been shown to perform as well as LSTM [2] on sequence modelling
tasks [14] while being conceptually simpler. GRU units have only 2 gates and do not require the use
of a cell. While we use RNNs for our model, any encoder and decoder can be used so long as we
can backpropagate through it.
Assume we are given a sentence tuple (si?1 , si , si+1 ). Let wit denote the t-th word for sentence si
and let xti denote its word embedding. We describe the model in three parts: the encoder, decoder
and objective function.
Encoder. Let wi1 , . . . , wiN be the words in sentence si where N is the number of words in the
sentence. At each time step, the encoder produces a hidden state hti which can be interpreted as the
representation of the sequence wi1 , . . . , wit . The hidden state hN
i thus represents the full sentence.
1

A preliminary version of our model was developed in the context of a computer vision application [9].

2

Query and nearest sentence
he ran his hand inside his coat , double-checking that the unopened letter was still there .
he slipped his hand between his coat and his shirt , where the folded copies lay in a brown envelope .
im sure youll have a glamorous evening , she said , giving an exaggerated wink .
im really glad you came to the party tonight , he said , turning to her .
although she could tell he had n?t been too invested in any of their other chitchat , he seemed genuinely curious about this .
although he had n?t been following her career with a microscope , he ?d definitely taken notice of her appearances .
an annoying buzz started to ring in my ears , becoming louder and louder as my vision began to swim .
a weighty pressure landed on my lungs and my vision blurred at the edges , threatening my consciousness altogether .
if he had a weapon , he could maybe take out their last imp , and then beat up errol and vanessa .
if he could ram them from behind , send them sailing over the far side of the levee , he had a chance of stopping them .
then , with a stroke of luck , they saw the pair head together towards the portaloos .
then , from out back of the house , they heard a horse scream probably in answer to a pair of sharp spurs digging deep into its flanks .
? i ?ll take care of it , ? goodman said , taking the phonebook .
? i ?ll do that , ? julia said , coming in .
he finished rolling up scrolls and , placing them to one side , began the more urgent task of finding ale and tankards .
he righted the table , set the candle on a piece of broken plate , and reached for his flint , steel , and tinder .

Table 2: In each example, the first sentence is a query while the second sentence is its nearest
neighbour. Nearest neighbours were scored by cosine similarity from a random sample of 500,000
sentences from our corpus.
To encode a sentence, we iterate the following sequence of equations (dropping the subscript i):
rt
t

=

?(Wr xt + Ur ht?1 )
t

t?1

?(Wz x + Uz h

(1)

z
?
ht

=
=

tanh(Wx + U(r  h

ht

=

?t
(1 ? zt )  ht?1 + zt  h

t

)

(2)

t

t?1

))

(3)
(4)

? t is the proposed state update at time t, zt is the update gate, rt is the reset gate () denotes
where h
a component-wise product. Both update gates takes values between zero and one.
Decoder. The decoder is a neural language model which conditions on the encoder output hi . The
computation is similar to that of the encoder except we introduce matrices Cz , Cr and C that are
used to bias the update gate, reset gate and hidden state computation by the sentence vector. One
decoder is used for the next sentence si+1 while a second decoder is used for the previous sentence
si?1 . Separate parameters are used for each decoder with the exception of the vocabulary matrix V,
which is the weight matrix connecting the decoder?s hidden state for computing a distribution over
words. In what follows we describe the decoder for the next sentence si+1 although an analogous
computation is used for the previous sentence si?1 . Let hti+1 denote the hidden state of the decoder
at time t. Decoding involves iterating through the following sequence of equations (dropping the
subscript i + 1):
rt
t

z
?
ht
hti+1

= ?(Wrd xt?1 + Udr ht?1 + Cr hi )
=

?(Wzd xt?1 + Udz ht?1 +
d t?1
d t

= tanh(W x
=

Cz hi )
t?1

+ U (r  h

) + Chi )

?t
(1 ? zt )  ht?1 + zt  h

(5)
(6)
(7)
(8)

t
Given hti+1 , the probability of word wi+1
given the previous t ? 1 words and the encoder vector is
t
<t
t
P (wi+1
|wi+1
, hi ) ? exp(vwi+1
hti+1 )

(9)

t
t
where vwi+1
denotes the row of V corresponding to the word of wi+1
. An analogous computation
is performed for the previous sentence si?1 .

Objective. Given a tuple (si?1 , si , si+1 ), the objective optimized is the sum of the log-probabilities
for the forward and backward sentences conditioned on the encoder representation:
X
X
t
<t
t
<t
logP (wi+1
|wi+1
, hi ) +
logP (wi?1
|wi?1
, hi )
(10)
t

t

The total objective is the above summed over all such training tuples.
3

2.2

Vocabulary expansion

We now describe how to expand our encoder?s vocabulary to words it has not seen during training.
Suppose we have a model that was trained to induce word representations, such as word2vec. Let
Vw2v denote the word embedding space of these word representations and let Vrnn denote the RNN
word embedding space. We assume the vocabulary of Vw2v is much larger than that of Vrnn . Our
goal is to construct a mapping f : Vw2v ? Vrnn parameterized by a matrix W such that v0 = Wv
for v ? Vw2v and v0 ? Vrnn . Inspired by [15], which learned linear mappings between translation
word spaces, we solve an un-regularized L2 linear regression loss for the matrix W. Thus, any word
from Vw2v can now be mapped into Vrnn for encoding sentences.

3

Experiments

In our experiments, we evaluate the capability of our encoder as a generic feature extractor after
training on the BookCorpus dataset. Our experimentation setup on each task is as follows:
? Using the learned encoder as a feature extractor, extract skip-thought vectors for all sentences.
? If the task involves computing scores between pairs of sentences, compute component-wise features between pairs. This is described in more detail specifically for each experiment.
? Train a linear classifier on top of the extracted features, with no additional fine-tuning or backpropagation through the skip-thoughts model.
We restrict ourselves to linear classifiers for two reasons. The first is to directly evaluate the representation quality of the computed vectors. It is possible that additional performance gains can be
made throughout our experiments with non-linear models but this falls out of scope of our goal. Furthermore, it allows us to better analyze the strengths and weaknesses of the learned representations.
The second reason is that reproducibility now becomes very straightforward.
3.1

Details of training

To induce skip-thought vectors, we train two separate models on our book corpus. One is a unidirectional encoder with 2400 dimensions, which we subsequently refer to as uni-skip. The other is
a bidirectional model with forward and backward encoders of 1200 dimensions each. This model
contains two encoders with different parameters: one encoder is given the sentence in correct order, while the other is given the sentence in reverse. The outputs are then concatenated to form a
2400 dimensional vector. We refer to this model as bi-skip. For training, we initialize all recurrent
matricies with orthogonal initialization [16]. Non-recurrent weights are initialized from a uniform
distribution in [-0.1,0.1]. Mini-batches of size 128 are used and gradients are clipped if the norm of
the parameter vector exceeds 10. We used the Adam algorithm [17] for optimization. Both models were trained for roughly two weeks. As an additional experiment, we also report experimental
results using a combined model, consisting of the concatenation of the vectors from uni-skip and
bi-skip, resulting in a 4800 dimensional vector. We refer to this model throughout as combine-skip.
After our models are trained, we then employ vocabulary expansion to map word embeddings into
the RNN encoder space. The publically available CBOW word vectors are used for this purpose
2
. The skip-thought models are trained with a vocabulary size of 20,000 words. After removing
multiple word examples from the CBOW model, this results in a vocabulary size of 930,911 words.
Thus even though our skip-thoughts model was trained with only 20,000 words, after vocabulary
expansion we can now successfully encode 930,911 possible words.
Since our goal is to evaluate skip-thoughts as a general feature extractor, we keep text pre-processing
to a minimum. When encoding new sentences, no additional preprocessing is done other than basic
tokenization. This is done to test the robustness of our vectors. As an additional baseline, we also
consider the mean of the word vectors learned from the uni-skip model. We refer to this baseline as
bow. This is to determine the effectiveness of a standard baseline trained on the BookCorpus.
3.2

Semantic relatedness

Our first experiment is on the SemEval 2014 Task 1: semantic relatedness SICK dataset [30]. Given
two sentences, our goal is to produce a score of how semantically related these sentences are, based
on human generated scores. Each score is the average of 10 different human annotators. Scores
take values between 1 and 5. A score of 1 indicates that the sentence pair is not at all related, while
2

http://code.google.com/p/word2vec/

4

r

?

MSE

Method

Acc

Illinois-LH [18]
UNAL-NLP [19]
Meaning Factory [20]
ECNU [21]

0.7993
0.8070
0.8268
0.8414

0.7538
0.7489
0.7721
?

0.3692
0.3550
0.3224
?

feats [24]
RAE+DP [24]
RAE+feats [24]
RAE+DP+feats [24]

73.2
72.6
74.2
76.8

83.6

Mean vectors [22]
DT-RNN [23]
SDT-RNN [23]
LSTM [22]
Bidirectional LSTM [22]
Dependency Tree-LSTM [22]

0.7577
0.7923
0.7900
0.8528
0.8567
0.8676

0.6738
0.7319
0.7304
0.7911
0.7966
0.8083

0.4557
0.3822
0.3848
0.2831
0.2736
0.2532

FHS [25]
PE [26]
WDDP [27]
MTMETRICS [28]
TF-KLD [29]

75.0
76.1
75.6
77.4
80.4

82.7
82.7
83.0
84.1
86.0

bow
uni-skip
bi-skip
combine-skip
combine-skip+COCO

0.7823
0.8477
0.8405
0.8584
0.8655

0.7235
0.7780
0.7696
0.7916
0.7995

0.3975
0.2872
0.2995
0.2687
0.2561

bow
uni-skip
bi-skip
combine-skip
combine-skip + feats

67.8
73.0
71.2
73.0
75.8

80.3
81.9
81.2
82.0
83.0

Method

F1

Table 3: Left: Test set results on the SICK semantic relatedness subtask. The evaluation metrics
are Pearson?s r, Spearman?s ?, and mean squared error. The first group of results are SemEval 2014
submissions, while the second group are results reported by [22]. Right: Test set results on the
Microsoft Paraphrase Corpus. The evaluation metrics are classification accuracy and F1 score. Top:
recursive autoencoder variants. Middle: the best published results on this dataset.
a score of 5 indicates they are highly related. The dataset comes with a predefined split of 4500
training pairs, 500 development pairs and 4927 testing pairs. All sentences are derived from existing
image and video annotation datasets. The evaluation metrics are Pearson?s r, Spearman?s ?, and
mean squared error.
Given the difficulty of this task, many existing systems employ a large amount of feature engineering
and additional resources. Thus, we test how well our learned representations fair against heavily engineered pipelines. Recently, [22] showed that learning representations with LSTM or Tree-LSTM
for the task at hand is able to outperform these existing systems. We take this one step further
and see how well our vectors learned from a completely different task are able to capture semantic
relatedness when only a linear model is used on top to predict scores.
To represent a sentence pair, we use two features. Given two skip-thought vectors u and v, we
compute their component-wise product u ? v and their absolute difference |u ? v| and concatenate
them together. These two features were also used by [22]. To predict a score, we use the same
setup as [22]. Let r> = [1, . . . , 5] be an integer vector from 1 to 5. We compute a distribution p
as a function of prediction scores y given by pi = y ? byc if i = byc + 1, pi = byc ? y + 1 if
i = byc and 0 otherwise. These then become our targets for a logistic regression classifier. At test
time, given new sentence pairs we first compute targets p? and then compute the related score as r> p?.
As an additional comparison, we also explored appending features derived from an image-sentence
embedding model trained on COCO (see section 3.4). Given vectors u and v, we obtain vectors u0
and v 0 from the learned linear embedding model and compute features u0 ? v 0 and |u0 ? v 0 |. These
are then concatenated to the existing features.
Table 3 (left) presents our results. First, we observe that our models are able to outperform all
previous systems from the SemEval 2014 competition. It highlights that skip-thought vectors learn
representations that are well suited for semantic relatedness. Our results are comparable to LSTMs
whose representations are trained from scratch on this task. Only the dependency tree-LSTM of [22]
performs better than our results. We note that the dependency tree-LSTM relies on parsers whose
training data is very expensive to collect and does not exist for all languages. We also observe
using features learned from an image-sentence embedding model on COCO gives an additional
performance boost, resulting in a model that performs on par with the dependency tree-LSTM. To
get a feel for the model outputs, Table 4 shows example cases of test set pairs. Our model is able to
accurately predict relatedness on many challenging cases. On some examples, it fails to pick up on
small distinctions that drastically change a sentence meaning, such as tricks on a motorcycle versus
tricking a person on a motorcycle.
3.3

Paraphrase detection

The next task we consider is paraphrase detection on the Microsoft Research Paraphrase Corpus [31]. On this task, two sentences are given and one must predict whether or not they are
5

Sentence 1

Sentence 2

GT

pred

A little girl is looking at a woman in costume
A little girl is looking at a woman in costume
A little girl is looking at a woman in costume

A young girl is looking at a woman in costume
The little girl is looking at a man in costume
A little girl in costume looks like a woman

4.7
3.8
2.9

4.5
4.0
3.5

A sea turtle is hunting for fish
A sea turtle is not hunting for fish

A sea turtle is hunting for food
A sea turtle is hunting for fish

4.5
3.4

4.5
3.8

A man is driving a car
There is no man driving the car

The car is being driven by a man
A man is driving a car

5
3.6

4.9
3.5

A large duck is flying over a rocky stream
A large duck is flying over a rocky stream

A duck, which is large, is flying over a rocky stream
A large stream is full of rocks, ducks and flies

4.8
2.7

4.9
3.1

A person is performing acrobatics on a motorcycle
A person is performing tricks on a motorcycle

A person is performing tricks on a motorcycle
The performer is tricking a person on a motorcycle

4.3
2.6

4.4
4.4

Someone is pouring ingredients into a pot
Nobody is pouring ingredients into a pot
Someone is pouring ingredients into a pot

Someone is adding ingredients to a pot
Someone is pouring ingredients into a pot
A man is removing vegetables from a pot

4.4
3.5
2.4

4.0
4.2
3.6

Table 4: Example predictions from the SICK test set. GT is the ground truth relatedness, scored
between 1 and 5. The last few results show examples where slight changes in sentence structure
result in large changes in relatedness which our model was unable to score correctly.

Model
Random Ranking
DVSA [32]
GMM+HGLMM [33]
m-RNN [34]
bow
uni-skip
bi-skip
combine-skip

R@1
0.1
38.4
39.4
41.0
33.6
30.6
32.7
33.8

COCO Retrieval
Image Annotation
R@5 R@10 Med r
0.6
1.1
631
69.6
80.5
1
67.9
80.9
2
73.0
83.5
2
65.8
79.7
3
64.5
79.8
3
67.3
79.6
3
67.7
82.1
3

R@1
0.1
27.4
25.1
29.0
24.4
22.7
24.2
25.9

Image Search
R@5 R@10
0.5
1.0
60.2
74.8
59.8
76.6
42.2
77.0
57.1
73.5
56.4
71.7
57.1
73.2
60.0
74.6

Med r
500
3
4
3
4
4
4
4

Table 5: COCO test-set results for image-sentence retrieval experiments. R@K is Recall@K (high
is good). Med r is the median rank (low is good).
paraphrases. The training set consists of 4076 sentence pairs (2753 which are positive) and the
test set has 1725 pairs (1147 are positive). We compute a vector representing the pair of sentences
in the same way as on the SICK dataset, using the component-wise product u ? v and their absolute
difference |u ? v| which are then concatenated together. We then train logistic regression on top to
predict whether the sentences are paraphrases. Cross-validation is used for tuning the L2 penalty.
As in the semantic relatedness task, paraphrase detection has largely been dominated by extensive
feature engineering, or a combination of feature engineering with semantic spaces. We report experiments in two settings: one using the features as above and the other incorporating basic statistics
between sentence pairs, the same features used by [24]. These are referred to as feats in our results.
We isolate the results and baselines used in [24] as well as the top published results on this task.
Table 3 (right) presents our results, from which we can observe the following: (1) skip-thoughts
alone outperform recursive nets with dynamic pooling when no hand-crafted features are used, (2)
when other features are used, recursive nets with dynamic pooling works better, and (3) when skipthoughts are combined with basic pairwise statistics, it becomes competitive with the state-of-the-art
which incorporate much more complicated features and hand-engineering. This is a promising result
as many of the sentence pairs have very fine-grained details that signal if they are paraphrases.
3.4

Image-sentence ranking

We next consider the task of retrieving images and their sentence descriptions. For this experiment,
we use the Microsoft COCO dataset [35] which is the largest publicly available dataset of images
with high-quality sentence descriptions. Each image is annotated with 5 captions, each from different annotators. Following previous work, we consider two tasks: image annotation and image
search. For image annotation, an image is presented and sentences are ranked based on how well
they describe the query image. The image search task is the reverse: given a caption, we retrieve
images that are a good fit to the query. The training set comes with over 80,000 images each with 5
captions. For development and testing we use the same splits as [32]. The development and test sets
each contain 1000 images and 5000 captions. Evaluation is performed using Recall@K, namely the
mean number of images for which the correct caption is ranked within the top-K retrieved results
6

(and vice-versa for sentences). We also report the median rank of the closest ground truth result
from the ranked list.
The best performing results on image-sentence ranking have all used RNNs for encoding sentences,
where the sentence representation is learned jointly. Recently, [33] showed that by using Fisher
vectors for representing sentences, linear CCA can be applied to obtain performance that is as strong
as using RNNs for this task. Thus the method of [33] is a strong baseline to compare our sentence
representations with. For our experiments, we represent images using 4096-dimensional OxfordNet
features from their 19-layer model [36]. For sentences, we simply extract skip-thought vectors for
each caption. The training objective we use is a pairwise ranking loss that has been previously
used by many other methods. The only difference is the scores are computed using only linear
transformations of image and sentence inputs. The loss is given by:
XX
XX
max{0, ? ? s(Ux, Vy) + s(Ux, Vyk )} +
max{0, ? ? s(Vy, Ux) + s(Vy, Uxk )},
x

y

k

k

where x is an image vector, y is the skip-thought vector for the groundtruth sentence, yk are vectors
for constrastive (incorrect) sentences and s(?, ?) is the image-sentence score. Cosine similarity is
used for scoring. The model parameters are {U, V} where U is the image embedding matrix and
V is the sentence embedding matrix. In our experiments, we use a 1000 dimensional embedding,
margin ? = 0.2 and k = 50 contrastive terms. We trained for 15 epochs and saved our model
anytime the performance improved on the development set.
Table 5 illustrates our results on this task. Using skip-thought vectors for sentences, we get performance that is on par with both [32] and [33] except for R@1 on image annotation, where other methods perform much better. Our results indicate that skip-thought vectors are representative enough
to capture image descriptions without having to learn their representations from scratch. Combined
with the results of [33], it also highlights that simple, scalable embedding techniques perform very
well provided that high-quality image and sentence vectors are available.
3.5

Classification benchmarks

For our final quantitative experiments, we report results on several classification benchmarks which
are commonly used for evaluating sentence representation learning methods.
We use 5 datasets: movie review sentiment (MR), customer product reviews (CR), subjectivity/objectivity classification (SUBJ), opinion polarity (MPQA) and question-type classification
(TREC). On all datasets, we simply extract skip-thought vectors and train a logistic regression classifier on top. 10-fold cross-validation is used for evaluation on the first 4 datasets, while TREC has
a pre-defined train/test split. We tune the L2 penality using cross-validation (and thus use a nested
cross-validation for the first 4 datasets).
Method

MR

CR

SUBJ

MPQA

TREC

NB-SVM [37]
MNB [37]
cBoW [6]

79.4
79.0
77.2

81.8
80.0
79.9

93.2
93.6
91.3

86.3
86.3
86.4

87.3

GrConv [6]
RNN [6]
BRNN [6]
CNN [4]
AdaSent [6]

76.3
77.2
82.3
81.5
83.1

81.3
82.3
82.6
85.0
86.3

89.5
93.7
94.2
93.4
95.5

84.5
90.1
90.3
89.6
93.3

88.4
90.2
91.0
93.6
92.4

Paragraph-vector [7]

74.8

78.1

90.5

74.2

91.8

bow
uni-skip
bi-skip
combine-skip
combine-skip + NB

75.0
75.5
73.9
76.5
80.4

80.4
79.3
77.9
80.1
81.3

91.2
92.1
92.5
93.6
93.6

87.0
86.9
83.3
87.1
87.5

84.8
91.4
89.4
92.2

On these tasks, properly tuned bag-ofwords models have been shown to perform exceptionally well. In particular,
the NB-SVM of [37] is a fast and robust performer on these tasks. Skipthought vectors potentially give an alternative to these baselines being just as
fast and easy to use. For an additional
comparison, we also see to what effect augmenting skip-thoughts with bigram Naive Bayes (NB) features improves performance 3 .

Table 6 presents our results. On most
tasks, skip-thoughts performs about as
well as the bag-of-words baselines but
Table 6: Classification accuracies on several standard bench- fails to improve over methods whose
marks. Results are grouped as follows: (a): bag-of-words mod- sentence representations are learned diels; (b): supervised compositional models; (c) Paragraph Vector rectly for the task at hand. This indicates
(unsupervised learning of sentence representations); (d) ours. that for tasks like sentiment classificaBest results overall are bold while best results outside of group tion, tuning the representations, even on
(b) are underlined.
small datasets, are likely to perform better than learning a generic unsupervised
3

We use the code available at https://github.com/mesnilgr/nbsvm

7

(a) TREC

(b) SUBJ

(c) SICK

Figure 2: t-SNE embeddings of skip-thought vectors on different datasets. Points are colored based
on their labels (question type for TREC, subjectivity/objectivity for SUBJ). On the SICK dataset,
each point represents a sentence pair and points are colored on a gradient based on their relatedness
labels. Results best seen in electronic form.
sentence vector on much bigger datasets. Finally, we observe that the skip-thoughts-NB combination is effective, particularly on MR. This results in a very strong new baseline for text classification:
combine skip-thoughts with bag-of-words and train a linear model.
3.6

Visualizing skip-thoughts

As a final experiment, we applied t-SNE [38] to skip-thought vectors extracted from TREC, SUBJ
and SICK datasets and the visualizations are shown in Figure 2. For the SICK visualization, each
point represents a sentence pair, computed using the concatenation of component-wise and absolute
difference of features. Even without the use of relatedness labels, skip-thought vectors learn to
accurately capture this property.

4

Conclusion

We evaluated the effectiveness of skip-thought vectors as an off-the-shelf sentence representation
with linear classifiers across 8 tasks. Many of the methods we compare against were only evaluated
on 1 task. The fact that skip-thought vectors perform well on all tasks considered highlight the
robustness of our representations.
We believe our model for learning skip-thought vectors only scratches the surface of possible objectives. Many variations have yet to be explored, including (a) deep encoders and decoders, (b) larger
context windows, (c) encoding and decoding paragraphs, (d) other encoders, such as convnets. It is
likely the case that more exploration of this space will result in even higher quality representations.
Acknowledgments
We thank Geoffrey Hinton for suggesting the name skip-thoughts. We also thank Felix Hill, Kelvin
Xu, Kyunghyun Cho and Ilya Sutskever for valuable comments and discussion. This work was
supported by NSERC, Samsung, CIFAR, Google and ONR Grant N00014-14-1-0232.

References
[1] Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and
Christopher Potts. Recursive deep models for semantic compositionality over a sentiment treebank. In
EMNLP, 2013.
[2] Sepp Hochreiter and J?rgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735?
1780, 1997.
[3] Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. A convolutional neural network for modelling
sentences. ACL, 2014.
[4] Yoon Kim. Convolutional neural networks for sentence classification. EMNLP, 2014.
[5] Kyunghyun Cho, Bart van Merri?nboer, Dzmitry Bahdanau, and Yoshua Bengio. On the properties of
neural machine translation: Encoder-decoder approaches. SSST-8, 2014.
[6] Han Zhao, Zhengdong Lu, and Pascal Poupart. Self-adaptive hierarchical sentence model. IJCAI, 2015.
[7] Quoc V Le and Tomas Mikolov. Distributed representations of sentences and documents. ICML, 2014.
[8] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation of word representations
in vector space. ICLR, 2013.
[9] Yukun Zhu, Ryan Kiros, Richard S. Zemel, Ruslan Salakhutdinov, Raquel Urtasun, Antonio Torralba, and
Sanja Fidler. Aligning books and movies: Towards story-like visual explanations by watching movies and
reading books. In ICCV, 2015.

8

[10] Nal Kalchbrenner and Phil Blunsom. Recurrent continuous translation models. In EMNLP, pages 1700?
1709, 2013.
[11] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk, and Yoshua
Bengio. Learning phrase representations using rnn encoder-decoder for statistical machine translation.
EMNLP, 2014.
[12] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural networks. In
NIPS, 2014.
[13] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning
to align and translate. ICLR, 2015.
[14] Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. Empirical evaluation of gated
recurrent neural networks on sequence modeling. NIPS Deep Learning Workshop, 2014.
[15] Tomas Mikolov, Quoc V Le, and Ilya Sutskever. Exploiting similarities among languages for machine
translation. arXiv preprint arXiv:1309.4168, 2013.
[16] Andrew M Saxe, James L McClelland, and Surya Ganguli. Exact solutions to the nonlinear dynamics of
learning in deep linear neural networks. ICLR, 2014.
[17] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. ICLR, 2015.
[18] Alice Lai and Julia Hockenmaier. Illinois-lh: A denotational and distributional approach to semantics.
SemEval 2014, 2014.
[19] Sergio Jimenez, George Duenas, Julia Baquero, Alexander Gelbukh, Av Juan Dios B?tiz, and Av Mendiz?bal. Unal-nlp: Combining soft cardinality features for semantic textual similarity, relatedness and
entailment. SemEval 2014, 2014.
[20] Johannes Bjerva, Johan Bos, Rob van der Goot, and Malvina Nissim. The meaning factory: Formal
semantics for recognizing textual entailment and determining semantic similarity. SemEval 2014, page
642, 2014.
[21] Jiang Zhao, Tian Tian Zhu, and Man Lan. Ecnu: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment. SemEval 2014, 2014.
[22] Kai Sheng Tai, Richard Socher, and Christopher D Manning. Improved semantic representations from
tree-structured long short-term memory networks. ACL, 2015.
[23] Richard Socher, Andrej Karpathy, Quoc V Le, Christopher D Manning, and Andrew Y Ng. Grounded
compositional semantics for finding and describing images with sentences. TACL, 2014.
[24] Richard Socher, Eric H Huang, Jeffrey Pennin, Christopher D Manning, and Andrew Y Ng. Dynamic
pooling and unfolding recursive autoencoders for paraphrase detection. In NIPS, 2011.
[25] Andrew Finch, Young-Sook Hwang, and Eiichiro Sumita. Using machine translation evaluation techniques to determine sentence-level semantic equivalence. In IWP, 2005.
[26] Dipanjan Das and Noah A Smith. Paraphrase identification as probabilistic quasi-synchronous recognition. In ACL, 2009.
[27] Stephen Wan, Mark Dras, Robert Dale, and C?cile Paris. Using dependency-based features to take the
"para-farce" out of paraphrase. In Proceedings of the Australasian Language Technology Workshop, 2006.
[28] Nitin Madnani, Joel Tetreault, and Martin Chodorow. Re-examining machine translation metrics for
paraphrase identification. In NAACL, 2012.
[29] Yangfeng Ji and Jacob Eisenstein. Discriminative improvements to distributional sentence similarity. In
EMNLP, pages 891?896, 2013.
[30] Marco Marelli, Luisa Bentivogli, Marco Baroni, Raffaella Bernardi, Stefano Menini, and Roberto Zamparelli. Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment. SemEval-2014, 2014.
[31] Bill Dolan, Chris Quirk, and Chris Brockett. Unsupervised construction of large paraphrase corpora:
Exploiting massively parallel news sources. In Proceedings of the 20th international conference on Computational Linguistics, 2004.
[32] A. Karpathy and L. Fei-Fei. Deep visual-semantic alignments for generating image descriptions. In
CVPR, 2015.
[33] Benjamin Klein, Guy Lev, Gil Sadeh, and Lior Wolf. Associating neural word embeddings with deep
image representations using fisher vectors. In CVPR, 2015.
[34] Junhua Mao, Wei Xu, Yi Yang, Jiang Wang, and Alan Yuille. Deep captioning with multimodal recurrent
neural networks (m-rnn). ICLR, 2015.
[35] Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll?r,
and C Lawrence Zitnick. Microsoft coco: Common objects in context. In ECCV, pages 740?755. 2014.
[36] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. ICLR, 2015.
[37] Sida Wang and Christopher D Manning. Baselines and bigrams: Simple, good sentiment and topic classification. In ACL, 2012.
[38] Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. JMLR, 2008.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

