query sentence: deployment of fault tolerant clouds
---------------------------------------------------------------------
title: 2508-parameterized-novelty-detectors-for-environmental-sensor-monitoring.pdf

parameter novelti detect environment sensor monitor cynthia archer todd k. leen antonio baptista ogi school scienc engin oregon health scienc univers n. w. walker road beaverton archer cse.ogi.edu tleen cse.ogi.edu baptista ccalmr.ogi.edu abstract part environment observ forecast system sensor deploy columbia river estuari cori gather inform physic dynam chang estuari habitat salin sensor particular suscept biofoul gradual degrad sensor respons corrupt critic data automat fault detector capabl identifi bio-foul earli minim data loss complic develop discriminatori classifi scarciti bio-foul onset exampl variabl bio-foul signatur solv problem take novelti detect approach incorpor parameter bio-foul model detector identifi occurr bio-foul onset time reliabl human expert real-tim detector instal summer produc fals alarm yet detect episod sensor degrad field staff schedul sensor clean initi deploy februari bio-foul detector essenti doubl amount use data come cori sensor introduct environment observ forecast system eof gather process deliv environment inform facilit sustain develop natur resourc work part pilot eof system develop columbia river estuari cori system use data sensor deploy throughout estuari figur calibr verifi numer model circul materi transport cori scientist use model predict evalu effect develop estuari environ cori salin sensor deploy estuari lose sever month data everi year due sensor degrad corrupt miss field measur compromis model calibr verif lead invalid environment forecast common form salin sensor degrad bio-foul reduct sensor respons due growth biolog materi sensor prior deploy technolog describ year basi cori salin sensor suffer data loss due bio-foul although bio-foul degrad common problem environment sensor appar previous work develop automat detector degrad figur map columbia river estuari mark locat cori sensor earli bio-foul detect made difficult normal variabl salin measur tide caus measur vari near river salin near ocean salin twice day tempor pattern salin penetr vari spatial estuari addit upriv site show substanti variabl day spring-neap tidal cycl chang weather wind precipit ocean condit caus addit variat salin complic bio-foul detect bio-foul signatur also vari episod episod time onset complet bio-foul take anywher week month depend season type growth observ two type bio-foul estuari hard growth barnacl character quick linear degrad soft growth plant materi character slow linear degrad occasion interrupt downtrend figur illustr tidal variat salin effect bio-foul measur contain salin time seri practic salin unit psu two sensor mount red26 station figur upper trace sensor contain clean measur lower trace sensor contain clean bio-foul measur first half two time seri similar begin septemb salin measur diverg sensor exhibit typic hard-growth bio-foul degrad primari challeng work detect degrad quick ideal within sever diurnal cycl earli detect limit use corrupt data on-lin applic provid basi rapid replac degrad sensor thus drastic reduc data loss although cori data archiv contain mani month bio-foul data relat exampl onset degrad sensor salin salin date month/day figur clean bio-foul salin time seri exampl red26 station upper time seri clean instrument lower time seri instrument show degrad begin septemb remov found bio-foul deploy estuari onset must detect dearth onset exampl observ variabl bio-foul signatur spatial season week accord spring/neap tidal cycl prevent use classic discriminatori fault detector instead develop parameter novelti detector detect bio-foul detector incorpor parameter model bio-foul behavior paramet model bio-foul sensor behavior fit on-lin maximum-likelihood estim model clean sensor behavior fit archiv data model use sequenti likelihood test provid detect bio-foul estim time degrad began evalu show detector identifi onset bio-foul reliabl human expert frequent within fewer tidal cycl onset deploy sensor throughout estuari result actual reduct error loss howev figur adequ reflect efficaci detector econom replac sensor immedi upon detect degrad data loss would reduc salin temperatur detector monitor maximum diurnal salin defin maximum salin near one two diurnal tidal flood sensor clean md salin stay close mean valu occasion dip sever psu caus variat intrus salt water estuari sensor biofoul md salin gradual decreas typic less half normal mean valu seen figur exampl detector monitor salin alon distinguish normal decreas salin earli bio-foul result high fals alarm rate natur salin decreas recogn monitor correl sourc inform corrupt bio-foul salin temperatur station product mix process ocean river water expect valu correl assum linear mix ocean river water measur salin sm temperatur tm linear function ocean river sr tr valu sm tm mix coeffici time river salin sr close zero consequ estim mix coeffici tr tr well correl salin sm so river temperatur measur far upstream station elliot woodi ocean temperatur estim measur sand island outermost sensor station bio-foul detect earli experi single-measur detect suggest develop detector accru inform time similar standard sequenti likelihood method classic pattern recognit natur framework detect degrad grow time assum sequenc measur salin temperatur yn current time construct probabl densiti sequenc clean sensor yn biofoul sensor yn distribut construct likelihood ratio test yn yn threshold chosen high enough provid specifi fals alarm rate neyman-pearson test assum probabl densiti measur sequenc foul detector parameter vector unknown paramet model construct densiti sequenc assum foul detector equal densiti sequenc assum clean detector yn yn next suppos given sequenc contain bio-foul event initi unknown time densiti model consecut measur sequenc independ condit state detector equival alarm threshold increas maintain low fals alarm rate rate proper detect decreas consequ likelihood ratio sequenc reduc yn yn yn yn p yn p yn final fit foul model paramet onset time maxim log-likelihood yn respect sinc clean detector model independ equival maxim log-likelihood ratio henc replac latter max p yn p yn if sequenc come clean sensor fit give henc cf detect event assum construct variant type signal chang detect discuss bassevill bio-foul fault model parameter bio-foul model abl develop detector use clean exampl data parameter novelti detector bio-foul paramet fit on-lin data test develop classifi first defin model clean bio-foul data model true salin temperature-bas mix coeffici joint gaussian provid regress salin probabl md salin measur condit temperatur sensor clean gaussian condit mean condit varianc when bio-foul occur salin measur suppress relat true valu model suppress linear downtrend unknown rate slope begin unknown time model measur md salin valu foul detector g n sn suppress factor n bio-foul rate use suppress factor probabl salin measur condit temperatur p xn note sinc temperatur sensor suscept bio-foul need consid case sensor degrad time discrimin function depend paramet clean model estim histor data also depend slope paramet foul model onset time fit onlin per appli gaussian model give us n max n n when chosen threshold detector signal biofoul sensor threshold set provid maximum fals alarm rate histor data model fit find maximum likelihood estim clean archiv timep seri data yn sn train valu mean given n1 yn covari matrix n1 yn classifi paramet valu extract or calcul time step determin maximum likelihood estim onset time bio-foul rate data test find maximum likelihood estim bio-foul rate onset time set first deriv respect equal zero oper yield relat xk xk k current time note appear begin definit so close form solut howev valu act weight increas import recent measur this weight account expect decreas measur varianc bio-foul progress estim take iter approach first initi minimum mean-squar error valu given pn pn second repeat solv calcul use previous valu estim rate valu stop chang when reach maximum if set window length maxim log likelihood ratio best estim onset time determin onset time estim search past time valu maxim possibl window length determin maximum likelihood estim calcul correspond discrimin estim onset time window length give largest valu if this threshold current measur classifi bio-foul on-lin bio-foul detector see well classifi work practic implement version oper real-tim salin temperatur measur four instanc max sal max sal sensor degrad three bio-foul incid one instrument failur mimick bio-foul occur summer test period our classifi correct indic sensor problem field staff awar addit real-tim classifi produc fals alarm summer test period in-depth discuss detector suit given archer al date slr slr date red26 tansi point figur bio-foul indic red26 tansi point top plot show maximum diurnal salin dot line indic histor fals alarm lower fals alarm rate upper field staff schedul sensor clean when maximum salin drop low rough fals alarm level bottom plot show sequenti likelihood discrimin forti day salin temperatur measur dot line indic histor fals alarm upper fals alarm rate lower indic estim bio-foul onset time on-lin monitor display bio-foul indic previous forti day data figur show on-lin bio-foul monitor incid red26 sensor tansi point sensor sinc we anoth sensor mount red26 site bio-foul figur we abl estim bio-foul time septemb our detector discrimin pass fals alarm threshold five day onset rough three day field staff decid instrument need clean this reduct time detect correspond reduc data loss addit onset time estim septemb within day true onset time tansi point sensor began bio-foul day red26 sensor our detector indic tansi point sensor bio-foul octob 9th sinc neighbor sensor red26 replac octob field staff decid retriev tansi point sensor as well on remov this sensor found earli stage bio-foul this case indic our classifi permit sensor replac field staff would normal schedul it retriev experi our on-lin bio-foul indic demonstr these method substanti reduc time biofoul onset detect addit event describ we fair extens experi onlin detector sinc initi deploy spring at this write we bio-foul detector at observ station estuari experi event throughout year near end octob we experienc fals alarm sensor near surfac lower estuari in this case steadi downward trend in surfac salin caus sever day rain trigger detector respons follow cessat precipit discrimin function return back sub-threshold level in recent februari studi five sensor station in estuari we compar data loss prior deploy bio-foul detector data loss postdeploy pre-deploy period includ approxim four year data the summer the post-deploy period ran spring/summ februari neglect season variat prior the deploy our detector the sensor data corrupt bio-foul follow deploy the rate data loss due bio-foul drop to this the actual data loss includ delay in respond to the event detect were it econom to replac the sensor immedi upon detect bio-foul the data loss rate would drop farther to even the delay in respond to event detect the detector more doubl the amount reliabl data collect the estuari discuss cori salin sensor lose sever month data everi year due to sensor biofoul develop discriminatori fault detector these sensor hamper the variabl the bio-foul time-signatur the dearth bio-foul onset exampl data train to solv this problem we built parameter novelti detector clean sensor model were develop base on archiv data biofoul sensor model given simpl parametr form fit onlin on-lin bio-foul detector deploy the summer detect all episod sensor degrad sever day the field staff without generat fals alarm expand instal a suit detector throughout the estuari continu to success detect bio-foul with minim fals alarm intrus the detector deploy effect doubl the amount clean data avail from the estuari salin sensor acknowledg we thank member the cori team arun chawla charl seaton for help in acquir appropri sensor data michael wilkin for assist in label the sensor data haim zheng for carri forward the sensor develop deploy provid the comparison of data loss rate the detector deploy this work support by the nation scienc foundat under grant
----------------------------------------------------------------

title: 228-synergy-of-clustering-multiple-back-propagation-networks.pdf

lincoln skrzypek synergi cluster multipl back propag network william p. lincoln josef skrzypekt ucla machin percept laboratori comput scienc depart los angel ca abstract properti cluster multipl back-propag network examin compar perform singl bp network under idea synergist effect within cluster improv perfonn fault toler five network initi train perfonn input-output map follow train cluster creat comput averag output generat individu network output cluster use desir output train feed back individu network comparison singl bp network cluster multipl bp 's general signific fault toler appear cluster advantag follow simpl maxim fool singl bp 's cluster time fool time lincoln introduct shortcom back-propag supervis learn well document past souli bernasconi often network finit size learn particular map complet general poor increas size number hidden layer often lead improv souli also hugh aircraft compani correspond address synergi cluster multipl back propag network central question paper address whether synergi cluster multipl back-prop net improv properti cluster system compar complex non-clust system use formul back-prop given rumelhart cluster shown figur start five three-lay back propag network learn perform input-output map initi net given differ start weight thus learn individu net expect differ intern represent input cluster rout net net comput output judg use output yk form cluster output mani way form sake simplic paper we consid follow two rule simpl averag yk k=l convex combin wkyk k=l cluster function add extra level fault toler give judg abil bias output base past reliabl net wk adjust take account recent reliabl net one weight adjust rule ek gain adjust ek k=l ek i iy yk i i network deviat cluster output also absenc wk initi train period perfect teacher cluster collect selforgan cluster case perform averag map individu network perform base initi distribut weight simul done verifi self organ fact occur simul converg occur pass besid improv learn general cluster network display desir characterist fault toler self-organ feed back cluster 's output individu network desir output train endow cluster fault toler absenc teacher feed back also make cluster continu adapt chang condit aspect cluster similar track capabl adapt equal after initi train period usual assum teacher present teacher present relat infrequ interv howev failur rate larg enough perfonn singl non-clust net degrad period teacher present cluster feedback increas fault toler absenc perfect teacher teacher present use desir output use continu train individu net general correc error backpropag dk y-yk differ actual error dk yk dk dk differ signific error individu net thus cluster whole increas lincoln skrzypek time phenomenon call drift drift retrain use desir output may seem disadvantag fault exist within net possibl drift decreas train net suffici small error fact circumst suffici small error possibl see error decreas even we assum fault exist retrain becom advantag failur rate network node suffici low injur net retrain use judg 's output mani net cluster effect injur net 's output cluster output minim retrain use add fault toler caus drift if net complet learn teacher remov cluster figur cluster back-prop net experi al method test idea outlin paper abstract learn problem chosen abstract problem use becaus mani neural network problem requir similar separ classif group topolog equival set process learn lippman instanc imag categor accord characterist input 3-dimension point problem categor point one eight set set sphere radius center input layer consist three continu node size output layer node train indic function associ sphere one hidden layer use full connect layer five net specif use form cluster general test use point outsid sphere synergi cluster multipl back propag network cluster advantag perform singl net compar perform five net cluster net retrain use network cluster structur size singl network averag error two system compar use measur cluster advantag obtain take ratio individu net error cluster error ratio smaller larger depend relat magnitud cluster individu net 's error figur 2a 2b show cluster advantag plot versus individu net error train pass respect seen individu net either learn task complet n't learn cluster advantag howev task learn even margin cluster advantag i pass i i pass error error figur cluster advantag versus error data point one learn task shown after train pass mter train pass cluster 's increas learn base synergi individu network larger size cluster compar individu network individu net error depend size hidden layer length train period howev general error decreas function size hidden layer throughout domain increas size hidden layer alway result decreas error may due direct credit assign smaller number node figur 4a 4b show individu net 's error versus hidden layer size differ train pass point pedagog counter anticip argument cluster lower error base fact node lincoln skrzypek pass pass number hidden unit number hidden unit figur error singl bp network nonlinear funtion number hidden node after train pass after train pass fault toler judg 's output desir output retrain individu network fault toler ad fault toler capabl cluster studi size hidden layer after net train failur rate link cluster per input introduc failur rate term singl unclust net link per input link chosen fail cluster random select link network cluster link fail weight set link net judg consid immun fault comparison pass consist present random point each sphere figur show fault toler capabl cluster know behavior singl net presenc fault fault toler behavior convent configur comparison spare singl net determin form fault toler compar convent fault toler scheme synergi cluster multipl back propag network numb.r train figur fault toler cluster use feedback judg desir train output error function time train pass without link failur solid circl link failur open cirl link failur rate cluster link per input singl net link per input conclus cluster multipl back-prop net shown increas perform fault toler singl network cluster exhibit interest self organ preliminari investig restrict simpl exampl nevertheless interest result appear rather general thus expect remain valid much larger complex system cluster idea present this paper specif back-prop appli net train supervis learn rule result this paper view enlighten way given set weight cluster perform map there empir evid local minimum this map space initi point map space taken when cluster output begin fed back each time new cluster output fed back point map space move step size relat step size back prop algorithm each task conjectur local minimum map space if point move away desir local minimum drift occur fault move point away local minimum feedback move point closer local minimum self organ view find local minimum valley point initi place base initi distribut weight lincoln skrzypek numb.r trllnlng figur cluster continu learn in absenc teacher if feedback judg use desir train output link failur interpretanon result result previous section interpret viewpoint model describ in this section this model attempt describ state net chang due possibl incorrect error term back-propag in turn state net determin perform state net could defin weight string given weight string there dualiti map net perform error when net train toward particular map current weight string determin error the net the back-propag algorithm use chang the weight string the error decreas the dualiti time net perform map it may the desir map it perfon map no error this dualiti signific in connect selforgan view take averag the map synergi cluster multipl back propag network while the state net could defin by weight string state transit due backward error propag obvious use definit the state net error the error estim by take a repres sampl input vector propag the net comput the averag error the output have defin the state a descript the state transit rule given output net state net input state net state net output net output net n delta error error error cluster mistak i correct output cluster output i this model say posit constant a delta error a cluster mistak this equat the properti the error increas decreas proport the size the cluster mistak the equilibrium when the mistak equal b an assumpt made an individu net 's mistak a guassian random variabl zj with mean varianc equal to error the purpos this analysi the judg use a convex combin the net output to form the cluster output use the assumpt this i1vjdel it shown a strategi increas the relat weight in the convex combin of a net a relat small error convers decreas the relat weight for poor perform net an exampl weight adjust rule this rule the effect of increas the weight of a network produc a network deviat smaller averag the opposit effect seen for a network produc a network deviat larger averag
----------------------------------------------------------------

title: 344-neural-network-application-to-diagnostics-and-control-of-vehicle-control-systems.pdf

neural network applic diagnost control vehicl control system kenneth a. marko research staff ford motor compani dearborn michigan abstract diagnosi fault complex real-tim control system complic task resist solut tradit method shown neural network success employ diagnos fault digit control powertrain system paper discuss mean use develop appropri databas train test order select optimum network architectur provid reason estim classif accuraci network new sampl data recent work appli neural net adapt control activ suspens system present introduct paper report work perform applic artifici neural system an techniqu diagnosi control vehicl system specif examin diagnosi common fault powertrain system investig problem develop adapt control activ suspens system diagnost investig util neural network routin establish standard diagnost accuraci expect analysi vehicl data previous examin use various an paradigm diagnosi wide rang fault care collect data set vehicl oper narrow rang speed load subsequ explor classif data set restrict set fault drawn much broader rang oper condit step taken concern need specif real-tim continu diagnost supersed need develop well-control on-demand diagnost test marko impetus aris recent enact legisl dictat real-tim diagnosi powertrain system req uir car sold u.s. differ two applic simpl former studi presum independ agent identifi fault present root caus need identifi real-tim problem diagnost task detect identifi fault soon occur consequ real-tim applic demand analyz difficult task explor complic aris develop success classif scheme virtual semi-infinit data stream prcxjuce continu oper vehicl fleet obstacl realiz applic neural net area often stem sophist requir classifi complex problem address limit comput resourc on-board vehicl determin scope diagnost task implement an method oper final briefli examin extens an work develop trainabl control non-linear dynam system activ suspens system preliminari work area indic effecti control non-linear plant develop effici despit exclus accur plant model train process although studi carri simul accur plant model therefor avail capabl develop control absenc model signific step forward control develop exist unmodel hardwar therebi reduc effort requir develop control algorithm convent mean time program real-tim control neural net diag~ost control system interest neural network diagnosi fault control system stem work model-bas diagnosi fault system typic call plant model-bas approach model system control develop use predict dynam behavior system system oper plant perform observ expect behavior observ behavior compar differ found plant deem oper normal deviat found differ indic fault sort present failur detect analysi differ use attempt identifi caus fault identif success implemem liubakka al rizzoni ai fault detect identif complex system linear select oper point put togeth util mathemat construct call failur detect filter filter simpli matric transform set observ becom input vector filter plant anoth vector space output vector classif space form filter suggest us neural network could use learn similar transform therebi avoid tedious process model develop valid priori identif detect filter matrix element show previous complex signal pattern oper intern combust engin could examin cycl cycl basi two revolut common four-strok engin cycl use correct identifi fault present engin marko el typic data collect oper engin shown elsewher marko demonstr focuss product engin limit small neural network applic diagnost oper rang one might suppos linear model-bas diagnost system could construct task one wish expend time effort therefor exercis strenuous test neural network approach addit expert diagnostician could examin data trace accur identifi fault howev demonstr problem elud autom solut mean time could easili handl neural network classifi encourag us proceed difficult problem effici rigor procedur exist prepar toler develop empir solut difficult problem sinc expect thorough analyt understand would preced demonstr solut process outlin util neural network analysi almost exclus predomin back-propag problem understand relationship neural network structur data train test classifi emerg accept solut use neural network method obtain consequ next problem address identifi similar fault observ system multiplex serial communic link resid engin control comput serial link provid simpl hook-up procedur vehicl without sever link plant microcontrol howev chief drawback approach great complic recognit task complic aris data plant sampl infrequ contamin process control deliv asynchron serial link respect event plant data output process permit interrupt real-tim control requir case test sampl smaller number fault drawn vehicl oper similar limit rang first exampl attempt detect identifi fault made use varieti network unlik previous case imposs experienc technician identifi fault neural network classifi found develop satisfactori solut limit data set later verifi number care statist test marko el ai complex problem also produc wider rang perform among various neural ne.t paradigm studi shown figur i. error rate various classifi data set shown graph result suggest would data qualiti quantiti need control improv problem would implicit direct us choic classifi paradigm issu thorough discuss elsewher marko al weiss conclus complet accept solut real scope problem could develop group 's resourc data collect data verif classifi valid two experi mind could see first approach effect mean handl failur detect identif fdi problem latter although attract standpoint easi link-up vehicl numer analysi difficult task seem appropri cours obtain reliabl data observ plant direct perfonn classif data effect scheme accomplish goal perfonn classif task control microprocessor access dire data adopt strategi move diagnost off-board processor on-board processor creat new set possibl diagnost marko diagnost contain control processor diagnost shift on-demand activ undertaken predetermin interv vehicl oper detect problem continu real-tim activ chang impli diagnost algorithm part evalu proper oper system infrequ requir detect failur identifi caus addit diagnost algorithm compact sinc current control microprocessor limit time memori calcul compar off-board pc furthermor classif task need learn sampl data minuscul compar data set deploy diagnost classifi fact impos train data set requir accur statist sampl much volumin real-world data situat must prevail anticip deploy classifi mal undergo continu train classifi capabl continu adapt would requir comput capabl quit like supervis learn environ fact even relat simpl diagnost oper engin assembl larg accur train data set off-lin consider task last issu explor next paragraph seem rule earli deploy anyth pretrain classifi experi much larger data set deploy diagnost system obtain error rate pin data dcldata n.n rcesingl rcemult back prop treehyppl tree c.r classifi figur i comparison perform various neural network paradigm two static data set leave~ne~ut test measur perform vehicl servic bay network paradigm test arc nearest neighbor restrict coulomb energi crce singl unit rce multipl unit backpropag tree classifi use hyperplan separ tree classifi use center-radius decis surfac 6o-pin data data obtain direct engin dcl data communic link data come control microprocessor multiplex two-wir link note rce-multipl requir priori knowledg problem unavail dcl data thal complet statist test backpropag impract due length time requir train network neural network applic diagnost examin issu real-tim diagnost it appli engin misfir detect identif data nonnal misfir engin requir wide rang condit task consum hour test track drive set measur taken extens order cenain infonn obtain superset minimum set informalion requir addit great care need exercis eslablish accuraci train set supervis learn specif need certain sampl misfir includ intent creat occur spontan presum mislabel normal intent fault introduc time order accomplish purif train set one must either independ detector misfir none exist product engin oper vehicl go iter process remov data vector misclassifi misfir data set network complet train sinc independ assess misfir obtain must accept latter method altogeth satisfactori problem iter method one must initi exclud train set exact type event system train classifi stan assumpt addit misfir beyond number introduc classif error reserv right amend judgment light experi build confid classifi result initi studi shown here see backpropag neural network classifi broad rang engin oper correct thal network quit well broaden oper rang almost perfonn limit engin classif error indic exhaust studi misfir detect misfir introduc at this stage investig certain real error may well misfir occur spontan appear result addit unintent induc misfrr engin cycl follow one fault introduc result shown therefor repres conserv estim classif error thal expect test engin data backpropag network construct demonstr misfir detect identif attain if adequ comput resourc avail appropri limit opera non extend opera non normal normal misfir misfir ansclass normal misfir normal misfir figur classif accuraci backpropag neural network train misfir data tabul confus matric data similar shown collect modest rang dynam condit wide rang condit pothol road sever acceler brake etc estim perform limit classifi data misclassif rate indic best possibl perfonn obtain data therefor reason estim practic implement classifi produc marko care obtain suitabl train set exercis howev order make neural net practic mean perform this diagnosi aboard vehicl we need ehmin inform input vector effect classif accuraci otherwis comput task hopeless beyond capabl engin microcontrol this work current underway use combin priori knowledg sensor inform princip compon analysi data set nonetheless neural network analysi establish solut exist set standard classif accuraci we hope emul compact form classifi neural net control activ suspens empir approach develop solut diagnost problem suggest similar tactic might employ effect control problem develop accept control non-linear dynam system convent mean daunt task we wish explor applic feed-forward network problem learn control model non-linear activ suspens system this problem interest consider effort gone design control convent mean perform comparison could readili made addit sinc activ suspens system investig number compani we wish examin possibl develop model-independ control system sinc effect hardwar system usual avail thorough valid system model appear initi result this investig outlin quit encourag backpropag network train emul exist control activ suspens first exercis establish feel complex network requir perform task complet descript work found elsewher hampo briefli network seve.r hidden node train provid perfonn equival convent control sinc this exercis simpli replic exist control next step develop control the absenc convent control therefor system model novel non-linear develop util train neural network control plant the architectur this control system similar use nygen widrow ngyen al describ detail elsewher hampo onc again backpropag network hidden node train provid satisfactori perform in control the suspens system simul run workstat this small network learn the task with less woo train vector the equival less feet bumpi road final we examin the perform the neural network the plant without explicit use the plant model in the control architectur in this scheme the output error deriv the differ the observ perform the desir perform produc cost function base upon convent measur suspens perform in this cost function architectur network similar size readili train control non-linear plant attain perform equival convent control hand-tun plant control develop in this manner provid a flexibl mean approach the problem investig tradeoff the conflict demand made such suspens system these demand neural network applic diagnost includ ride qualiti vehicl control energi manag this control architectur appli simul new system actual un-model hardwar rig expedit prototyp develop conclus this brief summari our investig shown neural network play an import role in the develop classif system diagnosi fault in control system control practic non-linear plant in these task neural network must compet with convent method convent method although endow with a thorough analyt understand usual fail provid accept solut the problem we encount readili the neural network method therefor the an method a crucial role in develop solut although neural network provid these solut expediti we begin understand these solut aris the growth of this understand detennin the role neural network play in the deploy implement of these solut
----------------------------------------------------------------

title: 1377-bidirectional-retrieval-from-associative-memory.pdf

bidirect retriev associ memori friedrich t. sommer gunther palm depart neural inform process univers ulm ulm germani sommer palm ~informatik.uni-ulm.d abstract similar base fault toler retriev neural associ memori am lead wiedespread applic drawback effici willshaw model spars pattern high asymptot inform capac littl practic use high cross talk nois aris retriev finit size here new bidirect iter retriev method willshaw model present call crosswis bidirect retriev provid enhanc perform discuss asymptot capac limit analyz first step compar experi willshaw model appli effici cb memori model either inform retriev system function model reciproc cortico-cort pathway requir robust random nois input our experi show also segment abil cb-retriev address contain superposit patten provid even high memori load introduct technic point view neural associ memori am provid data storag retriev neural model natur impli parallel implement storag retriev algorithm correspond synapt modif neural activ distribut code data recal am model fault toler robust nois superposit address local damag synapt weight matrix biolog model am f. t. sommer g. palm propos general work scheme network pyramid cell mani place cortex import properti nam model inform capac measur effici synapt weight use earli sixti steinbuch realiz name lernmatrix memori model binari synaps known will haw model ste6i great varieti nam model propos sinc mani trigger hopfield 's work reach high asymptot inform capac willshaw model finit network size willshaw model optim retriev store inform sinc inner product matrix colum input pattern determin activ output neuron independ autoassoci pattern complet iter retriev reduc cross talk nois simpl bidirect iter bidirect associ memori bam howev improv heteroassoci pattern map task propos cb-retriev retriev step form result activ pattern autoassoci process use connect matrix twice threshold therebi exploit store inform effici willshaw model cb extens here pattern map task xv yv consid set memori pattern xv o n yv number i-compon pattern call pattern activ willshaw model work effici memori spars memori pattern activ ixvi lyvl yi nand dure learn set memori pattern transform weight matrix cij min i xiv supxiy'j given initi pattern xj1 retriev yield output pattern form neuron dendrit sum ci/if calcul activ valu threshold comparison yj xj1.j vj global threshold valu denot heavisid function finit size high memori load pi prob cij willshaw model provid toler respect error address see bidirect iter standard simpl retriev propos bam model therefor rule retriev error reduct energi function willshaw bam lcijxiyj ij lxi lyj indroduc factor account magnitud dendrit potenti acti vate neuron bidirect retriev associ memori differenti energi function yield gradient descent equat yr lci cikxi yk cxu wjk x~ew ct lpiicljyi xl i new term sum pattern compon weight quantiti wjk wft occur wjk overlap matrix column condit pattern call condit link y-unit restrict condit link term yield new iter retriev scheme denot crosswis bidirect retriev i i cij ct cij cx r-i j iex r iey r pattern replac boolean and result timestep appli shown improv iter retriev willshaw model autoassoci model evalu two possibl retriev error type distinguish miss error convert i-entri add error opposit simpl add error add error cb-r miss error figur mean retriev error rate correspond memori load x-ax display address activ lilll correspond errorfre learn pattern lower activ due miss error higher activ due add error left theori add error simpl retriev eq upper curv lower bound first step cb-retriev eq right simul error simpl cb retriev analysi simpl retriev address yield optim threshold set add error rate expect spurious one b prob f. t. sommer g. palm binomi random variabl prob r=l b lit'i pt i denot add error rate lit'l number correct address first step cb-retriev lower bound add error rate deriv analysi cb-retriev fix address iij perfect learn pattern ylj start pattern y-iayer case add error rate random variabl rl r2 distribut prob rl lib prob b ab pi thus pdsbs pi bs binomi sum analyt result first step compar simul left versus right diagram experi simpl retriev perform threshold cb-retriev iter y-iayer fix address start three random chosen simpl retriev result iter stop stabl pattern threshold bk reach memori capac calcul per pattern compon assumpt memori pattern compon independ probabl a/n b/m respect probabl add miss error simpli renorm rate denot x-pattern y-pattern inform store pattern contain noisi initi retriev pattern given transinform shannon inform condit inform heteroassoci map evalu output capac mm unit bit/synaps depend initi nois sinc perform drop grow initi error assum maximum fault toler provid noiseless initi pattern see autoassoci complet distort x-pattern evalu complet capac mn p bam map complet time therefor evalu search capac asymptot capac willshaw model strike high complet capac autoassoci map capac heteroassoci input nois bit/syn lead valu search capac bit/syn estim general retriev procedur one consid recognit process store pattern whole space spars initi pattern initi pattern recogn invari bidirect retriev cycl so-cal recognit capac process an upper bound complet capac it determin see this achiev paramet provid yield bit/syn upper bound asymptot search capac summari we know asymptot search capac cb-model bit/syn experiment result see bidirect retriev associ memori experiment result cb model test simul compar willshaw model simpl retriev address random nois address compos two learn pattern wide enlarg rang high qualtiti retriev cb-model demonstr differ system size output miss error simpl cb r output add error simpl transinform output pattern bit impl retriev address random nois x-axi label small system left system size two trial right output activ adjust near iyl threshold set retriev address compos two learn pattern paramet right column explan left right column see text address contain one learn pattern i-compon second learn pattern success ad increas abscissa right end diagram pattern complet superimpos diagram left column show error transinform retriev result compar learn pattern li i domin address simpl retriev error behav similiar random nois address error level cb-retriev rais faster add second pattern present diagram right column show quantiti retriev result compar closest two learn pattern it observ learn pattern retriev even address complet superposit ii second pattern almost complet address retriev pattern correspond case second pattern howev case cbretriev yield one learn pattern pair it could use generat good address retriev delet correspond i-compon origin address f. t. sommer g. palm output searchc output search capac cb retriev bit/syn x-axi label for differ curv contribut due x-pattern complet complet capac c. it zero for initi pattern errorfre search capac cb model close theoret expect sect increas input nois due address complet spars code appli propos am model for instanc inform retriev code data access spars binari pattern requir use extract spars featur take account statist data properti way user act on there evid cognit psycholog a code typic quit easi find the featur encod a person extract featur set character complex situat a present featur one the three basic class cognit process defin sternberg similar the data repres featur pattern a larg number present featur common a high overlap l i xix'i for text retriev word fragment use in exist index techniqu direct taken as spars binari featur for imag process spars code strategi neural model for spars featur extract anti-hebbian learn propos spars pattern extract differ data channel in heterogen data simpli concaten process simultan in am if part the origin data held in a convent memori also address repres distribut spars pattern in order exploit the high perform the propos nam conclus a new bidirect retriev method cb-retriev present for the willshaw neural associ memori model our analysi the first cb-retriev step indic a high potenti for error reduct increas input fault toler the asymptot capac for bidirect retriev in the binari willshaw matrix determin bit/syn in experi cb-retriev show signific increas input fault toler respect the standard model lead to a practic inform capac in the order the theoret expect bit/syn also the segment abil cb-retriev with ambigu address shown even high memori load input pattern decompos correspond memori entri return individu the model improv requir sophist individu threshold set strategi propos for bam like complex learn procedur dummi augment in the pattern code the demonstr perform the cb-model encourag applic as massiv parallel search strategi in inform retriev the spars code requir briefli discuss regard technic strategi and psycholog plausibl biolog plausibl variant cb-retriev contribut to bidirect retriev from associ memori refin cell assembl theori see acknowledg one the author support grant the deutsch forschungsgemeinschaft
----------------------------------------------------------------

title: 3721-noisy-generalized-binary-search.pdf

noisi general binari search robert nowak univers wisconsin-madison engin drive madison wi nowak ece.wisc.edu abstract paper address problem noisi general binari search gbs well-known greedi algorithm determin binary-valu hypothesi sequenc strateg select queri step queri select even split hypothes consider two disjoint subset natur general idea under classic binari search gbs use mani applic includ fault test machin diagnost diseas diagnosi job schedul imag process comput vision activ learn case respons queri noisi past work provid partial character gbs exist noise-toler version gbs suboptim term queri complex paper present optim algorithm noisi gbs demonstr applic learn multidimension threshold function introduct paper studi learn problem follow form consid finit potenti larg collect binary-valu function defin domain paper call hypothesi space call queri space map assum function uniqu one function produc correct binari label goal determin queri possibl queri valu corrupt independ distribut binari nois observ queri noiseless usual call membership queri distinguish type queri simpli refer queri problem natur aris mani applic includ channel code experiment design diseas diagnosi fault-toler comput job schedul imag process comput vision comput geometri amm activ learn past work provid partial character problem respons queri noiseless select optim sequenc queri equival determin optim binari decis tree sequenc queri defin path root tree correspond leaf correspond singl element h general determin optim tree np-complet howev exist greedi procedur yield queri sequenc within o log factor optim search tree depth amm denot cardin h. greedi procedur refer general binari search gbs split algorithm reduc classic binari search special case gbs algorithm outlin figur step gbs select queri result even split hypothes consider two subset respond respect queri correct respons queri elimin one two subset consider sinc hypothes assum distinct clear gbs termin queri sinc alway possibl find queri elimin least noisi general binari search ngbs initi p0 uniform h. arg minx x h h pi obtain noisi respons bay updat pi eqn general binari search gbs initi h0 h. hi select arg minx x h hi obtain respons set hi h xi hypothesi select step hi arg maxh h pi figur general binari search gbs algorithm noise-toler variant ngbs one hypothesi step fact simpl exampl demonstr best one hope general howev also true mani case perform gbs much better amm general number queri requir bound term combinatori paramet call extend teach dimens also see relat work altern exist geometr relat pair call neighbor condit suffici bound number queri need focus paper noisi gbs mani applic unrealist assum respons queri without error noise-toler version classic binari search well-studi classic binari search problem equival learn one-dimension binary-valu threshold function select point evalu function accord bisect procedur noisi version classic binari search studi first context channel code feedback horstein probabilist bisect procedur shown optim optim decay error probabl also one straightforward approach noisi gbs explor idea follow gbs algorithm repeat queri step multipl time order decid whether respons probabl strategi repeat queri suggest general approach devis noise-toler learn algorithm simpl approach studi context noisi version classic binari search shown suboptim sinc classic binari search special case general problem follow immedi approach propos suboptim paper address open problem determin optim strategi noisi gbs optim noise-toler version gbs develop number queri algorithm requir confid identifi call queri complex algorithm queri complex new algorithm optim awar algorithm capabl also shown optim converg rate queri complex achiev broad class geometr hypothes aris imag recoveri binari classif edg imag decis boundari classif problem natur view curv plane surfac embed higher-dimension space associ multidimension threshold function valu either side curve/surfac thus one import set gbs subset dimension euclidean space set consist multidimension threshold function show algorithm achiev optim queri complex activ learn multidimension threshold function noisi condit paper organ follow section describ bayesian algorithm noisi gbs present main result section examin propos method learn multidimension threshold function section discuss agnost algorithm perform well even hypothesi space h. proof given section bayesian algorithm noisi gbs noisi gbs one must cope erron respons specif assum binari respons queri independ realize random variabl satisfi p y p y fix unknown word respons probabl correct queri repeat respons independ realize defin noise-level queri p y throughout paper let supx x assum bayesian approach noisi gbs investig paper let p0 known probabl meap sure h. p0 h h p0 measur p0 view initi weight hypothesi class express fact hypothesi equal reason prior make queri after queri respons distribut updat accord pi zi h xip constant satisfi normal satisfi h h updat view applic bay rule effect simpl probabl mass hypothes agre label boost relat disagre paramet control size boost hypothesi largest weight select step hi arg maxh h pi maxim uniqu one maxim select random goal noisi gbs drive error p b hi zero quick possibl strateg select queri similar procedur shown optim noisi classic binari search problem crucial distinct gbs call fundament differ approach queri select queri select eachpstep must inform respect distribut pi exampl weight predict h h pi close zero certain label point inform due larg disagr among hypothes suggest follow noisetoler variant gbs outlin figur paper show slight variat queri select ngbs algorithm figur yield algorithm optim queri complex shown long larger noise-level queri ngbs produc sequenc hypothes h0 h1 p b hn bound monoton decreas sequenc theorem main interest paper algorithm drive error zero exponenti fast requir queri select criterion modifi slight see necessari suppos step ngbs algorithm singl hypothesi major probabl mass weight predict almost equal predict hypothesi close queri therefor respons queri relat certain non-inform thus converg algorithm could becom quit slow condit similar effect true case noisi classic binari search address issu queri select criterion modifi via random respons select queri alway high uncertain order state modifi select procedur main result observ queri space partit equival subset everi constant queri subset let denot smallest partit note everi valu constant either denot valu first note play import role gbs particular observ queri select step ngbs equival optim rather random queri select step base notion neighbor set definit two set a0 said neighbor singl hypothesi complement also belong output differ valu a0 modifi ngbs algorithm outlin figur note queri select step ident origin ngbs algorithm unless exist two neighbor set strong bipolar weight respons latter case queri random select one two set equal probabl guarante high uncertain respons theorem let denot under probabl measur govern nois algorithm random ngbs modifi ngbs algorithm figur figur respect generat sequenc hypothes p b hn monoton decreas sequenc condit ensur updat over aggress turn matter suffici condit guarante p b hn exponenti fast modifi ngbs initi p0 uniform h. let mina h h pi neighbor set a0 exist h h pi h h pi select a0 probabl otherwis select set amin arg mina h h pi case set non-uniqu choos random one satisfi requir obtain noisi respons bay updat pi eqn hypothesi select step hi arg maxh h pi figur modifi ngbs algorithm exponenti converg rate classic binari search hing fact hypothes order respect general situat hypothesi space order fashion neighborhood graph provid similar local structur definit pair said neighbor neighborhood graph connect everi pair set exist sequenc neighbor set begin one pair end essenc neighbor condit simpli mean hypothesi local distinguish other local mean vicin point output hypothesi chang neighbor condit first introduc analysi gbs shown section neighbor condit hold import case hypothesi space consist multidimension threshold function if neighbor modifi ngbs algorithm guarante p b hi exponenti fast theorem let denot under probabl measur govern nois algorithm random if neighbor modifi ngbs algorithm figur generat sequenc hypothes satisfi p b hn exponenti constant min min max dp h h exponenti converg rate1 govern key paramet minim exist minim comput space finite-dimension probabl mass function element long hypothesi constant whole valu typic a small constant much less independ size next section concret exampl situat converg rate modifi ngbs optim constant factor no algorithm solv noisi gbs problem a lower queri complex queri complex modifi ngbs algorithm deriv follow let a prespecifi confid paramet number queri requir ensur p b hn log o log optim queri complex intuit o log bit requir encod hypothesi more formal classic noisi binari search problem satisfi assumpt theorem note factor exponenti rate paramet a posit constant strict less a nois level factor maxim a valu tend tend henc a special case general problem known optim queri complex noisi classic binari search o log contrast simpl noise-toler gbs algorithm base repeat queri standard gbs algorithm figur multipl time control nois relat deriv follow chernoff bound queri complex determin correct label a singl queri confid least suppos gbs requir n0 queri noiseless situat use union bound requir log n queri step guarante label determin n0 queri correct probabl if neighbor gbs requir n0 o log queri noiseless condit therefor condit theorem queri complex simpl noise-toler gbs algorithm o log log log |h a logarithm factor wors optim queri complex noisi gbs learn multidimension threshold appli theori modifi ngbs algorithm problem learn multidimension threshold function point evalu a problem aris common comput vision amm imag process activ learn case hypothes determin possibl nonlinear decis surfac d-dimension euclidean space a subset rd queri point rd suffic consid linear decis surfac form ha b sign ha a rd kak2 constant ha denot inner product rd note hypothes this form use repres nonlinear decis surfac appli a nonlinear map queri space theorem let a finit collect hypothes form sign ha constant hypothes select modifi ngbs algorithm satisfi p b hn moreov hn comput time polynomi base discuss end previous section conclud queri complex modifi ngbs algorithm o log this optim constant factor algorithm this capabl awar analyz base a quit differ approach tailor specif linear threshold problem agnost algorithm also mention possibl agnost algorithm guarante find best hypothesi even if optim hypothesi and/or assumpt theorem hold best hypothesi in one minim error respect a given probabl measur denot px follow theorem prove in demonstr an agnost algorithm perform almost well empir risk minim erm in general optim o log queri complex condit theorem hold theorem let px denot a probabl distribut suppos a queri budget let h1 denot hypothesi select modifi ngbs use queri let h2 denot hypothesi select erm queri drawn independ px draw remain queri independ restrict px set h1 denot averag number error made h1 h2 disagre let in general h2 queri select arg min r e r b min e r h1 denot probabl error respect px denot expect respect random quantiti furthermor if assumpt theorem hold nois bound p b appendix proof proof theorem let denot expect respect defin cn pn note cn reflect amount mass pn place suboptim hypothes first note p b hn p pn p cn e cn markov inequ next observ e cn e cn e cn max e cn c0 max max ci pi note p0 assum uniform c0 a similar condit techniqu employ interv estim in rest proof entail show ci proof result requir a differ approach precis form p1 p2 deriv as follow let pi zi weight proport hypothes agre factor normal updat dis zi tribut in relat as follow note pi h zi pi h zi pi thus pi denot reciproc updat factor zi observ pi thus pi pi pi ci pi pi pi now bound maxpi ci pi we show maxpi pi accomplish this we assum pi arbitrari everi a a everi let denot valu set a defin a pi proport hypothes take valu a note everi a we a sinc least one hypothesi valu a h. let ai denot set select consid four possibl situat a a bound pi it help condit ai defin qi px y|ai if ai pi ai a a a qi ai qi qi qi a a defin ai a a pi ai qi similar if ai qi qi a ai ai assumpt qi sinc factor qi defin obtain bound sinc ai ai a a ai a ai a less it follow pi proof theorem proof amount obtain upper bound ai ai defin in everi a a probabl measur weight predict a defin a h h the constant valu everi a the follow lemma play a crucial role in the analysi the modifi ngbs algorithm lemma if neighbor for everi probabl measur either exist a set a a a pair neighbor set a a0 a a a0 proof lemma suppos mina a then must exist a a0 a a a0 otherwis the minimax moment h. see this suppos for a for a a then for everi instanc distribut we h h p h h x dpr this contradict rthe definit sinc h h p h h x dp h h dp maxh h dp the neighbor condit guarante exist a sequenc neighbor set begin a end a0 sinc everi set the sign must chang point in the sequenc it follow exist neighbor set satisfi the claim now consid two distinct situat defin bi mina a pi a first suppos exist neighbor set a a0 pi a bi pi a0 bi then lemma this impli bi accord the queri select step the modifi ngbs algorithm ai arg mina pi a note pi ai a henc ai ai bound now suppos exist neighbor set a a0 pi a bi pi a0 bi recal in this case ai random chosen a a0 equal probabl note a bi a bi if a then appli result in bi bi bi sinc bi similar if then yield pi ai a0 if a then appli a a0 yield pi ai a0 a a a a a a a a a a pi ai a0 sinc a a the final possibl a appli a a obtain pi ai a0 a a a a a a next use the fact a a0 neighbor a a pi pi if belong then pi henc pi ai a0 a a a pi pi pi pi pi pi pi sinc the bound maxim pi now bound pi the maximum the condit bound obtain pi max pi thus it easi to see pi pi min pi ci pi proof theorem first we show the pair rd neighbor definit a a a polytop in rd polytop generat by intersect the halfspac correspond to the hypothes ani two polytop share a common face neighbor the hypothesi whose decis boundari defin the face complement if it exist the one predict differ valu these two set sinc the polytop tessel rd the neighborhood graph a connect next consid the final bound in the proof theorem we next show the valu defin in sinc the offset the hypothes less in magnitud it follow the distanc the origin to the nearest point the decis surfac everi hypothesi let pr denot the uniform probabl distribut a ball radius center at the origin in rd then for everi the form sign ha dp limr dpr last note the modifi ngbs algorithm involv comput h h pi for a a at each step the comput complex each step therefor proport to the cardin a equal to the number polytop generat by intersect half-spac it pd known that
----------------------------------------------------------------

title: 1540-general-purpose-localization-of-textured-image-regions.pdf

general-purpos local textur imag region rutb rosenboltz xeroxparc coyot hill rd palo alto ca abstract suggest work definit textur textur stuff compact repres statist specifi configur part definit suggest fmd textur look outlier local statist label textur region outlier present method base upon idea label point natur scene belong textur region simultan allow us label lowlevel bottom-up cue visual attent method base upon recent psychophys result process textur popout textur whi want find number problem comput vlslon imag process one must distinguish imag region correspond object correspond textur perform differ process depend upon type region current comput vision algorithm assum one magic know region label what textur notion textur involv pattern somehow homogen signal chang complex describ aggreg properti must use instead saund mean firm divis textur object rather character often depend upon scale interest saund email rruth parc.xerox.com r. rosenholtz ideal defmit textur probabl depend upon applic investig definit believ fair general util textur stuff seem belong local statist propos extract sever textur featur sever differ scale label textur region whose featur valu like come local distribut outlier local statist tend draw attent rosenholtz phenomenon often refer popout thus label local statist homogen region textur simultan highlight salient outlier local statist revis defmit textur absenc popout section discuss previous work human percept fmding textur region interest imag section we describ method we present discuss result number real imag section previous work see wolf review visual search literatur popout typic studi use simpl display experiment subject search unusu target item among distractor item one typic attempt judg salienc degre target pop studi effici search item typic popout model relat lowlevel oper oper independ number basic featur imag includ orient contrast/color depth motion paper we look featur contrast orient within image-process field much work fmding textur defm textur region high lumin varianc vaisey gersho unfortun lumin varianc region contain edg high textur region won park use model fit detect imag block contain edg label block high varianc contain textur recent sever comput vision research also tackl problem leung malik found region complet determinist textur research use defmit lumin goe vice versa 's textur forsyth ai howev method treat line textur also notion similar within textur also lack image-process work one would mark fault textur belong textur would unaccept textur synthesi applic routin tri synthes textur would like fail reproduc high visibl fault recent shi malik present method segment imag base upon textur featur method perform extrem well segment task divid imag region intern similar high compar similar across region howev difficult compar their result sinc explicit label subset result region textur furthermor method may also tend mark fault textur belong textur method bias separ small region group patch one region depend much upon differ patch region upon similar patch given region littl comput vision work done attent cue milanes al found salient imag region use top-down inform bottomup conspicu oper mark local region salient greater general-purpos local o/textur imag region differ local featur valu mean featur valu surround region howev differ mean local region less salient there greater varianc featur valu surround region duncan humphrey rosenholtz we use salienc measur test outlier local distribut captur mani case depend salienc differ given featur valu local mean relat local standard deviat we discuss salienc measur greater detail follow section find textur region interest we comput multiresolut featur map orient contrast look outlier local orient contrast statist we do fast creat 3-level gaussian pyramid represent imag extract contrast we filter pyramid differ circular symmetr gaussian respons filter oscil even region constant-contrast textur sinewav pattern we approxim comput maximum respons filter small region fast squar filter respons filter contrast energi appropri gaussian final we threshold contrast elimin low-contrast region flat textur threshold one scale set examin visibl sinewav pattern various spatial frequenc we comput orient simpl biolog plausibl way use bergen landi 's back pocket model low-level comput filter pyramid horizont vertic orient gaussian second deriv comput oppon energi squar filter output pool region time scale second deriv filter subtract vertic horizont respons respons normal oppon energi scale divid total energi orient energi band scale result two imag scale pyramid good approxim region strong orient imag repres local orient scale valu relat local orient specif orient estim point low specif tend veri noisi imag white nois estim fall therefor confid orient specif occur due chanc we use valu threshold orient estim low oriented we estim local featur distribut featur scale use method parzen window blur distribut estim parzen window mimic uncertainti estim featur valu visual system we collect statist local integr region textur process size this region ind.epend view distanc rough los diamet support gaussian 2nd deriv filter use extract textur featur kingdom keebl kingdom we next comput non-parametr measur salienc salienc p v id maxp x id r. rosenholtz note gaussian this simplifi compar standard parametr test outlier use measur salienc measur essenti general nonparametr form this measur it assum gaussian distribut point salienc less label candid textur point if gaussian this would correspond featur estim within one standard deviat mean point salienc greater label candid bottom-up attent cue if gaussian this would correspond featur estim mean standard parametr test outlier one could cours keep raw salienc valu measur likelihood region contain textur rather set hard threshold we use hard threshold our exampl better display result textur imag region interest imag median-filt remov extran point experiment result figur show sever exampl imag figur show textur found scale process stripe checker pattern repres orient homogen contrast textur respect absenc imag figur mean textur given type found imag given scale note we perform segment one textur anoth build imag algorithm label brick window pane fme-scal textur window shutter coarser-scal textur leopard skin low-frequ stripe lower right comer leopard imag correct label textur desk imag wood textur correct identifi regular pattern window mark textur hotel imag hous imag wood side tree part grass label textur much grass low contrast label flat textur one bush correct identifi coarser textur other in lighthous imag hous san window fenc tower mark well low-frequ orient pattern in cloud figur show region interest found stripe plaid pattern mean chosen maximum visibl most complex natur scene interest low-level attent area in lighthous imag life preserv mark in hotel curv unusu angular window identifi attent cue well top build both these result in agreement psychophys result show observ quick identifi curv bent line among straight line review in wolf simpler desk scene yield intuit result object label well the phone cord bottom-up attent cue outlier to the local distribut featur we suggest textur the absenc outlier this definit captur the intuit textur is homogen statist in natur we present method for fmding contrast orient outlier result both local textur and find popout in natur imag for the simpl desk imag the algorithm highlight salient region correspond to our notion the import object in the scene complic natur scene result less intuit suggest search in natur scene make use higher-level general-purpos local o/textur imag region process group object this result terribl surpris but serv use check on simpl low-level model visual attent the algorithm good job identifi textur region number of differ scale the result perhap more intuit finer scale acknowledg this work partial support nrc postdoctor award nasa ame mani thank to david marimont and eric saund for use discuss
----------------------------------------------------------------

title: 6145-a-multi-batch-l-bfgs-method-for-machine-learning.pdf

multi-batch l-bfgs method machin learn albert s. beraha northwestern univers evanston il albertberaha u.northwestern.edu jorg noced northwestern univers evanston il j-noced northwestern.edu martin tak c lehigh univers bethlehem pa takac.mt gmail.com abstract question parallel stochast gradient descent sgd method receiv much attent literatur paper focus instead batch method use sizeabl fraction train set iter facilit parallel employ second-ord inform order improv learn process follow multi-batch approach batch chang iter caus difficulti l-bfgs employ gradient differ updat hessian approxim gradient comput use differ data point process unstabl paper show perform stabl quasi-newton updat multi-batch set illustr behavior algorithm distribut comput platform studi converg properti convex nonconvex case introduct common machin learn encount optim problem involv million paramet larg dataset deal comput demand impos applic high perform implement stochast gradient batch quasi-newton method develop paper studi batch approach base l-bfgs method strive reach right balanc effici learn product parallel supervis learn one seek minim empir risk 1x def fi denot train exampl rd composit predict function parametr loss function train problem consist find optim choic paramet rd respect min w rd 1x fi present prefer optim method stochast gradient descent sgd method variant implement either asynchron manner confer neural inform process system nip barcelona spain use paramet server distribut set follow synchron mini-batch approach exploit parallel gradient evalu drawback asynchron approach use larg batch would caus updat becom dens compromis stabil scalabl method result algorithm spend time communic compar comput hand use synchron mini-batch approach one achiev near-linear decreas number sgd iter mini-batch size increas certain point increas comput offset faster converg altern sgd batch method l-bfgs abl reach high train accuraci allow one perform comput per node achiev better balanc communic cost batch method howev effici learn algorithm sgd sequenti set benefit strength method high perform system employ sgd start later switch batch method multi-batch method paper follow differ approach consist singl method select sizeabl subset batch train data comput step chang batch iter improv learn abil method call multi-batch approach differenti mini-batch approach use conjunct sgd employ small subset train data use larg batch natur employ quasinewton method incorpor second-ord inform impos littl comput overhead improv stabil speed method focus l-bfgs method employ gradient inform updat estim hessian comput step flop number variabl multi-batch approach howev caus difficulti l-bfgs method employ gradient differ updat hessian approxim gradient use differ base differ data point updat procedur unstabl similar difficulti aris parallel implement standard l-bfgs method comput node devot evalu function gradient unabl return result time amount use differ data point evalu function gradient begin end iter goal paper show stabl quasi-newton updat achiev set without incur extra comput cost special synchron key perform quasi-newton updat base overlap consecut batch restrict overlap small someth achiev situat contribut describ novel implement batch l-bfgs method robust absenc sampl consist differ sampl use evalu object function gradient consecut iter numer experi show method propos paper call multi-batch l-bfgs method achiev good balanc comput communic cost also analyz converg properti new method use fix step length strategi convex nonconvex problem multi-batch quasi-newton method pure batch approach one appli gradient base method l-bfgs determinist optim problem number train exampl larg natur parallel evalu assign comput compon function fi differ processor done distribut platform possibl comput node slower rest case contribut slow unrespons comput node could ignor given stochast natur object function lead howev inconsist object function gradient begin end iter detriment quasi-newton method thus seek find fault-toler variant batch l-bfgs method capabl deal slow unrespons comput node similar challeng aris multi-batch implement l-bfgs method entir train set employ everi iter rather subset data use comput gradient specif consid method dataset random divid number batch say minim perform respect differ batch everi iter k-th iter algorithm choos batch sk comput fi wk sk wk sk sk sk wk gksk fi wk sk sk take step along direct hk gksk hk approxim wk allow sampl sk chang freeli everi iter give approach flexibl implement benefici learn process show section refer sk sampl train point even though sk index point case unrespons comput node multi-batch method similar main differ node failur creat unpredict chang sampl sk wherea multi-batch method control sampl generat either case algorithm employ stochast approxim gradient longer consid determinist must howev distinguish set classic sgd method employ small mini-batch noisi gradient approxim algorithm oper much larger batch distribut function evalu benefici comput time gksk overwhelm communic cost give rise gradient relat small varianc justifi use second-ord method l-bfgs robust quasi-newton updat difficulti creat use differ sampl sk iter circumv consecut sampl sk overlap ok sk one perform stabl quasi-newton updat comput gradient differ base overlap defin ok gkok wk notat given correct pair yk sk use bfgs updat overlap set ok small yk use approxim curvatur object function along recent displac lead product quasi-newton step observ base import properti newton-lik method name much freedom choos hessian approxim comput gradient thus smaller sampl ok employ updat invers hessian approxim hk comput batch gradient gksk search direct hk gksk summari ensur unrespons node constitut vast major work node fault-toler parallel implement exert small degre control creation sampl sk multi-batch method one design robust method natur build upon fundament properti bfgs updat mention pass common use strategi ensur stabil quasi-newton updat machin learn enforc gradient consist use sampl sk comput gradient evalu begin end iter anoth popular remedi use batch sk multipl iter allevi gradient inconsist problem price slower converg paper assum achiev sampl consist possibl fault-toler case desir multi-batch framework wish design new variant l-bfgs impos minim restrict sampl chang specif method k-th iter multi-batch bfgs algorithm choos set sk comput new iter wk hk gksk step length gksk batch gradient hk invers bfgs hessian matrix approxim updat everi iter mean formula vkt hk vk sk stk ts yk vk yk stk comput correct vector sk yk determin overlap set ok sk consist sampl common k-th iter defin ok wk fi wk ok wk gkok fi wk ok ok ok i ok comput correct vector paper assum constant limit memori version matrix hk defin iter result appli bfgs updat multipl ident matrix use set correct pair si kept storag memori paramet typic rang when comput matrix-vector product necessari form matrix hk sinc one obtain product via two-loop recurs use recent correct pair si step comput oldest pair sj yj discard new curvatur pair store pseudo-cod propos method given depend sever paramet paramet denot fraction sampl dataset use defin gradient paramet denot length overlap consecut sampl defin fraction number sampl given batch algorithm multi-batch l-bfgs input w0 initi iter train set memori paramet batch fraction overlap fraction batch iter counter creat initi batch s0 shown firgur calcul search direct pk hk gksk use l-bfgs formula choos step length comput wk pk creat next batch ok comput curvatur pair wk gkok replac oldest pair si end sampl generat discuss sampl creat iter line algorithm distribut comput fault consid distribut implement slave node read current iter wk master node comput local gradient subset dataset send back master node aggreg calcul given time comput budget possibl node fail return result schemat figur 1a illustr gradient calcul across two iter presenc fault here bi denot batch data slave node receiv bi gradient calcul use node respond within prealloc time master node wk s0 b1 b2 b1 wk rf b3 slave node bb b3 wk rf bb wk rf wk b1 b2 b3 b1 rf master node wk rf shuffl data o0 shuffl data s3 o3 s6 o6 bb s1 o1 s4 o4 bb rf s2 o2 s5 o5 rf figur sampl overlap format let jk set indic node return gradient k-th iter respect use notat sk j jk bj bj defin ok j jk bj simplest implement set prealloc data comput node requir minim data communic one data transfer case sampl sk independ node failur occur random hand set node fail sampl creation bias harm theori practic one way ensur independ sampl shuffl redistribut data node certain number iter multi-batch sampl propos two strategi multi-batch set figur 1b illustr sampl creation process first strategi dataset shuffl batch generat collect subset train set order everi set except s0 form sk nk ok ok overlap sampl batch respect nk sampl uniqu batch sk pass dataset sampl reshuffl procedur describ repeat implement sampl drawn without replac guarante after everi pass epoch sampl use strategi advantag requir extra comput ok evalu gkok sampl sk independ second sampl strategi simpler requir less control everi iter batch sk creat random select sk element overlap set ok form random select ok element sk subsampl strategi slight expens ok sinc requir extra comput overlap small cost signific converg analysi this section analyz converg properti multi-batch l-bfgs method algorithm when appli minim strong convex nonconvex object function use fix step length strategi we assum goal minim empir risk given note similar analysi could use studi minim expect risk strong convex case due stochast natur multi-batch approach everi iter algorithm employ gradient contain error converg zero therefor use fix step length strategi one establish converg optim solut converg neighborhood nevertheless this result interest reflect common practic use fix step length decreas desir test error achiev also illustr tradeoff aris size batch step length analysi we make follow assumpt object function algorithm assumpt a. twice continu differenti i i rd exist posit constant set constant es k f rd set sampl drawn independ unbias estim true gradient rd es note assumpt impli entir hessian also satisfi i rd constant assum everi sub-sampl function strong convex unreason regular term common ad practic when case we begin show invers hessian approxim hk generat multi-batch l-bfgs method eigenvalu uniform bound away zero proof techniqu use adapt lemma assumpt hold there exist constant hessian approxim hk generat algorithm satisfi i hk i util lemma we show multi-batch l-bfgs method constant step length converg neighborhood optim solut theorem suppos assumpt hold let minim let wk iter generat algorithm start w0 then e f wk bound provid this theorem two compon term decay linear zero term identifi neighborhood converg note larger step length yield favor constant linear decay term cost increas size neighborhood converg we consid tradeoff section we also note larger batch increas opportun parallel improv limit accuraci in solut slow learn abil algorithm one establish converg multi-batch l-bfgs method optim solut employ sequenc step length converg zero accord schedul propos robbin monro howev provid sublinear rate converg littl interest in context larg batch employ type linear converg expect in this light theorem relev practic nonconvex case bfgs method known fail noconvex problem even l-bfgs make finit number updat iter one guarante hessian approxim eigenvalu uniform bound away zero establish converg bfgs method in nonconvex case cautious updat procedur propos here we employ cautious strategi well suit our particular algorithm we skip updat set hk if curvatur condit ykt sk ksk satisfi predetermin constant use said mechan we show eigenvalu hessian matrix approxim generat multi-batch l-bfgs method bound away zero lemma analysi present in this section base follow assumpt assumpt b. twice continu differenti gradient lipschitz continu gradient lipschitz continu rd set function bound scalar fb there exist constant es k f rd set sampl drawn independ an unbias estim true gradient rd lemma suppos assumpt hold let given let hk hessian approxim generat algorithm modif hk whenev satisfi then there exist constant i hk i we follow analysi in chapter establish follow result behavior gradient norm multi-batch l-bfgs method cautious updat strategi theorem suppos assumpt hold let given let wk iter generat algorithm start w0 modif hk whenev satisfi then fb k f wk this result bound averag norm gradient after first iter show iter spend increas time in region object function small gradient numer result in this section we present numer result evalu propos robust multi-batch l-bfgs scheme algorithm logist regress problem figur show perform webspam dataset1 we compar three method multi-batch l-bfgs without enforc sampl consist l-bfgs gradient differ comput use differ sampl yk gksk multi-batch gradient descent gradient descent obtain set hk i in algorithm iii serial sgd at everi iter one sampl use comput gradient we run method differ random seed applic report result differ batch overlap size propos method stabl standard l-bfgs method this especi notic when small hand serial sgd achiev similar accuraci robust l-bfgs method at similar rate at cost communic per epoch versus communic per epoch figur also indic robust l-bfgs method sensit size overlap similar behavior observ dataset in regim small we mention in pass l-bfgs step comput use vector-fre implement propos in webspam epoch webspam epoch webspam robust l bfgs l bfgs gradient descent sgd epoch webspam robust l bfgs l bfgs gradient descent sgd robust l bfgs l bfgs gradient descent sgd k f k f k f robust l bfgs l bfgs gradient descent sgd webspam robust l bfgs l bfgs gradient descent sgd k f k f webspam robust l bfgs l bfgs gradient descent sgd k f epoch epoch epoch figur webspam dataset comparison robust l-bfgs l-bfgs multi-batch l-bfgs without enforc sampl consist gradient descent multi-batch gradient method sgd various batch overlap size solid line show averag perform dash line show worst best perform run per algorithm mpi process we also explor perform robust multi-batch l-bfgs method in presenc node failur fault compar it multi-batch variant enforc sampl consist l-bfgs figur illustr perform method webspam dataset various libsvm https //www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html probabl node failur suggest the robust l-bfgs variant stabl webspam webspam robust l bfgs l bfgs webspam robust l bfgs l bfgs robust l bfgs l bfgs k f k f k f iterations/epoch iterations/epoch iterations/epoch figur webspam dataset comparison robust l-bfgs l-bfgs multi-batch l-bfgs without enforc sampl consist various node failur probabl solid line show averag perform dash line show worst best perform run per algorithm mpi process last we studi the strong weak scale properti the robust l-bfgs method artifici data figur we measur the time need comput gradient gradient the associ communic gradient+c as well as the time need comput the l-bfgs direct lbfgs the associ communic l-bfgs+c various batch size the figur the left show strong scale multi-batch lbfgs dimension problem sampl the size input data we vari the number mpi process the time it take to comput the gradient decreas howev small valu the communic time exceed the comput time the figur on the right show weak scale on problem similar size vari sparsiti sampl non-zero element thus the size local problem rough size data we observ almost constant time the gradient comput the cost comput the l-bfgs direct decreas howev if communic consid the overal time need to comput the l-bfgs direct increas slight strong scale elaps time gradient gradient+c l bfgs l bfgs+c elaps time number mpi process weak scale fix problem dimens gradient gradient+c l bfgs l bfgs+c number mpi process figur strong weak scale multi-batch l-bfgs method conclus this paper describ a novel variant the l-bfgs method robust effici in two set the first occur in the presenc node failur in a distribut comput implement the second aris when one wish to employ a differ batch at each iter in order to acceler learn the propos method avoid the pitfal use inconsist gradient differ perform quasi-newton updat base on the overlap consecut sampl numer result show the method effici in practic a converg analysi illustr theoret properti acknowledg the first two author support the offic naval research award the depart energi grant the nation scienc foundat grant martin tak c support nation scienc foundat grant
----------------------------------------------------------------

title: 473-constructing-proofs-in-symmetric-networks.pdf

construct proof symmetr network gadi pinka comput scienc depart washington univers campus box st. loui mo abstract paper consid problem express predic calculus connectionist network base energi minim given firstorder-log knowledg base bound symmetr network construct like boltzman machin hopfield network search proof given queri resolution-bas proof length longer exist global minima energi function associ network repres proof network generat size cubic bound linear knowledg size restrict type logic formula repres network inher fault toler cope inconsist nonmonoton introduct abil reason acquir knowledg undoubt one basic import compon human intellig among major tool reason area ai deduct proof techniqu howev tradit method plagu intract inabl learn adjust well inabl cope nois inconsist connectionist approach may miss link fine grain massiv parallel architectur may give us real-tim approxim network potenti trainabl adjust may made toler nois result collect comput connectionist reason system implement part first-ord logic exampl holldobl shastri use spread activ paradigm usual trade express time effici contrast pinka paper use energi minim paradigm like derthick ballard pinka repres intract problem trade time correct time given probabl converg correct answer increas symmetr connectionist network use constraint satisfact target platform hopfield hinton sejnowski peterson hartman smolenski character quadrat energi function minim model famili may seen perform search global minimum energi function task therefor repres logic deduct bound finit proof length energi minim without bound proof length problem undecid when queri clamp network search proof support queri proof queri exist everi global minimum energi function associ network repres proof proof exist global minima repres lack proof paper elabor proposit case howev due space limit first-ord fol case sketch detail full treatment fol see pinka repres proof proposit logic ll start assum knowledg base proposit proof area proof list claus end queri everi claus use either origin claus copi weaken claus appear earlier proof result resolut step two claus appear earlier proof emerg activ pattern special unit structur call proof area repres revers common practic queri appear first exampl given knowledg base follow claus vc would like prove queri generat follow list claus avcv vc obtain resolut claus cancel origin claus obtain resolut claus cancel c origin claus obtain resolut claus cancel b origin claus origin claus claus proof either origin claus copi claus earlier proof resolut step matrix figur function claus list list repres order set claus form proof queri claus clamp onto area construct proof symmetr network activ hard constraint forc rest unit matrix form valid proof exist avd cvd avcvd queri jjvd avbvc res kb o'i l igur proof area proposit case variabl bind perform dynam alloc instanc use techniqu similar anand barnden techniqu two symbol need bound togeth instanc alloc pool general purpos instanc connect symbol instanc connect liter claus predic type constant function slot anoth instanc exampl constant bound first slot predic claus particip proof repres use 3-dimension matrix 2-dimension matrix illustr figur row repres claus proof row repres atom pinka proposit column matric repres pool instanc use bind proposit claus claus list negat posit instanc repres liter instanc thus behav two-way pointer bind composit structur like claus constitu atom proposit row matrix repres claus compos pair instanc unit set matrix repres posit liter claus if pa also set repres posit liter claus bound atom proposit similar repres negat liter first row matrix figur queri claus d. contain one posit liter bound atom proposit via instanc anoth exampl consid third row repres claus two liter posit one bound via instanc negat one bound via instanc claus generat result resolut step particip proof vector repres whether claus particip proof exampl claus proof howev general case row may meaningless when mean claus proof must prove well everi claus particip proof either result resolut step res set copi claus cpyi set origin claus knowledg base b. set second claus figur exampl origin claus knowledg base if claus copi must proof therefor nj set similar if claus result resolut step two resolv claus must also proof ni+l therefor must resolv copi origin chain constraint continu constraint satisfi valid proof generat post queri user post queri clamp claus onto first row set appropri unit indic queri claus particip proof prove either resolut step copi step origin claus figur repres complet proof queri start alloc instanc matrix clamp posit liter first row rest first row 's unit clamp zero unit inl bias valu one indic queri proof this caus chain constraint activ satisfi valid proof if proof exist nl unit becom zero global minima obtain set nl zero despit bias repres resolut step vector res structur unit indic claus obtain resolut step if res set ith row obtain resolv row row thus unit resl figur indic claus first row resolv second third row repres respect two liter cancel if opposit sign repres instanc figur liter third row liter second row cancel generat claus first row row matrix repres liter cancel resolut step if row construct proof symmetr network result resolut step must one one instanc claus claus includ opposit sign exampl figur claus first row result resolv claus clause.. second third row respect instanc repres atom proposit one cancel ri set therefor indic claus obtain resolut step cancel liter instanc copi origin claus matrix indic claus copi claus proof area set di mean claus obtain copi weaken claus claus exampl use copi step matrix indic origin knowledge-bas claus particip proof unit ki j indic claus proof area origin claus syntax j-th claus knowledg base must impos unit claus figur exampl claus proof second row assum ident claus number knowledg base therefor set constraint readi specifi constraint must satisfi unit proof found constraint specifi well form logic formula exampl formula impos constraint unit possibl valid assign unit general method implement arbitrari logic constraint connectionist network shown pinka most constraint specifi this section hard constraint must satisfi valid proof emerg toward end this section soft constraint present in-proof constraint if claus particip proof must either result resolut step copi step origin claus logic constraint may express vi ini resi cp'yi bi three unit per claus consist winner take subnetwork this mean one three unit actual set wta constraint may express resi-.. cp'yi bi cp'yi resi bi bi resi wta properti may enforc inhibitori connect everi pair three unit copi constraint if cpyi set claus must copi anoth claus proof this express vi p'yi v. di i i ni row dare wtas allowing-i copi one addit if claus copi weaken claus everi unit set claus must also set claus this may specifi vi j l resolut constraint if claus result resolv two claus must one one instanc cancel repres c. obtain copi instanc chi without instanc these constraint may express pinka vi re si vi ri i vi vi resi-ini+l vi re vi resi least one instanc cancel one instanc cancel wt.t cancel liter opposit sign two resolv also proof copi posit liter copi negat liter clause-inst constraint sign instanc claus uniqu therefor instanc pair in matrix cis wta vi column matrix wtas sinc instanc allow repres one atom prop06it va row may also wtas va i j f pa i- pa j this constraint impos in fol case knowledg base constraint if claus origin knowledg base claus must claus origin claus whose syntax forc upon unit i-th row matrix c. this constraint express vi bi vj ki i row wta network one origin claus forc unit claus vi hard constraint left forc syntax particular claus knowledg base assum exampl set mean claus in must syntax fourth claus in knowledg base exampl d instanc must alloc atom proposit respect must appear also in claus liter c- ij follow constraint captur syntax vi ij pc i vi exist negat liter bound exist posit liter bound d. fol extens in first-ord predic logic fol instead atom proposit must deal predic pinka for detail in proposit case liter in claus repres posit negat instanc howev instanc must alloc predic name may slot fill instanc repres function constant accommod complex a new matrix nest ad role matrix revis matrix must accommod function name predic name constant name instead atom proposit row repres a name column repres instanc alloc name row associ predic function may contain sever differ instanc predic function thus they wta anymor in order repres compound term predic instanc may bound slot instanc new matrix esn i p capabl repres bind if esn i p set instanc bound slot instanc column nest wta allow one instanc bound a certain slot anoth instanc when a claus forc syntax origin claus i syntact constraint trigger liter claus becom instanti relev predic function constant variabl impos claus i. construct proof in symmetr network unif implicit obtain if two predic repres instanc still satisfi constraint impos syntax two claus when a resolut step need network tri alloc instanc the two liter need cancel each if the syntact constraint the liter permit share instanc the attempt share the instanc success a unif occur occur check done implicit sinc the matrix nest allow the finit tree repres minim the violat soft constraint among the valid proof prefer other mean soft constraint optim possibl encourag the network search for prefer proof theorem-prov thus view a constraint optim problem a weight may assign each the constraint pinka the network tri minim the weight sum the violat constraint the set the optim solut exact the set the prefer proof for exampl prefer proof most general unif obtain assign small penalti negat bias everi bind a function a posit anoth instanc nest use similar techniqu the network made prefer shorter parsimoni reliabl proof low-cost plan even specif argument in nonmonoton reasonmg summari given a finit set claus the number differ predic function constant given also a bound the proof length we generat a network search for a proof length longer for a clamp queri q if a global minimum found answer given as whether exist a proof the proof mgu 's may extract the state the visibl unit among the possibl valid proof the system prefer some better proof by minim the violat soft constraint the concept better proof may appli applic like plan minim the cost abduct parsimoni nonmonoton reason specif in the proposit case the generat network km kn unit km kn connect for predica te logic there km kn unit connect we need add pm connect hidden unit the complexity-level the syntact constraint pinka the result improv an earlier approach ballard there restrict the rule allow everi proof longer the bound allow the network compact the represent bind unif effici nest function multipl use rule allow one relax phase need inconsist allow in the knowledg base the queri need negat pre-wir clamp queri time the architectur discuss a natur fault-toler capabl when a unit becom faulti it simpli assum a role in the proof unit alloc instead acknowledg i wish to thank dana ballard bill ball rina dechter peter had dawi dan kimura stan kwasni ron loui dave touretzki for pinka help conun
----------------------------------------------------------------

title: 237-a-reconfigurable-analog-vlsi-neural-network-chip.pdf

satyanarayana tsividi graf reconfigur analog vlsi neural network chip srinagesh satyanarayana yanni tsividi depart electr engin center telecommun research columbia univers new york ny usa han peter graf t bell laboratori holmdel nj usa abstract distributed-neuron synaps integr activ area use double-met single-poli n-well cmos technolog distributed-neuron synaps arrang block call tile switch matric interleav tile provid programm interconnect small area overhead unit network rearrang various configur possibl configur network network two network etc number separ dash indic number unit per layer includ input layer weight store analog form mas capacitor synapt weight usabl resolut full scale valu limit aris due charg inject access switch charg leakag paramet like gain shape nonlinear also programm introduct wide varieti ptoblem solv use neural network framework howev problem requir differ topolog weight set much lower system level perform network improv select suitabl neuron gain satur level hardwar realize reconfigur analog vlsi neural network chip hidcmn ntuyoft input input input figur reconfigur neural network provid fast mean solv problem chosen analog circuit implement neural network provid high synaps densiti high comput speed order provid general purpos hardwar solv wide varieti problem map neural network framework necessari make topolog weight neurosynapt paramet programm weight programm extens dealt sever implement howev featur like programm topolog neuron gain satur level address extens design fabric test analog vlsi neural network topolog weight neuron gain satur level programm sinc process design fabric test time-consum expens redesign hardwar applic ineffici sinc field neural network still infanc new solut problem search everyday involv modifi topolog find best weight set environ comput tool fulli programm desir concept reconfigur defin reconfigurabilitya abil alter topolog number oflay number neuron per layer interconnect layer layer interconnect within layer network topolog network describ valu synapt weight specifi presenc absenc synaps two neuron howev special case binari weight defin topolog specifi weight abil alter synapt weight defin weight programm figur illustr reconfigur wherea figur show weight valu realiz implement voltag vw across capacitor repres synapt weight alter voltag make weight programm possibl whi on-chip reconfigur import synaps neuron interconnect occupi real estat chip chip size limit due various factor like yield cost henc limit number satyanarayana tsividi graf figur weight programm synaps integr given chip area current compact realize consid bit synapt accuraci permit us integr thousand synaps per cm situat everi zero-valu inact synaps repres wast area decreas comput abil per unit area chip fix topolog network use differ problem underutil long synaps set zero valu hand if network reconfigur limit resourc on-chip realloc build network differ topolog effici exampl network topology-2 figur requir synaps if network reconfigur could util synaps build two-lay network synaps first layer second layer similar fashion could also build network topology-3 network local recept field distributed-neuron concept order provid reconfigur on-chip develop new cell call distributed-neuron synaps addit make reconfigur easi advantag like modular henc make design easi provid automat gain scale avoid larg current build-up point make possibl fault toler system figur show lump neuron synapt input we call lump circuit provid nonlinear function lump one block yout figur lump neuron synapt input recontigur analog vlsi neural network chip synaps assum voltage-to-curr transconductor cell neuron assum current-to-voltag cell summat achiev addit synaps output current parallel connect figur show equival distributed-neuron synapt input it call distribut circuit function neuron split part one part integr synaps new block contain synaps fraction neuron call distributed-neuron synaps detail distributed-neuron concept describ it note split neuron form distributed-neuron synaps done summat point comput linear henc two realize neuron comput equival howev distributedneuron implement offer number advantag explain yout distribut.d n.uron disiribui.d-n.uron s~nllps figur distributed-neuron synapt input modular design obvious figur task build complet network involv design one singl distributed-neuron synaps modul interconnect sever form whole system though circuit level fraction neuron integr synaps system level design simplifi due modular automat gain normal distributed-neuron unit neuron serv load output synaps number synaps input neuron increas number neuron element also increas number neuron output given yj wijxi yj output ph neuron wij weight ith synapt input 8j threshold implement connect parallel appropri number distributed-neuron synaps fix input assum satyanarayana tsividi graf distri bute neuron synaps figur switch use reconfigur distributed-neuron implement moment input maximum possibl valu it easili seen yj independ manifest automat gain normal inher idea distributed-neuron synaps eas reconfigur distributed-neuron implement reconfigur involv interconnect set distributed-neuron synaps modul figur neuron right size get form output requir number synaps connect lump neuron implement reconfigur involv interconnect set synaps set neuron involv wire switch logic control block void larg current build-up neuron implement synapt output current current sum kirchoff current law sent neuron sinc neuron distribut total current divid equal part where number distributedneuron synaps one these part flow unit distribut neuron illustr figur this obviat need larg current summat wire avoid problem associ larg current singl point fault toler vlsi chip defect common seen these defect short wire henc corrupt signal carri defect also render some synaps neuron defect implement we integr switch in-between group distributed-neuron synaps we call tile make chip reconfigur figur this make tile chip extern testabl defect section chip isol remain synaps thus reconfigur anoth topolog shown figur circuit descript distributed-neuron synaps figur show distributed-neuron synaps construct around differential-input differential-output transconduct multipli weight convert use con reconfigur analog vlsi neural network chip figur improv fault toler distributed-neuron system figur distributed-neuron synaps circuit vert single-end weight control voltag vw set differenti current serv bias current multipli weight store amo capacitor differenti natur circuit offer sever advantag like improv reject power suppli nois linear multipl common-mod feedback provid output synaps amplitud limit oper weight sum exceed certain rang serv as distributed-neuron part satur level neuron program adjust vn1 vn gain set adjust bias current ib and/or load shown measur synaps characterist shown figur satyanarayana tsividi graf if iii difterenti input wt fs wt fs wt o.oif wt fs wt fs individu curvel differ eight valu i fs full scale i figur measur characterist distributed-neuron synaps distributed-neuron synaps output wlr i l ml ttn symbol diagram actual on-chip wire dodd dodo tile horizont swi tch matri dodd dodd dodo dodd dodo dodo dodo dodo dodo synaps group figur organ distributed-neuron switch chip reconfigur analog vlsi neural network chip organ chip figur show distributed-neuron synaps arrang on-chip distributed-neuron synaps arrang crossbar fashion form 4-input-4-output network we call this tile input output wire avail four side tile this make interconnect adjac block easi vertic horizont switch matric interleav in-between tile select one various possibl mode interconnect these mode configur set bit memori switch matrix distributed-neuron synaps integr activ area use double-met single-poli n-well cmos technolog weight update/refresh scheme weight store analog form mos capacitor semi-serial-parallel weight updat scheme built pin chip use distribut weight capacitor chip pin refresh capacitor contain in row tile capacitor in each tile-row select one a time a decod maximum refresh speed depend time need charg weight storag capacitor parasit capacit one complet refresh weight chip possibl in j.l second howev one could refresh a much slower rate lower limit decid charg leakag a 7-bit precis in weight at room temperatur a refresh rate in order millisecond adequ charg inject due parasit capacit kept low use small switch in first version chip distributed-neuron synaps switch use reconfigur topolog memori integr weight store outsid chip in digit form in a 1k ram content ram continu read convert analog form use a bank off-chip a convert advantag scheme forward-pass oper interrupt weight refresh mechan a fast weight updat scheme type use desir execut learn algorithm at a high speed complet block diagram weight refresh/upd test scheme shown in figur configur exampl in figur we show some network topolog configur resourc avail chip left-hand side the figur show the actual wire on the chip the right-hand side show the symbol diagram the network configur the darken tile use implement the threshold sever topolog like feedback network network local recept field configur this chip the complet system figur show the neural network chip fit a complet system necessari use test the config-eprom store the bit pattern corr satyanarayana tsividi graf single-end duferenltl1 conyert weight ran neural networl conflg epron figur block diagram the system reconfigur weight update/refresh test spond the desir topolog this bit pattern down-load the memori cell the switch matric the start comput input vector read the data memori convert analog form d/a convert the output the a convert transform differenti signal then fed the chip the chip deliv differenti output convert digit form use an a/d convert store in a comput for analysi the delay in process one layer input drive anoth layer an equal number input typic 1j.lsec henc a network take 6j.lsec for one forward-pass oper howev extern load slow the comput consider this problem solv increas the bias current or/and use pad buffer each block on the chip test found function as expect test the complet chip in a varieti neural network configur plan conclus we design a reconfigur array distributed-neuron synaps configur sever differ type neural network the distributedneuron concept integr this chip offer advantag in term of modular automat gain normal the chip cascad with sever other chip of the type build larger system
----------------------------------------------------------------

title: 516-neural-network-routing-for-random-multistage-interconnection-networks.pdf

neural network rout random multistag interconnect network mark w. goudreau princeton univers nee research institut inc independ way princeton nj lee gile nec research institut inc independ way princeton nj abstract rout scheme use neural network develop aid establish point-to-point communic rout multistag interconnect network min neural network network type examin hopfield hopfield work problem establish rout random min rmin shared-memori distribut comput system address perform neural network rout scheme compar two tradit approach exhaust search rout greedi rout result suggest neural network router may competit certain rmin introduct neural network develop aid establish point-topoint communic rout multistag interconnect network min goudreau gile interconnect network wide studi huang siegel rout problem great interest due broad applic although neural network rout scheme accommod mani type communic system work concentr use shared-memori distribut comput system neural network sometim use solv certain interconnect network neural network rout random multistag interconnect network input port output port interconnect network control bit logic1 neural network interconnect logic2 network control i externa control figur communic system neural network router input port processor left output port memori modul right problem find legal rout brown hakim meadow increas throughput interconnect network brown liu marrakchi troudet neural network router subject work howev differ signific router special design handl parallel process system min random interstag connect random min call rmin rmin tend greater fault-toler regular min problem allow set processor access set memori modul rmin pictur communic system neural network router shown figur processor memori modul system assum synchron begin messag cycl set processor may desir access set memori modul job router establish mani desir connect possibl non-conflict manner obtain optim solut critic stymi processor may attempt communic subsequ messag cycl combin speed qualiti solut import object work discov neural network router could competit type router term qualiti solut speed resourc goudreau gile rmin2 rmini rmin3 figur three random multistag interconnect network block shown crossbar switch input may connect output util end neural scheme rout rmin rout so far result router may inde practic larg network rout scheme compar two name exhaust search rout greedi investig suggest neural network altern rout rmin exhaust search rout exhaust search rout method optim term abil router find best solut mani way implement such router one approach describ given interconnect network everi rout input output store databas rmin use test case paper alway least one rout processor memori modul new messag cycl began new messag set present router router would search databas combin rout messag set conflict conflict said occur one rout set rout use singl bus interconnect network case everi combin rout messag set conflict router would find combin rout could establish largest possibl number desir connect possibl rout messag algorithm need memori size mnk worst case take exponenti time respect size neural network rout random multistag interconnect network messag set consequ impract approach rmin provid conveni upper bound perform router greedi rout greedi rout appli messag connect establish one time onc rout establish given messag cycl may remov greedi rout alway provid optim rout solut greedi rout algorithm use requir rout databas exhaust search router howev select combin rout follow manner new messag set present router choos one desir messag look first rout messag 's list rout router establish rout next router examin second messag assum second desir messag request see one rout second messag 's rout list establish without conflict alreadi establish first messag such rout exist router establish rout move next desir messag worst case speed greedi router quadrat respect size messag set neural network rout focal point neural network router neural network type examin hopfield hopfield problem establish set non-conflict rout reduc constraint satisfact problem structur neural network router complet determin rmin when new set rout desir certain bias current network chang neural network rout scheme also certain fault-toler properti describ neural network calcul rout converg legal rout array legal rout array 3-dimension therefor element rout array three indic element ai i k equal messag rout output port stage we say row if i column if i final they rod if legal rout array satisfi follow three constraint one one element column equal element success column equal repres output port connect interconnect network one element rod equal first restrict ensur messag rout one one output port stage interconnect network second restrict ensur messag rout legal path goudreau gile interconnect network third restrict ensur resourc content interconnect network resolv word one messag use certain output port certain stage interconnect network when three constraint met rout array provid legal rout messag messag set like rout array neural network router natur 3-dimension structur ai j k rout array repres output voltag neuron at begin messag cycl neuron random output voltag if neural network settl one global minima problem solv continu time mode network chosen simul digit neural network neuron input neuron ui input bias current ii output vi input ui convert output vi sigmoid function neuron influenc neuron connect repres similar neuron affect neuron connect iij order liapunov function equat construct iij must equal7ji we assum iii synchron updat model also time constant denot t. equat describ output neuron duo ln t dt t=rc g uj e-x equat forc neural net stabl state local minima approxim energi equat inn 2l iij vi v'i ii i=l neural network weight iii 's set bias current it output voltag vari minim e. let number messag messag set let number stage rmin let number port per stage may function stage number below energi function implement three constraint discuss e1 e2 p=l vm i p neural network rout random multistag interconnect network ea s-l m=l p=l tt i=l vm i jim j vm ij pm vm s ij arbitrari posit constant el ea handl first constraint rout array e4 deal second constraint e2 ensur third equat function sl pl p2 repres distanc output port pi stage sl output port p2 from stage if pi connect p2 stage sl distanc may set zero if pi p2 connect stage sl distanc may set one also sourc address messag f3m destin address messag entir energi function solv connect bias current valu shown equat result follow equat oml m2 1m p kroneck delta when otherwis essenti approach promis neural network act parallel comput hope neural network generat solut much faster convent approach rout rmin neural network use standard problem name global minimum alway reach but serious difficulti typic when global minim energi reach neural network desir rout calcul other even local minim solut may partial solv rout problem consequ would seem particular encourag type applic type neural network applic tradit problem reach global minimum may hurt system 's perform much expect speed neural network calcul solut a great asset ifor simul a chosen empir valu a goudreau gile tabl rout result rmin shown figur calcul due comput complex rmin1 rmin2 entri rmin3 eel egr enn eel egr enn eel egr enn neural network router use a larg number neuron if input port output port each stage rmin upper bound number neuron need s. often howev number neuron actual requir much smaller upper bound it shown empir neural network the type use con verg a solut essenti constant time exampl claim made the neural network describ takefuji lee a slight variat the model use simul result figur show three rmin examin the rout result the three rout scheme shown in tabl eel repres the expect number messag rout use exhaust search rout egr greedi rout enn neural network rout valu function the size the messag set m. onli messag set obvious conflict examin exampl messag set could two processor tri communic the memori modul the tabl show at least three rmin the three rout scheme produc solut similar virtu in case the neural network router appear outperform the suppos optim exhaust search router the eel egr valu calcul test everi messag set size enn calcul test random generat messag set size m. the neural network router appear perform best it must gotten messag set easier rout averag in general the perform the neural network router degener the size the rmin increas it felt the neural network router in present form scale well for larg rmin this work shown larg neural network the type use difficulti converg a valid solut hopfield neural network rout for random multistag interconnect network conclus the result show there much differ in term qualiti solut for the three rout methodolog work relat small sampl rmin the exhaust search approach clear a practic approach sinc it time consum but when consid the asymptot analys for these three methodolog one keep in mind the perform degrad the greedi router the neural network router the size the rmin increas greedi rout neural network rout would appear valid approach for rmin moder size but sinc asymptot analysi a limit signific the best way compar the speed these two rout scheme would to build actual implement sinc the neural network router essenti calcul the rout in parallel it reason hope a fast analog implement for the neural network router may find solut faster the exhaust search router even the greedi router thus the neural network router may a viabl altern for rmin that larg
----------------------------------------------------------------

