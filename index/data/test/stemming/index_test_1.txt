query sentence: weakest link in subnetworks
---------------------------------------------------------------------
title: 3491-measures-of-clustering-quality-a-working-set-of-axioms-for-clustering.pdf

Measures of Clustering Quality: A Working Set of
Axioms for Clustering

Margareta Ackerman and Shai Ben-David
School of Computer Science
University of Waterloo, Canada

Abstract
Aiming towards the development of a general clustering theory, we discuss abstract axiomatization for clustering. In this respect, we follow up on the work of
Kleinberg, ([1]) that showed an impossibility result for such axiomatization. We
argue that an impossibility result is not an inherent feature of clustering, but rather,
to a large extent, it is an artifact of the specific formalism used in [1].
As opposed to previous work focusing on clustering functions, we propose to
address clustering quality measures as the object to be axiomatized. We show that
principles like those formulated in Kleinberg?s axioms can be readily expressed in
the latter framework without leading to inconsistency.
A clustering-quality measure (CQM) is a function that, given a data set and its partition into clusters, returns a non-negative real number representing how strong or
conclusive the clustering is. We analyze what clustering-quality measures should
look like and introduce a set of requirements (axioms) for such measures. Our
axioms capture the principles expressed by Kleinberg?s axioms while retaining
consistency.
We propose several natural clustering quality measures, all satisfying the proposed
axioms. In addition, we analyze the computational complexity of evaluating the
quality of a given clustering and show that, for the proposed CQMs, it can be
computed in polynomial time.

1

Introduction

In his highly influential paper, [1], Kleinberg advocates the development of a theory of clustering that
will be ?independent of any particular algorithm, objective function, or generative data model.? As a
step in that direction, Kleinberg sets up a set of ?axioms? aimed to define what a clustering function
is. Kleinberg suggests three axioms, each sounding plausible, and shows that these seemingly natural
axioms lead to a contradiction - there exists no function that satisfies all three requirements.
Kleinberg?s result is often interpreted as stating the impossibility of defining what clustering is, or
even of developing a general theory of clustering. We disagree with this view. In this paper we show
that the impossibility result is, to a large extent, due to the specific formalism used by Kleinberg
rather than being an inherent feature of clustering.
Rather than attempting to define what a clustering function is, and demonstrating a failed attempt,
as [1] does, we turn our attention to the closely related issue of evaluating the quality of a given
data clustering. In this paper we develop a formalism and a consistent axiomatization of that latter
notion.
As it turns out, the clustering-quality framework is richer and more flexible than that of clustering
functions. In particular, it allows the postulation of axioms that capture the features that Kleinberg?s
axioms aim to express, without leading to a contradiction.
1

A clustering-quality measure is a function that maps pairs of the form (dataset, clustering) to
some ordered set (say, the set of non-negative real numbers), so that these values reflect how ?good?
or ?cogent? that clustering is.
Measures for the quality of a clusterings are of interest not only as a vehicle for axiomatizing clustering. The need to measure the quality of a given data clustering arises naturally in many clustering
issues. The aim of clustering is to uncover meaningful groups in data. However, not any arbitrary
partitioning of a given data set reflects such a structure. Upon obtaining a clustering, usually via
some algorithm, a user needs to determine whether this clustering is sufficiently meaningful to rely
upon for further data mining analysis or practical applications. Clustering-quality measures (CQMs)
aim to answer that need by quantifying how good is any specific clustering.
Clustering-quality measures may also be used to help in clustering model-selection by comparing
different clusterings over the same data set (e.g., comparing the results of a given clustering paradigm
over different choices of clustering parameters, such as the number of clusters).
When posed with the problem of finding a clustering-quality measure, a first attempt may be to
invoke the loss (or objective) function used by a clustering algorithm, such as k-means or k-median,
as a clustering-quality measure. However, such measures have some shortcomings for the purpose
at hand. Namely, these measures are usually not scale-invariant, and they cannot be used to compare
the quality of clusterings obtained by different algorithms aiming to minimize different clustering
costs (e.g., k-means with different values of k). See Section 6 for more details.
Clustering quality has been previously discussed in the applied statistics literature, where a variety
of techniques for evaluating ?cluster validity? were proposed. Many of these methods, such as the
external criteria discussed in [2], are based on assuming some predetermined data generative model,
and as such do not answer our quest for a general theory of clustering. In this work, we are concerned
with quality measures regardless of any specific generative model, for examples, see the internal
criteria surveyed in [2].
We formulate a theoretical basis for clustering-quality evaluations. We propose a set of requirements (?axioms?) of clustering-quality measures. We demonstrate the relevance and consistency of
these axioms by showing that several natural notions satisfy these requirements. In particular, we
introduce quality-measures that reflect the underlying intuition of center-based and linkage-based
clustering. These notions all satisfy our axioms, and, given a data clustering, their value on that
clustering can be computed in polynomial time.
Paper outline: we begin by presenting Kleinberg?s axioms for clustering functions and discuss their
failure. In Section 4.3 we show how these axioms can be translated into axioms pertaining clustering
quality measures, and prove that the resulting set of axioms is consistent. In Section 4, we discuss
desired properties of an axiomatization and propose an accordingly revised set of axioms. Next, in
Section 5 we present several clustering-quality measures, and claim that they all satisfy our axioms.
Finally, in Section 5.3, we show that the quality of a clustering can be computed in polynomial time
with respect to our proposed clustering-quality measures.

2

Definitions and Notation

Let X be some domain set (usually finite). A function d : X ? X ? R is a distance function over
X if d(xi , xi ) ? 0 for all xi ? X, for any xi , xj ? X, d(xi , xj ) > 0 if and only if xi 6= xj , and
d(xi , xj ) = d(xj , xi ) otherwise. Note that we do not require the triangle inequality.
A k-clustering of X is a k-partition, C = {C1 , C2 , . . . , Ck }. That is, Ci ? Cj = ? for i 6= j and
?ki=1 Ci = X. A clustering of X is a k-clustering of X for some k ? 1. A clustering is trivial if
each of its clusters contains just one point, or if it consists of just one cluster.
For x, y ? X and clustering C of X, we write x ?C y whenever x and y are in the same cluster of
clustering C and x 6?C y, otherwise.
A clustering function for some domain set X is a function that takes a distance function d over X,
and outputs a clustering of X.
2

A clustering-quality measure (CQM) is a function that is given a clustering C over (X, d) (where
d is a distance function over X) and returns a non-negative real number, as well as satisfies some
additional requirements. In this work we explore the question of what these requirements should be.

3

Kleinberg?s Axioms

Kleinberg, [1], proposes the following three axioms for clustering functions. These axioms are
intended to capture the meaning of clustering by determining which functions (from a domain set
endowed with a distance function) are worthy of being considered clustering functions and which
are not. Kleinberg shows that the set is inconsistent - there exist no functions that satisfies all three
axioms.
The first two axioms require invariance of the clustering that f defines under some changes of the
input distance function.
Function Scale Invariance: Scale invariance requires that the output of a clustering function be
invariant to uniform scaling of the input.
A function f is scale-invariant if for every distance function d and positive ?, f (d) = f (?d) (where
?d is defined by setting, for every pair of domain points x, y, ?d(x, y) = ? ? d(x, y)).
Function Consistency: Consistency requires that if within-cluster distances are decreased, and
between-cluster distances are increased, then the output of a clustering function does not change.
Formally,
? Given a clustering C over (X, d), a distance function d0 is a C-consistent variant of d, if
d0 (x, y) ? d(x, y) for all x ?C y, and d0 (x, y) ? d(x, y) for all x 6?C y.
? A function f is consistent if f (d) = f (d0 ) whenever d0 is an f (d)-consistent variant of d.
Function Richness: Richness requires that by modifying the distance function, any partition of the
underlying data set can be obtained.
A function f is rich if for each partitioning, C, of X, there exists a distance function d over X so
that f (d) = C.
Theorem 1 (Kleinberg, [1]) There exists no clustering function that simultaneously satisfies scale
invariance, consistency and richness.
Discussion: The intuition behind these axioms is rather clear. Let us consider, for example, the
Consistency requirement. It seems reasonable that by pulling closer points that are in the same
cluster and pushing further apart points in different clusters, our confidence in the given clustering
will only rise. However, while this intuition can be readily formulated in terms of clustering quality
(namely, ?changes as these should not decrease the quality of a clustering?), the formulation through
clustering functions says more. It actually requires that such changes to the underlying distance
function should not create any new contenders for the best-clustering of the data.
For example, consider Figure 1, where we illustrate a good 6-clustering. On the right hand-side, we
show a consistent change of this 6-clustering. Notice that the resulting data has a 3-clustering that is
reasonably better than the original 6-clustering. While one may argue that the quality of the original
6-clustering has not decreased as a result of the distance changes, the quality of the 3-clustering has
improved beyond that of the 6-clustering. This illustrates a significant weakness of the consistency
axiom for clustering functions.
The implicit requirement that the original clustering remains the best clustering following a consistent change is at the heart of Kleinberg?s impossibility result. As we shall see below, once we relax
that extra requirement the axioms are no longer unsatisfiable.

4

Axioms of Clustering-Quality Measures

In this section we change the primitive that is being defined by the axioms from clustering functions
to clustering-quality measures (CQM). We reformulate the above three axioms in terms of CQMs
3

Figure 1: A consistent change of a 6-clustering.
and show that this revised formulation is not only consistent, but is also satisfied by a number of
natural clustering quality measures. In addition, we extend the set of axioms by adding another
axiom (of clustering-quality measures) that is required to rule out some measures that should not be
counted as CQMs.
4.1

Clustering-Quality Measure Analogues to Kleinberg?s Axioms

The translation of the Scale Invariance axiom to the CQM terminology is straightforward:
Definition 1 (Scale Invariance) A quality measure m satisfies scale invariance if for every clustering C of (X, d), and every positive ?, m(C, X, d) = m(C, X, ?d).
The translation of the Consistency axiom is the place where the resulting CQM formulation is indeed
weaker than the original axiom for functions. While it clearly captures the intuition that consistent
changes to d should not hurt the quality of a given partition, it allows the possibility that, as a result
of such a change, some partitions will improve more than others1 .
Definition 2 (Consistency) A quality measure m satisfies consistency if for every clustering C over
(X, d), whenever d0 is a C consistent variant of d, then m(C, X, d0 ) ? m(C, X, d).
Definition 3 (Richness) A quality measure m satisfies richness if for each non-trivial clustering C
of X, there exists a distance function d over X such that C = Argmax{m(C, X, d)}.
Theorem 2 Consistency, scale invariance, and richness for clustering-quality measures form a consistent set of requirements.
Proof: To show that scale-invariance, consistency, and richness form a consistent set of axioms, we
present a clustering quality measure that satisfies the three axioms. This measure captures a quality
that is intuitive for center-based clusterings. In Section 5, we introduce more quality measures that
capture the goal of other types of clusterings. All of these CQM?s satisfy the above three axioms.
For each point in the data set, consider the ratio of the distance from the point to its closest center to
the distance from the point to its second closest center. Intuitively, the smaller this ratio is, the better
the clustering (points are ?more confident? about their cluster membership). We use the average of
this ratio as a quality measure.
Definition 4 (Relative Point Margin) The K-Relative Point Margin of x ? X is K-RMX,d (x) =
d(x,cx )
0
d(x,cx0 ) , where cx ? K is the closest center to x, cx ? K is a second closest center to x, and
K ? X.
1
The following formalization assumes that larger values of m indicate better clustering quality. For some
quality measures, smaller values indicate better clustering quality - in which case we reverse the direction of
inequalities for consistency and use Argmin instead of Argmax for richness.

4

A set K is a representative set of a clustering C if it consists of exactly one point from each cluster
of C.
Definition 5 (Representative Set) A set K is a representative set of clustering C
{C1 , C2 , . . . , Ck } if |K| = k and for all i, K ? Ci 6= ?.

=

Definition 6 (Relative Margin) The Relative Margin of a clustering C over (X, d) is
RMX,d (C) =

min

K is a representative set of C

avgx?X\K K-RMX,d (x).

Smaller values of Relative Margin indicate better clustering quality.
Lemma 1 Relative Margin is scale-invariant.
proof: Let C be a clustering of (X, d). Let d0 be a distance function so that d0 (x, y) = ?d(x, y)
d0 (x,y)
for all x, y ? X and some ? ? R+ . Then for any points x, y, z ? X, d(x,y)
d(x,z) = d0 (x,z) . Note also
that scaling does not change the centers selected by Relative Margin. Therefore, RMX,d0 (C) =
RMX,d (C).
Lemma 2 Relative Margin is consistent.
proof: Let C be a clustering of distance function (X, d). Let d0 be a C consistent variant of d. Then
for x ?C y, d0 (x, y) ? d(x, y) and for x 6?C y, d0 (x, y) ? d(x, y). Therefore, RMX,d0 (C) ?
RMX,d (C).
Lemma 3 Relative Margin is rich.
proof: Given a non-trivial clustering C over a data set X, consider the distance function d where
d(x, y) = 1 for all x ?C y, and d(x, y) = 10 for all x 6?C y. Then C = Argmin{m(C, X, d)}.
It follows that scale-invariance, consistency, and richness are consistent axioms.
4.2

Soundness and Completeness of Axioms

What should a set of ?axioms for clustering? satisfy? Usually, when a set of axioms is proposed
for some semantic notion (or a class of objects, say clustering functions), the aim is to have both
soundness and completeness. Soundness means that every element of the described class satisfies
all axioms (so, in particular, soundness implies consistency of the axioms), and completeness means
that every property shared by all objects of the class is implied by the axioms. Intuitively, ignoring
logic subtleties, a set of axioms is complete for a class of objects if any element outside that class
fails at least one of these axioms.
In our context, there is a major difficulty - there exist no semantic definition of what clustering is.
We wish to use the axioms as a definition of clustering functions, but then what is the meaning of
soundness and completeness? We have to settle for less. While we do not have a clear definition of
what is clustering and what is not, we do have some examples of functions that should be considered
clustering functions, and we can come up with some examples of partitionings that are clearly not
worthy of being called ?clustering?. We replace soundness by the requirement that all of our axioms
are satisfied by all these examples of common clustering functions (relaxed soundness), and we want
that partitioning functions that are clearly not clusterings fail at least one of our axioms (relaxed
completeness).
In this respect, the axioms of [1] badly fail (the relaxed version of) soundness. For each of these
axioms there are natural clustering functions that fail to satisfy it (this is implied by Kleinberg?s
demonstration that any pair of axioms is satisfied by a natural clustering, while the three together
never hold). We argue that our scale invariance, consistency, and richness, are sound for the class
of CQMs. However, they do not make a complete set of axioms, even in our relaxed sense. There
are functions that should not be considered ?reasonable clustering quality measures? and yet they
satisfy these three axioms. One type of ?non-clustering-functions? are functions that make cluster
membership decisions based on the identity of domain points. For example, the function that returns
5

the Relative Margin of a data set whenever some specific pair of data points belong to the same
cluster, and twice the Relative Margin of the data set otherwise. We overcome this problem by
introducing a new axiom.
4.3

Isomorphism Invariance

This axiom resembles the permutation invariance objective function axiom by Puzicha et al. [3],
modeling the requirement that clustering should be indifferent to the individual identity of clustered elements. This axiom of clustering-quality measures does not have a corresponding Kleinberg
axiom.
Definition 7 (Clustering Isomorphism) Two clusterings C and C 0 over the same domain, (X, d),
are isomorphic, denoted C ?d C 0 , if there exists a distance-preserving isomorphism ? : X ? X,
such that for all x, y ? X, x ?C y if and only if ?(x) ?C 0 ?(y).
Definition 8 (Isomorphism Invariance) A quality measure m is isomorphism -invariant if for all
clusterings C, C 0 over (X, d) where C ?d C 0 , m(C, X, d) = m(C 0 , X, d).
Theorem 3 The set of axioms consisting of Isomorphism Invariance, Scale Invariance, Consistency,
and Richness, (all in their CQM formulation) is a consistent set of axioms.
Proof: Just note that the Relative Margin quality measure satisfies all four axioms.
As mentioned in the above discussion, to have a satisfactory axiom system, for any notion, one needs
to require more than just consistency. To be worthy of being labeled ?axioms?, the requirements we
propose should be satisfied by any reasonable notion of CQM. Of course, since we cannot define
what CQMs are ?reasonable?, we cannot turn this into a formal statement. What we can do, however,
is demonstrate that a variety of natural CQMs do satisfy all our axioms. This is done in the next
section.

5

Examples of Clustering Quality Measures

In a survey of validity measures, Milligan [2] discusses examples of quality measures that satisfy
our axioms (namely, scale-invariance, consistency, richness, and perturbation invariance). We have
verified that the best performing internal criteria examined in [2], satisfy all our axioms.
In this section, we introduce two novel QCMs; a measure that reflects the underlying intuition of
linkage-based clustering, and a measure for center-based clustering. In addition to satisfying the
axioms, given a clustering, these measures can computed in polynomial time.
5.1

Weakest Link

In linkage-based clustering, whenever a pair of points share the same cluster they are connected via
a tight chain of points in that cluster. The weakest link quality measure focuses on the longest link
in such a chain.
Definition 9 (Weakest Link Between Points)
C-W LX,d (x, y) =

min

x1 ,x2 ,...,x` ?Ci

(max(d(x, x1 ), d(x1 , x2 ), . . . , d(x` , y))),

where C is a clustering over (X, d) and Ci is a cluster in C.
The weakest link of C is the maximal value of C-W LX,d (x, y) over all pairs of points belonging to
the same cluster, divided by the shortest between-cluster distance.
Definition 10 (Weakest Link of C) The Weakest Link of a clustering C over (X, d) is
W L(C) =

maxx?C y C-W LX,d (x, y)
.
minx6?C y d(x, y)

The range of values of weakest link is (0, ?).
6

5.2

Additive Margin

In Section 4.3, we introduced Relative Margin, a quality measure for center-based clustering. We
now introduce another quality measure for center-based clustering. Instead of looking at ratios,
Additive Margin evaluates differences.
Definition 11 (Additive Point Margin) The K-Additive Point Margin of x is K-AMX,d (x) =
d(x, cx0 ) ? d(x, cx ), where cx ? K is the closest center to x, cx0 ? K is a second closest center to x, and K ? X.
The Additive Margin of a clustering is the average Additive Point Margin, divided by the average
within-cluster distance. The normalization is necessary for scale invariance.
Definition 12 (Additive Margin) The Additive Margin of a center-based clustering C over (X, d)
is
P
1
x?X K-AMX,d (x)
|X|
P
AMX,d (C) =
min
.
1
K is a representative set of C
x?C y d(x, y)
|{{x,y}?X|x?C y}|
Unlike Relative Margin, Additive Margin gives higher values to better clusterings.
5.3

Computational complexity

For a clustering-quality measure to be useful, it is important to be able to quickly compute the quality
of a clustering using that measure. The quality of a clustering using the measures presented in this
paper can be computed in polynomial time in terms of n (the number of points in the data set).
Using relative or Additive Margin, it takes O(nk+1 ) operations to compute the clustering quality
of a data set, which is exponential in k. If a set of centers is given, the Relative Margin can be
computed in O(nk) operations and the Additive Margin can be computed in O(n2 ) operations. The
weakest link of a clustering can be computed in O(n3 ) operations.
5.4

Variants of quality measures

Given a clustering-quality measure, we can construct new quality measures with different characteristics by applying the quality measure on a subset of clusters. It suffices to consider a quality
measure m that is defined for clusterings consisting of 2 clusters. Given such measure, we can
create new quality measures. For example,
mmin (C, X, d) =

min

m(S, X, d),

S?C,|S|=2

measures the worst quality of a pair of clusters in C.
Alternately, we can define, mmax (C, X, d) and mavg (C, X, d), which evaluate the best or average
quality of a pair of clusters in C. A nice feature of these variations is that if m satisfies the four
axioms of clustering-quality measures then so do mmin , mmax , and mavg .
More generally, if m is defined for clusterings on an arbitrary number of clusters, we can define a
quality measure as a function of m over larger clusterings. For example, mmax subset (C, X, d) =
maxS?C,|S|?2 m(S, X, d). Many such variations, which apply existing clustering-quality measures
on subsets of clusters, satisfy the axioms of clustering-quality measures whenever the original quality measure satisfies the axioms.

6

Dependence on Number of Clusters

The clustering-quality measures discussed in this paper up to now are independent of the number
of clusters, which enables the comparison of clusterings with a different number of clusters. In this
section we discuss an alternative type of clustering quality evaluation, that depends on the number of
clusters. Such quality measures arise naturally from common loss functions (or, objective functions)
that drive clustering algorithm, such as k-means or k-median.
7

These common loss functions fail to satisfy two of our axioms, scale-invariance and richness. One
can easily overcome the dependence on scaling by normalization. As we will show, the resulting
normalized loss functions make a different type of clustering-quality measures from the measures
we previously discussed, due to their dependence on the number of clusters.
A natural remedy to the failure of scale invariance is to normalize a loss function by dividing it by
the variance of the data, or alternatively, by the loss of the 1-clustering of the data.
Definition 13 (L-normalization) The L-normalization of a clustering C over (X, d) is
L-normalize(C, X, d) =

L(Call , X, d)
.
L(C, X, d)

where Call denotes the 1-clustering of X.
Common loss functions, even after normalization, usually have a bias towards either more refined
or towards more coarse clusterings ? they assign lower cost (that is, higher quality) to more refined
(respectively, coarse) clusterings. This prevents using them as a meaningful tool for comparing
the quality of clusterings with different number of clusters. We formalize this feature of common
clustering loss functions through the notion of refinement preference:
Definition 14 (Refinement and coarsening) For a pair of clusterings C, C 0 of the same domain,
we say C 0 is a refinement of C (or, equivalently, that C is a coarsening of C 0 ) if for every cluster Ci
of C, Ci is a union of clusters of C 0 .
Definition 15 (Refinement/Coarsening Preference) A measure m is refinement-preferring if for
every clustering C of (X, d) if it has a non-trivial refinement, then there exists such a refinement C 0 of
C for which m(C 0 , X, d) > m(C, X, d). Coarsening-preferring measures are defined analogously.
Note that both refinement preferring and coarsening preferring measures fail to satisfy the Richness
axiom.
It seems that there is a divide between two types of evaluations for clusterings; those that satisfy
richness, and those that satisfy either refinement or coarsening preference. To evaluate the quality of
a clustering using a refinement (and coarsening) preferring measure, it is essential to fix the number
of clusters. Since the correct number of clusters is often unknown, measures that are independent of
the number of clusters apply in a more general setting.

7

Conclusions

We have investigated the possibility of providing a general axiomatic basis for clustering. Our
starting point was the impossibility result of Kleinberg. We argue that a natural way to overcome
these negative conclusions is by changing the primitive used to formulate the axioms from clustering
functions to clustering quality measures (CQMs). We demonstrate the merits of the latter framework
by providing a set of axioms for CQMs that captures the essence of all of Kleinberg?s axioms while
maintaining consistency. We propose several CQMs that satisfy our proposed set of axioms. We
hope that this work, and our demonstration of a way to overcome the ?impossibility result? will
stimulate further research towards a general theory of clustering.

References
[1] Jon Kleinberg. ?An Impossibility Theorem for Clustering.? Advances in Neural Information Processing
Systems (NIPS) 15, 2002.
[2] Glen W. Milligan. ?A Monte-Carlo study of 30 internal criterion measures for cluster-analysis.? Psychometrica 46, 187-195, 1981.
[3] J. Puzicha, T. Hofmann, and J. Buhmann. ?Theory of Proximity Based Clustering: Structure Detection by
Optimization,? Pattern Recognition, 33(2000).

8


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4659-topic-partitioned-multinetwork-embeddings.pdf

Topic-Partitioned Multinetwork Embeddings

Peter Krafft?
CSAIL
MIT
pkrafft@mit.edu

?

Juston Moore? , Bruce Desmarais? , Hanna Wallach?
Department of Computer Science, ? Department of Political Science
University of Massachusetts Amherst
?
{jmoore, wallach}@cs.umass.edu
?
desmarais@polsci.umass.edu

Abstract
We introduce a new Bayesian admixture model intended for exploratory analysis of communication networks?specifically, the discovery and visualization of
topic-specific subnetworks in email data sets. Our model produces principled visualizations of email networks, i.e., visualizations that have precise mathematical
interpretations in terms of our model and its relationship to the observed data.
We validate our modeling assumptions by demonstrating that our model achieves
better link prediction performance than three state-of-the-art network models and
exhibits topic coherence comparable to that of latent Dirichlet allocation. We
showcase our model?s ability to discover and visualize topic-specific communication patterns using a new email data set: the New Hanover County email network.
We provide an extensive analysis of these communication patterns, leading us to
recommend our model for any exploratory analysis of email networks or other
similarly-structured communication data. Finally, we advocate for principled visualization as a primary objective in the development of new network models.

1

Introduction

The structures of organizational communication networks are critical to collaborative problem solving [1]. Although it is seldom possible for researchers to directly observe complete organizational
communication networks, email data sets provide one means by which they can at least partially observe and reason about them. As a result?and especially in light of their rich textual detail, existing
infrastructure, and widespread usage?email data sets hold the potential to answer many important scientific and practical questions within the organizational and social sciences. While some
questions may be answered by studying the structure of an email network as a whole, other, more
nuanced, questions can only be answered at finer levels of granularity?specifically, by studying
topic-specific subnetworks. For example, breaks in communication (or duplicated communication)
about particular topics may indicate a need for some form of organizational restructuring. In order to
facilitate the study of these kinds of questions, we present a new Bayesian admixture model intended
for discovering and summarizing topic-specific communication subnetworks in email data sets.
There are a number of probabilistic models that incorporate both network and text data. Although
some of these models are specifically for email networks (e.g., McCallum et al.?s author?recipient?
topic model [2]), most are intended for networks of documents, such as web pages and the links
between them [3] or academic papers and their citations [4]. In contrast, an email network is more
naturally viewed as a network of actors exchanging documents, i.e., actors are associated with nodes
while documents are associated with edges. In other words, an email network defines a multinetwork
in which there may be multiple edges (one per email) between any pair of actors. Perhaps more
importantly, much of the recent work on modeling networks and text has focused on tasks such as
?

Work done at the University of Massachusetts Amherst

1

=

+

+

Figure 1: Our model partitions an observed email network (left) into topic-specific subnetworks
(right) by associating each author?recipient edge in the observed network with a single topic.
predicting links or detecting communities. Instead, we take a complementary approach and focus on
exploratory analysis. Specifically, our goal is to discover and visualize topic-specific subnetworks.
Rather than taking a two-stage approach in which subnetworks are discovered using one model and
visualized using another, we present a single probabilistic model that partitions an observed email
network into topic-specific subnetworks while simultaneously producing a visual representation of
each subnetwork. If network modeling and visualization are undertaken separately, the resultant visualizations may not directly reflect the model and its relationship to the observed data. Rather, these
visualizations provide a view of the model and the data seen through the lens of the visualization
algorithm and its associated assumptions, so any conclusions drawn from such visualizations can be
biased by artifacts of the visualization algorithm. Producing principled visualizations of networks,
i.e., visualizations that have precise interpretations in terms of an associated network model and its
relationship to the observed data, remains an open challenge in statistical network modeling [5].
Addressing this open challenge was a primary objective in the development of our new model.
In order to discover and visualize topic-specific subnetworks, our model must associate each author?
recipient edge in the observed email network with a topic, as shown in Figure 1. Our model draws
upon ideas from latent Dirichlet allocation (LDA) [6] to identify a set of corpus-wide topics of
communication, as well as the subset of topics that best describe each observed email. We model
network structure using an approach similar to that of Hoff et al.?s latent space model (LSM) [7] so
as to facilitate visualization. Given an observed network, LSM associates each actor in the network
with a point in K-dimensional Euclidean space. For any pair of actors, the smaller the distance
between their points, the more likely they are to interact. If K = 2 or K = 3, these interaction
probabilities, collectively known as a ?communication pattern?, can be directly visualized in 2- or
3-dimensional space via the locations of the actor-specific points. Our model extends this idea by
associating a K-dimensional Euclidean space with each topic. Observed author?recipient edges are
explicitly associated with topics via the K-dimensional topic-specific communication patterns.
In the next section, we present the mathematical details of our new model and outline a corresponding inference algorithm. We then introduce a new email data set: the New Hanover County (NHC)
email network. Although our model is intended for exploratory analysis, we test our modeling assumptions via three validation tasks. In Section 4.1, we show that our model achieves better link
prediction performance than three state-of-the-art network models. We also demonstrate that our
model is capable of inferring topics that are as coherent as those inferred using LDA. Together,
these experiments indicate that our model is an appropriate model of network structure and that
modeling this structure does not compromise topic quality. As a final validation experiment, we
show that synthetic data generated using our model possesses similar network statistics to those of
the NHC email network. In Section 4.4, we showcase our model?s ability to discover and visualize
topic-specific communication patterns using the NHC network. We give an extensive analysis of
these communication patterns and demonstrate that they provide accessible visualizations of emailbased collaboration while possessing precise, meaningful interpretations within the mathematical
framework of our model. These findings lead us to recommend our model for any exploratory analysis of email networks or other similarly-structured communication data. Finally, we advocate for
principled visualization as a primary objective in the development of new network models.

2

Topic-Partitioned Multinetwork Embeddings

In this section, we present our new probabilistic generative model (and associated inference algorithm) for communication networks. For concreteness, we frame our discussion of this model in
2

terms of email data, although it is generally applicable to any similarly-structured communication
data. The generative process and graphical model are provided in the supplementary materials.
(d)

(d)

A single email, indexed by d, is represented by a set of tokens w(d) = {wn }N
n=1 that comprise the
text of that email, an integer a(d) ? {1, ..., A} indicating the identity of that email?s author, and a
(d)
set of binary variables y (d) = {yr }A
r=1 indicating whether each of the A actors in the network is
a recipient of that email. For simplicity, we assume that authors do not send emails to themselves
(d)
(i.e., yr = 0 if r = a(d) ). Given a real-world email data set D = {{w(d) , a(d) , y (d) }}D
d=1 , our
model permits inference of the topics expressed in the text of the emails, a set of topic-specific
K-dimensional embeddings (i.e., points in K-dimensional Euclidean space) of the A actors in the
network, and a partition of the full communication network into a set of topic-specific subnetworks.
As in LDA [6], a ?topic? t is characterized by a discrete distribution over V word types with probability vector ?(t) . A symmetric Dirichlet prior with concentration parameter ? is placed over
? = {?(1) , ..., ?(T ) }. To capture the relationship between the topics expressed in an email and
that email?s recipients, each topic t is also associated with a ?communication pattern?: an A ? A
(t)
matrix of probabilities P (t) . Given an email about topic t, authored by actor a, element par is the
probability of actor a including actor r as a recipient of that email. Inspired by LSM [7], each communication pattern P (t) is represented implicitly via a set of A points in K-dimensional Euclidean
(t)
(t)
(t)
(t)
(t)
(t)
such that par = pra = ?(b(t) ? ksa ? sr k)
space S (t) = {sa }A
a=1 and a scalar bias term b
(t)
with sa ? N (0, ?12 I) and b(t) ? N (?, ?22 ).1 If K = 2 or K = 3, this representation enables
each topic-specific communication pattern to be visualized in 2- or 3-dimensional space via the locations of the points associated with the A actors. It is worth noting that the dimensions of each
(t)
K-dimensional space have no inherent meaning. In isolation, each point sa conveys no information; however, the distance between any two points has a precise and meaningful interpretation in the
generative process. Specifically, the recipients of any email associated with topic t are more likely
to be those actors near to the email?s author in the Euclidean space corresponding to that topic.
Each email, indexed by d, has a discrete distribution over topics ? (d) . A symmetric Dirichlet prior
(d)
with concentration parameter ? is placed over ? = {? (1) , ..., ? (D) }. Each token wn is associated
(d)
(d)
(d)
(d)
with a topic assignment zn , such that zn ? ? (d) and wn ? ?(t) for zn = t. Our model does
not include a distribution over authors; the generative process is conditioned upon their identities.
(d)
The email-specific binary variables y (d) = {yr }A
r=1 indicate the recipients of email d and thus the
presence (or absence) of email-specific edges from author a(d) to each of the A ? 1 other actors.
Consequently, there may be multiple edges (one per email) between any pair of actors, and D defines
a multinetwork over the entire set of actors. We assume that the complete multinetwork comprises T
(d)
topic-specific subnetworks. In other words, each yr is associated with some topic t and therefore
(t)
(d)
with topic-specific communication pattern P (t) such that yr ? Bern(par ) for a(d) = a. A natural
(d)
way to associate each yr with a topic would be to draw a topic assignment from ? (d) in a manner
(d)
analogous to the generation of zn ; however, as outlined by Blei and Jordan [8], this approach can
result in the undesirable scenario in which one subset of topics is associated with tokens, while another (disjoint) subset is associated with edges. Additionally, models of annotated data that possess
this exchangeable structure tend to exhibit poor generalization [3, 8]. A better approach, advocated
(d)
by Blei and Jordan, is to draw a topic assignment for each yr from the empirical distribution over
(d)
topics defined by z . By definition, the set of topics associated with edges will therefore be a subset of the topics associated with tokens. One way of simulating this generative process is to associate
(d)
(d)
each yr with a position n = 1, . . . , max (1, N (d) ) and therefore with the topic assignment zn at
(d)
(d)
that position2 by drawing a position assignment xr ? U(1, . . . , max (1, N (d) )) for each yr . This
(d)
(t)
(d)
(d)
indirect procedure ensures that yr ? Bern(par ) for a(d) = a, xr = n, and zn = t, as desired.
The function ?(?) is the logistic function, while the function k ? k is the l2 -norm.
Emails that do not contain any text (i.e., N (d) = 0) convey information about the frequencies of communication between their authors and recipients. As a result, we do not omit such emails from D; instead, we
(d)
(d)
augment each one with a single, ?dummy? topic assignment z1 for which there is no associated token w1 .
1

2

3

2.1

Inference

(d) D
For real-world data D = {w(d) , a(d) , y (d) }D
}d=1 , authors A =
d=1 , the tokens W = {w
(d) D
(d) D
{a }d=1 , and recipients Y = {y }d=1 are observed, while ?, ?, S = {S (t) }Tt=1 , B = {b(t) }Tt=1 ,
(d) D
Z = {z (d) }D
}d=1 are unobserved. Dirichlet?multinomial conjugacy allows ?
d=1 , and X = {x
and ? to be marginalized out [9], while typical values for the remaining unobserved variables can
be sampled from their joint posterior distribution using Markov chain Monte Carlo methods. In
this section, we outline a Metropolis-within-Gibbs sampling algorithm that operates by sequentially
(t)
(d)
(d)
resampling the value of each latent variable (i.e., sa , bt , zn , or xr ) from its conditional posterior.
(d)

Since zn is a discrete random variable, new values may be sampled directly using
P (zn(d) = t | wn(d) = v, W\d,n , A, Y, S, B, Z\d,n , X , ?, ?)
?
(v|t)
yr(d)
1?yr(d)
+ V? Q
(t)
(t)
?
?(N (t|d) + ? ) N\d,n
(p
)
(1
?
p
)
(d)
(t)
\d,n
T
a(d) r
a(d) r
r:xr =n
N\d,n +?
?
(d)
(d)
?
y
1?y
Q
r
r
?
(t)
(t)
(1 ? pa(d) r )
r:r6=a(d) (pa(d) r )

for N (d) > 0
otherwise,

where subscript ?\d, n? denotes a quantity excluding data from position n in email d. Count N (t) is
the total number of tokens in W assigned to topic t by Z, of which N (v|t) are of type v and N (t|d)
(d)
belong to email d. New values for discrete random variable xr may be sampled directly using
(t)

(d)
P (x(d)
r = n | A, Y, S, B, zn = t, Z\d,n ) ? (pa(d) r )

yr(d)

(t)

(1 ? pa(d) r )

1?yr(d)

.

(t)

New values for continuous random variables sa and b(t) cannot be sampled directly from their
conditional posteriors, but may instead be obtained using the Metropolis?Hastings algorithm. With
(t)
(t)
(t)
a non-informative prior over sa (i.e., sa ? N (0, ?)), the conditional posterior over sa is
Y
N (1|a,r,t) +N (1|r,a,t)
N (0|a,r,t) +N (0|r,a,t)
(t) (t)
P (s(t)
(p(t)
(1 ? p(t)
,
a | A, Y, S \a , b , Z, X ) ?
ar )
ar )
r:r6=a

where count N (1|a,r,t) =

(d)

PD

(d)
= a) 1(yr = 1)
d=1 1(a

N (d)
n=1

P


(d)
(d)
1(xr = n) 1(zn = t) .3 Counts

N (1|r,a,t) , N (0|a,r,t) , and N (0|r,a,t) are defined similarly. Likewise, with an improper, noninformative prior over b(t) (i.e., b(t) ? N (0, ?)), the conditional posterior over b(t) is
P (b(t) | A, Y, S (t) , Z, X ) ?

A Y
Y

(p(t)
ar )

N (1|a,r,t) +N (1|r,a,t)

N (0|a,r,t) +N (0|r,a,t)

(1 ? p(t)
ar )

.

a=1 r:r<a

3

Data

Due to a variety of factors involving personal privacy concerns and the ownership of content by
email service providers, academic researchers rarely have access to organizational email data. For
example, the Enron data set [10]?arguably the most widely studied email data set?was only released because of a court order. The public record is an alternative source of organizational email
data. Public record data sets are widely available and can be continually updated, yet remain relatively untapped by the academic community. We therefore introduce and analyze a new public
record email data set relevant to researchers in the organizational and social sciences as well as machine learning researchers. This data set consists of emails between the managers of the departments
that constitute the executive arm of government at the county level for New Hanover County, North
Carolina. In this semi-autonomous local government, county managers act as executives, and the individual departments are synonymous with the individual departments and agencies in, for instance,
the U.S. federal government. Therefore, not only does this email data set offer a view into the communication patterns of the managers of New Hanover County, but analyses of it also serve as case
studies in modeling inter-agency communications in the U.S. federal government administration.
3

The function 1(?) evaluates to one if its argument evaluates to true and evaluates to zero otherwise.

4

?
?

?
?

??

?

our model
Erosheva
baseline 2
0

?

MMSB
baseline 1
LSM

50
100
150
Number of Topics

(a)

200

?
?

?

?

?

?

?
?

?
?

?
?
?

0.1

?
?
?
?
?

?
?

?

?

?
?

0

our model
Erosheva
baseline 2

MMSB
baseline 1
LSM

50
100
150
Number of Topics

our model
Erosheva
baseline 2
LDA

?

?
?
?
?

?
?
?

?

?
?
?

?
?
?
?

?
?
?

?
?
?

?
?
?

?
?
?

200

0

(b)

Average Topic Coherence
?90 ?80 ?70 ?60 ?50

?
?

?

our model
Erosheva
baseline 2
LDA

??
??
?
??
?
?

?
?
?
?

?110

?

?

?

?
?

Average Topic Coherence
?90 ?80 ?70 ?60 ?50

?

?

?

Average F1 Score
0.2
0.3

?

?

?

0.0

Average F1 Score
0.2
0.3

?

?

?

0.0

0.1

?
?

?

?110

0.4

0.4

?

?

50
100
150
Number of Topics

(c)

200

?
?

?
?
?

?
?
?

0

?
?
?

50
100
150
Number of Topics

?
?
?

200

(d)

Figure 2: Average link prediction performance for (a) the NHC email network and (b) the Enron data
set. For MMSB and LSM, we only report results obtained using the best-performing hyperparameter
values. Average topic coherence scores for (c) the NHC email network and (d) the Enron data set.

The New Hanover County (NHC) email network comprises the complete inboxes and outboxes of
30 department managers from the month of February, 2011. In total, there are 30,909 emails, of
which 8,097 were authored by managers. Of these 8,097 emails, 1,739 were sent to other managers
(via the ?To? or ?Cc? fields), excluding any emails sent from a manager to him- or herself only.
For our experiments, we used these 1,739 emails between 30 actors. To verify that our model is
applicable beyond the NHC email network, we also performed two validation experiments using
the Enron email data set [10]. For this data set, we treated each unique @enron email address
as an actor and used only those emails between the 50 most active actors (determined by the total
numbers of emails sent and received). Emails that were not sent to at least one other active actor (via
the ?To? or ?Cc? fields) were discarded. To avoid duplicate emails, we retained only those emails
from ? sent mail?, ?sent?, or ?sent items? folders. These steps resulted in a total of 8,322 emails
involving 50 actors. Both data sets were preprocessed to concatenate the text of subject lines and
message bodies and to remove any stop words, URLs, quoted text, and (where possible) signatures.

4

Experiments

Our model is primarily intended as an exploratory analysis tool for organizational communication
networks. In this section, we use the NHC email network to showcase our model?s ability to discover
and visualize topic-specific communication subnetworks. First, however, we test our underlying
modeling assumptions via three quantitative validation tasks, as recommended by Schrodt [11].
4.1

Link Prediction

In order to gauge our model?s predictive performance, we evaluated its ability to predict the recipients of ?test? emails, from either the NHC email network or the Enron data set, conditioned on the
text of those emails and the identities of their authors. For each test email d, the binary variables
(d)
indicating the recipients of that email, i.e., {yr }A
r=1 , were treated as unobserved. Typical values
for these variables were sampled from their joint posterior distribution and compared to the true
values to yield an F1 score. We formed a test split of each data set by randomly selecting emails
with probability 0.1. For each data set, we averaged the F1 scores over five random test splits.
We compared our model?s performance with that of two baselines and three existing network models, thereby situating it within the existing literature. Given a test email authored by actor a, our
simplest baseline na??vely predicts that actor a will include actor r as a recipient of that email with
probability equal to the number of non-test emails sent from actor a to actor r divided by the total number of non-test emails sent by actor a. Our second baseline is a variant of our model in
which each topic-specific communication pattern P (t) is represented explicitly via A(A + 1) / 2
probabilities drawn from a symmetric Beta prior with concentration parameter ?. Comparing our
model to this variant enables us to validate our assumption that topic-specific communication patterns can indeed be accurately represented by a set of A points (one per actor) in K-dimensional
Euclidean space. We also compared our model?s performance to that of three existing network models: a variant of Erosheva et al.?s model for analyzing scientific publications [4], LSM [7], and the
5

mixed-membership stochastic blockmodel (MMSB) [12]. Erosheva et al.?s model can be viewed as
(d)
a variant of our model in which the topic assignment for each yr is drawn from ? (d) instead of
(d)
the empirical distribution over topics defined by z . Like our second baseline, each topic-specific
communication pattern is represented explicitly via probabilities drawn from a symmetric Beta prior
with concentration parameter ?; however, unlike this baseline, each one is represented using A prob(t)
(t)
abilities such that par = pr . LSM can be viewed as a network-only variant of our model in which
text is not modeled. As a result, there are no topics and a single communication pattern P . This pattern is represented implicitly via a set of A actor-specific points in K-dimensional Euclidean space.
Finally, MMSB is a widely-used model for mixed-membership community discovery in networks.
(d)

For our model and all its variants, typical values for {yr }A
r=1 can be sampled from their joint
posterior distribution using an appropriately-modified version of the Metropolis-within-Gibbs algorithm in Section 2.1. In all our experiments, we ran this algorithm for 40,000?50,000 iterations. On
iteration i, we defined each proposal distribution to be a Gaussian distribution centered on the value
from iteration i ? 1 with covariance matrix max (1, 100 / i) I, thereby resulting in larger covariances
for earlier iterations. Beta?binomial conjugacy allows the elements of P (t) to be marginalized out
in both our second baseline and Erosheva et al.?s model. For MMSB, typical values can be sampled using a modified version of Chang?s Gibbs sampling algorithm [13]. We ran this algorithm
for 5,000 iterations. For all models involving topics, we set concentration parameter ? to 1 for the
NHC network and 2 for the Enron data set. For both data sets, we set concentration parameter ? to
0.01V .4 We varied the number of topics from 1 to 200. In order to facilitate visualization, we used
2-dimensional Euclidean spaces for our model. For LSM, however, we varied the dimensionality of
the Euclidean space from 1 to 200. We report only those results obtained using the best-performing
dimensionality. For our second baseline and Erosheva et al.?s model, we set concentration parameter
? to 0.02. For MMSB, we performed a grid search over all hyperparameter values and the number
of blocks and, as with LSM, report only those results obtained using the best-performing values.5
F1 scores, averaged over five random test splits of each data set, are shown in Figure 2. Although our
model is intended for exploratory analysis, it achieves better link prediction performance than the
other models. Furthermore, the fact that our model outperforms our second baseline and Erosheva
et al.?s model validates our assumption that topic-specific communication patterns can indeed be
accurately represented by a set of A actor-specific points in 2-dimensional Euclidean space.
4.2

Topic Coherence

When evaluating unsupervised topic models, topic coherence metrics [14, 15] are often used as a
proxy for subjective evaluation of semantic coherence. In order to demonstrate that incorporating
network data does not impair our model?s ability to model text, we compared the coherence of topics
inferred using our model with the coherence of topics inferred using LDA, our second baseline, and
Erosheva et al.?s model. For each model, we varied the number of topics from 1 to 200 and drew five
samples from the joint posterior distribution over the unobserved random variables in that model. We
evaluated the topics resulting from each sample using Mimno et al.?s coherence metric [14]. Topic
coherence, averaged over the five samples, is shown in Figure 2. Our model achieves coherence
comparable to that of LDA. This result, when combined with the results in Section 4.1, demonstrates
that our model can achieve state-of-the-art predictive performance while producing coherent topics.
4.3

Posterior Predictive Checks

We used posterior predictive checking to assess the extent to which our model is a ?good fit? for the
NHC email network [16, 17]. Specifically, we defined four network statistics (i.e., four discrepancy
functions) that summarize meaningful aspects of the NHC network: generalized graph transitivity,
the dyad intensity distribution, the vertex degree distribution, and the geodesic distance distribution.6
We then generated 1,000 synthetic networks from the posterior predictive distribution implied by our
4
These values were obtained by slice sampling typical values for the concentration parameters in LDA.
They are consistent with the concentration parameter values used in previous work [9].
5
These values correspond to a Dir(0.1, . . . , 0.1) prior over block memberships, a Beta(0.1, 0.1) prior over
diagonal entries of the blockmodel, a Beta(0.01, 0.01) prior over off-diagonal entries, and 30 blocks.
6
These statistics are defined in the supplementary materials.

6

50

60

?
?

40

0.655

0.665

Transitivity

(a)

400
200

0

0.645

600

?

?
?
?
?
?
?

20

0

Simulated Quantile

100

1.2

800
Degree

Simulated Quantile

Frequency

150

1.4

?
?

80

200

??
??

??
???
?

?
?
??
?

0
0

20

40

?
?
??
?????
???

??
????

60

1.0
0.8
0.6
0.4
0.2
0.0
0.0 0.2 0.4 0.6 0.8 1.0 1.2

Observed Quantile

Actor (Sorted by Observed Degree)

(b)

(c)

Observed Quantile

(d)

Figure 3: Four posterior predictive checks of our model using the NHC email network and 100
topics: (a) a histogram of the graph transitivity of the synthetic networks, with the graph transitivity
of the NHC email network indicated by a vertical line; (b) a quantile?quantile plot comparing the
distribution of dyadic intensities in the synthetic networks to that of the observed network; (c) a box
plot indicating the sampled degree of each manager in the synthetic networks, with managers sorted
from highest to lowest observed degree and their observed degrees indicated by a line; and (d) a
quantile?quantile plot comparing the observed and synthetic geodesic distance distributions.

model and the NHC network. We applied each discrepancy function to each synthetic network to
yield four distributions over the values of the four network statistics. If our model is a ?good fit?
for the NHC network, these distributions should be centered around the values of the corresponding
discrepancy functions when computed using the observed NHC network. As shown in Figure 3,
our model generates synthetic networks with dyad intensity, vertex degree, and geodesic distance
distributions that are very similar to those of the NHC network. The distribution over synthetic graph
transitivity values is not centered around the observed graph transitivity, but the observed transitivity
is not sufficiently far into the tail of the distribution to warrant reparameterization of our model.
4.4

Exploratory Analysis

In order to demonstrate our model?s novel ability to discover and visualize topic-specific communication patterns, we performed an exploratory analysis of four such patterns inferred from the NHC
email network using our model. These patterns are visualized in Figure 4. Each pattern is represented implicitly via a single set of A points in 2-dimensional Euclidean space drawn from their joint
posterior distribution. The recipients of any email associated with topic t are more likely to be those
actors near to the email?s author in the Euclidean space corresponding to that topic. We selected the
patterns in Figure 4 so as to highlight the types of insights that can be obtained using our model.
Although many structural properties may be of interest, we focus on modularity and assortativity.
For each topic-specific communication pattern, we examined whether there are active, disconnected
components in that topic?s Euclidean space (i.e., high modularity). The presence of such components indicates that there are groups of actors who engage in within- but not between-group communication about that topic. We also used a combination of node proximity and node coloration
to determine whether there is more communication between departments that belong to the same
?division? in the New Hanover County government organizational chart than between departments
within different divisions (i.e., assortativity). In Figure 4, we show one topic that exhibits strong
modularity and little assortativity (the ?Public Signage? topic), one topic that exhibits strong assortativity and little modularity (the ?Broadcast Messages? topic), and one topic that exhibits both
strong assortativity and strong modularity (the ?Meeting Scheduling? topic). The ?Public Relations?
topic, which includes communication with news agencies, is mostly dominated by a cluster involving many departments. Finally, the ?Meeting Scheduling? topic displays hierarchical structure, with
two assistant county managers located at the centers of groups that correspond to their divisions.
Exploratory analysis of communication patterns is a powerful tool for understanding organizational
communication networks. For example, examining assortativity can reveal whether actual communication patterns resemble official organizational structures. Similarly, if a communication pattern
exhibits modularity, each disconnected component may benefit from organizational efforts to facilitate inter-component communication. Finally, structural properties other than assortativity and
modularity may also yield scientific or practical insights, depending on organizational needs.
7

Public Signage

Broadcast Messages

15
change signs sign process
ordinance

17
fw fyi bulletin summary
week legislative
?
PM

CC
?

400

300

HL
?

?
AM
SF
?

?
PS
?
DS

200

EG
?

?
EG

LB
?

AM
?

?
DS
?
FN

PS
?

100

200

?
PI

TX
?

?
BG

LB
?

FS
?

0

?
HR

MS
?

?
CM

RD
?

AM
AM
EM PG
?

?
IT

CE
?

EM
?

RD
?

PG
?

CA
?

CC
?

SF
?

?

TX
?

FS
?

?300

?
SS

?

?

?200

EV
?

?
IT

MS
?

?100

?
PM

?200

?
RM

0
?
BG
EL
?

?400

?
EV

?
CM

CA
?

?
FN

?
YS
?
PI
?
SS

RM
?

YS
?

?
VS

?
HL

HR
?

VS
?

EL
?

CE
?

?400

?200

0

200

400

?300

?200

?100

0

100

200

300

Public Relations

Meeting Scheduling

31
city breakdown information
give

63
meeting march board
agenda week

EL
?

FS
?

400

400

SF
?
CA
?

PS
?
RM
?

200

200

RD
?
EG
?

RM
?

?
HR

?
MS
PI
?

?
DS

0

FS
?CE
?
EV
?

?
CM

? EL
PG
?

RD
?

?
TX

CC
?

?
LB

?
CE

?
EM

?
AM

?
HR
BG
?

?
FN

?
HL

0

?
PM
?
? SS
LB
?
HL

?
EM
?
AM
?

?200

IT
?
PG
?
BG

CA
?

MS
?

?200

?
PS

?
CM

?
EG

?
SS

IT
?

TX
?

0

?

?600

?400

CC
?

?400

AM

YS
?

?
AM

VS
?

DS

?
PI

?200

?
FN

YS
??

?400

?
PM

VS
?

SF
?

Assistant County Manager
Budget
Cooperative Extension
County Attorney
County Commissioners
County Manager
Development Services
Elections
Emergency Management
Engineering
Environmental Management
Finance
Fire Services
Health
Human Resources
Information Technology
Library
Museum
Parks and Gardens
Planning and Inspections
Pretrial Release Screening
Property Management
Register of Deeds
Risk Management
Sheriff
Social Services
Tax
?
Veteran Services
Youth Empowerment Services

AM
BG
CE
CA
CC
CM
DS
EL
EM
EG
EV
FN
FS
HL
HR
IT
LB
MS
PG
PI
PS
PM
RD
RM
SF
SS
TX
VS
YS

EV
?

200

400

600

?200

0

200

400

Figure 4: Four topic-specific communication patterns inferred from the NHC email network. Each
pattern is labeled with a human-selected name for the corresponding topic, along with that topic?s
most probable words in order of decreasing
probability. The size of each manager?s acronym in
q
(t)

(t)

(t)

topic t?s pattern (given by 0.45 + 1.25 da / maxa da , where da is the degree of actor a in that
subnetwork) indicates how often that manager communicates about that topic. Managers? acronyms
are colored according to their respective division in the New Hanover County organizational chart.
The acronym ?AM? appears twice in all plots because there are two assistant county managers.

5

Conclusions

We introduced a new Bayesian admixture model for the discovery and visualization of topic-specific
communication subnetworks. Although our model is intended for exploratory analysis, the validation experiments described in Sections 4.1 and 4.2 demonstrate that our model can achieve stateof-the-art predictive performance while exhibiting topic coherence comparable to that of LDA. To
showcase our model?s ability to discover and visualize topic-specific communication patterns, we
introduced a new data set (the NHC email network) and analyzed four such patterns inferred from
this data set using our model. Via this analysis, were are able to examine the extent to which actual
communication patterns resemble official organizational structures and identify groups of managers
who engage in within- but not between-group communication about certain topics. Together, these
predictive and exploratory analyses lead us to recommend our model for any exploratory analysis of
email networks or other similarly-structured communication data. Finally, our model is capable of
producing principled visualizations of email networks, i.e., visualizations that have precise mathematical interpretations in terms of this model and its relationship to the observed data. We advocate
for principled visualization as a primary objective in the development of new network models.

Acknowledgments
This work was supported in part by the Center for Intelligent Information Retrieval and in part by
the NSF GRFP under grant #1122374. Any opinions, findings, and conclusions or recommendations
expressed in this material are those of the authors and do not necessarily reflect those of the sponsors.
8

References
[1] W. Mason and D.J. Watts. Collaborative learning in networks. Proceedings of the National
Academy of Sciences, 109(3):764?769, 2012.
[2] A. McCallum, A. Corrada-Emmanuel, and X. Wang. Topic and role discovery in social networks. In Proceedings of the International Joint Conference on Artificial Intelligence, 2005.
[3] J. Chang and D.M. Blei. Relational topic models for document networks. In Proceedings of
the Twelfth International Conference on Artificial Intelligence and Statistics, 2009.
[4] E. Erosheva, S. Fienberg, and J. Lafferty. Mixed-membership models of scientific publications.
Proceedings of the National Academy of Sciences, 101(Suppl. 1), 2004.
[5] S.E Fienberg. A brief history of statistical models for network analysis and open challenges.
Journal of Computational and Graphical Statistics, 22, 2012.
[6] D.M. Blei, A.Y. Ng, and M.I. Jordan. Latent Dirichlet allocation. Journal of Machine Learning
Research, 3:993?1022, 2003.
[7] P.D. Hoff, A.E. Raftery, and M.S. Handcock. Latent space approaches to social network analysis. Journal of the American Statistical Association, 97(460):1090?1098, 2002.
[8] D.M. Blei and M.I. Jordan. Modeling annotated data. In Proceedings of the Twenty-Sixth
Annual International ACM SIGIR Conference on Research and Development in Information
Retrieval, pages 127?134, 2003.
[9] T.L. Griffiths and M. Steyvers. Finding scientific topics. Proceedings of the National Academy
of Sciences, 101(Suppl. 1), 2004.
[10] B. Klimt and Y. Yang. Introducing the Enron corpus. In Proceedings of the First Conference
on Email and Anti-Spam, 2004.
[11] P.A Schrodt. Seven deadly sins of contemporary quantitative political analysis. In Proceedings
of the Annual American Political Science Association Meeting and Exhibition, 2010.
[12] E.M. Airoldi, D.M. Blei, S.E. Fienberg, and E.P. Xing. Mixed membership stochastic blockmodels. Journal of Machine Learning Research, 9:1981?2014, 2008.
[13] J. Chang. Uncovering, Understanding, and Predicting Links. PhD thesis, Princeton Unversity,
2011.
[14] D. Mimno, H.M. Wallach, E.T.M. Leenders, and A. McCallum. Optimizing semantic coherence in topic models. In Proceedings of the Conference on Empirical Methods in Natural
Language Processing, 2011.
[15] D. Newman, J.H. Lau, K. Grieser, and T. Baldwin. Automatic evaluation of topic coherence. In
Proceedings of Human Language Technologies: The Annual Conference of the North American
Chapter of the Association for Computational Linguistics, pages 100?108, 2010.
[16] D.R. Hunter, M.S. Handcock, C.T. Butts, S.M. Goodreau, and M. Morris. ergm: A package
to fit, simulate and diagnose exponential-family models for networks. Journal of Statistical
Software, 24(3):1?29, 2008.
[17] D. Mimno and D.M. Blei. Bayesian checking for topic models. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 227?237, 2011.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 964-an-input-output-hmm-architecture.pdf

An Input Output HMM Architecture
Yoshua Bengio*
Dept. Informatique et Recherche
Operationnelle
Universite de Montreal, Qc H3C-3J7
bengioyOIRO.UMontreal.CA

Paolo Frasconi
Dipartimento di Sistemi e Informatica
Universita di Firenze (Italy)
paoloOmcculloch.ing.unifi.it

Abstract
We introduce a recurrent architecture having a modular structure
and we formulate a training procedure based on the EM algorithm.
The resulting model has similarities to hidden Markov models, but
supports recurrent networks processing style and allows to exploit
the supervised learning paradigm while using maximum likelihood
estimation.

1

INTRODUCTION

Learning problems involving sequentially structured data cannot be effectively dealt
with static models such as feedforward networks. Recurrent networks allow to model
complex dynamical systems and can store and retrieve contextual information in
a flexible way. Up until the present time, research efforts of supervised learning
for recurrent networks have almost exclusively focused on error minimization by
gradient descent methods. Although effective for learning short term memories,
practical difficulties have been reported in training recurrent neural networks to
perform tasks in which the temporal contingencies present in the input/output
sequences span long intervals (Bengio et al., 1994; Mozer, 1992).
Previous work on alternative training algorithms (Bengio et al., 1994) could suggest
that the root of the problem lies in the essentially discrete nature of the process
of storing information for an indefinite amount of time. Thus, a potential solution
is to propagate, backward in time, targets in a discrete state space rather than
differential error information. Extending previous work (Bengio & Frasconi, 1994a),
in this paper we propose a statistical approach to target propagation, based on the
EM algorithm. We consider a parametric dynamical system with discrete states and
we introduce a modular architecture, with subnetworks associated to discrete states.
The architecture can be interpreted as a statistical model and can be trained by the
EM or generalized EM (GEM) algorithms (Dempster et al., 1977), considering the
internal state trajectories as missing data. In this way learning is decoupled into
? also, AT&T Bell Labs, Holmdel, N J 07733

428

Yoshua Bengio, Paolo Frasconi

a temporal credit assignment subproblem and a static learning subproblem that
consists of fitting parameters to the next-state and output mappings defined by the
estimated trajectories . In order to iteratively tune parameters with the EM or GEM
algorithms, the system propagates forward and backward a discrete distribution over
the n states, resulting in a procedure similar to the Baum-Welch algorithm used
to train standard hidden Markov models (HMMs) (Levinson et al., 1983) . HMMs
however adjust their parameters using unsupervised learning, whereas we use EM
in a supervised fashion . Furthermore, the model presented here could be called
Input/Output HMM, or IOHMM , because it can be used to learn to map input
sequences to output sequences (unlike standard HMMs, which learn the output
sequence distribution) . This model can also be seen as a recurrent version of the
Mixture of Experts architecture (Jacobs et al. , 1991) , related to the model already
proposed in (Cacciatore and Nowlan, 1994). Experiments on artificial tasks (Bengio
& Frasconi , 1994a) have shown that EM recurrent learning can deal with long
term dependencies more effectively than backpropa~ation through time and other
alternative algorithms. However, the model used in (Bengio & Frasconi, 1994a) has
very limited representational capabilities and can only map an input sequence to a
final discrete state. In the present paper we describe an extended architecture that
allows to fully exploit both input and output portions of the data, as required by
the supervised learning paradigm. In this way, general sequence processing tasks,
such as production, classification, or prediction, can be dealt with.

2

THE PROPOSED ARCHITECTURE

We consider a discrete state dynamical system based on the following state space
x - f(x
U )
description:
t t-l, t
(1)
Yt = 9(Xt, Ut)
where Ut E R m is the input vector at time t, Yt E R r is the output vector, and
Xt E {I , 2, .. . , n} is a discrete state. These equations define a generalized Mealy
finite state machine, in which inputs and outputs may take on continuous values . In
this paper , we consider a probabilistic version of these dynamics, where the current
inputs and the current state distribution are used to estimate the state distribution
and the output distribution for the next time step. Admissible state transitions will
be specified by a directed graph 9 whose vertices correspond to the model 's states
and the set of successors for state j is Sj .
The system defined by equations (1) can be modeled by the recurrent architecture
depicted in Figure l(a) . The architecture is composed by a set of state n etworks
N j, j = 1 .. . n and a set of output networks OJ, j = 1 . .. n. Each one of the state
and output networks is uniquely associated to one of the states,and all networks
share the same input Ut . Each state network M has the task of predicting the next
state distribution , based on the current input and given that Xt-l = j . Similarly,
each output network OJ predicts the output of the system, given the current state
and input. All the subnetworks are assumed to be static and they are defined by
means of smooth mappings Nj (Ut ;9j ) and OJ (Ut; 1Jj), where 9j and 1Jj are vectors
of adjustable parameters (e .g., connection weights). The ranges of the functions
N j 0 may be constrained in order to account for the underlying transition graph
9 . Each output 'Pij ,t of the state subnetwork Nj (at time t) is associated to one
of the successors i of state j . Thus the last layer of M has as many units as the
cardinality of Sj. For convenience of notation, we suppose that 'Pij,t are defined for
each i, j = 1, ... , n and we impose the condition 'Pij ,t = 0 for each i not belonging
to S j . The softmax function is used in the last layer: 'Pij ,t = e a,j ,t ILlEsj ea l j,t, j =
1, ... , n , i E Sj where aij, t are intermediate variables that can be thought of as the

An Input Output HMM Architecture

cu ... nt Input

EIYt

...

Xt-l

current ??pectod output,
given PIlat Input Mquenc.

11 t

429

current atilt. dlatrtbutton

Ct= Pl' t I Ul )

lull

...

...

Xt

Xt+l

1 1 1

Yt-l

Yt

Yt+l

Xt-l

X(

Xt+l

'-'t

\.Yt-l

\Yt

I

I

Ut-l

HMM

\.Yt+l

I

Ut

.. ....

IOHMM

Ut+l

(b)

(a)

Figure 1: (a): The proposed IOHMM architecture. (b): Bottom: Bayesian network
expressing conditional dependencies for an IOHMM; top: Bayesian network for a
standard HMM

't

activations of the output units of subnetwork N j . In this way L:7=1 'Pij ,t = 1 Tij,t.
The vector
E R n represents the internal state of the model and it is computed as
a linear combination of the outputs of the state networks, gated by the previously
n
computed internal state:
't

= L ( j ,t-IIPj,t

(2)

j=1

where IPj,t = ['PIj,t, ... , 'Pnj,t]'. Output networks compete to predict the global
output of the system 1Jt E R r :
n
1Jt

= L (jt1Jjt

(3)

j=1

where 1Jjt E R r is the output of subnetwork OJ. At this level , we do not need
to further specify the internal architecture of the state and output subnetworks.
Depending on the task, the designer may decide whether to include hidden layers
and what activation rule to use for the hidden units.
This connectionist architecture can be also interpreted as a probability model. Let
us assume a multinomial distribution for the state variable Xt and let us consider
the main variable of the temporal recurrence (2). If we initialize the vector
to positive numbers summing to 1, it can be interpreted as a vector of initial state
probabilities. In general, we obtain relation (it = P(Xt = i I
having denoted
with ui the subsequence of inputs from time 1 to t, inclusively. Equation (2) then
has the following probabilistic interpretation:

't,

un,

'0

n

P(Xt

= i

lui) =

L

P(Xt

= i I Xt-I = j, ut}P(Xt-1 = j

lui-I)

(4)

j=l

i.e., the subnetworks N j compute transition probabilities conditioned on the input
sequence Ut:
P( Xt = ~. I Xt-l = ),.Ut
)
(5)
'Pij,t =
As in neural networks trained to minimize the output squared error, the output
1Jt of this architecture can be interpreted as an expected "position parameter"
for the probability distribution of the output Yt. However, in addition to being
conditional on an input Ut, this expectation is also conditional on the state Xt, i.e.

Yoshua Bengio, Paolo Frasconi

430

= E[Yt I Xt,Ut] . The actual form of the output density, denoted !Y(Yt ; 7]t), will
be chosen according to the task . For example a multinomial distribution is suitable
for sequence classification, or for symbolic mutually exclusive outputs. Instead, a
Gaussian distribution is adequate for producing continuous outputs. In the first
case we use a softmax function at the output of subnetworks OJ; in the second case
we use linear output units for the subnetworks OJ.
7]t

In order to reduce the amount of computation, we introduce an independency model
among the variables involved in the probabilistic interpretation of the architecture.
We shall use a Bayesian network to characterize the probabilistic dependencies
among these variables. Specifically, we suppose that the directed acyclic graph
9 depicted at the bottom of Figure 1b is a Bayesian network for the dependency
One of the most evident consequences
model associated to the variables u
of this independency model is that only the previous state and the current input are
relevant to determine the next-state. This one-step memory property is analogue
to the Markov assumption in hidden Markov models (HMM). In fact, the Bayesian
network for HMMs can be obtained by simply removing the Ut nodes and arcs from
them (see top of Figure Ib) .

I ,xI, YI.

3

A SUPERVISED LEARNING ALGORITHM

The learning algorithm for the proposed architecture is derived from the maximum
likelihood principle. The training data are a set of P pairs of input/ output sequences
(of length Tp): 1) = {(uip(p),Yip(p));p = 1 .. . P}. Let ?J denote the vector of
parameters obtained by collecting all the parameters (Jj and iJi of the architecture.
The likelihood function is then given by
p

L(?J; 1))

= II p(Yip(p) I uip(p); ?J).

(6)

p=l

The output values (used here as targets) may also be specified intermittently. For
example, in sequence classification tasks , one may only be interested in the output YT at the end of each sequence. The modification of the likelihood to account
for intermittent targets is straightforward. According to the maximum likelihood
principle, the optimal parameters are obtained by maximizing (6). In order to
apply EM to our case we begin by noting that the state variables Xt are not observed. Knowledge of the model's state trajectories would allow one to decompose
the temporal learning problem into 2n static learning subproblems. Indeed , if Xt
were known, the probabilities (it would be either 0 or 1 and it would be possible
to train each subnetwork separately, without taking into account any temporal dependency. This observation allows to link EM learning to the target propagation
approach discussed in the introduction . Note that if we used a Viterbi-like approximation (i .e., considering only the most likely path) , we would indeed have 2n static
learning problems at each epoch. In order to we derive the learning equations, let
us define the complete data as 1)c = {(uiP(p),yiP(p),xiP(p));p = 1 ... P}. The
corresponding complete data l%-likelihood is
T
T
T
Ic(?J;1)c) = """
L...IOgP(YIP(P),ZlP(P)
I u1P(p);
?J).

(7)

p=l

Since lc( ?J; 1)c) depends on the hidden state variables it cannot be maximized directly. The MLE optimization is then solved by introducing the auxiliary function
Q(?J; 0) and iterating the following two,steps for k = 1, 2 ... :,
Estimation:
Compute Q(?J ; ?J) = E[lc(?J; 1)c) r 1), ?J]
(8)
Maximization: Update the parameters as 0 t- arg max?J Q( ?J; 0)

An Input Output HMM Architecture

431

The expectation of (7) can be expressed as
p

Q(0 ; 0)

Tp

N

N

= L: L: L: (it!og P(Yt I Xt = i , Ut i 0) + L: hij,tlog<Pij ,t
p=1 t=1 i=1

(9)

j=1

I

where hij ,t = EIZitzj,t-l uf, yf; 0J, denoting Zit for an indicator variable = 1 if
Xt = i and 0 otherwise. The hat in ( it and hij ,t means that these variables are
computed using the "old" parameters 0 . In order to compute hij ,t we introduce
the forward probabilities Qit = P(YL Xt = i ; uD and the backward probabilities
f3it = p(yf I Xt = i ,
that are updated as follows:

un,

f3it = fY(Yt;l1it) Lt <Pti(Ut+df3l,t+l

(10)

Qit = fY(Yt; l1it) Lt <pa(ut} Qt ,t-l .
(11)
- f3it Qj ,t-l<Pij (ut)
"
wi QiT
Each iteration of the EM algorithm requires to maximize Q(0 ; 0). We first
consider a simplified case, in which the inputs are quantized (i .e., belonging
to a finite alphabet {0"1, "" O"K}) and the subnetworks behave like lookup tables addressed by the input symbols O"t, i.e. we interpret each parameter as
Wi' k = P(Xt = i I Xt-l = j , O"t = k). For simplicity, we restrict the analysis to classification tasks and we suppose that targets are specified as desired final states for
each sequence. Furthermore, no output subnetworks are used in this particular
application of the algorithm. In this case we obtain the reestimation formulae:
h

Wijk =

ij ,t -

"

"p"

(12)

. .

{j,t(j,t-l
w i ESj wp=1 wt :Ut=k , + T

?

"'T '

In general, however, if the subnetworks have hidden sigmoidal units, or use a softmax function to constrain their outputs to sum to one, the maximum of Q cannot
be found analytically. In these cases we can resort to a GEM algorithm, that simply produces an increase in Q, for example by gradient ascent. In this case, the
derivatives of Q with respect to the parameters can be easily computed as follows.
Let Ojlt be a generic weight in the state subnetwork N j . From equation (9):
8Q(0;0)
80jk

= L:L:L:hij,t_l_8<pij ,t
p

t

i

<Pij,t 80jk

(13)

where the partial derivatives &:e~;t can be computed using backpropagation . Similarly, denoting with t'Jik a generic weight of the output subnetwork Oi, we have:
8Q( 0; 0)
'" '" '" .
8
87]a t
8t'J ?
= L..JL..JL..J(i , t~logfY(Yy;l1it) 8t'J .'
p
t
t
7],t,t
,k
,k

(14)

where ~;;:~t are also computed using backpropagation. Intuitively, the parameters
are updated as if the estimation step of EM had provided targets for the outputs of
the 2n subnetworks , for each time t . Although GEM algorithms are also guaranteed
to find a local maximum of the likelihood, their convergence may be significantly
slower compared to EM. In several experiments we noticed that convergence can be
accelerated with stochastic gradient ascent .

432

4

Yoshua Bengio, Paolo Frasconi

COMPARISONS

It appears natural to find similarities between the recurrent architecture described
so far and standard HMMs (Levinson et al., 1983). The architecture proposed in this
paper differs from standard HMMs in two respects: computing style and learning.
With IOHMMs, sequences are processed similarly to recurrent networks, e.g., an
input sequence can be synchronously transformed into an output sequence. This
computing style is real-time and predictions of the outputs are available as the input
sequence is being processed. This architecture thus allows one to implement all three
fundamental sequence processing tasks: production, prediction, and classification.
Finally, transition probabilities in standard HMMs are fixed, i.e. states form a
homogeneous Markov chain. In IOHMMs, transition probabilities are conditional
on the input and thus depend on time, resulting in an inhomogeneous Markov chain.
Consequently, the dynamics of the system (specified by the transition probabilities)
are not fixed but are adapted in time depending on the input sequence.
The other fundamental difference is in the learning procedure. While interesting
for their capabilities of modeling sequential phenomena, a major weakness of standard HMMs is their poor discrimination power due to unsupervised learning. An
approach that has been found useful to improve discrimination in HMMs is based
on maximum mutual information (MMI) training . It has been pointed out that
supervised learning and discriminant learning criteria like MMI are actually strictly
related (Bridle, 1989). Although the parameter adjusting procedure we have defined
is based on MLE,
is used as desired output in response to the input
resulting
in discriminant supervised learning. Finally, it is worth mentioning that a number
of hybrid approaches have been proposed to integrate connectionist approaches into
the HMM frame\'Vork. For example in (Bengio et al. , 1992) the observations used
by the HMM are generated by a feedforward neural network. In (Bourlard and
Wellekens, 1990) a feedforward network is used to estimate state probabilities, conditional to the acoustic sequence. A common feature of these algorithms and the
one proposed in this paper is that neural networks are used to extract temporally
local information whereas a Markovian system integrates long-term constraints.

yf

uf ,

We can also establish a link between IOHMMs and adaptive mixtures of experts
(ME) (Jacobs et al., 1991). Recently, Cacciatore & Nowlan (1994) have proposed a
recurrent extension to the ME architecture, called mixture of controllers (MC), in
which the gating network has feedback connections, thus allowing to take temporal
context into account . Our IOHMM architecture can be interpreted as a special case
of the MC architecture, in which the set of state subnetworks play the role of a
gating network having a modular structure and second order connections.

5

REGULAR GRAMMAR INFERENCE

In this section we describe an application of our architecture to the problem of
grammatical inference. In this task the learner is presented a set of labeled strings
and is requested to infer a set of rules that define a formal language. It can be
considered as a prototype for more complex language processing problems. However,
even in the "simplest" case, i.e. regular grammars, the task can be proved to
be NP-complete (Angluin and Smith, 1983) . We report experimental results on
a set of regular grammars introduced by Tomita (1982) and afterwards used by
other researchers to measure the accuracy of inference methods based on recurrent
networks (Giles et al. , 1992; Pollack, 1991; Watrous and Kuhn , 1992) .
We used a scalar output with supervision on the final output YT that was modeled
as a Bernoulli variable fy (YT ; 7]T) = 7]~T (1 - 7] ) l-YT, with YT = 0 if the string
is rejected and YT = 1 if it is accepted . In tbis application we did not apply

An Input Output HMM Architecture

433

Table 1: Summary of experimental results on the seven Tomita's grammars.
Grammar

n*
1
2
3
4
5
6
7

2
8
7
4
4
3
3

Sizes
FSA min
2
3
5
4
4
3
5

Convergence
.600
.800
.150
.100
.100
.350
.450

Average
1.000
.965
.867
1.000
1.000
1.000
.856

Accuracies
Worst
Best
1.000 1.000
.834 1.000
.775 1.000
1.000 1.000
1.000 1.000
1.000 1.000
.815 1.000

W&K Best
1.000
1.000
.783
.609
.668
.462
.557

external inputs to the output networks . This corresponds to modeling a Moore
finite state machine. Given the absence of prior knowledge about plausible state
paths, we used an ergodic transition graph (i.e., fully connected).In the experiments
we measured convergence and generalization performance using different sizes for
the recurrent architecture. For each setting we ran 20 trials with different seeds
for the initial weights. We considered a trial successful if the trained network was
able to correctly label all the training strings. The model size was chosen using a
cross-validation criterion based on performance on 20 randomly generated strings
of length T ::; 12. For comparison, in Table 1 we also report for each grammar
the number of states of the minimal recognizing FSA (Tomita, 1982). We tested
the trained networks on a corpus of 213 - 1 binary strings of length T ::; 12. The
final results are summarized in Table 1. The column "Convergence" reports the
fraction of trials that succeeded to separate the training set. The next three columns
report averages and order statistics (worst and best trial) of the fraction of correctly
classified strings, measured on the successful trials. For each grammar these results
refer to the model size n* selected by cross-validation. Generalization was always
perfect on grammars 1,4,5 and 6. For each grammar, the best trial also attained
perfect generalization. These results compare very favorably to those obtained with
second-order networks trained by gradient descent, when using the learning sets
proposed by Tomita. For comparison , in the last column of Table 1 we reproduce
the results reported by Watrous & Kuhn (1992) in the best of five trials. In most
of the successful trials the model learned an actual FSA behavior with transition
probabilities asymptotically converging either to 0 or to 1. This renders trivial the
extraction of the corresponding FSA . Indeed, for grammars 1,4,5, and 6, we found
that the trained networks behave exactly like the minimal recognizing FSA .
A potential training problem is the presence of local maxima in the likelihood function. For example, the number of converged trials for grammars 3, 4, and 5 is quite
small and the difficulty of discovering the optimal solution might become a serious
restriction for tasks involving a large number of states. In other experiments (Bengio & Frasconi , 1994a) , we noticed that restricting the connectivity of the transition
graph can significantly help to remove problems of convergence. Of course, this approach can be effectively exploited only if some prior knowledge about the state
space is available. For example, applications of HMMs to speech recognition always
rely on structured topologies.

6

CONCLUSIONS

There are still a number of open questions . In particular, the effectiveness of the
model on tasks involving large or very large state spaces needs to be carefully evaluated. In (Bengio & Frasconi 1994b) we show that learning long term dependencies
in these models becomes more difficult as we increase the connectivity of the state

434

Yoshua Bengio, Paolo Frasconi

transition graph. However, because transition probabilities of IOHMMs change at
each t, they deal better with this problem of long-term dependencies than standard
HMMs. Another interesting aspect to be investigated is the capability of the model
to successfully perform tasks of sequence production or prediction. For example,
interesting tasks that could also be approached are those related to time series
modeling and motor control learning.

References
Angluin, D. and Smith, C. (1983). Inductive inference: Theory and methods. Computing Surveys, 15(3):237-269.
Bengio, Y. and Frasconi, P. (1994a) . Credit assignment through time: Alternatives
to backpropagation. In Cowan, J., Tesauro, G., and Alspector, J., editors,
Advances in Neural Information Processing Systems 6. Morgan Kaufmann.
Bengio, Y. and Frasconi, P. (1994b). An EM Approach to Learning Sequential
Behavior. Tech. Rep. RT-DSI/11-94, University of Florence.
Bengio, Y., De Mori, R., Flammia, G., and Kompe, R. (1992). Global optimization
of a neural network-hidden markov model hybrid. IEEE Transactions on Neural
Networks, 3(2):252-259.
Bengio, Y., Simard, P., and Frasconi, P. (1994) . Learning long-term dependencies
with gradient descent is difficult. IEEE Trans. Neural Networks, 5(2).
Bourlard, H. and Wellekens, C. (1990). Links between hidden markov models and
multilayer perceptrons. IEEE Trans. Pattern An. Mach. Intell., 12:1167-1178.
Bridle, J. S. (1989). Training stochastic model recognition algorithms as networks can lead to maximum mutual information estimation of parameters. In
D.S.Touretzky, ed., NIPS2, pages 211-217. Morgan Kaufmann.
Cacciatore, T. W. and Nowlan, S. J. (1994). Mixtures of controllers for jump
linear and non-linear plants. In Cowan, J. et. al., editors, Advances in Neural
Information Processing Systems 6, San Mateo, CA. Morgan Kaufmann.
Dempster, A. P., Laird, N. M., and Rubin, D. B. (1977). Maximum-likelihood from
incomplete data via the EM algorithm. J. Royal Stat. Soc. B,39:1-38.
Giles, C. L., Miller, C. B ., Chen, D., Sun, G. Z., Chen, H. H., and Lee, Y. C. (1992).
Learning and extracting finite state automata with second-order recurrent neural networks. Neural Computation, 4(3):393-405.
Jacobs, R. A., Jordan, M. I., Nowlan, S. J., and Hinton, G. E. (1991). Adaptive
mixture of local experts. Neural Computation, 3:79-87.
Levinson, S. E., Rabiner, L. R., and Sondhi, M. M. (1983). An introduction to
the application of the theory of probabilistic functIons of a markov process to
automatic speech recognition. Bell System Technical Journal, 64(4):1035-1074.
Mozer, M. C. (1992). The induction of multiscale temporal structure. In Moody,
J. et. al., eds, NIPS 4 pages 275-282. Morgan Kaufmann.
Pollack, J. B. (1991) . The induction of dynamical recognizers. Machine Learning,
7(2):196-227.
Tomita, M. (1982). Dynamic construction of finite-state automata from examples
using hill-climbing. Proc. 4th Cog. Science Con!, pp. 105-108, Ann Arbor MI.
Watrous, R. 1. and Kuhn, G. M. (1992). Induction of finite-state languages using
second-order recurrent networks. Neural Computation, 4(3):406-414 .


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 5059-compete-to-compute.pdf

Compete to Compute

Rupesh Kumar Srivastava, Jonathan Masci, Sohrob Kazerounian,
Faustino Gomez, J?rgen Schmidhuber
IDSIA, USI-SUPSI
Manno?Lugano, Switzerland
{rupesh, jonathan, sohrob, tino, juergen}@idsia.ch

Abstract
Local competition among neighboring neurons is common in biological neural networks (NNs). In this paper, we apply the concept to gradient-based,
backprop-trained artificial multilayer NNs. NNs with competing linear
units tend to outperform those with non-competing nonlinear units, and
avoid catastrophic forgetting when training sets change over time.

1

Introduction

Although it is often useful for machine learning methods to consider how nature has arrived
at a particular solution, it is perhaps more instructive to first understand the functional
role of such biological constraints. Indeed, artificial neural networks, which now represent
the state-of-the-art in many pattern recognition tasks, not only resemble the brain in a
superficial sense, but also draw on many of its computational and functional properties.
One of the long-studied properties of biological neural circuits which has yet to fully impact
the machine learning community is the nature of local competition. That is, a common
finding across brain regions is that neurons exhibit on-center, off-surround organization
[1, 2, 3], and this organization has been argued to give rise to a number of interesting
properties across networks of neurons, such as winner-take-all dynamics, automatic gain
control, and noise suppression [4].
In this paper, we propose a biologically inspired mechanism for artificial neural networks
that is based on local competition, and ultimately relies on local winner-take-all (LWTA)
behavior. We demonstrate the benefit of LWTA across a number of different networks and
pattern recognition tasks by showing that LWTA not only enables performance comparable
to the state-of-the-art, but moreover, helps to prevent catastrophic forgetting [5, 6] common
to artificial neural networks when they are first trained on a particular task, then abruptly
trained on a new task. This property is desirable in continual learning wherein learning
regimes are not clearly delineated [7]. Our experiments also show evidence that a type of
modularity emerges in LWTA networks trained in a supervised setting, such that different
modules (subnetworks) respond to different inputs. This is beneficial when learning from
multimodal data distributions as compared to learning a monolithic model.
In the following, we first discuss some of the relevant neuroscience background motivating
local competition, then show how we incorporate it into artificial neural networks, and
how LWTA, as implemented here, compares to alternative methods. We then show how
LWTA networks perform on a variety of tasks, and how it helps buffer against catastrophic
forgetting.

2

Neuroscience Background

Competitive interactions between neurons and neural circuits have long played an important
role in biological models of brain processes. This is largely due to early studies showing that
1

many cortical [3] and sub-cortical (e.g., hippocampal [1] and cerebellar [2]) regions of the
brain exhibit a recurrent on-center, off-surround anatomy, where cells provide excitatory
feedback to nearby cells, while scattering inhibitory signals over a broader range. Biological
modeling has since tried to uncover the functional properties of this sort of organization,
and its role in the behavioral success of animals.
The earliest models to describe the emergence of winner-take-all (WTA) behavior from local
competition were based on Grossberg?s shunting short-term memory equations [4], which
showed that a center-surround structure not only enables WTA dynamics, but also contrast
enhancement, and normalization. Analysis of their dynamics showed that networks with
slower-than-linear signal functions uniformize input patterns; linear signal functions preserve
and normalize input patterns; and faster-than-linear signal functions enable WTA dynamics.
Sigmoidal signal functions which contain slower-than-linear, linear, and faster-than-linear
regions enable the supression of noise in input patterns, while contrast-enhancing, normalizing and storing the relevant portions of an input pattern (a form of soft WTA). The
functional properties of competitive interactions have been further studied to show, among
other things, the effects of distance-dependent kernels [8], inhibitory time lags [8, 9], development of self-organizing maps [10, 11, 12], and the role of WTA networks in attention [13].
Biological models have also been extended to show how competitive interactions in spiking
neural networks give rise to (soft) WTA dynamics [14], as well as how they may be efficiently
constructed in VLSI [15, 16].
Although competitive interactions, and WTA dynamics have been studied extensively in the
biological literature, it is only more recently that they have been considered from computational or machine learning perspectives. For example, Maas [17, 18] showed that feedforward
neural networks with WTA dynamics as the only non-linearity are as computationally powerful as networks with threshold or sigmoidal gates; and, networks employing only soft
WTA competition are universal function approximators. Moreover, these results hold, even
when the network weights are strictly positive?a finding which has ramifications for our
understanding of biological neural circuits, as well as the development of neural networks
for pattern recognition. The large body of evidence supporting the advantages of locally
competitive interactions makes it noteworthy that this simple mechanism has not provoked
more study by the machine learning community. Nonetheless, networks employing local
competition have existed since the late 80s [21], and, along with [22], serve as a primary
inspiration for the present work. More recently, maxout networks [19] have leveraged locally
competitive interactions in combination with a technique known as dropout [20] to obtain
the best results on certain benchmark problems.

3

Networks with local winner-take-all blocks

This section describes the general network architecture with locally competing neurons.
The network consists of B blocks which are organized into layers (Figure 1). Each block,
bi , i = 1..B, contains n computational units (neurons), and produces an output vector yi ,
determined by the local interactions between the individual neuron activations in the block:
yij = g(h1i , h2i ..., hni ),

(1)

where g(?) is the competition/interaction function, encoding the effect of local interactions
in each block, and hji , j = 1..n, is the activation of the j-th neuron in block i computed by:
T
hi = f (wij
x),

(2)

where x is the input vector from neurons in the previous layer, wij is the weight vector of
neuron j in block i, and f (?) is a (generally non-linear) activation function. The output
activations y are passed as inputs to the next layer. In this paper we use the winner-take-all
interaction function, inspired by studies in computational neuroscience. In particular, we
use the hard winner-take-all function:
 j
hi if hji ? hki , ?k = 1..n
yij =
0 otherwise.
In the case of multiple winners, ties are broken by index precedence. In order to investigate the capabilities of the hard winner-take-all interaction function in isolation, f (x) = x
2

Figure 1: A Local Winner-Take-All (LWTA) network with blocks of size two showing the
winning neuron in each block (shaded) for a given input example. Activations flow forward
only through the winning neurons, errors are backpropagated through the active neurons.
Greyed out connections do not propagate activations. The active neurons form a subnetwork
of the full network which changes depending on the inputs.

(identity) is used for the activation function in equation (2). The difference between this
Local Winner Take All (LWTA) network and a standard multilayer perceptron is that no
non-linear activation functions are used, and during the forward propagation of inputs, local
competition between the neurons in each block turns off the activation of all neurons except
the one with the highest activation. During training the error signal is only backpropagated
through the winning neurons.
In a LWTA layer, there are as many neurons as there are blocks active at any one time for
a given input pattern1 . We denote a layer with blocks of size n as LWTA-n. For each input
pattern presented to a network, only a subgraph of the full network is active, e.g. the highlighted neurons and synapses in figure 1. Training on a dataset consists of simultaneously
training an exponential number of models that share parameters, as well as learning which
model should be active for each pattern. Unlike networks with sigmoidal units, where all of
the free parameters need to be set properly for all input patterns, only a subset is used for
any given input, so that patterns coming from very different sub-distributions can potentially be modelled more efficiently through specialization. This modular property is similar
to that of networks with rectified linear units (ReLU) which have recently been shown to
be very good at several learning tasks (links with ReLU are discussed in section 4.3).

4
4.1

Comparison with related methods
Max-pooling

Neural networks with max-pooling layers [23] have been found to be very useful, especially
for image classification tasks where they have achieved state-of-the-art performance [24, 25].
These layers are usually used in convolutional neural networks to subsample the representation obtained after convolving the input with a learned filter, by dividing the representation
into pools and selecting the maximum in each one. Max-pooling lowers the computational
burden by reducing the number of connections in subsequent convolutional layers, and adds
translational/rotational invariance.
1
However, there is always the possibility that the winning neuron in a block has an activation
of exactly zero, so that the block has no output.

3

0.5

0.5

0

0.8

0.8

before

after

0.8
0.8

before

after

(a) max-pooling

(b) LWTA

Figure 2: Max-pooling vs. LWTA. (a) In max-pooling, each group of neurons in a layer
has a single set of output weights that transmits the winning unit?s activation (0.8 in this
case) to the next layer, i.e. the layer activations are subsampled. (b) In an LWTA block,
there is no subsampling. The activations flow into subsequent units via a different set of
connections depending on the winning unit.

At first glance, the max-pooling seems very similar to a WTA operation, however, the two
differ substantially: there is no downsampling in a WTA operation and thus the number of
features is not reduced, instead the representation is "sparsified" (see figure 2).
4.2

Dropout

Dropout [20] can be interpreted as a model-averaging technique that jointly trains several
models sharing subsets of parameters and input dimensions, or as data augmentation when
applied to the input layer [19, 20]. This is achieved by probabilistically omitting (?dropping?) units from a network for each example during training, so that those neurons do not
participate in forward/backward propagation. Consider, hypothetically, training an LWTA
network with blocks of size two, and selecting the winner in each block at random. This
is similar to training a neural network with a dropout probability of 0.5. Nonetheless, the
two are fundamentally different. Dropout is a regularization technique while in LWTA the
interaction between neurons in a block replaces the per-neuron non-linear activation.
Dropout is believed to improve generalization performance since it forces the units to learn
independent features, without relying on other units being active. During testing, when
propagating an input through the network, all units in a layer trained with dropout are
used with their output weights suitably scaled. In an LWTA network, no output scaling is
required. A fraction of the units will be inactive for each input pattern depending on their
total inputs. Viewed this way, WTA is restrictive in that only a fraction of the parameters
are utilized for each input pattern. However, we hypothesize that the freedom to use different
subsets of parameters for different inputs allows the architecture to learn from multimodal
data distributions more accurately.
4.3

Rectified Linear units

Rectified Linear Units (ReLU) are simply linear neurons that clamp negative activations to
zero (f (x) = x if x > 0, f (x) = 0 otherwise). ReLU networks were shown to be useful for
Restricted Boltzmann Machines [26], outperformed sigmoidal activation functions in deep
neural networks [27], and have been used to obtain the best results on several benchmark
problems across multiple domains [24, 28].
Consider an LWTA block with two neurons compared to two ReLU neurons, where x1 and
x2 are the weighted sum of the inputs to each neuron. Table 1 shows the outputs y1 and
y2 in all combinations of positive and negative x1 and x2 , for ReLU and LWTA neurons.
For both ReLU and LWTA neurons, x1 and x2 are passed through as output in half of the
possible cases. The difference is that in LWTA both neurons are never active or inactive at
the same time, and the activations and errors flow through exactly one neuron in the block.
For ReLU neurons, being inactive (saturation) is a potential drawback since neurons that
4

Table 1: Comparison of rectified linear activation and LWTA-2.
x1

x2

Positive
Positive
Negative

Positive
Negative
Negative

Positive
Negative
Negative

Positive
Positive
Negative

ReLU neurons
y1
y2
x1 > x2
x1
x2
x1
0
0
0
x2 > x1
x1
x2
0
x2
0
0

LWTA neurons
y1
y2
x1
x1
x1

0
0
0

0
0
0

x2
x2
x2

do not get activated will not get trained, leading to wasted capacity. However, previous
work suggests that there is no negative impact on optimization, leading to the hypothesis
that such hard saturation helps in credit assignment, and, as long as errors flow through
certain paths, optimization is not affected adversely [27]. Continued research along these
lines validates this hypothesis [29], but it is expected that it is possible to train ReLU
networks better.
While many of the above arguments for and against ReLU networks apply to LWTA networks, there is a notable difference. During training of an LWTA network, inactive neurons
can become active due to training of the other neurons in the same block. This suggests
that LWTA nets may be less sensitive to weight initialization, and a greater portion of the
network?s capacity may be utilized.

5

Experiments

In the following experiments, LWTA networks were tested on various supervised learning
datasets, demonstrating their ability to learn useful internal representations without utilizing
any other non-linearities. In order to clearly assess the utility of local competition, no special
strategies such as augmenting data with transformations, noise or dropout were used. We
also did not encourage sparse representations in the hidden layers by adding activation
penalties to the objective function, a common technique also for ReLU units. Thus, our
objective is to evaluate the value of using LWTA rather than achieving the absolute best
testing scores. Blocks of size two are used in all the experiments.2
All networks were trained using stochastic gradient descent with mini-batches, learning rate
lt and momentum mt at epoch t given by

?0 ?t if ?t > ?min
?t =
?
otherwise
 t min
m
+
(1 ? Tt )mf if t < T
i
T
mt =
pf
if t ? T
where ? is the learning rate annealing factor, ?min is the lower learning rate limit, and
momentum is scaled from mi to mf over T epochs after which it remains constant at
mf . L2 weight decay was used for the convolutional network (section 5.2), and max-norm
normalization for other experiments. This setup is similar to that of [20].
5.1

Permutation Invariant MNIST

The MNIST handwritten digit recognition task consists of 70,000 28x28 images (60,000
training, 10,000 test) of the 10 digits centered by their center of mass [33]. In the permutation
invariant setting of this task, we attempted to classify the digits without utilizing the 2D
structure of the images, e.g. every digit is a vector of pixels. The last 10,000 examples in the
training set were used for hyperparameter tuning. The model with the best hyperparameter
setting was trained until convergence on the full training set. Mini-batches of size 20 were
2

To speed up our experiments, the Gnumpy [30] and CUDAMat [31] libraries were used.

5

Table 2: Test set errors on the permutation invariant MNIST dataset for methods without
data augmentation or unsupervised pre-training
Activation
Sigmoid [32]
ReLU [27]
ReLU + dropout in hidden layers [20]
LWTA-2

Test Error
1.60%
1.43%
1.30%
1.28%

Table 3: Test set errors on MNIST dataset for convolutional architectures with no data
augmentation. Results marked with an asterisk use layer-wise unsupervised feature learning
to pre-train the network and global fine tuning.
Architecture
2-layer CNN + 2 layer MLP [34] *
2-layer ReLU CNN + 2 layer LWTA-2
3-layer ReLU CNN [35]
2-layer CNN + 2 layer MLP [36] *
3-layer ReLU CNN + stochastic pooling [33]
3-layer maxout + dropout [19]

Test Error
0.60%
0.57%
0.55%
0.53%
0.47%
0.45%

used, the pixel values were rescaled to [0, 1] (no further preprocessing). The best model
obtained, which gave a test set error of 1.28%, consisted of three LWTA layers of 500
blocks followed by a 10-way softmax layer. To our knowledge, this is the best reported
error, without utilizing implicit/explicit model averaging, for this setting which does not use
deformations/noise to enhance the dataset or unsupervised pretraining. Table 2 compares
our results with other methods which do not use unsupervised pre-training. The performance
of LWTA is comparable to that of a ReLU network with dropout in the hidden layers. Using
dropout in input layers as well, lower error rates of 1.1% using ReLU [20] and 0.94% using
maxout [19] have been obtained.
5.2

Convolutional Network on MNIST

For this experiment, a convolutional network (CNN) was used consisting of 7 ? 7 filters in
the first layer followed by a second layer of 6 ? 6, with 16 and 32 maps respectively, and
ReLU activation. Every convolutional layer is followed by a 2 ? 2 max-pooling operation.
We then use two LWTA-2 layers each with 64 blocks and finally a 10-way softmax output
layer. A weight decay of 0.05 was found to be beneficial to improve generalization. The
results are summarized in Table 3 along with other state-of-the-art approaches which do not
use data augmentation (for details of convolutional architectures, see [33]).
5.3

Amazon Sentiment Analysis

LWTA networks were tested on the Amazon sentiment analysis dataset [37] since ReLU units
have been shown to perform well in this domain [27, 38]. We used the balanced subset of the
dataset consisting of reviews of four categories of products: Books, DVDs, Electronics and
Kitchen appliances. The task is to classify the reviews as positive or negative. The dataset
consists of 1000 positive and 1000 negative reviews in each category. The text of each review
was converted into a binary feature vector encoding the presence or absence of unigrams
and bigrams. Following [27], the 5000 most frequent vocabulary entries were retained as
features for classification. We then divided the data into 10 equal balanced folds, and
tested our network with cross-validation, reporting the mean test error over all folds. ReLU
activation was used on this dataset in the context of unsupervised learning with denoising
autoencoders to obtain sparse feature representations which were used for classification. We
trained an LWTA-2 network with three layers of 500 blocks each in a supervised setting to
directly classify each review as positive or negative using a 2-way softmax output layer. We
obtained mean accuracies of Books: 80%, DVDs: 81.05%, Electronics: 84.45% and Kitchen:
85.8%, giving a mean accuracy of 82.82%, compared to 78.95% reported in [27] for denoising
autoencoders using ReLU and unsupervised pre-training to find a good initialization.
6

Table 4: LWTA networks outperform sigmoid and ReLU activation in remembering dataset
P1 after training on dataset P2.
Testing error on P1
After training on P1
After training on P2

6

LWTA
1.55 ? 0.20%
6.12 ? 3.39%

Sigmoid
1.38 ? 0.06%
57.84 ? 1.13%

ReLU
1.30 ? 0.13%
16.63 ? 6.07%

Implicit long term memory

This section examines the effect of the LWTA architecture on catastrophic forgetting. That
is, does the fact that the network implements multiple models allow it to retain information
about dataset A, even after being trained on a different dataset B? To test for this implicit
long term memory, the MNIST training and test sets were each divided into two parts, P1
containing only digits {0, 1, 2, 3, 4}, and P2 consisting of the remaining digits {5, 6, 7, 8, 9}.
Three different network architectures were compared: (1) three LWTA layers each with 500
blocks of size 2, (2) three layers each with 1000 sigmoidal neurons, and (3) three layers each
of 1000 ReLU neurons. All networks have a 5-way softmax output layer representing the
probability of an example belonging to each of the five classes. All networks were initialized
with the same parameters, and trained with a fixed learning rate and momentum.
Each network was first trained to reach a 0.03 log-likelihood error on the P1 training set.
This value was chosen heuristically to produce low test set errors in reasonable time for
all three network types. The weights for the output layer (corresponding to the softmax
classifier) were then stored, and the network was trained further, starting with new initial
random output layer weights, to reach the same log-likelihood value on P2. Finally, the
output layer weights saved from P1 were restored, and the network was evaluated on the
P1 test set. The experiment was repeated for 10 different initializations.
Table 4 shows that the LWTA network remembers what was learned from P1 much better
than sigmoid and ReLU networks, though it is notable that the sigmoid network performs
much worse than both LWTA and ReLU. While the test error values depend on the learning
rate and momentum used, LWTA networks tended to remember better than the ReLU
network by about a factor of two in most cases, and sigmoid networks always performed
much worse. Although standard network architectures are known to suffer from catastrophic
forgetting, we not only show here, for the first time, that ReLU networks are actually quite
good in this regard, and moreover, that they are outperformed by LWTA. We expect this
behavior to manifest itself in competitive models in general, and to become more pronounced
with increasingly complex datasets. The neurons encoding specific features in one dataset
are not affected much during training on another dataset, whereas neurons encoding common
features can be reused. Thus, LWTA may be a step forward towards models that do not
forget easily.

7

Analysis of subnetworks

A network with a single LWTA-m of N blocks consists of mN subnetworks which can be
selected and trained for individual examples while training over a dataset. After training,
we expect the subnetworks consisting of active neurons for examples from the same class to
have more neurons in common compared to subnetworks being activated for different classes.
In the case of relatively simple datasets like MNIST, it is possible to examine the number
of common neurons between mean subnetworks which are used for each class. To do this,
which neurons were active in the layer for each example in a subset of 10,000 examples were
recorded. For each class, the subnetwork consisting of neurons active for at least 90% of the
examples was designated the representative mean subnetwork, which was then compared to
all other class subnetworks by counting the number of neurons in common.
Figure 3a shows the fraction of neurons in common between the mean subnetworks of each
pair of digits. Digits that are morphologically similar such as ?3? and ?8? have subnetworks
with more neurons in common than the subnetworks for digits ?1? and ?2? or ?1? and ?5?
which are intuitively less similar. To verify that this subnetwork specialization is a result
of training, we looked at the fraction of common neurons between all pairs of digits for the
7

untrained
trained

0.4

0.7
0.6
0.5
0.4

0.3

0.3

0.2
0

1

2

3

4 5 6
Digits

7

8

9

0.2
0

10

20

30

40

50

Fraction of neurons in common

Digits

0
1
2
3
4
5
6
7
8
9

0.1

MNIST digit pairs
(b)

(a)

Figure 3: (a) Each entry in the matrix denotes the fraction of neurons that a pair of MNIST
digits has in common, on average, in the subnetworks that are most active for each of the
two digit classes. (b) The fraction of neurons in common in the subnetworks of each of the
55 possible digit pairs, before and after training.
same 10000 examples both before and after training (Figure 3b). Clearly, the subnetworks
were much more similar prior to training, and the full network has learned to partition its
parameters to reflect the structure of the data.

8

Conclusion and future research directions

Our LWTA networks automatically self-modularize into multiple parameter-sharing subnetworks responding to different input representations. Without significant degradation of
state-of-the-art results on digit recognition and sentiment analysis, LWTA networks also
avoid catastrophic forgetting, thus retaining useful representations of one set of inputs even
after being trained to classify another. This has implications for continual learning agents
that should not forget representations of parts of their environment when being exposed to
other parts. We hope to explore many promising applications of these ideas in the future.
Acknowledgments
This research was funded by EU projects WAY (FP7-ICT-288551), NeuralDynamics (FP7ICT-270247), and NASCENCE (FP7-ICT-317662); additional funding from ArcelorMittal.

References
[1] Per Anderson, Gary N. Gross, Terje L?mo, and Ola Sveen. Participation of inhibitory and
excitatory interneurones in the control of hippocampal cortical output. In Mary A.B. Brazier,
editor, The Interneuron, volume 11. University of California Press, Los Angeles, 1969.
[2] John Carew Eccles, Masao Ito, and J?nos Szent?gothai. The cerebellum as a neuronal machine.
Springer-Verlag New York, 1967.
[3] Costas Stefanis. Interneuronal mechanisms in the cortex. In Mary A.B. Brazier, editor, The
Interneuron, volume 11. University of California Press, Los Angeles, 1969.
[4] Stephen Grossberg. Contour enhancement, short-term memory, and constancies in reverberating neural networks. Studies in Applied Mathematics, 52:213?257, 1973.
[5] Michael McCloskey and Neal J. Cohen. Catastrophic interference in connectionist networks:
The sequential learning problem. The Psychology of Learning and Motivation, 24:109?164,
1989.
[6] Gail A. Carpenter and Stephen Grossberg. The art of adaptive pattern recognition by a
self-organising neural network. Computer, 21(3):77?88, 1988.
[7] Mark B. Ring. Continual Learning in Reinforcement Environments. PhD thesis, Department
of Computer Sciences, The University of Texas at Austin, Austin, Texas 78712, August 1994.
[8] Samuel A. Ellias and Stephen Grossberg. Pattern formation, contrast control, and oscillations
in the short term memory of shunting on-center off-surround networks. Bio. Cybernetics, 1975.
[9] Brad Ermentrout. Complex dynamics in winner-take-all neural nets with slow inhibition.
Neural Networks, 5(1):415?431, 1992.

8

[10] Christoph von der Malsburg. Self-organization of orientation sensitive cells in the striate cortex.
Kybernetik, 14(2):85?100, December 1973.
[11] Teuvo Kohonen. Self-organized formation of topologically correct feature maps. Biological
cybernetics, 43(1):59?69, 1982.
[12] Risto Mikkulainen, James A. Bednar, Yoonsuck Choe, and Joseph Sirosh. Computational maps
in the visual cortex. Springer Science+ Business Media, 2005.
[13] Dale K. Lee, Laurent Itti, Christof Koch, and Jochen Braun. Attention activates winner-takeall competition among visual filters. Nature Neuroscience, 2(4):375?81, April 1999.
[14] Matthias Oster and Shih-Chii Liu. Spiking inputs to a winner-take-all network. In Proceedings
of NIPS, volume 18. MIT; 1998, 2006.
[15] John P. Lazzaro, Sylvie Ryckebusch, Misha Anne Mahowald, and Caver A. Mead. Winnertake-all networks of O(n) complexity. Technical report, 1988.
[16] Giacomo Indiveri. Modeling selective attention using a neuromorphic analog VLSI device.
Neural Computation, 12(12):2857?2880, 2000.
[17] Wolfgang Maass. Neural computation with winner-take-all as the only nonlinear operation. In
Proceedings of NIPS, volume 12, 1999.
[18] Wolfgang Maass. On the computational power of winner-take-all. Neural Computation,
12:2519?2535, 2000.
[19] Ian J. Goodfellow, David Warde-Farley, Mehdi Mirza, Aaron Courville, and Yoshua Bengio.
Maxout networks. In Proceedings of the ICML, 2013.
[20] Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R.
Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors,
2012. arXiv:1207.0580.
[21] Juergen Schmidhuber. A local learning algorithm for dynamic feedforward and recurrent
networks. Connection Science, 1(4):403?412, 1989.
[22] Rupesh K. Srivastava, Bas R. Steunebrink, and Juergen Schmidhuber. First experiments with
powerplay. Neural Networks, 2013.
[23] Maximillian Riesenhuber and Tomaso Poggio. Hierarchical models of object recognition in
cortex. Nature Neuroscience, 2(11), 1999.
[24] Alex Krizhevsky, Ilya Sutskever, and Goeffrey E. Hinton. Imagenet classification with deep
convolutional neural networks. In Proceedings of NIPS, pages 1?9, 2012.
[25] Dan Ciresan, Ueli Meier, and J?rgen Schmidhuber. Multi-column deep neural networks for
image classification. Proceeedings of the CVPR, 2012.
[26] Vinod Nair and Geoffrey E. Hinton. Rectified linear units improve restricted boltzmann machines. In Proceedings of the ICML, number 3, 2010.
[27] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Deep sparse rectifier networks. In AISTATS, volume 15, pages 315?323, 2011.
[28] George E. Dahl, Tara N. Sainath, and Geoffrey E. Hinton. Improving Deep Neural Networks
for LVCSR using Rectified Linear Units and Dropout. In Proceedings of ICASSP, 2013.
[29] Andrew L. Maas, Awni Y. Hannun, and Andrew Y. Ng. Rectifier nonlinearities improve neural
network acoustic models. In Proceedings of the ICML, 2013.
[30] Tijmen Tieleman. Gnumpy: an easy way to use GPU boards in Python. Department of
Computer Science, University of Toronto, 2010.
[31] Volodymyr Mnih. CUDAMat: a CUDA-based matrix class for Python. Department of Computer Science, University of Toronto, Tech. Rep. UTML TR, 4, 2009.
[32] Patrice Y. Simard, Dave Steinkraus, and John C. Platt. Best practices for convolutional
neural networks applied to visual document analysis. In International Conference on Document
Analysis and Recognition (ICDAR), 2003.
[33] Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning
applied to document recognition. Proceedings of the IEEE, 1998.
[34] Marc?Aurelio Ranzato, Christopher Poultney, Sumit Chopra, and Yann LeCun. Efficient learning of sparse representations with an energy-based model. In Proceedings of NIPS, 2007.
[35] Matthew D. Zeiler and Rob Fergus. Stochastic pooling for regularization of deep convolutional
neural networks. In Proceedings of the ICLR, 2013.
[36] Kevin Jarrett, Koray Kavukcuoglu, Marc?Aurelio Ranzato, and Yann LeCun. What is the best
multi-stage architecture for object recognition? In Proc. of the ICCV, pages 2146?2153, 2009.
[37] John Blitzer, Mark Dredze, and Fernando Pereira. Biographies, bollywood, boom-boxes and
blenders: Domain adaptation for sentiment classification. Annual Meeting-ACL, 2007.
[38] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain adaptation for large-scale sentiment classification: A deep learning approach. In Proceedings of the ICML, number 1, 2011.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 1747-a-snow-based-face-detector.pdf

A SNoW-Based Face Detector
Ming-Hsuan Yang
Dan Roth
Narendra Ahuja
Department of Computer Science and the Beckman Institute
University of Illinois at Urbana-Champaign
Urbana, IL 61801
mhyang~vision.ai.uiuc.edu

danr~cs.uiuc.edu

ahuja~vision.ai.uiuc.edu

Abstract
A novel learning approach for human face detection using a network
of linear units is presented. The SNoW learning architecture is a
sparse network of linear functions over a pre-defined or incrementally learned feature space and is specifically tailored for learning
in the presence of a very large number of features. A wide range of
face images in different poses, with different expressions and under
different lighting conditions are used as a training set to capture
the variations of human faces. Experimental results on commonly
used benchmark data sets of a wide range of face images show that
the SNoW-based approach outperforms methods that use neural
networks, Bayesian methods, support vector machines and others. Furthermore, learning and evaluation using the SNoW-based
method are significantly more efficient than with other methods.

1

Introduction

Growing interest in intelligent human computer interactions has motivated a recent
surge in research on problems such as face tracking, pose estimation, face expression
and gesture recognition. Most methods, however, assume human faces in their input
images have been detected and localized.
Given a single image or a sequence of images, the goal of face detection is to identify
and locate human faces regardless of their positions, scales, orientations, poses and
illumination. To support automated solutions for the above applications, this has
to be done efficiently and robustly. The challenge in building an efficient and robust
system for this problem stems from the fact that human faces are highly non-rigid
objects with a high degree of variability in size, shape, color and texture.
Numerous intensity-based methods have been proposed recently to detect human
faces in a single image or a sequence of images. Sung and Poggio [24J report an
example-based learning approach for locating vertical frontal views of human faces.
They use a number of Gaussian clusters to model the distributions of face and
non-face patterns. A small window is moved over an image to determine whether a
face exists using the estimated distributions. In [16], a detection algorithm is proposed that combines template matching and feature-based detection method using
hierarchical Markov random fields (MRF) and maximum a posteriori probability
(MAP) estimation. Colmenarez and Huang [4) apply Kullback relative information
for maximal discrimination between positive and negative examples of faces. They
use a family of discrete Markov processes to model faces and background patterns
and estimate the density functions. Detection of a face is based on the likelihood

A SNoW-Based Face Detector

863

ratio computed during training. Moghaddam and Pentland [12] propose a probabilistic method that is based on density estimation in a high dimensional space
using an eigenspace decomposition. In [20], Rowleyet al. use an ensemble of neural
networks to learn face and non-face patterns for face detection. Schneiderman et al.
describe a probabilistic method based on local appearance and principal component
analysis [23]. Their method gives some preliminary results on profile face detection.
Finally, hidden Markov models [17], higher order statistics [17], and support vector
machines (SVM) [14] have also been applied to face detection and demonstrated
some success in detecting upright frontal faces under certain lighting conditions.
In this paper, we present a face detection method that uses the SNoW learning
architecture [18, 3] to detect faces with different features and expressions, in different
poses, and under different lighting conditions. SNoW (Sparse Network of Winnows)
is a sparse network of linear functions that utilizes the Winnow update rule [10].
SNoW is specifically tailored for learning in domains in which the potential number
of features taking part in decisions is very large, but may be unknown a priori. Some
of the characteristics of this learning architecture are its sparsely connected units,
the allocation of features and links in a data driven way, the decision mechanism
and the utilization of an efficient update rule. SNoW has been used successfully on
a variety of large scale learning tasks in the natural language domain [18, 13, 5, 19]
and this is its first use in the visual processing domain.
In training the SNoW-based face detector, we use a set of 1,681 face images from
Olivetti [22], UMIST [6], Harvard [7], Yale [1] and FERET [15] databases to capture the variations in face patterns. In order to compare our approach with other
methods, our experiments involve two benchmark data sets [20, 24] that have been
used in other works on face detection. The experimental results on these benchmark
data sets (which consist of 225 images with 619 faces) show that our method outperforms all other methods evaluated on this problem, including those using neural
networks [20], Kullback relative information [4], naive Bayes [23] and support vector
machines [14], while being significantly more efficient computationally. Along with
these experimental results we describe further experiments that provide insight into
some of the theoretical and practical considerations of SNoW-based learning systems. In particular, we study the effect of learning with primitive as well as with
multi-scale features, and discuss some of the sources of the success of the approach.

2

The SN oW System

The SNoW (Sparse Network of Winnows) learning architecture is a sparse network
of linear units over a common pre-defined or incrementally learned feature space.
Nodes in the input layer of the network represent simple relations over the input
and are being used as the input features. Each linear unit is called a target node and
represents relations which are of interest over the input examples; in the current
application, only two target nodes are being used, one as a representation for a face
pattern and the other for a non-face pattern. Given a set of relations (Le., types of
features) that may be of interest in the input image, each input image is mapped into
a set of features which are active (present) in it; this representation is presented
to the input layer of SNoW and propagates to the target nodes. (Features may
take either binary value, just indicating the fact that the feature is active (present)
or real values, reflecting its strength; in the current application, all features are
binary. See Sec 3.1.) Target nodes are linked via weighted edges to (some of the)
input features. Let At = {i 1 , ... , i m } be the set of features that are active in an
example and are linked to the target node t. Then the linear unit is active if and
only if 2:iEAt wf > Ot, where wf is the weight on the edge connecting the ith feature
to the target node t, and Ot is its threshold.
In the current application a single SNoW unit which includes two subnetworks, one

M-H Yang, D. Roth and N. Ahuja

864

for each of the targets, is used. A given example is treated autonomously by each
target subnetwork; that is, an image labeled as a face is used as a positive example
for the face target and as a negative example for the non-face target, and vice-versa.
The learning policy is on-line and mistake-driven; several update rules can be used
within SNoW. The most successful update rule, and the only one used in this
work is a variant of Littlestone's Winnow update rule, a mUltiplicative update rule
tailored to the situation in which the set of input features is not known a priori, as
in the infinite attribute model [2]. This mechanism is implemented via the sparse
architecture of SNoW. That is, (1) input features are allocated in a data driven
way - an input node for the feature i is allocated only if the feature i is active
in the input image and (2) a link (Le., a non-zero weight) exists between a target
node t and a feature i if and only if i has been active in an image labeled t. Thus,
the architecture also supports augmenting the feature types at later stages or from
external sources in a flexible way, an option we do not use in the current work.
The Winnow update rule has, in addition to the threshold fh at the target t, two
update parameters: a promotion parameter a > 1 and a demotion parameter 0 <
f3 < 1. These are being used to update the current representation of the target t (the
set of weights w;) only when a mistake in prediction is made. Let At = {il' ... , i m }
be the set of active features that are linked to the target node t. If the algorithm
predicts 0 (that is, LiEAt w~ ::; fh) and the received label is 1, the active weights in
the current example are promoted in a mUltiplicative fashion: 'Vi E At, wf +- a . w~.
If the algorithm predicts 1 (LiEA t wf > Ot) and the received label is 0, the active
weights in the current example are demoted: 'Vi E At, w~ +- f3. wf. All other weights
are unchanged. The key property of the Winnow update rule is that the number
of examples l it requires to learn a linear function grows linearly with the number
of relevant features and only logarithmically with the total number of features.
This property seems crucial in domains in which the number of potential features
is vast, but a relatively small number of them is relevant (this does not mean that
only a small number of them will be active, or have non-zero weights). Winnow
is known to learn efficiently any linear threshold function and to be robust in the
presence of various kinds of noise and in cases where no linear-threshold function can
make perfect classification, and still maintain its abovementioned dependence on the
number of total and relevant attributes [11, 9]. Once target subnetworks have been
learned and the network is being evaluated, a winner-take-all mechanism selects
the dominant active target node in the SNoW unit to produce a final prediction.
In general, but not in this work, units' output may be cached and processed along
with the output of other SNoW units to produce a coherent output.

3

Learning to detect faces

For training, we use a set of 1,681 face images (collected from Olivetti [22], UMIST
[6], Harvard [7], Yale [1] and FE RET [15] databases) which have wide variations
in pose, facial expression and lighting condition. For negative examples we start
with 8,422 non-face examples from 400 images of landscapes, trees, buildings, etc.
Although it is extremely difficult to collect a representative set of non-face examples,
the bootstrap method [24] is used to include more non-face examples during training.
For positive examples, each face sample is manually cropped and normalized such
that it is aligned vertically and its size is 20 x 20 pixels. To make the detection
method less sensitive to scale and rotation variation, 10 face examples are generated
from each original sample. The images are produced by randomly rotating the
images by up to 15 degrees with scaling between 80% and 120%. This produces
16,810 face samples. Then, histogram equalization is performed that maps the
lIn the on-line setting [10] this is usually phrased in terms of a mistake-bound but is
known to imply convergence in the PAC sense [25, 8].

A SNoW-Based Face Detector

865

intensity values to expand the range of intensities. The same procedure is applied
to input images in detection phase.
3.1 Primitive Features
The SNoW-based face detector makes use of Boolean features that encode the positions and intensity values of pixels. Let the pixel at (x, y) of an image with width
wand height h have intensity value I(x, y) (O :::; I{x, y) :::; 255). This information
is encoded as a feature whose index is 256{y * w + x) + I{x, y). This representation
ensures that different points in the {position x intensity} space are mapped to
different features. (That is, the feature indexed 256{y * w + x) + I{x, y) is active if
and only if the intensity in position (x, y) is I{x, y).) In our experiments, the values
for wand hare 20 since each face sample has been normalized to an image of 20 x 20
pixels. Note that although the number of potential features in our representation
is 102400 (400 x 256), only 400 of those are active (present) in each example, and it
is plausible that many features will never be active. Since the algorithm's complexity depends on the number of active features in an example, rather than the total
number of features, the sparseness also ensures efficiency.
3.2 Multi-scale Features
Many vision problems have utilized multi-scale features to capture the structures
of an object. However, extracting detailed multi-scale features using edge or region
information from segmentation is a computationally expensive task. Here we use the
SNo W paradigm to extract Boolean features that represent multi-scale information.
This is done in a similar way to the {position x intensity} used in Sec. 3.1,
only that in this case we encode, in addition to position, the mean and variance of a
multi-scale pixel. The hope is that the multi-scale feature will capture information
that otherwise requires many pixel-based features to represent, and thus simplify
the learning problem. Uninformative multi-scale features will be quickly assigned
low weights by the learning algorithm and will not degrade performance. Since
each face sample is normalized to be a rectangular image of the same size, it suffices
to consider rectangular sub-images with varying size from face samples, and for
each generate features in terms of the means and variances of their intensity values.
Empirical results show that faces can be described effectively this way.

Instead of using the absolute values of the mean and variance when encoding the
features, we discretize these values into a predefined number of classes. Since the
distribution of the mean values as well as the variance values is normal, the discretization is finer near the means of these distributions. The total number of
values was determined empirically to be 100, out of which 80 ended up near the
mean. Given that, we use the same scheme as in Sec. 3.1 to map the {position x
intensi ty mean x intensity variance} space into the Boolean feature space.
This is done separately for four different sub-image scales, of 1 x 1, 2 x 2, 4 x 4 to
10 x 10 pixels. The multi-scale feature vector consists of active features corresponding to all these scales. The number of active features in each example is therefore
400 + 100 + 25 + 4, although the total number of features is much larger.
In recent work we have used more sophisticated conjunctive features for this purpose
yielding even better results. However, the emphasis here is that with the SNoW
approach, even very simplistic features support excellent performance.

4

Empirical Results

We tested the SNoW-based approach with both sets of features on the two sets
of images collected by Rowley [20], and Sung [24]. Each image is scanned with a
rectangular window to determine whether a face exists in the window or not. To
detect faces of different scales, each input image is repeatedly subsampled by a
factor of 1.2 and scanned through for 10 iterations. Table 1 shows the reported

866

M-H. Yang, D. Roth and N Ahuja

experimental results of the SNoW-based face detectors and several face detection
systems using the two benchmark data sets (available at http://www.cs.cmu.edu/
-har/ faces.html). The first data set consists of 130 images with 507 frontal faces
and the second data set consists of 23 images with 155 frontal faces. There are
a few hand drawn faces and cartoon faces in both sets. Since some methods use
intensity values as their features, systems 1-4 and 7 discard these such hand drawn
and cartoon faces. Therefore, there are 125 images with 483 faces in test set 1 and
20 images with 136 faces in test set 2 respectively. The reported detection rate is
computed as the ratio between the number of faces detected in the images by the
system and the number of faces identified there by humans. The number of false
detections is the number of non-faces detected as faces.
It is difficult to evaluate the performance of different methods even though they
use the same benchmark data sets because different criteria (e.g. training time,
number of training examples involved, execution time, number of scanned windows
in detection) can be applied to favor one over another. Also, one can tune the
parameters of one's method to increase the detection rates while increasing also the
false detections. The methods using neural networks [20], distribution-based [24],
Kullback relative information [4] and naive Bayes [23] report several experimental
results based on different sets of parameters. Table 1 summarizes the best detection
rates and corresponding false detections of these methods. Although the method
in [4] has the highest detection rates in one benchmark test, this was done by
significantly increasing the number of false detections. Other than that, it is evident
that the SNoW-based face detectors outperforms others in terms of the overall
performance. These results show the credibility of SNoW for these tasks, as well
Table 1: Experimental results on images from test set 1 (125 images with 483 faces)
in [20] and test set 2 (20 images with 136 faces) in [24] (see text for details)
Test Set 1
Test Set 2
II
Method
/I Detect Rate
SNoW w/ priDlitive features
94.2'70
SNoW wi Dlulti-scale features
94.8%
Mixture of factor analyzers [261
92.3'70
Fisher linear discriminant [271
93.6'7.
Distribution- based. [24 J
N~
Neural network [20J
92.5J"o
Naive Bayes [23J
93.0%
Kullback relative information [41
98.0'7.
Support vector machine [14J
N/A

False Detects
84
78
82
74
N/A
862
88
12758
N/A

Detect Rate 1 False Detects
93.6'70
3
94.1%
3
89.4'70
3
91.5'7.
1
81.9%
13
90.3%
42
91.2%
12
NjA
NjA
74.2'7.
20

as exhibit the improvement achieved by increasing the expressiveness of the features.
This may indicate that further elaboration of the features, which can be done in a
very general and flexible way within SNoW, would yield further improvements.
In addition to comparing feature sets, we started to investigate some of the reasons
for the success of SNoW in this domain, which we discuss briefly below. Two
potential contributions are the Winnow update rule and the architecture. First, we
studied the update rule in isolation, independent of the SNoW architecture. The
results we got when using the Winnow simply as a discriminator were fairly poor
(63.9%/65.3% for Test Set 1, primitive and multi-scale features, respectively, and
similar results for the Test Set 2.). The results are not surprising, given that Winnow
is used here only as a discriminator and is using only positive weights. Investigating
the architecture in isolation reveals that weighting or discarding features based on
their contribution to mistakes during training, as is done within SNoW, is crucial.
Considering the active features uniformly (separately for faces and non-faces) yields
poor results. Specifically, studying the resulting SNoW network shows that the total
number of features that were active with non-faces is 102,208, out of 102,400 possible

A SNoW-Based Face Detector

867

(primitive) features. The total number of active features in faces was only 82,608,
most of which are active only a few times. In retrospect, this is clear given the
diverse set of images used as negative examples, relative to the somewhat restricted
(by nature) set of images that constitute faces. (Similar phenomenon occurs with
the multi-scale features, where the numbers are 121572 and 90528, respectively, out
of 135424.) Overall it exhibits that the architecture, the learning regime and the
update rule all contribute significantly to the success of the approach.
Figure 1 shows some faces detected in our experiments. Note that profile faces and
faces under heavy illumination are detected. Experimental results show that profile
faces and faces under different illumination are detected very well by our method.
Note that although there may exist several detected faces around each face, only
one window is drawn to enclose each detected face for clear presentation .

.

.f?,~' "ru

-

i

...

'

Figure 1: Sample experimental results using our method on images from two benchmark data sets. Every detected face is shown with an enclosing window.

5

Discussion and Conclusion

Many theoretical and experimental issues are to be addressed before a learning system of this sort can be used to detect faces efficiently and robustly under general
conditions. In terms of the face detection problem, the presented method is still
not able to detect rotated faces. A recent method [21], addresses this problem by
building upon a upright face detector [20] and rotating each test sample to upright
position. However, it suffers from degraded detection rates and more false detections. Given our results, we believe that the SNoW approach, if adapted in similar
ways, would generalize very well to detect faces under more general conditions.
In terms of the SNoW architecture, although the main ingredients of it are understood theoretically, more work is required to better understand its strengths. This
is increasingly interesting given that the architecture has been found to perform
very well in large-scale problem in the natural language domain as well

868

M-H. Yang, D. Roth and N Ahuja

The contributions of this paper can be summarized as follows. We have introduced
the SNoW learning architecture to the domain of visual processing and described an
approach that detect faces regardless of their poses, facial features and illumination
conditions. Experimental results show that this method outperforms other methods
in terms of detection rates and false detectionss, while being more efficient both in
learning and evaluation.

References
[1) P. Belhumeur, J. Hespanha, and D. Kriegman. Eigenfaces vs. fisherfaces: Recognition using class
specific linear projection. IEEE Transactions on Pattern Analysis and Machine Intelligence,
19(7):711-720, 1997.
[2) A. Blum. Learning boolean functions in an infinite attribute space. Machine Learning, 9(4):373386, 1992.
[3) A. Carleson, C. Cumby, J. Rosen, and D. Roth . The SNoW learning architecture. Technical Report
UIUCDCS-R-99-2101, UIUC Computer Science Department, May 1999.
[4) A. J. Colmenarez and T . S. Huang. Face detection with information-based maximum discrimination. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern
Recognition, pages 782-787, 1997.
[5) A. R. Golding and D. Roth. A winnow based approach to context-sensitive spelling correction.
Machine Learning, 34:107-130, 1999. Special Issue on Machine Learning and Natural Language.
[6) D. B . Graham and N . M. Allinson. Characterizing virtual eigensignatures for general purpose face
recognition. In H. Wechsler, P. J. Phillips, V . Bruce, F. Fogelman-Soulie, and T . S. Huang, editors,
Face Recognition: From Theory to Applications, volume 163 of NATO ASI Series F, Computer
and Systems Sciences, pages 446-456. Springer, 1998.
[7) P. Hallinan. A Deformable Model for Face Recognition Under Arbitrary Lighting Conditions.
PhD thesis, Harvard University, 1995.
[8) D. Helmbold and M . K. Warmuth. On weak learning. Journal of Computer and System Sciences,
50(3):551-573, June 1995.
[9) J . kivinen and M. K . Warmuth. Exponentiated gradient versus gradient descent for linear predictors. In Proceedings oj the Annual ACM Symposium on the Theory of Computing, 1995.
[10) N. Littlestone. Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm. Machine Learning, 2:285-318, 1988.
[11) N. Littlestone. Redundant noisy attributes, attribute errors, and linear threshold learning using
winnow. In Proceedings oj the fourth Annual Workshop on Computational Learning Theory,
pages 147-156, 1991.
[12) B. Moghaddam and A . Pentland. Probabilistic visual learning for object recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence, 19(7):696-710, 1997.
[13) M. Munoz, V. Punyakanok, D. Roth, and D. Zimak. A learning approach to shallow parsing. In
EMNLP- VLC'99, the Joint SIGDAT Conference on Empirical Methods in Natural Language
Processing and Very Large Corpora, June 1999.
[14) E. Osuna, R . Freund, and F. Girosi. Training support vector machines: an application to face
detection. In Proceedings of the IEEE Computer Society Conference on Computer Vision and
Pattern Recognition, pages 130-136, 1997.
[15) P. J. Phillips, H. Moon, S . Rizvi , and P . Rauss. The feret evaluation. In H. Wechsler, P. J.
Phillips, V . Bruce, F. Fogelman-Soulie, and T. S . Huang, editors, Face Recognition: From Theory
to Applications, volume 163 of NATO ASI Series F, Computer and Systems Sciences, pages
244-261. Springer, 1998.
[16) R. J. Qian and T. S . Huang. Object detection using hierarchical mrf and map estimation. In
Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, pages 186-192, 1997.
[17) A. N. Rajagopalan, K. S. Kumar, J. Karlekar, R. Manivasakan, and M . M. Patil. Finding faces in
photographs . In Proceedings of the Sixth International Conference on Computer Vision, pages
640-645, 1998.
[18) D. Roth. Learning to resolve natural language ambiguities: A unified approach. In Proceedings of
the Fifteenth National Conference on Artificial Intelligence, pages 806-813, 1998.
[19) D. Roth and D. Zelenko. Part of speech tagging using a network of linear separators. In COLINGACL 98, The 17th Int. Conference on Computational Linguistics, pages 1136-1142, 1998.
[20) H. Rowley, S . Baluja, and T. Kanade. Neural network-based face detection. IEEE Transactions
on Pattern Analysis and Machine Intelligence, 20(1):23-38, 1998.
[21) H. Rowley, S. Baluja, and T . Kanade . Rotation invariant neural network-based face detection.
In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern
Recognition, pages 38-44, 1998.
[22) F. S. Samaria. Face Recognition Using Hidden Markov Models. PhD thesis, University of Cambridge, 1994.
[23) H . Schneiderman and T . Kanade. Probabilistic modeling of local appearance and spatial relationships for object recognition. In Proceedings of the IEEE Computer Society Conference on
Computer Vision and Pattern Recognition, pages 45- 51, 1998.
[24) K.-K. Sung and T . Poggio. Example-based learning for view-based human face detection . IEEE
Transactions on Pattern Analysis and Machine Intelligence, 20(1):39-51, 1998.
L. G. Valiant. A theory of the learnable. Commun. ACM, 27(11):1134-1142, Nov. 1984.
M .-H. Yang, N. Ahuja, and D. Kriegman . Face detection using a mixture of factor analyzers . In
Proce'edings of the IEEE International Conference on Image Processing, 1999 .
[27) M.-H. Yang, N. Ahuja, and D . Kriegman. Mixtures of linear subspaces for face detection. In Proceedings of the Foruth IEEE International Conference on Automatic Face and Gesture Recognition, 2000.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 553-propagation-filters-in-pds-networks-for-sequencing-and-ambiguity-resolution.pdf

Propagation Filters in PDS Networks for
Sequencing and Ambiguity Resolution

Ronald A. Sumida
Michael G. Dyer
Artificial Intelligence Laboratory
Computer Science Department
University of California
Los Angeles, CA, 90024
sumida@cs.ucla.edu

Abstract
We present a Parallel Distributed Semantic (PDS) Network architecture
that addresses the problems of sequencing and ambiguity resolution in
natural language understanding. A PDS Network stores phrases and their
meanings using multiple PDP networks, structured in the form of a semantic net. A mechanism called Propagation Filters is employed: (1) to
control communication between networks, (2) to properly sequence the
components of a phrase, and (3) to resolve ambiguities. Simulation results
indicate that PDS Networks and Propagation Filters can successfully represent high-level knowledge, can be trained relatively quickly, and provide
for parallel inferencing at the knowledge level.

1

INTRODUCTION

Backpropagation has shown considerable potential for addressing problems in natural language processing (NLP). However, the traditional PDP [Rumelhart and
McClelland, 1986] approach of using one (or a small number) of backprop networks
for NLP has been plagued by a number of problems: (1) it has been largely unsuccessful at representing high-level knowledge, (2) the networks are slow to train, and
(3) they are sequential at the knowledge level. A solution to these problems is to
represent high-level knowledge structures over a large number of smaller PDP net-

233

234

Sumida and Dyer

works. Reducing the size of each network allows for much faster training, and since
the different networks can operate in parallel, more than one knowledge structure
can be stored or accessed at a time.
In using multiple networks, however, a number of important issues must be addressed: how the individual networks communicate with one another, how patterns
are routed from one network to another, and how sequencing is accomplished as
patterns are propagated. In previous papers [Sumida and Dyer, 1989] [Sumida,
1991], we have demonstrated how to represent high-level semantic knowledge and
generate dynamic inferences using Parallel Distributed Semantic (PDS) Networks,
which structure multiple PDP networks in the form of a semantic network. This
paper discusses how Propagation Filters address communication and sequencing
issues in using multiple PDP networks for NLP.

2

PROPAGATION FILTERS

Propagation Filters are inspired by the idea of skeleton filters, proposed by [Sejnowski, 1981, Hinton, 1981]. They are composed of: (1) sets of filter ensembles
that gate the connection from a source to a destination and (2) a selector ensemble
that decides which filter group to enable. Each filter group is sensitive to a particular pattern over the selector. When the particular pattern occurs, the source
pattern is propagated to its destination. Figure 1 is an example of a propagation filter where the "01" pattern over units 2 and 3 of the selector opens up filter group1,
thus permitting the pattern to be copied from source1 to destination!. The units
of filter group2 do not respond to the "01" pattern and remain well below thresold,
so the activation pattern over the source2 ensemble is not propagated.

H*wrMA~f-~
I

I

I

I

...

I

????

lOurcol

i1
I

I I

fill? IJ'OUpl I I

~-----~-~~--~
I I

sourcc2

Mv..-~-

filter group2

destin.tioo2

Figure 1: A Propagation Filter architecture. The small circles indicate PDP units
within an ensemble (oval), the black arrows represent full connectivity between two
ensembles, and the dotted lines connecting units 2 and 3 of the selector to each
filter group oval indicate total connectivity from selector units to filter units. The
jagged lines are suggestive of temporary patterns of activation over an ensemble.
The units in a filter group receive input from units in the selector. The weights
on these input connections are set so that when a specific pattern occurs over the

Propagation Filters in PDS Networks

selector, every unit in the filter group is driven above threshold. The filter units
also receive input from the source units and provide output to the destination units.
The weights on both these i/o connections can be set so that the filter merely copies
the pattern from the source to the destination when its units exceed threshold (as
in Figure 1). Alternatively, these weights can be set (e.g. using backpropagation)
so that the filter transforms the source pattern to a desired destination pattern.

3

PDS NETWORKS

PDS Networks store syntactic and semantic information over multiple PDP networks, with each network representing a class of concepts and with related networks connected in the general manner of a semantic net. For example, Figure 2
shows a network for encoding a basic sentence consisting of a subject, verb and
direct object. The network is connected to other PDP networks, such as HUMAN,
VERB and ANIMAL, that store information about the content of the subject role
(s-content), the filler for the verb role, and the content of the direct-object role
(do-content). Each network functions as a type of encoder net, where: (1) the input
and output layers have the same number of units and are presented with exactly the
same pattern, (2) the weights of the network are modified so that the input pattern
will recreate itself as output, and (3) the resulting hidden unit pattern represents
a reduced description of the input. In the networks that we use, a single set of
units is used for both the input and output layers. The net can thus be viewed as
an encoder with the output layer folded back onto the input layer and with two
sets of connections: one from the single input/output layer to the hidden layer,
and one from the hidden layer back to the i/o layer. In Figure 2 for example, the
subject-content, verb, and direct-object-content role-groups collectively represent
the input/output layer, and the BASIC-S ensemble represents the hidden layer .

......... ...........

-----....<//tvM
,
,
I

HUMAN

I
I

I

MA
="hit"

VERB

= DOG

Figure 2: The network that stores information about a basic sentence. The black
arrows represent links from the input layer to the hidden layer and the grey arrows
indicate links from the hidden layer to the output layer. The thick lines represent
links between networks that propagate a pattern without changing it.
A network stores information by learning to encode the items in its training set.

235

236

Sumida and Dyer

For each item, the patterns that represent its features are presented to the input
role groups, and the weights are modified so that the patterns recreate themselves
as output. For example, in Figure 2, the MAN-"hit"-DOG pattern is presented to
the BASIC-S network by propagating the MAN pattern from the HUMAN network
to the s-content role, the "hit" pattern from the VERB network to the verb-content
role, and the DOG pattern from the ANIMAL network to the do-content role.
The BASIC-S network is then trained on this pattern by modifying the weights
between the input/output role groups and the BASIC-S hidden units so that the
MAN-"hit"-DOG pattern recreates itself as output. The network automatically
generalizes by having the hidden units become sensitive to common features of the
training patterns. When the network is tested on a new concept (i.e., one that is
not in the training set), the pattern over the hidden units reflects its similarity to
the items seen during training.

3.1

SEQUENCING PHRASES

To illustrate how Propagation Filters sequence the components of a phrase, consider
the following sentence, whose constituents occur in the standard subject-verb-object
order: 81. The man hit the dog. We would like to recognize that the BASIC-S
network of Figure 2 is applicable to the input by binding the roles of the network to
the correct components. In order to generate the proper role bindings, the system
must: (1) recognize the components of the sentence in the correct order (e.g. "the
man" should be recognized as the subject, "hit" as the verb, and "the dog" as
the direct object), and (2) associate each phrase of the input with its meaning
(e.g. reading the phrase "the man" should cause the pattern for the concept MAN
to appear over the HUMAN units). Figure 3 illustrates how Propagation Filters
properly sequence the components of the sentence.
First, the phrase "the man" is read by placing the pattern for "the" over the determiner network (Step 1) and the pattern for "man" over the noun network (Step 2).
The "the" pattern is then propagated to the np-determiner input role units of
the NP network (Step 3) and the "man" pattern to the np-noun role input units
(Step 4). The pattern that results over the hidden NP units is then used to represent the entire phrase "the man" (Step 5). The filters connecting the NP units with
the subject and direct object roles are not enabled, so the pattern is not yet bound
to any role. Next, the word "hit" is read and a pattern for it is generated over
the VERB units (Step 6). The BASIC-S network is now applicable to the input
(for simplicity of exposition, we ignore passive constructions here). Since there are
no restrictions (i.e., no filter) on the connection between the VERB units and the
verb role of BASIC-S, the "hit" pattern is bound to the verb role (Step 7). The
verb role units act as the selector of the Propagation Filter that connects the NP
units to the subject units. The filter is constructed so that whenever any of the
verb role units receive non-zero input (i.e., whenever the role is bound) it opens up
the filter group connecting NP with the subject role (Step 8). Thus, the pattern
for "the man" is copied from NP to the subject (Step 9) and deleted from the NP
units. Similarly, the subject units act as the selector of a filter that connects NP
with the direct object. Since the subject was just bound, the connection from the
NP to direct object is enabled (Step 10). At this point, the system has generated
the expectation that a NP will occur next. The phrase "the dog" is now read and

Propagation Filters in PDS Networks

9.

16.~

7.~

MA

....

"the man"

,. ,.

.... ....

"hit"

,.

"the dog"

VERB

s?MA

~

6.~

"the dog"

"hit"

11-IS.

"the man"

3.~

4?NM

"the"

DET

l.~
"the"

"man"

N

2.NM

"man"

Figure 3: The figure shows how Propagation Filters sequence the components of
the sentence "The man hit the dog". The numbers indicate the order of events.
The dotted arrows indicate Propagation Filter connections from a selector to an
open filter group (indicated by a black circle) and the dark arrows represent the
connections from a source to a destination.
its pattern is generated over the NP units (Steps 11-15). Finally, the pattern for
"the dog" is copied across the open connection from NP to direct-object (Step 16).

3.2

ASSOCIATING PHRASES WITH MEANINGS

The next task is to associate lexical patterns with their corresponding semantic patterns and bind semantic patterns to the appropriate roles in the BASIC-S network.
Figure 4 indicates how Propagation Filters: (1) transform the phrase "the man"
into its meaning (i.e., MAN), and (2) bind MAN to the s-content role of BASIC-S.
Reading the word "man", by placing the "man" pattern into the noun units (Step 2),
opens the filter connecting N to HUMAN (Step 5), while leaving the filters connecting N to other networks (e.g. ANIMAL) closed. The opened filter transforms
the lexical pattern "man" over N into the semantic pattern MAN over HUMAN
(Step 7). Binding "the man" to subject (Step 8) by the procedure shown in the
Figure 3 opens the filter connecting HUMAN to the s-content role of BASIC-S
(Step 9). The s-content role is then bound to MAN (Step 10).
The do-content role is bound by a procedure similar to that shown in Figure 4.
When "dog" is read, the filter connecting N with ANIMAL is opened while filters
to other networks (e.g. HUMAN) remain closed. The "dog" pattern is then transformed into the semantic pattern DOG over the ANIMAL units. When "the dog"

237

238

Sumida and Dyer
BASIC-S

Figure 4: The figure illustrates how the concept MAN is bound to the s-content role
of BASIC-S, given the phrase "the man" as input. Black (white) circles indicate
open (closed) filters.

is bound to direct-object as in Figure 3, the filter from ANIMAL to do-content is
opened, and DOG is propagated from ANIMAL to the do-content role of BASIC-S.

3.3

AMBIGUITY RESOLUTION AND INFERENCING

There are two forms that inference and ambiguity resolution can take: (1) routing
patterns (e.g. propagation of role bindings) to the appropriate subnets and (2)
pattern reconstruction from items seen during training.
(1) Pattern Routing: Propagation Filters help resolve ambiguities by having the
selector only open connections to the network containing the correct interpretation.
As an example, consider the following sentence: S2. The singer hit the note. Both
S2 and Sl (Sec. 3.1) have the same syntactic structure and are therefore represented
over the BASIC-S ensemble of Figure 2. However, the meaning of the word "hit"
in Sl refers to physically striking an object while in S2 it refers to singing a musical
note. The pattern over the BASIC-S units that represents Sl differs significantly
from the pattern that represents S2, due to the differences in the s-content and
do-content roles. A Propagation Filter with the BASIC-S units as its selector uses
the differences in the two patterns to determine whether to open connections to the
HIT network or to the PERFORM-MUSIC network (Figure 5).

Propagation Filters in PDS Networks
PERRlRM-MUSIC

---/wA
Figure 5: The pattern over BASIC-S acts as a selector that determines whether
to open the connections to HIT or to PERFORM-MUSIC. Since the input here is
MAN-"hit"-DOG, the filters to HIT are opened while the filters to PERFORMMUSIC remain closed. The black and grey arrows indicating connections between
the input/output and hidden layers have been replaced by a single thin line.
During training, the BASIC-S network was presented with sentences of the general
form <MUSIC-PERFORMER "hit" MUSICAL-NOTE> and <ANIMATE "hit"
OBJECT>. The BASIC-S hidden units generalize from the training sentences by
developing a distinct pattern for each of the two types of "hit" sentences. The Propagation Filter is then constructed so that the hidden unit pattern for <MUSICPERFORMER "hit" MUSICAL-NOTE> opens up connections to PERFORMMUSIC, while the pattern for <ANIMATE "hit" OBJECT> opens up connections
to HIT. Thus, when S1 is presented, the BASIC-S hidden units develop the pattern
classifying it as <ANIMATE "hit" OBJECT>, which enables connections to HIT.
For example, Figure 5 shows how the MAN pattern is routed from the s-content
role of BASIC-S to the actor role of HIT and the DOG pattern is routed from the
do-content role of BASIC-S to the object role of HIT. If S2 is presented instead, the
hidden units will classify it as <MUSIC-PERFORMER "hit" MUSICAL-NOTE>
and open the connections to PERFORM-MUSIC.
The technique of using propagation filters to control pattern routing can also be
applied to generate inferences. Consider the sentence, "Douglas hit Tyson". Since
both are boxers, it is plausible they are involved in a competitive activity. In S1,
however, punishing the dog is a more plausible motivation for HIT. The proper
inference is generated in each case by training the HIT network (Figure 5) on a
number of instances of boxers hitting one another and of people hitting dogs. The
network learns two distinct sets of hidden unit patterns: <BOXER-HIT-BOXER>
and <HUMAN-HIT-DOG>. A Propagation Filter, (like that shown in Figure 5)
with the HIT units as its selector, uses the differences in the two classes of patterns
to route to either the network that stores competitive activities or to the network
that stores punishment acts.
(2) Pattern Reconstruction: The system also resolves ambiguities by reconstructing
patterns that were seen during training. For example, the word "note" in sentence

239

240

Sumida and Dyer

S2 is ambiguous and could refer to a message, as in "The singer left the note".
Thus, when the word "note" is read in S2, the do-content role of BASIC-S can
be bound to MESSAGE or to MUSICAL-NOTE. To resolve the ambiguity, the
BASIC-S network uses the information that SINGER is bound to the s-content role
and "hit" to the verb role to: (1) reconstruct the <MUSIC-PERFORMER "hit"
MUSICAL-NOTE> pattern that it learned during training and (2) predict that the
do-content will be MUSICAL-NOTE. Since the prediction is consistent with one of
the possible meanings for the do-content role, the ambiguity is resolved. Similarly, if
the input had been "The singer left the note", BASIC-S would use the binding of a
human to the s-content role and the binding of "left" to the verb role to reconstruct
the pattern <HUMAN "left" MESSAGE> and thus resolve the ambiguity.

4

CURRENT STATUS AND CONCLUSIONS

PDS Networks and Propagation Filters are implemented in OCAIN, a natural language understanding system that: (1) takes each word of the input sequentially, (2)
binds the roles of the corresponding syntactic and semantic structures in the proper
order, and (3) resolves ambiguities. In our simulations with OCAIN, we successfully represented high-level knowledge by structuring individual PDP networks in
the form of a semantic net. Because the system's knowledge is spread over multiple
subnetworks, each one is relatively small and can therefore be trained quickly. Since
the subnetworks can operate in parallel, OCAIN is able to store and retrieve more
than one knowledge structure simultaneously, thus achieving knowlege-Ievel parallelism. Because PDP ensembles (versus single localist units) are used, the generalization, noise and fault-tolerance properties of the PDP approach are retained. At
the same time, Propagation Filters provide control over the way patterns are routed
(and transformed) between subnetworks. The PDS architecture, with its Propagation Filters, thus provides significant advantages over traditional PDP models for
natural language understanding.
References

[Hinton, 1981] G. E. Hinton. Implementing Semantic Networks in Parallel Hardware. In Parallel Models of Associative Memory, Lawrence Erlbaum, Hillsdale,
NJ, 1981.
[Rumelhart and McClelland, 1986] D. E. Rumelhart and J. L. McClelland. Parallel
Distributed Processing, Volume 1. MIT Press, Cambridge, Massachusetts, 1986.
[Sejnowski, 1981] T. J. Sejnowski. Skeleton Filters in the Brain. In Parallel Models
of Associative Memory, Lawrence Erlbaum, Hillsdale, NJ, 1981.
[Sumida and Dyer, 1989] R. A. Sumida and M. G. Dyer. Storing and Generalizing
Multiple Instances while Maintaining Knowledge-Level Parallelism. In Proceedings of the Eleventh International Joint Conference on Artificial Intelligence,

Detroit, MI, 1989.
[Sumida, 1991] R. A. Sumida. Dynamic Inferencing in Parallel Distributed Semantic Networks. In Proceedings of the Thirteenth Annual Conference of the Cognitive
Science Society, Chicago, IL, 1991.


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 6465-r-fcn-object-detection-via-region-based-fully-convolutional-networks.pdf

R-FCN: Object Detection via
Region-based Fully Convolutional Networks

Jifeng Dai
Microsoft Research

Yi Li?
Tsinghua University

Kaiming He
Microsoft Research

Jian Sun
Microsoft Research

Abstract
We present region-based, fully convolutional networks for accurate and efficient
object detection. In contrast to previous region-based detectors such as Fast/Faster
R-CNN [7, 19] that apply a costly per-region subnetwork hundreds of times, our
region-based detector is fully convolutional with almost all computation shared on
the entire image. To achieve this goal, we propose position-sensitive score maps
to address a dilemma between translation-invariance in image classification and
translation-variance in object detection. Our method can thus naturally adopt fully
convolutional image classifier backbones, such as the latest Residual Networks
(ResNets) [10], for object detection. We show competitive results on the PASCAL
VOC datasets (e.g., 83.6% mAP on the 2007 set) with the 101-layer ResNet.
Meanwhile, our result is achieved at a test-time speed of 170ms per image, 2.5-20?
faster than the Faster R-CNN counterpart. Code is made publicly available at:
https://github.com/daijifeng001/r-fcn.

1

Introduction

A prevalent family [9, 7, 19] of deep networks for object detection can be divided into two subnetworks
by the Region-of-Interest (RoI) pooling layer [7]: (i) a shared, ?fully convolutional? subnetwork
independent of RoIs, and (ii) an RoI-wise subnetwork that does not share computation. This
decomposition [9] was historically resulted from the pioneering classification architectures, such
as AlexNet [11] and VGG Nets [24], that consist of two subnetworks by design ? a convolutional
subnetwork ending with a spatial pooling layer, followed by several fully-connected (fc) layers. Thus
the (last) spatial pooling layer in image classification networks is naturally turned into the RoI pooling
layer in object detection networks [9, 7, 19].
But recent state-of-the-art image classification networks such as Residual Nets (ResNets) [10] and
GoogLeNets [25, 27] are by design fully convolutional2 . By analogy, it appears natural to use
all convolutional layers to construct the shared, convolutional subnetwork in the object detection
architecture, leaving the RoI-wise subnetwork no hidden layer. However, as empirically investigated
in this work, this na?ve solution turns out to have considerably inferior detection accuracy that does
not match the network?s superior classification accuracy. To remedy this issue, in the ResNet paper
[10] the RoI pooling layer of the Faster R-CNN detector [19] is unnaturally inserted between two
sets of convolutional layers ? this creates a deeper RoI-wise subnetwork that improves accuracy, at
the cost of lower speed due to the unshared per-RoI computation.
We argue that the aforementioned unnatural design is caused by a dilemma of increasing translation
invariance for image classification vs. respecting translation variance for object detection. On one
hand, the image-level classification task favors translation invariance ? shift of an object inside an
image should be indiscriminative. Thus, deep (fully) convolutional architectures that are as translation?
2

This work was done when Yi Li was an intern at Microsoft Research.
Only the last layer is fully-connected, which is removed and replaced when fine-tuning for object detection.

30th Conference on Neural Information Processing Systems (NIPS 2016), Barcelona, Spain.

top-left top-center

?...

bottom-right

k
2

k (C+1)-d
conv

conv

vote

RoI
pool

image

softmax

C+1

k

feature
maps
C+1
2

k (C+1)

C+1

position-sensitive
score maps

Figure 1: Key idea of R-FCN for object detection. In this illustration, there are k ? k = 3 ? 3
position-sensitive score maps generated by a fully convolutional network. For each of the k ? k bins
in an RoI, pooling is only performed on one of the k 2 maps (marked by different colors).
Table 1: Methodologies of region-based detectors using ResNet-101 [10].
depth of shared convolutional subnetwork
depth of RoI-wise subnetwork

R-CNN [8]

Faster R-CNN [20, 10]

R-FCN [ours]

0
101

91
10

101
0

invariant as possible are preferable as evidenced by the leading results on ImageNet classification
[10, 25, 27]. On the other hand, the object detection task needs localization representations that are
translation-variant to an extent. For example, translation of an object inside a candidate box should
produce meaningful responses for describing how good the candidate box overlaps the object. We
hypothesize that deeper convolutional layers in an image classification network are less sensitive
to translation. To address this dilemma, the ResNet paper?s detection pipeline [10] inserts the RoI
pooling layer into convolutions ? this region-specific operation breaks down translation invariance,
and the post-RoI convolutional layers are no longer translation-invariant when evaluated across
different regions. However, this design sacrifices training and testing efficiency since it introduces a
considerable number of region-wise layers (Table 1).
In this paper, we develop a framework called Region-based Fully Convolutional Network (R-FCN)
for object detection. Our network consists of shared, fully convolutional architectures as is the case of
FCN [16]. To incorporate translation variance into FCN, we construct a set of position-sensitive score
maps by using a bank of specialized convolutional layers as the FCN output. Each of these score
maps encodes the position information with respect to a relative spatial position (e.g., ?to the left of
an object?). On top of this FCN, we append a position-sensitive RoI pooling layer that shepherds
information from these score maps, with no weight (convolutional/fc) layers following. The entire
architecture is learned end-to-end. All learnable layers are convolutional and shared on the entire
image, yet encode spatial information required for object detection. Figure 1 illustrates the key idea
and Table 1 compares the methodologies among region-based detectors.
Using the 101-layer Residual Net (ResNet-101) [10] as the backbone, our R-FCN yields competitive
results of 83.6% mAP on the PASCAL VOC 2007 set and 82.0% the 2012 set. Meanwhile, our results
are achieved at a test-time speed of 170ms per image using ResNet-101, which is 2.5? to 20? faster
than the Faster R-CNN + ResNet-101 counterpart in [10]. These experiments demonstrate that our
method manages to address the dilemma between invariance/variance on translation, and fully convolutional image-level classifiers such as ResNets can be effectively converted to fully convolutional object
detectors. Code is made publicly available at: https://github.com/daijifeng001/r-fcn.

2

Our approach

Overview. Following R-CNN [8], we adopt the popular two-stage object detection strategy [8, 9, 6,
7, 19, 1, 23] that consists of: (i) region proposal, and (ii) region classification. Although methods that
do not rely on region proposal do exist (e.g., [18, 15]), region-based systems still possess leading
accuracy on several benchmarks [5, 14, 21]. We extract candidate regions by the Region Proposal
2

ZWE
RoIs
conv

????Z?/

conv

conv

RoI
vote
pool

feature
maps

Figure 2: Overall architecture of R-FCN. A Region Proposal Network (RPN) [19] proposes candidate
RoIs, which are then applied on the score maps. All learnable weight layers are convolutional and are
computed on the entire image; the per-RoI computational cost is negligible.
Network (RPN) [19], which is a fully convolutional architecture in itself. Following [19], we share
the features between RPN and R-FCN. Figure 2 shows an overview of the system.
Given the proposal regions (RoIs), the R-FCN architecture is designed to classify the RoIs into object
categories and background. In R-FCN, all learnable weight layers are convolutional and are computed
on the entire image. The last convolutional layer produces a bank of k 2 position-sensitive score
maps for each category, and thus has a k 2 (C + 1)-channel output layer with C object categories (+1
for background). The bank of k 2 score maps correspond to a k ? k spatial grid describing relative
positions. For example, with k ? k = 3 ? 3, the 9 score maps encode the cases of {top-left, top-center,
top-right, ..., bottom-right} of an object category.
R-FCN ends with a position-sensitive RoI pooling layer. This layer aggregates the outputs of the
last convolutional layer and generates scores for each RoI. Unlike [9, 7], our position-sensitive RoI
layer conducts selective pooling, and each of the k ? k bin aggregates responses from only one score
map out of the bank of k ? k score maps. With end-to-end training, this RoI layer shepherds the last
convolutional layer to learn specialized position-sensitive score maps. Figure 1 illustrates this idea.
Figure 3 and 4 visualize an example. The details are introduced as follows.
Backbone architecture. The incarnation of R-FCN in this paper is based on ResNet-101 [10],
though other networks [11, 24] are applicable. ResNet-101 has 100 convolutional layers followed by
global average pooling and a 1000-class fc layer. We remove the average pooling layer and the fc
layer and only use the convolutional layers to compute feature maps. We use the ResNet-101 released
by the authors of [10], pre-trained on ImageNet [21]. The last convolutional block in ResNet-101 is
2048-d, and we attach a randomly initialized 1024-d 1?1 convolutional layer for reducing dimension
(to be precise, this increases the depth in Table 1 by 1). Then we apply the k 2 (C + 1)-channel
convolutional layer to generate score maps, as introduced next.
Position-sensitive score maps & Position-sensitive RoI pooling. To explicitly encode position
information into each RoI, we divide each RoI rectangle into k ? k bins by a regular grid. For an RoI
h
rectangle of a size w ? h, a bin is of a size ? w
k ? k [9, 7]. In our method, the last convolutional layer
2
is constructed to produce k score maps for each category. Inside the (i, j)-th bin (0 ? i, j ? k ? 1),
we define a position-sensitive RoI pooling operation that pools only over the (i, j)-th score map:
X
rc (i, j | ?) =
zi,j,c (x + x0 , y + y0 | ?)/n.
(1)
(x,y)?bin(i,j)

Here rc (i, j) is the pooled response in the (i, j)-th bin for the c-th category, zi,j,c is one score map
out of the k 2 (C + 1) score maps, (x0 , y0 ) denotes the top-left corner of an RoI, n is the number
of pixels in the bin, and ? denotes all learnable parameters of the network. The (i, j)-th bin spans
w
h
h
bi w
k c ? x < d(i + 1) k e and bj k c ? y < d(j + 1) k e. The operation of Eqn.(1) is illustrated in
Figure 1, where a color represents a pair of (i, j). Eqn.(1) performs average pooling (as we use
throughout this paper), but max pooling can be conducted as well.
3

The k 2 position-sensitive scores then vote on the RoI. In this paper we simply
P vote by averaging the
scores, producing a (C + 1)-dimensional vector for each RoI: rc (?) = i,j rc (i, j | ?). Then we
PC
compute the softmax responses across categories: sc (?) = erc (?) / c0 =0 erc0 (?) . They are used for
evaluating the cross-entropy loss during training and for ranking the RoIs during inference.
We further address bounding box regression [8, 7] in a similar way. Aside from the above k 2 (C +1)-d
convolutional layer, we append a sibling 4k 2 -d convolutional layer for bounding box regression. The
position-sensitive RoI pooling is performed on this bank of 4k 2 maps, producing a 4k 2 -d vector for
each RoI. Then it is aggregated into a 4-d vector by average voting. This 4-d vector parameterizes a
bounding box as t = (tx , ty , tw , th ) following the parameterization in [7]. We note that we perform
class-agnostic bounding box regression for simplicity, but the class-specific counterpart (i.e., with a
4k 2 C-d output layer) is applicable.
The concept of position-sensitive score maps is partially inspired by [3] that develops FCNs for
instance-level semantic segmentation. We further introduce the position-sensitive RoI pooling layer
that shepherds learning of the score maps for object detection. There is no learnable layer after
the RoI layer, enabling nearly cost-free region-wise computation and speeding up both training and
inference.
Training. With pre-computed region proposals, it is easy to end-to-end train the R-FCN architecture.
Following [7], our loss function defined on each RoI is the summation of the cross-entropy loss and
the box regression loss: L(s, tx,y,w,h ) = Lcls (sc? ) + ?[c? > 0]Lreg (t, t? ). Here c? is the RoI?s
ground-truth label (c? = 0 means background). Lcls (sc? ) = ? log(sc? ) is the cross-entropy loss
for classification, Lreg is the bounding box regression loss as defined in [7], and t? represents the
ground truth box. [c? > 0] is an indicator which equals to 1 if the argument is true and 0 otherwise.
We set the balance weight ? = 1 as in [7]. We define positive examples as the RoIs that have
intersection-over-union (IoU) overlap with a ground-truth box of at least 0.5, and negative otherwise.
It is easy for our method to adopt online hard example mining (OHEM) [23] during training. Our
negligible per-RoI computation enables nearly cost-free example mining. Assuming N proposals per
image, in the forward pass, we evaluate the loss of all N proposals. Then we sort all RoIs (positive
and negative) by loss and select B RoIs that have the highest loss. Backpropagation [12] is performed
based on the selected examples. Because our per-RoI computation is negligible, the forward time is
nearly not affected by N , in contrast to OHEM Fast R-CNN in [23] that may double training time.
We provide comprehensive timing statistics in Table 3 in the next section.
We use a weight decay of 0.0005 and a momentum of 0.9. By default we use single-scale training:
images are resized such that the scale (shorter side of image) is 600 pixels [7, 19]. Each GPU holds 1
image and selects B = 128 RoIs for backprop. We train the model with 8 GPUs (so the effective
mini-batch size is 8?). We fine-tune R-FCN using a learning rate of 0.001 for 20k mini-batches and
0.0001 for 10k mini-batches on VOC. To have R-FCN share features with RPN (Figure 2), we adopt
the 4-step alternating training3 in [19], alternating between training RPN and training R-FCN.
Inference. As illustrated in Figure 2, the feature maps shared between RPN and R-FCN are computed
(on an image with a single scale of 600). Then the RPN part proposes RoIs, on which the R-FCN
part evaluates category-wise scores and regresses bounding boxes. During inference we evaluate 300
RoIs as in [19] for fair comparisons. The results are post-processed by non-maximum suppression
(NMS) using a threshold of 0.3 IoU [8], as standard practice.
? trous and stride. Our fully convolutional architecture enjoys the benefits of the network modifications that are widely used by FCNs for semantic segmentation [16, 2]. Particularly, we reduce
ResNet-101?s effective stride from 32 pixels to 16 pixels, increasing the score map resolution. All
layers before and on the conv4 stage [10] (stride=16) are unchanged; the stride=2 operations in the
first conv5 block is modified to have stride=1, and all convolutional filters on the conv5 stage are
modified by the ?hole algorithm? [16, 2] (?Algorithme ? trous? [17]) to compensate for the reduced
stride. For fair comparisons, the RPN is computed on top of the conv4 stage (that are shared with
R-FCN), as is the case in [10] with Faster R-CNN, so the RPN is not affected by the ? trous trick.
The following table shows the ablation results of R-FCN (k ? k = 7 ? 7, no hard example mining).
The ? trous trick improves mAP by 2.6 points.
3

Although joint training [19] is applicable, it is not straightforward to perform example mining jointly.

4

vote

image and RoI

yes

position-sensitive
RoI-pool

position-sensitive score maps

Figure 3: Visualization of R-FCN (k ? k = 3 ? 3) for the person category.

vote

image and RoI

no

position-sensitive
RoI-pool

position-sensitive score maps

Figure 4: Visualization when an RoI does not correctly overlap the object.

R-FCN with ResNet-101 on:

conv4, stride=16

conv5, stride=32

conv5, ? trous, stride=16

mAP (%) on VOC 07 test

72.5

74.0

76.6

Visualization. In Figure 3 and 4 we visualize the position-sensitive score maps learned by R-FCN
when k ? k = 3 ? 3. These specialized maps are expected to be strongly activated at a specific
relative position of an object. For example, the ?top-center-sensitive? score map exhibits high scores
roughly near the top-center position of an object. If a candidate box precisely overlaps with a true
object (Figure 3), most of the k 2 bins in the RoI are strongly activated, and their voting leads to a high
score. On the contrary, if a candidate box does not correctly overlaps with a true object (Figure 4),
some of the k 2 bins in the RoI are not activated, and the voting score is low.

3

Related Work

R-CNN [8] has demonstrated the effectiveness of using region proposals [28, 29] with deep networks.
R-CNN evaluates convolutional networks on cropped and warped regions, and computation is not
shared among regions (Table 1). SPPnet [9], Fast R-CNN [7], and Faster R-CNN [19] are ?semiconvolutional?, in which a convolutional subnetwork performs shared computation on the entire
image and another subnetwork evaluates individual regions.
There have been object detectors that can be thought of as ?fully convolutional? models. OverFeat [22]
detects objects by sliding multi-scale windows on the shared convolutional feature maps; similarly, in
Fast R-CNN [7] and [13], sliding windows that replace region proposals are investigated. In these
cases, one can recast a sliding window of a single scale as a single convolutional layer. The RPN
component in Faster R-CNN [19] is a fully convolutional detector that predicts bounding boxes with
respect to reference boxes (anchors) of multiple sizes. The original RPN is class-agnostic in [19], but
its class-specific counterpart is applicable (see also [15]) as we evaluate in the following.
5

Table 2: Comparisons among fully convolutional (or ?almost? fully convolutional) strategies using
ResNet-101. All competitors in this table use the ? trous trick. Hard example mining is not conducted.
method
na?ve Faster R-CNN

RoI output size (k ? k)

mAP on VOC 07 (%)

1?1
7?7

61.7
68.9

class-specific RPN

-

67.6

R-FCN (w/o position-sensitivity)

1?1

fail

R-FCN

3?3
7?7

75.5
76.6

Another family of object detectors resort to fully-connected (fc) layers for generating holistic object
detection results on an entire image, such as [26, 4, 18].

4
4.1

Experiments
Experiments on PASCAL VOC

We perform experiments on PASCAL VOC [5] that has 20 object categories. We train the models on
the union set of VOC 2007 trainval and VOC 2012 trainval (?07+12?) following [7], and evaluate on
VOC 2007 test set. Object detection accuracy is measured by mean Average Precision (mAP).
Comparisons with Other Fully Convolutional Strategies
Though fully convolutional detectors are available, experiments show that it is nontrivial for them to
achieve good accuracy. We investigate the following fully convolutional strategies (or ?almost? fully
convolutional strategies that have only one classifier fc layer per RoI), using ResNet-101:
Na?ve Faster R-CNN. As discussed in the introduction, one may use all convolutional layers in
ResNet-101 to compute the shared feature maps, and adopt RoI pooling after the last convolutional
layer (after conv5). An inexpensive 21-class fc layer is evaluated on each RoI (so this variant is
?almost? fully convolutional). The ? trous trick is used for fair comparisons.
Class-specific RPN. This RPN is trained following [19], except that the 2-class (object or not)
convolutional classifier layer is replaced with a 21-class convolutional classifier layer. For fair
comparisons, for this class-specific RPN we use ResNet-101?s conv5 layers with the ? trous trick.
R-FCN without position-sensitivity. By setting k = 1 we remove the position-sensitivity of the
R-FCN. This is equivalent to global pooling within each RoI.
Analysis. Table 2 shows the results. We note that the standard (not na?ve) Faster R-CNN in the ResNet
paper [10] achieves 76.4% mAP with ResNet-101 (see also Table 3), which inserts the RoI pooling
layer between conv4 and conv5 [10]. As a comparison, the na?ve Faster R-CNN (that applies RoI
pooling after conv5) has a drastically lower mAP of 68.9% (Table 2). This comparison empirically
justifies the importance of respecting spatial information by inserting RoI pooling between layers for
the Faster R-CNN system. Similar observations are reported in [20].
The class-specific RPN has an mAP of 67.6% (Table 2), about 9 points lower than the standard
Faster R-CNN?s 76.4%. This comparison is in line with the observations in [7, 13] ? in fact, the
class-specific RPN is similar to a special form of Fast R-CNN [7] that uses dense sliding windows as
proposals, which shows inferior results as reported in [7, 13].
On the other hand, our R-FCN system has significantly better accuracy (Table 2). Its mAP (76.6%) is
on par with the standard Faster R-CNN?s (76.4%, Table 3). These results indicate that our positionsensitive strategy manages to encode useful spatial information for locating objects, without using
any learnable layer after RoI pooling.
The importance of position-sensitivity is further demonstrated by setting k = 1, for which R-FCN is
unable to converge. In this degraded case, no spatial information can be explicitly captured within
an RoI. Moreover, we report that na?ve Faster R-CNN is able to converge if its RoI pooling output
resolution is 1 ? 1, but the mAP further drops by a large margin to 61.7% (Table 2).
6

Table 3: Comparisons between Faster R-CNN and R-FCN using ResNet-101. Timing is evaluated on
a single Nvidia K40 GPU. With OHEM, N RoIs per image are computed in the forward pass, and
128 samples are selected for backpropagation. 300 RoIs are used for testing following [19].
depth of per-RoI
subnetwork

training
w/ OHEM?

train time
(sec/img)

test time
(sec/img)

mAP (%) on VOC07

1.2
0.45

0.42
0.17

76.4
76.6

Faster R-CNN
R-FCN

10
0

Faster R-CNN
R-FCN

10
0

X(300 RoIs)
X(300 RoIs)

1.5
0.45

0.42
0.17

79.3
79.5

Faster R-CNN
R-FCN

10
0

X(2000 RoIs)
X(2000 RoIs)

2.9
0.46

0.42
0.17

N/A
79.3

Table 4: Comparisons on PASCAL VOC 2007 test set using ResNet-101. ?Faster R-CNN +++? [10]
uses iterative box regression, context, and multi-scale testing.
training data

mAP (%)

test time (sec/img)

Faster R-CNN [10]
Faster R-CNN +++ [10]

07+12
07+12+COCO

76.4
85.6

0.42
3.36

R-FCN
R-FCN multi-sc train
R-FCN multi-sc train

07+12
07+12
07+12+COCO

79.5
80.5
83.6

0.17
0.17
0.17

Table 5: Comparisons on PASCAL VOC 2012 test set using ResNet-101. ?07++12? [7] denotes the
union set of 07 trainval+test and 12 trainval. ? : http://host.robots.ox.ac.uk:8080/anonymous/44L5HI.html ? :
http://host.robots.ox.ac.uk:8080/anonymous/MVCM2L.html

training data

mAP (%)

test time (sec/img)

Faster R-CNN [10]
Faster R-CNN +++ [10]

07++12
07++12+COCO

73.8
83.8

0.42
3.36

R-FCN multi-sc train
R-FCN multi-sc train

07++12
07++12+COCO

77.6?
82.0?

0.17
0.17

Comparisons with Faster R-CNN Using ResNet-101
Next we compare with standard ?Faster R-CNN + ResNet-101? [10] which is the strongest competitor
and the top-performer on the PASCAL VOC, MS COCO, and ImageNet benchmarks. We use
k ? k = 7 ? 7 in the following. Table 3 shows the comparisons. Faster R-CNN evaluates a 10-layer
subnetwork for each region to achieve good accuracy, but R-FCN has negligible per-region cost. With
300 RoIs at test time, Faster R-CNN takes 0.42s per image, 2.5? slower than our R-FCN that takes
0.17s per image (on a K40 GPU; this number is 0.11s on a Titan X GPU). R-FCN also trains faster
than Faster R-CNN. Moreover, hard example mining [23] adds no cost to R-FCN training (Table 3).
It is feasible to train R-FCN when mining from 2000 RoIs, in which case Faster R-CNN is 6? slower
(2.9s vs. 0.46s). But experiments show that mining from a larger set of candidates (e.g., 2000) has no
benefit (Table 3). So we use 300 RoIs for both training and inference in other parts of this paper.
Table 4 shows more comparisons. Following the multi-scale training in [9], we resize the image in
each training iteration such that the scale is randomly sampled from {400,500,600,700,800} pixels. We
still test a single scale of 600 pixels, so add no test-time cost. The mAP is 80.5%. In addition, we
train our model on the MS COCO [14] trainval set and then fine-tune it on the PASCAL VOC set.
R-FCN achieves 83.6% mAP (Table 4), close to the ?Faster R-CNN +++? system in [10] that uses
ResNet-101 as well. We note that our competitive result is obtained at a test speed of 0.17 seconds per
image, 20? faster than Faster R-CNN +++ that takes 3.36 seconds as it further incorporates iterative
box regression, context, and multi-scale testing [10]. These comparisons are also observed on the
PASCAL VOC 2012 test set (Table 5).
On the Impact of Depth
The following table shows the R-FCN results using ResNets of different depth [10], as well as the
VGG-16 model [24]. For VGG-16 model, the fc layers (fc6, fc7) are turned into sliding convolutional
layers, and a 1 ? 1 convolutional layer is applied on top to generate the position-sensitive score
7

maps. R-FCN with VGG-16 achieves slightly lower than that of ResNet-50. Our detection accuracy
increases when the depth is increased from 50 to 101 in ResNet, but gets saturated with a depth of
152.
R-FCN
R-FCN multi-sc train

training data

test data

07+12
07+12

07
07

VGG-16

ResNet-50

ResNet-101

ResNet-152

75.6
76.5

77.0
78.7

79.5
80.5

79.6
80.4

On the Impact of Region Proposals
R-FCN can be easily applied with other region proposal methods, such as Selective Search (SS) [28]
and Edge Boxes (EB) [29]. The following table shows the results (using ResNet-101) with different
proposals. R-FCN performs competitively using SS or EB, showing the generality of our method.
R-FCN

4.2

training data

test data

07+12

07

RPN [19]

SS [28]

EB [29]

79.5

77.2

77.8

Experiments on MS COCO

Next we evaluate on the MS COCO dataset [14] that has 80 object categories. Our experiments
involve the 80k train set, 40k val set, and 20k test-dev set. We set the learning rate as 0.001 for 90k
iterations and 0.0001 for next 30k iterations, with an effective mini-batch size of 8. We extend the
alternating training [19] from 4-step to 5-step (i.e., stopping after one more RPN training step), which
slightly improves accuracy on this dataset when the features are shared; we also report that 2-step
training is sufficient to achieve comparably good accuracy but the features are not shared.
The results are in Table 6. Our single-scale trained R-FCN baseline has a val result of 48.9%/27.6%.
This is comparable to the Faster R-CNN baseline (48.4%/27.2%), but ours is 2.5? faster testing.
It is noteworthy that our method performs better on objects of small sizes (defined by [14]). Our
multi-scale trained (yet single-scale tested) R-FCN has a result of 49.1%/27.8% on the val set and
51.5%/29.2% on the test-dev set. Considering COCO?s wide range of object scales, we further
evaluate a multi-scale testing variant following [10], and use testing scales of {200,400,600,800,1000}.
The mAP is 53.2%/31.5%. This result is close to the 1st-place result (Faster R-CNN +++ with
ResNet-101, 55.7%/34.9%) in the MS COCO 2015 competition. Nevertheless, our method is simpler
and adds no bells and whistles such as context or iterative box regression that were used by [10], and
is faster for both training and testing.
Table 6: Comparisons on MS COCO dataset using ResNet-101. The COCO-style AP is evaluated @
IoU ? [0.5, 0.95]. AP@0.5 is the PASCAL-style AP evaluated @ IoU = 0.5.

5

training
data

test
data

AP@0.5

AP

AP
small

AP
medium

AP
large

test time
(sec/img)

Faster R-CNN [10]
R-FCN
R-FCN multi-sc train

train
train
train

val
val
val

48.4
48.9
49.1

27.2
27.6
27.8

6.6
8.9
8.8

28.6
30.5
30.8

45.0
42.0
42.2

0.42
0.17
0.17

Faster R-CNN +++ [10]
R-FCN
R-FCN multi-sc train
R-FCN multi-sc train, test

trainval
trainval
trainval
trainval

test-dev
test-dev
test-dev
test-dev

55.7
51.5
51.9
53.2

34.9
29.2
29.9
31.5

15.6
10.3
10.8
14.3

38.7
32.4
32.8
35.5

50.9
43.3
45.0
44.2

3.36
0.17
0.17
1.00

Conclusion and Future Work

We presented Region-based Fully Convolutional Networks, a simple but accurate and efficient
framework for object detection. Our system naturally adopts the state-of-the-art image classification
backbones, such as ResNets, that are by design fully convolutional. Our method achieves accuracy
competitive with the Faster R-CNN counterpart, but is much faster during both training and inference.
We intentionally keep the R-FCN system presented in the paper simple. There have been a series
of orthogonal extensions of FCNs that were developed for semantic segmentation (e.g., see [2]), as
well as extensions of region-based methods for object detection (e.g., see [10, 1, 23]). We expect our
system will easily enjoy the benefits of the progress in the field.
8

References
[1] S. Bell, C. L. Zitnick, K. Bala, and R. Girshick. Inside-outside net: Detecting objects in context with skip
pooling and recurrent neural networks. In CVPR, 2016.
[2] L.-C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille. Semantic image segmentation with
deep convolutional nets and fully connected crfs. In ICLR, 2015.
[3] J. Dai, K. He, Y. Li, S. Ren, and J. Sun. Instance-sensitive fully convolutional networks. arXiv:1603.08678,
2016.
[4] D. Erhan, C. Szegedy, A. Toshev, and D. Anguelov. Scalable object detection using deep neural networks.
In CVPR, 2014.
[5] M. Everingham, L. Van Gool, C. K. Williams, J. Winn, and A. Zisserman. The PASCAL Visual Object
Classes (VOC) Challenge. IJCV, 2010.
[6] S. Gidaris and N. Komodakis. Object detection via a multi-region & semantic segmentation-aware cnn
model. In ICCV, 2015.
[7] R. Girshick. Fast R-CNN. In ICCV, 2015.
[8] R. Girshick, J. Donahue, T. Darrell, and J. Malik. Rich feature hierarchies for accurate object detection
and semantic segmentation. In CVPR, 2014.
[9] K. He, X. Zhang, S. Ren, and J. Sun. Spatial pyramid pooling in deep convolutional networks for visual
recognition. In ECCV. 2014.
[10] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016.
[11] A. Krizhevsky, I. Sutskever, and G. Hinton. Imagenet classification with deep convolutional neural
networks. In NIPS, 2012.
[12] Y. LeCun, B. Boser, J. S. Denker, D. Henderson, R. E. Howard, W. Hubbard, and L. D. Jackel. Backpropagation applied to handwritten zip code recognition. Neural computation, 1989.
[13] K. Lenc and A. Vedaldi. R-CNN minus R. In BMVC, 2015.
[14] T.-Y. Lin, M. Maire, S. Belongie, J. Hays, P. Perona, D. Ramanan, P. Doll?r, and C. L. Zitnick. Microsoft
COCO: Common objects in context. In ECCV, 2014.
[15] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, and S. Reed. SSD: Single shot multibox detector.
arXiv:1512.02325v2, 2015.
[16] J. Long, E. Shelhamer, and T. Darrell. Fully convolutional networks for semantic segmentation. In CVPR,
2015.
[17] S. Mallat. A wavelet tour of signal processing. Academic press, 1999.
[18] J. Redmon, S. Divvala, R. Girshick, and A. Farhadi. You only look once: Unified, real-time object detection.
In CVPR, 2016.
[19] S. Ren, K. He, R. Girshick, and J. Sun. Faster R-CNN: Towards real-time object detection with region
proposal networks. In NIPS, 2015.
[20] S. Ren, K. He, R. Girshick, X. Zhang, and J. Sun. Object detection networks on convolutional feature
maps. arXiv:1504.06066, 2015.
[21] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla,
M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. IJCV,
2015.
[22] P. Sermanet, D. Eigen, X. Zhang, M. Mathieu, R. Fergus, and Y. LeCun. Overfeat: Integrated recognition,
localization and detection using convolutional networks. In ICLR, 2014.
[23] A. Shrivastava, A. Gupta, and R. Girshick. Training region-based object detectors with online hard example
mining. In CVPR, 2016.
[24] K. Simonyan and A. Zisserman. Very deep convolutional networks for large-scale image recognition. In
ICLR, 2015.
[25] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, and A. Rabinovich. Going deeper
with convolutions. In CVPR, 2015.
[26] C. Szegedy, A. Toshev, and D. Erhan. Deep neural networks for object detection. In NIPS, 2013.
[27] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the inception architecture for
computer vision. In CVPR, 2016.
[28] J. R. Uijlings, K. E. van de Sande, T. Gevers, and A. W. Smeulders. Selective search for object recognition.
IJCV, 2013.
[29] C. L. Zitnick and P. Doll?r. Edge boxes: Locating object proposals from edges. In ECCV, 2014.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 4878-understanding-dropout.pdf

Understanding Dropout

Peter Sadowski
Department of Computer Science
University of California, Irvine
Irvine, CA 92697
pjsadows@ics.uci.edu

Pierre Baldi
Department of Computer Science
University of California, Irvine
Irvine, CA 92697
pfbaldi@uci.edu

Abstract
Dropout is a relatively new algorithm for training neural networks which relies
on stochastically ?dropping out? neurons during training in order to avoid the
co-adaptation of feature detectors. We introduce a general formalism for studying dropout on either units or connections, with arbitrary probability values, and
use it to analyze the averaging and regularizing properties of dropout in both linear and non-linear networks. For deep neural networks, the averaging properties
of dropout are characterized by three recursive equations, including the approximation of expectations by normalized weighted geometric means. We provide
estimates and bounds for these approximations and corroborate the results with
simulations. Among other results, we also show how dropout performs stochastic
gradient descent on a regularized error function.

1

Introduction

Dropout is an algorithm for training neural networks that was described at NIPS 2012 [7]. In its
most simple form, during training, at each example presentation, feature detectors are deleted with
probability q = 1 ? p = 0.5 and the remaining weights are trained by backpropagation. All weights
are shared across all example presentations. During prediction, the weights are divided by two.
The main motivation behind the algorithm is to prevent the co-adaptation of feature detectors, or
overfitting, by forcing neurons to be robust and rely on population behavior, rather than on the
activity of other specific units. In [7], dropout is reported to achieve state-of-the-art performance on
several benchmark datasets. It is also noted that for a single logistic unit dropout performs a kind of
?geometric averaging? over the ensemble of possible subnetworks, and conjectured that something
similar may occur also in multilayer networks leading to the view that dropout may be an economical
approximation to training and using a very large ensemble of networks.
In spite of the impressive results that have been reported, little is known about dropout from a
theoretical standpoint, in particular about its averaging, regularization, and convergence properties.
Likewise little is known about the importance of using q = 0.5, whether different values of q can
be used including different values for different layers or different units, and whether dropout can be
applied to the connections rather than the units. Here we address these questions.

2

Dropout in Linear Networks

It is instructive to first look at some of the properties of dropout in linear networks, since these can
be studied exactly in the most general setting of a multilayer feedforward network described by an
underlying acyclic graph. The activity in unit i of layer h can be expressed as:
Sih (I) =

XX
l<h

hl l
wij
Sj

j

1

with Sj0 = Ij

(1)

where the variables w denote the weights and I the input vector. Dropout applied to the units can be
expressed in the form
Sih =

XX
l<h

hl l l
wij
?j Sj

with

Sj0 = Ij

(2)

j

where ?jl is a gating 0-1 Bernoulli variable, with P (?jl = 1) = plj . Throughout this paper we assume
that the variables ?jl are independent of each other, independent of the weights, and independent of
the activity of the units. Similarly, dropout applied to the connections leads to the random variables
Sih =

XX
l<h

hl hl l
?ij
wij Sj

with

Sj0 = Ij

(3)

j

For brevity in the rest of this paper, we focus exclusively on dropout applied to the units, but all the
results remain true for the case of dropout applied to the connections with minor adjustments.
For a fixed input vector, the expectation of the activity of all the units, taken over all possible realizations of the gating variables hence all possible subnetworks, is given by:
E(Sih ) =

XX
l<h

hl l
wij
pj E(Sjl )

for h > 0

(4)

j

with E(Sj0 ) = Ij in the input layer. In short, the ensemble average can easily be computed by
hl
hl l
feedforward propagation in the original network, simply replacing the weights wij
by wij
pj .

3
3.1

Dropout in Neural Networks
Dropout in Shallow Neural Networks

Pn
Consider first a single logistic unit with n inputs O = ?(S) = 1/(1 + ce??S ) and S = 1 wj Ij .
To achieve the greatest level of generality, we assume that the unit produces different outputs
OP
1 , . . . , Om , corresponding to different sums S1 . . . , Sm with different probabilities P1 , . . . , Pm
( Pm = 1). In the most relevant case, these outputs and these sums are associated with the
m = 2n possible subnetworks of the unit. The probabilities P1 , . . . , Pm could be generated, for
instance, by using Bernoulli gating variables, although this isP
not necessary for this derivation. It is
useful to define the following four quantities: the mean E =
Pi Oi ; the mean of the complements
P
Q
E0 =
Pi (1 ? Oi ) = 1 ? E; the weighted geometric
mean
(W GM ) G = i OiPi ; and the
Q
weighted geometric mean of the complements G0 = i (1 ? Oi )Pi . We also define the normalized
weighted geometric mean N W GM = G/(G + G0 ). We can now prove the key averaging theorem
for logistic functions:
1
= ?(E(S))
1 + ce??E(S)

(5)

1
1
Q
Q
=
(1?Oi )Pi
(1??(Si ))Pi
1 + Q Pi
1 + Q ?(S )Pi

(6)

N W GM (O1 , . . . , Om ) =
To prove this result, we write
N W GM (O1 , . . . , Om ) =

Oi

i

??x

The logistic function satisfies the identity [1 ? ?(x)]/?(x) = ce

and thus

1
1
P
Q ??S P =
N W GM (O1 , . . . , Om ) =
= ?(E(S))
(7)
i
i
??
Pi Si
1 + [ce
]
1 + ce
Thus in the case of Bernoulli gating variables, we can compute the N WP
GM over all possible
n
dropout configurations by simple forward propagation by: N W GM = ?( 1 wj pj Ij ). A similar
result is true also for normalized exponential transfer functions. Finally, one can also show that
the only class of functions f that satisfy N W GM (f ) = f (E) are the constant functions and the
logistic functions [1].
2

3.2

Dropout in Deep Neural Networks

We can now deal with the most interesting case of deep feedforward networks of sigmoidal units 1 ,
described by a set of equations of the form
Oih = ?(Sih ) = ?(

XX

hl l
wij
Oj )

with

Oj0 = Ij

(8)

j

l<h

where Oih is the output of unit i in layer h. Dropout on the units can be described by
Oih = ?(Sih ) = ?(

XX
l<h

hl l l
wij
?j Oj )

with Oj0 = Ij

(9)

j

using the Bernoulli selector variables ?jl . For each sigmoidal unit
N W GM (Oih ) = Q

h P (N )
N (Oi )
Q
h
P
(N
)
+ N (1 ?
N (Oi )

Q

Oih )P (N )

(10)

where N ranges over all possible subnetworks. Assume for now that the N W GM provides a
good approximation to the expectation (this point will be analyzed in the next section). Then the
averaging properties of dropout are described by the following three recursive equations. First the
approximation of means by NWGMs:
E(Oih ) ? N W GM (Oih )

(11)

Second, using the result of the previous section, the propagation of expectation symbols:


N W GM (Oih ) = ?ih E(Sih )

(12)

And third, using the linearity of the expectation with respect to sums, and to products of independent
random variables:
E(Sih ) =

XX
l<h

hl l
wij
pj E(Ojl )

(13)

j

Equations 11, 12, and 13 are the fundamental equations explaining the averaging properties of the
dropout procedure. The only approximation is of course Equation 11 which is analyzed in the next
section. If the network contains linear units, then Equation 11 is not necessary for those units and
their average can be computed exactly. In the case of regression with linear units in the top layers,
this allows one to shave off one layer of approximations. The same is true in binary classification
by requiring the output layer to compute directly the N W GM of the ensemble rather than the
expectation. It can be shown that for any error function that is convex up (?), the error of the mean,
weighted geometric mean, and normalized weighted geometric mean of an ensemble is always less
than the expected error of the models [1].
Equation 11 is exact if and only if the numbers Oih are identical over all possible subnetworks N .
h
Thus it is useful to
 measure
 the consistency C(Oi , I) of neuron i in layer h for input I by using
the variance V ar Oih (I) taken over all subnetworks N and their distribution when the input I is
fixed. The larger the variance is, the less consistent the neuron is, and the worse we can expect
the approximation in Equation 11 to be. Note that for a random variable O in [0,1] the variance
cannot exceed 1/4 anyway. This is because V ar(O) = E(O2 ) ? (E(O))2 ? E(O) ? (E(O))2 =
E(O)(1 ? E(O)) ? 1/4. This measure can also be averaged over a training set or a test set.
1
Given the results of the previous sections, the network can also include linear units or normalized exponential units.

3

4

The Dropout Approximation

Given a set of numbers O1 , . . . , Om between 0 and 1, with probabilities P1 , . . . , PM (corresponding
to the outputs of a sigmoidal neuron for a fixed input and different subnetworks), we are primarily
interested in the approximation of E by N W GM . The N W GM provides a good approximation
because we show below that to a first order of approximation: E ? N W GM and E ? G. Furthermore, there are formulae in the literature for bounding the error E ? G in terms of the consistency
(e.g. the Cartwright and Field inequality [6]). However, one can suspect that the N W GM provides
even a better approximation to E than the geometric mean. For instance, if the numbers Oi satisfy
0 < Oi ? 0.5 (consistently low), then
G
E
G
? 0 and therefore G ?
?E
(14)
G0
E
G + G0
This is proven by applying Jensen?s inequality to the function ln x ? ln(1 ? x) for x ? (0, 0.5]. It is
also known as the Ky Fan inequality [2, 8, 9].
To get even better results, one must consider a second order approximation. For this, we write
Oi = 0.5 + i with 0 ? |i | ? 0.5. Thus we have E(O) = 0.5 + E() and V ar(O) = V ar().
Using a Taylor expansion:
?
?
?  
X
X pi (pi ? 1)
X
1 Y X pi
1
G=
(2i )n = ?1 +
pi 2i +
(2i )2 +
4pi pj i j + R3 (i )?
2 i n=0 n
2
2
i
i
i<j
(15)
where R3 (i ) is the remainder and
R3 (i ) =

 
pi
(2i )3
3 (1 + ui )3?pi

(16)

where |ui | ? 2|i |. Expanding the product gives
X
X
1 X
1
G= +
pi i +(
i )2 ?
pi 2i +R3 () = +E()?V ar()+R3 () = E(O)?V ar(O)+R3 ()
2 i
2
i
(17)
By symmetry, we have
G0 =

Y
(1 ? Oi )pi = 1 ? E(O) ? V ar(O) + R3 ()

(18)

i

where R3 () is the higher order remainder. Neglecting the remainder and writing E = E(O) and
V = V ar(O) we have
G
E?V
G0
1?E?V
?
and
?
(19)
0
0
G+G
1 ? 2V
G+G
1 ? 2V
Thus, to a second order, the differences between the mean and the geometric mean and the normalized geometric means satisfy
E?G?V

and E ?

G
V (1 ? 2E)
?
0
G+G
1 ? 2V

(20)

and
G0
V (1 ? 2E)
?
(21)
0
G+G
1 ? 2V
Finally it is easy to check that the factor (1 ? 2E)/(1 ? 2V ) is always less or equal to 1. In addition
we always have V ? E(1 ? E), with equality achieved only for 0-1 Bernoulli variables. Thus
1 ? E ? G0 ? V

and

(1 ? E) ?

4

V |1 ? 2E|
E(1 ? E)|1 ? 2E|
G
|?
?
? 2E(1 ? E)|1 ? 2E|
(22)
G + G0
1 ? 2V
1 ? 2V
The first inequality is optimal in the sense that it is attained in the case of a Bernoulli variable
with expectation E and, intuitively, the second inequality shows that the approximation error is
always small, regardless of whether E is close to 0, 0.5, or 1. In short, the NWGM provides a
very good approximation to E, better than the geometric mean G. The property is always true to
a second order of approximation and it is exact when the activities are consistently low, or when
N W GM ? E, since the latter implies G ? N W GM ? E. Several additional properties of the
dropout approximation, including the extension to rectified linear units and other transfer functions,
are studied in [1].
|E ?

5

Dropout Dynamics

Dropout performs gradient descent on-line with respect to both the training examples and the ensemble of all possible subnetworks. As such, and with the appropriately decreasing learning rates,
it is almost surely convergent like other forms of stochastic gradient descent [11, 4, 5]. To further
understand the properties of dropout, it is again instructive to look at the properties of the gradient
in the linear case.
5.1

Single Linear Unit

In the case of a single linear unit, consider the two error functions EEN S and ED associated with
the ensemble of all possible subnetworks and the network with dropout. For a single input I, these
are defined by:

EEN S

n
X
1
1
2
= (t ? OEN S ) = (t ?
pi wi Ii )2
2
2
i=1

(23)

n
X
1
1
(t ? OD )2 = (t ?
?i wi Ii )2
2
2
i=1

(24)

ED =

We use a single training input I for notational simplicity, otherwise the errors of each training
example can be combined additively. The learning gradient is given by
?EEN S
?OEN S
= ?(t ? OEN S )
= ?(t ? OEN S )pi Ii
?wi
?wi
X
?ED
?OD
= ?(t ? OD )
= ?(t ? OD )?i Ii = ?t?i Ii + wi ?i2 Ii2 +
wj ?i ?j Ii Ij
?wi
?wi

(25)

(26)

j6=i

The dropout gradient is a random variable and we can take its expectation. A short calculation yields

E

?ED
?wi


=

?EEN S
?EEN S
+ wi pi (1 ? pi )Ii2
+ wi Ii2 V ar(?i )
?wi
?wi

(27)

Thus, remarkably, in this case the expectation of the gradient with dropout is the gradient of the
regularized ensemble error
n

E = EEN S +

1X 2 2
w I V ar(?i )
2 i=1 i i

(28)

The regularization term is the usual weight decay or Gaussian prior term based on the square of the
weights to prevent overfitting. Dropout provides immediately the magnitude of the regularization
term which is adaptively scaled by the inputs and by the variance of the dropout variables. Note that
pi = 0.5 is the value that provides the highest level of regularization.
5

5.2

Single Sigmoidal Unit

The previous result generalizes to a sigmoidal unit O = ?(S) = 1/(1 + ce??S ) trained to minimize
the relative entropy error E = ?(t log O + (1 ? t) log(1 ? O)). In this case,
?ED
?S
= ??(t ? O)
= ??(t ? O)?i Ii
(29)
?wi
?wi
The terms O and Ii are not independent but using a Taylor expansion with the N W GM approximation gives

?EEN S
?ED
?
+ ?? 0 (SEN S )wi Ii2 V ar(?i )
(30)
E
?wi
?wi
P
with SEN S = j wj pj Ij . Thus, as in the linear case, the expectation of the dropout gradient is approximately the gradient of the ensemble network regularized by weight decay terms with the proper
adaptive coefficients. A similar analysis, can be carried also for a set of normalized exponential
units and for deeper networks [1].


5.3

Learning Phases and Sparse Coding

During dropout learning, we can expect three learning phases: (1) At the beginning of learning, when
the weights are typically small and random, the total input to each unit is close to 0 for all the units
and the consistency is high: the output of the units remains roughly constant across subnetworks
(and equal to 0.5 with c = 1). (2) As learning progresses, activities tend to move towards 0 or 1
and the consistency decreases, i.e. for a given input the variance of the units across subnetworks
increases. (3) As the stochastic gradient learning procedure converges, the consistency of the units
converges to a stable value.
Finally, for simplicity, assume that dropout
is applied only in layer h where the units have an output
P
hl l l
of the form Oih = ?(Sih ) and Sih = l<h wij
?j Oj . For a fixed input, Ojl is a constant since dropout
is not applied to layer l. Thus
V ar(Sih ) =

X

hl 2
(wij
) (Ojl )2 plj (1 ? plj )

(31)

l<h

under the usual assumption that the selector variables ?jl are independent of each other. Thus
V ar(Sih ) depends on three factors. Everything else being equal, it is reduced by: (1) Small weights
which goes together with the regularizing effect of dropout; (2) Small activities, which shows that
dropout is not symmetric with respect to small or large activities. Overall, dropout tends to favor
small activities and thus sparse coding; and (3) Small (close to 0) or large (close to 1) values of the
dropout probabilities plj . Thus values plj = 0.5 maximize the regularization effect but may also lead
to slower convergence to the consistent state. Additional results and simulations are given in [1].

6

Simulation Results

We use Monte Carlo simulation to partially investigate the approximation framework embodied by
the three fundamental dropout equations 11, 12, and 13, the accuracy of the second-order approximation and bounds in Equations 20 and 22, and the dynamics of dropout learning. We experiment
with an MNIST classifier of four hidden layers (784-1200-1200-1200-1200-10) that replicates the
results in [7] using the Pylearn2 and Theano software libraries[12, 3]. The network is trained with
a dropout probability of 0.8 in the input, and 0.5 in the four hidden layers. For fixed weights and
a fixed input, 10,000 Monte Carlo simulations are used to estimate the distribution of activity O
in each neuron. Let O? be the activation under the deterministic setting with the weights scaled
appropriately.
The left column of Figure 1 confirms empirically that the second-order approximation in Equation
20 and the bound in Equation 22 are accurate. The right column of Figure 1 shows the difference between the true ensemble average E(O) and the prediction-time neuron activity O? . This difference
grows very slowly in the higher layers, and only for active neurons.
6

Figure 1: Left: The difference E(O) ? N W GM (O), it?s second-order approximation in Equation
20, and the bound from Equation 22, plotted for four hidden layers and a typical fixed input. Right:
The difference between the true ensemble average E(O) and the final neuron prediction O? .
Next, we examine the neuron consistency during dropout training. Figure 2a shows the three phases
of learning for a typical neuron. In Figure 2b, we observe that the consistency does not decline in
higher layers of the network.
One clue into how this happens is the distribution of neuron activity. As noted in [10] and section 5
above, dropout training results in sparse activity in the hidden layers (Figure 3). This increases the
consistency of neurons in the next layer.

7

(a) The three phases of learning. For a particular input, a typical active neuron (red) starts out
with low variance, experiences a large increase in
variance during learning, and eventually settles to
some steady constant value. In contrast, a typical
inactive neuron (blue) quickly learns to stay silent.
Shown are the mean with 5% and 95% percentiles.

(b) Consistency does not noticeably decline in the upper layers. Shown here are the mean Std(O) for active
neurons (0.1 < O after training) in each layer, along
with the 5% and 95% percentiles.

Figure 2

Figure 3: In every hidden layer of a dropout trained network, the distribution of neuron activations
O? is sparse and not symmetric. These histograms were totalled over a set of 100 random inputs.

8

References
[1] P. Baldi and P. Sadowski. The Dropout Learning Algorithm. Artificial Intelligence, 2014. In
press.
[2] E. F. Beckenbach and R. Bellman. Inequalities. Springer-Verlag Berlin, 1965.
[3] J. Bergstra, O. Breuleux, F. Bastien, P. Lamblin, R. Pascanu, G. Desjardins, J. Turian,
D. Warde-Farley, and Y. Bengio. Theano: a CPU and GPU math expression compiler. In
Proceedings of the Python for Scientific Computing Conference (SciPy), Austin, TX, June
2010. Oral Presentation.
[4] L. Bottou. Online algorithms and stochastic approximations. In D. Saad, editor, Online Learning and Neural Networks. Cambridge University Press, Cambridge, UK, 1998.
[5] L. Bottou. Stochastic learning. In O. Bousquet and U. von Luxburg, editors, Advanced Lectures
on Machine Learning, Lecture Notes in Artificial Intelligence, LNAI 3176, pages 146?168.
Springer Verlag, Berlin, 2004.
[6] D. Cartwright and M. Field. A refinement of the arithmetic mean-geometric mean inequality.
Proceedings of the American Mathematical Society, pages 36?38, 1978.
[7] G. Hinton, N. Srivastava, A. Krizhevsky, I. Sutskever, and R. R. Salakhutdinov. Improving neural networks by preventing co-adaptation of feature detectors. http://arxiv.org/abs/1207.0580,
2012.
[8] E. Neuman and J. S?andor. On the Ky Fan inequality and related inequalities i. MATHEMATICAL INEQUALITIES AND APPLICATIONS, 5:49?56, 2002.
[9] E. Neuman and J. Sandor. On the Ky Fan inequality and related inequalities ii. Bulletin of the
Australian Mathematical Society, 72(1):87?108, 2005.
[10] S. Nitish. Improving Neural Networks with Dropout. PhD thesis, University of Toronto,
Toronto, Canada, 2013.
[11] H. Robbins and D. Siegmund. A convergence theorem for non negative almost supermartingales and some applications. Optimizing methods in statistics, pages 233?257, 1971.
[12] D. Warde-Farley, I. Goodfellow, P. Lamblin, G. Desjardins, F. Bastien, and Y. Bengio.
pylearn2. 2011. http://deeplearning.net/software/pylearn2.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 303-art2bp-architecture-for-adaptive-estimation-of-dynamic-processes.pdf

ART2/BP architecture for adaptive estimation of
dynamic processes

Einar S~rheim *
Department of Computer Science
UNIK, Kjeller
University of Oslo
N-2007 Norway

Abstract

The goal has been to construct a supervised artificial neural network that
learns incrementally an unknown mapping. As a result a network consisting of a combination of ART2 and backpropagation is proposed and
is called an "ART2/BP" network. The ART2 network is used to build
and focus a supervised backpropagation network. The ART2/BP network
has the advantage of being able to dynamically expand itself in response
to input patterns containing new information. Simulation results show
that the ART2/BP network outperforms a classical maximum likelihood
method for the estimation of a discrete dynamic and nonlinear transfer
function.

1

INTRODUCTION

Most current neural network architectures such as backpropagation require a cyclic
presentation of the entire training set to converge. They are thus not very well suited
for adaptive estimation tasks where the training vectors arrive one by one, and where
the network may never see the same training vector twice. The ART2/BP network
system is an attempt to construct a network that works well on these problems.
Main features of our ART2/BP are:
? implements incremental supervised learning
? dynamically self-expanding
*e-mail address:einar@tellus.unik.nooreinars@ifi.uio.no

169

170

Sorheim
? learning of a novel training pattern does not wash away memory of previous
training patterns
? short convergence time for learning a new pattern

2

BACKGROUND

Adaptive estimation of nonlinear functions requires some basic features of the estimation algorithm.
1. Incremental learning
The input/output pairs arrive to the estimation machine one by one. By accumulating the input/output pairs into a training set and rerun the training
procedure at every arrival of a new input/output pair, one could use a conventional method. Obvious disadvantages would however be

? huge learning time required as the size of the training set increases .
? an upper limit, N, on the number of elements in the training set will
have to be set. The training set will then be a gliding horizon of the N
last input/output pairs, and information prior to the N last input/output
pairs will be lost.
2. Plasticity
Learning of a new input/output pair should not wash away the memory of
previously learned nonconflicting input/output pairs. With most existing feedforward supervised nets this is hard to accomplish, though some efforts have
been made (Otwell 90). Some networks, like the ART-family and RCN (Ryan
1988) are plastic but they are self-organizing, not supervised.

To summarize:
Need a supervised network that learns incrementally the mapping of an unknown
system and that can be used to predict future outputs. The system in question
maps analog vectors to analog vectors.

3

COMBINED ARCHITECTURE

In the proposed network architecture an ART2 network controls a BP network, see
Figure 1.
The BP-network consists of many relatively small subnetworks where the subnets
are specialized on one particular domain of the input space. ART2 controls how the
input space is divided among the subnets and the total amount of sub nets needed.
The ART2 network analyzes the input part of the input/output pairs as they arrive
....
to the system. For a given input pattern i:r, ART2 finds the category G:r which has
the closest resemblance to ~. If this resemblance is good enough, ~ is of category
G:r and the LTM-weights of G:r are updated. The BP-subnetwork BP:r, connected
to G:r, is as a consequence activatedt and relearning of BP:r is done. The learning
set consists of a "representative" set of the neighbouring subnets patterns and a
small number of the previous patterns belonging to category G:r. To summarize the

ART2IBP Architecture for Adaptive Estimation of Dynamic Processes
algorithm goes as follows:
1. Send input vector to ART2 network

2. ART2 classification.
3. If in learning mode adjust ART2 LTM weights of the winning node.
4. Send input to the back propagation network connected to the winning ART2
node.
5. If in learning mode:
? find a representative training set.
? do epoch learning on training set.
Otherwise
? compute output of the selected back propagation network.
6. Go to 1. for new input vector.
The ART2/BP neural network can be used for adaptive estimation of nonlinear
dynamic processes. The mapping to be estimated then is

yet + ot)
u(t)
yet)

=

l( u(t), yet?~

(1)

f ~m
f ~n

The input/output pairs will be i7J [u(t) , yet), yet + ot)], denote the input part of
i7J: i [u(t) , yet)] and the output part of (0: 0 yet + ot).

=

4

=

ART2 MODIFIED

ART2 was developed by Carpenter& Grossberg see (Carpenter 1987) and (Carpenter 1988). ART2 categorizes arbitrary sequences of analog input patterns, and the
categories can be of arbitrary coarseness. For a detailed description of ART2, see
(Carpenter 1987).

4.1

MODIFICATION

In the standard ART2-algorithm input vectors (patterns) are normalized. For this
application it is not desired to classify parallel vectors of different magnitude as
belonging to the same category. By adding an extra element to the input vector
where this element is simply
(2)
the new input vector becomes

-

From a scaled vector of i: i

-

(3)

= a :{ the original vector i could easily be found as :
(4)

171

172

Sorheim

and by using the augmented i as the input to ART2 instead of i one can at any
point in Fl( representation layer) and F2( categorization layer) generate the corresponding non-normalized vector. The F2 node competition is modified so that the
node having bottom-up LTM weights with the smallest distance (distance being the
euclidean norm) to the Fl layer pattern code wins the competition. The distance
d J of F2 node J is given by:

IIv -

v

zj

(5)

zjll

being the 12 - norm
Fl pattern code.
bottom - up LTM weights of F2 node J

Reset is done by calculating the distance d between the Fl layer pattern code V and
~

J :

d = IIv- ~I

(6)

and comparing it to a largest acceptable bound p. If d > p the winning node is
inhibited and a new node will be created. If d ~ p LTM-patterns of the winning
node J are modified (learning).

5

BACK PROPAGATION NETWORK

The backpropagation network used in this work is of the standard feedforward type,
see (Rumelhart 1986) . The number of hidden layers and nodes should be kept low
in the subnetworks, for the problems in our simulations we used 1 hidden layer with
2 nodes. As for training algorithms several different kinds have been tried:
? Standard back propagation (SBP)
? A modified back propagation (MBP) method similar to the one used in the
BPS simulator from George Mason University.
? Quickprop (Q).
? A quasi-Newton method (BFGS).
All of these except SBP show similar performance in my test cases.
The BP-networks performs as an interpolator in this algorithm and any good interpolation algorithm can be used instead of BP. Approximation theory gives several
interesting techniques for approximation/interpolation of multidimensional functions such as Radial Basis Functions and Hyper Basis Functions, for further detail
see (Poggio 90). These methods requires a representative training set where the
input part determines the location of centers in the input space. The ART2 alg<r
rithm can be used for determining these centers in an adaptive way and thus making
possible an incremental version of the approximation theory techniques. This idea
has not been tested yet, but is an interesting concept for further research.

ART2IBP Architecture for Adaptive Estimation of Dynamic Processes

6

LEARNING

Learning in ART2/BP is a two stage process. First the input patterns is sent to
the ART2 network for categorizing and learning. ART2 will then activate the
BP subnetwork that is a local expert on patterns of the same category as the
input pattern, and learning of this subnetwork will occur. A training set that is
representative for the domain of the input space has to be found. Let a small
number of the last categorized input/output pairs be allocated to its corresponding
subnet to provide a part of the training set. Denote such a set as LJOc, (C being
the category). Define the location ofF2 node J to be its bottom-up weights ;J. Let
the current input i~ define an origin, then find the F2 nodes closest to origin in each
n-ant of the input space. Call this set of nodes N~ and the set oflast input/output
pairs stored in these nodes N JO~. The training set is then chosen to be:
T~
N _IO~ U LJO~
Before training, the elements in T~ are scaled to increase accuracy and to accelerate
learning. BP-Iearning is then performed, the stopping criteria being a fixed error
term or a maximum number of iterations.

=

7

ESTIMATION

In estimation mode learning in the network is turned off. Given an input thenetwork
will produce an output that hopefully will be close to the output of the real system.
The ART2-network selects a winning node in the same way as described before but
now the reset assembly is not activated. Then the input is fed to the corresponding
BP subnetwork and its output is used as an estimate of the original functions output.
Because each subnetwork is scaled to cover the domain of the input space made up
by the complex hull Co(T~) of its training set T~, the entire ART2/BP network will
cover the complex hull C o(T) C ~n+m where:
T=
{set of all previous fs used to train the network}
Good estimation/prediction can thus be expected if i ( Co(T). This means that if
the input vector i lies in a domain of the input space that has not been previously
explored by the elements in the training set, the network will generalize poorly.

8

EXAMPLE

The ART2/BP network has been used to estimate a dynamic model of a tank filled
with liquid. The liquid level is sampled every 6t time interval and the ART2/BP
network is used to estimate the discrete dynamic nonlinear transfer function of the
liquid level as a function of inlet liquid flow and previous liquid level. That is, we
want to find a good estimate j(.,.) of:
y(t

+ 6t)
u(t)
y(t)

f( u(t), y(t?
inlet liquid flow at time t
liquid level at time t

(7)

173

174

Sorheim

o. 2
0.1 5

o. 1
0.0 5

',J

,

'\

.1

An

.~

r VS] '

j

-0.0 5

\

w'

~J

WH

I,~
II!

.~,

.A.

e-

~Yce:::::::::J

150

2100

250

=

I
300

,

-0. 1

black line: ARMA model estimation error (y(t + 6t) - YARMA(t + 6t))
grey line: ART2/BP estimation error (y(t + 6t) - YART2/BP(t + 6t?
Figure 1: Comparison of the estimation error of the ARMA model and the
ART2/BP network
To increase the nonlinearities of the transfer function, the area of the tank varies
with a step function of the liquid level. The BP subnetworks have 2 input nodes,
1 hidden layer with 2 neurons and a single neuron output layer. In the simulations
p
0.04 and the last three categorized input/output pairs are stored at every
subnetwork. As the input space is 2-dimensional giving 4 neighbouring nodes the
maximum size of the training set 7 input/output pairs. After a learning period of
1000 samples with random inlet flow, three test cases are run with the network in
estimation mode. The network had then formed about 140 categories. The same
set of simulation data is also run through an offline maximum likelihood method to
estimate a linear ARMA model of the plant, see (Ljung 1983). /

=

Figure 1 shows the simulation results of the three test cases where :
samples 1-100 : random input flow.
samples 101-200 : constant input flow at a low level.
samples 201-300 : constant input flow at a high level.
In Figure 1, the estimation errors of the two methods are compared. For the
first 100 samples with stochastic input flow, the estimation error variance of the

ART2IBP Architecture for Adaptive Estimation of Dynamic ftocesses
ART2/BP network is roughly a factor 10 less than that of the ARMA-model. The
performance of ART2/BP is also significantly better for the constant input flow
cases, here the ARMA model has an error of -- 0.02 while the ART2/BP-error is
- 0.002. The overall improvement in estimation error is a reduction of roughly 0.1
. Also keep in mind that ART2/BP is compared to an offline maximum likelihood
method while ART2/BP clearly is an online method. The online version of the
maximum likelihood would most probably have given a worse performance than the
offline version.

9

CONCLUSION/COMMENTS

The proposed ART2/BP neural network architecture offers some unique features
compared to backpropagation. It provides incremental learning and can be applied
to truly adaptive estimation tasks. In our example it also outperforms a classical
maximum likelihood method for the estimation of a discrete dynamic nonlinear
transfer function. Future work will be the investigation of ART2/BP's properties for
multistep-ahead prediction of dynamic nonlinear transfer functions, and embedding
ART2/BP in a neural adaptive controller.
Acknow ledgments

Special thanks to Steve Lehar at Boston University for providing me with his ART2
simulation program. It proved to be crucial for getting a quick start on ART2 and
understanding the concept.
References

Carpenter, G.A. & Grossberg, S. (1987). ART2: Self-organization of stable category recognition codes for analog input patterns. Applied Optics pp 4919-4930.
Carpenter, G.A. & Grossberg, S. (1988). The ART of adaptive pattern recognition
by a self-organizing neural network. Computer 21 pp 77-88.
Fahlman, S.E. (1988). Faster-Learning Variations on Back-Propagation: An Empirical Study. Proceedings of the 1988 Connectionist Models Summer School. Morgan
Kaufmann.
Ljung, L. &

S~derstr~m

(1983). Theory and practice of recursive identification.
The MIT press, Cambridge, MA.

Otwell, K. (1990). Incremental backpropagation learning from novelty-based orthogonalization. Proceedings IJNN90 .
Poggio, T., Girosi, F. (1990). Networks for Approximation and Learning. Proceedings of the IEEE,Vol. 78, No.9.
Rumelhart, D.E., Hinton, G.E., & Williams, R.J. (1986). Parallel Distributed
Processing: Explorations in the microstructure of Cognition, Vol. 1. The MIT
Press,Cambridge, MA.
Ryan, T. W. (1988). The resonance correlation network. Proceedings IJNN88.

175


<<----------------------------------------------------------------------------------------------------------------------------------------->>

title: 3957-penalized-principal-component-regression-on-graphs-for-analysis-of-subnetworks.pdf

Penalized Principal Component Regression on
Graphs for Analysis of Subnetworks

George Michailidis
Department of Statistics and EECS
University of Michigan
Ann Arbor, MI 48109
gmichail@umich.edu

Ali Shojaie
Department of Statistics
University of Michigan
Ann Arbor, MI 48109
shojaie@umich.edu

Abstract
Network models are widely used to capture interactions among component of
complex systems, such as social and biological. To understand their behavior, it
is often necessary to analyze functionally related components of the system, corresponding to subsystems. Therefore, the analysis of subnetworks may provide
additional insight into the behavior of the system, not evident from individual
components. We propose a novel approach for incorporating available network
information into the analysis of arbitrary subnetworks. The proposed method offers an efficient dimension reduction strategy using Laplacian eigenmaps with
Neumann boundary conditions, and provides a flexible inference framework for
analysis of subnetworks, based on a group-penalized principal component regression model on graphs. Asymptotic properties of the proposed inference method,
as well as the choice of the tuning parameter for control of the false positive rate
are discussed in high dimensional settings. The performance of the proposed
methodology is illustrated using simulated and real data examples from biology.

1

Introduction

Simultaneous analysis of groups of system components with similar functions, or subsystems, has
recently received considerable attention. This problem is of particular interest in high dimensional
biological applications, where changes in individual components may not reveal the underlying
biological phenomenon, whereas the combined effect of functionally related components could improve the efficiency and interpretability of results. This idea has motivated the method of gene set
enrichment analysis (GSEA), along with a number of related methods [1, 2]. The main premise
of this method is that by assessing the significance of sets rather than individual components (i.e.
genes), interactions among them can be preserved, and more efficient inference methods can be
developed. A different class of models (see e.g. [3, 4] and references therein) has focused on directly incorporating the network information in order to achieve better efficiency in assessing the
significance of individual components.
These ideas have been combined in [5, 6], by introducing a model for incorporating the regulatory
gene network, and developing an inference framework for analysis of subnetworks defined by biological pathways. In this frameworks, called NetGSA, a global model is introduced with parameters
1

for individual genes/proteins, and the parameters are then combined appropriately in order to assess
the significance of biological pathways. However, the main challenge in applying NetGSA in realworld biological applications is the extensive computational time. In addition, the total number of
parameters allowed in the model are limited by the available sample size n (see Section 5).
In this paper, we propose a dimension reduction technique for networks, based on Laplacian eigenmaps, with the goal of providing an optimal low-dimensional projection for the space of random
variables in each subnetwork. We then propose a general inference framework for analysis of subnetworks by reformulating the inference problem as a penalized principal regression problem on the
graph. In Section 2, we review the Laplacian eigenmaps and establish their connection to principal
component analysis (PCA) for random variables on a graph. Inference for significance of subnetworks is discussed in Section 3, where we introduce Laplacian eigenmaps with Neumann boundary
conditions and present the group-penalized principal component regression framework for analysis of arbitrary subnetworks. Results of applying the new methodology to simulated and real data
examples are presented in Section 4, and the results are summarized in Section 5.

2

Laplacian Eigenmaps

Consider p random variables Xi , i = 1, . . . , p (e.g. expression values of genes) defined on nodes of
an undirected (weighted) graph G = (V, E). Here V is the set of nodes of G and E ? V ?V its edge
set. Throughout this paper, we represent the edge set and the strength of associations among nodes
through the adjacency matrix of the graph A. Specifically, Ai j ? 0 and i and j are adjacent if the Ai j
(and hence A ji ) is non-zero. In this case we write i ? j. Finally, we denote the observed values of
the random variables by the n ? p data matrix X.
The subnetworks of interest are defined based on additional knowledge about their attributes and
functions. In biological applications, these subnetworks are defined by common biological function,
co-regulation or chromosomal location. The objective of the current paper is to develop dimension
reduction methods on networks, in order to assess the significance of a priori defined subnetworks
(e.g. biological pathways) with minimal information loss.
2.1

Graph Laplacian and Eigenmaps

Laplacian eigenmaps are defined using the eigenfunctions of the graph Laplacian, which is commonly used in spectral graph theory, computer science and image processing. Applications based
on Laplacian eigenmaps include image segmentation and the normalized cut algorithm of [7], spectral clustering [8, 9] and collaborative filtering [10].
The Laplacian matrix and its eigenvectors have also been used in biological applications. For example, in [11], the Laplacian matrix has been used to define a network-penalty for variable selection
on graphs, and the interpretation of Laplacian eigenmaps as a Fourier basis was exploited in [12] to
propose supervised and unsupervised classification methods.
Different definitions and representations have been proposed for the spectrum of a graph, and the
results may vary depending on the definition of the Laplacian matrix (see [13] for a review). Here,
we follow the notation in [13], and consider the normalized Laplacian matrix of the graph. To that
end, let D denote the diagonal degree matrix for A, i.e. Dii = ? j Ai j ? di , and define the Laplacian
matrix of the graph by L = D?1/2 (D ? A)D?1/2 , or alternatively
?
Ajj
?
j = i, d j 6= 0
? 1 ? dj
?
Ai j
Li j =
??
j?i
?
di d j
?
?
0
o.w.
2

It can be shown that [13] L is positive semidefinite with eigenvalues 0 = ?0 ? ?1 ? . . . ? ? p?1 ? 2.
Its eigenfunctions are known as the spectrum of G , and optimize the Rayleigh quotient
hg, L gi ?i? j ( f (i) ? f ( j))2
,
=
hg, gi
? j f ( j)2 d j

(1)

It can be seen from (1), that the 0-eigenvalue of L is g = D1/2 1, corresponding to the average
over the graph G . The first non-zero eigenvalue ?1 is the harmonic eigenfunction of L , which
corresponds to the Laplace-Beltrami operator on Reimannian manifolds, and is given by
? j?i ( f (i) ? f ( j))2
f ?D1
? j f ( j)2 d j

?1 = inf

More generally, denoting by Ck?1 the projection to the subspace of the first k ? 1 eigenfunctions,
?k =
2.2

? j?i ( f (i) ? f ( j))2
.
f ?DCk?1
? j f ( j)2 d j
inf

Principal Component Analysis on Graphs

Previous applications of the graph Laplacian and its spectrum often focus on the properties of the
graph; however, the connection to the probability distribution of the random variables on nodes of
the graph has not been strongly emphasized. In graphical models, the undirected graph G among
random variables corresponds naturally to a Markov random field [14]. The following result establishes the relationship between the Laplacian eigenmaps and the principal components of the
random variables defined on the nodes of the graph, in case of Gaussian observations.
Lemma 1. Let X = (X1 , . . . , X p ) be random variables defined on the nodes of graph G = (V, E)
and denote by L and L + the Laplacian matrix of G and its Moore-Penrose generalized inverse.
If X ? N(0, ?), then L and L + correspond to ? and ?, respectively (? ? ??1 ). In addition, let
?0 , . . . , ? p?1 denote the eigenfunctions corresponding to eigenvalues of L . Then ?0 , . . . , ? p?1 are
the principal components of X, with ?0 corresponding to the leading principal component.
Proof. For Gaussian random variables, the inverse covariance (or precision) matrix has the same
non-zero pattern as the adjacency matrix of the graph, i.e. for i 6= j, ?i j = 0 iff Ai j = 0. Moreover,
?ii = ?i?2 , where ?i2 is the partial variance of Xi (see e.g. [15]). However, using the conditional
autoregression (CAR) representation of Gaussian Markov random fields [16], we can write
E(Xi |X?i ) = ? ci j X j

(2)

j?i

where ?i ? {1 . . . p}\i and C = [ci j ] has the same non-zero pattern as the adjacency matrix of
the graph A, and amounts to a proper probability
 distribution for X. In 	particular, by Brook?s
Lemma [16] it follows from (2) that fX (x) ? exp ?1/2xT (0, T ?1 (I p ?C))x , where T = diag[?i2 ].
Therefore, ? = T ?1 (I p ?C) and hence (I p ?C) should be PD.
However, since L = I p ?D?1/2 AD?1/2 is PSD, we can set C = D?1/2 AD?1/2 ?? I for any ? > 0. In
other words, (I p ?C) = L + ? I p , which implies that L? ? L + ? I p = T ?, and hence L? ?1 = ?T ?1 .
Taking limit as ? ? 0, it follows that L and L + correspond to ? and ?, respectively.
The second part follows directly from the above connection between L? ?1 and ?. In particular,
suppose, without loss of generality, that ?i2 = 1. Then, it is easily seen that the principal components
of X are given by eigenfunctions of L? ?1 , which are in turn equal to the eigenfunctions of L? with
the ordering of the eigenvalues reversed. However, since eigenfunctions of L + ? I p and L are
equal, the principal components of X are obtained from eigenfunctions of L .
3

X1

?1

X2

?2

X3

Figure 1: Left: A simple subnetwork of interest, marked with the dotted circle. Right: Illustration
of the Neumann random walk, the dotted curve indicates the boundary of the subnetwork.
Remark 2. An alternative justification for the above result, for general probability distributions
defined on graphs, can be given by assuming that the graph represents ?similarities? among random
variables and using an optimal embedding of graph G in a lower dimensional Euclidean space1 .
In the case of one dimensional embedding, the goal is to find an embedding v = (v1 , . . . , v p )T that
preserves the distances among the nodes of the graph. The objective function of the embedding
problem is then given by Q = ?i, j (vi ? v j )2 Ai j , or alternatively Q = 2vT (D ? A)v [17]. Thus, the
optimal embedding is found by solving argminvT Dv=1 vT (D ? A)v. Setting u = D1/2 v, this is solved
by finding the eigenvector corresponding to the smallest eigenvalue of L .
Lemma 1 provides an efficient dimension reduction framework that summarizes the information in
the entire network into few feature vectors. Although the resulting dimension reduction method
can be used efficiently in classification (as in [12]), the eigenfunctions of G do not provide any
information about significance of arbitrary subnetworks, and therefore cannot be used to analyze
the changes in subnetworks. In the next section, we introduce a restricted version of Laplacian
eigenmaps, and discuss the problem of analysis of subnetworks.

3

Analysis of Subnetworks and PCR on Graph (GPCR)

In [5], the authors argue that to analyze the effect of subnetworks, the test statistic needs to represent
the pure effect of the subnetwork, without being influenced by external nodes, and propose an
inference procedure based on mixed linear models to achieve this goal. However, in order to achieve
dimension reduction, we need a method that only incorporates local information at the level of each
subnetwork, and possibly its neighbors (see the left panel of Figure 1).
Using the connection of the Laplace operator in Reimannian manifolds to heat flow (see e.g. [17]),
the problem of analysis of arbitrary subnetworks can be reformulated as a heat equation with boundary conditions. It then follows that in order to assess the ?effect? of each subnetwork, the appropriate
boundary conditions should block the flow of heat at the boundary of the set. This corresponds to
insulating the boundary, also known as the Neumann boundary condition. For the general heat
equation ?(v, x), this boundary condition is given by ?? ?v (x) = 0 at each boundary point x, where v is
the normal direction orthogonal to the tangent hyperplane at x.
The eigenvalues of subgraphs with boundary conditions are studied in [13]. In particular, let S
be any (connected) subnetwork of G , and denote by ? S the boundary of S in G . The Neumann
boundary condition states that for every x ? ? S, ?y:{x,y}?? S ( f (x) ? f (y)) = 0.
The Neumann eigenfunctions of S are then the optimizers of the restricted Rayleigh quotient
?S,i = inf sup

f g?Ci?1

?{t,u}?S?? S ( f (t) ? f (u))2
2
?t?S ( f (t) ? g(t)) dt

where Ci?1 is the projection to the space of previous eigenfunctions.
1 For

unweighted graphs, this justification was given by [17], using the unnormlized Laplacian matrix.

4

In [13], a connection between the Neumann boundary conditions and a reflected random walk on the
graph is established, and it is shown that the Neumann eigenvectors can be alternatively calculated
from the eigenvectors of the transition probability matrix of this reflected random walk, also known
as the Neumann random walk (see [13] for additional details). Here, we generalize this idea to
weighted adjacency matrices.
Let P? and P denote the transition probability matrix of the reflected random walk, and the original
random walk defined on G , respectively. Noting that P = D?1 A, we can extend the results in [13]
as follows. For the general case of weighted graphs, define the transition probability matrix of the
reflected random walk by
?
j ? i, i, j ? S
? Pi j
A A
Pi j + dik d 0k j j ? k ? i, k ?
/S
P?i j =
(3)
i k
?
0
o.w.
where dk0 = ?i?k,i?S Aki denotes the degree of the node k in S. Then, the Neumann eigenvalues are
?
given by ?i = 1 ? ?i , where ?i is the ith eigenvalue of P.
Remark 3. The connection with the Neumann random walk also sheds light into the effect of the
proposed boundary condition on the joint probability distribution of the random variables on the
graph. To illustrate this, consider the simple graph in the right panel of Figure 1. For the moment,
suppose that the random variables X1 , X2 , X3 are Gaussian, and the edges from X1 and X2 to X3 are
directed. As discussed in [5], the joint probability distribution of the random variables on the graph
is then given by linear structural equation models:
X1
X2
X3

= ?1
= ?2
= ?1 X1 + ?1 X2

?

Y = ??,

?=

1
0
?1

0
1
?2

0
0
1

!

Then, the conditional probability distribution of X1 and X2 given X3 , is Gaussian, with the inverse
covariance matrix given by


1 + ?12 ?1 ?2
(4)
?1 ?2 1 + ?22
A comparison between (3) and (4) then reveals that the proposed Neumann random walk corresponds to conditioning on the boundary variables, if the edges going from the set S to its boundary
are directed. The reflected random walk, for the original problem, therefore corresponds to first
setting all the influences from other nodes in the graph to nodes in the set S to zero (resulting in
directed edges) and then conditioning on the boundary variables. Therefore, the proposed method
offers a compromise compared to the full model of [5], based on local information at the level of
each subnetwork.
3.1

Group-Penalized PCR on Graph

Using the Neumann eigenvectors of subnetworks, we now define a principal component regression
on graphs, which can be used to analyze the significance of subnetworks. Let N j denote the |S j | ?
m j matrix of the m j smallest Neumann eigenfunctions for subgraph S j . Also, let X ( j) be the n ? |S j |
matrix of observations for the j-th subnetwork. An m j -dimensional projection of the original data
matrix X ( j) is then given by X? ( j) = X ( j) N j . Different methods can be used in order to determine
the number of eigenfunctions m j for each subnetwork. A simple procedure determines a predefined
threshold for the proportion of variance explained by each eigenfunction. These proportions can be
determined by considering the reciprocal of Neumann eigenvalues (ignoring the 0-eigenvalue). To
simplify the presentation, here we assume m j = m, ? j.
5

The significance of subnetwork S j is a function of the combined effect of all the nodes, captured
by the transformed data matrix X? ( j) . This can be evaluated by forming a multivariate ANOVA
(MANOVA) model. Formally, let y be the mn ? 1 vector of observations obtained by stacking all
the transformed data matrices X? ( j) . Also, let X be the mn ? Jmr design matrix corresponding to the
experimental settings, where r is the number of parameters used to model experimental conditions,
and ? be the vector of regression coefficients. For simplicity, here we focus on the case of a twoclass inference problem (e.g. treatment vs. control). Extensions to more general experimental
settings follow naturally and are discussed in Section 5.
To evaluate the combined effect of each subnetwork, we impose a group penalty on the coefficient
of the regression of y on the design matrix X . In particular, using the group lasso penalty [18], we
estimate the significance of the subnetwork by solving the following optimization problem2
(
)
J

argmin n?1 ky ? ? X ( j) ? ( j) k22 + ?
?

j=1

J

? k? ( j) k2

(5)

j=1

where J is the total number of subnetworks considered and X ( j) and ? ( j) denote the columns of
X , and entries of ? corresponding to the subnetwork j, respectively.
In equation (5), ? is the tuning parameter and is usually determined by performing k-fold cross validation or evaluation on independent data sets. However, since the goal of our analysis is to determine
the significance of subnetworks, ? should be determined so that the probability of false positives is
controlled at a given significance level ?. Here we adapt the approach in [20] and determine the
optimal value of ? so that the family-wise error rate (FWER) in repeated sampling with replacement
(bootstrap) is controlled at the level ?. Specifically, let qi? be the total number of subnetworks considered significant based on the value of ? in the ith bootstrap sample. Let ? be the threshold for
( j)
selection of variables as significant. In other words, if Pi is the probability of selecting the coefficients corresponding to subnetwork j in the ith bootstrap sample, the subnetwork j is considered
p
( j)
significant if max? Pi ? ?. Using this method, we select ? such that qi? = (2? ? 1)? p.3
The following result shows that the proposed methodology correctly selects the significant subnetworks, while controlling FWER at level ?. We begin by introducing some additional notations and
assumptions. We assume the columns of design matrix X are normalized so that n?1 Xi T Xi = 1,
Throughout this paper, we consider the case where the total number of nodes in the graph p, and the
number of design parameters r are allowed to diverge (the p  n setting). In addition, let s be the
total number of non-zero elements in the true regression vector ? .
Theorem 4. Suppose that m, n ? 1 and there exists ? ? 1 and t ? s ? 1 such that n?1 X T Xi j ?
(7?t)?1 for all i 6= j. Also suppose that for j 6= k, the transformed random variables
X? ( j) and X? (k)
p
are independent. If the tuning parameter ? is selected such that such that q? = (2? ? 1)?rp,
(i) there exists ? = ? (n, p) > 0 such that ? ? 0 as n ? ? and with probability at least 1 ? ? the
significant subnetworks are correctly selected with high probability,
(ii) the family-wise error rate is controlled at the level ?.
Outline of the Proof. First note that the MANOVA model presented above can be reformulated as a
multi-task
learning problem [21]. Upon establishing the fact that for the proposed tuning parameter
p
? ? log p/(nm3/2 ), it follows from the results in [22] that for each bootstrap sample, there exists
? = ?(n) > 0 such that with probability at least 1 ? (rp)?? the significant subnetworks are correctly
selected. Thus if ? ? 1?(rp)?? , the coefficients for significant subnetworks are included in the final
2 The

problem in (5) can be solved using the R-package grplasso [19].
details for this method are given in [20], but are excluded here due to space limitations.

3 Additional

6

?
model with hight probability. In particular, it can be shown that ? = ?{ B(1 ? (rp)?? ? ?)/2},
where B is the number of bootstrap samples and ? is the cumulative normal distribution. This
proves the first claim.
Next, note that the normality assumption, and the fact that the eigenfunctions within each sub( j)
network are orthogonal, imply that for each j, X?i , i = 1, . . . , m are independent. Moreover, the
assumption of independence of X? ( j) and X? (k) for j 6= k implies that the values of y are independent
realizations of i.i.d standard normal random variables. On the other hand, the KarushKuhnTucker
conditions for the optimization problem in (5) imply that ? ( j) 6= 0 iff (nm)(?1) h(y ? X ? ), X ( j) i =
sgn (?? ( j) )?, where hx, yi denotes their inner product. It is hence clear that 1[? ( j) 6=0] are exchangeable.
Combining this with the first part of the theorem, the claim follows from Theorem 1 of [20].
Remark 5. The main assumption of Theorem 4 is the independence of the variables in different subnetworks. Although this is not satisfied in general problems, it may be satisfied by the conditioning
argument of Remark 3. It is possible to further relax this assumption using an argument similar to
Theorem 2 of [20], but we do not pursue this here.

4

Experiments

We illustrate the performance of the proposed method using simulated data motivated by biological
applications, as well as a real data application based on gene expression analysis. In the simulation,
we generate a small network of 80 nodes (genes), with 8 subnetworks. The random variables (expression levels of genes) are generated according to a normal distribution with mean ?. Under the
null hypothesis, ?null = 1 and the association weight ? for all edges of the network is set to 0.2. The
setting of parameters under the alternative hypothesis are given in Table 1, where ?alt = 3. These
settings are illustrated in the left panel of Figure 2. Table 1 also includes the estimated powers of
the tests for subnetworks based on 200 simulations with n = 50 observations. It can be seen that the
proposed GPCR method offers improvements over GSEA [1], especially in case of subnetworks 3
and 6. However, it results in a less accurate inference compared to NetGSA [5].
In [5], the pathways involved in Galactose utilization in yeast were analyzed based on the data from
[23], and the performances of the NetGSA and GSEA methods were compared. The interactions
among genes, along with significance of individual genes (based on single gene analysis) are given
in the right panel of Figure 2, and the results of significance analysis based on NetGSA, GSEA
and the proposed GPCR are given in Table 2. As in the simulated example, the results of this
analysis indicate that GPCR results in improved efficiency over GSEA, while failing to detect the
significance of some of the pathways detected by NetGSA.

5

Conclusion

We proposed a principal component regression method for graphs, called GPCR, using Laplacian
eigenmaps with Neumann boundary conditions. The proposed method offers a systematic approach

Table 1: Parameter settings under the alternative and estimated powers for the simulation study.
Subnet
1
2
3
4

Parameter Setting
% ?alt
?
0.05
0.2
0.20
0.2
0.50
0.2
0.80
0.2

Estimated Powers
NetGSA
GPCR
GSEA
0.02
0.08
0.01
0.03
0.21
0.02
1.00
0.65
0.27
1.00
0.81
0.90

Subnet
5
6
7
8

7

Parameter Setting
% ?alt
?
0.05
0.6
0.20
0.6
0.50
0.6
0.80
0.6

Estimated Powers
NetGSA
GPCR
GSEA
0.94
0.41
0.12
1.00
0.61
0.15
1.00
0.99
0.97
1.00
0.99
1.00

Figure 2: Left: Setting of the simulation parameters under the alternative hypothesis. Right: Network of yeast genes involved in Galactose utilization.
for dimension reduction in networks, with a priori defined subnetworks of interest. It can also incorporate both weighted and unweighted adjacency matrices and can be easily extended to analyzing
complex experimental conditions through the framework of linear models. This method can also be
used in longitudinal and time-course studies.
Our simulation studies, and the real data example indicate that the proposed GPCR method offers
significant improvements over the methods of gene set enrichment analysis (GSEA). However, it
does not achieve optimal powers in comparison to NetGSA. This difference in power may be attributable to the mechanism of incorporating the network information in the two methods: while
NetGSA incorporates the full network information, GPCR only account for local network information, at the level of each subnetwork, and restricts the interactions with the rest of the network based
on the Neumann boundary condition. However, the most computationally involved step in NetGSA requires O(p3 ) operation, whereas the computational cost of GPCR is O(m3 ). It is clear that
since m  p in most applications, GPCR could result in significant improvement in terms of computational time and memory requirements for analysis of high dimensional networks. In addition,
NetGSA requires that r < n, whilst the dimension reduction and the penalization of the proposed
GPCR removes the need for any such restriction and facilitates the analysis of complex experiments
in the settings with small sample sizes.
Acknowledgments
Funding for this work was provided by NIH grants 1RC1CA145444-0110 and 5R01LM010138-02.

Table 2: Significance of pathways in Galactose utilization.
PATHWAY
rProtein Synthesis
Glycolytic Enzymes
RNA Processing
Fatty Acid Oxidation
O2 Stress
Mating, Cell Cycle
Vesicular Transport
Amino Acid Synthesis

Size
28
16
75
7
13
58
19
30

NetGSA
X

GPCR

X

X

GSEA

PATHWAY
Sugar Transport
Glycogen Metabolism
Stress
Metal Uptake
Respiration
Gluconeogenesis
Galactose Utilization

8

Size
2
12
12
4
9
7
12

NetGSA

GPCR

X

X

GSEA

X
X

X

X

References
[1] A. Subramanian, P. Tamayo, V.K. Mootha, S. Mukherjee, B.L. Ebert, M.A. Gillette, A. Paulovich, S.L.
Pomeroy, T.R. Golub, E.S. Lander, et al. Gene set enrichment analysis: A knowledge-based approach
for interpreting genome-wide expression profiles. Proceedings of the National Academy of Sciences,
102(43):15545?15550, 2005.
[2] B. Efron and R. Tibshirani. On testing the significance of sets of genes. Annals of Applied Statistics,
1(1):107?129, 2007.
[3] T. Ideker, O. Ozier, B. Schwikowski, and A.F. Siegel. Discovering regulatory and signalling circuits in
molecular interaction networks. Bioinformatics, 18(1):S233?S240, 2002.
[4] Zhi Wei and Li Hongzhe. A markov random field model for network-based analysis of genomic data.
Bioinformatics, 2007.
[5] A. Shojaie and G. Michailidis. Analysis of gene sets based on the underlying regulatory network. Journal
of Computational Biology, 16(3):407?426, 2009.
[6] A. Shojaie and G. Michailidis. Network enrichment analysis in complex experiments. Statisitcal Applications in Genetics and Molecular Biology, 9(1), Article 22, 2010.
[7] J. Shi and J. Malik. Normalized cuts and image segmentation. IEEE Transactions on pattern analysis
and machine intelligence, 22(8):888?905, 2000.
[8] M. Saerens, F. Fouss, L. Yen, and P. Dupont. The principal components analysis of a graph, and its
relationships to spectral clustering. Machine Learning: ECML 2004, pages 371?383, 2004.
[9] A.Y. Ng, M.I. Jordan, and Y. Weiss. On spectral clustering: Analysis and an algorithm. Advances in
neural information processing systems, 2:849?856, 2002.
[10] F. Fouss, A. Pirotte, J.M. Renders, and M. Saerens. A novel way of computing dissimilarities between
nodes of a graph, with application to collaborative filtering and subspace projection of the graph nodes.
In European Conference on Machine Learning Proceedings, ECML, 2004.
[11] C. Li and H. Li. Variable Selection and Regression Analysis for Graph-Structured Covariates with an
Application to Genomics. Annals of Applied Statistics, in press, 2010.
[12] F. Rapaport, A. Zinovyev, M. Dutreix, E. Barillot, and J.P. Vert. Classification of microarray data using
gene networks. BMC bioinformatics, 8(1):35, 2007.
[13] F.R.K. Chung. Spectral graph theory. American Mathematical Society, 1997.
[14] S.L. Lauritzen. Graphical models. Oxford Univ Press, 1996.
[15] H. Rue and L. Held. Gaussian Markov random fields: theory and applications. Chapman & Hall, 2005.
[16] J. Besag. Spatial interaction and the statistical analysis of lattice systems. Journal of the Royal Statistical
Society. Series B (Methodological), 36(2):192?236, 1974.
[17] M. Belkin and P. Niyogi. Laplacian eigenmaps and spectral techniques for embedding and clustering.
Advances in neural information processing systems, 1:585?592, 2002.
[18] M. Yuan and Y. Lin. Model selection and estimation in regression with grouped variables. Journal of
Royal Statistical Society. Series B Statistical Methodology, 68(1):49, 2006.
[19] L. Meier, S. Van de Geer, and P. Buhlmann. The group lasso for logistic regression. Journal of Royal
Statistical Society. Series B Statistical Methodology, 70(1):53, 2008.
[20] N. Meinshausen and P. B?uhlmann. Stability selection. Preprint, arXiv, 809, 2009.
[21] A. Argyriou, T. Evgeniou, and M. Pontil. Convex multi-task feature learning. Machine Learning,
73(3):243?272, 2008.
[22] K. Lounici, M. Pontil, A.B. Tsybakov, and S. van de Geer. Taking Advantage of Sparsity in Multi-Task
Learning. Preprint, arXiv, 903, 2009.
[23] T. Ideker, V. Thorsson, J.A. Ranish, R. Christmas, J. Buhler, J.K. Eng, R. Bumgarner, D.R. Goodlett,
R. Aebersold, and L. Hood. Integrated genomic and proteomic analyses of a systematically perturbed
metabolic network. Science, 292(5518):929, 2001.

9


<<----------------------------------------------------------------------------------------------------------------------------------------->>

