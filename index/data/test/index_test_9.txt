query sentence: data collection sensors
<<------------------------------------------------------------------------------------------------------------------------------------------->>
title: 5982-efficient-learning-by-directed-acyclic-graph-for-resource-constrained-prediction.pdf

Efficient Learning by Directed Acyclic Graph For
Resource Constrained Prediction
Joseph Wang
Department of Electrical
Computer Engineering
Boston University
Boston MA
joewang@bu.edu
Kirill Trapeznikov
Systems Technology Research
Woburn MA
kirill.trapeznikov@
stresearch.com
Venkatesh Saligrama
Department of Electrical
Computer Engineering
Boston University
Boston MA
srv@bu.edu
Abstract
We study the problem of reducing test-time acquisition costs in classification systems Our goal is to learn decision rules that adaptively select sensors for each
example as necessary to make a confident prediction We model our system as a
directed acyclic graph DAG where internal nodes correspond to sensor subsets
and decision functions at each node choose whether to acquire a new sensor or
classify using the available measurements This problem can be posed as an empirical risk minimization over training data Rather than jointly optimizing such
a highly coupled and non-convex problem over all decision nodes we propose an
efficient algorithm motivated by dynamic programming We learn node policies
in the DAG by reducing the global objective to a series of cost sensitive learning
problems Our approach is computationally efficient and has proven guarantees of
convergence to the optimal system for a fixed architecture In addition we present
an extension to map other budgeted learning problems with large number of sensors to our DAG architecture and demonstrate empirical performance exceeding
state-of-the-art algorithms for data composed of both few and many sensors
Introduction
Many scenarios involve classification systems constrained by measurement acquisition budget In
this setting a collection of sensor modalities with varying costs are available to the decision system
Our goal is to learn adaptive decision rules from labeled training data that when presented with an
unseen example would select the most informative and cost-effective acquisition strategy for this
example In contrast non-adaptive methods attempt to identify a common sparse subset of
sensors that can work well for all data Our goal is an adaptive method that can classify typical cases
using inexpensive sensors while using expensive sensors only for atypical cases
We propose an adaptive sensor acquisition system learned using labeled training examples The
system modeled as a directed acyclic graph is composed of internal nodes which contain
decision functions and a single sink node the only node with no outgoing edges representing
the terminal action of stopping and classifying At each internal node a decision function
routes an example along one of the outgoing edges Sending an example to another internal node
represents acquisition of a previously unacquired sensor whereas sending an example to the sink
node indicates that the example should be classified using the currently acquired set of sensors The
goal is to learn these decision functions such that the expected error of the system is minimized
subject to an expected budget constraint
First we consider the case where the number of sensors available is small as in 23 though
the dimensionality of data acquired by each sensor may be large such as an image taken in different
modalities In this scenario we construct a DAG that allows for sensors to be acquired in any order
and classification to occur with any set of sensors In this regime we propose a novel algorithm to
learn node decisions in the DAG by emulating dynamic programming In our approach we
decouple a complex sequential decision problem into a series of tractable cost-sensitive learning
subproblems Cost-sensitive learning CSL generalizes multi-decision learning by allowing decision costs to be data dependent Such reduction enables us to employ computationally efficient
CSL algorithms for iteratively learning node functions in the DAG. In our theoretical analysis we
show that given a fixed DAG architecture the policy risk learned by our algorithm converges to the
Bayes risk as the size of the training set grows
Next we extend our formulation to the case where a large number of sensors exist but the number
of distinct sensor subsets that are necessary for classification is small as in where the depth
of the trees is fixed to For this regime we present an efficient subset selection algorithm based
on sub-modular approximation We treat each sensor subset as a new sensor construct a DAG
over unions of these subsets and apply our DP algorithm Empirically we show that our approach
outperforms state-of-the-art methods in both small and large scale settings
Related Work There is an extensive literature on adaptive methods for sensor selection for reducing
test-time costs It arguably originated with detection cascades and

<<----------------------------------------------------------------------------------------------------------------------->>

title: 2754-recovery-of-jointly-sparse-signals-from-few-random-projections.pdf

Recovery of Jointly Sparse Signals
from Few Random Projections
Michael B. Wakin
ECE Department
Rice University
wakin@rice.edu
Marco F. Duarte
ECE Department
Rice University
duarte@rice.edu
Dror Baron
ECE Department
Rice University
drorb@rice.edu
Shriram Sarvotham
ECE Department
Rice University
shri@rice.edu
Richard G. Baraniuk
ECE Department
Rice University
richb@rice.edu
Abstract
Compressed sensing is an emerging field based on the revelation that a small group
of linear projections of a sparse signal contains enough information for reconstruction In this paper we introduce a new theory for distributed compressed sensing
DCS that enables new distributed coding algorithms for multi-signal ensembles
that exploit both intra and inter-signal correlation structures The DCS theory rests
on a new concept that we term the joint sparsity of a signal ensemble We study
three simple models for jointly sparse signals propose algorithms for joint recovery of multiple signals from incoherent projections and characterize theoretically
and empirically the number of measurements per sensor required for accurate reconstruction In some sense DCS is a framework for distributed compression of
sources with memory which has remained a challenging problem in information
theory for some time DCS is immediately applicable to a range of problems in
sensor networks and arrays
Introduction
Distributed communication sensing and computing are emerging fields with numerous promising applications In a typical setup large groups of cheap and individually unreliable nodes may collaborate to perform a variety of data processing tasks such
as sensing data collection classification modeling tracking and so on As individual
nodes in such a network are often battery-operated power consumption is a limiting factor and the reduction of communication costs is crucial In such a setting distributed
source coding 13 may allow the sensors to save on communication costs In the
Slepian-Wolf framework for lossless distributed coding the availability of correlated side information at the decoder enables the source encoder to communicate losslessly
at the conditional entropy rate rather than the individual entropy Because sensor networks
and arrays rely on data that often exhibit strong spatial correlations distributed
compression can reduce the communication costs substantially thus enhancing battery life
Unfortunately distributed compression schemes for sources with memory are not yet mature 13
We propose a new approach for distributed coding of correlated sources whose signal correlations take the form of a sparse structure Our approach is based on another emerging
field known as compressed sensing CS builds upon the groundbreaking work
of Cand`es and Donoho who showed that signals that are sparse relative to a
known basis can be recovered from a small number of nonadaptive linear projections onto
a second basis that is incoherent with the first A random basis provides such incoherence
with high probability Hence CS with random projections is universal the signals can
be reconstructed if they are sparse relative to any known basis The implications of CS
for signal acquisition and compression are very promising With no a priori knowledge of
a signal?s structure a sensor node could simultaneously acquire and compress that signal
preserving the critical information that is extracted only later at a fusion center
In our framework for distributed compressed sensing this advantage is particularly
compelling In a typical DCS scenario a number of sensors measure signals that are each
individually sparse in some basis and also correlated from sensor to sensor Each sensor
independently encodes its signal by projecting it onto another incoherent basis such as a
random one and then transmits just a few of the resulting coefficients to a single collection
point Under the right conditions a decoder at the collection point can reconstruct each of
the signals precisely The DCS theory rests on a concept that we term the joint sparsity of a
signal ensemble We study in detail three simple models for jointly sparse signals propose
tractable algorithms for joint recovery of signal ensembles from incoherent projections and
characterize theoretically and empirically the number of measurements per sensor required
for reconstruction While the sensors operate entirely without collaboration joint decoding
can recover signals using far fewer measurements per sensor than would be required for
separable CS recovery This paper presents our specific results for one of the three models
the other two are highlighted in our papers
Sparse Signal Recovery from Incoherent Projections
In the traditional CS setting we consider a single signal RN which we assume to be
sparse in a known orthonormal basis or frame That is
for some where holds.1 The signal is observed indirectly via an
measurement matrix where We let be the observation vector
consisting of the inner products of the measurement vectors against the signal The
rows of are the measurement vectors against which the signal is projected These rows
are chosen to be incoherent with that is they each have non-sparse expansions in
the basis In general meets the necessary criteria when its entries are drawn
randomly for example independent and identically distributed Gaussian
Although the equation is underdetermined it is possible to recover from under
certain conditions In general due to the incoherence between and can be recovered
by solving the optimization problem
arg min
In principle remarkably few random measurements are required to recover a K-sparse
signal via minimization Clearly more than measurements must be taken to avoid
ambiguity in theory random measurements will suffice Unfortunately solving
this optimization
problem appears to be NP-hard requiring a combinatorial enumer
ation of the
possible sparse subspaces for
The amazing revelation that supports the CS theory is that a much simpler problem yields
an equivalent solution thanks again to the incoherence of the bases we need only solve
The norm merely counts the number of nonzero entries in the vector CS theory also
applies to signals for which k?kp where such extensions for DCS are a topic of
ongoing research
for the sparsest vector that agrees with the observed coefficients
arg min
This optimization problem known also as Basis Pursuit is significantly more
tractable and can be solved with traditional linear programming techniques There is no
free lunch however more than measurements will be required in order to recover
sparse signals In general there exists a constant oversampling factor such
that cK measurements suffice to recover with very high probability Commonly
quoted as O(log(N we have found that log2 provides a useful
rule-of-thumb At the expense of slightly more measurements greedy algorithms have
also been developed to recover from One example known as Orthogonal Matching
Pursuit OMP requires ln(N We exploit both BP and greedy algorithms for
recovering jointly sparse signals
Joint Sparsity Models
In this section we generalize the notion of a signal being sparse in some basis to the
notion of an ensemble of signals being jointly sparse We consider three different joint
sparsity models JSMs that apply in different situations In most cases each signal is itself
sparse and so we could use the CS framework from above to encode and decode each one
separately However there also exists a framework wherein a joint representation for the
ensemble uses fewer total vectors
We use the following notation for our signal ensembles and measurement model Denote
the signals in the ensemble by and assume that each signal RN
We assume that there exists a known sparse basis for RN in which the can be sparsely
represented Denote by the measurement matrix for signal is Mj and in
general the entries of are different for each Thus yj consists of Mj
incoherent measurements of
Sparse common component innovations In this model all signals share a
common sparse component while each individual signal contains a sparse innovation component that is
zC zj
with
zC k?C k0
and
zj k?j k0 Kj
Thus the signal zC is common to all of the and has sparsity in basis The signals
zj are the unique portions of the and have sparsity Kj in the same basis A practical
situation well-modeled by JSM-1 is a group of sensors measuring temperatures at a number
of outdoor locations throughout the day The temperature readings have both temporal
intra-signal and spatial inter-signal correlations Global factors such as the sun and
prevailing winds could have an effect zC that is both common to all sensors and structured
enough to permit sparse representation More local factors such as shade water or animals could contribute localized innovations zj that are also structured and hence sparse
Similar scenarios could be imagined for a network of sensors recording other phenomena
that change smoothly in time and in space and thus are highly correlated
Common sparse supports In this model all signals are constructed from the
same sparse set of basis vectors but with different coefficients that is
where each is supported only on the same with K. Hence
all signals have sparsity of and all are constructed from the same basis elements
but with arbitrarily different coefficients A practical situation well-modeled by JSM-2
is where multiple sensors acquire the same signal but with phase shifts and attenuations
caused by signal propagation In many cases it is critical to recover each one of the sensed
signals such as in many acoustic localization and array processing algorithms Another
useful application for JSM-2 is MIMO communication
Nonsparse common sparse innovations This model extends JSM-1 so that
the common component need no longer be sparse in any basis that is
zC zj
with
zC
and
zj k?j k0 Kj
but zC is not necessarily sparse in the basis We also consider the case where the supports
of the innovations are shared for all signals which extends A practical situation
well-modeled by JSM-3 is where several sources are recorded by different sensors together
with a background signal that is not sparse in any basis Consider for example a computer
vision-based verification system in a device production plant Cameras acquire snapshots
of components in the production line a computer system then checks for failures in the
devices for quality control purposes While each image could be extremely complicated
the ensemble of images will be highly correlated since each camera is observing the same
device with minor sparse variations JSM-3 could also be useful in some non-distributed
scenarios For example it motivates the compression of data such as video where the
innovations or differences between video frames may be sparse even though a single frame
may not be very sparse In general JSM-3 may be invoked for ensembles with significant
inter-signal correlations but insignificant intra-signal correlations
Recovery of Jointly Sparse Signals
In a setting where a network or array of sensors may encounter a collection of jointly
sparse signals and where a centralized reconstruction algorithm is feasible the number
of incoherent measurements required by each sensor can be reduced For each JSM we
propose algorithms for joint signal recovery from incoherent projections and characterize
theoretically and empirically the number of measurements per sensor required for accurate
reconstruction We focus in particular on JSM-3 in this paper but also overview our results
for JSMs and which are discussed in further detail in our papers
Sparse common component innovations
For this model also we have proposed an analytical framework inspired by the
principles of information theory This allows us to characterize the measurement rates Mj
required to jointly reconstruct the signals The measurement rates relate directly to the
signals conditional sparsities in parallel with the Slepian-Wolf theory More specifically
we have formalized the following intuition Consider the simple case of signals By
employing the CS machinery we might expect that K1 coefficients suffice to
reconstruct coefficients suffice to reconstruct yet only iii
K2 coefficients should suffice to reconstruct both and since we have K1 K2
nonzero elements in and In addition given the K1 measurements for
as side information and assuming that the partitioning of into zC and z1 is known
cK2 measurements that describe z2 should allow reconstruction of Formalizing these
arguments allows us to establish theoretical lower bounds on the required measurement
rates at each sensor shows such a bound for the case of signals
We have also established upper bounds on the required measurement rates Mj by proposing
a specific algorithm for reconstruction The algorithm uses carefully designed measurement matrices which some rows are identical and some differ so that the resulting
measurements can be combined to allow step-by-step recovery of the sparse components
The theoretical rates Mj are below those required for separable CS recovery of each signal
We also proposed a reconstruction technique based on a single execution of a linear program which seeks the sparsest components zC z1 zJ that
32
Converse
R2
Anticipated
Achievable
Simulation
Separate
Prob of exact reconstruction
32
Number of measurements per sensor
Figure Converse bounds and achievable measurement rates for signals with common
sparse component and sparse innovations We fix signal lengths and sparsities
K1 K2 The measurement rates Rj Mj reflect the number of measurements normalized by the signal length Blue curves indicate our theoretical and anticipated converse
bounds red indicates a provably achievable region and pink denotes the rates required for separable
CS signal reconstruction Reconstructing a signal ensemble with common sparse supports We plot the probability of perfect reconstruction via DCS-SOMP solid lines and independent
CS reconstruction dashed lines as a function of the number of measurements per signal and the
number of signals We fix the signal length to and the sparsity to An oracle
encoder that knows the positions of the large coefficients would use measurements per signal
account for the observed measurements Numerical simulations support such an approach
Future work will extend JSM-1 to compressible signals
Common sparse supports
Under the JSM-2 signal ensemble model also independent recovery of each
signal via minimization would require cK measurements per signal However algorithms inspired by conventional greedy pursuit algorithms such as OMP can substantially reduce this number In the single-signal case OMP iteratively constructs the
sparse support set decisions are based on inner products between the columns of
and a residual In the multi-signal case there are more clues available for determining the
elements of
To establish a theoretical justification for our approach we first proposed a simple OneStep Greedy Algorithm OSGA that combines all of the measurements and seeks the
largest correlations with the columns of the We established that assuming that
has Gaussian entries and that the nonzero coefficients in the are Gaussian then
with measurements per signal OSGA recovers with probability approaching
as Moreover with measurements per signal OSGA recovers all with
probability approaching as This meets the theoretical lower bound for Mj
In practice OSGA can be improved using an iterative greedy algorithm We proposed a
simple variant of Simultaneous Orthogonal Matching Pursuit SOMP that we term
DCS-SOMP For this algorithm plots the performance as the number of
sensors varies from to 32 We fix the signal lengths at and the sparsity of
each signal to With DCS-SOMP for perfect reconstruction of all signals the average number of measurements per signal decreases as a function of J. The trend suggests
that for very large close to measurements per signal should suffice On the contrary
with independent CS reconstruction for perfect reconstruction of all signals the number of
measurements per sensor increases as a function of J. This surprise is due to the fact that
each signal will experience an independent probability of successful reconstruction
therefore the overall probability of complete success is pJ Consequently each sensor must
compensate by making additional measurements
Nonsparse common sparse innovations
The JSM-3 signal ensemble model provides a particularly compelling motivation for joint
recovery Under this model no individual signal is sparse and so separate signal recovery would require fully measurements per signal As in the other JSMs however the
commonality among the signals makes it possible to substantially reduce this number
Our recovery algorithms are based on the observation that if the common component zC
were known then each innovation zj could be estimated using the standard single-signal
CS machinery on the adjusted measurements yj zC zj While zC is not known in
advance
it can be estimated from the measurements In fact across all sensors a total of
Mj random projections of zC are observed each corrupted by a contribution from one
of the zj Since zC is not sparse it cannot be
recovered via CS techniques but when the
number of measurements is sufficiently large Mj zC can be estimated using
standard tools from linear algebra A key requirement for such a method to succeed in
recovering zC is that each be different so that their rows combine to span all of RN In
the limit zC can be recovered while still allowing each sensor to operate at the minimum
measurement rate dictated by the zj A prototype algorithm which we name Transpose
Estimation of Common Component TECC is listed below where we assume that each
measurement matrix has entries
TECC Algorithm for JSM-3
as the concatenation of the regu1 Estimate common component Define the matrix
larized individual measurement matrices Mj that is
Calculate the estimate of the common component as zc
bT
Estimate measurements generated by innovations Using the previous estimate subtract the contribution of the common part on the measurements and generate estimates
for the measurements caused by the innovations for each signal ybj yj zc
C.
Reconstruct innovations Using a standard single-signal CS reconstruction algorithm
obtain estimates of the innovations zbj from the estimated innovation measurements ybj
Obtain signal estimates Sum the above estimates letting
bj zc
bj
The following theorem shows that asymptotically by using the TECC algorithm each
sensor need only measure at the rate dictated by the sparsity Kj
Theorem Assume that the nonzero expansion coefficients of the sparse innovations
zj are Gaussian random variables and that their locations are uniformly distributed
on Then the following statements hold
Let the measurement matrices contain entries with Mj Kj
Then each signal can be recovered using the TECC algorithm with probability
approaching as
Let be a measurement matrix with Mj Kj for some J}. Then with
probability the signal cannot be uniquely recovered by any algorithm for any J.
For large the measurement rates permitted by Statement are the lowest possible for any
reconstruction strategy on JSM-3 signals even neglecting the presence of the nonsparse
component Thus Theorem provides a tight achievable and converse for JSM-3 signals
The CS technique employed in Theorem involves combinatorial searches for estimating
the innovation components More efficient techniques could also be employed including
several proposed for CS in the presence of noise
While Theorem suggests the theoretical gains from joint recovery as practical
gains can also be realized with a moderate number of sensors For example suppose in
the TECC algorithm that the initial estimate zc
is not accurate enough to enable correct
identification of the sparse innovation supports In such a case it may still be possible
for a rough approximation of the innovations zj to help refine the estimate zc
This in
turn could help to refine the estimates of the innovations Since each component helps to
estimate the others we propose an iterative algorithm for JSM-3 recovery The Alternating
Common and Innovation Estimation ACIE algorithm exploits the observation that once
the basis vectors comprising the innovation zj have been identified in the index set
their effect on the measurements yj can be removed to aid in estimating zC
ACIE Algorithm for JSM-3
for each Set the iteration counter
Initialize Set
Estimate common component Let
be the Mj submatrix obtained
from and construct an Mj Mj
matrix
by sampling the columns
Qj qj,Mj
having
orthonormal
columns
that
span
the
orthogonal
comb
plement of colspan(?j
Remove the projection of the measurements into the aforeb letting
mentioned span to obtain measurements caused exclusively by vectors not in
QT Use the modified measurements Ye yeT yeT yeT
yej QTj yj and
iT
eT
eT
eT
and modified holographic basis
to refine the estimate of the
measurements caused by the common part of the signal setting zf
where
A AT AT denotes the pseudoinverse of matrix A.
Estimate innovation supports For each signal subtract zf
from the measurements
ybj yj zf
and estimate the sparse support of each innovation
Iterate If a preset number of iterations then increment and return to Step
Otherwise proceed to Step
Estimate innovation coefficients For each signal estimate the coefficients for the
is a sampled version of
setting yj zf
indices in
where
the innovation?s sparse coefficient vector estimate bj
Reconstruct signals Estimate each signal as
bj zf
bj zf
the measurements
In the case where the innovation support estimate is correct
yej will describe only the common component
If
this
is
true
for every signal and the
number of remaining measurements Mj KJ then zC can be perfectly recovered
in Step Because it may be difficult to correctly obtain all in the first iteration we find
it preferable to run the algorithm for several iterations
shows that for sufficiently large we can recover all of the signals with significantly fewer than measurements per signal We note the following behavior in the graph
First as grows it becomes more difficult to perfectly reconstruct all signals We believe this is inevitable because even if zC were known without error then perfect ensemble
recovery would require the successful execution of independent runs of OMP. Second
for small the probability of success can decrease at high values of We believe this is
due to the fact that initial errors in estimating zC may tend to be somewhat sparse since zc
roughly becomes an average of the signals and these sparse errors can mislead the
subsequent OMP processes For more moderate it seems that the errors in estimating
zC though greater tend to be less sparse We expect that a more sophisticated algorithm
could alleviate such a problem and we note that the problem is also mitigated at higher J.
shows that when the sparse innovations share common supports we see an even
greater savings As a point of

<<----------------------------------------------------------------------------------------------------------------------->>

title: 2847-off-road-obstacle-avoidance-through-end-to-end-learning.pdf

Off-Road Obstacle Avoidance through
End-to-End Learning
Yann LeCun
Courant Institute of Mathematical Sciences
New York University
New York NY USA
http://yann.lecun.com
Jan Ben
Net-Scale Technologies
Morganville NJ USA
Eric Cosatto
NEC Laboratories
Princeton NJ
Urs Muller
Net-Scale Technologies
Morganville NJ USA
urs@net-scale.com
Beat Flepp
Net-Scale Technologies
Morganville NJ USA
Abstract
We describe a vision-based obstacle avoidance system for off-road mobile robots The system is trained from end to end to map raw input
images to steering angles It is trained in supervised mode to predict the
steering angles provided by a human driver during training runs collected
in a wide variety of terrains weather conditions lighting conditions and
obstacle types The robot is a off-road truck with two forwardpointing wireless color cameras A remote computer processes the video
and controls the robot via radio The learning system is a large 6-layer
convolutional network whose input is a single left/right pair of unprocessed low-resolution images The robot exhibits an excellent ability to
detect obstacles and navigate around them in real time at speeds of
Introduction
Autonomous off-road vehicles have vast potential applications in a wide spectrum of domains such as exploration search and rescue transport of supplies environmental management and reconnaissance Building a fully autonomous off-road vehicle that can reliably
navigate and avoid obstacles at high speed is a major challenge for robotics and a new
domain of application for machine learning research
The last few years have seen considerable progress toward that goal particularly in areas
such as mapping the environment from active range sensors and stereo cameras
simultaneously navigating and building maps and classifying obstacle types
Among the various sub-problems of off-road vehicle navigation obstacle detection and
avoidance is a subject of prime importance The wide diversity of appearance of potential
obstacles and the variability of the surroundings lighting conditions and other factors
make the problem very challenging
Many recent efforts have attacked the problem by relying on a multiplicity of sensors
including laser range finder and radar While active sensors make the problem considerably simpler there seems to be an interest from potential users for purely passive
systems that rely exclusively on camera input Cameras are considerably less expensive
bulky power hungry and detectable than active sensors allowing levels of miniaturization
that are not otherwise possible More importantly active sensors can be slow limited in
range and easily confused by vegetation despite rapid progress in the area
Avoiding obstacles by relying solely on camera input requires solving a highly complex
vision problem A time-honored approach is to derive range maps from multiple images
through multiple cameras or through motion Deriving steering angles to avoid obstacles from the range maps is a simple matter A large number of techniques have been
proposed in the literature to construct range maps from stereo images Such methods have
been used successfully for many years for navigation in indoor environments where edge
features can be reliably detected and matched but navigation in outdoors environment
despite a long history is still a challenge real-time stereo algorithms are considerably less reliable in unconstrained outdoors environments The extreme variability of
lighting conditions and the highly unstructured nature of natural objects such as tall grass
bushes and other vegetation water surfaces and objects with repeating textures conspire
to limit the reliability of this approach In addition stereo-based methods have a rather
limited range which dramatically limits the maximum driving speed
End-To-End Learning for Obstacle Avoidance
In general computing depth from stereo images is an ill-posed problem but the depth map
is only a means to an end Ultimately the output of an obstacle avoidance system is a set
of possible steering angles that direct the robot toward traversible regions
Our approach is to view the entire problem of mapping input stereo images to possible
steering angles as a single indivisible task to be learned from end to end Our learning
system takes raw color images from two forward-pointing cameras mounted on the robot
and maps them to a set of possible steering angles through a single trained function
The training data was collected by recording the actions of a human driver together with the
video data The human driver remotely drives the robot straight ahead until the robot encounters a non-traversible obstacle The human driver then avoids the obstacle by steering
the robot in the appropriate direction The learning system is trained in supervised mode
It takes a single pair of heavily-subsampled images from the two cameras and is trained to
predict the steering angle produced by the human driver at that time
The learning architecture is a 6-layer convolutional network The network takes the
left and right color images and produces two outputs A large value on the first
output is interpreted as a left steering command while a large value on the second output
indicates a right steering command Each layer in a convolutional network can be viewed as
a set of trainable shift-invariant linear filters with local support followed by a point-wise
non-linear saturation function All the parameters of all the filters in the various layers
are trained simultaneously The learning algorithm minimizes the discrepancy between the
desired output vector and the output vector produced by the output layer
The approach is somewhat reminiscent of the ALVINN and MANIAC systems The
main differences with ALVINN are our system uses stereo cameras it is trained
for off-road obtacle avoidance rather than road following Our trainable system uses a
convolutional network rather than a traditional fully-connected neural net
Convolutional networks have two considerable advantages for this applications Their local and sparse connection scheme allows us to handle images of higher resolution than
ALVINN while keeping the size of the network within reasonnable limits Convolutional
nets are particularly well suited for our task because local feature detectors that combine
inputs from the left and right images can be useful for estimating distances to obstacles
possibly by estimating disparities Furthermore the local and shift-invariant property of
the filters allows the system to learn relevant local features with a limited amount of training
data
They key advantage of the approach is that the entire function from raw pixels to steering
angles is trained from data which completely eliminates the need for feature design and
selection geometry camera calibration and hand-tuning of parameters The main motivation for the use of end-to-end learning is in fact to eliminate the need for hand-crafted
heuristics Relying on automatic global optimization of an objective function from massive
amounts for data may produce systems that are more robust to the unpredictable variability
of the real world Another potential benefit of a pure learning-based approach is that the
system may use other cues than stereo disparity to detect obstacles possibly alleviating the
short-sightedness of methods based purely on stereo matching
Vehicle Hardware
We built a small and light-weight vehicle which can be carried by a single person so as
to facilitate data collection and testing in a wide variety of environments Using a small
rugged and low-cost robot allowed us to drive at relatively high speed without fear of causing damage to people property or the robot itself The downside of this approach is the
limited payload too limited for holding the computing power necessary for the visual processing Therefore the robot has no significant on-board computing power It is remotely
controled by an off-board computer A wireless link is used to transmit video and sensor
readings to the remote computer Throttle and steering controls are sent from the computer
to the robot through a regular radio control channel
The robot chassis was built around a customized scale remote-controlled electricpowered four-wheel-drive truck which was roughly in length The typical speed of
the robot during data collection and testing sessions was roughly meters per second Two
forward-pointing low-cost CCD cameras were mounted apart behind a
clear lexan window With lenses the horizontal field of view of each camera was
about degrees
A pair of analog video transmitters was used to send the camera outputs to the
remote computer The analog video links were subject to high signal noise color shifts
frequent interferences and occasional video drop-outs But the small size light weight
and low cost provided clear advantages The vehicle is shown in Figure The remote
control station consisted of a Athlon PC running Linux with video capture cards
and an interface to an R/C transmitter
Figure Left The robot is a modified cm-long truck platform controled by a remote
computer Middle sample images images from the training data Right poor reception
occasionally caused bad quality images
Data Collection
During a data collection session the human operator wears video goggles fed with the
video signal from one the robot?s cameras no stereo and controls the robot through a
joystick connected to the PC. During each run the PC records the output of the two video
cameras at frames per second together with the steering angle and throttle setting from
the operator
A crucially important requirement of the data collection process was to collect large
amounts of data with enough diversity of terrain obstacles and lighting conditions Tt
was necessary for the human driver to adopt a consistent obstacle avoidance behaviour To
ensure this the human driver was to drive the vehicle straight ahead whenever no obstacle
was present within a threatening distance Whenever the robot approached an obstacle the
human driver had to steer left or right so as to avoid the obstacle The general strategy
for collecting training data was as follows Collecting data from as large a variety of
off-road training grounds as possible Data was collected from a large number of parks
playgrounds frontyards and backyards of a number of suburban homes and heavily cluttered construction areas Collecting data with various lighting conditions different
weather conditions and different times of day Collecting sequences where the vehicle
starts driving straight and then is steered left or right as the robot approached an obstacle
Avoiding turns when no obstacles were present Including straight runs with no obstacles and no turns as part of the training set Trying to be consistent in the turning
behavior always turning at approximately the same distance from an obstacle
Even though great care was taken in collecting the highest quality training data there were
a number of imperfections in the training data that could not be avoided The smallform-factor low-cost cameras presented significant differences in their default settings In
particular the white balance of the two cameras were somewhat different To maximize
image quality the automatic gain control and automatic exposure were activated Because
of differences in fabrication the left and right images had slightly different brightness and
contrast characteristics In particular the AGC adjustments seem to react at different speeds
and amplitudes Because of AGC driving into the sunlight caused the images to become
very dark and obstacles to become hard to detect The wireless video connection caused
dropouts and distortions of some frames Approximately of the frames were affected
An example is shown in Figures The cameras were mounted rigidly on the vehicle
and were exposed to vibration despite the suspension Despite these difficult conditions
the system managed to learn the task quite well as will be shown later
The data was recorded and archived at a resolution of pixels at frames per
second The data was collected on 17 different days during the Winter of the
sun was very low on the horizon A total of clips were collected with an average
length of about 85 frames each This resulted in a total of about individual pairs of
frames Segments during which the robot was driven into position in preparation for a run
were edited out No other manual data cleaning took place In the end frame pairs
were used for training and for validation/testing The training pairs and testing pairs
came from different sequences and often different locations
Figure shows example snapshots from the training data including an image with poor
reception Note that only one of the two stereo images is shown High noise and frame
dropouts occurred in approximately of the frames It was decided to leave them in the
training set and test set so as to train the system under realistic conditions
The Learning System
The entire processing consists of a single convolutional network The architecture of convolutional nets is somewhat inspired by the structure of biological visual systems Convolutional nets have been used successfully in a number of vision applications such as
handwriting recognition object recognition and face detection
The input to the convolutional net consists of planes of size pixels The six
planes respectively contain the and components for the left camera and the right
camera The input images were obtained by cropping the images and through
horizontal low-pass filtering and subsampling and vertical low-pass filtering and
subsampling The horizontal resolution was set higher so as to preserve more accurate
image disparity information
Each layer in a convolutional net is composed of units organized in planes called feature
maps Each unit in a feature map takes inputs from a small neighborhood within the feature
maps of the previous layer Neighborhing units in a feature map are connected to neighboring possibly overlapping windows Each unit computes a weighted sum of its inputs and
passes the result through a sigmoid saturation function All units within a feature map share
the same weights Therefore each feature map can be seen as convolving the feature maps
of the previous layers with small-size kernels and passing the sum of those convolutions
through sigmoid functions Units in a feature map detect local features at all locations on
the previous layer
The first layer contains feature maps of size connected to various combinations
of the input maps through kernels The first feature map is connected to the YUV
planes of the left image the second feature map to the YUV planes of the right image and
the other feature maps to all input planes Those feature maps are binocular and
can learn filters that compare the location of features in the left and right images Because
of the weight sharing the first layer merely has free parameters kernels of size
plus biases The next layer is an averaging/subsampling layer of size whose
purpose is to reduce the spatial resolution of the feature maps so as to build invariances
to small geometric distortions of the input The subsampling ratios are horizontally and
vertically The layer contains 24 feature maps of size Each feature map is
connected to various subsests of maps in the previous layer through a total of 96 kernels of
size The layer is an averaging/subsampling layer of size with subsampling ratios The layer contains feature maps of size connected to the
layer through kernels of size full connection finally the output layer contains
two units fully-connected to the units in the layer The two outputs respectively
code for turn left and turn right commands The network has Million connections
and about trainable parameters
The bottom half of figure shows the states of the six layers of the convolutional net the
size of the input was essentially limited by the computing power of the remote
computer Athlon The network as shown runs in about per image pair on
the remote computer Including all the processing the driving system ran at a rate of
cycles per second
The system?s output is computed on a frame by frame basis with no memory of the past
and no time window Using multiple successive frames as input would seem like a good
idea since the multiple views resulting from ego-motion facilitates the segmentation and
detection of nearby obstacles Unfortunately the supervised learning approach precludes
the use of multiple frames The reason is that since the steering is fairly smooth in time
with long stable periods the current rate of turn is an excellent predictor of the next
desired steering angle But the current rate of turn is easily derived from multiple successive
frames Hence a system trained with multiple frames would merely predict a steering
angle equal to the current rate of turn as observed through the camera This would lead to
catastrophic behavior in test mode The robot would simply turn in circles
The system was trained with a stochastic gradient-based method that automatically sets the
relative step sizes of the parameters based on the local curvature of the loss surface Gradients were computed using the variant of back-propagation appropriate for convolutional
nets
Results
Two performance measurements were recorded the average loss and the percentage of
correctly classified steering angles The average loss is the sum of squared differences
between outputs produced by the system and the target outputs averaged over all samples The percentage of correctly classified steering angles measures the number of times
the predicted steering angle quantized into three bins left straight right agrees with
steering angle provided by the human driver Since the thresholds for deciding whether an
angle counted as left center or right were somewhat arbitrary the percentages cannot be
intepreted in absolute terms but merely as a relative figure of merit for comparing runs and
architectures
Figure Internal state of the convolutional net for two sample frames The top row shows
left/right image pairs extracted from the test set The light-blue bars below show the steering angle produced by the system The bottom halves show the state of the layers of the
network where each column is a layer the penultimate layer is not shown Each rectangular image is a feature map in which each pixel represents a unit activation The YUV
components of the left and right input images are in the leftmost column
With training image pairs training took 18 epochs through the training set No
significant improvements in the error rate occurred thereafter After training the error rate
was on the training set and on the test set The average loss mean-sqaured
error was on the training set and on the test set A complete training session
required about four days of CPU time on a Pentium/Xeon-based server Naturally
a classification error rate of doesn?t mean that the vehicle crashes into obstacles
of the time but merely that the prediction of the system was in a different bin
than that of the human drivers for of the frames The seemingly high error rate is
not an accurate reflection of the actual effectiveness of the robot in the field There are
several reasons for this First there may be several legitimate steering angles for a given
image pair turning left or right around an obstacle may both be valid options but our
performance measure would record one of those options as incorrect In addition many
illegitimate errors are recorded when the system starts turning at a different time than the
human driver or when the precise values of the steering angles are different enough to be
in different bins but close enough to cause the robot to avoid the obstacle Perhaps more
informative is diagram in figure It shows the steering angle produced by the system and
the steering angle provided by the human driver for frames from the test set It is
clear for the plot that only a small number of obstacles would not have been avoided by the
robot
The best performance measure is a set of actual runs through representative testing grounds
Videos of typical test runs are available at
http://www.cs.nyu.edu/?yann/research/dave/index.html
Figure shows a snapshot of the trained system in action The network was presented with
a scene that was not present in the training set This figure shows that the system can detect
obstacles and predict appropriate steering angles in the presence of back-lighting and with
wild difference between the automatics gain settings of the left and right cameras
Another visualization of the results can be seen in Figures They are snapshots of
video clips recorded from the vehicle?s cameras while the vehicle was driving itself autonomously Only one of the two camera outputs is shown here Each picture also shows
Figure The steering angle produced by the system black compared to the steering
angle provided by the human operator red line for frames from the test set Very
few obstacles would not have been avoided by the system
the steering angle produced by the system for that particular input
Conclusion
We have demonstrate the applicability of end-to-end learning methods to the task of obstacle avoidance for off-road robots
A 6-layer convolutional network was trained with massive amounts of data to emulate the
obstacle avoidance behavior of a human driver the architecture of the system allowed it
to learn low-level and high-level features that reliably predicted the bearing of traversible
areas in the visual field
The main advantage of the system is its robustness to the extreme diversity of situations
in off-road environments Its main design advantage is that it is trained from raw pixels to
directly produce steering angles The approach essentially eliminates the need for manual
calibration adjustments parameter tuning etc Furthermore the method gets around the
need to design and select an appropriate set of feature detectors as well as the need to
design robust and fast stereo algorithms
The construction of a fully autonomous driving system for ground robots will require several other components besides the purely-reactive obstacle detection and avoidance system
described here The present work is merely one component of a future system that will
include map building visual odometry spatial reasoning path finding and other strategies
for the identification of traversable areas
Acknowledgment
This project was a preliminary study for the DARPA project Learning Applied to Ground Robots
LAGR The material presented is based upon work supported by the Defense Advanced Research
Project Agency Information Processing Technology Office ARPA Order No. Program Code
No. Issued by DARPA/CMO under Contract

<<----------------------------------------------------------------------------------------------------------------------->>

title: 2770-affine-structure-from-sound.pdf

Affine Structure From Sound
Sebastian Thrun
Stanford AI Lab
Stanford University Stanford CA
Email thrun@stanford.edu
Abstract
We consider the problem of localizing a set of microphones together
with a set of external acoustic events hand claps emitted at unknown times and unknown locations We propose a solution that approximates this problem under a far field approximation defined in the
calculus of affine geometry and that relies on singular value decomposition SVD to recover the affine structure of the problem We then
define low-dimensional optimization techniques for embedding the solution into Euclidean geometry and further techniques for recovering the
locations and emission times of the acoustic events The approach is useful for the calibration of ad-hoc microphone arrays and sensor networks
Introduction
Consider a set of acoustic sensors microphones for detecting acoustic events in the environment a hand clap The structure from sound SFS problem addresses the problem of simultaneously localizing a set of sensors and a set of external acoustic events
whose locations and emission times are unknown
The SFS problem is relevant to the spatial calibration problem for microphone arrays
Classically microphone arrays are mounted on fixed brackets of known dimensions hence
there is no spatial calibration problem Ad-hoc microphone arrays however involve a person placing microphones at arbitrary locations with limited knowledge as to where they
are Today?s best practice requires a person to measure the distance between the microphones by hand and to apply algorithms such as multi-dimensional scaling MDS for
recovering their locations When sensor networks are deployed from the air manual calibration may not be an option Some techniques rely on GPS receivers Others require
a capability to emit and sense wireless radio signals or sounds which are then
used to estimate relative distances between microphones directly or indirectly as in
Unfortunately wireless signal strength is a poor estimator of range and active acoustic
and GPS localization techniques are uneconomical in that they consume energy and require additional hardware In contrast SFS relies on environmental acoustic events such
as hand claps which are not generated by the sensor network The general SFS problem
was previously treated in under the name passive localization A related paper describes a technique for incrementally localizing a microphone relative to a well-calibrated
microphone array through external sound events
In this paper the structure from sound SFS problem is defined as the simultaneous localization problem of sound sensors and acoustic events in the environment detected
by these sensors Each event occurs at an unknown time and an unknown location The
sensors are able to measure the detection times of the event We assume that the clocks
of the sensors are synchronized that events are spaced sufficiently far apart in
time to make the association between different sensors unambiguous and we also assume
absence of sound reverberation For the ease of representation the paper assumes a 2D
world although the technique is easily generalized to
Under the assumption of independent and identically distributed iid Gaussian noise
the SFS problem can be formulated as a least squares problem in a space over three types of
variables the locations of the microphones the locations of the acoustic events and their
emission times However this least squares problem is plagued by local minima and the
number of constraints is quite large
The gist of this paper transforms this optimization problem into a sequence of simpler
problems some of which can be solved optimally without the danger of getting stuck in
local minima The key transformation involves a far field approximation which presupposes that the sound sources are relatively far away from the sensors This approximation
reformulates the problem as one of recovering the incident angle of the acoustic signal
which is the same for all sensors for any fixed acoustic event The resulting optimization
problem is still non-linear however by relaxing the laws of Euclidean geometry into the
more general calculus of affine geometry the optimization problem can be solved by singular value decomposition The resulting solution is mapped back into Euclidean
space by optimizing a matrix of size which is easily carried out using gradient descent A subsequent non-linear optimization step overcomes the far field approximation
and enables the algorithm to recover locations and emission times of the defining acoustic
events Experimental results illustrate that our approach reliably solves hard SFS problems
where gradient-based techniques consistently fail
Our approach is similar in spirit to the affine solution to the structure from motion
SFM problem proposed by a seminal paper by Tomasi&Kanade which was later
extended to the non-orthographic case Like us these authors expressed the structure
finding problem using affine geometry and applied SVD for solving it SFM is of course
defined for cameras not for microphone arrays Camera measure angles whereas microphones measure range This paper establishes an affine solution to the structure from sound
problem that tends to work well in practice
Problem Definition
Setup
We are given sensors microphones located in a 2D plane We shall denote the location
of the i-th sensor by which defined the following sensor location matrix of size
xN
y1
y2
yN
We assume that the sensor array detects acoustic events Each event has as unknown coordinate and an unknown emission time The coordinate of the j-th event shall be denoted
aj bj providing us with the event location matrix A of size The emission time
of the j-th acoustic event is denoted tj resulting in the vector of length
a1
A
a2
aM
b1
b2
bM
t1
t2
tM
A and comprise the set of unknown variables In problems such as sensor calibration only is of interest In general SFS applications A and might also be of interest
Measurement Data
In SFS the variables A and are recovered from data The data establishes the
detection times of the acoustic events by the individual sensors Specifically the data
matrix is of the form
dN,M
Here each di,j denotes the detection time of acoustical event by sensor Notice that we
assume that there is no data association problem Even if all acoustic events sound alike
the correspondence between different detections is easily established as long as there exists
sufficiently long time gaps between any two sound events
The matrix is a random field induced by the laws of sound propagation without reverberation In the absence of measurement noise each di,j is the sum of the corresponding emission time tj plus the time it takes for sound to travel from aj bj to
aj
di,j tj
bj
Here denotes the norm Euclidean distance and denoted the speed of sound
Relative Formulation
Obviously we cannot recover the global coordinates of the sensors Hence without loss of
generality we define the first sensor?s location as y1 This gives us the relative
location matrix for the sensors
x3
xN
y2
y3
yN
This relative sensor location matrix is of dimension
It shall prove convenient to subtract from the arrival time di,j the arrival time
measured by the first sensor This relative arrival time is defined as di,j
In the relative arrival time the absolute emission times tj cancel out
aj
aj
tj
bj
bj
aj aj
bj
bj
We now define the matrix of relative arrival times
This matrix is of dimension
dN,M
Least Squares Formulation
The relative sensor locations and the corresponding locations of the acoustic events
A can now be recovered through the following least squares problem This optimization
seeks to identify and A so as to minimize the quadratic difference between the predicted
relative measurements and the actual measurements
aj aj
hA argmin
bj
bj
X,A
The minimum of this expression is a maximum likelihood solution for the SFS problem
under the assumption of iid Gaussian measurement noise
If emission times are of interest they are now easily recovered by the following
weighted mean
aj
di,j
bj
The minimum of is not unique This is because any solution can be rotated around
the origin of the coordinate system and mirrored through any axis intersecting the origin
This shall not concern us as we shall be content with any solution of others are then
easily generated
What is of concern however is the fact that minimizing is difficult A straw
man algorithm?which tends to work poorly in practice?involves starting with random
guesses for and A and then adjusting them in the direction of the negative gradient until
convergence As we shall show experimentally such gradient algorithms work poorly in
practice because of the large number of local minima
The Far Field Approximation
The essence of our approximation pertains to the fact that for far range acoustic events
events that are infinitely far away from the sensor array?the incoming sound wave
hits each sensor at the same incident angle Put differently the rays connecting the location
of an acoustic event aj bj with each of the perceiving sensors are approximately
parallel for all but not for all Under the far field approximation these incident angles
are entirely parallel Thus all that matters are the incident angle of the acoustic events
To derive an equation for this case it shall prove convenient to write the Euclidean
distance between a sensor and an acoustic event as a function of the incident angle This
angle is given by the four-quadrant extension of the arctan function
arctan2
bj
aj
The Euclidean distance between aj bj and can now be written as
aj
aj
cos
sin
i,j
i,j
bj
bj
For far-away points aj bj we can safely assume that all incident angles for the j-th
acoustic event are identical
Hence we substitute for in Plugging this back into this gives us the
following expression for
aj aj
bj
bj
cos sin
aj
bj
cos sin
aj
bj
This leads to the following non-linear least squares problem for the desired sensor locations
cos cos cos
hX
argmin
sin
sin
sin
The reader many notice that in this formulation of the SFS problem the locations of the
sound events aj bj have been replaced by the incident angles of the sound waves
One might think of this as the ortho-acoustic model of sound propagation analogy
to the orthographic camera model in computer vision The ortho-acoustic projection reduces the number of variables in the optimization However the argument in the quadratic
expression is still non-linear due to the non-linear trigonometric functions involved
Affine Solution for the Sensor Locations
is trivially solvable in the space of affine geometry Following in affine geometry projections can be arbitrary linear functions not just rotations and translations
Specifically let us replace the specialized matrix
cos
sin
cos
sin
cos
sin
by a general matrix of the form
This leads to the least squares problem
hX
argmin
In the noise free-case case we know that there must exist a and a for which
This suggests that the rank of should be since it is the product of a matrix of size
and a matrix of size
Further we can recover both and via singular value decomposition Specifically we know that the matrix can be decomposed as into three other matrices
and
UV
where is a matrix of size a diagonal matrix of eigenvalues of size
and a matrix of size In practice might be of higher rank because of noise or
because of violations of the far field assumption but it suffices to restrict the consideration
to the first two eigenvalues
The decomposition in 18 leads to the optimal affine solution of the SFS problem
UV
WT
and
However this solution is not yet Euclidean since might not be of the form of
Specifically is a function of angles and each row in must be of the form
cos2 sin2 Clearly this constraint is not enforced in the SVD.
However there is an easy trick for recovering a and for which this constraint is
at least approximately met The key insight is that for any invertible matrix
X0
and
CW
is equally a solution to the factorization problem in This is because
CW
The remaining search problem thus is the problem of finding an appropriate matrix for
which is of the form of This is a non-linear optimization problem but it is much
lower-dimensional than the original SFS problem it only involves parameters
Specifically we seek a for which CW minimizes
argmin
Here denotes the dot product The expression labeled evaluates to a vector of expressions of the form
Error
grad desc
@
@
SVD
SVD+grad desc
here
log?error confidence intervals
error confidence intervals
Log-error
SVD
grad desc
desc
SVD+grad
here
Figure Error and log error for three different algorithms gradient descent SVD
blue and SVD followed by gradient descent green Performance is shown for different values of
and with The plot also shows confidence bars
ground truth
gradient descent
SVD
SVD grad desc
sensors
acoustic events
Figure Typical SFS results for a simulated array of nine microphones spaced in a regular grid
surrounded by sounds arranged on a circle Ground truth Result of plain gradient descent
after convergence the dashed lines visualize the residual error Result of the SVD with sound
directions as indicated and Result of gradient descent initialized with our SVD result
The minimization in 22 is carried out through standard gradient descent It involves
only variables is of the size and each single iteration is linear in O(N
instead of the O(N constraints that define In tens of thousands of experiments
with synthetic noise-free data we find empirically that gradient descent reliably converges
to the globally optimal solution
Recovering the Acoustic Event Locations and Emission Times
With regards to the acoustic events the optimization for the far field case only yields the
incident angles In the near field setting in which the incident angles tend to differ for
different sensors it may be desirable to recover the locations A of the acoustic event and
the corresponding emission times
To determine these variables we use the vector from the far field case as mere
starting points in a subsequent gradient search The event location matrix A is initialized
by selecting points sufficiently far away along the estimated incident angle for the far field
approximation to be sound
A
Here with defined in 22 and is a multiple of the diameter of the
locations in With this initial guess for A we apply gradient descent to optimize
and finally use to recover
Experimental Results
We ran a series of simulation experiments to characterize the quality of our algorithm
especially in comparison with the obvious nonlinear least squares problem from
which it is derived graphs the residual error as a function of the number of sensors
Error
grad desc
@
@
SVD
SVD+grad desc
diameter ratio of events vs sensor array
log?error confidence intervals
error confidence intervals
Log-error
grad desc
SVD
SVD+grad desc
diameter ratio of events vs sensor array
Figure Error and log-error for three different algorithms gradient descent in red SVD
in blue and SVD followed by gradient descent in green graphed here for varying distances of the
sound events to the sensor array An error above means the reconstruction has entirely failed All
diagrams also show the confidence intervals and we set
One of our motes
used to generate the data
Optimal hand-measured
Result of gradient descent
SVD and GD
sounds
motes
Figure Results using our seven sensor motes as the sensor array and a seventh mote to generate
sound events A mote the globally optimal solution big circles compared to the handmeasures locations small circles a typical result of vanilla gradient descent and the result
of our approach all compared to the optimal solution given the noisy data
and acoustic events here Panel plots the regular error along with
confidence intervals and panel the corresponding log-error Clearly as and
increase plain gradient descent tends to diverge whereas our approach converges Each
data point in these graphs was obtained by averaging random configurations in which
sensors were sampled uniformly within an interval of sounds were placed at varying
ranges from 2m to An example outcome for a non-random configuration is shown
in This figure plots a simulated sensor array consisting of sensors with sound
sources arranged in a circle and the resulting reconstructions of our three methods
For the SVD result shown in only the directions of the incoming sounds are shown
An interesting question pertains to the effect of the far field approximation in cases
where it is clearly violated To examine the robustness of our approach we ran a series of
experiments in which we varied the diameter of the acoustic events relative to the diameter
of the sensors If this parameter is the acoustic events are emitted in the same region as
the microphones for values such as the events are far away
graphs the residual errors and log-errors The further away the acoustic events
the better our results However even for nearby events for which the far field assumption
is clearly invalid our approach generates results that are no worse than those of the plain
gradient descent technique
We also implemented our approach using a physical sensor array plots empirical
results using a microphone array comprised of seven Crossbow sensor motes one of which
is shown in Panel Panels compare the recovered structure with the one that
globally minimizes the LMS error which we obtain by running gradient descent using the
hand-measured locations as starting point Panel in shows the manually measured
locations the relatively high deviation to the LMS optimum is the result of measurement
error which is amplified by the fact that our motes are only spaced a few tens of centimeters
apart from each other the standard deviation in the timing error corresponds to a distance
of and the motes are placed between and apart Panel in
shows the solution of plain gradient descent applied to applied to and compares it
to the optimal reconstruction and Panel illustrates our solution In all plots the lines
indicate residual error This result shows that our method may work well on real-world
data that is noisy and that does not adhere to the far field assumption
Discussion
This paper considered the structure from sound problem and presented an algorithm for
solving it Our approach makes is possible to simultaneously recover the location of a
collection of microphones the locations of external acoustic events detected by these microphones and the emission times for these events By resorting to affine geometry our
approach overcomes the problem of local minima in the structure from sound problem
There remain a number of open research issues We believe the extension to is
mathematically straightforward but requires empirical validation The current approach
also fails to address reverberation problems that are common in confined space It shall
further be interesting to investigate data association problems in the SFS framework and
to develop parallel algorithms that can be implemented on sensor networks with limited
communication resources Finally of great interest should be the incomplete data case in
which individual sensors may fail to detect acoustic events?a problem studied in
Acknowledgement
The motes data was made available by Rahul Biswas which is gratefully acknowledged
We also acknowledge invaluable suggestions by three anonymous reviewers

<<----------------------------------------------------------------------------------------------------------------------->>

title: 2582-chemosensory-processing-in-a-spiking-model-of-the-olfactory-bulb-chemotopic-convergence-and-center-surround-inhibition.pdf

Chemosensory processing in a spiking
model of the olfactory bulb chemotopic
convergence and center surround
inhibition
Baranidharan Raman and Ricardo Gutierrez-Osuna
Department of Computer Science
Texas A&M University
College Station TX
barani,rgutier}@cs.tamu.edu
Abstract
This paper presents a neuromorphic model of two olfactory signalprocessing primitives chemotopic convergence of olfactory
receptor neurons and center on-off surround lateral inhibition in
the olfactory bulb A self-organizing model of receptor
convergence onto glomeruli is used to generate a spatially
organized map an olfactory image This map serves as input to a
lattice of spiking neurons with lateral connections The dynamics
of this recurrent network transforms the initial olfactory image into
a spatio-temporal pattern that evolves and stabilizes into odor and
intensity-coding attractors The model is validated using
experimental data from an array of temperature-modulated gas
sensors Our results are consistent with recent neurobiological
findings on the antennal lobe of the honeybee and the locust
In trod ction
An artificial olfactory system comprises of an array of cross-selective chemical
sensors followed by a pattern recognition engine An elegant alternative for the
processing of sensor-array signals normally performed with statistical pattern
recognition techniques involves adopting solutions from the biological olfactory
system The use of neuromorphic approaches provides an opportunity for
formulating new computational problems in machine olfaction including mixture
segmentation background suppression olfactory habituation and odor-memory
associations
A biologically inspired approach to machine olfaction involves identifying key
signal processing primitives in the olfactory pathway adapting these primitives
to account for the unique properties of chemical sensor signals and applying the
models to solving specific computational problems
The biological olfactory pathway can be divided into three general stages
olfactory epithelium where primary reception takes place olfactory bulb
where the bulk of signal processing is performed and iii olfactory cortex where
odor associations are stored A review of literature on olfactory signal processing
reveals six key primitives in the olfactory pathway that can be adapted for use in
machine olfaction These primitives are chemical transduction into a
combinatorial code by a large population of olfactory receptor neurons
chemotopic convergence of ORN axons onto glomeruli logarithmic
compression through lateral inhibition at the GL level by periglomerular
interneurons contrast enhancement through lateral inhibition of mitral
projection neurons by granule interneurons storage and association of odor
memories in the piriform cortex and bulbar modulation through cortical
feedback
This article presents a model that captures the first three abovementioned
primitives population coding chemotopic convergence and contrast enhancement
The model operates as follows First a large population of cross-selective pseudosensors is generated from an array of metal-oxide MOS gas sensors by means of
temperature modulation Next a self-organizing model of convergence is used to
cluster these pseudo-sensors according to their relative selectivity This clustering
generates an initial spatial odor map at the GL layer Finally a lattice of spiking
neurons with center on-off surround lateral connections is used to transform the GL
map into identity and intensity-specific attractors
The model is validated using a database of temperature-modulated sensor patterns
from three analytes at three concentration levels The model is shown to address the
first problem in biologically-inspired machine olfaction intensity and identity
coding of a chemical stimulus in a manner consistent with neurobiology
opi
The projection of sensory signals onto the olfactory bulb is organized such that
ORNs expressing the same receptor gene converge onto one or a few GLs This
convergence transforms the initial combinatorial code into an organized spatial
pattern an olfactory image In addition massive convergence improves the
signal to noise ratio by integrating signals from multiple receptor neurons
When incorporating this principle into machine olfaction a fundamental difference
between the artificial and biological counterparts must be overcome the input
dimensionality at the receptor/sensor level The biological olfactory system employs
a large population of ORNs over million in humans replicated from
primary receptor types whereas its artificial analogue uses a few chemical sensors
commonly one replica of up to 32 different sensor types
To bridge this gap we employ a sensor excitation technique known as temperature
modulation MOS sensors are conventionally driven in an isothermal fashion by
maintaining a constant temperature However the selectivity of these devices is a
function of the operating temperature Thus capturing the sensor response at
multiple temperatures generates a wealth of additional information as compared to
the isothermal mode of operation If the temperature is modulated slow enough
mHz the behavior of the sensor at each point in the temperature cycle can
then be treated as a pseudo-sensor and thus used to simulate a large population of
cross-selective ORNs refer to Figure
To model chemotopic convergence these temperature-modulated pseudo-sensors
referred to as ORNs in what follows must be clustered according to their
selectivity As a first approximation each ORN can be modeled by an affinity
vector consisting of the responses across a set of analytes
i1 i2 iC
where ia is the response of the ith ORN to analyte a The selectivity of this ORN
is then defined by the orientation of the affinity vector
A close look at the OB also shows that neighboring GLs respond to similar odors
Therefore we model the ORN-GL projection with a Kohonen self-organizing
map SOM In our model the SOM is trained to model the distribution of
ORNs in chemical sensitivity space defined by the affinity vector Once the
training of the SOM is completed each ORN is assigned to the closest SOM node
simulated GL in affinity space thereby forming a convergence map The response
of each GL can then be computed as
aj
Wij ORN ia
where ORN ia is the response of pseudo-sensor to analyte a Wij=1 if pseudo-sensor
converges to GL and zero otherwise and is a squashing sigmoidal function
that models saturation
This convergence model works well under the assumption that the different sensory
inputs are reasonably uncorrelated Unfortunately most gas sensors are extremely
collinear As a result this convergence model degenerates into a few dominant GLs
that capture most of the sensory activity and a large number of dormant GLs that do
not receive any projections To address this issue we employ a form of competition
known as conscience learning which incorporates a habituation mechanism to
prevent certain SOM nodes from dominating the competition In this scheme the
fraction of times that a particular SOM node wins the competition is used as a bias
to favor non-winning nodes This results in a spreading of the ORN projections to
neighboring units and therefore significantly reduces the number of dormant units
We measure the performance of the convergence mapping with the entropy across
the lattice Pi log Pi where Pi is the fraction of ORNs that project to SOM
node To compare Kohonen and conscience learning we built convergence
mappings with pseudo-sensors and GL units refer to section for
details The theoretical maximum of the entropy for this network which
corresponds to a uniform distribution is When trained with Kohonen?s
algorithm the entropy of the SOM is With conscience learning the entropy
increases to Thus conscience is an effective mechanism to improve the
spreading of ORN projections across the GL lattice
a wo
Mitral cells which synapse ORNs at the GL level transform the initial olfactory
image into a spatio-temporal code by means of lateral inhibition Two roles have
been suggested for this lateral inhibition sharpening of the molecular tuning
range of individual cells with respect to that of their corresponding ORNs
and global redistribution of activity such that the bulb-wide representation of an
odorant rather than the individual tuning ranges becomes specific and concise over
time More recently center on-off surround inhibitory connections have been
found in the OB These circuits have been suggested to perform pattern
normalization noise reduction and contrast enhancement of the spatial patterns
We model each cell using a leaky integrate-and-fire spiking neuron The
input current and change in membrane potential of a neuron are given by
I
du
dt
du
I RC
dt
Each cell receives current Iinput from ORNs and current Ilateral from lateral
connections with other cells
I input Wij ORNi
I lateral Lkj
where Wij indicates the presence/absence of a synapse between ORNi and Mj as
determined by the chemotopic mapping Lkj is the efficacy of the lateral connection
between Mk and Mj and is the post-synaptic current generated by a spike at
Mk
Esyn
is the conductance of the synapse between Mk and Mj at time is
the membrane potential of Mj at time and the subscript indicates this value
becomes zero if negative and Esyn is the reverse synaptic potential The change in
conductance of post-synaptic membrane is
dg
dt
syn
dz
norm spk
dt
syn
where and are low pass filters of the form exp(-t/?syn and exp(?t syn
respectively syn is the synaptic time constant gnorm is a normalization constant and
spk(j,t marks the occurrence of a spike in neuron at time
Vspike
spk
Vspike
Combining equations and the membrane potential can be expressed as
du I lateral I input
dt
RC
dt Vthreshold
Vspike
Vthreshold
When the membrane potential reaches Vthreshold a spike is generated and the
membrane potential is reset to Vrest Any further inputs to the neuron are ignored
during the subsequent refractory period
Following lateral interactions are modeled with a center on-off surround
matrix Lij. Each cell makes excitatory synapses to nearby cells where
is the Manhattan distance measured in the lattice and inhibitory synapses with
distant cells de<d<di through granule cells implicit in our model Excitatory
synapses are assigned uniform random weights between Inhibitory
synapses are assigned negative weights in the same interval Model parameters are
summarized in Table
Table Parameters of the OB spiking neuron lattice
Parameter
Peak synaptic conductance Gpeak
Capacitance
Resistance
Spike voltage spike
Threshold voltage Vthreshold
Synapse Reverse potential syn
Value
nF
MOhm
70 mV
mV
70 mV
Excitatory distance
Parameter
Synaptic time constants syn
Total simulation time tot
Integration time step
Refractory period ref
Number of mitral cells
Normalization constant norm
Inhibitory distance
Value
ms
ms
ms
ms
Results
The proposed model is validated on an experimental dataset containing gas sensor
signals for three analytes acetone isopropyl alcohol and ammonia at
three different concentration levels per analyte Two Figaro MOS sensors TGS
TGS were temperature modulated using a sinusoidal heater voltage
period sampling frequency The response of the two sensors to the
three analytes at the three concentration levels is shown in Figure This
response was used to generate a population of ORNs which were then
mapped onto a GL layer with units arranged as a lattice
Sensor Conductance
Iso-propyl alcohol
Sensor conductance
Acetone
Sensor
Sensor
A3
A2
A1
A1
A3
18
B3
B2
B1
B1
B2
B3
Sensor Conductance
Ammonia
A2
18
C3
C2
C1
C1
C2
Pseudo-Sensors
Concentration
C3
18
Figure Temperature modulated response to the three analytes at three
concentrations highest concentration of and initial GL maps
The sensor response to the highest concentration of each analyte was used to
generate the SOM convergence map Figure shows the initial odor map of the
three analytes following conscience learning of the SOM. These olfactory images
show that the identity of the stimulus is encoded by the spatial pattern across the
lattice whereas the intensity is encoded by the overall amplitude of this pattern
Analytes A and which induce similar responses on the MOS sensors also lead to
very similar GL maps
The GL maps are input to the lattice of spiking neurons for further processing As a
result of the dynamics induced by the recurrent connections these initial maps are
transformed into a spatio-temporal pattern Figure shows the projection of
membrane potential of the cells along their first three principal components
Three trajectories are shown per analyte which correspond to the sensor response to
the highest analyte concentration on three separate days of data collection These
results show that the spatio-temporal pattern is robust to the inherent drift of
chemical sensors The trajectories originate close to each other but slowly migrate
and converge into unique odor-specific attractors It is important to note that these
trajectories do not diverge indefinitely but in fact settle into an attractor as
illustrated by the insets in Figure
Odor
Odor
Odor A
Figure Odor-specific attractors from experimental sensor data Three trajectories
are shown per analyte corresponding to the sensor response on three separate days
These results show that the attractors are repeatable and robust to sensor drift
To illustrate the coding of identity and intensity performed by the model Figure
shows the trajectories of the three analytes at three concentrations The OB network
activity evolves to settle into an attractor where the identity of the stimulus is
encoded by the direction of the trajectory relative to the initial position and the
intensity is encoded by the length along the trajectory This emerging code is also
consistent with recent findings in neurobiology as discussed next
on
A recent study of spatio-temporal activity in projection neurons of the
honeybee antennal lobe analogous to cells in mammalian OB reveals evolution
and convergence of the network activity into odor-specific attractors Figure
shows the projection of the spatio-temporal response of the PNs along their
first three principal components These trajectories begin close to each other and
evolve over time to converge into odor specific regions These experimental results
are consistent with the attractor patterns emerging from our model Furthermore an
experimental study of odor identity and intensity coding in the locust show
hierarchical groupings of spatio-temporal PN activity according to odor identity
followed by odor intensity Figure illustrates this grouping in the activity
of PNs when exposed to three odors at five concentrations Again these results
closely resemble the grouping of attractors in our model shown in Figure
B3
B2
B1
A3
A2
PC3
A1
C1
C2
C3
PC2
PC1
Figure Identity and intensity coding using dynamic attractors
Previous studies by Pearce using a large population of optical micro-bead
chemical sensors have shown that massive convergence of sensory inputs can be
used to provide sensory hyperacuity by averaging out uncorrelated noise In
contrast the focus of our work is on the coding properties induced by chemotopic
convergence Our model produces an initial spatial pattern or olfactory image
whereby odor identity is coded by the spatial activity across the GL lattice and odor
intensity is encoded by the amplitude of this pattern Hence the bulk of the
identity/intensity coding is performed by this initial convergence primitive
Subsequent processing by a lattice of spiking neurons introduces time as an
additional coding dimension The initial spatial maps are transformed into a spatiotemporal pattern by means of center on-off surround lateral connections Excitatory
lateral connections allow the model to spread cell activity and are responsible for
moving the attractors away from their initial coordinates In contrast inhibitory
connections ensure that these trajectories eventually converge onto an attractor
rather than diverge indefinitely It is the interplay between excitatory and inhibitory
connections that allows the model to enhance the initial coding produced by the
chemotopic convergence mapping
octanol
hexanol
nonanol
isoamylacetate
Figure Odor trajectories formed by spatio-temporal activity in the honeybee
AL adapted from Identity and intensity clustering of spatio-temporal
activity in the locust AL adapted from arrows indicate the direction of
increasing concentration
At present our model employs a center on-off surround kernel that is constant
throughout the lattice Further improvements can be achieved through adaptation of
these lateral connections by means of Hebbian and anti-Hebbian learning These
extensions will allow us to investigate additional computational functions
pattern completion orthogonalization coding of mixtures in the processing of
information from chemosensor arrays
Acknowledgments
This material is based upon work supported by the National Science Foundation
under CAREER award Takao Yamanaka Alexandre PereraLluna and Agustin Gutierrez-Galvez are gratefully acknowledged for valuable
suggestions during the preparation of this manuscript

<<----------------------------------------------------------------------------------------------------------------------->>

title: 4682-multiresolution-gaussian-processes.pdf

Multiresolution Gaussian Processes
David B. Dunson
Dept of Statistical Science Duke University
dunson@stat.duke.edu
Emily B. Fox
Dept of Statistics University of Washington
ebfox@stat.washington.edu
Abstract
We propose a multiresolution Gaussian process to capture long-range nonMarkovian dependencies while allowing for abrupt changes and non-stationarity
The multiresolution GP hierarchically couples a collection of smooth GPs each
defined over an element of a random nested partition Long-range dependencies are captured by the top-level GP while the partition points define the abrupt
changes Due to the inherent conjugacy of the GPs one can analytically marginalize the GPs and compute the marginal likelihood of the observations given the partition tree This property allows for efficient inference of the partition itself for
which we employ graph-theoretic techniques We apply the multiresolution GP to
the analysis of magnetoencephalography MEG recordings of brain activity
Introduction
A key challenge in many time series applications is capturing long-range dependencies for which
Markov-based models are insufficient One method of addressing this challenge is through employing a Gaussian process with an appropriate non-band-limited covariance function However GPs typically assume smoothness properties that can blur key elements of the signal if abrupt
changes occur The Mat?ern kernel enables less smooth functions but assumes a stationary process
that does not adapt to varying levels of smoothness Likewise a changepoint or partition
model between smooth functions fails to capture long range dependencies spanning changepoints
Another long-memory process is the fractional ARIMA process Wavelet methods have also
been proposed including recently for smooth functions with discontinuities We take a fundamentally different approach based on GPs that allows direct interpretability local stationarity
iii irregular grids of observations and sharing information across related time series
As a motivating application consider magnetoencephalography MEG recordings of brain activity
in response to some word stimulus Due to the low signal-to-noise-ratio SNR regime multiple
trials are often recorded presenting a functional data analysis scenario Each trial results in a noisy
trajectory with key discontinuities after stimulus onset Although there are overall similarities
between the trials there are also key differences that occur based on various physiological phenomena as depicted in We clearly see abrupt changes as well as long-range correlations Key to
the data analysis is the ability to share information about the overall trajectory between the single
trials without forcing unrealistic smoothness assumptions on the single trials themselves
In order to capture both long-range dependencies and potential discontinuities we propose a multiresolution GP mGP that hierarchically couples a collection of smooth GPs each defined over an
element of a nested partition set The top-level GP captures a smooth global trajectory while the
partition points define abrupt changes in correlation induced by the lower-level GPs. Due to the inherent conjugacy of the GPs conditioned on the partition points the resulting function at the bottom
level is marginally GP-distributed with a partition-dependent and thus non-stationary covariance
function The correlation between any two observations and yj generated by the mGP at locations
and is a function of the distance and which partition sets contain both and
In a standard regression setting the marginal GP structure of the mGP allows us to compute the
marginal likelihood of the data conditioned on the partition enabling efficient inference of the partition itself We integrate over the hierarchy of GPs and only sample the partition points For our
Observations
A0
Time
Figure mGP on a balanced binary tree
Figure For sensor and word house Left Data from three partition Parent function is split by A1
trials Middle Empirical correlation matrix from trials Right A2 Recursing down the tree each
Hierarchical segmentation produced by recursive minimization of partition has a GP with mean given by its
parent function restricted to that set
normalized cut objective with color indicating tree level
proposal distribution we borrow the graph-theoretic idea of normalized cuts often used in image
segmentation Our inferences integrate over the partition tree allowing blurring of discontinuities
and producing functions which can appear smooth when discontinuities are not present in the data
Background
A GP provides a distribution on real-valued functions with the property that the function
evaluated at any finite collection of points is jointly Gaussian The GP denoted GP(m is uniquely
defined by its mean function and covariance function That is GP(m if and only if for
all and Nn with m(xn and
K]ij c(xi The properties continuity smoothness periodicity etc of functions
drawn from a given GP are determined by the covariance function The squared exponential kernel
leads to smooth functions Here is a scale hyperparameter and
is the bandwidth determining the extent of the correlation in over See for further details
Multiresolution Gaussian Process Formulation
Our interest is in modeling a function that is locally smooth exhibits long-range correlations
corr(g(x for relatively large and iii has abrupt changes We begin by
modeling a single function but with a specification that readily lends itself to modeling a collection
of functions that share a common global trajectory as explored in Sec.
Generative Model Assume a set of noisy observations yn of the function
at locations
g(xi
We hierarchically define as follows Let A A1 be a nested partition or tree
for some Furthermore
partition of with A0 A?i A?i A?j and A?i
assume that each A?i is a contiguous subset of depicts a balanced binary tree partition We
define a global parent function on A0 as c0 This function captures the overall shape
of and its long-range dependencies Then over each partition set A?i we independently draw
GP(f c?i
That is the mean of the GP is given by the parent function restricted to the current partition set Due
to the conditional independence of these draws can have discontinuities at the partition points
However due to the coupling of GPs through the tree will maintain aspects of the shape of
Finally we set A pictorial representation of the mGP is shown in
We can equivalently represent the mGP as an additive GP model c?i
Covariance Function We assume a squared exponential kernel c?i d?i
encouraging local smoothness over each partition set Ai We focus on di with
for finite variance regardless of tree depth and additionally encouraging lower levels to vary less from
their parent function providing regularization and robustness to the choice of L.
We typically assume bandwidths so that each child function is locally as smooth as
its parent One can think of this formulation as akin to a fractal process zooming in on any partition
the locally defined function has the same smoothness as that of its parent over the larger partition
Thus lower levels encode finer-resolution details We denote the covariance hyperparameters as
and omit the dependency in conditional distributions for notational simplicity
See the Supplementary Material for discussion of other possible covariance specifications
Induced Marginal GP
The conditional independencies of our mGP imply that
p(g A p(f
p(f A df
Due to the inherent conjugacy of the GPs one can analytically marginalize the hierarchy of GPs
conditioned on the partition tree A yielding
A c?A
c?A
XX
c?i IA?i
Here IA?i if A?i and otherwise provides an interpretation of the mGP
as a marginally partition-dependent GP where the partition A defines the discontinuities in the
covariance function c?A The covariance function encodes local smoothness of and discontinuities
at the partition points Note that c?A defines a non-stationary covariance function
The correlation between any two observations and yj at locations and generated as in
is a function of how many tree levels contain both and and the distance Let ri
index the partition set such that and Lij the lowest level for which and fall into the
same set the largest such that ri rj Then for
PLij
PLij
cri
corr(yi yj A
cr xk xk
where the second equality follows from assuming the previously described kernels An example
correlation matrix is shown in determines the width of the bands while controls the
contribution of level Since is square summable lower levels are less influential
Marginal Likelihood Based on a vector of observations yn at locations
we can restrict our attention to evaluating the GPs at Let
By definition of the GP we have
c?r A?r
A
otherwise
The level-specific covariance matrix is block-diagonal with structure determined by the levelspecific partition A Observations are generated as In Recalling
standard results yield
A In
A
This result can also be derived from the induced mGP of We see that the marginal likelihood
p(y A has a closed form Alternatively one can condition on the GP at any level
A In
A key advantage of the mGP is the conditional conjugacy of the latent GPs that allows us to compute
the likelihood of the data simply conditioned on the hierarchical partition A This fact
is fundamental to the efficiency of the partition inference procedure described in Sec.
Multiple Trials
In many applications such as the motivating MEG application one has a collection of observations
of an underlying signal To capture the common global trajectory of these trials while still allowing
for trial-specific variability we model each as a realization from an mGP with a shared parent function One could trivially allow for alternative structures of hierarchical sharing beyond if an
application warranted For simplicity and due to the motivating MEG application we additionally
assume shared changepoints between the trials though this assumption can also be relaxed
Observations
Observations
Time
Time
Figure Three trials and all trials of data generated from a 5-level mGP with a shared parent
function and partition A randomly sampled True correlation matrix Empirical correlation matrix
from trials Hierarchical segmentation produced by recursive minimization of normalized cut objective
Generative Model For each trial yn we model
with generated from a trial-specific GP hierarchy
with shared parent Again alternative structures can be considered From with
and exploiting the independence of independently for each
A In
Note that with our GP-based formulation we need not assume coincident observation locations
between the trials However for simplicity of exposition we consider shared locations
We compactly denote the covariance by In
Simulated data generated from a 5-level mGP with shared and A are shown in The sample
correlation matrix is also shown Compare with the MEG data of Both the qualitative structure of the raw time series as well as blockiness of the correlation matrix have striking similarities
Posterior Global Trajectory and Predictions Based on a set of trials it is of
interest to infer the posterior of Standard Gaussian conjugacy results imply that
K0
p(f A K0
where
Likewise the predictive distribution of data from a new trial is
A A)p(f A)df
K0
K0
Marginal Likelihood Since the set of trials are generated from a shared
parent function the marginal likelihood does not decompose over trials Instead
exp
p(Y A
See the Supplementary Material for a derivation One can easily verify that the above simplifies to
the marginal likelihood of when
Inference of the Hierarchical Partition
In the formulation so far we have assumed that the hierarchical partition A is given A key question
is to infer the partition from the data Assume that we have prior on the hierarchical partition
Based on the fact that we can analytically compute p(Y we can use importance sampling or
independence chain Metropolis Hastings to draw samples from the posterior p(A
In what follows we assume a balanced binary tree for A. See the Supplementary Material for a
discussion of how unbalanced trees can be considered via modifications to the covariance hyperparameter specification or by considering alternative priors such as the Mondrian process
Partition Prior We consider a prior solely on the partition points rather than
taking tree level into account as well Because of our time-series
analysis focus we assume
We define a distribution on and specify zi Generatively one can think of
drawing partition points from and deterministically forming a balanced binary tree
A from these For multidimensional one could use Voronoi tessellation and graph matching to
build the tree from the randomly selected zi Such a prior allows for trivial specification of a uniform
distribution on A simply taking uniform on or for eliciting prior information on changepoints
such as based on physiological information for the MEG data Eliciting such information in a leveldependent setup is not straightforward Also despite common deployment taking the partition point
at level as uniformly distributed over the parent set
yields high mass on A with small A?i
This property is undesirable because it leads to trees with highly unbalanced partitions
Our resulting inferences perform Bayesian model averaging over trees As such even though we
specify a prior on partitions with changepoints the resulting functions can appear to
adaptively use fewer by averaging over the uncertainty in the discontinuity location
Partition Proposal Although stochastic tree search algorithms tend to be inefficient in general
we can harness the well-defined correlation structure associated with a given hierarchical partition
to much more efficiently search the tree space One can think of every observed location as a
node in a graph with edge weights between and defined by the magnitude of the correlation of
and yj Based on this interpretation the partition points of A correspond to graph cuts that bisect
small edge weights as graphically depicted in As such we seek a method for hierarchically
cutting a graph Given a cost matrix with elements wuv defined for all pairs of nodes in a set
the normalized cut metric for partitioning into disjoint sets A and is given by
ncut(A cut(A assoc(A assoc(B
where cut(A u?A,v?B wuv and assoc(A u?A,v?V wuv Typically the cut point
is selected as the minimum of the metric ncut(A computed over all possible subsets A and B.
The normalized cut metric balances between the cost of edge weights cut and the connectivity of the
cut component thus avoiding cuts that separate small sets shows an example of applying a
greedy normalized cuts algorithm recursively minimizing ncut(A to MEG data
Instead of deterministically selecting cut points we employ the
cut
cut
cut
normalized cut objective as a proposal distribution Let the cost
matrix be the absolute value of the empirical correlation matrix
computed from trials Due to the
natural ordering of our locations the algorithm is
TIME
straightforwardly implemented We step down the hierarchy first
Figure Illustration of cutpoints
proposing a cut of A0 into with probability
dividing contiguous segments at
A2 ncut(A1 A2
points of low correlation
At level each A?i is partitioned via a normalized cut proposal based on the submatrix of corresponding to the locations A?i The probability of any partition A under the specified proposal
distribution is simply computed as the product of the sequence of conditional probabilities of each
cut This procedure generates cut points only at the observed locations More formally the
partition point in is proposed as uniformly distributed between and Extensions to multidimensional rely on spectral clustering algorithms based on the graph Laplacian
Markov Chain Monte Carlo An importance sampler draws hierarchical partitions
with the proposal distribution defined as above and then weights the samples by
to obtain posterior draws Such an approach is naively parallelizable and thus amenable to
efficient computations though the effective sample size may be low if does not adequately match
the posterior p(A Alternatively a straightforward independence chain Metropolis Hastings
algorithm Supplementary Material is defined by iteratively proposing A which is accepted
with probability min{r(A where A is a previous sample of a hierarchical partition and
A p(Y A
The tailoring of the proposal distribution to this application based on normalized cuts dramatically
aids in improving the acceptance rate relative to more naive tree proposals However the acceptance
rate tends to decrease as higher posterior probability partitions A are discovered especially for trees
with many levels and large input spaces for which the search space is larger
One benefit of the MCMC approach over importance sampling is the ability to include more intricate
tree proposals to increase efficiency We choose to interleave both local and global tree proposals At
each iteration we first randomly select a node in the tree a partition set A?i and then propose a
new sequence of cuts for all children of this node When the root node is selected corresponding to
A0 the proposal is equivalent to the global proposals previously considered We adapt the proposal
distribution for node selection to encourage more global searches at first and then shift towards a
greater balance between local and global searches as the sampling progresses Sequential Monte
Carlo methods can also be considered with particles generated as global proposals
Computational Complexity The per iteration complexity is equivalent to a typical likelihood evaluation under a GP prior Using dynamic programming the cost associated with the normalized cuts proposal is Standard techniques for more efficient GP computations are
readily applicable as well as extensions that harness the additive block structure of the covariance
Related Work
Various aspects of the mGP have similarities to other models proposed in the literature that primarily
fall into two main categories GPs defined over a partitioned input space and collections of
GPs defined at tree nodes The treed GP captures non-stationarities by defining independent GPs
at the leaves of a Bayesian CART-partitioned input space The related approach of assumes
a Voronoi tessellation For time series examines online inference of changepoints with GPs
modeling the data within each segment These methods capture abrupt changes but do not allow for
long-range dependencies spanning changepoints nor a functional data hierarchical structure both
inherent to our multiresolution perspective A main motivation of the treed GP is the resulting
computational speed-ups of an independently partitioned GP. A two-level hierarchical GP also aimed
at computational efficiency is considered by where the top-level GP is defined at a coarser scale
and provides a piece-wise constant mean for lower-level GPs on a pre-partitioned input space
consider covariance functions defined on a phylogenetic tree such that the covariance between function-valued traits depends on both their spatial distance and evolutionary time spanned
via a common ancestor Here the tree defines the strength and structure of sharing between a collection of functions rather than abrupt changes within the function The Bayesian rose tree of
considers a mixture of GP experts as in but using Bayesian hierarchical clustering with
arbitrary branching structure in place of a Dirichlet process mixture Such an approach is fundamentally different from the mGP each GP is defined over the entire input space data result from a
GP mixture and input points are not necessarily spatially clustered Alternatively multiscale processes have a long history the variables define a Markov process on a typically balanced
binary tree and higher-level nodes capture coarser level information about the process In contrast
the higher level nodes in the mGP share the same temporal resolution and only vary in smoothness
At a high level the mGP differs from previous GP-based tree models in that the nodes of our tree
represent GPs over a contiguous subset of the input space constrained in a hierarchical fashion
Thus the mGP combines ideas of GP-based tree models and GP-based partition models
As presented in Sec. one can formulate an mGP as an additive GP where each GP in the sum
decomposes independently over the level-specific partition of the input space The additive GPs
of instead focus on coping with multivariate inputs in a similar vain to hierarchical kernel learning thus addressing an inherently different task
Results
Synthetic Experiments
To assess our ability to infer a hierarchical partition via the proposed MCMC sampler we generated
trials of length from a 5-level mGP with a shared parent function The hyperparameters
were set to d0 for with d0 The
data are shown in along with the empirical correlation matrix that is used as the cost matrix
for the normalized cuts proposals
For inference we set
and
where
is the average timespecific sample variance was as in the simulation The hyperparameter mismatch demonstrates
mGP
hGP
GP
Iteration
Heldout Log Likelihood
estimated(f0 f0
Log Likelihood
Time
hG
Figure For the data of true and MAP partitions Trace plots of log likelihood versus
MCMC iteration for chains Log likelihood under the true partition cyan and minimized normalized cut
partition of magenta are also shown Errors between posterior mean and true for GP hGP and
mGP Predictive log likelihood of heldout sequences for GP hGP and mGP with
some robustness to mispecification For a uniform prior independent MCMC chains were
run for iterations thinned by The first iterations used pure global tree searches the
sampler was then tempered to uniform node proposals The effects of this choice are apparent in
the likelihood plot of which also displays the true hierarchical partition and MAP estimate
Compare to the normalized cuts partition of especially at the important level cut The full
simulation study took less than minutes to run on a single GHz Intel Core i7 processor
To assess sensitivity to the choice of we compare the predictive log-likelihood of heldout test
sequences under an mGP with and levels As shown in there is a clear gain
going from to levels However overestimating has minimal influence on predictive likelihood
since lower tree levels capture finer details and have less overall effect We also compare to a single
GP and a 2-level hierarchical GP hGP Sec. For a direct comparison both use squared
exponential kernels Hyperparameters were set as in the mGP for the top-level GP. The total variance
was also matched with the GP taking this as noise and the hGP splitting between level and noise
In addition to better predictive performance shows the mGP?s improved estimation of
MEG Analysis
We analyzed magnetoencephalography MEG recordings of neuronal activity collected from a helmet with gradiometers distributed over locations around the head The gradiometers measure
the spatial gradient of the magnetic activity in Teslas per meter Since the firings of neurons in the brain only induce a weak magnetic field outside of the skull the signal-to-noise ratio of
the MEG data is very low and typically multiple recordings or trials of a given task are collected
Our MEG data was recorded while a subject viewed stimuli describing concrete nouns both
the written noun and a representative line drawing with interleaved trials per word See the
Supplementary Material for further details on the data and our analyses presented herein
Efficient sharing of information between the single trials is important for tasks such as word classification A key insight of was the importance of capturing the time-varying correlations
between MEG sensors for performing classification However the formulation still necessitates a
mean model propose a 2-level hierarchical GP a parent GP captures the common global
trajectory as in the mGP and each trial-specific GP is centered about the entire parent function1
This formulation maintains global smoothness at the individual trial level The mGP instead models the trial-specific variability with a multi-level tree of GPs defined as deviations from the parent
function over local partitions allowing for abrupt changes relative to the smooth global trajectory
For our analyses we consider the words associated with the building and tool categories shown
in Independently for each of the words and sensors we trained a 5-level mGP
using randomly selected trials as training data and the remaining for testing Each trial was
of length We ran independent MCMC chains for iterations with both global and
local tree searches We discarded the first samples as burn-in and thinned by The mGP
hyperparameters were set exactly as in the simulated study of Sec. for structure learning and
then optimized over a grid to maximize the marginal likelihood of the training data
We compare the predictive performance of the mGP in terms of MSE of heldout segments relative to
a GP and hGP each with similarly optimized hyperparameters The predictive mean conditioned on
data up to the heldout time is straightforwardly derived from For the mGP the calculation is
averaged over the posterior samples of A. displays the MSEs decomposed by cortical region
The model of uses an hGP in a latent space The mGP could be similarly deployed
Conditioning Point
Time sec
Conditioning Point
MLE
hGP
mGP
Heldout Log Likelihood
fm
Visual
Frontal
Parietal
Temporal
Observations
Decrease in MSE hGP
Decrease in MSE GP
Visual
Frontal
Parietal
Temporal
Figure Per-lobe comparison of mGP to GP and hGP For various values of decrease in predictive
MSE of heldout conditioned on
and training sequences For a visual cortex sensor and
word hammer plots of test data empirical mean and hGP and mGP predictive mean for entire heldout
Boxplots of predictive log likelihood of heldout for the mGP and wavelet-based method of
The results clearly indicate that the mGP consistently better captures the features of the data and particularly for
sensors with large abrupt changes such as in the visual
cortex The heldout trials for a visual cortex sensor are
displayed in Relative to the hGP the mGP
much better tracks the early dip in activity right after the
visual stimulus onset The posterior distribution of inferred changepoints at level also broken down
by cortical region are displayed in As expected
the visual cortex has the earliest changepoints Similar
trends are seen in the parietal lobe that handles perception and sensory integration The temporal lobe which
is key in semantic processing has changepoints occurring later These results concur with the findings of
semantic processing starts between and ms and
word length visual feature is decoded most accurately
very near the standard response time
Visual
Frontal
igloo
house
church
apartment
barn
hammer
saw
screwdriver
pliers
chisel
Time sec
Parietal
Time sec
Temporal
igloo
house
church
apartment
barn
hammer
saw
screwdriver
pliers
chisel
Time sec
Time sec
Figure Inferred changepoints at level
aggregated over sensors within each lobe
visual top-left frontal top-right parietal
bottom-left and temporal bottom-right
We also compare our predictive performance to that of the wavelet-based functional mixed model
wfmm of The wfmm has become a standard approach for functional data analysis since it
allows for spiky trajectories and efficient sharing of information between trials One limitation however is the restriction to a regular grid of observations The wfmm enables analysis in a multivariate
setting but for a direct comparison we simply apply the wfmm to each word and sensor independently shows boxplots of the predictive heldout log likelihood of the test trials under the
mGP and wfmm The results are over heldout trials sensors and words In addition to the
easier interpretability of the mGP the predictive performance also exceeds that of the wfmm
Discussion
The mGP provides a flexible framework for characterizing the dependence structure of real data
such as the examined MEG recordings capturing certain features more accurately than previous
models In particular the mGP provides a hierarchical functional data analysis framework for modeling strong locally smooth sharing of information global long-range correlations and iii
abrupt changes The simplicity of the mGP formulation enables further theoretical analysis for
example combining posterior consistency results from changepoint analysis with those for GPs.
Although we focused on univariate time series analysis our formulation is amenable to multivariate functional data analysis extensions one can naturally accommodate hierarchical dependence
structures through partial sharing of parents in the tree or possibly via mGP factor models
There are many interesting questions relating to the proposed covariance function Our fractal specification represents a particular choice to avoid over-parameterization although alternatives could
be considered For hyperparameter inference we anticipate that joint sampling with the partition
would mix poorly and consider it a topic for future exploration Another interesting topic is to
explore proposals for more general tree structures We believe that the proposed mGP represents a
powerful broadly applicable new framework for non-stationary analyses especially in a functional
data analysis setting and sets the foundation for many interesting possible extensions
Acknowledgments
The authors thank Alona Fyshe Gustavo Sudre and Tom Mitchell for their help with data acquisition preprocessing and useful suggestions This work was supported in part by AFOSR Grant and the
National Institute of Environmental Health Sciences NIEHS of the NIH under Grant

<<----------------------------------------------------------------------------------------------------------------------->>

title: 2034-receptive-field-structure-of-flow-detectors-for-heading-perception.pdf

Receptive field structure of flow detectors
for heading perception
Jaap A. intema
Dept Zoology Neurobiology
Ruhr University Bochum Germany
beintema@neurobiologie.ruhr-uni-bochum.de
Albert V. van den Berg
Dept of Neuro-ethology Helmholtz Institute
Utrecht University The Netherlands
a vandenberg@bio.uu.nl
Markus Lappe
Dept Zoology Neurobiology
Ruhr University Bochum Germany
lappe@neurobiologie ruhr-uni-bochum.de
Abstract
Observer translation relative to the world creates image flow that
expands from the observer's direction of translation heading from
which the observer can recover heading direction Yet the image
flow is often more complex depending on rotation of the eye scene
layout and translation velocity A number of models have
been proposed on how the human visual system extracts heading
from flow in a neurophysiologic ally plausible way These models
represent heading by a set of neurons that respond to large image
flow patterns and receive input from motion sensed at different image locations We analysed these models to determine the exact
receptive field of these heading detectors We find most models
predict that contrary to widespread believe the contribut ing motion sensors have a preferred motion directed circularly rather than
radially around the detector's preferred heading Moreover the results suggest to look for more refined structure within the circular
flow such as bi-circularity or local motion-opponency
Introduction
The image flow can be considerably more complicated than merely an expanding
pattern of motion vectors centered on the heading direction Flow caused
by eye rotation causes the center of flow to be displaced compare 1a
and The effect of rotation depends on the ratio ofrotation and translation speed
A
Translational flow
Combined flow
Rotational flow
I
Figure Flow during observer translation through a 3D-cloud of dots headed
towards the left during observer rotation about the vertical towards the
right and during the combination of both
Also since the image motions caused by translation depend on point distance and
the image motions caused by rotation do not the combined movement results in flow
that is no longer purely expanding for scenes containing depth differences
Heading detection can therefore not rely on a simple extrapolation mechanism that
determines the point of intersection of motion vectors
A number of physiologically-based models have been proposed on how the
visual system might arrive at a representation of heading from flow that is insensit ive to parameters other than heading direction These models assume heading is
encoded by a set of units that each respond best to a specific pattern of flow that
matches their preferred heading Such units resemble neurons found in monkey
brain area MST. MST cells have large receptive fields typically covering one
quart or more of the visual field and receive input from several local motion sensors in brain area MT. The receptive field of MST neurons may thus be defined as
the preferred location speed and direction of all input local motion sensors Little
is known yet about the RF structure of MST neurons We looked for similarities
between current models at the level of the RF structure First we explain the RF
structure of units in the velocity gain model because this model makes clear assumptions on the RF structure Next we we show the results of reconstructing RF
structure of units in the population model[2 Finally we analyse the RF structure
of the template model[3 and motion-opponency model[4
Velocity gain field model
The velocity gain field model[l is based on flow templates A flow template as
introduced by Perrone and Stone[3 is a unit that evaluates the evidence that the
flow fits the unit preferred flow field by summing the responses of local motion
sensors outputs Heading is then represented by the preferred heading direction of
the most active template(s The velocity gain field model[l is different from Perrone and Stone's template model[2 in the way it acquires invariance for translation
speed point distances and eye rotation Whereas the template model requires a
different template for each possible combination of heading direction and rotation
he velocity gain field model obtains rotation invariance using far less templates by
exploiting eye rotation velocity signals
The general scheme applied in the velocity gain field model is as follows In a set
of flow templates each tuned to pure expansion with specific preferred heading
A Circular component
Radial component
Jr
Figure The heading-centered circular and radial component of the flow
during combined translation and rotation as in
the templates would change their activity during eye rotation Simply subtracting
the rotation velocity signal for each flow template would not suffice to compensate
because each template is differently affected by rotational flow However each
flow template can become approximately rotation-invariant by subtracting a gain
field activity that is a multiplication of the eye velocity with a derivative template
activity 8R that is specific for each flow template The latter reflects the change
in flow template activity given a change in rotational flow Such derivative
template 8R can be constructed from the activity difference of two templates
tuned to the same heading but opposite rotation Thus in the velocity gain field
model templates tuned to heading direction and a component of rotation play an
important role
To further appreciate the idea behind the RF structure in the velocity gain field
model note that the retinal flow can be split into a circular and radial component
centered on the heading point Translation at different speeds or through
a different 3D environment will alter the radial component only The circular component contains a rotational component of flow but does not change with point
distances or translational speed This observation lead to the assumption implemented in the velocity gain field model that templates should only measure the flow
along circles centered on the point of preferred heading
An example of the RF structure of a typical unit in the velocity gain field model
tuned to heading and rightward rotation is shown in This circular RF structure strongly reduces sensitivity to variations in depth structure or the translational
speed while the template's tuning to heading direction is preserved because its preferred structure is centered on its preferred heading direction Interestingly the
RF structure of the typical rotation-tuned heading units is bi-circular because the
direction of circular flow is opponent in the hemifields to either side of an axis
this case the horizontal axis through the heading point Moreover the structure
contains a gradient in magnitude along the circle decreasing towards the horizontal
axis
I\.
I\.
I\.
It
I
It
Of
rJ
Figure Bi-circular RF structure of a typical unit in the velocity gain field model
tuned to leftward heading and simultaneous rightward rotation about the vertical
Individual vectors show the preferred direction and velocity of the input motion
sensors
Population model
The population model derives a representation of heading direction that is invariant to the other flow parameters using a totally different approach This model
does not presume an explicit RF structure Instead the connections strengths and
preferred directions of local motion inputs to heading-specific flow units are computed according to an optimizing algorithm[5 We here present the results obtained
for a restricted version of the model in which eye rotation is assumed to be limited
to pursuit that keeps the eye fixated on a stationary point in the scene during the
observer translation Specifically we investigated whether a circular or bi-circular
RF structure as predicted by the velocity gain model emerges in the population
model
The population model is an implementation of the subspace algorithm by
Heeger and Jepson into a neural network The subspace algorithm computes a
residual function R(T for a range of possible preferred heading directions The
residual function is minimized when flow vectors measured at image locations
described as one array are perpendicular to the vectors hat form columns of a
matrix This matrix is computed from the preferred translation vector
and the image locations Thus by finding the matrix that minimizes the
residue the algorithm has solved the heading irrespective of the 3D-rotation vector
unknown depths of points and translation speed
To implement the subspace algorithm in a neurophysiologically plausible way the
population model assumes two layers of units The first MT-like layer contains local
motion sensors that fire linearly with speed and have cosine-like direction tuning
These sensors connect to units in the second MST-like layer The activity in a 2nd
layer unit with specific preferred heading represents the likelihood that the
residual function is zero The connection strengths are determined by the
matrix As not to have too many motion inputs per 2nd layer unit the residual
function R(T is partitioned into smaller sub residues that take only a few motion
inputs The likelihood for a specific heading is hen given by the sum of responses
in a population with same preferred heading
Given the image locations and the preferred heading one can reconstruct the RF
structure for 2nd layer units with the same preferred heading The preferred motion
inputs to a second layer unit are given by vectors hat make up each column of
Hereby he vector direction represents the preferred motion direction
A
I
Figure Examples of receptive field structure of a population that encodes heading
towards the left circle Five pairs of MT-like sensors where the motion
sensors of each pair are at the same image location or at image locations
one quarter of a cycle apart Distribution of multiple pairs leading to bi-circular
pattern
and the vector magnitude represents the strength of the synaptic connection The
matrix is computed from the orthogonal complement of a
matrix C(Tj On the assumption that only fixational eye movements occur the
matrix reduces to Given only two flow vector inputs the
matrix reduces to one column of length The orthogonal complement
of this matrix was solved in Mathematica by first computing the nullspace of
the inverse matrix of and then constructing an orthonormal basis for it using
Gram-Schmidt orthogonalisation We computed the orientation and magnitude of
the two MT-inputs analytically Instead of giving the mathematics we here describe
the main results
Circularity
Independent of the spatial arrangement of the two MT-inputs to a 2nd-layer unit
their preferred motions turned out to be always directed along a circle centered on
the preferred heading point shows examples of the circular RF structures
for different distributions of motion pairs that code for the same heading direction
Motion-opponency
For pairs of motion sensors at overlapping locations the vectors of each pair always
turned out to be opponent and of equal magnitude For pairs of spatially
separated motion sensors the preferred magnitude and direction of the two motion
inputs depend on their location with respect to the hemispheres divided by the line
through heading and fixation point We find that preferred motion directions are
opponent if the pair is located within the same hemifield but uni-directional if the
pair is split across the two hemifields as in
Bi-circularity
Interestingly if pairs of motion sensors are split across hemi fields with partners at
image locations 90 rotated about the heading point a magnitude gradient appears
in the RF structure Thus with these pairs a bi-circular RF structure can
be constructed similar to units tuned to rotation about the vertical in the velocity
gain field model compare with
Note that the bi-circular RF structures do differ since the axis along which the
largest magnitude occurs is horizontal for the population model and vertical for the
velocity gain field model The RF structure of the population model unit resembles
a velocity gain field unit tuned to rotation about the horizontal axis implying a
Adapted from Perrone and Stone
A
Effective RF structure
Direction and speed
tuned motion sensors
Figure Adapted from Perrone and Stone Each detector sums the
responses of the most active sensor at each location This most active motion
sensor is selected from a pool of sensors tuned to different depth planes Cb
etc These vectors are the vector sums of preferred rotation component Rand
translational components Ta Tb etc Effective RF structure
large sensitivity to such rotation This however does not conflict with the expected
performance of the population model Because in this restricted version rotation
invariance is expected only for rotation that keeps the point of interest in the center
of the image plane this case rotation about the vertical because heading is leftward units are likely to be sensitive to rotation about the horizontal and torsional
axis
Template model
The template model and the velocity gain field model differ in how invariance for
translation velocities depth structure and eye rotation is obtained Here we investigate whether this difference affects the predicted RF structure In the template
model of Perrone and Stone a template invariant to translation velocity or depth
structure is obtained by summing the responses of the most active sensor at each
image location This most active sensor is selected from a collection of motion sensors each tuned to a different ego-translation speed depth plane but with the
same preferred ego-rotation and heading direction Given a large range of
depth planes it follows that a different radial component of motion will stimulate
another sensor maximally but that activity nevertheless remains the same The
contributing response will change only due to a component of motion along a circle
centered on the heading such as is the case when heading direction or rotation
is varied Thus the contributing response will always be from the motion sensor
oriented along the circle around the template's preferred heading Effectively this
leads to a bi-circular RF structure for units tuned to heading and rotation
Motion-opponency model
Royden[4 proposed that the effect of rotation is removed at local motion detection
level before the motion signals are received by flow detectors This is achieved by
MT-like sensors that compute the difference vector between spatially neighbouring
motion vectors Such difference vector will always be oriented along lines intersecting at the heading point Thus the resulting input to flow detectors will
be oriented radially Indeed Royden's results[4 show that the preferred directions
of the operators with the largest response will be radially not circularly oriented
A
Translational flow
Rotational flow
Figure Motion parallax the difference vector between locally neighbouring motion vectors For translation flow the difference vector will be oriented along
line through the heading point whereas for rotational flow the difference vector
vanishes compare vectors within square
Summary and Discussion
We showed that a circular RF structure such as proposed by the velocity gain field
model[l is also found in the population model[2 and is effectively present in the
template model[3 as well Only the motion-opponent model prefers radial RF
structures Furthermore we find that under certain restrictions the population
model reveals local motion-opponency and bi-circularity properties that can be
found in the other models as well
A circular RF structure turns out to be a prominent property in three models
This supports the counterintuitive but computationally sensible idea that it is not
the radial flow structure but the structure perpendicular to it that contributes
to the response of heading-sensitive units in the human brain Studies on area
MST cells not only report selectivity for expanding motion patterns but also a
significant proportion of cells that are selective to rotation patterns These
models could explain why cells respond so well to circular motion in particular to
the high rotation speeds up to about deg/s not experienced in daily life
This model study suggests that selectivity for circular flow has a direct link to
heading detection mechanisms It also suggests that testing selectivity for expanding
motion might be a bad indicator for determining a cell's preferred heading This
point has been noted before as MST seems to be systematically tuned to the focus
of rotation exactly like model neurons
Little is still known about the receptive field structure of MST cells So far the
receptive field structure of MST cells has only been roughly probed and the
results neither support a radial nor a circular structure Also so far only uni-circular
motion has been tested Our analyses points out that it would be worthwhile to
look for more refined circular structure such as local motion-opponency Local
motion opponency has already been found in area MT where some cells respond
only if different parts of their receptive field are stimulated with different motion
Another promising structure to look for would be bi-circularity with gradients
in magnitude of preferred motion along the circles
Acknowledgments
Supported by the German Science Foundation and the German Federal Ministry of
Education and Research

<<----------------------------------------------------------------------------------------------------------------------->>

title: 2996-distributed-inference-in-dynamical-systems.pdf

Distributed Inference in Dynamical Systems
Stanislav Funiak Carlos Guestrin
Carnegie Mellon University
Mark Paskin
Google
Rahul Sukthankar
Intel Research
Abstract
We present a robust distributed algorithm for approximate probabilistic inference
in dynamical systems such as sensor networks and teams of mobile robots Using
assumed density filtering the network nodes maintain a tractable representation
of the belief state in a distributed fashion At each time step the nodes coordinate
to condition this distribution on the observations made throughout the network
and to advance this estimate to the next time step In addition we identify a
significant challenge for probabilistic inference in dynamical systems message
losses or network partitions can cause nodes to have inconsistent beliefs about the
current state of the system We address this problem by developing distributed
algorithms that guarantee that nodes will reach an informative consistent distribution when communication is re-established We present a suite of experimental
results on real-world sensor data for two real sensor network deployments one
with cameras and another with 54 temperature sensors
Introduction
Large-scale networks of sensing devices have become increasingly pervasive with applications
ranging from sensor networks and mobile robot teams to emergency response systems Often nodes
in these networks need to perform probabilistic dynamic inference to combine a sequence of local
noisy observations into a global joint estimate of the system state For example robots in a team
may combine local laser range scans collected over time to obtain a global map of the environment
nodes in a camera network may combine a set of image sequences to recognize moving objects in a
heavily cluttered scene A simple approach to probabilistic dynamic inference is to collect the data
to a central location where the processing is performed Yet collecting all the observations is often
impractical in large networks especially if the nodes have a limited supply of energy and communicate over a wireless network Instead the nodes need to collaborate to solve the inference task
in a distributed manner Such distributed inference techniques are also necessary in online control
applications where nodes of the network need estimates of the state in order to make decisions
Probabilistic dynamic inference can often be efficiently solved when all the processing is performed centrally For example in linear systems with Gaussian noise the inference tasks can be
solved in a closed form with a Kalman Filter for large systems assumed density filtering can
often be used to approximate the filtered estimate with a tractable distribution Unfortunately distributed dynamic inference is substantially more challenging Since the observations are
distributed across the network nodes must coordinate to incorporate each others observations and
propagate their estimates from one time step to the next Online operation requires the algorithm
to degrade gracefully when nodes run out of processing time before the observations propagate
throughout the network Furthermore the algorithm needs to robustly address node failures and
interference that may partition the communication network into several disconnected components
We present an efficient distributed algorithm for dynamic inference that works on a large family
of processes modeled by dynamic Bayesian networks In our algorithm each node maintains a
possibly approximate marginal distribution over a subset of state variables conditioned on the
measurements made by the nodes in the network At each time step the nodes condition on the
observations using a modification of the robust static distributed inference algorithm and
then advance their estimates to the next time step locally The algorithm guarantees that with
sufficient communication at each time step the nodes obtain the same solution as the corresponding
centralized algorithm Before convergence the algorithm introduces principled approximations
in the form of independence assertions in the node estimates and in the transition model
In the presence of unreliable communication or high latency the nodes may not be able to condition their estimates on all the observations in the network when interference causes a network
partition or when high latency prevents messages from reaching every node Once the estimates are
advanced to the next time step it is difficult to condition on the observations made in the past
Hence the beliefs at the nodes may be conditioned on different evidence and no longer form a consistent global probability distribution over the state space We show that such inconsistencies can
lead to poor results when nodes attempt to combine their estimates Nevertheless it is often possible
to use the inconsistent estimates to form an informative globally consistent distribution we refer to
this task as alignment We propose an online algorithm optimized conditional alignment
that obtains the global distribution as a product of conditionals from local estimates and optimizes
over different orderings to select a global distribution of minimal entropy We also propose an alternative more global optimization approach that minimizes a KL divergence-based criterion and
provides accurate solutions even when the communication network is highly fragmented
We present experimental results on real-world sensor data covering sensor calibration and
distributed camera localization These results demonstrate the convergence properties of the
algorithm its robustness to message loss and network partitions and the effectiveness of our method
at recovering from inconsistencies
Distributed dynamic inference has received some attention in the literature For example particle filtering techniques have been applied to these settings Zhao use mostly
independent PFs to track moving objects and Rosencrantz run PFs in parallel sharing
measurements as appropriate Pfeffer and Tai use loopy belief propagation to approximate the
estimation step in a continuous-time Bayesian network When compared to these techniques our
approach addresses several additional challenges we do not assume point-to-point communication
between nodes we provide robustness guarantees to node failures and network partitions and we
identify and address the belief inconsistency problem that arises in distributed systems
The distributed dynamic inference problem
Following we assume a network model where each node can perform local computations and
communicate with other nodes over some channel The nodes of the network may change over
time existing nodes can fail and new nodes may be introduced We assume a message-level error
model messages are either received without error or they are not received at all The likelihood of
successful transmissions link qualities are unknown and can change over time and link qualities
of several node pairs may be correlated
We model the system as a dynamic Bayesian network A DBN consists of a set of state
processes XL and a set of observed measurement processes ZK
each measurement process Zk corresponds to one of the sensors on one of the nodes State processes
are not associated with unique nodes A DBN defines a joint probability model over steps as
initial prior
transition model
measurement model
The initial prior is given by a factorized probability model where each
QL
Ah is a subset of the state processes The transition model factors as p(Xi Pa[Xi
where Pa[Xi are the parents of in the previous time step The measurement model factors
QK
as p(Zk Pa[Zk where Pa[Zk are the parents of Zk in the current time step
In the distributed dynamic inference problem each node is associated with a set of processes
Qn these are the processes about which node wishes to reason The nodes need to collab(t
orate so that each node can obtain an approximation to the posterior distribution over Qn given
all measurements made in the network up to the current time step p(Qi
We assume that
node clocks are synchronized so that transitions to the next time step are simultaneous
Filtering in dynamical systems
The goal of centralized filtering is to compute the posterior distribution for
as the observations arrive The basic approach is to recursively compute from in three steps
Estimation
Prediction
Roll-up dx(t
Exact filtering in DBNs is usually expensive or intractable because the belief state rapidly loses
all conditional independence structure An effective approach proposed by Boyen and Koller
hereby denoted is to periodically project the exact posterior to a distribution that satisfies
independence assertions
encoded in a junction tree Given a junction tree with cliques Ci
and separators Si,j the projection operation amounts to computing the clique marginals hence
the filtered distribution is approximated as
i?NT
i,j
where NT and ET are the nodes and edges of respectively With this representation the es(t
timation step is implemented by multiplying each observation likelihood p(zk Pa[Zk to a
clique marginal the clique and separator potentials are then recomputed with message passing
so that the posterior
as a ratio of cliqueiand separator marginals
hQdistribution is once again
hwritten
Ci
Si,j The prediction step is
i?NT
performed independently for each clique Ci
we multiply with the transition
model p(X Pa[X for each variable Ci
and using variable elimination
compute the marginals over the clique at the next time step p(Ci
Approximate distributed filtering
In principle the centralized filtering approach described in the previous section could be applied to a
distributed system by communicating the observations made in the network to a central location
that performs all computations and distributing the answer to every node in the network While
conceptually simple this approach has substantial drawbacks including the high communication
bandwidth the introduction of a single point of failure to the system and the fact that nodes do not
have valid estimates when the network is partitioned In this section we present a distributed filtering
algorithm where each node obtains an approximation to the posterior distribution over subset of the
state variables Our estimation step builds on the robust distributed inference algorithm of Paskin
while the prediction roll-up and projection steps are performed locally at each node
Estimation as a robust distributed probabilistic inference
In the distributed inference approach of Paskin the nodes collaborate so that each node
can obtain the posterior distribution over some set of variables Qn given all measurements made
throughout the network In our setting Qn contains the variables in a subset Ln of the cliques
used in our assumed density representation In their architecture nodes form a distributed data
structure along a routing tree in the network where each node in this tree is associated with a
cluster of variables Dn that includes Qn as well as any other variables needed to preserve the flow
of information between the nodes a property equivalent to the running intersection property in
junction trees We refer to this tree as the network junction tree and for clarity we refer to the
junction tree used for the assumed density as the external junction tree
Using this architecture Paskin and Guestrin developed a robust distributed probabilistic inference algorithm RDPI for static inference settings where nodes compute the posterior distribution p(Qn over Qn given all measurements throughout the network RDPI provides two crucial
properties convergence if there are no network partitions these distributed estimates converge to
the true posteriors and smooth degradation even before convergence the estimates provide a principled approximation to the true posterior which introduces additional independence assertions
In RDPI each node maintains the current belief of p(Qn Initially node knows
only the marginals of the prior distribution p(Ci Ln for a subset of cliques Ln in the
external junction tree and its local observation model p(zn Pa[Zn for each of its sensors We
assume that Pa[Zn Ci for some Ln thus is represented as a collection of priors over
cliques of variables and of observation likelihood functions over these variables Messages are then
sent between neighboring nodes in an analogous fashion to the sum-product algorithm for junction
trees However messages in RDPI are always represented as a collection of priors Ci
over cliques of variables Ci and of measurement likelihood functions Ci over these cliques
This decomposition into prior and likelihood factors is the key to the robustness properties of the
algorithm With sufficient communication converges to p(Qn
In our setting at each time step each prior Ci is initialized to p(Ci The
likelihood functions are similarly initialized to Ci p(zi Ci if some sensor makes an
observation about these variables or to otherwise Through message passing converges to
An important property of RDPI that will be useful in the remainder of the paper is
Property Let be the result computed by the RDPI algorithm at convergence at node Then
the cliques in form a subtree of an external junction tree that covers Qn
Prediction roll-up and projection
The previous section shows that the estimation step can be implemented in a distributed manner
using RDPI At convergence each node obtains the calibrated marginals Ci for
Ln In order to advance to the next time step each node must perform prediction and roll-up
obtaining the marginals
Ci
Recall from Section that in order to compute a marginal
Ci
this node needs
Due to the conditional independencies encoded in
it is sufficient to obtain a subtree of the external junction tree that covers the parents
Pa[Ci
of all variables in the clique The next time step marginal Ci
can then
be computed by multiplying this subtree with the transition model p(X
Pa[X for each
Ci
and eliminating all variables but Ci
recall that Pa[X
This procedure suggests the following distributed implementation of prediction roll-up and
projection after completing the estimation step each node selects a subtree of the global exter(t+1
nal junction tree that covers Pa[Ci
and collects the marginals of this tree from other nodes in
the network Unfortunately it is unclear how to allocate the running time between estimation and
collection of marginals in time-critical applications when the estimation step may not run to completion Instead we propose a simple approach that performs both steps at once run the distributed
inference algorithm described in the previous section to obtain the posterior distribution over the
parents of each clique maintained at the node This task can be accomplished by ensuring that these
parent variables are included in the query variables of node Pa[Ci
Qn Ln
When the estimation step cannot be run to convergence within the allotted time the variables
Scope[?n covered by the distribution that node obtains may not cover the entire parent set
Pa[Ci
In this case multiplying in the standard transition model is equivalent to assuming an uniform prior for the missing variables which can lead to very poor solutions in practice When the transition model is learned from data p(X Pa[X is usually computed from the empirical distribution Pa[X pM LE Pa[X
Pa[X
Pa[X Building on these empirical distributions we can obtain
an improved solution for the prediction and roll-up steps when we do not have a distribution
over the entire parent set Pa[Ci
Specifically we obtain a valid approximate transition model
where Scope[?n Pa[X online by simply marginalizing the empirical distribution
Pa[X down to This procedure is equivalent
to introducing an additional independence assertion to the model at time step is
independent of Pa[X given
Summary of the algorithm
Our distributed approximate filtering algorithm can be summarized as follows
Using the architecturein construct
tree the query variables Qn
aSnetwork junction
at each node cover
Pa[C
i?Ln
i?Ln
For at each node
run RDPI until the end of step obtaining a possibly approximate belief
for each Ci
Ln compute an approximate transition model
WX where WX Scope[?n Pa[X
for each clique Ci
Ln compute the clique marginal Ci
from
and from each
WX locally using variable elimination
Using the convergence properties of the RDPI algorithm we prove that given sufficient communication our distributed algorithm obtains the same solution as the centralized 98 algorithm
Theorem For a set of nodes running our distributed filtering algorithm if at each time step there
is sufficient communication for the RDPI algorithm to converge and the network is not partitioned
then for each node for each clique Ln the distribution Ci obtained by node
is equal to the distribution obtained by the 98 algorithm with assumed density given by
BK solution
alignment rooted at alignment rooted at
min KL divergence
Figure Alignment results after partition shown by vertical line circles represent confidence intervals
in the estimate of the camera location The exact solution computed by the BK algorithm in the absence of
partitions Solution obtained when aligning from node Solution obtained when aligning from node
Solution obtained by joint optimized alignment
Robust distributed filtering
In the previous section we introduced an algorithm for distributed filtering with dynamic Bayesian
networks that with sufficient communication converges to the centralized 98 algorithm In
some settings for example when interference causes a network partition messages may not be propagated long enough to guarantee convergence before nodes must roll-up to the next time step Consider the example illustrated in Figure in which a network of cameras localizes itself by observing
a moving object Each camera carries a clique marginal over the location of the object its
own camera pose variable and the pose of one of its neighboring cameras
and Suppose communication were interrupted due to a network
partition observations would not propagate and the marginals carried by the nodes would no
longer form a consistent distribution in the sense that might not agree on their marginals
The goal of alignment is to obtain a consistent distribution
from marginals that is close to the true posterior as
measured for example by the root-mean-square error of the estimates For simplicity of notation
we omit time indices and conditioning on the past evidence throughout this section
Optimized conditional alignment
One way to define a consistent distribution is to start from a root node and allow each
clique marginal to decide the conditional density of Ci given its parent
p1
This density
p1 forms a coherent distribution over and we say that is rooted at node
Thus fully defines the marginal density over defines the conditional density of
given and so on If node were the root then node would only contribute
and we would obtain a different approximate distribution
In general given a collection of marginals Ci over the cliques of a junction tree and a
root node NT the distribution obtained by conditional alignment from can be written as
Ci Sup(i),i Sup(i),i
pr Cr
i?(NT
where up(i denotes the upstream neighbor of on the unique path between and
The choice of the root often crucially determines how well the aligned distribution pr approximates the true prior Suppose that in the example in Figure the nodes on the left side of the partition do not observe the person while the communication is interrupted and the prior marginals
are uncertain about If we were to align the distribution from multiplying
into the marginal would result in a distribution that is uncertain in both and
Figure while a better choice of root could provide a much better estimate Figure
One possible metric to optimize when choosing the root for the alignment is the entropy of the
resulting distribution
pr For example the entropy of in the previous example can be written as
where we use the fact that for Gaussians the conditional entropy of given only depends
on the conditional distribution
p2 A na??ve algorithm for obtaining
the best root would exploit this decomposition to compute the entropy of each and pick the root
that leads to a lowest total entropy the running time of this algorithm is O(|NT We propose a
dynamic programming approach that significantly reduces the running time Comparing Equation
with the entropy of the distribution rooted at a neighboring node we see that they share a common
term and If
is positive node is a better root than is negative we have the reverse situation Thus
when comparing neighboring nodes as root candidates the difference in entropy of the resulting
distribution is simply the difference in entropy their local distributions assign to their separator This
property generalizes to the following dynamic programming algorithm that determines the root
with minimal H?pr in O(|NT time
For any node NT define the message from to its neighbor as
if mk?i
mi?j
maxk6=j mk?i otherwise
where H?j Si,j H?i Si,j and varies over the neighbors of in
If maxk mk?i then is the optimal root otherwise up(i argmaxk mk?i
Intuitively the message mi?j represents the loss entropy with root node compared to the best
root on i?s side of the tree Ties between nodes if any can be resolved using node IDs.
Distributed optimized conditional alignment
In the absence of an additional procedure RDPI can be viewed as performing conditional alignment
However the alignment is applied to the local belief at each node rather than the global distribution
and the nodes may not agree on the choice of the root Thus the network is not guaranteed to
reach a globally consistent aligned distribution In this section we show that RDPI can be extended
to incorporate the optimized conditional alignment OCA algorithm from the previous section
By Property at convergence the priors at each node form a subtree of an external junction tree
for the assumed density Conceptually if we were to apply OCA to this subtree the node would have
an aligned distribution but nodes may not be consistent with each other Intuitively this happens
because the optimization messages mi?j were not propagated between different nodes
In RDPI node n?s belief includes a collection of potentially inconsistent priors Ci
In the standard sum-product inference algorithm an inference message from node to node
is computed by marginalizing out some variables from the factor
m?n
that combines the messages received from node m?s other neighbors with node m?s local belief The
inference message in RDPI involves a similar marginalization which corresponds to pruning some
cliques from
m?n When such pruning occurs any likelihood information Ci associated
with the pruned clique is transferred to its neighbor
Our distributed OCA algorithm piggy-backs on this pruning computing an optimization message
mi?j which is stored in clique To compute this message cliques must also carry their original
unaligned priors At convergence the nodes will not only have a subtree of an external tree but also
the incoming optimization messages that result from pruning of all other cliques of the external tree
In order to determine the globally optimal root each node locally selects a root for its subtree If
this root is one of the initial cliques associated with then and in particular this clique is the root
of the conditional alignment The alignment is propagated throughout the network If the optimal
root is determined to be a clique that came from a message received from a neighbor then the neighbor another node upstream is the root and node aligns itself with respect to the neighbor?s
message With an additional tie-breaking rule that ensures that all the nodes make consistent choices
about their subtrees this procedure is equivalent to running the OCA algorithm centrally
Theorem Given sufficient communication and in the absence of network partitions nodes running distributed OCA reach a globally consistent belief based on conditional alignment selecting
the root clique that leads to the joint distribution of minimal entropy In the presence of partitions
each partition will reach a consistent belief that minimizes the entropy within this partition
Jointly optimized alignment
While conceptually simple there are situations where such a rooted alignment will not provide
a good aligned distribution For example if in the example in Figure cameras and carry
marginals and respectively and both observe the person node will
have a better estimate of while node estimate of will be more accurate If either node
is chosen as the root the aligned distribution will have a worse estimate of the pose of one of
the cameras because performing rooted alignment from either direction effectively overwrites the
marginal of the other node In this example rather than fixing a root we want an aligned distribution
that attempts to simultaneously optimize the distance to both and
35 nodes
54 nodes
Camera
Camera
RMS error
RMS error
Camera
time step
epochs per time step
25-camera testbed
Convergence cameras
Convergence temperature
Figure Testbed of cameras used for the SLAT experiments Convergence results for individual
cameras in one experiment Horizontal lines indicate the cooresponding centralized solution at the end of the
experiment Convergence versus amount of communication for a temperature network of 54 real sensors
We propose the following optimization problem that minimizes the sum of reverse KL divergence from the aligned distribution to the clique marginals Ci
D(q(Ci Ci
argmin
i?NT
where denotes the constraint that factorizes according to the junction tree This method
will often provide very good aligned distributions Figure For Gaussian distributions this
optimization problem corresponds to
min?C
log
Ci
Ci
Ci
subject to
i?NT
Ci
i?NT
NT
where Ci Ci are the means and covariances of over the variables Ci and are the means
and covariances of the marginals The problem in Equation consists of two independent convex
optimization problems over the means and covariances of respectively The former problem can
be solved in a distributed manner using distributed linear regression while the latter can be
solved using a distributed version of an iterative methods such as conjugate gradient descent
Experimental results
We evaluated our approach on two applications a camera localization problem SLAT in
which a set of cameras simultaneously localizes itself by tracking a moving object and temperature monitoring application analogous to the one presented in Figure shows some of the
ceiling-mounted cameras used to collect the data in our camera experiments We implemented
our distributed algorithm in a network simulator that incorporates message loss and used data from
these real sensors as our observations Figure shows the estimates obtained by three cameras in
one of our experiments Note that each camera converges to the estimate obtained by the centralized
98 algorithm In Figure we evaluate the sensitivity of the algorithm to incomplete communication We see that with a modest number of rounds of communication performed in each time
step the algorithm obtains a high quality of the solution and converges to the centralized solution
In the second set of experiments we evaluate the alignment methods presented in Section In
Figure the network is split into four components in each component the nodes communicate
fully and we evaluate the solution if the communication were to be restored after a given number of
time steps The vertical axis shows the RMS error of estimated camera locations at the end of the experiment For the unaligned solution the nodes may not agree on the estimated pose of a camera so
it is not clear which node?s estimate should be used in the RMS computation the plot shows an omniscient envelope of the RMS error where given the unknown true camera locations we select
the best and worst estimates available in the network for each camera?s pose The results show that
in the absence of optimized alignment inconsistencies can degrade the solution observations collected after the communication is restored may not make up for the errors introduced by the partition
The third experiment evaluates the performance of the distributed algorithm in highlydisconnected scenarios Here the sensor network is hierarchically partitioned into smaller disconnected components by selecting a random cut through the largest component The communication
is restored shortly before the end of the experiment Figures shows the importance of aligning
from the correct node the difference between the optimized root and an arbitrarily chosen root is
significant particularly when the network becomes more and more fractured In our experiments
large errors often resulted from the nodes having uncertain beliefs hence justifying the objective
function We see that the jointly optimized alignment described in Section min KL tends
to provide the best aligned distribution though often close to the optimized root which is simpler
upper bound
lower bound
fixed root
optimized root upper bound
min KL
unaligned
lower bound
lower bound
Duration of the partition
camera localization
Number of partitions
camera localization
upper bound
RMS error
fixed root
optimized root
unaligned
RMS error
RMS error
fixed root
optimized root
min KL
unaligned
Number of partitions
temperature monitoring
Figure Comparison of the alignment methods RMS error duration of the partition For the unaligned
solution the plot shows bounds on the error given the unknown camera locations we select the best and worst
estimates available in the network for each camera?s pose In the absence of optimized alignment inconsistencies can degrade the quality of the solution RMS error number of partitions In camera localization
the difference between the optimized alignment and the alignment from an arbitrarily chosen fixed root is
significant For the temperature monitoring the differences are less pronounced but follow the same trend
to compute Finally shows the alignment results on the temperature monitoring application
Compared to SLAT the effects of network partitions on the results for the temperature data are less
severe One contributing factor is that every node in a partition is making local temperature observations and the approximate transition model for temperatures in each partition is quite accurate
hence all the nodes continue to adjust their estimates meaningfully while the partition is in progress
Conclusions
This paper presents a new distributed approach to approximate dynamic filtering based on a distributed representation of the assumed density in the network Distributed filtering is performed by
first conditioning on evidence using a robust distributed inference algorithm and then advancing
to the next time step locally With sufficient communication in each time step our distributed algorithm converges to the centralized 98 solution In addition we identify a significant challenge
for probabilistic inference in dynamical systems nodes can have inconsistent beliefs about the current state of the system and an ineffective handling of this situation can lead to very poor estimates
of the global state We address this problem by developing a distributed algorithm that obtains an
informative consistent distribution optimizing over various choices of the root node and an alternative joint optimization approach that minimizes a KL divergence-based criterion We demonstrate
the effectiveness of our approach on a suite of experimental results on real-world sensor data
Acknowledgments
This research was supported by grants NSF-NeTS and NSF ITR. S.
Funiak was supported by the Intel Research Scholar Program C. Guestrin was partially supported
by an Alfred P. Sloan Fellowship

<<----------------------------------------------------------------------------------------------------------------------->>

title: 3609-estimating-the-location-and-orientation-of-complex-correlated-neural-activity-using-meg.pdf

Estimating the Location and Orientation of Complex
Correlated Neural Activity using MEG
D.P. Wipf J.P. Owen H.T. Attias K. Sekihara and S.S. Nagarajan
Biomagnetic Imaging Laboratory
University of California San Francisco
Abstract
The synchronous brain activity measured via MEG EEG can be interpreted
as arising from a collection possibly large of current dipoles or sources located
throughout the cortex Estimating the number location and orientation of these
sources remains a challenging task one that is significantly compounded by the
effects of source correlations and the presence of interference from spontaneous
brain activity sensor noise and other artifacts This paper derives an empirical
Bayesian method for addressing each of these issues in a principled fashion The
resulting algorithm guarantees descent of a cost function uniquely designed to
handle unknown orientations and arbitrary correlations Robust interference suppression is also easily incorporated In a restricted setting the proposed method
is shown to have theoretically zero bias estimating both the location and orientation of multi-component dipoles even in the presence of correlations unlike a
variety of existing Bayesian localization methods or common signal processing
techniques such as beamforming and sLORETA Empirical results on both simulated and real data sets verify the efficacy of this approach
Introduction
Magnetoencephalography MEG and related electroencephalography EEG use an array of sensors to take electromagnetic field voltage potential measurements from on or near the scalp
surface with excellent temporal resolution In both cases the observed field is generated by the
same synchronous compact current sources located within the brain Although useful for research
and clinical purposes accurately determining the spatial distribution of these unknown sources is
an open problem The relevant estimation problem can be posed as follows The measured electromagnetic signal is Rdb dt where db equals the number of sensors and dt is the number of time
points at which measurements are made Each unknown source Si Rdc dt is a dc dimensional
neural current dipole at dt timepoints projecting from the i-th discretized voxel or candidate location distributed throughout the cortex These candidate locations can be obtained by segmenting a
structural MR scan of a human subject and tesselating the gray matter surface with a set of vertices
and each Si are related by the likelihood model
ds
Li Si
where ds is the number of voxels under consideration Li Rdb dc is the so-called lead-field
matrix for the i-th voxel The k-th column of Li represents the signal vector that would be observed
at the scalp given a unit current source/dipole at the i-th vertex with a fixed orientation in the k-th
direction It is common to assume dc for MEG or dc for EEG which allows flexible
source orientations to be estimated in 2D or 3D space Multiple methods based on the physical
properties of the brain and Maxwell?s equations are available for the computation of each
Finally is a noise-plus-interference term where we assume for simplicity that columns are drawn
independently from However temporal correlations can easily be incorporated if desired
using a simple transformation outlined in
To obtain reasonable spatial resolution the number of candidate source locations will necessarily
be much larger than the number of sensors ds db The salient inverse problem then becomes
the ill-posed estimation of regions with significant brain activity which are reflected by voxels
such that kSi we refer to these as active dipoles or sources Because the inverse model is
severely underdetermined the mapping from source activity configuration Sds to
sensor measurement is many to one all efforts at source reconstruction are heavily dependent
on prior assumptions which in a Bayesian framework are embedded in the distribution Such
a prior is often considered to be fixed and known as in the case of minimum current estimation
MCE minimum variance adaptive beamforming MVAB and sLORETA Alternatively a number of empirical Bayesian approaches have been proposed that attempt a form of model
selection by using the data whether implicitly or explicitly to guide the search for an appropriate
prior Examples include variational Bayesian methods and hierarchical covariance component models While advantageous in many respects all of these methods retain substantial
weaknesses estimating complex correlated source configurations with unknown orientation in the
presence of background interference spontaneous brain activity sensor noise
There are two types of correlations that can potentially disrupt the source localization process First
there are correlations within dipole components meaning the individual rows of are correlated
which always exists to a high degree in real data with unknown orientation Secondly
there are correlations between different dipoles that are simultaneously active meaning rows of
are correlated with rows of Sj for some voxels These correlations are more application specific and may or may not exist The larger the number of active sources the greater the chance that
both types or correlation can disrupt the estimation process This issue can be problematic for two
reasons First failure to accurately account for unknown orientations or correlations can severely
disrupt the localization process leading to a very misleading impression of which brain areas are
active Secondly the orientations and correlations themselves may have clinical significance
In this paper we present an alternative empirical Bayesian scheme that attempts to improve upon
existing methods in terms of source reconstruction accuracy and/or computational robustness and
efficiency Section presents the basic generative model which underlies the proposed method and
describes the associated inference problem Section derives a robust algorithm for estimating the
sources using this model and proves that each iteration is guaranteed to reduce the associated cost
function It also describes how interference suppression can be naturally incorporated Section
then provides a theoretical analysis of the bias involved in estimating both the location and orientation of active sources demonstrating that the proposed method has substantial advantages over
existing approaches Finally Section contains experimental results using our algorithm on both
simulated and real data followed by a brief discussion in Section
Modeling Assumptions
To begin we invoke the noise model from which fully defines the assumed likelihood
ds
exp
Li
where kXkW denotes the weighted matrix norm trace[X X]. The unknown noise covariance
will be estimated from the data using a variational Bayesian factor analysis VBFA model as
discussed in Section below for now we will consider that it is fixed and known Next we adopt
the following source prior for
exp trace
This is equivalent to applying independently at each time point a zero-mean Gaussian distribution
with covariance to each source Si We define to be the ds dc ds dc block-diagonal matrix
formed by ordering each along the diagonal
of anotherwise zero-valued matrix This implies
equivalently that exp trace
If were somehow known then the conditional distribution is a fully
specified Gaussian distribution with mean and covariance given by
LT L?LT
Covp(sj sj LT L?LT
where sj denotes the j-th column of and individual columns are uncorrelated However since
must first be found One principled way to
is actually not known a suitable approximation
accomplish this is to integrate out the sources and then maximize
exp L?LT
This is equivalent to minimizing the cost function
log trace Cb
log
where Cb BB is the empirical covariance and is sometimes referred to as type-II maximum
likelihood evidence maximization or empirical Bayes
The first term of is a measure of the dissimilarity between the empirical data covariance and
the model data covariance in general this factor encourages to be large The second term provides a regularizing or sparsifying effect penalizing a measure of the volume formed by the model
covariance Since the volume of any high dimensional space is more effectively reduced by
collapsing individual dimensions as close to zero as possible as opposed to incrementally reducing
all dimensions isometrically this penalty term promotes a model covariance that is maximally degenerate non-spherical which pushes elements of to exactly zero This intuition is supported
theoretically by the results in Section
we obtain the attendant empirical prior
To the extent
Given some type-II ML estimate
that this learned prior is realistic the resulting posterior quantifies regions of significant
current density and point estimates for the unknown source dipoles Si can be obtained by evaluating
as described above then the associated
the posterior mean computed using If a given
Si computed using also becomes zero It is this pruning mechanism that naturally chooses the
number of active dipoles
Algorithm Derivation
Given and computing the posterior on is trivial Consequently determining these unknown
quantities is the primary estimation task We will first derive an algorithm for computing assuming
is known Later in Section we will describe a powerful procedure for learning
Learning the Hyperparameters
The primary objective of this section is to minimize with respect to Of course one option is
to treat the problem as a general nonlinear optimization task and perform gradient descent or some
other generic procedure Related methods in the MEG literature rely either directly or indirectly on
a form of the EM algorithm However these algorithms are exceedingly slow when is large
and they have not been extended to handle flexible orientations Consequently here we derive an
alternative optimization procedures that expands upon ideas from handles arbitrary/unknown
dipole orientations and converges quickly
To begin we note that only depends on the data through the db db sample correlation matrix
Rdb rank(B
Cb Therefore to reduce the computational burden we replace with a matrix
such that Cb This removes any per-iteration dependency on dt which can potentially be
large without altering that actual cost function It also implies that for purposes of computing
the number of columns of is reduced to match rank(B We now re-express the cost function
in an alternativeform leading to convenient update rules and by construction a proof that
at each iteration
The determinant of a matrix is equal to the product of its eigenvalues a well-known volumetric measure
First the data fit term can be expressed as
ds
ds
trace Cb
min
Li
kXi
is a matrix of auxiliary variables Likewise because the logwhere X1T XdTs
determinant term of is concave in it can be expressed as a minimum over upper-bounding
hyperplanes via
log min
trace Zi
and is the concave conjugate of log For our purposes
where
below we will never actually have to compute Dropping the minimizations and combining
terms from and leads to the modified cost function
ds
ds
Xe
Li
kXi trace ZiT
Z1T ZdTs
where by construction minX minZ Z). It is straightforward to show that if
is a local global minimum to then
is a local global minimum to
Since direct optimization of may be difficult we can instead iteratively optimize
via coordinate descent over and Z. In each case when two are held fixed the third can be
globally minimized in closed form This ensures that each cycle will reduce but more
importantly will reduce leave it unchanged if a fixed-point or limit cycle is reached The
associated update rules from this process are as follows
The optimal with and fixed is just the standard weighted minimum-norm solution given by
Xinew LTi
for each The minimizing equals the slope at the current of log As such we have
Zinew O?i log LTi
Li
With and fixed computing the minimizing is a bit more difficult because of the constraint
for all where is the set of positive-semidefinite symmetric dc dc covariance
matrices To obtain each we must solve
new
kXi trace ZiT
arg min
An unconstrained solution will satisfy
O?i Zi
which after computing the necessary derivatives and re-arranging terms gives the equivalent condition
XiT Zi
There are multiple unconstrained solutions to this equation we will choose the unique one that
satisfies the constraint This can be found using
Zi
XiT Zi
Zi XiT Zi
Zi XiT Zi
Zi
Zi
Zi XiT Zi
Zi
Zi XiT Zi
Zi
Zi Zi
Zi XiT Zi
Zi
This indicates the solution update equation
new
Zi XiT Zi
Zi
Zi
which is satisfies the constraint And since we are minimizing a convex function of over the
constraint set we know that this is indeed a minimizing solution
In summary then to estimate we need simply iterate and and with each pass we
are guaranteed to reduce leave unchanged The per-iteration cost is linear in the number
of voxels ds so the computational cost is relatively modest it is quadratic in db and cubic in dc
but these quantities are relatively small The convergence rate is orders of magnitude faster than
EM-based algorithms such as those in Figure right
Learning the Interference
The learning procedure described in the previous section boils down to fitting a structured maximum
likelihood covariance estimate to the data covariance Cb The idea here is that
will reflect the brain signals of interest while will capture all interfering factors
spontaneous brain activity sensor noise muscle artifacts etc Since is unknown it must somehow be estimated or otherwise accounted for Given access to pre-stimulus data data assumed
to have no signal/sources of interest stimulus evoked factor analysis SEFA provides a powerful
means of decomposing a data covariance matrix Cb into signal and interference components While
details can be found in SEFA computes the approximation
Cb EE AAT
where represents a matrix of learned interference factors is a diagonal noise matrix and A is a
matrix of signal factors There are two ways to utilize this decomposition more details can be found
in First we can simply set EE and proceed as in Section Alternatively
we can set and then substitute AAT for Cb run the same algorithm on a de-noised
signal covariance For technical reasons beyond the scope of this paper it appears that algorithm
performance may be superior when the latter paradigm is adopted
Analysis of Theoretical Localization/Orientation Bias
Theoretical support for the proposed algorithm is possible in the context of estimation bias assuming
simplified source configurations For example substantial import has been devoted to quantifying
localization bias when estimating a single dipolar source Recently it has been shown both empirically and theoretically that the MVAB and sLORETA algorithms have zero location bias under
this condition at high SNR. This has been extended to include certain empirical Bayesian methods
However these results assume a single dipole with fixed known orientation alternatively
that dc and therefore do not formally handle source correlations or multi-component dipoles
The methods from also purport to address these issues but no formal analyses are presented
In contrast despite being a complex non-convex function we now demonstrate that has very
attractive bias properties regarding both localization and orientation We will assume that the full
lead-field LT1 LTds represents a sufficiently high sampling of the source space such that
any active dipole component aligns with some lead-field columns Unbiasedness can also be shown
in the continuous case but the discrete scenario is more straightforward and of course more relevant
to any practical task
Some preliminary definitions are required to proceed We define the empirical intra-dipole correlation matrix at the i-th voxel as Cii d1t SiT Si non-zero off-diagonal elements imply that correlations are present Except in highly contrived situations this type of correlation will always exist
The empirical inter-dipole correlation matrix between voxels and is Cij d1t SiT Sj any nonzero element implies the existence of a correlation In practice this form of correlation may or may
not be present With regard to the lead-field spark is defined as the smallest number of linearly
dependent columns By definition then spark(L db Finally da denotes the number
of active sources the number of voxels whereby kSi
Theorem In the limit as high SNR and assuming da dc spark(L the cost
function maintains the following two properties
For arbitrary Cii and Cij the unique global minimum produces a source estimate
computed using that equals the generating source matrix it is
unbiased in both location and orientation for all active dipoles and correctly zeros out the
inactive ones
If Cij for all active dipoles although Cii is still arbitrary then there are no local
minima the cost function is unimodal
The proof has been deferred to In words this theorem says that intra-dipole correlations do
not disrupt the estimation process by creating local minima and that the global minimum is always
unbiased In contrast inter-dipole correlations can potentially create local minima but they do not
affect the global minimum Empirically we will demonstrate that the algorithm derived in Section
is effective at avoiding these local minima Section With added assumptions these results
can be extended somewhat to handle the inclusion of noise
The cost functions from bear the closest resemblance to however neither possesses
the second attribute from Theorem This is a very significant failing because as mentioned previously intra-dipole correlations are always present in each active dipole Consequently localization
and orientation bias can occur because of convergence to a local minimum The iterative Bayesian
scheme from while very different in structure also directly attempts to estimate flexible orientations and handle to some extent source correlations While details are omitted for brevity we
can prove that the full model upon which this algorithm is based fails to satisfy the first property
of the theorem so the corresponding global minimum can be biased In contrast beamformers
and sLORETA are basically linear methods with no issue of global or local minima However the
popular sLORETA and MVAB solutions will in general display a bias for multi-component dipoles
dc or when multiple dipoles da are present regardless of correlations
Empirical Evaluation
In this section we test the performance of our algorithm on both simulated and real data sets We
focus here on localization accuracy assuming strong source correlations and unknown orientations
While orientation estimates themselves are not shown for space considerations accurate localization
implicitly indicates that this confound has been adequately handled More comprehensive experiments including comparisons with additional algorithms are forthcoming
Simulated Data We first conducted tests using simulated data with realistic source configurations
The brain volume was segmented into 5mm voxels and a two orientation dc forward leadfield
was calculated using a spherical-shell model The data time course was partitioned into pre and
post-stimulus periods In the pre-stimulus period samples there is only noise and interfering
brain activity while in the post-stimulus period samples there is the same statistically noise
and interference factors plus source activity of interest We used two noise conditions Gaussiannoise and real-brain noise In the former case we seeded voxels with Gaussian noise in each orientation and then projected the activity to the sensors using the leadfield producing colored Gaussian
noise at the sensors To this activity we added additional Gaussian sensor noise For the real-brain
noise case we used resting-state data collected from a human subject that is presumed to have ongoing and spontaneous activity and sensor noise In both the Gaussian and real-brain noise cases
the pre-stimulus activity was on-going and continued into the post-stimulus period where the simulated source signals were added Sources were seeded at locations in the brain as damped-sinusoids
and this voxel activity was projected to the sensors We could adjust both the signal-to-noise-plusinterefence ratio SNIR and the correlations between the different voxel time-courses to examine
the algorithm performance on correlated sources and unknown dipole orientations
We ran simulations of three randomly seeded sources at different SNIR levels
The sources in these simulations always had an inter-dipole correlation coefficient of intradipole correlations were present as well We ran the simulation with both Gaussian-noise and real
brain noise using a MVAB and our proposed method In order to evaluate performance we used the
following test for a hit or miss We drew spheres around each seeded source location and obtained the
maximum voxel value in each sphere Then we calculated the maximum voxel activation outside the
three spheres If the maximum inside each sphere was greater than the maximum outside all of the
spheres it was counted as a hit this way we are implicitly accounting somewhat for false alarms
Each simulation could get a score or or with being the best Figure left displays
comparative results averaged over trials with standard errors Our method quite significantly
outperforms the MVAB which is designed to handle unknown orientations but has difficulty with
source correlations Figure middle shows a sample reconstruction on a much more complex
source configuration composed of dipolar sources Finally Figure right gives an example
of the relative convergence improvement afforded by our method relative to an EM implementation
analogous to We also wanted to test the performance on perfectly correlated sources with
unknown orientations and compare it to other state-of-the-art Bayesian methods An example using
three such sources and dB SNIR is given in Figure
cost function value
Gaussian Noise
Proposed Method
Real Brain Noise
Proposed Method
successful localizations
Gaussain Noise
MVAB
Real Brain Noise
MVAB
EM algorithm
proposed method
SNIR
70
90
iteration number
Figure Left Aggregate localization results for MVAB and the proposed method recovering three
correlated sources with unknown orientations Middle Example reconstruction of relatively
shallow sources green circles using proposed method MVAB performs poorly on this task Right
Convergence rate of proposed method relative to a conventional EM implementation based on
Figure Reconstructions of three perfectly correlated dipoles green circles with unknown orientations using Left MVAB Middle variational Bayesian method from Right proposed
method
Real Data Two stimulus-evoked data sets were collected from normal healthy research subjects
on a 275-channel CTF System MEG device The first data set was a sensory evoked field SEF
paradigm where the subject?s right index finger was tapped for a total of trials A peak is typically seen after stimulation in the contralateral this case the left somatosensory cortical
area for the hand dorsal region of the postcentral gyrus The proposed algorithm was able to
localize this activation to the correct area of somatosensory cortex as seen in Figure left and the
estimated time course shows the typical peak data not shown The second data set analyzed
was an auditory evoked field AEF paradigm In this paradigm the subject is presented tones binaurally for a total of trials There are two typical peaks seen after the presentation of an auditory
stimulus one at and one at called the and respectively The auditory processing of tones is bilateral at early auditory areas and the activations are correlated The algorithm
was able to localize activity in both primary auditory cortices and the time courses for these two
activations reveal the and Figure middle and right displays these results The
analysis of simple auditory paradigms is problematic because many source localization algorithms
such as the MVAB do not handle the bilateral correlated sources well We also ran MVAB on the
AEF data and it localized activity to the center of the head between the two auditory cortices data
not shown
Discussion
This paper derives a novel empirical Bayesian algorithm for MEG source reconstruction that readily
handles multiple correlated sources with unknown orientations a situation that commonly arises
even with simple imaging tasks Based on a principled cost function and fast convergent update
Normalized Intensity
Time
Figure Real-world example Left Somatosensory reconstruction Middle Bilateral auditory reconstruction Right Recovered timecourse from left auditory cortex right auditory cortex not
shown is similar
rules this procedure displays significant theoretical and empirical advantages over many existing
methods We have restricted most of our exposition and analyses to MEG however preliminary
work with EEG is also promising For example on a real-world passive visual task where subjects
viewed flashing foreground/background textured images our method correctly localizes activity to
the lateral occipital cortex while two state-of-the-art beamformers fail This remains an active area
of research

<<----------------------------------------------------------------------------------------------------------------------->>

title: 5927-a-generalization-of-submodular-cover-via-the-diminishing-return-property-on-the-integer-lattice.pdf

A Generalization of Submodular Cover via the
Diminishing Return Property on the Integer Lattice
Tasuku Soma
The University of Tokyo
tasuku soma@mist.i.u-tokyo.ac.jp
Yuichi Yoshida
National Institute of Informatics and
Preferred Infrastructure Inc.
yyoshida@nii.ac.jp
Abstract
We consider a generalization of the submodular cover problem based on the concept of diminishing return property on the integer lattice We are motivated by
real scenarios in machine learning that cannot be captured by traditional submodular set functions We show that the generalized submodular cover problem
can be applied to various problems and devise a bicriteria approximation algorithm Our algorithm is guaranteed to output a log-factor approximate solution
that satisfies the constraints with the desired accuracy The running time of our
algorithm is roughly O(n log(nr log where is the size of the ground set and
is the maximum value of a coordinate The dependency on is exponentially
better than the naive reduction algorithms Several experiments on real and artificial datasets demonstrate that the solution quality of our algorithm is comparable
to naive algorithms while the running time is several orders of magnitude faster
Introduction
A function 2S is called submodular if for
all where is a finite ground set An equivalent and more intuitive definition is by
the diminishing return property for all and
In the last decade the optimization of a submodular function has attracted particular
interest in the machine learning community One reason of this is that many real-world models
naturally admit the diminishing return property For example document summarization
influence maximization in viral marketing and sensor placement can be described with the
concept of submodularity and efficient algorithms have been devised by exploiting submodularity
for further details refer to
A variety of proposed models in machine learning 13 boil down to the submodular cover
problem for given monotone and nonnegative submodular functions 2S and
we are to
minimize
subject to
Intuitively and represent the cost and the quality of a solution respectively The objective of this problem is to find of minimum cost with the worst quality guarantee Although this
problem is NP-hard since it generalizes the set cover problem a simple greedy algorithm achieves
tight log-factor approximation and it practically performs very well
The aforementioned submodular models are based on the submodularity of a set function a function
defined on 2S However we often encounter problems that cannot be captured by a set function Let
us give two examples
Sensor Placement Let us consider the following sensor placement scenario Suppose that we
have several types of sensors with various energy levels We assume a simple trade-off between
information gain and cost Sensors of a high energy level can collect a considerable amount of
information but we have to pay a high cost for placing them Sensors of a low energy level can
be placed at a low cost but they can only gather limited information In this scenario we want to
decide which type of sensor should be placed at each spot rather than just deciding whether to place
a sensor or not Such a scenario is beyond the existing models based on submodular set functions
Optimal Budget Allocation A similar situation also arises in the optimal budget allocation problem In this problem we want to allocate budget among ad sources so that at least a certain
number of customers is influenced while minimizing the total budget Again we have to decide
how much budget should be set aside for each ad source and hence set functions cannot capture the
problem
We note that a function 2S can be seen as a function defined on a Boolean hypercube
Then the above real scenarios prompt us to generalize the submodularity and the diminishing return property to functions defined on the integer lattice ZS The most natural generalization
of the diminishing return property to a function ZS is the following inequality
for and where is the s-th unit vector If satisfies then also satisfies the
following lattice submodular inequality
for all ZS where and are the coordinate-wise max and min operations respectively
While the submodularity and the diminishing return property are equivalent for set functions this
is not the case for functions over the integer lattice the diminishing return property is stronger
than the lattice submodular inequality We say that is lattice submodular if satisfies
and if further satisfies we say that is diminishing return submodular DR-submodular for
short One might feel that the DR-submodularity is too restrictive However considering the
fact that the diminishing return is more crucial in applications we may regard the DR-submodularity
as the most natural generalization of the submodularity at least for applications mentioned so
far For example under a natural condition the objective function in the optimal budget allocation satisfies The DR-submodularity was also considered in the context of submodular
welfare
In this paper we consider the following generalization of the submodular cover problem for set
functions Given a monotone DR-submodular function ZS a subadditive function
ZS and we are to
minimize
subject to
ZS
where we say that is subadditive if c(x for all
We call problem
the DR-submodular cover problem This problem encompasses problems that boil down to the submodular cover problem for set functions and their generalizations to the integer lattice Furthermore
the cost function is generalized to a subadditive function In particular we note that two examples
given above can be rephrased using this problem Section for details
If is also monotone DR-submodular one can reduce the problem to the set version for
technical details see Section The problem of this naive reduction is that it only yields a
pseudo-polynomial time algorithm the running time depends on rather than log Since can be
huge in many practical settings the maximum energy level of a sensor even linear dependence
on could make an algorithm impractical Furthermore for a general subadditive function this
naive reduction does not work
Our Contribution
For the problem we devise a bicriteria approximation algorithm based on the decreasing threshold technique of More precisely our algorithm takes the additional parameters
The
output of our algorithm is guaranteed to satisfy that is at most log
times the optimum and where is the curvature of Section for the definition maxs is the maximum value of over all standard unit vectors and is the
minimum value of the positive increments of in the feasible region
Running Time dependency on An important feature of our algorithm is that the running
time depends on the bit length of only polynomially whereas the naive reduction algorithms depend on it exponentially as mentioned above More precisely the running time of our algorithm is
max
log nrc
cmin log which is polynomial in the input size whereas the naive algorithm is only
psuedo-polynomial time algorithm In fact our experiments using real and synthetic datasets show
that our algorithm is considerably faster than naive algorithms Furthermore in terms of the objective value that is the cost of the output our algorithm also exhibits comparable performance
Approximation Guarantee Our approximation guarantee on the cost is almost tight Note that
the DR submodular cover problem includes the set cover problem in which we are given a
collection of sets and we want to find a minimum number of sets that covers all the elements In
our context corresponds to the collection of sets the cost is the number of chosen sets and
is the number of covered elements It is known that we cannot obtain an o(log m)-approximation
unless NP where is the number of elements However since for the set cover problem
we have and our approximation guarantee is O(log
Related Work
Our result can be compared with several results in the literature for the submodular cover problem
for set functions It is shown by Wolsey that if a simple greedy algorithm yields
log approximation which coincides with our approximation ratio except for the
factor Note that when or more generally when is modular Recently Wan
discussed a slightly different setting in which is also submodular and both and
are integer valued They proved that the greedy algorithm achieves H(d)-approximation where
is the d-th harmonic number Again their ratio asymptotically coincides
with our approximation ratio Note that when is integer valued
Another common submodular-based model in machine learning is in the form of the submodular
maximization problem Given a monotone submodular set function and a feasible
set a matroid polytope or a knapsack polytope we want to maximize subject
to Such models can be widely found in various tasks as already described We
note that the submodular cover problem and the submodular maximization problem are somewhat
dual to each other Indeed Iyer and Bilmes showed that a bicriteria algorithm of one of these
problems yields a bicriteria algorithm for the other Being parallel to our setting generalizing the
submodular maximization problem to the integer lattice ZS is a natural question In this direction
Soma considered the maximization of lattice submodular functions not necessarily being
DR-submodular and devised a constant-factor approximation pseudo-polynomial time algorithm
We note that our result is not implied by via the duality of In fact such reduction only
yields a pseudo-polynomial time algorithm
Organization of This Paper
The rest of this paper is organized as follows Section sets the mathematical basics of submodular functions over the integer lattice Section describes our algorithm and the statement of our
main theorem In Section we show various experimental results using real and artificial datasets
Section sketches the proof of the main theorem Finally we conclude the paper in Section
Preliminaries
Let be a finite set For each we denote the s-th unit vector by that is
if otherwise A function ZS is said to be lattice submodular if
for all ZS A function is monotone if
for all ZS with For ZS and a function ZS we denote
A function is diminishing return submodular DR-submodular if
for each ZS and S. For a DR-submodular
function one can immediately check that for arbitrary
and A function is subadditive if for ZS For each
ZS we define to be the multiset in which each is contained times
In a lattice submodular function ZS is said to have the diminishing return property if
is coordinate-wise concave for each ZS and
S. We note that our definition is consistent with Formally we have the following lemma
whose proof can be found in Appendix
Lemma A function ZS is DR-submodular if and only if is lattice submodular and
coordinate-wise concave
The following is fundamental for a monotone DR-submodular function A proof is placed in Appendix due to the limitation of space
Lemma For a monotone DR-submodular function for
arbitrary ZS
Algorithm for the DR-submodular Cover
Recall the DR-submodular cover problem Let ZS be a monotone DR-submodular
function and let ZS be a subadditive cost function The objective is to minimize
subject to and where and are the given constants Without
loss of generality we can assume that max{f otherwise we can consider
fb(x min{f instead of Furthermore we can assume for any ZS
A pseudocode description of our algorithm is presented in Algorithm The algorithm can be viewed
as a modified version of the greedy algorithm and works as follows We start with the initial solution
and increase each coordinate of gradually To determine the amount of increments the
algorithm maintains a threshold that is initialized to be sufficiently large enough For each
the algorithm finds the largest integer step size such that the marginal cost-gain
ratio
is above the threshold If such exists the algorithm updates to k?s After
repeating this for each the algorithm decreases the threshold by a factor of If
becomes feasible the algorithm returns the current Even if does not become feasible the final
satisfies if we iterate until gets sufficiently small
Algorithm Decreasing Threshold for the DR-Submodular Cover Problem
Input ZS ZS
Output r1 such that
max cmin min cmax max
s?S
s?S
s?S
for cmin
ncmax
do
for all do
Find maximum integer such that
If such exists then k?s
If then break the outer for loop
return
kc(?s
with binary search
Before we claim the theorem we need to define several parameters on and Let min{f
ZS and maxs Let cmax maxs and
cmin mins Define the curvature of to be
min
optimal solution
Definition For and a vector ZS is a bicriteria approximate
solution if and
Our main theorem is described below We sketch the proof in Section
Theorem Algorithm outputs a log bicriteria approximate solution
max
in log nrc
cmin log time
Discussion
Integer-valued Case Let us make a simple remark on the case that is integer valued Without
loss of generality we can assume Then Algorithm always returns a feasible solution for
any Therefore our algorithm can be easily modified to an approximation algorithm
if is integer valued
Definition of Curvature Several authors use a different notion of curvature called the
total curvature whose natural extension for a function over the integer lattice is as follows The
total curvature of ZS is defined as mins?S
Note that
if is modular while if is modular For example Iyer and Bilmes devised a bicriteria
approximation algorithm whose approximation guarantee is roughly log
Let us investigate the relation between and for DR-submodular functions One can show that
Lemma in Appendix which means that our bound in terms of
is tighter than one in terms of
Comparison to Naive Reduction Algorithm If is also a monotone DR-submodular function
one can reduce to the set version as follows For each create copies of and let
define ZS be the integral vector such that
be the set of these copies For
Then
is submodular Similarly
is the number of copies of contained in
c(x is also submodular if is a DR-submodular function Therefore we may apply a
standard greedy algorithm of to the reduced problem and this is exactly what Greedy does
in our experiment Section However this straightforward reduction only yields a pseudo nr even if the original algorithm was linear the resulting
polynomial time algorithm since
algorithm would require O(nr time Indeed this difference is not negligible since can be quite
large in practical applications as illustrated by our experimental evaluation
Lazy Evaluation We finally note that we can combine the lazy evaluation technique
which significantly reduces runtime in practice with our algorithm Specifically we first push all
the elements in to a max-based priority queue Here the key of an element is
Then
the inner loop of Algorithm is modified as follows Instead of checking all the elements in
we pop elements whose keys are at least For each popped element we find such that
with
with binary search If there is such we update with
k?s Finally we push again with the key
if
The correctness of this technique is obvious because of the DR-submodularity of In particular
where is the current vector
the key of each element in the queue is always at least
Hence we never miss with
kc(?s
Experiments
Experimental Setting
We conducted experiments on a Linux server with an Intel Xeon GHz processor and
GB of main memory The experiments required at most GB of memory All the algorithms
were implemented in and compiled with
In our experiments the cost function ZS is always chosen as kxk1
s?S Let be a submodular function and be the worst quality guarantee
We implemented the following four methods
Decreasing-threshold is our method with the lazy evaluation technique We chose
as stated otherwise
Greedy is a method in which starting from we iteratively increment for
that maximizes until we get We also implemented the lazy
evaluation technique
Degree is a method in which we assign a value proportional to the marginal
where kxk1 is determined by binary search so that Precisely speaking
is approximately proportional to the marginal since must be an integer
Uniform is a method that returns k1 for minimum such that
We use the following real-world and synthetic datasets to confirm the accuracy and efficiency of our
method against other methods We set for both problems
Sensor placement We used a dataset acquired by running simulations on a 129-vertex sensor
network used in Battle of the Water Sensor Networks BWSN We used the bwsn-utilities
program to simulate random injection events to this network for a duration of 96 hours Let
and be the set of the sensors in the network and the set of the events respectively For
each sensor and event a value is provided which denotes the time in minutes
the pollution has reached after the injection time.1
We define a function ZS as follows Let ZS be a vector where we regard as
the energy level of the sensor Suppose that when the pollution reaches a sensor the probability
that we can detect it is
where In other words by spending unit energy
we obtain an extra chance of detecting the pollution with probability For each event let se
be the first sensor where the pollution is detected in that injection event Note that se is a random
variable Let max Then we define as follows
e?E,s?S
z(se
e?E se
where z(se is defined as when there is no sensor that managed to detect the pollution Intuitively speaking z(se expresses how much time we managed to save in the event
se
on average Then we take the average over all the events A similar function was also used in
to measure the performance of a sensor allocation although they only considered the case
This corresponds to the case that by spending unit energy at a sensor we can always detect the
pollution that has reached We note that is DR-submodular Lemma for the proof
Budget allocation problem In order to observe the behavior of our algorithm for large-scale
instances we created a synthetic instance of the budget allocation problem as follows The
instance can be represented as a bipartite graph where is a set of vertices and
is a set of vertices We regard a vertex in as an ad source and a vertex in as a person
Then we fix the degrees of vertices in so that their distribution obeys the power law of
that is the fraction of ad sources with out-degree is proportional to For a vertex of
the supposed degree we choose vertices in uniformly at random and connect them to with
edges We define a function ZS as
t?T
where is the set of vertices connected to and Here we suppose that by investing
a unit cost to an ad source we have an extra chance of influencing a person with
with probability Then can be seen as the expected number of people influenced
by ad sources We note that is known to be a monotone DR-submodular function
Experimental Results
Figure illustrates the obtained objective value kxk1 for various choices of the worst quality guarantee on each dataset We chose in Decreasing threshold We can observe that Decreasing threshold attains almost the same objective value as Greedy and it outperforms Degree
and Uniform
Figure illustrates the runtime for various choices of the worst quality guarantee on each dataset
We chose in Decreasing threshold We can observe that the runtime growth of Decreasing threshold is significantly slower than that of Greedy
Although three other values are provided they showed similar empirical results and we omit them
Sensor placement BWSN
Greedy
time
Greedy
Decreasing threshold
Degree
Uniform
Relative cost increase
Greedy
Decreasing threshold
Degree
Uniform
Sensor placement BWSN
Objective value
Relative increase of the objective value
time
Objective value
Uniform
Decreasing threshold
Degree
Greedy
time
Uniform
Decreasing threshold
Degree
Greedy
Budget allocation synthetic
Budget allocation synthetic
Runtime
Figure Objective values
Figure Runtime
Figure Effect of
Figures and show the relative increase of the objective value and the runtime respectively
of our method against Greedy on the BWSN dataset We can observe that the relative increase of the
objective value gets smaller as increases This phenomenon can be well explained by considering
the extreme case that max In this case we need to choose r1 anyway in order to
achieve the worst quality guarantee and the order of increasing coordinates of does not matter
Also we can see that the empirical runtime grows as a function of which matches our theoretical
bound
Proof of Theorem
In this section we outline the proof of the main theorem Proofs of some minor claims can be found
in Appendix
First we introduce a notation Let us assume that is updated times in the algorithm Let be
the variable after the i-th update L). Note that and xL is the final output of
the algorithm Let si and ki be the pair used in the i-th update for that is
c(?si
for L. Let
ki si for L. Let and kii?s
and
for where is the threshold value on the i-thP
update Note that
for L. Let be an optimal solution such that
We regard that in the i-th update the elements of are charged by the value of
Then the total charge on is defined as
Claim Let us fix arbitrary and let be the threshold value on the i-th update Then
ki si
and
S).
ki c(?si
Eliminating from the inequalities in Claim we obtain
ki c(?si
ki si
Furthermore we have
Claim
for L.
Claim For each the total charge on is at most
Proof Let us fix and let be the minimum such that By we have
ki c(?si
ki si
Then we have
since log for
log
log
log
Proof of Theorem Combining these claims we have
log
log
Thus is an approximate solution with the desired ratio
Let us see that approximately satisfies the constraint that is We will now
consider a slightly modified version of the algorithm in the modified algorithm the threshold is
updated until Let be the output of the modified algorithm Then we have
cmax nr
The third inequality holds since cmax and nr Thus
Conclusions
In this paper motivated by real scenarios in machine learning we generalized the submodular cover
problem via the diminishing return property over the integer lattice We proposed a bicriteria approximation algorithm with the following properties The approximation ratio to the cost almost
matches the one guaranteed by the greedy algorithm and is almost tight in general We can
satisfy the worst solution quality with the desired accuracy iii The running time of our algorithm
is roughly O(n log log The dependency on is exponentially better than that of the greedy algorithm We confirmed by experiment that compared with the greedy algorithm the solution quality
of our algorithm is almost the same and the runtime is several orders of magnitude faster
Acknowledgments
The first author is supported by JSPS Grant-in-Aid for JSPS Fellows The second author is supported
by JSPS Grant-in-Aid for Young Scientists MEXT Grant-in-Aid for Scientific
Research on Innovative Areas and JST ERATO Kawarabayashi Large Graph Project
The authors thank Satoru Iwata and Yuji Nakatsukasa for reading a draft of this paper

<<----------------------------------------------------------------------------------------------------------------------->>

