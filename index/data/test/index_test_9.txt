query sentence: deployment of fault tolerant clouds
---------------------------------------------------------------------
title: 50-an-adaptive-and-heterodyne-filtering-procedure-for-the-imaging-of-moving-objects.pdf

AN ADAPTIVE AND HETERODYNE FILTERING PROCEDURE
FOR THE IMAGING OF MOVING OBJECTS
F. H. Schuling H. A. K. Mastebroek and W. H. Zaagman
Biophysics Department Laboratory for General Physics
Westersingel 34 eM Groningen The Netherlands
ABSTRACT
Recent experimental work on the stimulus velocity dependent time resolving
power of the neural units situated in the highest order optic ganglion of the
blowfly revealed the at first sight amazing phenomenon that at this high level of
the fly visual system the time constants of these units which are involved in the
processing of neural activity evoked by moving objects are roughly spokeninverse proportional to the velocity of those objects over an extremely wide range
In this paper we will discuss the implementation of a two dimensional heterodyne
adaptive filter construction into a computer simulation model The features of this
simulation model include the ability to account for the experimentally observed
stimulus-tuned adaptive temporal behaviour of time constants in the fly visual
system The simulation results obtained clearly show that the application of such
an adaptive processing procedure delivers an improved imaging technique of
moving patterns in the high velocity range
A FEW REMARKS ON THE FLY VISUAL SYSTEM
The visual system of the diptera including the blowfly Calliphora
erythrocephala is very regularly organized and allows therefore very precise
optical stimulation techniques Also long term electrophysiological recordings can
be made relatively easy in this visual system For these reasons the blowfly which
is well-known as a very rapid and clever pilot turns out to be an extremely
suitable animal for a systematic study of basic principles that may underlie the
detection and further processing of movement information at the neural level
In the fly visual system the input retinal mosaic structure is precisely
mapped onto the higher order optic ganglia lamina medulla lobula This means
that each neural column in each ganglion in this visual system corresponds to a
certain optical axis in the visual field of the compound eye In the lobula complex
a set of wide-field movement sensitive neurons is found each of which integrates
the input signals over the whole visual field of the entire eye One of these wide
field neurons that has been classified as I by Hausen has been extensively
studied both anatomically2 as well as electrophysiologically5 The
obtained results generally agree very well with those found in behavioral
optomotor experiments on movement detection and can be understood in terms of
Reichardts correlation model
The I neuron is sensitive to horizontal movement and directionally
selective very high rates of action potentials spikes up to per second can be
recorded from this element in the case of visual stimuli which move horizontally
inward from back to front in the visual field pre/erred direction whereas
movement horizontally outward from front to back null direction suppresses
its activity
American Institute of Physics
EXPERIMENTAL RESULTS AS A MODELLING BASE
When the I neuron is stimulated in its preferred direction with a step wise
pattern displacement it will respond with an increase of neural activity By
repeating this stimulus step over and over one can obtain the averaged response
after a ms latency period the response manifests itself as a sharp increase in
average firing rate followed by a much slower decay to the spontaneous activity
level Two examples of such averaged responses are shown in the Post Stimulus
Time Histograms PSTH's of figure Time to peak and peak height are related
and depend on modulation depth stimulus step size and spatial extent of the
stimulus The tail of the responses can be described adequately by an exponential
decay toward a constant spontaneous firing rate
For each setting of the stimulus parameters the response parameters
defined by equation can be estimated by a least-squares fit to the tail of the
PSTH The smooth lines in figure are the results of two such fits
tlmsl
OJ
I'JO
tf
MoO IO
Mdl05
Fig.l
I
lsI
A veraged responses PSTH's obtained from the I neuron being
adapted to smooth stimulus motion with velocities top and
bottom respectively The smooth lines represent least-squares
fits to the PSTH's of the form Values of for the
two PSTH's are and 24 ms respectively de Ruyter van Steveninck
Fitted values of as a function of adaptation velocity for three
modulation depths M. The straight line is a least-squares fit to represent
the data for in the region It has the form
f=Q with ms and de Ruyter van Steveninck
Fig.2
Figure shows fitted values of the response time constant as a function of
the angular velocity of a moving stimulus square wave grating in most
experiments which was presented to the animal during a period long enough to let
its visual system adapt to this moving pattern and before the step wise pattern
displacement which reveals was given The straight line described by
with in Is and in ms represents a least-squares fit to the data over the
velocity range from to Is. For this range varies from to roughly
ms with ms and Defining the adaptation range of as
that interval of velocities for which decreases with increasing velocity we may
conclude from figure that within the adaptation range is not very sensitive to
the modulation depth
The outcome of similar experiments with a constant modulation depth of the
pattern and a constant pattern velocity but with four different values of
the contrast frequency fc the number of spatial periods per second that
traverse an individual visual axis as determined by the spatial wavelength As of the
pattern and the pattern velocity according to fc=v lAs reveal also an almost
complete independency of the behaviour of on contrast frequency Other
experiments in which the stimulus field was subdivided into regions with different
adaptation velocities made clear that the time constants of the input channels of
the I neuron were set locally by the values of the stimulus velocity in each
stimulus sub-region Finally it was found that the adaptation of is driven by
the stimulus velocity independent of its direction
These findings can be summarized qualitatively as follows in steady state
the response time constants of the neural units at the highest level in the fly
visual system are found to be tuned locally within a large velocity range
exclusively by the magnitude of the velocity of the moving pattern and not by its
direction despite the directional selectivity of the neuron itself We will not go
into the question of how this amazing adaptive mechanism may be hard-wired in
the fly visual system Instead we will make advantage of the results derived thus
far and attempt to fit the experimental observations into an image processing
approach A large number of theories and several distinct classes of algorithms to
encode velocity and direction of movement in visual systems have been suggested
by for example Marr and Ullman I I and van Santen and Sperling12
We hypothesize that the adaptive mechanism for the setting of the time
constants leads to an optimization for the overall performance of the visual system
by realizing a velocity independent representation of the moving object In other
words within the range of velocities for which the time constants are found to be
tuned by the velocity the representation of that stimulus at a certain level within
the visual circuitry should remain independent of any variation in stimulus
velocity
OBJECT MOTION DEGRADATION MODELLING
Given the physical description of motion and a linear space invariant model
the motion degradation process can be represented by the following convolution
integral
co co
JJ
flu dudv
where is the object intensity at position in the object coordinate
frame is the Point Spread Function PSF of the imaging system
which is the response at to a unit pulse at and is the image
intensity at the spatial position as blurred by the imaging system Any
possible additive white noise degradation of the already motion blurred image is
neglected in the present considerations
For a review of principles and techniques in the field of digital image
degradation and restoration the reader is referred to Harris 13 Sawchuk
Sondhi Nahi A boutalib 17 18 Hildebrand 19 Rajala de Figueiredo20
It has been demonstrated first by Aboutalib that for situations in which
the motion blur occurs in a straight line along one spatial coordinate say along the
horizontal axis it is correct to look at the blurred image as a collection of
degraded line scans through the entire image The dependence on the vertical
coordinate may then be dropped and eq reduces to
f(u)du
Given the mathematical description of the relative movement
corresponding PSF can be derived exactly and equation becomes
b(x f(u)du
the
where is the extent of the motion blur Typically a discrete version of
applicable for digital image processing purposes is described by
I
where and I take on integer values and is related to the motion blur extent
According to Aboutalib 18 a scalar difference equation model
can then be derived to model the motion degradation process
cmA(i-m
where is the m-dimensional state vector at position along a scan line is
the input intensity at position is the output intensity is the blur extent
is the number of elements in a line is a scalar a and are constant
matrices of order mxl and lxm respectively containing the discrete
values Cj of the blurring PSF for and is the Kronecker delta
function
INFLUENCE OF BOTH TIME CONSTANT AND VELOCITY
ON THE AMOUNT OF MOTION BLUR IN AN ARTIFICIAL
RECEPTOR ARRAY
To start with we incorporate in our simulation model a PSF derived from
equation to model the performance of all neural columnar arranged filters in
the lobula complex with the restriction that the time constants remain fixed
throughout the whole range of stimulus velocities Realization of this PSF can
easily be achieved via the just mentioned state space model
I.
I.
Fig.3
POSITION IN
ARTIFICIAL RECEPTOR ARRAY
upper part Demonstration of the effect that an increase in magnitude of
the time constants of an one-dimensional array of filters will result in
increase in motion blur while the pattern velocity remains constant
Original pattern shown in solid lines is a square-wave grating with a
spatial wavelength equal to artificial receptor distances The three
other wave forms drawn show that for a gradual increase increase in
magnitude of the time constants the representation of the original
square-wave will consequently degrade lower part A gradual increase in
velocity of the moving square-wave while the filter time constants are
kept fixed results also in a clear increase of degradation
First we demonstrate the effect that an increase in time constant while the
pattern velocity remains the same will result in an increase in blur Therefore we
introduce an one dimensional array of filters all being equipped with the same
time constant in their impulse response The original pattern shown in square and
solid lines in the upper part of figure consists of a square wave grating with a
spatial period overlapping artificial receptive filters The other patterns drawn
there show that for the same constant velocity of the moving grating an increase
in the magnitude of the time constants of the filters results in an increased blur in
the representation of that grating On the other hand an increase in velocity
while the time constants of the artificial receptive units remain the same also
results in a clear increase in motion blur as demonstrated in the lower part of
figure
Inspection of the two wave forms drawn by means of the dashed lines in
both upper and lower half of the figure yields the conclusion that apart from
rounding errors introduced by the rather small number of artificial filters
available equal amounts of smear will be produced when the product of time
constant and pattern velocity is equal For the upper dashed wave form the
velocity was four times smaller but the time constant four times larger than for its
equivalent in the lower part of the figure
ADAPTIVE SCHEME
In designing a proper image processing procedure our next step is to
incorporate the experimentally observed flexibility property of the time constants
in the imaging elements of our device In figure 4a a scheme is shown which
filters the information with fixed time constants not influenced by the pattern
velocity In figure 4b a network is shown where the time constants also remain
fixed no matter what pattern movement is presented but now at the next level of
information processing a spatially differential network is incorporated in order to
enhance blurred contrasts
In the filtering network in figure 4c first a measurement of the magnitude
of the velocity of the moving objects is done by thus far hypothetically introduced
movement processing algorithms modelled here as a set of receptive elements
sampling the environment in such a manner that proper estimation of local pattern
velocities can be done Then the time constants of the artificial receptive elements
will be tuned according to the estimated velocities and finally the same
differential network as in scheme 4b is used
The actual tuning mechanism used for our simulations is outlined in figure
once given the range of velocities for which the model is supposed to be
operational and given a lower limit for the time constant min min can be the
smallest value which physically can be realized the time constant will be tuned to
a new value according to the experimentally observed reciprocal relationship and
will for all velocities within the adaptive range be larger than the fixed minimum
value As demonstrated in the previous section the corresponding blur in the
representation of the moving stimulus will thus always be larger than for the
situation in which the filtering is done with fixed and smallest time constants
min More important however is the fact that due to this tuning mechanism the
blur will be constant since the product of velocity and time constant is kept
constant So once the information has been processed by such a system a velocity
independent representation of the image will be the result which can serve as the
input for the spatially differentiating network as outlined in figure 4c
The most elementary form for this differential filtering procedure is the one
in which the gradient of two filters K-I and K+l which are the nearest neighbors
of filter is taken and then added with a constant weighing factor to the central
output as drawn in figure and where the sign of the gradient depends on
the direction of the estimated movement Essential for our model is that we claim
that this weighing factor should be constant throughout the whole set of filters
and for the whole high velocity range in which the heterodyne imaging has to be
performed Important to notice is the existence of a so-called settling time the
minimal time needed for our movement processing device to be able to accurately
measure the object velocity Note this time can be set equal to zero in the case
that the relative stimulus velocity is known a priori as demonstrated in figure
Since without doubt within this settling period estimated velocity values will
come out erroneously and thus no optimal performance of our imaging device can
be expected in all further examples results after this initial settling procedure
will be shown
A
yV
rYO
i~J
t"if
Pattern movement in this figure is to the right
A Network consisting of a set of filters with a fixed pattern velocity
independent time constant in their impulse response
Identical network as in figure 4A now followed by a spatially
differentiating circuitry which adds the weighed gradients of two
neighboring filter outputs K-l and K+I to the central filter output
K.
The time constants of the filtering network are tuned by a
hypothetical movement estimating mechanism visualized here as a
number of receptive elements of which the combined output tunes
the filters A detailed description of this mechanism is shown in
figure This tuned network is followed by an identical spatially
differentiating circuit as described in figure
increasing velocity
decreasing time constant
min
Detailed description of the mechanism used to tune the time constants
The time constant of a specific neural channel is set by the pattern
velocity according to the relationship shown in the insert which is
derived from eq with I and I.
4r
I
I
I
I
I
I
I
I
4V
I
I
a
2V
Wi
8V
I
POSITION IN ARTIFICIAL RECEPTOR ARRAY
Fig.6
Thick lines square-wave stimulus pattern with a spatial wavelength
overlapping 32 artificial receptive elements Thick lines responses for
different pattern velocities in a system consisting of paralleling neural
filters equipped with time constants tuned by this velocity and followed
by a spatially differentiating network as described
Dashed lines responses to the different pattern velocities in a filtering
system with fixed time constants followed by the same spatial
differentiating circuitry as before Note the sharp over and under
shoots for this case
Results obtained with an imaging procedure as drawn in figure and 4c
are shown in figure The pattern consists of a square wave overlapping 32
picture elements The pattern moves to the left with different velocities
At each velocity only one wavelength is shown Thick lines
square wave pattern Dashed lines the outputs of an imaging device as depicted in
figure constant time constants and a constant weighing factor in the spatial
processing stage Note the large differences between the several outputs Thin
continuous lines the outputs of an imaging device as drawn in figure tuned
time constants according to the reciprocal relationship between pattern velocity
and time constant and a constant weighing factor in the spatial processing stage
For further simulation details the reader is referred to Zaagman Now the
outputs are almost completely the same and in good agreement with the original
stimulus throughout the whole velocity range
Figure shows the effect of the gradient weighing factor on the overall
filter performance estimated as the improvement of the deblurred images as
compared with the blurred image measured in dB This quantitative measure has
been determined for the case of a moving square wave pattern with motion blur
IX
ItI
a
weighing factor
Effect of the weighing factor on the overall filter performance Curve
measured for the case of a moving square-wave grating Filter
performance is estimated as the improvement in signal to noise ratio
I:iI
where is the original intensity at position in the image
is the intensity at the same position in the motion blurred image and
is the intensity at in the image generated with the adaptive
tuning procedure
extents comparable to those used for the simulations to be discussed in section IV.
From this curve it is apparent that for this situation there is an optimum value for
this weighing factor Keeping the weight close to this optimum value will result in
a constant output of our adaptive scheme thus enabling an optimal deblurring of
the smeared image of the moving object
On the other hand starting from the point of view that the time constants
should remain fixed throughout the filtering process we should had have to tune
the gradient weights to the velocity in order to produce a constant output as
demonstrated in figure where the dashed lines show strongly differing outputs of
a fixed time constant system with spatial processing with constant weight figure
4b In other words tuning of the time constants as proposed in this section results
in I the realization of the blur-constancy criterion as formulated previously and
as a consequence the possibility to deblur the obtained image oPtimally with
one and the same weighing factor of the gradient in the final spatial processing
layer over the whole heterodyne velocity range
COMPUTER SIMULATION RESULTS AND
CONCLUSIONS
The image quality improvement algorithm developed in the present
contribution has been implemented on a general purpose DG Eclipse Sjl40 minicomputer for our two dimensional simulations Figure Sa shows an undisturbed
image consisting of lines of each pixels with bit intensity resolution
Figure Sb shows what happens with the original image if the PSF is modelled
according to the exponential decay In this case the time constants of all
spatial information processing channels have been kept fixed Again information
content in the higher spatial frequencies has been reduced largely The
implementation of the heterodyne filtering procedure was now done as follows
first the adaptation range was defined by setting the range of velocities This
means that our adaptive heterodyne algorithm is supposed to operate adequately
only within the thus defined velocity range and that in that range the time
constants are tuned according to relationship and will always come out larger
than the minimum value min For demonstration purposes we set Q=I and in
eq thus introducing the phenomenon that for any velocity the two
dimensional set of spatial filters with time constants tuned by that velocity will
always produce a constant output independent of this velocity which introduces
the motion blur Figure Sc shows this representation It is important to note here
that this constant output has far more worse quality than any set of filters with
smallest and fixed time constants min would produce for velocities within the
operational range The advantage of a velocity independent output at this level in
our simulation model is that in the next stage a differential scheme can be
implemented as discussed in detail in the preceding paragraph Constancy of the
weighing factor which is used in this differential processing scheme is guaranteed
by the velocity independency of the obtained image representation
Figure Sd shows the result of the differential operation with an optimized
gradient weighing factor This weighing factor has been optimized based on an
almost identical performance curve as described previously in figure A clear
and good restoration is apparent from this figure though close inspection reveals
fine structure especially for areas with high intensities which is unrelated with
the original intensity distribution These artifacts are caused by the phenomenon
that for these high intensity areas possible tuning errors will show up much more
pronounced than for low intensities
Fig.8a
Fig.8b
8c
Fig.8d
a
Original bit picture
Motion degraded image with a PSF derived from
where is kept fixed to pixels and the motion blur extent is 32
pixels
Worst case the result of motion degradation of the original image
with a PSF as in figure 8b but with tuning of the time constants based
on the velocity
Restored version of the degraded image using the heterodyne adaptive
processing scheme
In conclusion a heterodyne adaptive image processing technique inspired by
the fly visual system has been presented as an imaging device for moving objects
A scalar difference equation model has been used to represent the motion blur
degradation process Based on the experimental results described and on this state
space model we developed an adaptive filtering scheme which produces at a
certain level within the system a constant output permitting further differential
operations in order to produce an optimally deblurred representation of the
moving object
ACKNOWLEDGEMENTS
The authors wish to thank mT Eric Bosman for his expert programming
assistance mr Franco Tommasi for many inspiring discussions and advises during
the implementation of the simulation model and dr Rob de Ruyter van Steveninck
for experimental help This research was partly supported by the Netherlands
Organization lor the Advancement 01 Pure Research through the
foundation Stichting voor Biolysica

<<----------------------------------------------------------------------------------------------------------------------->>

title: 53-the-connectivity-analysis-of-simple-association.pdf

The Connectivity Analysis of Simple Association
orHow Many Connections Do You Need
Dan Hammerstrom
Oregon Graduate Center Beaverton OR
ABSTRACT
The efficient realization using current silicon technology of Very Large Connection
Networks VLCN with more than a billion connections requires that these networks exhibit
a high degree of communication locality Real neural networks exhibit significant locality
yet most connectionist/neural network models have little In this paper the connectivity
requirements of a simple associative network are analyzed using communication theory
Several techniques based on communication theory are presented that improve the robustness of the network in the face of sparse local interconnect structures Also discussed are
some potential problems when information is distributed too widely
INTRODUCTION
Connectionist/neural network researchers are learning to program networks that exhibit a broad range of cognitive behavior Unfortunately existing computer systems are limited in their ability to emulate such networks efficiently The cost of emulating a network
whether with special purpose highly parallel silicon-based architectures or with traditional
parallel architectures is directly proportional to the number of connections in the network
This number tends to increase geometrically as the number of nodes increases Even with
large massively parallel architectures connections take time and silicon area Many existing neural network models scale poorly in learning time and connections precluding large
implementations
The connectivity costs of a network are directly related to its locality A network
exhibits locality 01 communication if most of its processing elements connect to other physically adjacent processing elements in any reasonable mapping of the elements onto a planar
surface There is much evidence that real neural networks exhibit locality2 In this paper
a technique is presented for analyzing the effects of locality on the process of association
These networks use a complex node similar to the higher-order learning units of Maxwell
NETWORK MODEL
The network model used in this paper is now defined Figure
Definition A recursive neural network called a c-graph is a graph structure
where
There is a set of CNs network nodes whose outputs can take a range of positive
real values Vi between and There are N. nodes in the set
There is a set of codons that can take a range of positive real values eij for
codon of node between and There are Ne codons dedicated to each CN the
output of each codon is only used by its local so there are a total of Ne N. codons
in the network The fan-in or order of a codon is Ie. It is assumed that leis the
same for each codon and Ne is the same for each CN.
This work was supported in part by the Semiconductor Research Corporation contract no and
jointly by the Office of Naval Research and Air Force Office of Scientific Research ONR contract no NOOO14 87
American Institute of Physics
Ie
codon
Figure A ON
Cijk is a set of connections of ONs to codons and Ne Cijk can
take two values indicating the existence of a connection from ON to codon
of ON
Definition The value of ON is
Vi
F[8+~eijl
J-l
The function is a continuous non-linear monotonic function such as the sigmoid function
Definition Define a mapping where is an input vector to rand is
the Ie element input vector of codon of ON That is has as its elements those elements of Zk of where Cijk=1
The function indicates the subset of seen by codon of ON Different input vectors may map to the same codon vectors and D(i,j,Zj-y where
Definition The codon values eij are determined as follows Let be input vector
of the learned input vectors for ON For codon eij of ON let Tij be the set of I cdimensional vectors such that lij(m)E ij and That is each vector
lij in Tij consists of those subvectors of that are in codon ii's receptive field
The variable indexes the vectors of ij The number of distinct vectors in Tij
may be less than the total number of learned vectors Though the are
distinct the subsets lij(m need not be since there is a possible many to one mapping of
the vectors onto each vector lij
Let Xl be the subset of vectors where vi=l ON is supposed to output a and
those vectors where vi=O then define
izeof
for and that map to this I. That is is the number of
xo be
vectors that map
into Iij{l where
tlj-O
and is the number of vectors that map into Iii where
The compreaaion of a codon for a vector then is defined as
I IJ
Hqj(l)=O when both nt The output of codon
eii is the maximum-likelyhood
decoding
Where He indicates the likely hood of when a vector that maps to is input and
is that vector where I I and is the current input vector In other words is that vector of the set of subset learned vectors that codon ij
receives that is closest using distance measure to the subset input vector
The output of a codon is the most-likely output according to its inputs For example when there is no code compression at a codon if the closest terms of some
measure of vector distance Hamming distance subvector in the receptive field of the
codon belongs to a learned vector where the CN is to output a The codons described here
are very similar to those proposed by Marr and implement ne!'Lrest-neighbor classification
It is assumed that codon function is determined statically prior to network operation that
is the desired categories have already been learned
To measure performance network capacity is used
Definition The input noiae Or is the average between an input vector and the
closest minimum learned vector where is a measure of the difference between two
vectors for bit vectors this can be Hamming distance The output noise is the average
distance between network output and the learned output vector associated with the closest
learned input vector The in/ormation gain Gr is just
Gt
I
Definition The capacity of a network is the maximum number of learned vectors such
that the information gain Gr is strictly positive
COMMUNICATION ANALOGY
Consider a single connection network node or CN. The remainder of this paper will
be restricted to a single Assume that the CN output value space is restricted to two
values and Therefore the CN must decide whether the input it sees belongs to the
class of codes those codes for which it remains off or the class of codes those codes
for which it becomes active The inputs it sees in its receptive field constitute a subset of
the input vectors the function to the network It is also assumed that the CN is an
ideal I-NN Nearest Neighbor classifier or feature detector That is given a particular set
of learned vectors the CN will classify an arbitrary input according to the class of the
nearest using as a measure of distance learned vector This situation is equivalent to
the case where a single CN has a single codon whose receptive field size is equivalent to that
of the CN.
Imagine a sender who wishes to send one bit of information over a noisy channel The
sender has a probabilistic encoder that choses a code word learned vector according to
some probability distribution The receiver knows this code set though it has no knowledge
of which bit is being sent Noise is added to the code word during its transmission over the
channel which is analogous to applying an input vector to a network's inputs where the
vector lies within some learned vector's region The noise is represented by the distance
between the input vector and the associated learned vector
The code word sent over the channel consists of those bits that are seen in the receptive field of the ON being modeled In the associative mapping of input vectors to output
vectors each ON must respond with the appropriate output or for the associated
learned output vector Therefore a ON is a decoder that estimates in which class the
received code word belongs This is a classic block encoding problem where increasing the
field size is equivalent to increasing code length As the receptive field size increases the
performance of the decoder improves in the presence of noise Using communication theory
then the trade-off between interconnection costs as they relate to field size and the functionality of a node as it relates to the correctness of its decision making process output
errors can be characterized
As the receptive field size of a node increases so does the redundancy of the input
though this is dependent on the particular codes being used for the learned vectors since
there are situations where increasing the field size provides no additional information
There is a point of diminishing returns where each additional bit provides ever less reduction in output error Another factor is that interconnection costs increase exponentially
with field size The result of these two trends is a cost performance measure that has a single global maximum value In other words given a set of learned vectors and their probabilities and a set of interconnection costs a best receptive field size can be determined
beyond which increasing connectivity brings diminishing returns
SINGLE CODON WITH NO CODE COMPRESSION
A single neural element with a single codon and with no code compression can be
modelled exactly as a communication channel Figure Each network node is assumed
to have a single codon whose receptive field size is equal to that of the receptive field size of
the node
sender
I I
encoder
nOIsy
I
I
transmitter
receiver
I
decoder
ON
Figure A Transmission Channel
recelver
The operation of the channel is as follows A bit is input into the channel encoder
which selects a random code of length and transmits that code over the channel The
receiver then using nearest neighbor classification decides if the original message was either
a or a
Let be the number of code words used by the encoder The rate then indicates the
density of the code space
Definition The rate of a communication channel is
The block length corresponds directly to the receptive field size of the codon
The derivations in later sections use a related measure
Definition The code utilization is the number of learned vectors assigned to a particular code or
can be written in terms of
2N
As approaches code compression increases is essentially unbounded since may be
significantly larger than
The decode error information loss due to code compression is a random variable that
depends on the compression rate and the a priori probabilities therefore it will be different
with different learned vector sets and codons within a set As the average code utilization
for all codons approaches code compression occurs more often and codon decode error is
unavoidable
Let Zi be the vector output of the encoder and the input to the channel where each
element of Zi is either a or Let Vi be the vector output of the channel and the input to
the decoder where each element is either a or a The Noisy Channel Coding Theorem is
now presented for a general case where the individual input codes are to be distinguished The result is then extended to a CN where even though input codes are
used the ON need only distinguish those codes where it must output a from those where it
must output a The theorem is from Gallager Random codes are assumed
throughout
Theorem Let a discrete memoryless channel have transition probabilities PNU/k
and for any positive integer and positive number consider the ensemble of
block codes in which each letter of each code word is independently selected according to
fe
the probability assignment Then for each message NR
and all
the ensemble average probability of decoding error using maximum-likelyhood
decoding satisfies
where
In the definitions given here and the theorems below the notation of Gall ager is used Many of the
definitions and theorems are also from Gallager
Q(k)PU/kp!p
i-il
l+P
k-il
These results are now adjusted ror our special case
Theorem For a single CN the average channel error rate ror random code vectors is
Pe
where
I
is the probability or an input vector bit being a
These results cover a wide range or models A more easily computable expression can
be derived by recognizing some or the restrictions inherent in the CN model First assume
that all channel code bits are equally likely that is I that the error model is
the Binary Symmetric Channel and that the errors are identically distributed and
independent that is each bit has the same probability or being in error independent
or the code word and the bit position in the code word
A simplified version or the above theorem can be derived Maximizing gives the
tightest bounds
O$p~l
maxPe(p
where letting codon input be the block length I
The minimum value or this expression is obtained when for
Eo log
SINGLE-CODON WITH CODE COMPRESSION
Unfortunately the implementation complexity of a codon grows exponentially with the
size or the codon which limits its practical size An alternative is to approximate single
codon function of a single CN with many smaller overlapped codons The goal is to maintain performance and reduce implementation costs thus improving the cost/performance of
the decoding process As codons get smaller the receptive field size becomes smaller relative
to the number of CNs in the network When this happens there is codon compression or
vector alia6ing that introduces its own errors into the decoding process due to information
loss Networks can overcome this error by using multiple redundant codons with overlapping receptive fields that tend to correct the compression error
Compression occurs when two code words requiring different decoder output share the
same representation within the receptive field or the codon The following theorem gives
the probability of incorrect codon output with and without compression error
Theorem For a BSC model where the codon receptive field is Ic the code utilization is and the channel bits are selected randomly and independently the probability
of a codon decoding error when is approximately
where the expected compression error per codon is approximated by
Pc
and from equations when
exp
log
I-RI
Proof is given in Hammerstrom6
As grows Pc approaches asymptotically Thus the performance of a single codon
degrades rapidly in the presence of even small amounts of compression
MULTIPLE CODONS WITH CODE COMPRESSION
The use or mUltiple small codons is more efficient than a few large codons but there
are some fundamental performance constraints When a codon is split into two or more
smaller codons and the original receptive field is subdivided accordingly there are several
effects to be considered First the error rate of each new codon increases due to a decrease
in receptive field size the codon's block code length The second effect is that the code
utilization will increase for each codon since the same number of learned vectors is
mapped into a smaller receptive field This change also increases the error rate per codon
due to code compression In fact as the individual codon receptive fields get smaller
significant code compression occurs For higher-order input codes there is an added error
that occurs when the order of the individual codons is decreased since random codes are
being assumed this effect is not considered here The third effect is the mass action of
large numbers of codons Even though individual codons may be in error if the majority
are correct then the ON will have correct output This effect decreases the total error rate
Assume that each ON has more than one codon The union of the receptive fields
for these codons is the receptive field for the ON with no no restrictions on the degree of
overlap of the various codon receptive fields within or between ONs. For a ON with a large
number of codons the codon overlap will generally be random and uniformly distributed
Also assume that the transmission errors seen by different receptive fields are independent
Now consider what happens to a codon's compression error rate ignoring transmission
error for the time being when a codon is replaced by two or more smaller co dons covering
the same receptive field This replacement process can continue until there are only
codons which incidentally is analogous to most current neural models For a multiple
codon ON assume that each codon votes a or The summation unit then totals this
information and outputs a if the majority of codons vote for a etc
Theorem The probability of a ON error due to compression error is
Pc
where
Pc
dy
is given in equation and
Pc incorporates the two effects of moving to mUltiple smaller codons and adding more
codons Using equation 17 gives the total error probability per bit PeN
Proof is in Hammerstrom6
For networks that perform association as defined in this paper the connection weights
rapidly approach a single uniform value as the size of the network grows In information
theoretic terms the information content of those weights approaches zero as the compression increases Why then do simple non-conjunctive networks 1-codon equivalent work at
alI In the next section I define connectivity cost constraints and show that the answer to
the first question is that the general associative structures defined here do not scale costeffectively and more importantly that there are limits to the degree of distribution of information
CONNECTIVITY COSTS
It is much easier to assess costs if some implementation medium is assumed I have
chosen standard silicon which is a two dimensional surface where ON's and codons take up
surface area according to their receptive field sizes In addition there is area devoted to
the metal lines that interconnect the ONs. A specific VLSI technology need not be assumed
since the comparisons are relative thus keeping ONs codons and metal in the proper proportions according to a standard metal width which also includes the inter-metal
pitch For the analyses performed here it is assumed that
levels of metal are possible
In the previous section I established the relationship of network performance in terms
of the transmission error rate and the network capacity M. In this section I present an
implementation cost which is total silicon area A. This figure can then be used to derive a
cost/performance figure that can be used to compare such factors as codon size and receptive field size There are two components to the total area A ON the area of a ON and
AMI the area of the metal interconnect between ONs. AON consists of the silicon area
requirements of the codons for all ONs. The metal area for local intra-ON interconnect is
considered to be much smaller than that of the codons themselves and of that of the more
global inter-ON interconnect and is not considered here The area per ON is roughly
AON cfeme
where me is the maximum number of vectors that each codon must distinguish for
me
Theorem Assume a rectangular un6ounded grid of ONs all ONs are equi-distant
from their four nearest neighbors where each ON has a bounded receptive field of its nON
nearest ONs where ON is the receptive field size for the ON nON
C~e
where is the
number of codons and is the intra-ON redundancy that is the ratio of inputs to
synapses when R=l each ON input is used once at the ON when each input is
used on the average at two sites The metal area required to support each ON's receptive
field is proof is giving by Hammerstrom6
AMI
The total area per ON A then is
Another implementation IItrategy ill to place eNII along a diagonal which givell area However thill
technique only works ror a bounded number or eNII and when dendritic computation can be lipread over a large
area which limits the range or p08llible eN implementationll The theorem IItated here covers an infinite plane or
eNII each with a bounded receptive Held
Even with the assumption of maximum locality the total metal interconnect area
increases as the cube of the per CN receptive field size
SINGLE CN SIMULATION
What do the bounds tell us about CN connectivity requirements From simulations
increasing the CN's receptive field size improves the performance increases capacity but
there is also an increasing cost which increases faster than the performance Another
observation is that redundancy is quite effective as a means for increasing the effectiveness
of a CN with constrained connectivity There are some limits to since it can reach a
point where the intra-CN connectivity approaches that of inter-CN for some situations
With a fixed nON increasing cost-effectiveness A is possible by increasing both order
and redundancy
In order to verify the derived bounds I also wrote a discrete event simulation of a CN
where a random set of learned vectors were chosen and the CN's codons were programmed
according to the model presented earlier Learned vectors were chosen randomly and subjected to random noise The CN then attempted to categorize these inputs into two
major groups CN output and CN output For the most part the analytic bounds
agreed with the simulation though they tended to be optimistic in slightly underestimating
the error These differences can be easily explained by the simplifying assumptions that
were made to make the analytic bounds mathematically tractable
DISTRmUTED VS. LOCALIZED
Throughout this paper it has been tacitly assumed that representations are distributed
across a number of CNs and that any single CN participates in a number of representations In a local representation each CN represents a single concept or feature It is the distribution of representation that makes the CN's decode job difficult since it is the cause of
the code compression problem
There has been much debate in the connectionist/neuromodelling community as to the
advantages and disadvantages of each approach the interested reader is referred to Hinton7 Baum and BallardQ Some of the results derived here are relevant to this
debate A1s the distribution of representation increases the compression per CN increases
accordingly It was shown above that the mean error in a codon's response quickly
approaches independent of the input noise This result also holds at the CN level For
each individual CN this error can be offset by adding more codons but this is expensive
and tends to obviate one of the arguments in favor of distributed representations that is
the multi-use advantage where fewer CNs are needed because of more complex redundant
encodings A1s the degree of distribution increases the required connectivity and the code
compression increases so the added information that each codon adds to its CN's decoding
process goes to zero equivalent to all weights approaching a uniform value
SUMMARY AND CONCLUSIONS
In this paper a single CN node performance model was developed that was based on
Communication Theory Likewise an implementation cost model was derived
The communication model introduced the codon as a higher-order decoding element
and showed that for small codons much less than total CN fan-in or convergence code
compression or vector aliasing within the codon's receptive field is a severe problem for
large networks As code compression increases the information added by any individual
codon to the CN's decoding task rapidly approaches zero
The cost model showed that for 2-dimensional silicon the area required for inter-node
metal connectivity grows as the cube of a CN's fan-in
The combination of these two trends indicates that past a certain point which is
highly dependent on the probability structure of the learned vector space increasing the
fan-in of a CN as is done for example when the distribution of representation is increased
yields diminishing returns in terms of total cost-performance Though the rate of diminishing returns can be decreased by the use of redundant higher-order connections
The next step is to apply these techniques to ensembles of nodes CNs operating in a
competitive learning or feature extraction environment

<<----------------------------------------------------------------------------------------------------------------------->>

title: 48-a-neural-network-classifier-based-on-coding-theory.pdf

A Neural Network Classifier Based on Coding Theory
Tzt-Dar Chlueh and Rodney Goodman
eanrornla Instltute of Technology Pasadena eanromla
ABSTRACT
The new neural network classifier we propose transforms the
classification problem into the coding theory problem of decoding a noisy
codeword An input vector in the feature space is transformed into an internal
representation which is a codeword in the code space and then error correction
decoded in this space to classify the input feature vector to its class Two classes
of codes which give high performance are the Hadamard matrix code and the
maximal length sequence code We show that the number of classes stored in an
N-neuron system is linear in and significantly more than that obtainable by
using the Hopfield type memory as a classifier
I. INTRODUCTION
Associative recall using neural networks has recently received a great deal
of attention Hopfield in his papers deSCribes a mechanism which iterates
through a feedback loop and stabilizes at the memory element that is nearest the
input provided that not many memory vectors are stored in the machine He has
also shown that the number of memories that can be stored in an N-neuron
system is about for between and McEliece in their work
showed that for synchronous operation of the Hopfield memory about N/(2IogN
data vectors can be stored reliably when is large Abu-Mostafa has predicted
that the upper bound for the number of data vectors in an N-neuron Hopfield
machine is N. We believe that one should be able to devise a machine with the
number of data vectors linear in and larger than the achieved by the
Hopfield method
Feature Space
Code Space
Figure Classification problems versus Error control decoding problems
In this paper we are specifically concerned with the problem of
classification as in pattern recognition We propose a new method of building a
neural network classifier based on the well established techniques of error
control coding ConSider a typical classification problem in which one
is given a priori a set of classes a M. Associated with each class is a
feature vector which labels the class the exemplar of the class I.e. it is the
American Institute of Physics
most representative point in the class region The input is classified into the
class with the nearest exemplar to the input Hence for each class there is a
region in the N-dimensional binary feature space BN in which every
vector will be classified to the corresponding class
A similar problem is that of decoding a codeword in an error correcting
code as shown in In this case codewords are constructed by design and
are usually at least dmtn apart The received corrupted codeword is the input to
the decoder which then finds the nearest codeword to the input In principle
then if the distance between codewords is greater than 2t it is possible to
decode classify a noisy codeword feature vector into the correct codeword
exemplar provided that the Hamming distance between the noisy codeword and
the correct codeword is no more than Note that there is no guarantee that the
exemplars are uniformly distributed in BN. consequently the attraction radius
the maximum number of errors that can occur in any given feature vector such
that the vector can be correctly classified will depend on the minimum
distance between exemplars
Many solutions to the minimum Hamming distance classification have
been proposed the one commonly used is derived from the idea of matched filters
in communication theory Lippmann proposed a two-stage neural network
that solves this classification problem by first correlating the input with all
exemplars and then picking the maximum by a winner-take-all circuit or a
network composed of two-input comparators In Figure fI.f2 fN are the
input bits and SI.S2 SM are the matching score s(Similartty of with the
exemplars The second block picks the maximum of sI.S2 SM and produces the
index of the exemplar with the largest score The main disadvantage of such a
classifier is the complexity of the maximum-picking circuit for example a
winner-take-all net needs connection weights of large dynamic range and
graded-response neurons whilst the comparator maximum net demands M-I
comparators organized in log2M stages
A
DECODER~SS(f
I
cloSS(f
Feature
Space
Code
Space
A matched filter type classifier Structure of the proposed classifier
Our main idea is thus to transform every vector in the feature space to a
vector in some code space in such a way that every exemplar corresponds to a
codeword in that code The code should preferably but not necessarily have the
property that codewords are uniformly distributed in the code space that is the
Hamming distance between every pair of codewords is the same With this
transformation we turn the problem of classification into the coding problem of
decoding a noisy codeword We then do error correction decoding on the vector in
the code space to obtain the index of the noisy codeword and hence classify the
original feature vector as shown in Figure
This paper develops the construction of such a classification machine as
follows First we conSider the problem of transforming the input vectors from the
feature space to the code space We describe two hetero-associative memories for
dOing this the first method uses an outer product matrix technique Similar to
that of Hopfield's and the second method generates its matrix by the
pseudoinverse techruque[S.7J Given that we have transformed the problem of
associative recall or classification into the problem of decoding a noisy
codeword we next consider suitable codes for our machine We require the
codewords in this code to have the property of orthogonality or
pseudo-orthogonality that is the ratio of the cross-correlation to the
auto-correlation of the codewords is small We show two classes of such good
codes for this particular decoding problem the Hadamard matrix codes and
the maximal length sequence codes[8J We next formulate the complete decoding
algorithm and describe the overall structure of the classifier in terms of a two
layer neural network The first layer performs the mapping operation on the
input and the second one decodes its output to produce the index of the class to
which the input belongs
The second part of the paper is concerned with the performance of the
classifier We first analyze the performance of this new classifier by finding the
relation between the maximum number of classes that can be stored and the
classification error rate We show when using a transform based on the outer
product method that for negligible misclassification rate and large N. a not very
tight lower bound on M. the number of stored classes is We then present
comprehensive simulation results that confirm and exceed our theoretical
expectations The Simulation results compare our method with the Hopfield
model for both the outer product and pseudo-inverse method and for both the
analog and hard limited connection matrices In all cases our classifier exceeds
the performance of the Hopfield memory in terms of the number of classes that
can be reliably recovered
D. TRANSFORM TECHNIQUES
Our objective is to build a machine that can discriminate among input
vectors and classify each one of them into the appropriate class
Suppose
BN is the exemplar ofthe corresponding class a Given the
input we want the machine to be able to identify the class whose exemplar is
closest to that is we want to calculate the follOWing function
class
a
if
I I
I
I
where I I denotes Hamming distance in BN.
We approach the problem by seeking a transform that maps each
exemplar in BN to the corresponding codeword in BL. And an input
feature vector dey is thus mapped to a noisy codeword wlY where
is the error added to the exemplar and is the corresponding error pattern in the
code space We then do error correction decoding on to get the index of the
corresponding codeword Note that may not have the same Hamming weight as
that is the transformation may either generate more errors or eliminate
errors that are present in the original input feature vector We require to
satisfy the following equation
M-l
and
will be implemented uSing a Single-layer feedfoIWard network
Thus we first construct a matrix according to the sets of and call it
and define as
where sgn is the threshold operator that maps a vector in RL to BL and is the
field of real numbers
Let be an matrix whose lth column is and be an
matrix whose th column Is The two possible methods of constructing the
matrix for are as follows
Scheme A outer product method In this scheme the matrix Is
defined as the sum of outer products of all exemplar-codeword pairs
M-l
T(A)y
die
or equivalently
WDt
Scheme pseudo-Inverse method We want to find a matrix
satisfying the follOWing equation
In general is not a square matrix moreover may be singular so D-l
may not exist To circumvent this difficulty we calculate the pseudo-inverse
denoted Dt of the matrix instead of its real Inverse let DtD)-lDt can
be formulated as
Dt ot nt
CODES
The codes we are looking for should preferably have the property that its
codewords be distributed uniformly in BL that is the distance between each two
codewords must be the same and as large as pOSSible We thus seek classes of
eqUidistant codes Two such classes are the Hadamard matrix codes and the
maximal length sequence codes
First define the word pseudo-orthogonal
Defmition Let wO(a),Wl WL-l BL be the ath codeword of
code where a Code is said to be pseudo-orthogonal iff
L-l
Wl(a
where
where denotes inner product of two vectors
Hadamard Matrices An orthogonal code of length whose codewords are
rows or columns of an Hadamard matrix In this case and the
distance between any two codewords is L/2. It is conjectured that there exist such
codes for all which are multiples of thus providing a large class of codes[8
Mazlmal Length Sequence Codes There exists a family of maximal length
sequence also called pseudo-random or PN sequence codes(8 generated by shift
registers that satisfy pseudo-orthogonality with Suppose is a
primitive polynomial over OF of degree D. and let 2D and if
f(xl
l/g xl
ck xk
k=O
then CO.Cl is a periodic sequence of period since I If code is
made up of the cyclic shifts of
CO. cl Il
then code satisfies pseudo-orthogonality with One then easily sees that
the minimum distance of this code is which gives a correcting power of
approximately errors for large L.
IV. OVERALL CLASSIFIER STRUCTURE
We shall now describe the overall classifier structure essentially it
consists of the mapping followed by the error correction decoder for the
maximal length sequence code or Hadamard matrix code The decoder operates
by correlating the input vector with every codeword and then thresholding the
result at The rationale of this algorithm is as follows since the distance
between every two codewords in this code is exactly bits the decoder
should be able to correct any error pattern with less than errors if the
threshold is set halfway between Land I.e.
Suppose the input vector to the decoder is and has Hamming
weight nonzero components then we have
2s
2s
where a
From the above equation if is less than errors away from
then will be more than and will be
less than for all a As a result we arrive at the following decoding
algorithm
deax1e sgn
where which is an vector
In the case when and less than errors in the input the output
will be a vector in SM with only one component positive the index
of which is the index of the class that the input vector belongs However if there
are more than errors the output can be either the all negative vector
decoder failure or another vector with one pOSitive component(decoder error
The function class can now be defined as the composition of and decode
the overall structure of the new classifier is depicted in Figure It can be viewed
as a twO-layer neural network with hidden units and output neurons The
first layer is for mapping the input feature vector to a noisy codeword in the code
space the internal representation while the second one decodes the first's
output and produces the index of the class to which the input belongs
or
91
f1
f2
fN
9L
Figure
Overall architecture of the new neural network classifier
PERFORMANCE ANALYSIS
From the previous section we know that our classifier will make an error
only if the transformed vector in the code space which is the input to the decoder
has no less than errors We now proceed to find the error rate for this
classifier in the case when the input is one of the exemplars no error say
and an outer product connection matrix for Following the approach of
McEl1ece we have
N-l M-l
sgl
Wl(a dj(a
j=o a
N-l
sgn
M-l
Wl(a dl a
j=o a=O
Assume without loss of generality that and if
N-l
M-l
j=O
Wl(a dl a
a=o
then
Notice that we assumed all are random namely each component of
any is the outcome of a Bernoulli trial accordingly is the sum of
independent identically distributed random variables with mean and variance
In the asymptotic case when Nand are both very large can be
approximated by a normal distribution with mean variance NM. Thus
Pr
Q(vlN/M
where
vi TT
fOO
dt
Next we calculate the misclassification rate of the new classifier as follows
assuming
Pe
k=IL/4J
pk(l_p)L-k
where is the integer floor Since in generallt is not possible to express the
summation expliCitly we use the Chernoff method to bound Pe from above
Multiplying each term in the summation by a number larger than unity
et(k with and summing from instead of
Pe
t(k
k=O
Differentiating the RHS of the above equation and set it to we find
the optimal to as eto The condition that to implies that
and since we are dealing with the case where is small it is automatically
satisfied Substituting the optimal to we obtain
where
From the expression for Pe we can estimate the number of classes that
can be classified with negllgible misclassification rate in the following way
suppose Pe where land then
For small we have Log and since is a fixed value as
approaches infinity we have
From the above lower bound for one easily see that this new machlne is able to
classify a constant times classes which is better than the number of memory
items a Hopfield model can store Le. Although the analysis is done
assumlng approaches lnfinlty the simulation results in the next section show
that when is moderately large the above lower bound applles
VI. SIMULATION RESULTS AND A CHARACTER RECOGNITION EXAMPLE
We have Simulated both the Hopfield model and our new machine(using
maxlmallength sequence codes for 63 and for the following four cases
respectively
connection matrix generated by outer product method
connection matrix generated by pseudo-inverse method
ill connection matrix generated by outer product method the components of the
connection matrix are hard limited
connection matrix generated by pseudo-inverse method the components of
the connection matrix are hard limited
For each case and each choice of N. the program fixes and the number of
errors in the input vector then randomly generates sets of exemplars and
computes the connection matrix for each machine For each machine it
randomly picks an exemplar and adds nOise to it by randomly complementing
the specified number of bits to generate trial input vectors it then simulates
the machine and checks whether or not the input is classified to the nearest class
and reports the percentage of success for each machine
The simulation results are shown in Figure in each graph the hOrizontal
axis is and the vertical axis is the attraction radius The data we show are
obtained by collecting only those cases when the success rate is more than
that is for fixed what is the largest attraction radius number of bits in error of
the input vector that has a success rate of more than Here we use the
attraction radiUS of to denote that for this particular M. with the input being
an exemplar the success rate is less than in that machine
Hopfield Model
New Classifier{Op
New Classtfier{PI
Analog Connection Matrix
Binary Connection Matrix
CIl
23
a 18 It lit
tD
I.
23
en
tl.a
Binary Connection Matrix
13
17
Analog Connection Matrix
19
17
13
23
27
31
35 39 43
47 51
55
59
83
23
27
31
35
39 43
47 61
Figure Simulation results of the Hopfield memory and the new classifier
Hopfield Model
New Classifier(OP.L=63
New Classifier(OP.L=31
23
19
17
rIl
u.a
13
13
17
19
23
27
29
31
Figure Perfonnance of the new classifier using codes of different lengths
In all cases our classifier exceeds the perfonnance of the Hopfield model
in tenns of the number of classes that can be reliably recovered For example
consider the case of 63 and a hard limited connection matrix for both the new
classifier and the Hopfield model we find that for an attraction radius of zero
that is no error in the input vector the Hopfield model has a classification
capacity of approximately while our new model can store 47 Also for an
attraction radius of that is an average of errors in the input vector the
Hopfield model can reliably store classes while our new model stores 27
classes Another Simulation USing a shorter code 31 instead of
reveals that by shortening the code the performance of the classifier degrades
only slightly We therefore conjecture that it is pOSSible to use traditional error
correcting codes BCH code as internal representations however by going to
a higher rate code one is trading minimum distance of the code error tolerance
for complexity number of hidden units which implies pOSSibly poorer
performance of the classifier
We also notice that the superiority of the pseudoinverse method over the
outer product method appears only when the connection matrices are hard
limited The reason for this is that the pseudOinverse method is best for
decorrelating the dependency among exemplars yet the exemplars in this
simulation are generated randomly and are presumably independent
consequently one can not see the advantage of pseudoinverse method For
correlated exemplars we expect the pseudoinverse method to be clearly better
next example
Next we present an example of applying this classifier to recognizing
characters Each character is represented by a pixel array the input is
generated by flipping every pixel with and probability The input is then
passed to five machines Hopfield memory the new classifier with either the
pseudotnverse method or outer product method and or 31 Figure and
show the results of all machines for and pixel flipping probability
respectively a blank output means that the classifier refuses to make a decision
First note that the case is not necessarily worse than the case this
confirms the earlier conjecture that fewer hidden units shorter code only
degrades perfonnance slightly Also one eaSily sees that the pseudoinverse
method is better than the outer product method because of the correlation
between exemplars Both methods outperform the Hopfield memory since the
latter mixes exemplars that are to be remembered and produces a blend of
exemplars rather than the exemplars themselves accordingly it cannot classify
the input without mistakes
tF
Figure The character recognition
example with pixel reverse
probability input correct
output Hopfield Model new
classifier OP
PI PI 31
Figure The character recognition
example with pixel reverse
probability input correct
output Hopfield Model new
classifier OP
PI. PI. 31
Vll. CONCLUSION
In this paper we have presented a new neural network classifier design
based on coding theory techniques The classifier uses codewords from an error
correcting code as its internal representations Two classes of codes which give
high performance are the Hadamard matrix codes and the maximal length
sequence codes In penormance terms we have shown that the new machine is
significantly better than using the Hopfield model as a classifier We should also
note that when comparing the new classifier with the Hopfield model the
increased performance of the new classifier does not entail extra complexity
since it needs only hard limiter neurons and L(N connection weights
versus neurons and N2 weights in a Hopfield memory
In conclusion we believe that our model forms the basis of a fast practical
method of classification with an effiCiency greater than other previOUS neural
network techniques

<<----------------------------------------------------------------------------------------------------------------------->>

title: 56-discovering-structure-from-motion-in-monkey-man-and-machine.pdf

DISCOVERING STRUCfURE FROM MOTION IN
MONKEY MAN AND MACHINE
Ralph M. Siegel
The Salk Institute of Biology La Jolla Ca.
ABSTRACT
The ability to obtain three-dimensional structure from visual motion is
important for survival of human and non-human primates Using a parallel processing model the current work explores how the biological visual system might solve
this problem and how the neurophysiologist might go about understanding the
solution
INTRODUcnON
Psychophysical experiments have shown that monke and man are equally
adept at obtaining three dimensional structure from motion In the present work
much effort has been expended mimicking the visual system This was done for one
main reason the model was designed to help direct physiological experiments in the
primate It was hoped that if an approach for understanding the model could be
developed the approach could then be directed at the primate's visual system
Early in this century von Helmholtz2 described the problem of extracting
three-dimensional structure from motion
Suppose for instance that a person is standing still in a thick woods
where it is impossible for him to distinguish except vaguely and roughly
in the mass of foliage and branches all around him what belongs to one
tree and what to another or how far apart the separate trees are etc But
the moment he begins to move forward everything disentangles itself
and immediately he gets an apperception of the material content of the
woods and their relation to each other in space just as if he were looking
at a good stereoscopic view of it
If the object moves rather than the observer the perception of threedimensional structure from motion is still obtained Object-centered structure from
motion is examined in this report Lesion studies in monkey have demonstrated that
two extra-striate visual cortices called the middle temporal area abbreviated MT
Current address Laboratory of Neurobiology The Rockefeller University
York Avenue New York NY
American Institute of Physics
or and the medial superior temporal area are involved in obtaining
structure from motion The present model is meant to mimic the V5-MST part of
the cortical circuitry involved in obtaining structure from motion The model
attempts to determine ifthe visual image corresponds to a three-dimensional object
TIlE STRUCfURE FROM MOTION STIMULUS
The problem that the model solved was the same as that posed in the studies
of monkey and man Structured and unstructured motion displays of a hollow
orthographically projected cylinder were computed Figure The cylinder rotates
about its vertical axis The unstructured stimulus was generated by shuffling the
velocity vectors randomly on the display screen The overall velocity and spatial
distribution for the two displays are identical only the spatial relationships have
been changed in the unstructured stimulus Human subjects report that the points
are moving on the surface of a hollow cylinder when viewing the structured stimulus
With the unstructured stimulus most subjects report that they have no sense of
three-dimensional structure
B. Orthographic
Projection
A. Rotating Cylinder
Unstructured
Display
Figure The structured and unstructured motion stimulus A pomts are
randomly placed on the surface of a cylinder The points are orthographically projected The motion gives a strong percept of a hollow cylinder The unstructured
stimulus was generated by shuffling the velocity vectors randomly on the screen
FUNCTIONALARCHITECfUREOFTIlEMODEL
As with the primate subjects the model was required to only indicate whether
or not the display was structured Subjects were not required to describe the shape
velocity or size of the cylinder Thus the output cell of the model signaled if
By cell I mean a processing unit of the model which may correspond to a single
neuron or group of neurons The term neuron refers only to the actual wetware
in the brain
structured and if not structured This output layer corresponds to the cortical
area MST of macaque monkey which appear to be sensitive to the global organization of the motion image5 It is not known if MST neurons will distinguish between
structured and unstructured images
The input to the model was based on physiological studies in the maca~ue
monkey Neurons in area V5 have a retinotopic representation of visual space
For each retinotopic location there is
an encoding of a wide range of velocitiesS Thus in the model's input rep1
resentation there were cells that
CIl
represent different combinations of
velocity and retinotopic spatial posi0CIl
tion Furthermore motion velocity
neurons in V5 have a center-surround opponent organization9 The
width of the receptive fields was
taken from the data of Albright
retinal position deg
S. A typical receptive field of the
model is shown in Figure
Figure The receptive field of an input
layer cell The optimal velocity is
lt was possible to determine what the activity of the input cells would be for
the rotating cylinder given this representation The activation pattern of the set of
input cells was computed by convolving the velocity points with the difference of
gaussians The activity of the input cells for an image of points with an angular velocity of SO/sec is presented in Figure
Relinotopic map
Retinotopic map
Structure
Structure
Figure The input cell's activation pattern for a structured and unstructured stimuIus The circles correspond to the cells of the input layer The contours were com
puted using a linear interpolation between the individual cells The horizontal axis
corresponds to the position along the horizontal meridian The vertical axis corresponds to the speed along the horizontal meridian Thus activation of a cell in the
upper right hand corner of the graph correspond to a velocity of sec towards the
right at a location of to the right along the horizontal meridian
Inspection of this input pattern suggested that the problem of detecting
three-dimensional structure from motion may be reduced to a pattern recognition
task The problem was then Given a sparsely sampled input motion flow field determine whether it corresponds best to a structured or unstructured object
Itwas next necessary to determine the connections between the two input and
output layers such that the model will be able to correctly signal structure or no structure or over a wide range of cylinder radii and rotational velocities A parallel
distributed network of the type used by Rosenberg and Sejnowski provided the
functional architecture Figure
I
Figure The parallel architecture used to extract structure
from motion The input layer corresponding to area
mapped the position and speed along the horizontal axis
The output layer corresponded to area MST that it is
proposed signals structure or not The middle layer
may exist in either V5 or MST.
The input layer of cells was fully connected to the middle layer of cells The
middle layer of cells represented an intermediate stage of processing and may be in
either V5 or MST. All of the cells of the middle layer were then fully connected to
the output cell The inputs from cells of the lower layer to the next higher level were
summed linearly and then thresholded using the Hill equation
The weights between the layers were initially chosen between.?.1 The values of the
weights were then adjusted using back-propagation methods steepest descent so
that the network would learn to correctly predict the structure of the input image
The model learned to correctly perform the task after about iterations
Figure
Figure The education of the network to
perform the structure from motion problem
The iteration number is plotted against the
mean square error The error is defined as the
difference between the model's prediction and
the known structure The model was trained on
a set of structured and unstructured cylinders
a wi?e range adii number of points
with
and rotatlOnal velOCItIes
Iteration number
PSYCHOPHYSICAL PERFORMANCE OF THE MODEL
The model's performance was comparable to that of monkey and man with
respect to fraction of structure and number of points in the display Figure The
model was indeed performing a global analysis as shown by allowing the model to
view only a portion of the image Like man and monkey the model's performance
suffers Thus it appears that the model's performance was quite similar to known
monkey and human psychophysics
Output
monkey
man
machine
monkey
man
machine
Fraction structure
32
64
96
Number of points
Figure Psychophysical performance of the model A. The effect of varying the
fraction of structure As the fraction of structure increase the model's performance
improves Thirty repetitions were averaged for each value of structure for the model
The fraction of structure is defined as where Rs is the radius of shuffling
of the motion vectors and Rc is the radius of the cylinder The human and monkey
data are taken from psychophysical studies
HOW IS IT DONE
The model has similar performance to monkey and man It was next possible
to examine this artificial network in order to obtain hints for studying the biological
system Following the approach of an electrophysiologist receptive field maps for
all the cells of the middle and ou tput layers were made by activating individual inpu
cells The receptive field of some middle layer cells are shown in Figure The layout
of these maps are quite similar to that of Figure However now the activity of one
cell in the middle layer is plotted as a function of the location and speed of a motion
stimulus in the input layer One could imagine that an electrode was placed in one
of the cells of the middle layer while the experimentalist moved a bar about the
horizontal meridian with different locations and speeds The activity of the cell is
then plotted as a function of position and space
Relinolopic map
rJ
I
Figure The activity of two different cells in the middle layer Activity is plotted
as a contour map as a function of horizontal position and speed Dotted lines
indicate inhibition
These middle layer receptive field maps were interesting because they
appear to be quite simple and symmetrical In some the inhibitory central regions
of the receptive field were surrounded by excitatory regions Figure Complementary cells were also found In others there are inhibitory bands adjacent to
excitatory bands Figure The above results suggest that neurons involved in
extracting structure from motion may have relatively simple receptive fields in the
spatial velocity domain These receptive fields might be thought of as breaking the
image down into component parts a basis set Correct recombination of these
second order cells could then be used to detect the presence of a three-dimensional
structure
The output cell also had a simple receptive field again with interesting
symmetries Figure However the receptive field analysis is insufficient to
indicate the role of the cell Therefore in order to properly understand the meaning of the cell's receptive field it is necessary to use
stimuli that are real world relevant in this case the
structure from motion stimuli The output cell would
give its maximal response only when a cylinder stimulus
is presented
Figure The receptive field map of the output layer cell
Nothing about this receptive field structure indicates the
cell is involved in obtaining structure from motion
This work predicts that neurons in cortex involved in extracting structure
from motion will have relatively simple receptive fields In order to test this
hypothesis it will be necessary to make careful maps of these cells using small
patches of motion Figure Known qualitative results in areas V5 and MST are
consistent with but do not prove this hypothesis As well it will be necessary to use
relevant stimuli three-dimensional objects If such simple receptive fields
are indeed used in structure from motion then support will be found for the idea that
a simple cortical circuit center-surround can be used for many different visual
analyses
Motion patches consisting of random dots with
variable velocity
ru
Fix point
Figure It may be necessary to make careful
maps of these neurons using small patches of
motion in order to observe the postulated simple
receptive field properties of cortical neurons involved in extracting structure from
motion Such structures may not be apparent using hand moved bar stimuli
DISCUSSION
In conclusion it is possible to extract the three-dimensional structure of a
rotating cylinder using a parallel network based on a similar functional architecture
as found in primate cortex The present model has similar psychophysics to monkey
and man The receptive field structures that underlie the present model are simple
when viewed using a spatial-velocity representation It is suggested that in order to
understand how the visual system extracts structure from motion quantitative
spatial-velocity maps of cortical neurons involved need to be made One also needs
to use stimuli derived from the real world in order to understand how they may
be used in visual field analysis There are similarities between the shapes of the
receptive fields involved in analyzing structure from motion and receptive fields in
striate cortex It may be that similar cortical mechanisms and connections are used
to perform different functions in different cortical areas Lastly this model demonstrates that the use of parallel architectures that are closely modeled on the cortical
representation is a computationally efficient means to solve problems in vision Thus
as a final caveat I would like to advise the creators of networks that solve
ethologically realistic problems to use solutions that evolution has provided

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 50-an-adaptive-and-heterodyne-filtering-procedure-for-the-imaging-of-moving-objects.pdf

AN ADAPTIVE AND HETERODYNE FILTERING PROCEDURE
FOR THE IMAGING OF MOVING OBJECTS
F. H. Schuling H. A. K. Mastebroek and W. H. Zaagman
Biophysics Department Laboratory for General Physics
Westersingel 34 eM Groningen The Netherlands
ABSTRACT
Recent experimental work on the stimulus velocity dependent time resolving
power of the neural units situated in the highest order optic ganglion of the
blowfly revealed the at first sight amazing phenomenon that at this high level of
the fly visual system the time constants of these units which are involved in the
processing of neural activity evoked by moving objects are roughly spokeninverse proportional to the velocity of those objects over an extremely wide range
In this paper we will discuss the implementation of a two dimensional heterodyne
adaptive filter construction into a computer simulation model The features of this
simulation model include the ability to account for the experimentally observed
stimulus-tuned adaptive temporal behaviour of time constants in the fly visual
system The simulation results obtained clearly show that the application of such
an adaptive processing procedure delivers an improved imaging technique of
moving patterns in the high velocity range
A FEW REMARKS ON THE FLY VISUAL SYSTEM
The visual system of the diptera including the blowfly Calliphora
erythrocephala is very regularly organized and allows therefore very precise
optical stimulation techniques Also long term electrophysiological recordings can
be made relatively easy in this visual system For these reasons the blowfly which
is well-known as a very rapid and clever pilot turns out to be an extremely
suitable animal for a systematic study of basic principles that may underlie the
detection and further processing of movement information at the neural level
In the fly visual system the input retinal mosaic structure is precisely
mapped onto the higher order optic ganglia lamina medulla lobula This means
that each neural column in each ganglion in this visual system corresponds to a
certain optical axis in the visual field of the compound eye In the lobula complex
a set of wide-field movement sensitive neurons is found each of which integrates
the input signals over the whole visual field of the entire eye One of these wide
field neurons that has been classified as I by Hausen has been extensively
studied both anatomically2 as well as electrophysiologically5 The
obtained results generally agree very well with those found in behavioral
optomotor experiments on movement detection and can be understood in terms of
Reichardts correlation model
The I neuron is sensitive to horizontal movement and directionally
selective very high rates of action potentials spikes up to per second can be
recorded from this element in the case of visual stimuli which move horizontally
inward from back to front in the visual field pre/erred direction whereas
movement horizontally outward from front to back null direction suppresses
its activity
American Institute of Physics
EXPERIMENTAL RESULTS AS A MODELLING BASE
When the I neuron is stimulated in its preferred direction with a step wise
pattern displacement it will respond with an increase of neural activity By
repeating this stimulus step over and over one can obtain the averaged response
after a ms latency period the response manifests itself as a sharp increase in
average firing rate followed by a much slower decay to the spontaneous activity
level Two examples of such averaged responses are shown in the Post Stimulus
Time Histograms PSTH's of figure Time to peak and peak height are related
and depend on modulation depth stimulus step size and spatial extent of the
stimulus The tail of the responses can be described adequately by an exponential
decay toward a constant spontaneous firing rate
For each setting of the stimulus parameters the response parameters
defined by equation can be estimated by a least-squares fit to the tail of the
PSTH The smooth lines in figure are the results of two such fits
tlmsl
OJ
I'JO
tf
MoO IO
Mdl05
Fig.l
I
lsI
A veraged responses PSTH's obtained from the I neuron being
adapted to smooth stimulus motion with velocities top and
bottom respectively The smooth lines represent least-squares
fits to the PSTH's of the form Values of for the
two PSTH's are and 24 ms respectively de Ruyter van Steveninck
Fitted values of as a function of adaptation velocity for three
modulation depths M. The straight line is a least-squares fit to represent
the data for in the region It has the form
f=Q with ms and de Ruyter van Steveninck
Fig.2
Figure shows fitted values of the response time constant as a function of
the angular velocity of a moving stimulus square wave grating in most
experiments which was presented to the animal during a period long enough to let
its visual system adapt to this moving pattern and before the step wise pattern
displacement which reveals was given The straight line described by
with in Is and in ms represents a least-squares fit to the data over the
velocity range from to Is. For this range varies from to roughly
ms with ms and Defining the adaptation range of as
that interval of velocities for which decreases with increasing velocity we may
conclude from figure that within the adaptation range is not very sensitive to
the modulation depth
The outcome of similar experiments with a constant modulation depth of the
pattern and a constant pattern velocity but with four different values of
the contrast frequency fc the number of spatial periods per second that
traverse an individual visual axis as determined by the spatial wavelength As of the
pattern and the pattern velocity according to fc=v lAs reveal also an almost
complete independency of the behaviour of on contrast frequency Other
experiments in which the stimulus field was subdivided into regions with different
adaptation velocities made clear that the time constants of the input channels of
the I neuron were set locally by the values of the stimulus velocity in each
stimulus sub-region Finally it was found that the adaptation of is driven by
the stimulus velocity independent of its direction
These findings can be summarized qualitatively as follows in steady state
the response time constants of the neural units at the highest level in the fly
visual system are found to be tuned locally within a large velocity range
exclusively by the magnitude of the velocity of the moving pattern and not by its
direction despite the directional selectivity of the neuron itself We will not go
into the question of how this amazing adaptive mechanism may be hard-wired in
the fly visual system Instead we will make advantage of the results derived thus
far and attempt to fit the experimental observations into an image processing
approach A large number of theories and several distinct classes of algorithms to
encode velocity and direction of movement in visual systems have been suggested
by for example Marr and Ullman I I and van Santen and Sperling12
We hypothesize that the adaptive mechanism for the setting of the time
constants leads to an optimization for the overall performance of the visual system
by realizing a velocity independent representation of the moving object In other
words within the range of velocities for which the time constants are found to be
tuned by the velocity the representation of that stimulus at a certain level within
the visual circuitry should remain independent of any variation in stimulus
velocity
OBJECT MOTION DEGRADATION MODELLING
Given the physical description of motion and a linear space invariant model
the motion degradation process can be represented by the following convolution
integral
co co
JJ
flu dudv
where is the object intensity at position in the object coordinate
frame is the Point Spread Function PSF of the imaging system
which is the response at to a unit pulse at and is the image
intensity at the spatial position as blurred by the imaging system Any
possible additive white noise degradation of the already motion blurred image is
neglected in the present considerations
For a review of principles and techniques in the field of digital image
degradation and restoration the reader is referred to Harris 13 Sawchuk
Sondhi Nahi A boutalib 17 18 Hildebrand 19 Rajala de Figueiredo20
It has been demonstrated first by Aboutalib that for situations in which
the motion blur occurs in a straight line along one spatial coordinate say along the
horizontal axis it is correct to look at the blurred image as a collection of
degraded line scans through the entire image The dependence on the vertical
coordinate may then be dropped and eq reduces to
f(u)du
Given the mathematical description of the relative movement
corresponding PSF can be derived exactly and equation becomes
b(x f(u)du
the
where is the extent of the motion blur Typically a discrete version of
applicable for digital image processing purposes is described by
I
where and I take on integer values and is related to the motion blur extent
According to Aboutalib 18 a scalar difference equation model
can then be derived to model the motion degradation process
cmA(i-m
where is the m-dimensional state vector at position along a scan line is
the input intensity at position is the output intensity is the blur extent
is the number of elements in a line is a scalar a and are constant
matrices of order mxl and lxm respectively containing the discrete
values Cj of the blurring PSF for and is the Kronecker delta
function
INFLUENCE OF BOTH TIME CONSTANT AND VELOCITY
ON THE AMOUNT OF MOTION BLUR IN AN ARTIFICIAL
RECEPTOR ARRAY
To start with we incorporate in our simulation model a PSF derived from
equation to model the performance of all neural columnar arranged filters in
the lobula complex with the restriction that the time constants remain fixed
throughout the whole range of stimulus velocities Realization of this PSF can
easily be achieved via the just mentioned state space model
I.
I.
Fig.3
POSITION IN
ARTIFICIAL RECEPTOR ARRAY
upper part Demonstration of the effect that an increase in magnitude of
the time constants of an one-dimensional array of filters will result in
increase in motion blur while the pattern velocity remains constant
Original pattern shown in solid lines is a square-wave grating with a
spatial wavelength equal to artificial receptor distances The three
other wave forms drawn show that for a gradual increase increase in
magnitude of the time constants the representation of the original
square-wave will consequently degrade lower part A gradual increase in
velocity of the moving square-wave while the filter time constants are
kept fixed results also in a clear increase of degradation
First we demonstrate the effect that an increase in time constant while the
pattern velocity remains the same will result in an increase in blur Therefore we
introduce an one dimensional array of filters all being equipped with the same
time constant in their impulse response The original pattern shown in square and
solid lines in the upper part of figure consists of a square wave grating with a
spatial period overlapping artificial receptive filters The other patterns drawn
there show that for the same constant velocity of the moving grating an increase
in the magnitude of the time constants of the filters results in an increased blur in
the representation of that grating On the other hand an increase in velocity
while the time constants of the artificial receptive units remain the same also
results in a clear increase in motion blur as demonstrated in the lower part of
figure
Inspection of the two wave forms drawn by means of the dashed lines in
both upper and lower half of the figure yields the conclusion that apart from
rounding errors introduced by the rather small number of artificial filters
available equal amounts of smear will be produced when the product of time
constant and pattern velocity is equal For the upper dashed wave form the
velocity was four times smaller but the time constant four times larger than for its
equivalent in the lower part of the figure
ADAPTIVE SCHEME
In designing a proper image processing procedure our next step is to
incorporate the experimentally observed flexibility property of the time constants
in the imaging elements of our device In figure 4a a scheme is shown which
filters the information with fixed time constants not influenced by the pattern
velocity In figure 4b a network is shown where the time constants also remain
fixed no matter what pattern movement is presented but now at the next level of
information processing a spatially differential network is incorporated in order to
enhance blurred contrasts
In the filtering network in figure 4c first a measurement of the magnitude
of the velocity of the moving objects is done by thus far hypothetically introduced
movement processing algorithms modelled here as a set of receptive elements
sampling the environment in such a manner that proper estimation of local pattern
velocities can be done Then the time constants of the artificial receptive elements
will be tuned according to the estimated velocities and finally the same
differential network as in scheme 4b is used
The actual tuning mechanism used for our simulations is outlined in figure
once given the range of velocities for which the model is supposed to be
operational and given a lower limit for the time constant min min can be the
smallest value which physically can be realized the time constant will be tuned to
a new value according to the experimentally observed reciprocal relationship and
will for all velocities within the adaptive range be larger than the fixed minimum
value As demonstrated in the previous section the corresponding blur in the
representation of the moving stimulus will thus always be larger than for the
situation in which the filtering is done with fixed and smallest time constants
min More important however is the fact that due to this tuning mechanism the
blur will be constant since the product of velocity and time constant is kept
constant So once the information has been processed by such a system a velocity
independent representation of the image will be the result which can serve as the
input for the spatially differentiating network as outlined in figure 4c
The most elementary form for this differential filtering procedure is the one
in which the gradient of two filters K-I and K+l which are the nearest neighbors
of filter is taken and then added with a constant weighing factor to the central
output as drawn in figure and where the sign of the gradient depends on
the direction of the estimated movement Essential for our model is that we claim
that this weighing factor should be constant throughout the whole set of filters
and for the whole high velocity range in which the heterodyne imaging has to be
performed Important to notice is the existence of a so-called settling time the
minimal time needed for our movement processing device to be able to accurately
measure the object velocity Note this time can be set equal to zero in the case
that the relative stimulus velocity is known a priori as demonstrated in figure
Since without doubt within this settling period estimated velocity values will
come out erroneously and thus no optimal performance of our imaging device can
be expected in all further examples results after this initial settling procedure
will be shown
A
yV
rYO
i~J
t"if
Pattern movement in this figure is to the right
A Network consisting of a set of filters with a fixed pattern velocity
independent time constant in their impulse response
Identical network as in figure 4A now followed by a spatially
differentiating circuitry which adds the weighed gradients of two
neighboring filter outputs K-l and K+I to the central filter output
K.
The time constants of the filtering network are tuned by a
hypothetical movement estimating mechanism visualized here as a
number of receptive elements of which the combined output tunes
the filters A detailed description of this mechanism is shown in
figure This tuned network is followed by an identical spatially
differentiating circuit as described in figure
increasing velocity
decreasing time constant
min
Detailed description of the mechanism used to tune the time constants
The time constant of a specific neural channel is set by the pattern
velocity according to the relationship shown in the insert which is
derived from eq with I and I.
4r
I
I
I
I
I
I
I
I
4V
I
I
a
2V
Wi
8V
I
POSITION IN ARTIFICIAL RECEPTOR ARRAY
Fig.6
Thick lines square-wave stimulus pattern with a spatial wavelength
overlapping 32 artificial receptive elements Thick lines responses for
different pattern velocities in a system consisting of paralleling neural
filters equipped with time constants tuned by this velocity and followed
by a spatially differentiating network as described
Dashed lines responses to the different pattern velocities in a filtering
system with fixed time constants followed by the same spatial
differentiating circuitry as before Note the sharp over and under
shoots for this case
Results obtained with an imaging procedure as drawn in figure and 4c
are shown in figure The pattern consists of a square wave overlapping 32
picture elements The pattern moves to the left with different velocities
At each velocity only one wavelength is shown Thick lines
square wave pattern Dashed lines the outputs of an imaging device as depicted in
figure constant time constants and a constant weighing factor in the spatial
processing stage Note the large differences between the several outputs Thin
continuous lines the outputs of an imaging device as drawn in figure tuned
time constants according to the reciprocal relationship between pattern velocity
and time constant and a constant weighing factor in the spatial processing stage
For further simulation details the reader is referred to Zaagman Now the
outputs are almost completely the same and in good agreement with the original
stimulus throughout the whole velocity range
Figure shows the effect of the gradient weighing factor on the overall
filter performance estimated as the improvement of the deblurred images as
compared with the blurred image measured in dB This quantitative measure has
been determined for the case of a moving square wave pattern with motion blur
IX
ItI
a
weighing factor
Effect of the weighing factor on the overall filter performance Curve
measured for the case of a moving square-wave grating Filter
performance is estimated as the improvement in signal to noise ratio
I:iI
where is the original intensity at position in the image
is the intensity at the same position in the motion blurred image and
is the intensity at in the image generated with the adaptive
tuning procedure
extents comparable to those used for the simulations to be discussed in section IV.
From this curve it is apparent that for this situation there is an optimum value for
this weighing factor Keeping the weight close to this optimum value will result in
a constant output of our adaptive scheme thus enabling an optimal deblurring of
the smeared image of the moving object
On the other hand starting from the point of view that the time constants
should remain fixed throughout the filtering process we should had have to tune
the gradient weights to the velocity in order to produce a constant output as
demonstrated in figure where the dashed lines show strongly differing outputs of
a fixed time constant system with spatial processing with constant weight figure
4b In other words tuning of the time constants as proposed in this section results
in I the realization of the blur-constancy criterion as formulated previously and
as a consequence the possibility to deblur the obtained image oPtimally with
one and the same weighing factor of the gradient in the final spatial processing
layer over the whole heterodyne velocity range
COMPUTER SIMULATION RESULTS AND
CONCLUSIONS
The image quality improvement algorithm developed in the present
contribution has been implemented on a general purpose DG Eclipse Sjl40 minicomputer for our two dimensional simulations Figure Sa shows an undisturbed
image consisting of lines of each pixels with bit intensity resolution
Figure Sb shows what happens with the original image if the PSF is modelled
according to the exponential decay In this case the time constants of all
spatial information processing channels have been kept fixed Again information
content in the higher spatial frequencies has been reduced largely The
implementation of the heterodyne filtering procedure was now done as follows
first the adaptation range was defined by setting the range of velocities This
means that our adaptive heterodyne algorithm is supposed to operate adequately
only within the thus defined velocity range and that in that range the time
constants are tuned according to relationship and will always come out larger
than the minimum value min For demonstration purposes we set Q=I and in
eq thus introducing the phenomenon that for any velocity the two
dimensional set of spatial filters with time constants tuned by that velocity will
always produce a constant output independent of this velocity which introduces
the motion blur Figure Sc shows this representation It is important to note here
that this constant output has far more worse quality than any set of filters with
smallest and fixed time constants min would produce for velocities within the
operational range The advantage of a velocity independent output at this level in
our simulation model is that in the next stage a differential scheme can be
implemented as discussed in detail in the preceding paragraph Constancy of the
weighing factor which is used in this differential processing scheme is guaranteed
by the velocity independency of the obtained image representation
Figure Sd shows the result of the differential operation with an optimized
gradient weighing factor This weighing factor has been optimized based on an
almost identical performance curve as described previously in figure A clear
and good restoration is apparent from this figure though close inspection reveals
fine structure especially for areas with high intensities which is unrelated with
the original intensity distribution These artifacts are caused by the phenomenon
that for these high intensity areas possible tuning errors will show up much more
pronounced than for low intensities
Fig.8a
Fig.8b
8c
Fig.8d
a
Original bit picture
Motion degraded image with a PSF derived from
where is kept fixed to pixels and the motion blur extent is 32
pixels
Worst case the result of motion degradation of the original image
with a PSF as in figure 8b but with tuning of the time constants based
on the velocity
Restored version of the degraded image using the heterodyne adaptive
processing scheme
In conclusion a heterodyne adaptive image processing technique inspired by
the fly visual system has been presented as an imaging device for moving objects
A scalar difference equation model has been used to represent the motion blur
degradation process Based on the experimental results described and on this state
space model we developed an adaptive filtering scheme which produces at a
certain level within the system a constant output permitting further differential
operations in order to produce an optimally deblurred representation of the
moving object
ACKNOWLEDGEMENTS
The authors wish to thank mT Eric Bosman for his expert programming
assistance mr Franco Tommasi for many inspiring discussions and advises during
the implementation of the simulation model and dr Rob de Ruyter van Steveninck
for experimental help This research was partly supported by the Netherlands
Organization lor the Advancement 01 Pure Research through the
foundation Stichting voor Biolysica

<<----------------------------------------------------------------------------------------------------------------------->>

title: 50-an-adaptive-and-heterodyne-filtering-procedure-for-the-imaging-of-moving-objects.pdf

AN ADAPTIVE AND HETERODYNE FILTERING PROCEDURE
FOR THE IMAGING OF MOVING OBJECTS
F. H. Schuling H. A. K. Mastebroek and W. H. Zaagman
Biophysics Department Laboratory for General Physics
Westersingel 34 eM Groningen The Netherlands
ABSTRACT
Recent experimental work on the stimulus velocity dependent time resolving
power of the neural units situated in the highest order optic ganglion of the
blowfly revealed the at first sight amazing phenomenon that at this high level of
the fly visual system the time constants of these units which are involved in the
processing of neural activity evoked by moving objects are roughly spokeninverse proportional to the velocity of those objects over an extremely wide range
In this paper we will discuss the implementation of a two dimensional heterodyne
adaptive filter construction into a computer simulation model The features of this
simulation model include the ability to account for the experimentally observed
stimulus-tuned adaptive temporal behaviour of time constants in the fly visual
system The simulation results obtained clearly show that the application of such
an adaptive processing procedure delivers an improved imaging technique of
moving patterns in the high velocity range
A FEW REMARKS ON THE FLY VISUAL SYSTEM
The visual system of the diptera including the blowfly Calliphora
erythrocephala is very regularly organized and allows therefore very precise
optical stimulation techniques Also long term electrophysiological recordings can
be made relatively easy in this visual system For these reasons the blowfly which
is well-known as a very rapid and clever pilot turns out to be an extremely
suitable animal for a systematic study of basic principles that may underlie the
detection and further processing of movement information at the neural level
In the fly visual system the input retinal mosaic structure is precisely
mapped onto the higher order optic ganglia lamina medulla lobula This means
that each neural column in each ganglion in this visual system corresponds to a
certain optical axis in the visual field of the compound eye In the lobula complex
a set of wide-field movement sensitive neurons is found each of which integrates
the input signals over the whole visual field of the entire eye One of these wide
field neurons that has been classified as I by Hausen has been extensively
studied both anatomically2 as well as electrophysiologically5 The
obtained results generally agree very well with those found in behavioral
optomotor experiments on movement detection and can be understood in terms of
Reichardts correlation model
The I neuron is sensitive to horizontal movement and directionally
selective very high rates of action potentials spikes up to per second can be
recorded from this element in the case of visual stimuli which move horizontally
inward from back to front in the visual field pre/erred direction whereas
movement horizontally outward from front to back null direction suppresses
its activity
American Institute of Physics
EXPERIMENTAL RESULTS AS A MODELLING BASE
When the I neuron is stimulated in its preferred direction with a step wise
pattern displacement it will respond with an increase of neural activity By
repeating this stimulus step over and over one can obtain the averaged response
after a ms latency period the response manifests itself as a sharp increase in
average firing rate followed by a much slower decay to the spontaneous activity
level Two examples of such averaged responses are shown in the Post Stimulus
Time Histograms PSTH's of figure Time to peak and peak height are related
and depend on modulation depth stimulus step size and spatial extent of the
stimulus The tail of the responses can be described adequately by an exponential
decay toward a constant spontaneous firing rate
For each setting of the stimulus parameters the response parameters
defined by equation can be estimated by a least-squares fit to the tail of the
PSTH The smooth lines in figure are the results of two such fits
tlmsl
OJ
I'JO
tf
MoO IO
Mdl05
Fig.l
I
lsI
A veraged responses PSTH's obtained from the I neuron being
adapted to smooth stimulus motion with velocities top and
bottom respectively The smooth lines represent least-squares
fits to the PSTH's of the form Values of for the
two PSTH's are and 24 ms respectively de Ruyter van Steveninck
Fitted values of as a function of adaptation velocity for three
modulation depths M. The straight line is a least-squares fit to represent
the data for in the region It has the form
f=Q with ms and de Ruyter van Steveninck
Fig.2
Figure shows fitted values of the response time constant as a function of
the angular velocity of a moving stimulus square wave grating in most
experiments which was presented to the animal during a period long enough to let
its visual system adapt to this moving pattern and before the step wise pattern
displacement which reveals was given The straight line described by
with in Is and in ms represents a least-squares fit to the data over the
velocity range from to Is. For this range varies from to roughly
ms with ms and Defining the adaptation range of as
that interval of velocities for which decreases with increasing velocity we may
conclude from figure that within the adaptation range is not very sensitive to
the modulation depth
The outcome of similar experiments with a constant modulation depth of the
pattern and a constant pattern velocity but with four different values of
the contrast frequency fc the number of spatial periods per second that
traverse an individual visual axis as determined by the spatial wavelength As of the
pattern and the pattern velocity according to fc=v lAs reveal also an almost
complete independency of the behaviour of on contrast frequency Other
experiments in which the stimulus field was subdivided into regions with different
adaptation velocities made clear that the time constants of the input channels of
the I neuron were set locally by the values of the stimulus velocity in each
stimulus sub-region Finally it was found that the adaptation of is driven by
the stimulus velocity independent of its direction
These findings can be summarized qualitatively as follows in steady state
the response time constants of the neural units at the highest level in the fly
visual system are found to be tuned locally within a large velocity range
exclusively by the magnitude of the velocity of the moving pattern and not by its
direction despite the directional selectivity of the neuron itself We will not go
into the question of how this amazing adaptive mechanism may be hard-wired in
the fly visual system Instead we will make advantage of the results derived thus
far and attempt to fit the experimental observations into an image processing
approach A large number of theories and several distinct classes of algorithms to
encode velocity and direction of movement in visual systems have been suggested
by for example Marr and Ullman I I and van Santen and Sperling12
We hypothesize that the adaptive mechanism for the setting of the time
constants leads to an optimization for the overall performance of the visual system
by realizing a velocity independent representation of the moving object In other
words within the range of velocities for which the time constants are found to be
tuned by the velocity the representation of that stimulus at a certain level within
the visual circuitry should remain independent of any variation in stimulus
velocity
OBJECT MOTION DEGRADATION MODELLING
Given the physical description of motion and a linear space invariant model
the motion degradation process can be represented by the following convolution
integral
co co
JJ
flu dudv
where is the object intensity at position in the object coordinate
frame is the Point Spread Function PSF of the imaging system
which is the response at to a unit pulse at and is the image
intensity at the spatial position as blurred by the imaging system Any
possible additive white noise degradation of the already motion blurred image is
neglected in the present considerations
For a review of principles and techniques in the field of digital image
degradation and restoration the reader is referred to Harris 13 Sawchuk
Sondhi Nahi A boutalib 17 18 Hildebrand 19 Rajala de Figueiredo20
It has been demonstrated first by Aboutalib that for situations in which
the motion blur occurs in a straight line along one spatial coordinate say along the
horizontal axis it is correct to look at the blurred image as a collection of
degraded line scans through the entire image The dependence on the vertical
coordinate may then be dropped and eq reduces to
f(u)du
Given the mathematical description of the relative movement
corresponding PSF can be derived exactly and equation becomes
b(x f(u)du
the
where is the extent of the motion blur Typically a discrete version of
applicable for digital image processing purposes is described by
I
where and I take on integer values and is related to the motion blur extent
According to Aboutalib 18 a scalar difference equation model
can then be derived to model the motion degradation process
cmA(i-m
where is the m-dimensional state vector at position along a scan line is
the input intensity at position is the output intensity is the blur extent
is the number of elements in a line is a scalar a and are constant
matrices of order mxl and lxm respectively containing the discrete
values Cj of the blurring PSF for and is the Kronecker delta
function
INFLUENCE OF BOTH TIME CONSTANT AND VELOCITY
ON THE AMOUNT OF MOTION BLUR IN AN ARTIFICIAL
RECEPTOR ARRAY
To start with we incorporate in our simulation model a PSF derived from
equation to model the performance of all neural columnar arranged filters in
the lobula complex with the restriction that the time constants remain fixed
throughout the whole range of stimulus velocities Realization of this PSF can
easily be achieved via the just mentioned state space model
I.
I.
Fig.3
POSITION IN
ARTIFICIAL RECEPTOR ARRAY
upper part Demonstration of the effect that an increase in magnitude of
the time constants of an one-dimensional array of filters will result in
increase in motion blur while the pattern velocity remains constant
Original pattern shown in solid lines is a square-wave grating with a
spatial wavelength equal to artificial receptor distances The three
other wave forms drawn show that for a gradual increase increase in
magnitude of the time constants the representation of the original
square-wave will consequently degrade lower part A gradual increase in
velocity of the moving square-wave while the filter time constants are
kept fixed results also in a clear increase of degradation
First we demonstrate the effect that an increase in time constant while the
pattern velocity remains the same will result in an increase in blur Therefore we
introduce an one dimensional array of filters all being equipped with the same
time constant in their impulse response The original pattern shown in square and
solid lines in the upper part of figure consists of a square wave grating with a
spatial period overlapping artificial receptive filters The other patterns drawn
there show that for the same constant velocity of the moving grating an increase
in the magnitude of the time constants of the filters results in an increased blur in
the representation of that grating On the other hand an increase in velocity
while the time constants of the artificial receptive units remain the same also
results in a clear increase in motion blur as demonstrated in the lower part of
figure
Inspection of the two wave forms drawn by means of the dashed lines in
both upper and lower half of the figure yields the conclusion that apart from
rounding errors introduced by the rather small number of artificial filters
available equal amounts of smear will be produced when the product of time
constant and pattern velocity is equal For the upper dashed wave form the
velocity was four times smaller but the time constant four times larger than for its
equivalent in the lower part of the figure
ADAPTIVE SCHEME
In designing a proper image processing procedure our next step is to
incorporate the experimentally observed flexibility property of the time constants
in the imaging elements of our device In figure 4a a scheme is shown which
filters the information with fixed time constants not influenced by the pattern
velocity In figure 4b a network is shown where the time constants also remain
fixed no matter what pattern movement is presented but now at the next level of
information processing a spatially differential network is incorporated in order to
enhance blurred contrasts
In the filtering network in figure 4c first a measurement of the magnitude
of the velocity of the moving objects is done by thus far hypothetically introduced
movement processing algorithms modelled here as a set of receptive elements
sampling the environment in such a manner that proper estimation of local pattern
velocities can be done Then the time constants of the artificial receptive elements
will be tuned according to the estimated velocities and finally the same
differential network as in scheme 4b is used
The actual tuning mechanism used for our simulations is outlined in figure
once given the range of velocities for which the model is supposed to be
operational and given a lower limit for the time constant min min can be the
smallest value which physically can be realized the time constant will be tuned to
a new value according to the experimentally observed reciprocal relationship and
will for all velocities within the adaptive range be larger than the fixed minimum
value As demonstrated in the previous section the corresponding blur in the
representation of the moving stimulus will thus always be larger than for the
situation in which the filtering is done with fixed and smallest time constants
min More important however is the fact that due to this tuning mechanism the
blur will be constant since the product of velocity and time constant is kept
constant So once the information has been processed by such a system a velocity
independent representation of the image will be the result which can serve as the
input for the spatially differentiating network as outlined in figure 4c
The most elementary form for this differential filtering procedure is the one
in which the gradient of two filters K-I and K+l which are the nearest neighbors
of filter is taken and then added with a constant weighing factor to the central
output as drawn in figure and where the sign of the gradient depends on
the direction of the estimated movement Essential for our model is that we claim
that this weighing factor should be constant throughout the whole set of filters
and for the whole high velocity range in which the heterodyne imaging has to be
performed Important to notice is the existence of a so-called settling time the
minimal time needed for our movement processing device to be able to accurately
measure the object velocity Note this time can be set equal to zero in the case
that the relative stimulus velocity is known a priori as demonstrated in figure
Since without doubt within this settling period estimated velocity values will
come out erroneously and thus no optimal performance of our imaging device can
be expected in all further examples results after this initial settling procedure
will be shown
A
yV
rYO
i~J
t"if
Pattern movement in this figure is to the right
A Network consisting of a set of filters with a fixed pattern velocity
independent time constant in their impulse response
Identical network as in figure 4A now followed by a spatially
differentiating circuitry which adds the weighed gradients of two
neighboring filter outputs K-l and K+I to the central filter output
K.
The time constants of the filtering network are tuned by a
hypothetical movement estimating mechanism visualized here as a
number of receptive elements of which the combined output tunes
the filters A detailed description of this mechanism is shown in
figure This tuned network is followed by an identical spatially
differentiating circuit as described in figure
increasing velocity
decreasing time constant
min
Detailed description of the mechanism used to tune the time constants
The time constant of a specific neural channel is set by the pattern
velocity according to the relationship shown in the insert which is
derived from eq with I and I.
4r
I
I
I
I
I
I
I
I
4V
I
I
a
2V
Wi
8V
I
POSITION IN ARTIFICIAL RECEPTOR ARRAY
Fig.6
Thick lines square-wave stimulus pattern with a spatial wavelength
overlapping 32 artificial receptive elements Thick lines responses for
different pattern velocities in a system consisting of paralleling neural
filters equipped with time constants tuned by this velocity and followed
by a spatially differentiating network as described
Dashed lines responses to the different pattern velocities in a filtering
system with fixed time constants followed by the same spatial
differentiating circuitry as before Note the sharp over and under
shoots for this case
Results obtained with an imaging procedure as drawn in figure and 4c
are shown in figure The pattern consists of a square wave overlapping 32
picture elements The pattern moves to the left with different velocities
At each velocity only one wavelength is shown Thick lines
square wave pattern Dashed lines the outputs of an imaging device as depicted in
figure constant time constants and a constant weighing factor in the spatial
processing stage Note the large differences between the several outputs Thin
continuous lines the outputs of an imaging device as drawn in figure tuned
time constants according to the reciprocal relationship between pattern velocity
and time constant and a constant weighing factor in the spatial processing stage
For further simulation details the reader is referred to Zaagman Now the
outputs are almost completely the same and in good agreement with the original
stimulus throughout the whole velocity range
Figure shows the effect of the gradient weighing factor on the overall
filter performance estimated as the improvement of the deblurred images as
compared with the blurred image measured in dB This quantitative measure has
been determined for the case of a moving square wave pattern with motion blur
IX
ItI
a
weighing factor
Effect of the weighing factor on the overall filter performance Curve
measured for the case of a moving square-wave grating Filter
performance is estimated as the improvement in signal to noise ratio
I:iI
where is the original intensity at position in the image
is the intensity at the same position in the motion blurred image and
is the intensity at in the image generated with the adaptive
tuning procedure
extents comparable to those used for the simulations to be discussed in section IV.
From this curve it is apparent that for this situation there is an optimum value for
this weighing factor Keeping the weight close to this optimum value will result in
a constant output of our adaptive scheme thus enabling an optimal deblurring of
the smeared image of the moving object
On the other hand starting from the point of view that the time constants
should remain fixed throughout the filtering process we should had have to tune
the gradient weights to the velocity in order to produce a constant output as
demonstrated in figure where the dashed lines show strongly differing outputs of
a fixed time constant system with spatial processing with constant weight figure
4b In other words tuning of the time constants as proposed in this section results
in I the realization of the blur-constancy criterion as formulated previously and
as a consequence the possibility to deblur the obtained image oPtimally with
one and the same weighing factor of the gradient in the final spatial processing
layer over the whole heterodyne velocity range
COMPUTER SIMULATION RESULTS AND
CONCLUSIONS
The image quality improvement algorithm developed in the present
contribution has been implemented on a general purpose DG Eclipse Sjl40 minicomputer for our two dimensional simulations Figure Sa shows an undisturbed
image consisting of lines of each pixels with bit intensity resolution
Figure Sb shows what happens with the original image if the PSF is modelled
according to the exponential decay In this case the time constants of all
spatial information processing channels have been kept fixed Again information
content in the higher spatial frequencies has been reduced largely The
implementation of the heterodyne filtering procedure was now done as follows
first the adaptation range was defined by setting the range of velocities This
means that our adaptive heterodyne algorithm is supposed to operate adequately
only within the thus defined velocity range and that in that range the time
constants are tuned according to relationship and will always come out larger
than the minimum value min For demonstration purposes we set Q=I and in
eq thus introducing the phenomenon that for any velocity the two
dimensional set of spatial filters with time constants tuned by that velocity will
always produce a constant output independent of this velocity which introduces
the motion blur Figure Sc shows this representation It is important to note here
that this constant output has far more worse quality than any set of filters with
smallest and fixed time constants min would produce for velocities within the
operational range The advantage of a velocity independent output at this level in
our simulation model is that in the next stage a differential scheme can be
implemented as discussed in detail in the preceding paragraph Constancy of the
weighing factor which is used in this differential processing scheme is guaranteed
by the velocity independency of the obtained image representation
Figure Sd shows the result of the differential operation with an optimized
gradient weighing factor This weighing factor has been optimized based on an
almost identical performance curve as described previously in figure A clear
and good restoration is apparent from this figure though close inspection reveals
fine structure especially for areas with high intensities which is unrelated with
the original intensity distribution These artifacts are caused by the phenomenon
that for these high intensity areas possible tuning errors will show up much more
pronounced than for low intensities
Fig.8a
Fig.8b
8c
Fig.8d
a
Original bit picture
Motion degraded image with a PSF derived from
where is kept fixed to pixels and the motion blur extent is 32
pixels
Worst case the result of motion degradation of the original image
with a PSF as in figure 8b but with tuning of the time constants based
on the velocity
Restored version of the degraded image using the heterodyne adaptive
processing scheme
In conclusion a heterodyne adaptive image processing technique inspired by
the fly visual system has been presented as an imaging device for moving objects
A scalar difference equation model has been used to represent the motion blur
degradation process Based on the experimental results described and on this state
space model we developed an adaptive filtering scheme which produces at a
certain level within the system a constant output permitting further differential
operations in order to produce an optimally deblurred representation of the
moving object
ACKNOWLEDGEMENTS
The authors wish to thank mT Eric Bosman for his expert programming
assistance mr Franco Tommasi for many inspiring discussions and advises during
the implementation of the simulation model and dr Rob de Ruyter van Steveninck
for experimental help This research was partly supported by the Netherlands
Organization lor the Advancement 01 Pure Research through the
foundation Stichting voor Biolysica

<<----------------------------------------------------------------------------------------------------------------------->>

title: 56-discovering-structure-from-motion-in-monkey-man-and-machine.pdf

DISCOVERING STRUCfURE FROM MOTION IN
MONKEY MAN AND MACHINE
Ralph M. Siegel
The Salk Institute of Biology La Jolla Ca.
ABSTRACT
The ability to obtain three-dimensional structure from visual motion is
important for survival of human and non-human primates Using a parallel processing model the current work explores how the biological visual system might solve
this problem and how the neurophysiologist might go about understanding the
solution
INTRODUcnON
Psychophysical experiments have shown that monke and man are equally
adept at obtaining three dimensional structure from motion In the present work
much effort has been expended mimicking the visual system This was done for one
main reason the model was designed to help direct physiological experiments in the
primate It was hoped that if an approach for understanding the model could be
developed the approach could then be directed at the primate's visual system
Early in this century von Helmholtz2 described the problem of extracting
three-dimensional structure from motion
Suppose for instance that a person is standing still in a thick woods
where it is impossible for him to distinguish except vaguely and roughly
in the mass of foliage and branches all around him what belongs to one
tree and what to another or how far apart the separate trees are etc But
the moment he begins to move forward everything disentangles itself
and immediately he gets an apperception of the material content of the
woods and their relation to each other in space just as if he were looking
at a good stereoscopic view of it
If the object moves rather than the observer the perception of threedimensional structure from motion is still obtained Object-centered structure from
motion is examined in this report Lesion studies in monkey have demonstrated that
two extra-striate visual cortices called the middle temporal area abbreviated MT
Current address Laboratory of Neurobiology The Rockefeller University
York Avenue New York NY
American Institute of Physics
or and the medial superior temporal area are involved in obtaining
structure from motion The present model is meant to mimic the V5-MST part of
the cortical circuitry involved in obtaining structure from motion The model
attempts to determine ifthe visual image corresponds to a three-dimensional object
TIlE STRUCfURE FROM MOTION STIMULUS
The problem that the model solved was the same as that posed in the studies
of monkey and man Structured and unstructured motion displays of a hollow
orthographically projected cylinder were computed Figure The cylinder rotates
about its vertical axis The unstructured stimulus was generated by shuffling the
velocity vectors randomly on the display screen The overall velocity and spatial
distribution for the two displays are identical only the spatial relationships have
been changed in the unstructured stimulus Human subjects report that the points
are moving on the surface of a hollow cylinder when viewing the structured stimulus
With the unstructured stimulus most subjects report that they have no sense of
three-dimensional structure
B. Orthographic
Projection
A. Rotating Cylinder
Unstructured
Display
Figure The structured and unstructured motion stimulus A pomts are
randomly placed on the surface of a cylinder The points are orthographically projected The motion gives a strong percept of a hollow cylinder The unstructured
stimulus was generated by shuffling the velocity vectors randomly on the screen
FUNCTIONALARCHITECfUREOFTIlEMODEL
As with the primate subjects the model was required to only indicate whether
or not the display was structured Subjects were not required to describe the shape
velocity or size of the cylinder Thus the output cell of the model signaled if
By cell I mean a processing unit of the model which may correspond to a single
neuron or group of neurons The term neuron refers only to the actual wetware
in the brain
structured and if not structured This output layer corresponds to the cortical
area MST of macaque monkey which appear to be sensitive to the global organization of the motion image5 It is not known if MST neurons will distinguish between
structured and unstructured images
The input to the model was based on physiological studies in the maca~ue
monkey Neurons in area V5 have a retinotopic representation of visual space
For each retinotopic location there is
an encoding of a wide range of velocitiesS Thus in the model's input rep1
resentation there were cells that
CIl
represent different combinations of
velocity and retinotopic spatial posi0CIl
tion Furthermore motion velocity
neurons in V5 have a center-surround opponent organization9 The
width of the receptive fields was
taken from the data of Albright
retinal position deg
S. A typical receptive field of the
model is shown in Figure
Figure The receptive field of an input
layer cell The optimal velocity is
lt was possible to determine what the activity of the input cells would be for
the rotating cylinder given this representation The activation pattern of the set of
input cells was computed by convolving the velocity points with the difference of
gaussians The activity of the input cells for an image of points with an angular velocity of SO/sec is presented in Figure
Relinotopic map
Retinotopic map
Structure
Structure
Figure The input cell's activation pattern for a structured and unstructured stimuIus The circles correspond to the cells of the input layer The contours were com
puted using a linear interpolation between the individual cells The horizontal axis
corresponds to the position along the horizontal meridian The vertical axis corresponds to the speed along the horizontal meridian Thus activation of a cell in the
upper right hand corner of the graph correspond to a velocity of sec towards the
right at a location of to the right along the horizontal meridian
Inspection of this input pattern suggested that the problem of detecting
three-dimensional structure from motion may be reduced to a pattern recognition
task The problem was then Given a sparsely sampled input motion flow field determine whether it corresponds best to a structured or unstructured object
Itwas next necessary to determine the connections between the two input and
output layers such that the model will be able to correctly signal structure or no structure or over a wide range of cylinder radii and rotational velocities A parallel
distributed network of the type used by Rosenberg and Sejnowski provided the
functional architecture Figure
I
Figure The parallel architecture used to extract structure
from motion The input layer corresponding to area
mapped the position and speed along the horizontal axis
The output layer corresponded to area MST that it is
proposed signals structure or not The middle layer
may exist in either V5 or MST.
The input layer of cells was fully connected to the middle layer of cells The
middle layer of cells represented an intermediate stage of processing and may be in
either V5 or MST. All of the cells of the middle layer were then fully connected to
the output cell The inputs from cells of the lower layer to the next higher level were
summed linearly and then thresholded using the Hill equation
The weights between the layers were initially chosen between.?.1 The values of the
weights were then adjusted using back-propagation methods steepest descent so
that the network would learn to correctly predict the structure of the input image
The model learned to correctly perform the task after about iterations
Figure
Figure The education of the network to
perform the structure from motion problem
The iteration number is plotted against the
mean square error The error is defined as the
difference between the model's prediction and
the known structure The model was trained on
a set of structured and unstructured cylinders
a wi?e range adii number of points
with
and rotatlOnal velOCItIes
Iteration number
PSYCHOPHYSICAL PERFORMANCE OF THE MODEL
The model's performance was comparable to that of monkey and man with
respect to fraction of structure and number of points in the display Figure The
model was indeed performing a global analysis as shown by allowing the model to
view only a portion of the image Like man and monkey the model's performance
suffers Thus it appears that the model's performance was quite similar to known
monkey and human psychophysics
Output
monkey
man
machine
monkey
man
machine
Fraction structure
32
64
96
Number of points
Figure Psychophysical performance of the model A. The effect of varying the
fraction of structure As the fraction of structure increase the model's performance
improves Thirty repetitions were averaged for each value of structure for the model
The fraction of structure is defined as where Rs is the radius of shuffling
of the motion vectors and Rc is the radius of the cylinder The human and monkey
data are taken from psychophysical studies
HOW IS IT DONE
The model has similar performance to monkey and man It was next possible
to examine this artificial network in order to obtain hints for studying the biological
system Following the approach of an electrophysiologist receptive field maps for
all the cells of the middle and ou tput layers were made by activating individual inpu
cells The receptive field of some middle layer cells are shown in Figure The layout
of these maps are quite similar to that of Figure However now the activity of one
cell in the middle layer is plotted as a function of the location and speed of a motion
stimulus in the input layer One could imagine that an electrode was placed in one
of the cells of the middle layer while the experimentalist moved a bar about the
horizontal meridian with different locations and speeds The activity of the cell is
then plotted as a function of position and space
Relinolopic map
rJ
I
Figure The activity of two different cells in the middle layer Activity is plotted
as a contour map as a function of horizontal position and speed Dotted lines
indicate inhibition
These middle layer receptive field maps were interesting because they
appear to be quite simple and symmetrical In some the inhibitory central regions
of the receptive field were surrounded by excitatory regions Figure Complementary cells were also found In others there are inhibitory bands adjacent to
excitatory bands Figure The above results suggest that neurons involved in
extracting structure from motion may have relatively simple receptive fields in the
spatial velocity domain These receptive fields might be thought of as breaking the
image down into component parts a basis set Correct recombination of these
second order cells could then be used to detect the presence of a three-dimensional
structure
The output cell also had a simple receptive field again with interesting
symmetries Figure However the receptive field analysis is insufficient to
indicate the role of the cell Therefore in order to properly understand the meaning of the cell's receptive field it is necessary to use
stimuli that are real world relevant in this case the
structure from motion stimuli The output cell would
give its maximal response only when a cylinder stimulus
is presented
Figure The receptive field map of the output layer cell
Nothing about this receptive field structure indicates the
cell is involved in obtaining structure from motion
This work predicts that neurons in cortex involved in extracting structure
from motion will have relatively simple receptive fields In order to test this
hypothesis it will be necessary to make careful maps of these cells using small
patches of motion Figure Known qualitative results in areas V5 and MST are
consistent with but do not prove this hypothesis As well it will be necessary to use
relevant stimuli three-dimensional objects If such simple receptive fields
are indeed used in structure from motion then support will be found for the idea that
a simple cortical circuit center-surround can be used for many different visual
analyses
Motion patches consisting of random dots with
variable velocity
ru
Fix point
Figure It may be necessary to make careful
maps of these neurons using small patches of
motion in order to observe the postulated simple
receptive field properties of cortical neurons involved in extracting structure from
motion Such structures may not be apparent using hand moved bar stimuli
DISCUSSION
In conclusion it is possible to extract the three-dimensional structure of a
rotating cylinder using a parallel network based on a similar functional architecture
as found in primate cortex The present model has similar psychophysics to monkey
and man The receptive field structures that underlie the present model are simple
when viewed using a spatial-velocity representation It is suggested that in order to
understand how the visual system extracts structure from motion quantitative
spatial-velocity maps of cortical neurons involved need to be made One also needs
to use stimuli derived from the real world in order to understand how they may
be used in visual field analysis There are similarities between the shapes of the
receptive fields involved in analyzing structure from motion and receptive fields in
striate cortex It may be that similar cortical mechanisms and connections are used
to perform different functions in different cortical areas Lastly this model demonstrates that the use of parallel architectures that are closely modeled on the cortical
representation is a computationally efficient means to solve problems in vision Thus
as a final caveat I would like to advise the creators of networks that solve
ethologically realistic problems to use solutions that evolution has provided

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 51-reflexive-associative-memories.pdf

REFLEXIVE ASSOCIATIVE MEMORIES
Hendrlcus G. Loos
Laguna Research Laboratory Fallbrook CA
ABSTRACT
In the synchronous discrete model the average memory capacity of
bidirectional associative memories BAMs is compared with that of
Hopfield memories by means of a calculat10n of the percentage of good
recall for random BAMs of dimension for different numbers
of stored vectors The memory capac1ty Is found to be much smal1er than
the Kosko upper bound which Is the lesser of the two dimensions of the
BAM. On the average a BAM has about 68 of the capacity of the
corresponding Hopfield memory with the same number of neurons Orthonormal coding of the BAM Increases the effective storage capaCity by
only The memory capacity limitations are due to spurious stable
states which arise In BAMs In much the same way as in Hopfleld
memories Occurrence of spurious stable states can be avoided by
replacing the thresholding in the backlayer of the BAM by another
nonl1near process here called Dominant Label Selection The
simplest DLS is the wlnner-take-all net which gives a fault-sensitive
memory Fault tolerance can be improved by the use of an orthogonal or
unitary transformation An optical application of the latter is a Fourier
transform which is implemented simply by a lens
INTRODUCT ION
A reflexive associative memory also called bidirectional associative memory is a two-layer neural net with bidirectional connections
between the layers This architecture is implied by Dana Anderson's
optical resonator and by similar configurations Bart KoSk0 coined
the name Bidirectional Associative Memory and Investigated
several basic propertles We are here concerned with the memory
capac1ty of the BAM with the relation between BAMs and Hopfleld
memories and with certain variations on the BAM.
American Institute of Physics
BAM STRUCTURE
We will use the discrete model In which the state of a layer of
neurons Is described by a bipolar vector The Dirac notationS will be
used In which I and I denote respectively column and row vectors al
and la are each other transposes alb Is a scalar product and la><bl is
an outer product As depicted in the BAM has two layers of
neurons a front layer of Nneurons tth state vector and a back layer
back layer neurons
back
of neurons with state vector
state vector
stroke
Ib>. The bidirectional connectlons between the layers allow
signal flow In two directions
frOnt1ay~r eurons forward
The front stroke gives
state vector
stroke
s(Blf where the connecFig BAM structure
tlon matrix and Is a threshold function operating at
zero The back stroke results 1n an u~graded front state
whIch also may be wr1tten as Ib where the superscr1pt
denotes transpos1t10n We consider the synchronous model where all
neurons of a layer are updated s1multaneously but the front and back
layers are UPdated at d1fferent t1mes The BAM act10n 1s shown 1n F1g.
The forward stroke entalls takIng scalar products between a front
state vector If and the rows or and enter1ng the thresholded results
as elements of the back state vector Ib>. In the back stroke we take
threshold ing
reflection
lID
NxP
FIg. BAM act
threshold ing
reflection
hreShOlding
4J
NxN
feedback
Ftg. Autoassoc1at1ve
memory act10n
scalar products of Ib w1th column vectors of and enter the
thresholded results as elements of an upgraded state vector In
contrast the act10n of an autoassoc1at1ve memory 1s shown 1n F1gure
The BAM may also be described as an autoassoc1at1ve memory5 by
concatenating the front and back vectors tnto a s1ngle state vector
Iv>=lf,b>,and by taking the connection matrtx as shown in F1g.
This autoassoclat1ve memory has the same number of neurons as our
BAM viz N+P. The BAM operat1on where
initially only the front state 1s specif thresholding
zero IDT
feedback
f1ed may be obtained with the corresponding autoassoc1ative memory by
lID zero
initially spectfying Ib as zero and by
BAM as autoassoarranging the threshold1ng operat1on
ctative memory
such that does not alter the state
vector component For a Hopfteld
memory7 the connection matrix 1s
mD MI
m=l
I
where to are stored vectors and I is the tdentity matr1x
Writing the N+P d1mens1onal vectors as concatenations Idm,c
takes the form
I
ldm><dml+lcm><cml+ldm><cml+lcm><dmD)-MI
m=l
w1th proper block plactng of submatr1ces understood Writing
Llcm><dml
m=l
Hd=(Lldm><dmD-MI
L'lcm><cml>-MI
m=l
m=l
where the I are identities in appropriate subspaces the Hopfield matrix
may be partitioned as shown in is just the BAM matrix given
by Kosko and previously used by Kohonen for linear heteroassoclatjve
memories Comparison of Figs and shows that in the synchronous
discrete model the BAM with connection matrix is equivalent to a
Hopfield memory in which the diagonal blocks Hd and Hc have been
deleted Since the Hopfleld memory is robust this prun1ng may not
affect much the associative recall of stored vectors if is small
however on the average pruning will not improve the memory capaclty
It follows that on the average a discrete synchronous BAM with matrix
can at best have the capacity of a Hopfleld memory with the same
number of neurons
We have performed computations of the average memory capacity
for BAMs and for corresponding Hopfleld memories
Monte Carlo calculations were done for memories each of which
stores random bipolar vectors The straight recall of all these vectors
was checked al10wtng for 24 Iterations For the BAMs the iterations
were started with a forward stroke in which one of the stored vectors
Idm was used as input The percentage of good recall and its standard
deviation were calculated The results plotted in show that the
square BAM has about of the capacity of the corresponding Hopfleld
memory Although the total number of neurons is the same the BAM only
needs of the number of connections of the Hopfield memory The
storage capacity found Is much smaller than the Kosko upper bound
which Is min
Partitioned
Hopfield matrix
M. number of stored vectors
of good recall versus
CODED BAM
So far we have considered both front and back states to be used for
data There is another use of the BAM in which only front states are used
as data and the back states are seen as providing a code label or
pOinter for the front state Such use was antiCipated in our expression
for the BAM matrix which stores data vectors Idm and their labels or
codes lem For a square BAM. such an arrangement cuts the Information
contained in a single stored data vector jn half However the freedom of
choosing the labels fC may perhaps be put to good use Part of the
problem of spurious stable states which plagues BAMs as well as
Hopf1eld memories as they are loaded up is due to the lack of
orthogonality of the stored vectors In the coded BAM we have the
opportunity to remove part of this problem by choosing the labels as
orthonorma1 Such labels have been used previously by Kohonen 1n linear
heteroassociative memories The question whether memory capacity can
be Improved In this manner was explored by taking BAt1s In which
the labels are chosen as Hadamard vectors The latter are bipolar vectors
with Euclidean norm which form an orthonormal set These vectors
are rows of a PxP Hadamard matrix for a discussion see Harwtt and
Sloane The storage capacity of such Hadamard-coded BAMs was
calculated as function of the number of stored vectors for cases
for each value of in the manner discussed before The percentage of
good recall and its standard deviation are shown 1n It Is seen that
the Hadamard coding gives about a factor in compared to the
ordinary BAM. However the coded BAM has only half the stored
data vector dimension Accounting for this factor reduction of data
vector dimension the effective storage capacity advantage obtained by
Hadamard coding comes to only
HALF BAt1 WITH HADAMARD CODING
For the coded BAM there is the option of deleting the threshold
operation In the front layer The resulting architecture may be called
half In the half BAM thresholding Is only done on the labels and
consequently the data may be taken as analog vectors Although such an
arrangement diminishes the robustness of the memory somewhat there
are applications of interest We have calculated the percentage of good
recall for cases and found that giving up the data thresholding cuts
the storage capacity of the Hadamard-coded BAt1 by about
SELECTIVE REFLEXIVE MEMORY
The memory capacity limitations shown in are due to the
occurence of spurious states when the memories are loaded up
Consider a discrete BAM with stored data vectors to
orthonormal labels Icm and the connection matrix
For an input data vector Iv which is closest to the stored data vector
one has 1n the forward stroke
Ib>=s(clc
amlcm
where
llv
and
am=<mlv
Although for am<c for some vector component the sum
amlc
may accumulate to such a large value as to affect the thresholded result
Ib>. The problem would be avoided jf the thresholding operation in the
back layer of the BAM were to be replaced by another nonl1near operation
which selects from the I inear combination
clc
amlcm
the dominant label Ic The hypothetical device which performs this
operation is here called the Dominant Label Selector DLS and we
call the resulting memory architecture Selective Reflexive Memory
With the back state selected as the dominant label Ic the back
stroke gives by the orthogonal ity of the labels
Icm It follows that the SRM g1ves perfect assoc1attve recall of the
nearest stored data vector for any number of vectors stored Of course
the llnear independence of the P-dimensionallabel vectors Icm to
requires
The DLS must select from a linear combination of orthonormal
labels the dominant label A trivial case is obtained by choosing the
labels Icm>as basis vectors Ium which have all components zero except
for the mth component which 1s unity With this choice of labels the
DLS may be taken as a winnertake-all net as shown in
winner
This case appears to be Included in
take-all
net
Adapt Ive Resonance Theory
ART as a special sjmpllf1ed
case A relationship between
Simplest reflexive
the ordinary BAM and ART was
memory with DLS
pOinted out by KoskoS As in ART
there Is cons1derable fault sensitivity tn this memory because the
stored data vectors appear in the connectton matrix as rows
A memory with better fault tolerance may be obtained by using
orthogonal labels other than basis vectors The DLS can then be taken as
an orthogonal transformation followed by a winner-take-an net as
shown 1n is to be chosen such that 1t transforms the labels Icm
rthogonal
I
transformation
winner take-all
net
F1g. Select1ve reflex1ve
memory
tnto vectors proportional to the
basts vectors This can always
be done by tak1ng
G=[Iup><cpl
p=l
where the Icp to form a
complete orthonormal set which
contains the labels Icm m=l to M. The neurons in the DLS serve as
grandmother cells Once a single winning cell has been activated
the state of the layer Is a single basis vector say lu I this vector
must be passed back after appllcation of the transformation such
as to produce the label at the back of the BAM. Since 1s
orthogonal we have so that the reQu1red 1nverse
transformation may be accompl1shed sfmply by sending the bas1s vector
back through the transformer this gives
1IUp><cpl=<c
p=l
as required
HAlF SRM
The SRM may be modified by deleting the thresholding operation in
the front layer The front neurons then have a I inear output which is
reflected back through the SRM as shown in In this case the
stored data vectors and the
input data vectors may be taken
I near neurons
orthogonal
as analog vectors but we
transfor.1
Qu1re all the stored vectors to
mation
have the same norm The act on
winnerof the SRM proceeds in the same
I take-all
net
way as described above except
that we now require the orthoFig Half SRM with l1near
normal labels to have unit
norm It follows that just l1ke
neurons in front layer
the full SRM the half SRM gives
perfect associative recall to the nearest stored vector for any number
of stored vectors up to the dimension of the labels The latter
condition 1s due to the fact that a P-dimensional vector space can at
most conta1n orthonormal vectors
In the SRM the output transform Gis 1ntroduced in order to improve
the fauJt tolerance of the connection matrix K. This is accomplished at
the cost of some fault sensitivity of the extent of which needs to be
investigated In this regard 1t is noted that in certatn optical implementat ions of reflexive memories such as Dana Anderson's resonator I and
Similar conflgurations the transformation is a Fourier transform
which is implemented simply as a lens Such an implementation ts quite
insentive to the common semiconductor damage mechanisms
EQUIVALENT AUTOASSOCIATIVE MEMORIES
Concatenation of the front and back state vectors allows description of the SRMs tn terms of autoassociative memories For the SRM
which uses basis vectors as labels the corresponding autoassociative
memory js shown tn Fjg. This connect jon matrtx structure was also
proposed by Guest 13 The wtnner-take-all net needs to be
given t1me to settle on a basis
vector state before the state Ib
slow thres
holding
can influence the front state If>.
feedback
This may perhaps be achieved by
zero I[T
arranging the network to have a
ast thres thresholding and feedback which
WI bl olding
feedback
are fast compared with that of the
network An alternate method
Equivalent automay be to equip the network
associat lve memory
w1th an output gate which is
opened only after the net has
sett led These arrangements
present a compUcatlon and cause a delay which in some appllcations
may be 1nappropriate and In others may be acceptable in a trade
between speed and memory density
For the SRM wtth output transformer and orthonormal1abels other
than basis vectors a corresponf eedback
ding autoassoclat1ve memory may
be composed as shown In Fig.l1
thresholded
OJ OJ
An output gate in the layer is
linear
OJ
GT
I
chosen as the device which
thresholded
WI
prevents the backstroke through
output gate
the BAM to take place before the
w1nner-take-al net has settled
Autoassoc1at1ve memory
equivalent to SRM with transform
The same effect may perhaps be
achieved by choosing different
response times for the neuron
output gate
layers and These matters
wr winner-take-all
require investigation Unless
Woutput
the output transform 1s already
t@
back layer
required for other reasons as in
linear
some optical resonators the DLS
front layer
BAM connections
with output transform is clumsy
@ orthogonal transformat on
I would far better to combine
winner-take-all net
the transformer and the net
into a single network To find
Structure of SRM
such a DLS should be considered
a cha enge
The wort was partly supported by the Defense Advanced Research
projects Agency ARPA order through Contract DAAHOI-86-C
with the U.S. Army Missile Command

<<----------------------------------------------------------------------------------------------------------------------->>

title: 52-teaching-artificial-neural-systems-to-drive-manual-training-techniques-for-autonomous-systems.pdf

Teaching Artificial Neural Systems to Drive
Manual Training Techniques for Autonomous Systems
J. F. Shepanski and S. A. Macy
TRW Inc
One Space Park
Redondo Beach CA
Abetract
We have developed a methodology for manually training autononlous control systems
based on artificial neural systems In applications where the rule set governing an expert's
decisions is difficult to formulate ANS can be used to ext.ra.c:t rules by associating the information
an expert receives with the actions takes Properly constructed networks imitate rules of
behavior that permits them to function autonomously when they are trained on the spanning set
of possible situations This training can be provided manually either under the direct supervision
or a system trainer or indirectly using a background mode where the network assimilates training
data as the expert perrorms his day-to-day tasks To demonstrate these methods we have trained
an ANS network to drive a vehicle through simulated rreeway traffic
I ntJooducticn
Computational systems employing fine grained parallelism are revolutionizing the way we
approach a number or long standing problems involving pattern recognition and cognitive processing The field spans a wide variety or computational networks rrom constructs emulating neural
runctions to more crystalline configurations that resemble systolic arrays Several titles are used
to describe this broad area or research we use the term artificial neural systems Our concern in this work is the use or ANS ror manually training certain types or autonomous systems
where the desired rules of behavior are difficult to rormulate
Artificial neural systems consist of a number or processing elements interconnected in a
weighted user-specified fashion the interconnection weights acting as memory ror the system
Each processing element calculatE an output value based on the weighted sum or its inputs In
addition the input data is correlated with the output or desired output specified by an instructive
agent in a training rule that is used to adjust the interconnection weights In this way the ne
work learns patterns or imitates rules of behavior and decision making
The partiCUlar ANS architecture we use is a variation of Rummelhart lJ multi-layer
perceptron employing the generalized delta rule GD R). Instead of a single multi-layer structure our final network has a a multiple component or block configuration where one blOt'k
output reeds into another Figure The training methodology we have developed is not
tied to a particular training rule or architecture and should work well with alternative networks
like Grossberg's adaptive resonance model[2J
American Institute of Physics
The equations describing the network are derived and described in detail by Rumelhart
In summary they are
Transfer function
Sj
WjiOi
i-O
Weight adaptation rule
Error calculation
a
OJ
a l'??Awp.revious
OJ E0.tW.ti
where OJ is the output or processing element or a sensor input is the interconnection weight
leading from element ito is the number of inputs to Aw is the adjustment of is the
training constant a is the training momentum OJ is the calculated error for element and
is the Canout oC a given element Element zero is a constant input equal to one so that WjO is
equivalent to the bias threshold of element The factor in equation differs from standard GDR formulation but it is useful for keeping track of the relative magnitudes of the two
terms For the network's output layer the summation in equation is replaced with the
difference between the desired and actual output value of element
These networks are usually trained by presenting the system with sets of input/output data
vectors in cyclic fashion the entire cycle of database presentation repeated dozens of times This
method is effective when the training agent is a computer operating in batch mode but would be
intolerable for a human instructor There are two developments that will help real-time human
training The first is a more efficient incorporation of data/response patterns into a network The
second which we are addressing in this paper is a suitable environment wherein a man and ANS
network can interact in training situation with minimum inconvenience or boredom on the
human's part The ability to systematically train networks in this fashion is extremely useful for
developing certain types of expert systems including automatic signal processors autopilots
robots and other autonomous machines We report a number of techniques aimed at facilitating
this type of training and we propose a general method for teaching these networks
System Development
Our work focuses on the utility of ANS for system control It began as an application of
Barto and Sutton's associative search network[3 Although their approach was useful in a
number of ways it fell short when we tried to use it for capturing the subtleties of human
decision-making In response we shifted our emphasis rrom constructing goal runctions for
automatic learning to methods for training networks using direct human instruction An integral
part or this is the development or suitable interraces between humans networks and the outside
world or simulator In this section we will report various approaches to these ends and describe a
general methodology for manually teaching ANS networks To demonstrate these techniques we
taught a network to drive a robot vehicle down a simulated highway in traffic This application
combines binary decision making and control of continuous parameters
Initially we investigated the use or automatic learning based on goal functions[3 for training control systems We trained a network-controlled vehicle to maintain acceptable following
distances from cars ahead or it On a graphics workstation a one lane circular track was
constructed and occupied by two vehicles a network-controlled robot car and a pace car that
varied its speed at random Input data to the network consisted of the separation distance and
the speed of the robot vehicle The values of a goal function were translated into desired output
for GDR training Output controls consisted of three binary decision elements accelerate one
increment of speed maintain speed and decelerate one increment of speed At all times
the desired output vector had exactly one of these three elements active The goal runction was
quadratic with a minimum corresponding to the optimal following distance Although it had no
direct control over the simulation the goal function positively or negatively reinforced the
system's behavior
The network was given complete control of the robot vehicle and the human trainer had
no influence except the ability to start and terminate training This proved unsatisractory because
the initial system behavior--governed by random interconnection weights--was very unstable The
robot tended to run over the car in rront of it before significant training occurred By carerully
halting and restarting training we achieved stable system behavior At first the rollowing distance
maintained by the robot car oscillated as ir the vehicle was attached by a sj)ring to the pace car
This activity gradually damped Arter about one thousand training steps the vehicle maintained
the optimal following distance and responded quickly to changes in the pace car's speed
Constructing composite goal functions to promote more sophisticated abilities proved
difficult even ill-defined because there were many unspecified parameters To generate goal
runctions ror these abilities would be similar to conventional programming--the type or labor we
want to circumvent using ANS. On the other hand humans are adept at assessing complex situations and making decisions based on qualitative data but their goal runctions are difficult ir not
impossible to capture analytically One attraction of ANS is that it can imitate behavior based on
these elusive rules without rormally specifying them At this point we turned our efforts to
manual training techniques
The initially trained network was grafted into a larger system and augmented with additional inputs distance and speed inrormation on nearby pace cars in a second traffic lane and an
output control signal governing lane changes The original network's ability to maintain a safe
following distance was retained intact Thts grafting procedure is one of two methods we studied
for adding ne abilities to an existin system The second which employs a block structure is
described below The network remained in direct control of the robot vehicle but a human
trainer instructed it when and when not to change lanes His commands were interpreted as the
desired output and used in the GDR training algorithm This technique which we call coaching
proved userul and the network quickly correlated its environmental inputs with the teacher's
instructions The network became adept at changing lanes and weaving through traffic We found
that the network took on the behavior pattern or its trainer A conservative teacher produced a
timid network while an aggressive tzainer produced a network that tended to cut off other automobiles and squeeze through tight openings Despite its success the coaching method of training
did not solve the problem or initial network instability
The stability problem was solved by giving the trainer direct control over the simulation
The system configuration Figure allows the expert to exert control or release it to the
work During initial tzaining the expert is in the driver's seat while the network acts the role of
apprentice It receives sensor information predicts system commands and compares its predictions against the desired output the trainer's commands Figure shows the data and command flow in detail Input data is processed through different channels and presented to the
trainer and network Where visual and audio formats are effective for humans the network uses
information in vector form This differentiation of data presentation is a limitation of the system
removing it is a cask for future search The trainer issues control commands in accordance with
his assigned while the network takes the trainer's actions as desired system responses and
correlates these with the input We refer to this procedure as master/apprentice training network
training proceeds invisibly in the background as the expert proceeds with his day to day work It
avoids the instability problem because the network is free to make errors without the adverse
consequence of throwing the operating environment into disarray
I
Input
World sensors
or
Simulation
Actuation
I
Ne',WOrk
I
Expert
Commands
Figure A scheme for manually training ANS networks Input data is received by both
the network and trainer The trainer issues commands that are actuated solid command
line or he coaches the network in how it ought to respond broken command line
Commands
Preprocessing
tortunan
Input
data
Preprocessing
for network
twork
Predicted
commands
Actuation
Coaching/emphasis
Training
rule
Fegure Data and convnand flow In the training system Input data is processed and presented
to the trainer and network In master/appre~ice training solid command Hne the trainer's
orders are actuated and the network treats his commands as the system's desired output In
coaching the network's predicted oonvnands are actuated broken command line and the
trainer influences weight adaptation by specifying the desired system output and controlHng
the values of trailing constants-his suggestions are not cirec:tty actuated
Once initial bacqround wainmg is complete the expert proceeds in a more formal
manner to teach the network He releases control of the command system to the network in
order to evaluate ita behavior and weaknesses He then resumes control and works through a
series of scenarios designed to train t.he network out of its bad behavior By switching back and
forth between human and network control the expert assesses the network's reliability and
teaches correct responses as needed We find master/apprentice training works well for behavior
involving continuous functions like steering On the other hand coaching is appropriate for decision Cunctions like when Ule car ought to pass Our methodology employs both techniques
The Driving Network
The fully developed freeway simulation consists of a two lane highway that is made of
joined straight and curved segments which vary at random in length and curvature Several
pace cars move at random speeds near the robot vehicle The network is given the tasks of tracking the road negotiating curves returning to the road if placed far afield maintaining safe distances from the pace cars and changing lanes when appropriate Instead of a single multi-layer
structure the network is composed of two blocks one controls the steering and the other regulates speed and decides when the vehicle should change lanes Figure The first block receives
information about the position and speed of the robot vehicle relative to other ears in its vicinity
Its output is used to determine the automobile's speed and whet.her the robot should change
lanes The passing signal is converted to a lane assignment based on the car's current lane position The second block receives the lane assignment and data pertinent to the position and orientation of the vehicle with respect to the road The output is used to determine the steering angle
of the robot car
Block
Inputs
Outputs
Constant
Speed
Disl Ahead Pl
Disl Ahead Ol
Dist Behind Ol
ReI. Speed Ahead Pl
ReI. Speed Ahead Ol
ReI. Speed Behind Ol
I
Speed
Change lanes
Steering Angle
Convert lane change to lane number
Constant
Rei. Orientation
lane Nurmer
lateral Dist
Curvature
Figure The two blocks of the driving ANS network Heavy arrows Indicate total interconnectivity
between layers PL designates the traffic lane presently oca.apied by the robot vehicle Ol refers
to the other lane QJrvature refers to the road lane nurrber is either or relative orientation and
lateral distance refers to the robot car's direction and podion relative to the road'l direction and
center line respectively
The input data is displayed in pictorial and textual form to the driving instructor He views
the road and nearby vehicles from the perspective of the driver's seat or overhead The network
receives information in the form of a vector whose elements have been scaled to unitary order
Wide ranging input parameters like distance are compressed using the hyperbolic tangent
or logarithmic functions In each block the input layer is totally interconnected to both the ou
put and a hidden layer Our scheme trains in real time and as we discuss later it trains more
smoothly with a small modification of the training algorithm
Output is interpreted in two ways as a binary decision or as a continuously varying parameter The first simply compares the sigmoid output against a threshold The second scales the
output to an appropriate range for its application For example on the steering output element a
value is interpreted as a zero steering angle Left and right turns of varying degrees are initiated when this output is above or below respectively
The network is divided into two blocks that can be trained separately Beside being conceptually easier to understand we find this component approach is easy to train systematically
Because each block has a restricted well-defined set of tasks the trainer can concentrate
specifically on those functions without being concerned that other aspects of the network behavior
are deteriorating
trained the system from bottom up first teaching the network to stay on the road
negotiate curves chan~e lanes and how to return if the vehicle strayed off the highway Block
responsible for steering learned these skills in a few minutes using the master/apprentice mode
It tended to steer more slowly than a human but further training progressively improved its
responsiveness
We experimented with different trammg constants and momentum values Large
values about caused weights to change too coarsely values an order of magnitude smaller
worked well We found DO advantage in using momentum for this method of training in fact
the system responded about three times more slowly when than when the momentt:m
term was dropped Our standard training parameters were and Cl
Figure Typical behavior of a network-controlled vehicle dam rectangle when trained by
a conservative miYer ItI:I reckless driver Speed Is indicated by the length of the arrows
After Block Was trained we gave steering control to the network and concentrated on
teaching the network to change lanes and adjust speed Speed control in this was a continuous variable and was best taught using master/apprentice training On the other hand the binary
decision to change lanes was best taught by coaching About ten minutes of training were needed
to teach the network to weave through traffic We found that the network readily adapts the
behavioral pattern of its trainer A conservative trainer generated a network that hardly ever
passed while an aggressive trainer produced a network that drove recklessly and tended to cut off
other-cars Figure
Discussion
One of the strengths of el:pert 5ystf'mS based on ANS is that the use of input data in the
decision making and control proc~ss does not have to be specified The network adapts its internal weights to conform to input output correlat.ions it discovers It is important however that
data used by the human expert is also available to the network The different processing of sensor data for man and network may have important consequences key information may be
presented to the man but not the machine
This difference in data processing is particularly worrisome for image data where human
ability to extract detail is vastly superior to our au tomatic image processing capabilities Though
we would not require an image processing system to understand images it would have to extract
relevant information from cluttered backgrounds Until we have sufficiently sophisticated algorithms or networks to do this our efforts at constructing expert systems which halldle image data
are handicapped
Scaling input data to the unitary order of magnitude is important for training stability
is evident from equations and The sigmoid transfer function ranges from to in
approximat.eiy four units that is over an domain If system response must change in reaction to a large swing of a given input parameter the weight associated with that input will
be trained toward an magnitude On the other hand if the same system responds to an
input whose range is its associated weight will also be The weight adjustment equation does not recognize differences in weight magnitude therefore relatively small weights will
undergo wild magnitude adjustments and converge weakly On the other hand if all input parameters are of the same magnitude their associated weights will reflect this and the training constant
can be adjusted for gentle weight convergence Because the output of hidden units are constrained between zero and one is a good target range for input parameters Both the hyperbolic tangent and logarithmic functions are useful for scaling wide ranging inputs A useful form
of the latter is
if
ifx<-o
where and defines the limits of the intermediate linear section and is a scaling factor
This symmetric logarithmic function is continuous in its first derivative and useful when network
behavior should change slowly as a parameter increases without bound On the othl'r hand if the
system should approach a limiting behavior the tanh function is appropriate
Weight adaptation is also complicated by relaxing the common practice of restricting interconnections to adjacent layers Equation shows that the calculated error for a hidden layergiven comparable weights fanouts and output errors-will be one quarter or less than that of the
output layer This is caused by the slope ractor oil The difference in error magnitudes is
not noticeable in networks restricted to adjacent layer interconnectivity But when this constraint
is released the effect of errors originating directly from an output unit has times the magnitude
and effect of an error originating from a hidden unit removed layers from the output layer
Compared to the corrections arising from the output units those from the hidden units have little
influence on weight adjustment and the power of a multilayer structure is weakened The system
will train if we restrict connections to adjacent layers but it trains slowly To compensate for this
effect we attenuate the error magnitudes originating from the output layer by the above factor
This heuristic procedure works well and racilitates smooth learning
Though we have made progress in real-time learning systems using GDR compared to
humans-who can learn from a single data presentation-they remain relatively sluggish in learning
and response rates We are interested in improvements of the GDR algorithm or alternative
architectures that facilitate one-shot or rapid learning In the latter case we are considering least
squares restoration techniquesl4 and Grossberg and Carpenter's adaptive resonance modelsI3,5
The construction of automated expert systems by observation of human personnel is
attractive because of its efficient use of the expert's time and effort Though the classic AI
approach of rule base inference is applicable when such rules are clear cut and well organized too
often a human expert can not put his decision making process in words or specify the values of
parameters that influence him The attraction or ANS based systems is that imitations of expert
behavior emerge as a natural consequence of their training

<<----------------------------------------------------------------------------------------------------------------------->>

title: 52-teaching-artificial-neural-systems-to-drive-manual-training-techniques-for-autonomous-systems.pdf

Teaching Artificial Neural Systems to Drive
Manual Training Techniques for Autonomous Systems
J. F. Shepanski and S. A. Macy
TRW Inc
One Space Park
Redondo Beach CA
Abetract
We have developed a methodology for manually training autononlous control systems
based on artificial neural systems In applications where the rule set governing an expert's
decisions is difficult to formulate ANS can be used to ext.ra.c:t rules by associating the information
an expert receives with the actions takes Properly constructed networks imitate rules of
behavior that permits them to function autonomously when they are trained on the spanning set
of possible situations This training can be provided manually either under the direct supervision
or a system trainer or indirectly using a background mode where the network assimilates training
data as the expert perrorms his day-to-day tasks To demonstrate these methods we have trained
an ANS network to drive a vehicle through simulated rreeway traffic
I ntJooducticn
Computational systems employing fine grained parallelism are revolutionizing the way we
approach a number or long standing problems involving pattern recognition and cognitive processing The field spans a wide variety or computational networks rrom constructs emulating neural
runctions to more crystalline configurations that resemble systolic arrays Several titles are used
to describe this broad area or research we use the term artificial neural systems Our concern in this work is the use or ANS ror manually training certain types or autonomous systems
where the desired rules of behavior are difficult to rormulate
Artificial neural systems consist of a number or processing elements interconnected in a
weighted user-specified fashion the interconnection weights acting as memory ror the system
Each processing element calculatE an output value based on the weighted sum or its inputs In
addition the input data is correlated with the output or desired output specified by an instructive
agent in a training rule that is used to adjust the interconnection weights In this way the ne
work learns patterns or imitates rules of behavior and decision making
The partiCUlar ANS architecture we use is a variation of Rummelhart lJ multi-layer
perceptron employing the generalized delta rule GD R). Instead of a single multi-layer structure our final network has a a multiple component or block configuration where one blOt'k
output reeds into another Figure The training methodology we have developed is not
tied to a particular training rule or architecture and should work well with alternative networks
like Grossberg's adaptive resonance model[2J
American Institute of Physics
The equations describing the network are derived and described in detail by Rumelhart
In summary they are
Transfer function
Sj
WjiOi
i-O
Weight adaptation rule
Error calculation
a
OJ
a l'??Awp.revious
OJ E0.tW.ti
where OJ is the output or processing element or a sensor input is the interconnection weight
leading from element ito is the number of inputs to Aw is the adjustment of is the
training constant a is the training momentum OJ is the calculated error for element and
is the Canout oC a given element Element zero is a constant input equal to one so that WjO is
equivalent to the bias threshold of element The factor in equation differs from standard GDR formulation but it is useful for keeping track of the relative magnitudes of the two
terms For the network's output layer the summation in equation is replaced with the
difference between the desired and actual output value of element
These networks are usually trained by presenting the system with sets of input/output data
vectors in cyclic fashion the entire cycle of database presentation repeated dozens of times This
method is effective when the training agent is a computer operating in batch mode but would be
intolerable for a human instructor There are two developments that will help real-time human
training The first is a more efficient incorporation of data/response patterns into a network The
second which we are addressing in this paper is a suitable environment wherein a man and ANS
network can interact in training situation with minimum inconvenience or boredom on the
human's part The ability to systematically train networks in this fashion is extremely useful for
developing certain types of expert systems including automatic signal processors autopilots
robots and other autonomous machines We report a number of techniques aimed at facilitating
this type of training and we propose a general method for teaching these networks
System Development
Our work focuses on the utility of ANS for system control It began as an application of
Barto and Sutton's associative search network[3 Although their approach was useful in a
number of ways it fell short when we tried to use it for capturing the subtleties of human
decision-making In response we shifted our emphasis rrom constructing goal runctions for
automatic learning to methods for training networks using direct human instruction An integral
part or this is the development or suitable interraces between humans networks and the outside
world or simulator In this section we will report various approaches to these ends and describe a
general methodology for manually teaching ANS networks To demonstrate these techniques we
taught a network to drive a robot vehicle down a simulated highway in traffic This application
combines binary decision making and control of continuous parameters
Initially we investigated the use or automatic learning based on goal functions[3 for training control systems We trained a network-controlled vehicle to maintain acceptable following
distances from cars ahead or it On a graphics workstation a one lane circular track was
constructed and occupied by two vehicles a network-controlled robot car and a pace car that
varied its speed at random Input data to the network consisted of the separation distance and
the speed of the robot vehicle The values of a goal function were translated into desired output
for GDR training Output controls consisted of three binary decision elements accelerate one
increment of speed maintain speed and decelerate one increment of speed At all times
the desired output vector had exactly one of these three elements active The goal runction was
quadratic with a minimum corresponding to the optimal following distance Although it had no
direct control over the simulation the goal function positively or negatively reinforced the
system's behavior
The network was given complete control of the robot vehicle and the human trainer had
no influence except the ability to start and terminate training This proved unsatisractory because
the initial system behavior--governed by random interconnection weights--was very unstable The
robot tended to run over the car in rront of it before significant training occurred By carerully
halting and restarting training we achieved stable system behavior At first the rollowing distance
maintained by the robot car oscillated as ir the vehicle was attached by a sj)ring to the pace car
This activity gradually damped Arter about one thousand training steps the vehicle maintained
the optimal following distance and responded quickly to changes in the pace car's speed
Constructing composite goal functions to promote more sophisticated abilities proved
difficult even ill-defined because there were many unspecified parameters To generate goal
runctions ror these abilities would be similar to conventional programming--the type or labor we
want to circumvent using ANS. On the other hand humans are adept at assessing complex situations and making decisions based on qualitative data but their goal runctions are difficult ir not
impossible to capture analytically One attraction of ANS is that it can imitate behavior based on
these elusive rules without rormally specifying them At this point we turned our efforts to
manual training techniques
The initially trained network was grafted into a larger system and augmented with additional inputs distance and speed inrormation on nearby pace cars in a second traffic lane and an
output control signal governing lane changes The original network's ability to maintain a safe
following distance was retained intact Thts grafting procedure is one of two methods we studied
for adding ne abilities to an existin system The second which employs a block structure is
described below The network remained in direct control of the robot vehicle but a human
trainer instructed it when and when not to change lanes His commands were interpreted as the
desired output and used in the GDR training algorithm This technique which we call coaching
proved userul and the network quickly correlated its environmental inputs with the teacher's
instructions The network became adept at changing lanes and weaving through traffic We found
that the network took on the behavior pattern or its trainer A conservative teacher produced a
timid network while an aggressive tzainer produced a network that tended to cut off other automobiles and squeeze through tight openings Despite its success the coaching method of training
did not solve the problem or initial network instability
The stability problem was solved by giving the trainer direct control over the simulation
The system configuration Figure allows the expert to exert control or release it to the
work During initial tzaining the expert is in the driver's seat while the network acts the role of
apprentice It receives sensor information predicts system commands and compares its predictions against the desired output the trainer's commands Figure shows the data and command flow in detail Input data is processed through different channels and presented to the
trainer and network Where visual and audio formats are effective for humans the network uses
information in vector form This differentiation of data presentation is a limitation of the system
removing it is a cask for future search The trainer issues control commands in accordance with
his assigned while the network takes the trainer's actions as desired system responses and
correlates these with the input We refer to this procedure as master/apprentice training network
training proceeds invisibly in the background as the expert proceeds with his day to day work It
avoids the instability problem because the network is free to make errors without the adverse
consequence of throwing the operating environment into disarray
I
Input
World sensors
or
Simulation
Actuation
I
Ne',WOrk
I
Expert
Commands
Figure A scheme for manually training ANS networks Input data is received by both
the network and trainer The trainer issues commands that are actuated solid command
line or he coaches the network in how it ought to respond broken command line
Commands
Preprocessing
tortunan
Input
data
Preprocessing
for network
twork
Predicted
commands
Actuation
Coaching/emphasis
Training
rule
Fegure Data and convnand flow In the training system Input data is processed and presented
to the trainer and network In master/appre~ice training solid command Hne the trainer's
orders are actuated and the network treats his commands as the system's desired output In
coaching the network's predicted oonvnands are actuated broken command line and the
trainer influences weight adaptation by specifying the desired system output and controlHng
the values of trailing constants-his suggestions are not cirec:tty actuated
Once initial bacqround wainmg is complete the expert proceeds in a more formal
manner to teach the network He releases control of the command system to the network in
order to evaluate ita behavior and weaknesses He then resumes control and works through a
series of scenarios designed to train t.he network out of its bad behavior By switching back and
forth between human and network control the expert assesses the network's reliability and
teaches correct responses as needed We find master/apprentice training works well for behavior
involving continuous functions like steering On the other hand coaching is appropriate for decision Cunctions like when Ule car ought to pass Our methodology employs both techniques
The Driving Network
The fully developed freeway simulation consists of a two lane highway that is made of
joined straight and curved segments which vary at random in length and curvature Several
pace cars move at random speeds near the robot vehicle The network is given the tasks of tracking the road negotiating curves returning to the road if placed far afield maintaining safe distances from the pace cars and changing lanes when appropriate Instead of a single multi-layer
structure the network is composed of two blocks one controls the steering and the other regulates speed and decides when the vehicle should change lanes Figure The first block receives
information about the position and speed of the robot vehicle relative to other ears in its vicinity
Its output is used to determine the automobile's speed and whet.her the robot should change
lanes The passing signal is converted to a lane assignment based on the car's current lane position The second block receives the lane assignment and data pertinent to the position and orientation of the vehicle with respect to the road The output is used to determine the steering angle
of the robot car
Block
Inputs
Outputs
Constant
Speed
Disl Ahead Pl
Disl Ahead Ol
Dist Behind Ol
ReI. Speed Ahead Pl
ReI. Speed Ahead Ol
ReI. Speed Behind Ol
I
Speed
Change lanes
Steering Angle
Convert lane change to lane number
Constant
Rei. Orientation
lane Nurmer
lateral Dist
Curvature
Figure The two blocks of the driving ANS network Heavy arrows Indicate total interconnectivity
between layers PL designates the traffic lane presently oca.apied by the robot vehicle Ol refers
to the other lane QJrvature refers to the road lane nurrber is either or relative orientation and
lateral distance refers to the robot car's direction and podion relative to the road'l direction and
center line respectively
The input data is displayed in pictorial and textual form to the driving instructor He views
the road and nearby vehicles from the perspective of the driver's seat or overhead The network
receives information in the form of a vector whose elements have been scaled to unitary order
Wide ranging input parameters like distance are compressed using the hyperbolic tangent
or logarithmic functions In each block the input layer is totally interconnected to both the ou
put and a hidden layer Our scheme trains in real time and as we discuss later it trains more
smoothly with a small modification of the training algorithm
Output is interpreted in two ways as a binary decision or as a continuously varying parameter The first simply compares the sigmoid output against a threshold The second scales the
output to an appropriate range for its application For example on the steering output element a
value is interpreted as a zero steering angle Left and right turns of varying degrees are initiated when this output is above or below respectively
The network is divided into two blocks that can be trained separately Beside being conceptually easier to understand we find this component approach is easy to train systematically
Because each block has a restricted well-defined set of tasks the trainer can concentrate
specifically on those functions without being concerned that other aspects of the network behavior
are deteriorating
trained the system from bottom up first teaching the network to stay on the road
negotiate curves chan~e lanes and how to return if the vehicle strayed off the highway Block
responsible for steering learned these skills in a few minutes using the master/apprentice mode
It tended to steer more slowly than a human but further training progressively improved its
responsiveness
We experimented with different trammg constants and momentum values Large
values about caused weights to change too coarsely values an order of magnitude smaller
worked well We found DO advantage in using momentum for this method of training in fact
the system responded about three times more slowly when than when the momentt:m
term was dropped Our standard training parameters were and Cl
Figure Typical behavior of a network-controlled vehicle dam rectangle when trained by
a conservative miYer ItI:I reckless driver Speed Is indicated by the length of the arrows
After Block Was trained we gave steering control to the network and concentrated on
teaching the network to change lanes and adjust speed Speed control in this was a continuous variable and was best taught using master/apprentice training On the other hand the binary
decision to change lanes was best taught by coaching About ten minutes of training were needed
to teach the network to weave through traffic We found that the network readily adapts the
behavioral pattern of its trainer A conservative trainer generated a network that hardly ever
passed while an aggressive trainer produced a network that drove recklessly and tended to cut off
other-cars Figure
Discussion
One of the strengths of el:pert 5ystf'mS based on ANS is that the use of input data in the
decision making and control proc~ss does not have to be specified The network adapts its internal weights to conform to input output correlat.ions it discovers It is important however that
data used by the human expert is also available to the network The different processing of sensor data for man and network may have important consequences key information may be
presented to the man but not the machine
This difference in data processing is particularly worrisome for image data where human
ability to extract detail is vastly superior to our au tomatic image processing capabilities Though
we would not require an image processing system to understand images it would have to extract
relevant information from cluttered backgrounds Until we have sufficiently sophisticated algorithms or networks to do this our efforts at constructing expert systems which halldle image data
are handicapped
Scaling input data to the unitary order of magnitude is important for training stability
is evident from equations and The sigmoid transfer function ranges from to in
approximat.eiy four units that is over an domain If system response must change in reaction to a large swing of a given input parameter the weight associated with that input will
be trained toward an magnitude On the other hand if the same system responds to an
input whose range is its associated weight will also be The weight adjustment equation does not recognize differences in weight magnitude therefore relatively small weights will
undergo wild magnitude adjustments and converge weakly On the other hand if all input parameters are of the same magnitude their associated weights will reflect this and the training constant
can be adjusted for gentle weight convergence Because the output of hidden units are constrained between zero and one is a good target range for input parameters Both the hyperbolic tangent and logarithmic functions are useful for scaling wide ranging inputs A useful form
of the latter is
if
ifx<-o
where and defines the limits of the intermediate linear section and is a scaling factor
This symmetric logarithmic function is continuous in its first derivative and useful when network
behavior should change slowly as a parameter increases without bound On the othl'r hand if the
system should approach a limiting behavior the tanh function is appropriate
Weight adaptation is also complicated by relaxing the common practice of restricting interconnections to adjacent layers Equation shows that the calculated error for a hidden layergiven comparable weights fanouts and output errors-will be one quarter or less than that of the
output layer This is caused by the slope ractor oil The difference in error magnitudes is
not noticeable in networks restricted to adjacent layer interconnectivity But when this constraint
is released the effect of errors originating directly from an output unit has times the magnitude
and effect of an error originating from a hidden unit removed layers from the output layer
Compared to the corrections arising from the output units those from the hidden units have little
influence on weight adjustment and the power of a multilayer structure is weakened The system
will train if we restrict connections to adjacent layers but it trains slowly To compensate for this
effect we attenuate the error magnitudes originating from the output layer by the above factor
This heuristic procedure works well and racilitates smooth learning
Though we have made progress in real-time learning systems using GDR compared to
humans-who can learn from a single data presentation-they remain relatively sluggish in learning
and response rates We are interested in improvements of the GDR algorithm or alternative
architectures that facilitate one-shot or rapid learning In the latter case we are considering least
squares restoration techniquesl4 and Grossberg and Carpenter's adaptive resonance modelsI3,5
The construction of automated expert systems by observation of human personnel is
attractive because of its efficient use of the expert's time and effort Though the classic AI
approach of rule base inference is applicable when such rules are clear cut and well organized too
often a human expert can not put his decision making process in words or specify the values of
parameters that influence him The attraction or ANS based systems is that imitations of expert
behavior emerge as a natural consequence of their training

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 49-connecting-to-the-past.pdf

CONNECTING TO THE PAST
Bruce A. MacDonald Assistant Professor
Knowledge Sciences Laboratory Computer Science Department
The University of Calgary University Drive NW
Calgary Alberta T2N IN4
ABSTRACT
Recently there has been renewed interest in neural-like processing systems evidenced for example in the two volumes Parallel Distributed Processing edited by Rumelhart and McClelland
and discussed as parallel distributed systems connectionist models neural nets value passing
systems and multiple context systems Dissatisfaction with symbolic manipulation paradigms
for artificial intelligence seems partly responsible for this attention encouraged by the promise
of massively parallel systems implemented in hardware This paper relates simple neural-like
systems based on multiple context to some other well-known formalisms-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier sequence prediction results in a new light
INTRODUCTION
The revival of neural net research has been very strong exemplified recently by Rumelhart
and McClelland new journals and a number of meetings The nets are also described as
parallel distributed systems connectionist models value passing systems3 and multiple context
learning systems4 The symbolic manipulation paradigm for artificial intelligence does
not seem to have been as successful as some hoped and there seems at last to be real promise
of massively parallel systems implemented in hardware However in the flurry of new work it
is important to consolidate new ideas and place them solidly alongside established ones This
paper relates simple neural-like systems to some other well-known notions-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier results on the abilities of such networks in a new light
The general form of a connectionist system lO is simplified to a three layer net with binary
fixed weights in the hidden layer thereby avoiding many of the difficulties-and challengesof the recent work on neural nets The hidden unit weights are regularly patterned using a
template Sophisticated expensive learning algorithms are avoided and a simple method is
used for determining output unit weights In this way we gain some of the advantages of multilayered nets while retaining some of the simplicity of two layer net training methods Certainly
nothing is lost in computational power-as I will explain-and the limitations of two layer
nets are not carried over to the simplified three layer one Biological systems may similarly
avoid the need for learning algorithms such as the simulated annealing method commonly
used in connectionist models For one thing biological systems do not have the same clearly
distinguished training phase
Briefly the simplified net is a production system implemented as three layers of neuron-like
units an output layer an input layer and a hidden layer for the productions themselves Each
hidden production unit potentially connects a predetermined set of inputs to any output A
k-Iength sequence predictor is formed once Ie levels of delay unit are introduced into the input
layer k-Iength predictors are unable to distinguish simple sequences such as ba a and aa a
since after Ie or more characters the system has forgotten whether an a or appeared first If
the k-Iength predictor is augmented with auxiliary actions it is able to learn this and other
regular languages since the auxiliary actions can be equivalent to states and can be inputs to
aAmong them the 1st International Conference on Neural Nets San Diego,CA June and this
con.ference
bRoughly equivalent to a single context system in Andreae's multiple context system See also
MacDonald
@
American Institute of Physics
Figure The general form of a connectionist system
Form of a unit
Operations within a unit
in~uts excitation-.I
weIghts
sum
aCtiVation--W output
Typical
Typical
the production units enabling predictions to depend on previous states By combining several
augmented sequence predictors a Thring machine tape can be simulated along with a finite-state
controller giving the net the computational power of a Universal Turing machine Relatively
simple neural-like systems do not lack computational ability Previous implementations of
this ability are production system equivalents to the simplified nets
Organization of the paper
The next section briefly reviews the general form of connectionist systems Section simplifies
this then section explains that the result is equivalent to a production system dealing only
with inputs and outputs of the net Section extends the simplified version enabling it to learn
to predict sequences Section explains how the computational power of the sequence predictor
can be increased to that of a Thring machine if some input units receive auxiliary actions in fact
the system can learn to be a TUring machine Section discusses the possibility of a number of
nets combining their outputs forming an overall net with association areas
General form of a connectionist system
Figure shows the general form of a connectionist system unit neuron or ce1l In the figure
unit has inputs which are the outputs OJ of possibly all units in the network and an output of
its own The net input excitation net is the weighted sum of inputs where Vij is the weight
connecting the output from unit as an input to unit The activation of the unit is some
function Fi of the net input excitation Typically Fi is semilinear that is non-decreasing and
differentiable 13 and is the same function for all or at least large groups of units The output is
a function fi of the activation typically some kind of threshold function I will assume that the
quantities vary over discrete time steps so for example the activation at time is
and is given by Fi((neti(t
In general there is no restriction on the connections that may be made between units
Units not connected directly to inputs or outputs are hidden units In more complex nets
than those described in this paper there may be more than one type of connection Figure
shows a common connection topology where there are three layers of units-input hidden and
output-with no cycles of connection
The net is trained by presenting it with input combinations each along with the desired
output combination Once trained the system should produce the desired outputs given just
Figure The basic structure of a three layer connectionist system
input units
hidden
units
output units
inputs During training the weights are adjusted in some fashion that reduces the discrepancy
between desired and actual output The general method is lO
where is the desired training activation Equation is a general form of Hebb's classic
rule for adjusting the weight between two units with high activations lO The weight adjustment
is the product of two functions one that depends on the desired and actual activations--often
just the difference-and another that depends on the input to that weight and the weight itself
As a simple example suppose is the difference and as just the output OJ. Then the weight
change is the product of the output error and the input excitation to that weight
where the constant determines the learning rate This is the Widrow-Hoff or Delta rule which
may be used in nets without hidden units 1o
The important contribution of recent work on connectionist systems is how to implement
equation in hidden units for which there are no training signals ti directly available The
Boltzmann learning method iteratively varies both weights and hidden unit training activations
using the controlled gradually decreasing randomizing method simulated annealing Backpropagation 13 is also iterative performing gradient descent by propagating training signal errors
back through the net to hidden units I will avoid the need to determine training signals for
hidden units by fixing the weights of hidden units in section below
SIMPLIFIED SYSTEM
Assume these simplifications are made to the general connectionist system of section
The system has three layers with the topology shown in Figure ie no cycles
All hidden layer unit weights are fixed say at unity or zero
Each unit is a linear threshold unit lO which means the activation function for all units
is the identity function giving just net a weighted sum of the inputs and the output
function is a simple binary threshold of the form
I
output
threshold
activation
so that the output is binary on or oft Hidden units will have thresholds requiring all
inputs to be active for the output to be active like an AND gate while output units will
have thresholds requiring only or two active highly weighted inputs for an output to be
generated like an OR gate This is in keeping with the production system view of the
net explained in section
Learning-which now occurs only at the output unit weights-gives weight adjustments
according to
Wij
Wij
if
OJ
otherwise
so that weights are turned on if their input and the unit output are on and off otherwise
That is Wij A OJ. A simple example is given in Figure in section below
This simple form of net can be made probabilistic by replacing with below
Adjust weights so that Wij estimates the conditional probability of the unit output being
on when output is on That is
Wij
estimate of P(odoj
Then assuming independence of the inputs to a unit an output unit is turned on when the
conditional probability of occurrence of that output exceeds the threshold of the output
function
Once these simplifications are made there is no need for learning in the hidden units Also no
iterative learning is required weights are either assigned binary values or estimate conditional
probabilities This paper presents some of the characteristics of the simplified net Section
discusses the motivation for simplifying neural nets in this way
PRODUCTION SYSTEMS
The simplified net is a kind of simple production system A production system comprises a
global database a set of production rules and a control system The database for the net is
the system it interacts with providing inputs as reactions to outputs from t.he net The hidden
units of the network are the production rules which have the form
IF
precondition
THEN
action
The precondition is satisfied when the input excitation exceeds the threshold of a hidden unit
The actions are represented by the output units which the hidden production units activate
The control system of a production system chooses the rule whose action to perform from the
set of rules whose preconditions have been met In a neural net the control system is distributed
throughout the net in the output units For example the output units might form a winner-takeall net In production systems more complex control involves forward and backward chaining to
choose actions that seek goals This is discussed elsewhere4.12.16 Figure illust.rates a simple
production implemented as a neural net As the figure shows the inputs to hidden units are
just the elements of the precondition When the appropriate input combination is present the
associated hidden production unit is fired Once weights have been leamed connecting hidden
units to output units firing a production results in output The simplified neural net is directly
equivalent to a production system whose elements are inputs and outputs
Some production systems have symbolic elements such as variables which can be given
values by production actions The neural net cannot directly implement this since it can
have outputs only from a predetermined set However we will see later that extensions t.o the
framework enable this and other abilities
CThis might be referred to as a sensory-motor production system since when implemented ill a l'eal system
such as a robot it deals only with sensed inputs and executable motor actions which may include the auxiliary
actions of section
Figure A production implemented in a simplified neural net
A production rule
IF
Icloudy I Ipressure falling I
AND
THEN
Iit will rain I
The rule implemented as a hidden unit The threshold of the hidden unit is so it is
an AND gate The threshold of the output unit is so it is an OR gate The learned
weight will be or if the net is not probabilistic otherwise it will be an estimate of
P(it will rainlclouds AND pressure falling
It will
rain
weight
Figure A net that predicts the next character in a sequence based on only the last character
The net Production units hidden units have been combined with input units
For example this net could predict the sequence abcabcabc Productions have the
form IF last character is THEN next character will be The learning rule is
Wij
if inputj AND outputi Output is
WijOj
input
neural net
output
a
a
Learning procedure
Clamp inputs and outputs to desired values
System calculates weight values
Repeat and for all required input/output combinations
SEQUENCE PREDICTION
A production system or neural net can predict sequences Given examples of a repeating sequence productions are learned which predict future events on the basis of recent ones Figure
shows a trivially simple sequence predictor It predicts the next character of a sequence based
on the previous one The figure also gives the details of the learning procedure for the simplified
net The net need be trained only once on each input combination then it will predict as
an output every character seen after the current one The probabilistic form of the net would
estimate conditional probabilities for the next character conditional on the current one Many
Figure Using delayed inputs a neural net can implement a k-length sequence predictor
A net with the last three characters as input
input
hidden
output
a
a
a
2nd last
An example production
IF
last three characters were THEN
presentations of each possible character pair would be needed to properly estimate the probabilities The net would be learning the probability distribution of character pairs A predictor like
the one in Figure can be extended to a general k-Iength 17 predictor so long as inputs delayed
by steps are available Then as illustrated in Figure for 3-length prediction hidden
production units represent all possible combinations of symbols Again output weights are
trained to respond to previously seen input combinations here of three characters These delays
can be provided by dedicated neural nets such as that shown in Figure Note that the net
is assumed to be synchronously updated so that the input from feedback around units is not
changed until one step after the output changes There are various ways of implementing delay
in neurons and Andreae investigates some of them for the same purpose-delaying inputs-in
a more detailed simulation of a similar net
Other work on sequence prediction in neural nets
Feldman and Ballard find connectionist systems initially not suited to representing changes
with time One form of change is sequence and they suggest two methods for representing
sequence in nets The first is by units connected to each other in sequence so that sequential
tasks are represented by firing these units in succession The second method is to buffer the
inputs in time so that inputs from the recent past are available as well as current inputs that
is delayed inputs are available as suggested above An important difference is the necessary
length of the buffer Feldman and Ballard suggest the buffer be long enough to hold a phrase of
natural language but I expect to use buffers no longer than about after Andreae Symbolic
inputs can represent more complex information effectively giving the length seven buffers more
information than the most recent seven simple inputs as discussed in section
The method of back-propagation13 enables recurrent networks to learn sequential tasks in a
dFeldman and Ballard2 give some dedicated neural net connections for a variety of flUlctions
Figure Inputs can be delayed by dedicated neural subnets A two stage delay is shown
Delay network
Timing diagram for
tml
A
original signal
delay of one step
delay of two steps
manner similar to the first suggestion in the last paragraph where sequences of connected units
represent sequenced events In one example a net learns to complete a sequence of characters
when given the first two characters of a six character sequence the next four are output Errors
must be propagated around cycles in a recurrent net a number of times
Seriality may also be achieved by a sequence of states of distributed activation 18 An example
is a net playing both sides of a tic-tac-toe game 18 The sequential nature of the net's behavior is
derived from the sequential nature of the responses to the net's actions tic-tac-toe moves A net
can model sequence internally by modeling a sequential part of its environment For example
a tic-tac-toe playing net can have a model of its opponent
k-Iength sequence predictors are unable to learn sequences which do not repeat more frequently that every characters Their k-Iength context includes only information about the last
events However there are two ways in which information from before the kth last input can
be retained in the net The first method latches some inputs while the second involves auxiliary
actions
Latch units
Inputs can be latched and held indefinitely using the combination shown in Figure Not all
inputs would normally be latched Andreae discusses this technique of threading latched
events among non-latched events giving the net both information arbitrarily far back in its
input-output history and information from the immediate past Briefly the sequence ba a
can be distinguished from aa a if the first character is latched However this is an ad hoc
solution to this problem
Auxiliary actions
When an output is fed back into the net as an input signal this enables the system to choose the
next output at least partly based on the previous one as indicated in Figure If a particular
fed back output is also one without external manifestation or whose external manifestation
is independent of the task being performed then that output is an auxiliary action It Las
The interested reader should refer to Andreae where more extensive analysis is given
Figure Threading A latch circuit remembers an event until another comes along This is a
two input latch for two letters a and but any number of units may be similarly connected
It is formed from a mutual inhibition layer or winner-take-all connection along with positive
feedback to keep the selected output activated when the input disappears
a
Figure Auxiliary actions-the outputs-are fed back to the inputs of a net enabling the
net to remember a state Here both part of a net and an example of a production are shown
There are two types of action characters and actions
Sinputs
outputs
character inputs
IF
input is
and character input is
character outputs
THEN
output character
lliJ and ill
no direct effect on the task the system is performing since it evokes no relevant inputs and
so can be used by the net as a symbolic action If an auxiliary action is latched at the input
then the symbolic information can be remembered indefinitely being lost only when another
auxiliary action of that kind is input and takes over the latch Thus auxiliary actions can act
like remembered states the system performs an action to remind itself to be in a particular
state The figure illustrates this for a system that predicts characters and state changes given
the previous character and state An obvious candidate for auxiliary actions is speech So
the blank oval in the figure would represent the net's environment through which its own
speech actions are heard Although it is externally manifested speech has no direct effect on
our physical interactions with the world Its symbolic ability not only provides the power of
auxiliary actions but also includes other speakers in the interaction
SIMULATING ABSTRACT AUTOMATA
The example in Figure gives the essence of simulating a finite state automaton with a production system or its neural net equivalent It illustrates the transition function of an automaton
the new state and output are a function of the previous state and input Thus a neural net can
simulate a finite state automaton so long as it has additional auxiliary actions
A Thring machine is a finite state automaton controller plus an unbounded memory A
neural net could simulate a lUring machine in two ways and both ways have been demonstrated
with production system implementations-equivalent to neural nets----(;alled multiple context
learning systems briefly explained in section The first Thring machine simulation has the
system simulate only the finite state controller but is able to use an unbounded external memory
fSee John Andreae's and his colleagues work4
Figure Multiple context learning system implementation as multiple neural nets Each:3
layer net has the simplified form presented above with a number of elaborations such as extra
connections for goal-seeking by forward and backward chaining
Output
channels
from the real world much like the paper of Turing's original work 19 The second simnlat.ion
embeds the memory in the multiple context learning system along with a counter for accessing
this simulated memory Both learn all the productions-equivalent to learning output unit
weights-required for the simulations The second is able to add internal memory as required
up to a limit dependent on the size of the network which can easily be large enough to allow 70
years of computation The second could also employ external memory as the first did Briefly
the second simulation comprised multiple sequence predictors which predicted auxiliary actions
for remembering the state of the controller and the current memory position The memory
element is updated by relearning the production representing that element the precondition is
the address and the production action the stored item
MULTIPLE SYSTEMS FORM ASSOCIATION AREAS
A multiple context learning system is production system version of a multiple neural net although a simple version has been implemented as a simulated net It effectively comprises
several nets--or association areas-which may have outputs and inputs in common as indicated in Figure Hidden unit weights are specified by templates one for each net A template
gives the inputs to have a zero weight for the hidden units of a net and the inputs to have a
weight of unity Delayed and latched inputs are also available The actual outputs are selected
from the combined predictions of the nets in a winner-take-all fashion
I see the design for real neural nets say as controllers for real robots requiring a large
degree of predetermined connectivity A robot controller could not be one three layer net wit.h
every input connected to every hidden unit in turn connected to every output There will
need to be some connectivity constraints so the net reflects the functional specialization in the
control requirements The multiple context learning system has all the hidden layer connections
predetermined but allows output connections to be learned This avoids the credit assignment
problem and therefore also the need for learning algorithms such as Boltzmann learning and
back-propagation However as the multiple context learning system has auxiliary actions and
delayed and latched inputs it does not lack computational power Future work in this area
should investigate for example the ability of different kinds of nets to learn auxiliary act.ions
This may be difficult as symbolic actions may not be provided in training inputs and output.s
For
example a controller for a robot body would have to deal with vision manipulation motion etc
CONCLUSION
This paper has presented a sImplified three layer connectionist model with fixed weights for
hidden units delays and latches for inputs sequence prediction ability auxiliary state actions
and the ability to use internal and external memory The result is able to learn to simulate a
Turing machine Simple neural-like systems do not lack computational power
ACKNOWLEDGEMENTS
This work is supported by the Natural Sciences and Engineering Council of Canada

<<----------------------------------------------------------------------------------------------------------------------->>

title: 51-reflexive-associative-memories.pdf

REFLEXIVE ASSOCIATIVE MEMORIES
Hendrlcus G. Loos
Laguna Research Laboratory Fallbrook CA
ABSTRACT
In the synchronous discrete model the average memory capacity of
bidirectional associative memories BAMs is compared with that of
Hopfield memories by means of a calculat10n of the percentage of good
recall for random BAMs of dimension for different numbers
of stored vectors The memory capac1ty Is found to be much smal1er than
the Kosko upper bound which Is the lesser of the two dimensions of the
BAM. On the average a BAM has about 68 of the capacity of the
corresponding Hopfield memory with the same number of neurons Orthonormal coding of the BAM Increases the effective storage capaCity by
only The memory capacity limitations are due to spurious stable
states which arise In BAMs In much the same way as in Hopfleld
memories Occurrence of spurious stable states can be avoided by
replacing the thresholding in the backlayer of the BAM by another
nonl1near process here called Dominant Label Selection The
simplest DLS is the wlnner-take-all net which gives a fault-sensitive
memory Fault tolerance can be improved by the use of an orthogonal or
unitary transformation An optical application of the latter is a Fourier
transform which is implemented simply by a lens
INTRODUCT ION
A reflexive associative memory also called bidirectional associative memory is a two-layer neural net with bidirectional connections
between the layers This architecture is implied by Dana Anderson's
optical resonator and by similar configurations Bart KoSk0 coined
the name Bidirectional Associative Memory and Investigated
several basic propertles We are here concerned with the memory
capac1ty of the BAM with the relation between BAMs and Hopfleld
memories and with certain variations on the BAM.
American Institute of Physics
BAM STRUCTURE
We will use the discrete model In which the state of a layer of
neurons Is described by a bipolar vector The Dirac notationS will be
used In which I and I denote respectively column and row vectors al
and la are each other transposes alb Is a scalar product and la><bl is
an outer product As depicted in the BAM has two layers of
neurons a front layer of Nneurons tth state vector and a back layer
back layer neurons
back
of neurons with state vector
state vector
stroke
Ib>. The bidirectional connectlons between the layers allow
signal flow In two directions
frOnt1ay~r eurons forward
The front stroke gives
state vector
stroke
s(Blf where the connecFig BAM structure
tlon matrix and Is a threshold function operating at
zero The back stroke results 1n an u~graded front state
whIch also may be wr1tten as Ib where the superscr1pt
denotes transpos1t10n We consider the synchronous model where all
neurons of a layer are updated s1multaneously but the front and back
layers are UPdated at d1fferent t1mes The BAM act10n 1s shown 1n F1g.
The forward stroke entalls takIng scalar products between a front
state vector If and the rows or and enter1ng the thresholded results
as elements of the back state vector Ib>. In the back stroke we take
threshold ing
reflection
lID
NxP
FIg. BAM act
threshold ing
reflection
hreShOlding
4J
NxN
feedback
Ftg. Autoassoc1at1ve
memory act10n
scalar products of Ib w1th column vectors of and enter the
thresholded results as elements of an upgraded state vector In
contrast the act10n of an autoassoc1at1ve memory 1s shown 1n F1gure
The BAM may also be described as an autoassoc1at1ve memory5 by
concatenating the front and back vectors tnto a s1ngle state vector
Iv>=lf,b>,and by taking the connection matrtx as shown in F1g.
This autoassoclat1ve memory has the same number of neurons as our
BAM viz N+P. The BAM operat1on where
initially only the front state 1s specif thresholding
zero IDT
feedback
f1ed may be obtained with the corresponding autoassoc1ative memory by
lID zero
initially spectfying Ib as zero and by
BAM as autoassoarranging the threshold1ng operat1on
ctative memory
such that does not alter the state
vector component For a Hopfteld
memory7 the connection matrix 1s
mD MI
m=l
I
where to are stored vectors and I is the tdentity matr1x
Writing the N+P d1mens1onal vectors as concatenations Idm,c
takes the form
I
ldm><dml+lcm><cml+ldm><cml+lcm><dmD)-MI
m=l
w1th proper block plactng of submatr1ces understood Writing
Llcm><dml
m=l
Hd=(Lldm><dmD-MI
L'lcm><cml>-MI
m=l
m=l
where the I are identities in appropriate subspaces the Hopfield matrix
may be partitioned as shown in is just the BAM matrix given
by Kosko and previously used by Kohonen for linear heteroassoclatjve
memories Comparison of Figs and shows that in the synchronous
discrete model the BAM with connection matrix is equivalent to a
Hopfield memory in which the diagonal blocks Hd and Hc have been
deleted Since the Hopfleld memory is robust this prun1ng may not
affect much the associative recall of stored vectors if is small
however on the average pruning will not improve the memory capaclty
It follows that on the average a discrete synchronous BAM with matrix
can at best have the capacity of a Hopfleld memory with the same
number of neurons
We have performed computations of the average memory capacity
for BAMs and for corresponding Hopfleld memories
Monte Carlo calculations were done for memories each of which
stores random bipolar vectors The straight recall of all these vectors
was checked al10wtng for 24 Iterations For the BAMs the iterations
were started with a forward stroke in which one of the stored vectors
Idm was used as input The percentage of good recall and its standard
deviation were calculated The results plotted in show that the
square BAM has about of the capacity of the corresponding Hopfleld
memory Although the total number of neurons is the same the BAM only
needs of the number of connections of the Hopfield memory The
storage capacity found Is much smaller than the Kosko upper bound
which Is min
Partitioned
Hopfield matrix
M. number of stored vectors
of good recall versus
CODED BAM
So far we have considered both front and back states to be used for
data There is another use of the BAM in which only front states are used
as data and the back states are seen as providing a code label or
pOinter for the front state Such use was antiCipated in our expression
for the BAM matrix which stores data vectors Idm and their labels or
codes lem For a square BAM. such an arrangement cuts the Information
contained in a single stored data vector jn half However the freedom of
choosing the labels fC may perhaps be put to good use Part of the
problem of spurious stable states which plagues BAMs as well as
Hopf1eld memories as they are loaded up is due to the lack of
orthogonality of the stored vectors In the coded BAM we have the
opportunity to remove part of this problem by choosing the labels as
orthonorma1 Such labels have been used previously by Kohonen 1n linear
heteroassociative memories The question whether memory capacity can
be Improved In this manner was explored by taking BAt1s In which
the labels are chosen as Hadamard vectors The latter are bipolar vectors
with Euclidean norm which form an orthonormal set These vectors
are rows of a PxP Hadamard matrix for a discussion see Harwtt and
Sloane The storage capacity of such Hadamard-coded BAMs was
calculated as function of the number of stored vectors for cases
for each value of in the manner discussed before The percentage of
good recall and its standard deviation are shown 1n It Is seen that
the Hadamard coding gives about a factor in compared to the
ordinary BAM. However the coded BAM has only half the stored
data vector dimension Accounting for this factor reduction of data
vector dimension the effective storage capacity advantage obtained by
Hadamard coding comes to only
HALF BAt1 WITH HADAMARD CODING
For the coded BAM there is the option of deleting the threshold
operation In the front layer The resulting architecture may be called
half In the half BAM thresholding Is only done on the labels and
consequently the data may be taken as analog vectors Although such an
arrangement diminishes the robustness of the memory somewhat there
are applications of interest We have calculated the percentage of good
recall for cases and found that giving up the data thresholding cuts
the storage capacity of the Hadamard-coded BAt1 by about
SELECTIVE REFLEXIVE MEMORY
The memory capacity limitations shown in are due to the
occurence of spurious states when the memories are loaded up
Consider a discrete BAM with stored data vectors to
orthonormal labels Icm and the connection matrix
For an input data vector Iv which is closest to the stored data vector
one has 1n the forward stroke
Ib>=s(clc
amlcm
where
llv
and
am=<mlv
Although for am<c for some vector component the sum
amlc
may accumulate to such a large value as to affect the thresholded result
Ib>. The problem would be avoided jf the thresholding operation in the
back layer of the BAM were to be replaced by another nonl1near operation
which selects from the I inear combination
clc
amlcm
the dominant label Ic The hypothetical device which performs this
operation is here called the Dominant Label Selector DLS and we
call the resulting memory architecture Selective Reflexive Memory
With the back state selected as the dominant label Ic the back
stroke gives by the orthogonal ity of the labels
Icm It follows that the SRM g1ves perfect assoc1attve recall of the
nearest stored data vector for any number of vectors stored Of course
the llnear independence of the P-dimensionallabel vectors Icm to
requires
The DLS must select from a linear combination of orthonormal
labels the dominant label A trivial case is obtained by choosing the
labels Icm>as basis vectors Ium which have all components zero except
for the mth component which 1s unity With this choice of labels the
DLS may be taken as a winnertake-all net as shown in
winner
This case appears to be Included in
take-all
net
Adapt Ive Resonance Theory
ART as a special sjmpllf1ed
case A relationship between
Simplest reflexive
the ordinary BAM and ART was
memory with DLS
pOinted out by KoskoS As in ART
there Is cons1derable fault sensitivity tn this memory because the
stored data vectors appear in the connectton matrix as rows
A memory with better fault tolerance may be obtained by using
orthogonal labels other than basis vectors The DLS can then be taken as
an orthogonal transformation followed by a winner-take-an net as
shown 1n is to be chosen such that 1t transforms the labels Icm
rthogonal
I
transformation
winner take-all
net
F1g. Select1ve reflex1ve
memory
tnto vectors proportional to the
basts vectors This can always
be done by tak1ng
G=[Iup><cpl
p=l
where the Icp to form a
complete orthonormal set which
contains the labels Icm m=l to M. The neurons in the DLS serve as
grandmother cells Once a single winning cell has been activated
the state of the layer Is a single basis vector say lu I this vector
must be passed back after appllcation of the transformation such
as to produce the label at the back of the BAM. Since 1s
orthogonal we have so that the reQu1red 1nverse
transformation may be accompl1shed sfmply by sending the bas1s vector
back through the transformer this gives
1IUp><cpl=<c
p=l
as required
HAlF SRM
The SRM may be modified by deleting the thresholding operation in
the front layer The front neurons then have a I inear output which is
reflected back through the SRM as shown in In this case the
stored data vectors and the
input data vectors may be taken
I near neurons
orthogonal
as analog vectors but we
transfor.1
Qu1re all the stored vectors to
mation
have the same norm The act on
winnerof the SRM proceeds in the same
I take-all
net
way as described above except
that we now require the orthoFig Half SRM with l1near
normal labels to have unit
norm It follows that just l1ke
neurons in front layer
the full SRM the half SRM gives
perfect associative recall to the nearest stored vector for any number
of stored vectors up to the dimension of the labels The latter
condition 1s due to the fact that a P-dimensional vector space can at
most conta1n orthonormal vectors
In the SRM the output transform Gis 1ntroduced in order to improve
the fauJt tolerance of the connection matrix K. This is accomplished at
the cost of some fault sensitivity of the extent of which needs to be
investigated In this regard 1t is noted that in certatn optical implementat ions of reflexive memories such as Dana Anderson's resonator I and
Similar conflgurations the transformation is a Fourier transform
which is implemented simply as a lens Such an implementation ts quite
insentive to the common semiconductor damage mechanisms
EQUIVALENT AUTOASSOCIATIVE MEMORIES
Concatenation of the front and back state vectors allows description of the SRMs tn terms of autoassociative memories For the SRM
which uses basis vectors as labels the corresponding autoassociative
memory js shown tn Fjg. This connect jon matrtx structure was also
proposed by Guest 13 The wtnner-take-all net needs to be
given t1me to settle on a basis
vector state before the state Ib
slow thres
holding
can influence the front state If>.
feedback
This may perhaps be achieved by
zero I[T
arranging the network to have a
ast thres thresholding and feedback which
WI bl olding
feedback
are fast compared with that of the
network An alternate method
Equivalent automay be to equip the network
associat lve memory
w1th an output gate which is
opened only after the net has
sett led These arrangements
present a compUcatlon and cause a delay which in some appllcations
may be 1nappropriate and In others may be acceptable in a trade
between speed and memory density
For the SRM wtth output transformer and orthonormal1abels other
than basis vectors a corresponf eedback
ding autoassoclat1ve memory may
be composed as shown In Fig.l1
thresholded
OJ OJ
An output gate in the layer is
linear
OJ
GT
I
chosen as the device which
thresholded
WI
prevents the backstroke through
output gate
the BAM to take place before the
w1nner-take-al net has settled
Autoassoc1at1ve memory
equivalent to SRM with transform
The same effect may perhaps be
achieved by choosing different
response times for the neuron
output gate
layers and These matters
wr winner-take-all
require investigation Unless
Woutput
the output transform 1s already
t@
back layer
required for other reasons as in
linear
some optical resonators the DLS
front layer
BAM connections
with output transform is clumsy
@ orthogonal transformat on
I would far better to combine
winner-take-all net
the transformer and the net
into a single network To find
Structure of SRM
such a DLS should be considered
a cha enge
The wort was partly supported by the Defense Advanced Research
projects Agency ARPA order through Contract DAAHOI-86-C
with the U.S. Army Missile Command

<<----------------------------------------------------------------------------------------------------------------------->>

title: 55-mathematical-analysis-of-learning-behavior-of-neuronal-models.pdf

MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
By
JOHN Y. CHEUNG
MASSOUD OMIDVAR
SCHOOL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCE
UNIVERSITY OF OKLAHOMA
NORMAN OK
Presented to the IEEE Conference on Neural Information Processing SystemsNatural and Synthetic Denver November and to be published in
the Collection of Papers from the IEEE Conference on NIPS
Please address all further correspondence to
John Y. Cheung
School of EECS
W. Boyd CEC
Norman OK
November
American Institute of Physics
MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
John Y. Cheung and Massoud Omidvar
School of Electrical Engineering
and Computer Science
ABSTRACT
In this paper we wish to analyze the convergence behavior of a number
of neuronal plasticity models Recent neurophysiological research suggests that
the neuronal behavior is adaptive In particular memory stored within a neuron
is associated with the synaptic weights which are varied or adjusted to achieve
learning A number of adaptive neuronal models have been proposed in the
literature Three specific models will be analyzed in this paper specifically the
Hebb model the Sutton-Barto model and the most recent trace model In this
paper we will examine the conditions for convergence the position of convergence and the rate at convergence of these models as they applied to classical
conditioning Simulation results are also presented to verify the analysis
INTRODUCTION
A number of static models to describe the behavior of a neuron have been
in use in the past decades More recently research in neurophysiology suggests
that a static view may be insufficient Rather the parameters within a neuron
tend to vary with past history to achieve learning It was suggested that by
altering the internal parameters neurons may adapt themselves to repetitive
input stimuli and become conditioned Learning thus occurs when the neurons
are conditioned To describe this behavior of neuronal plasticity a number
of models have been proposed The earliest one may have been postulated
by Hebb and more recently by Sutton and Barto We will also introduce a
new model the most recent trace MRT model in this paper The primary
objective of this paper however is to analyze the convergence behavior of these
models during adaptation
The general neuronal model used in this paper is shown in Figure There
are a number of neuronal inputs N. Each input is scaled by
the corresponding synaptic weights N. The weighted inputs
are arithmetically summed
where is taken to be zero
Neuronal inputs are assumed to take on numerical values ranging from zero
to one inclusively Synaptic weights are allowed to take on any reasonable values
for the purpose of this paper though in reality the weights may very well be
bounded Since the relative magnitude of the weights and the neuronal inputs
are not well defined at this point we will not put a bound on the magnitude
of the weights also The neuronal output is normally the result of a sigmoidal
transformation For simplicity we will approximate this operation by a linear
transformation
Sigmodial
Transfonution
neuronal
output
rilure
A leneral aeuronal adel
For convergence analysis we will assume that there are only two neuronal
inputs in the traditional classical conditioning environment for simplicity Of
course the analysis techniques can be extended to any number of inputs In
classical conditioning the two inputs are the conditioned stimulus Xc and
the unconditioned stimulus
THE SUTTON-BARTO MODEL
More recently Sutton and Barto have proposed an adaptive model based
on both the signal trace and the output trace as given below
y(t
Xi(t axi(t Xi(t
where both a and are positive constants
Condition of Convergence
In order to simplify the analysis we will choose
and
and
y(t
In other words becomes
Wi(t
Wi(t CXi(t)(y(t y(t
The above assumption only serves to simplify the analysis and will not affect the
convergence conditions because the boundedness of and only depends
on that for Xi(t and y(t respectively
As in the previous section we recognize that is a recurrence relation so
convergence can be checked by the ratio test It is also possible to rewrite
in matrix format Due to the recursion of the neuronal output in the equation
we will include the neuronal output in the parameter vector also
or
To show convergence we need to set the magnitude of the determinant of
A to be less than unity
Hence the condition for convergence is
From we can see that the adaptation constant must be chosen to be less
than the reciprocal of the Euclidean sum of energies of all the inputs The
same techniques can be extended to any number of inputs This can be proved
merely by following the same procedures outlined above
Position At Convergence
Having proved convergence of the Sutton-Barto model equations of neuronal plasticity we want to find out next at what location the system remains
when converged We have seen earlier that at convergence the weights cease to
change and so does the neuronal output We will denote this converged position
as In other words
Since any arbitrary parameter vector can always be decomposed into a weighted
sum of the eigenvectors
The constants Ql and Q3 can easily be found by inverting The
eigenvalues of can be shown to be and When is
within the region of convergence the magnitude of the third eigenvalue is less
than unity That means that at convergence there will be no contribution from
the third eigenvector Hence
From we can predict precisely what the converged position would be given
only with the initial conditions
Rate of Convergence
We have seen that when is carefully chosen the Sutton-Barto model will
converge and we have also derived an expression for the converged position
Next we want to find out how fast convergence can be attained The rate
of convergence is a measure of how fast the initial parameter approaches the
optimal position The asymptotic rate of convergence is
where SeA is the spectral radius and is equalled to in this
case This completes the convergence analysis on the Sutton-Barto model of
neuronal plasticity
THE MRT MODEL OF NEURONAL PLASTICITY
The most recent trace MRT model of neuronal plasticity developed by
the authors can be considered as a cross between the Sutton-Barto model and
the Klopf's model The adaptation of the synaptic weights can he expressed
as follows
A comparison of and the Sutton-Barto model in ahOWl that the cond
term on the right hand aide contains an extra factor which iI used to
apeed up the convergence as ahoWD later The output trace hu been replaced
by If(t the most recent output hence the name the most recent trace
model The input trace is also replaced by the most recent input
Condition of Convergence
We can now proceed to analyze the condition of convergence for the MRT
model Due to the presence of the Wi(t factor in the second term in the
ratio test cannot be applied here To analyze the convergence behavior further
let us rewrite in matrix format
WI(t
y(t
or
The superscript denotes the matrix transpose operation The above equation
is quadratic in Complete convergence analysis of this equation is
extremely difficult
In order to understand the convergence behavior of we note that
the dominant term that determines convergence mainly relates to the second
quadratic term Hence for convergence analysis only we will ignore the first
term
We can readily see from above that the primary convergence factor is BT
Since is only dependent on convergence can be obtained if the duration
of the synaptic inputs being active is bounded It can be shown that the
condition of convergence is bounded by
We can readily see that the adaptation constant can be chosen according
to to ensure convergence for T.
SIMULATIONS
To verify the theoretical analysis of these three adaptive neuronal models
based on classical conditioning these models have been simulated on the mM
mainframe using the FORTRAN language in single precision Several test
scenarios have been designed to compare the analytical predictions with actual
simulation results
To verify the conditions for convergence we will vary the value of the
adaptation constant The conditioned and unconditioned stimuli were set
to unity and the value of varies between to For the Sutton-Barto
model the simulation given in shows that convergence is obtained for
as expected from theoretical analysis For the MRT model simulation
results given in shows that convergence is obtained for also as
expected from theoretical analysis The theoretical location at convergence for
the Sutton and Barto model is also shown in Figure It is readily seen that
the simulation results confirm the theoretical expectations
I
Output
Figure lou or MuroD&l tpuu YeT.US Ule er of for the
Suttoa-Barto el witb 1frerent alues of aptat1on CODstant
lleuroul
Output
I
I
I
a
Ju.ber of iteratiOGa
Figure Plotl of oeuroaal outputl craus the uuaber of iteratious
for the MaT el with different alues of adantatlon
I:DDStaut
To illustrate the rate of convergence we will plot the trajectory of the
deviation in synaptic weights from the optimal values in the logarithmic scale
since this error is logarithmic as found earlier The slope of the line yields the
rate of convergence The trajectory for the Sutton-Barto Model is given in
Figure while that for the MRT model is given in Figure It is clear from
Figure that the trajectory in the logarithmic form is a straight line The
slope can readily be calculated The curve for the MRT model
given in Figure is also a straight line but with a much larger slope showing
faster convergence
SUMMARY
In this paper we have sought to discover analytically the convergence
behavior of three adaptive neuronal models From the analysis we see that
the Hebb model does not converge at all With constant active inputs the
output will grow exponentially In spite of this lack of convergence the Hebb
model is still a workable model realizing that the divergent behavior would
be curtailed by the sigmoidal transformation to yield realistic outputs The
I
uroul
Output
Dniatiotl
Lto
I
I
u.ber of iterationa
Figure
Trajectories of Deuronal output deviationa froa atatic alues
for the Sutton-"rt el with lfferent value adaptation
cOIIstallt C.
lleuroD&l
Output
Deviation
Ltl
I
Nuaber of iterations
Figure
Trajectories of neuronal output deviations fra atatic
values for tbe KRT el witb different values of
adaptation constant
analysis on the Sutton and Barto model shows that this model will converge
when the adaptation constant is carefully chosen The bounds for is also
found for this model Due to the structure of this model both the location at
convergence and the rate of convergence are also found We have also introduced
a new model of neuronal plasticity called the most recent trace MRT model
Certain similarities exist between the MRT model and the Sutton-Barto model
and also between the MRT model and the Klopf model Analysis shows that the
update equations for the synaptic weights are quadratic resulting in polynomial
rate of convergence Simulation results also show that much faster convergence
rate can be obtained with the MRT model

<<----------------------------------------------------------------------------------------------------------------------->>

title: 55-mathematical-analysis-of-learning-behavior-of-neuronal-models.pdf

MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
By
JOHN Y. CHEUNG
MASSOUD OMIDVAR
SCHOOL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCE
UNIVERSITY OF OKLAHOMA
NORMAN OK
Presented to the IEEE Conference on Neural Information Processing SystemsNatural and Synthetic Denver November and to be published in
the Collection of Papers from the IEEE Conference on NIPS
Please address all further correspondence to
John Y. Cheung
School of EECS
W. Boyd CEC
Norman OK
November
American Institute of Physics
MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
John Y. Cheung and Massoud Omidvar
School of Electrical Engineering
and Computer Science
ABSTRACT
In this paper we wish to analyze the convergence behavior of a number
of neuronal plasticity models Recent neurophysiological research suggests that
the neuronal behavior is adaptive In particular memory stored within a neuron
is associated with the synaptic weights which are varied or adjusted to achieve
learning A number of adaptive neuronal models have been proposed in the
literature Three specific models will be analyzed in this paper specifically the
Hebb model the Sutton-Barto model and the most recent trace model In this
paper we will examine the conditions for convergence the position of convergence and the rate at convergence of these models as they applied to classical
conditioning Simulation results are also presented to verify the analysis
INTRODUCTION
A number of static models to describe the behavior of a neuron have been
in use in the past decades More recently research in neurophysiology suggests
that a static view may be insufficient Rather the parameters within a neuron
tend to vary with past history to achieve learning It was suggested that by
altering the internal parameters neurons may adapt themselves to repetitive
input stimuli and become conditioned Learning thus occurs when the neurons
are conditioned To describe this behavior of neuronal plasticity a number
of models have been proposed The earliest one may have been postulated
by Hebb and more recently by Sutton and Barto We will also introduce a
new model the most recent trace MRT model in this paper The primary
objective of this paper however is to analyze the convergence behavior of these
models during adaptation
The general neuronal model used in this paper is shown in Figure There
are a number of neuronal inputs N. Each input is scaled by
the corresponding synaptic weights N. The weighted inputs
are arithmetically summed
where is taken to be zero
Neuronal inputs are assumed to take on numerical values ranging from zero
to one inclusively Synaptic weights are allowed to take on any reasonable values
for the purpose of this paper though in reality the weights may very well be
bounded Since the relative magnitude of the weights and the neuronal inputs
are not well defined at this point we will not put a bound on the magnitude
of the weights also The neuronal output is normally the result of a sigmoidal
transformation For simplicity we will approximate this operation by a linear
transformation
Sigmodial
Transfonution
neuronal
output
rilure
A leneral aeuronal adel
For convergence analysis we will assume that there are only two neuronal
inputs in the traditional classical conditioning environment for simplicity Of
course the analysis techniques can be extended to any number of inputs In
classical conditioning the two inputs are the conditioned stimulus Xc and
the unconditioned stimulus
THE SUTTON-BARTO MODEL
More recently Sutton and Barto have proposed an adaptive model based
on both the signal trace and the output trace as given below
y(t
Xi(t axi(t Xi(t
where both a and are positive constants
Condition of Convergence
In order to simplify the analysis we will choose
and
and
y(t
In other words becomes
Wi(t
Wi(t CXi(t)(y(t y(t
The above assumption only serves to simplify the analysis and will not affect the
convergence conditions because the boundedness of and only depends
on that for Xi(t and y(t respectively
As in the previous section we recognize that is a recurrence relation so
convergence can be checked by the ratio test It is also possible to rewrite
in matrix format Due to the recursion of the neuronal output in the equation
we will include the neuronal output in the parameter vector also
or
To show convergence we need to set the magnitude of the determinant of
A to be less than unity
Hence the condition for convergence is
From we can see that the adaptation constant must be chosen to be less
than the reciprocal of the Euclidean sum of energies of all the inputs The
same techniques can be extended to any number of inputs This can be proved
merely by following the same procedures outlined above
Position At Convergence
Having proved convergence of the Sutton-Barto model equations of neuronal plasticity we want to find out next at what location the system remains
when converged We have seen earlier that at convergence the weights cease to
change and so does the neuronal output We will denote this converged position
as In other words
Since any arbitrary parameter vector can always be decomposed into a weighted
sum of the eigenvectors
The constants Ql and Q3 can easily be found by inverting The
eigenvalues of can be shown to be and When is
within the region of convergence the magnitude of the third eigenvalue is less
than unity That means that at convergence there will be no contribution from
the third eigenvector Hence
From we can predict precisely what the converged position would be given
only with the initial conditions
Rate of Convergence
We have seen that when is carefully chosen the Sutton-Barto model will
converge and we have also derived an expression for the converged position
Next we want to find out how fast convergence can be attained The rate
of convergence is a measure of how fast the initial parameter approaches the
optimal position The asymptotic rate of convergence is
where SeA is the spectral radius and is equalled to in this
case This completes the convergence analysis on the Sutton-Barto model of
neuronal plasticity
THE MRT MODEL OF NEURONAL PLASTICITY
The most recent trace MRT model of neuronal plasticity developed by
the authors can be considered as a cross between the Sutton-Barto model and
the Klopf's model The adaptation of the synaptic weights can he expressed
as follows
A comparison of and the Sutton-Barto model in ahOWl that the cond
term on the right hand aide contains an extra factor which iI used to
apeed up the convergence as ahoWD later The output trace hu been replaced
by If(t the most recent output hence the name the most recent trace
model The input trace is also replaced by the most recent input
Condition of Convergence
We can now proceed to analyze the condition of convergence for the MRT
model Due to the presence of the Wi(t factor in the second term in the
ratio test cannot be applied here To analyze the convergence behavior further
let us rewrite in matrix format
WI(t
y(t
or
The superscript denotes the matrix transpose operation The above equation
is quadratic in Complete convergence analysis of this equation is
extremely difficult
In order to understand the convergence behavior of we note that
the dominant term that determines convergence mainly relates to the second
quadratic term Hence for convergence analysis only we will ignore the first
term
We can readily see from above that the primary convergence factor is BT
Since is only dependent on convergence can be obtained if the duration
of the synaptic inputs being active is bounded It can be shown that the
condition of convergence is bounded by
We can readily see that the adaptation constant can be chosen according
to to ensure convergence for T.
SIMULATIONS
To verify the theoretical analysis of these three adaptive neuronal models
based on classical conditioning these models have been simulated on the mM
mainframe using the FORTRAN language in single precision Several test
scenarios have been designed to compare the analytical predictions with actual
simulation results
To verify the conditions for convergence we will vary the value of the
adaptation constant The conditioned and unconditioned stimuli were set
to unity and the value of varies between to For the Sutton-Barto
model the simulation given in shows that convergence is obtained for
as expected from theoretical analysis For the MRT model simulation
results given in shows that convergence is obtained for also as
expected from theoretical analysis The theoretical location at convergence for
the Sutton and Barto model is also shown in Figure It is readily seen that
the simulation results confirm the theoretical expectations
I
Output
Figure lou or MuroD&l tpuu YeT.US Ule er of for the
Suttoa-Barto el witb 1frerent alues of aptat1on CODstant
lleuroul
Output
I
I
I
a
Ju.ber of iteratiOGa
Figure Plotl of oeuroaal outputl craus the uuaber of iteratious
for the MaT el with different alues of adantatlon
I:DDStaut
To illustrate the rate of convergence we will plot the trajectory of the
deviation in synaptic weights from the optimal values in the logarithmic scale
since this error is logarithmic as found earlier The slope of the line yields the
rate of convergence The trajectory for the Sutton-Barto Model is given in
Figure while that for the MRT model is given in Figure It is clear from
Figure that the trajectory in the logarithmic form is a straight line The
slope can readily be calculated The curve for the MRT model
given in Figure is also a straight line but with a much larger slope showing
faster convergence
SUMMARY
In this paper we have sought to discover analytically the convergence
behavior of three adaptive neuronal models From the analysis we see that
the Hebb model does not converge at all With constant active inputs the
output will grow exponentially In spite of this lack of convergence the Hebb
model is still a workable model realizing that the divergent behavior would
be curtailed by the sigmoidal transformation to yield realistic outputs The
I
uroul
Output
Dniatiotl
Lto
I
I
u.ber of iterationa
Figure
Trajectories of Deuronal output deviationa froa atatic alues
for the Sutton-"rt el with lfferent value adaptation
cOIIstallt C.
lleuroD&l
Output
Deviation
Ltl
I
Nuaber of iterations
Figure
Trajectories of neuronal output deviations fra atatic
values for tbe KRT el witb different values of
adaptation constant
analysis on the Sutton and Barto model shows that this model will converge
when the adaptation constant is carefully chosen The bounds for is also
found for this model Due to the structure of this model both the location at
convergence and the rate of convergence are also found We have also introduced
a new model of neuronal plasticity called the most recent trace MRT model
Certain similarities exist between the MRT model and the Sutton-Barto model
and also between the MRT model and the Klopf model Analysis shows that the
update equations for the synaptic weights are quadratic resulting in polynomial
rate of convergence Simulation results also show that much faster convergence
rate can be obtained with the MRT model

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 51-reflexive-associative-memories.pdf

REFLEXIVE ASSOCIATIVE MEMORIES
Hendrlcus G. Loos
Laguna Research Laboratory Fallbrook CA
ABSTRACT
In the synchronous discrete model the average memory capacity of
bidirectional associative memories BAMs is compared with that of
Hopfield memories by means of a calculat10n of the percentage of good
recall for random BAMs of dimension for different numbers
of stored vectors The memory capac1ty Is found to be much smal1er than
the Kosko upper bound which Is the lesser of the two dimensions of the
BAM. On the average a BAM has about 68 of the capacity of the
corresponding Hopfield memory with the same number of neurons Orthonormal coding of the BAM Increases the effective storage capaCity by
only The memory capacity limitations are due to spurious stable
states which arise In BAMs In much the same way as in Hopfleld
memories Occurrence of spurious stable states can be avoided by
replacing the thresholding in the backlayer of the BAM by another
nonl1near process here called Dominant Label Selection The
simplest DLS is the wlnner-take-all net which gives a fault-sensitive
memory Fault tolerance can be improved by the use of an orthogonal or
unitary transformation An optical application of the latter is a Fourier
transform which is implemented simply by a lens
INTRODUCT ION
A reflexive associative memory also called bidirectional associative memory is a two-layer neural net with bidirectional connections
between the layers This architecture is implied by Dana Anderson's
optical resonator and by similar configurations Bart KoSk0 coined
the name Bidirectional Associative Memory and Investigated
several basic propertles We are here concerned with the memory
capac1ty of the BAM with the relation between BAMs and Hopfleld
memories and with certain variations on the BAM.
American Institute of Physics
BAM STRUCTURE
We will use the discrete model In which the state of a layer of
neurons Is described by a bipolar vector The Dirac notationS will be
used In which I and I denote respectively column and row vectors al
and la are each other transposes alb Is a scalar product and la><bl is
an outer product As depicted in the BAM has two layers of
neurons a front layer of Nneurons tth state vector and a back layer
back layer neurons
back
of neurons with state vector
state vector
stroke
Ib>. The bidirectional connectlons between the layers allow
signal flow In two directions
frOnt1ay~r eurons forward
The front stroke gives
state vector
stroke
s(Blf where the connecFig BAM structure
tlon matrix and Is a threshold function operating at
zero The back stroke results 1n an u~graded front state
whIch also may be wr1tten as Ib where the superscr1pt
denotes transpos1t10n We consider the synchronous model where all
neurons of a layer are updated s1multaneously but the front and back
layers are UPdated at d1fferent t1mes The BAM act10n 1s shown 1n F1g.
The forward stroke entalls takIng scalar products between a front
state vector If and the rows or and enter1ng the thresholded results
as elements of the back state vector Ib>. In the back stroke we take
threshold ing
reflection
lID
NxP
FIg. BAM act
threshold ing
reflection
hreShOlding
4J
NxN
feedback
Ftg. Autoassoc1at1ve
memory act10n
scalar products of Ib w1th column vectors of and enter the
thresholded results as elements of an upgraded state vector In
contrast the act10n of an autoassoc1at1ve memory 1s shown 1n F1gure
The BAM may also be described as an autoassoc1at1ve memory5 by
concatenating the front and back vectors tnto a s1ngle state vector
Iv>=lf,b>,and by taking the connection matrtx as shown in F1g.
This autoassoclat1ve memory has the same number of neurons as our
BAM viz N+P. The BAM operat1on where
initially only the front state 1s specif thresholding
zero IDT
feedback
f1ed may be obtained with the corresponding autoassoc1ative memory by
lID zero
initially spectfying Ib as zero and by
BAM as autoassoarranging the threshold1ng operat1on
ctative memory
such that does not alter the state
vector component For a Hopfteld
memory7 the connection matrix 1s
mD MI
m=l
I
where to are stored vectors and I is the tdentity matr1x
Writing the N+P d1mens1onal vectors as concatenations Idm,c
takes the form
I
ldm><dml+lcm><cml+ldm><cml+lcm><dmD)-MI
m=l
w1th proper block plactng of submatr1ces understood Writing
Llcm><dml
m=l
Hd=(Lldm><dmD-MI
L'lcm><cml>-MI
m=l
m=l
where the I are identities in appropriate subspaces the Hopfield matrix
may be partitioned as shown in is just the BAM matrix given
by Kosko and previously used by Kohonen for linear heteroassoclatjve
memories Comparison of Figs and shows that in the synchronous
discrete model the BAM with connection matrix is equivalent to a
Hopfield memory in which the diagonal blocks Hd and Hc have been
deleted Since the Hopfleld memory is robust this prun1ng may not
affect much the associative recall of stored vectors if is small
however on the average pruning will not improve the memory capaclty
It follows that on the average a discrete synchronous BAM with matrix
can at best have the capacity of a Hopfleld memory with the same
number of neurons
We have performed computations of the average memory capacity
for BAMs and for corresponding Hopfleld memories
Monte Carlo calculations were done for memories each of which
stores random bipolar vectors The straight recall of all these vectors
was checked al10wtng for 24 Iterations For the BAMs the iterations
were started with a forward stroke in which one of the stored vectors
Idm was used as input The percentage of good recall and its standard
deviation were calculated The results plotted in show that the
square BAM has about of the capacity of the corresponding Hopfleld
memory Although the total number of neurons is the same the BAM only
needs of the number of connections of the Hopfield memory The
storage capacity found Is much smaller than the Kosko upper bound
which Is min
Partitioned
Hopfield matrix
M. number of stored vectors
of good recall versus
CODED BAM
So far we have considered both front and back states to be used for
data There is another use of the BAM in which only front states are used
as data and the back states are seen as providing a code label or
pOinter for the front state Such use was antiCipated in our expression
for the BAM matrix which stores data vectors Idm and their labels or
codes lem For a square BAM. such an arrangement cuts the Information
contained in a single stored data vector jn half However the freedom of
choosing the labels fC may perhaps be put to good use Part of the
problem of spurious stable states which plagues BAMs as well as
Hopf1eld memories as they are loaded up is due to the lack of
orthogonality of the stored vectors In the coded BAM we have the
opportunity to remove part of this problem by choosing the labels as
orthonorma1 Such labels have been used previously by Kohonen 1n linear
heteroassociative memories The question whether memory capacity can
be Improved In this manner was explored by taking BAt1s In which
the labels are chosen as Hadamard vectors The latter are bipolar vectors
with Euclidean norm which form an orthonormal set These vectors
are rows of a PxP Hadamard matrix for a discussion see Harwtt and
Sloane The storage capacity of such Hadamard-coded BAMs was
calculated as function of the number of stored vectors for cases
for each value of in the manner discussed before The percentage of
good recall and its standard deviation are shown 1n It Is seen that
the Hadamard coding gives about a factor in compared to the
ordinary BAM. However the coded BAM has only half the stored
data vector dimension Accounting for this factor reduction of data
vector dimension the effective storage capacity advantage obtained by
Hadamard coding comes to only
HALF BAt1 WITH HADAMARD CODING
For the coded BAM there is the option of deleting the threshold
operation In the front layer The resulting architecture may be called
half In the half BAM thresholding Is only done on the labels and
consequently the data may be taken as analog vectors Although such an
arrangement diminishes the robustness of the memory somewhat there
are applications of interest We have calculated the percentage of good
recall for cases and found that giving up the data thresholding cuts
the storage capacity of the Hadamard-coded BAt1 by about
SELECTIVE REFLEXIVE MEMORY
The memory capacity limitations shown in are due to the
occurence of spurious states when the memories are loaded up
Consider a discrete BAM with stored data vectors to
orthonormal labels Icm and the connection matrix
For an input data vector Iv which is closest to the stored data vector
one has 1n the forward stroke
Ib>=s(clc
amlcm
where
llv
and
am=<mlv
Although for am<c for some vector component the sum
amlc
may accumulate to such a large value as to affect the thresholded result
Ib>. The problem would be avoided jf the thresholding operation in the
back layer of the BAM were to be replaced by another nonl1near operation
which selects from the I inear combination
clc
amlcm
the dominant label Ic The hypothetical device which performs this
operation is here called the Dominant Label Selector DLS and we
call the resulting memory architecture Selective Reflexive Memory
With the back state selected as the dominant label Ic the back
stroke gives by the orthogonal ity of the labels
Icm It follows that the SRM g1ves perfect assoc1attve recall of the
nearest stored data vector for any number of vectors stored Of course
the llnear independence of the P-dimensionallabel vectors Icm to
requires
The DLS must select from a linear combination of orthonormal
labels the dominant label A trivial case is obtained by choosing the
labels Icm>as basis vectors Ium which have all components zero except
for the mth component which 1s unity With this choice of labels the
DLS may be taken as a winnertake-all net as shown in
winner
This case appears to be Included in
take-all
net
Adapt Ive Resonance Theory
ART as a special sjmpllf1ed
case A relationship between
Simplest reflexive
the ordinary BAM and ART was
memory with DLS
pOinted out by KoskoS As in ART
there Is cons1derable fault sensitivity tn this memory because the
stored data vectors appear in the connectton matrix as rows
A memory with better fault tolerance may be obtained by using
orthogonal labels other than basis vectors The DLS can then be taken as
an orthogonal transformation followed by a winner-take-an net as
shown 1n is to be chosen such that 1t transforms the labels Icm
rthogonal
I
transformation
winner take-all
net
F1g. Select1ve reflex1ve
memory
tnto vectors proportional to the
basts vectors This can always
be done by tak1ng
G=[Iup><cpl
p=l
where the Icp to form a
complete orthonormal set which
contains the labels Icm m=l to M. The neurons in the DLS serve as
grandmother cells Once a single winning cell has been activated
the state of the layer Is a single basis vector say lu I this vector
must be passed back after appllcation of the transformation such
as to produce the label at the back of the BAM. Since 1s
orthogonal we have so that the reQu1red 1nverse
transformation may be accompl1shed sfmply by sending the bas1s vector
back through the transformer this gives
1IUp><cpl=<c
p=l
as required
HAlF SRM
The SRM may be modified by deleting the thresholding operation in
the front layer The front neurons then have a I inear output which is
reflected back through the SRM as shown in In this case the
stored data vectors and the
input data vectors may be taken
I near neurons
orthogonal
as analog vectors but we
transfor.1
Qu1re all the stored vectors to
mation
have the same norm The act on
winnerof the SRM proceeds in the same
I take-all
net
way as described above except
that we now require the orthoFig Half SRM with l1near
normal labels to have unit
norm It follows that just l1ke
neurons in front layer
the full SRM the half SRM gives
perfect associative recall to the nearest stored vector for any number
of stored vectors up to the dimension of the labels The latter
condition 1s due to the fact that a P-dimensional vector space can at
most conta1n orthonormal vectors
In the SRM the output transform Gis 1ntroduced in order to improve
the fauJt tolerance of the connection matrix K. This is accomplished at
the cost of some fault sensitivity of the extent of which needs to be
investigated In this regard 1t is noted that in certatn optical implementat ions of reflexive memories such as Dana Anderson's resonator I and
Similar conflgurations the transformation is a Fourier transform
which is implemented simply as a lens Such an implementation ts quite
insentive to the common semiconductor damage mechanisms
EQUIVALENT AUTOASSOCIATIVE MEMORIES
Concatenation of the front and back state vectors allows description of the SRMs tn terms of autoassociative memories For the SRM
which uses basis vectors as labels the corresponding autoassociative
memory js shown tn Fjg. This connect jon matrtx structure was also
proposed by Guest 13 The wtnner-take-all net needs to be
given t1me to settle on a basis
vector state before the state Ib
slow thres
holding
can influence the front state If>.
feedback
This may perhaps be achieved by
zero I[T
arranging the network to have a
ast thres thresholding and feedback which
WI bl olding
feedback
are fast compared with that of the
network An alternate method
Equivalent automay be to equip the network
associat lve memory
w1th an output gate which is
opened only after the net has
sett led These arrangements
present a compUcatlon and cause a delay which in some appllcations
may be 1nappropriate and In others may be acceptable in a trade
between speed and memory density
For the SRM wtth output transformer and orthonormal1abels other
than basis vectors a corresponf eedback
ding autoassoclat1ve memory may
be composed as shown In Fig.l1
thresholded
OJ OJ
An output gate in the layer is
linear
OJ
GT
I
chosen as the device which
thresholded
WI
prevents the backstroke through
output gate
the BAM to take place before the
w1nner-take-al net has settled
Autoassoc1at1ve memory
equivalent to SRM with transform
The same effect may perhaps be
achieved by choosing different
response times for the neuron
output gate
layers and These matters
wr winner-take-all
require investigation Unless
Woutput
the output transform 1s already
t@
back layer
required for other reasons as in
linear
some optical resonators the DLS
front layer
BAM connections
with output transform is clumsy
@ orthogonal transformat on
I would far better to combine
winner-take-all net
the transformer and the net
into a single network To find
Structure of SRM
such a DLS should be considered
a cha enge
The wort was partly supported by the Defense Advanced Research
projects Agency ARPA order through Contract DAAHOI-86-C
with the U.S. Army Missile Command

<<----------------------------------------------------------------------------------------------------------------------->>

title: 55-mathematical-analysis-of-learning-behavior-of-neuronal-models.pdf

MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
By
JOHN Y. CHEUNG
MASSOUD OMIDVAR
SCHOOL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCE
UNIVERSITY OF OKLAHOMA
NORMAN OK
Presented to the IEEE Conference on Neural Information Processing SystemsNatural and Synthetic Denver November and to be published in
the Collection of Papers from the IEEE Conference on NIPS
Please address all further correspondence to
John Y. Cheung
School of EECS
W. Boyd CEC
Norman OK
November
American Institute of Physics
MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
John Y. Cheung and Massoud Omidvar
School of Electrical Engineering
and Computer Science
ABSTRACT
In this paper we wish to analyze the convergence behavior of a number
of neuronal plasticity models Recent neurophysiological research suggests that
the neuronal behavior is adaptive In particular memory stored within a neuron
is associated with the synaptic weights which are varied or adjusted to achieve
learning A number of adaptive neuronal models have been proposed in the
literature Three specific models will be analyzed in this paper specifically the
Hebb model the Sutton-Barto model and the most recent trace model In this
paper we will examine the conditions for convergence the position of convergence and the rate at convergence of these models as they applied to classical
conditioning Simulation results are also presented to verify the analysis
INTRODUCTION
A number of static models to describe the behavior of a neuron have been
in use in the past decades More recently research in neurophysiology suggests
that a static view may be insufficient Rather the parameters within a neuron
tend to vary with past history to achieve learning It was suggested that by
altering the internal parameters neurons may adapt themselves to repetitive
input stimuli and become conditioned Learning thus occurs when the neurons
are conditioned To describe this behavior of neuronal plasticity a number
of models have been proposed The earliest one may have been postulated
by Hebb and more recently by Sutton and Barto We will also introduce a
new model the most recent trace MRT model in this paper The primary
objective of this paper however is to analyze the convergence behavior of these
models during adaptation
The general neuronal model used in this paper is shown in Figure There
are a number of neuronal inputs N. Each input is scaled by
the corresponding synaptic weights N. The weighted inputs
are arithmetically summed
where is taken to be zero
Neuronal inputs are assumed to take on numerical values ranging from zero
to one inclusively Synaptic weights are allowed to take on any reasonable values
for the purpose of this paper though in reality the weights may very well be
bounded Since the relative magnitude of the weights and the neuronal inputs
are not well defined at this point we will not put a bound on the magnitude
of the weights also The neuronal output is normally the result of a sigmoidal
transformation For simplicity we will approximate this operation by a linear
transformation
Sigmodial
Transfonution
neuronal
output
rilure
A leneral aeuronal adel
For convergence analysis we will assume that there are only two neuronal
inputs in the traditional classical conditioning environment for simplicity Of
course the analysis techniques can be extended to any number of inputs In
classical conditioning the two inputs are the conditioned stimulus Xc and
the unconditioned stimulus
THE SUTTON-BARTO MODEL
More recently Sutton and Barto have proposed an adaptive model based
on both the signal trace and the output trace as given below
y(t
Xi(t axi(t Xi(t
where both a and are positive constants
Condition of Convergence
In order to simplify the analysis we will choose
and
and
y(t
In other words becomes
Wi(t
Wi(t CXi(t)(y(t y(t
The above assumption only serves to simplify the analysis and will not affect the
convergence conditions because the boundedness of and only depends
on that for Xi(t and y(t respectively
As in the previous section we recognize that is a recurrence relation so
convergence can be checked by the ratio test It is also possible to rewrite
in matrix format Due to the recursion of the neuronal output in the equation
we will include the neuronal output in the parameter vector also
or
To show convergence we need to set the magnitude of the determinant of
A to be less than unity
Hence the condition for convergence is
From we can see that the adaptation constant must be chosen to be less
than the reciprocal of the Euclidean sum of energies of all the inputs The
same techniques can be extended to any number of inputs This can be proved
merely by following the same procedures outlined above
Position At Convergence
Having proved convergence of the Sutton-Barto model equations of neuronal plasticity we want to find out next at what location the system remains
when converged We have seen earlier that at convergence the weights cease to
change and so does the neuronal output We will denote this converged position
as In other words
Since any arbitrary parameter vector can always be decomposed into a weighted
sum of the eigenvectors
The constants Ql and Q3 can easily be found by inverting The
eigenvalues of can be shown to be and When is
within the region of convergence the magnitude of the third eigenvalue is less
than unity That means that at convergence there will be no contribution from
the third eigenvector Hence
From we can predict precisely what the converged position would be given
only with the initial conditions
Rate of Convergence
We have seen that when is carefully chosen the Sutton-Barto model will
converge and we have also derived an expression for the converged position
Next we want to find out how fast convergence can be attained The rate
of convergence is a measure of how fast the initial parameter approaches the
optimal position The asymptotic rate of convergence is
where SeA is the spectral radius and is equalled to in this
case This completes the convergence analysis on the Sutton-Barto model of
neuronal plasticity
THE MRT MODEL OF NEURONAL PLASTICITY
The most recent trace MRT model of neuronal plasticity developed by
the authors can be considered as a cross between the Sutton-Barto model and
the Klopf's model The adaptation of the synaptic weights can he expressed
as follows
A comparison of and the Sutton-Barto model in ahOWl that the cond
term on the right hand aide contains an extra factor which iI used to
apeed up the convergence as ahoWD later The output trace hu been replaced
by If(t the most recent output hence the name the most recent trace
model The input trace is also replaced by the most recent input
Condition of Convergence
We can now proceed to analyze the condition of convergence for the MRT
model Due to the presence of the Wi(t factor in the second term in the
ratio test cannot be applied here To analyze the convergence behavior further
let us rewrite in matrix format
WI(t
y(t
or
The superscript denotes the matrix transpose operation The above equation
is quadratic in Complete convergence analysis of this equation is
extremely difficult
In order to understand the convergence behavior of we note that
the dominant term that determines convergence mainly relates to the second
quadratic term Hence for convergence analysis only we will ignore the first
term
We can readily see from above that the primary convergence factor is BT
Since is only dependent on convergence can be obtained if the duration
of the synaptic inputs being active is bounded It can be shown that the
condition of convergence is bounded by
We can readily see that the adaptation constant can be chosen according
to to ensure convergence for T.
SIMULATIONS
To verify the theoretical analysis of these three adaptive neuronal models
based on classical conditioning these models have been simulated on the mM
mainframe using the FORTRAN language in single precision Several test
scenarios have been designed to compare the analytical predictions with actual
simulation results
To verify the conditions for convergence we will vary the value of the
adaptation constant The conditioned and unconditioned stimuli were set
to unity and the value of varies between to For the Sutton-Barto
model the simulation given in shows that convergence is obtained for
as expected from theoretical analysis For the MRT model simulation
results given in shows that convergence is obtained for also as
expected from theoretical analysis The theoretical location at convergence for
the Sutton and Barto model is also shown in Figure It is readily seen that
the simulation results confirm the theoretical expectations
I
Output
Figure lou or MuroD&l tpuu YeT.US Ule er of for the
Suttoa-Barto el witb 1frerent alues of aptat1on CODstant
lleuroul
Output
I
I
I
a
Ju.ber of iteratiOGa
Figure Plotl of oeuroaal outputl craus the uuaber of iteratious
for the MaT el with different alues of adantatlon
I:DDStaut
To illustrate the rate of convergence we will plot the trajectory of the
deviation in synaptic weights from the optimal values in the logarithmic scale
since this error is logarithmic as found earlier The slope of the line yields the
rate of convergence The trajectory for the Sutton-Barto Model is given in
Figure while that for the MRT model is given in Figure It is clear from
Figure that the trajectory in the logarithmic form is a straight line The
slope can readily be calculated The curve for the MRT model
given in Figure is also a straight line but with a much larger slope showing
faster convergence
SUMMARY
In this paper we have sought to discover analytically the convergence
behavior of three adaptive neuronal models From the analysis we see that
the Hebb model does not converge at all With constant active inputs the
output will grow exponentially In spite of this lack of convergence the Hebb
model is still a workable model realizing that the divergent behavior would
be curtailed by the sigmoidal transformation to yield realistic outputs The
I
uroul
Output
Dniatiotl
Lto
I
I
u.ber of iterationa
Figure
Trajectories of Deuronal output deviationa froa atatic alues
for the Sutton-"rt el with lfferent value adaptation
cOIIstallt C.
lleuroD&l
Output
Deviation
Ltl
I
Nuaber of iterations
Figure
Trajectories of neuronal output deviations fra atatic
values for tbe KRT el witb different values of
adaptation constant
analysis on the Sutton and Barto model shows that this model will converge
when the adaptation constant is carefully chosen The bounds for is also
found for this model Due to the structure of this model both the location at
convergence and the rate of convergence are also found We have also introduced
a new model of neuronal plasticity called the most recent trace MRT model
Certain similarities exist between the MRT model and the Sutton-Barto model
and also between the MRT model and the Klopf model Analysis shows that the
update equations for the synaptic weights are quadratic resulting in polynomial
rate of convergence Simulation results also show that much faster convergence
rate can be obtained with the MRT model

<<----------------------------------------------------------------------------------------------------------------------->>

title: 50-an-adaptive-and-heterodyne-filtering-procedure-for-the-imaging-of-moving-objects.pdf

AN ADAPTIVE AND HETERODYNE FILTERING PROCEDURE
FOR THE IMAGING OF MOVING OBJECTS
F. H. Schuling H. A. K. Mastebroek and W. H. Zaagman
Biophysics Department Laboratory for General Physics
Westersingel 34 eM Groningen The Netherlands
ABSTRACT
Recent experimental work on the stimulus velocity dependent time resolving
power of the neural units situated in the highest order optic ganglion of the
blowfly revealed the at first sight amazing phenomenon that at this high level of
the fly visual system the time constants of these units which are involved in the
processing of neural activity evoked by moving objects are roughly spokeninverse proportional to the velocity of those objects over an extremely wide range
In this paper we will discuss the implementation of a two dimensional heterodyne
adaptive filter construction into a computer simulation model The features of this
simulation model include the ability to account for the experimentally observed
stimulus-tuned adaptive temporal behaviour of time constants in the fly visual
system The simulation results obtained clearly show that the application of such
an adaptive processing procedure delivers an improved imaging technique of
moving patterns in the high velocity range
A FEW REMARKS ON THE FLY VISUAL SYSTEM
The visual system of the diptera including the blowfly Calliphora
erythrocephala is very regularly organized and allows therefore very precise
optical stimulation techniques Also long term electrophysiological recordings can
be made relatively easy in this visual system For these reasons the blowfly which
is well-known as a very rapid and clever pilot turns out to be an extremely
suitable animal for a systematic study of basic principles that may underlie the
detection and further processing of movement information at the neural level
In the fly visual system the input retinal mosaic structure is precisely
mapped onto the higher order optic ganglia lamina medulla lobula This means
that each neural column in each ganglion in this visual system corresponds to a
certain optical axis in the visual field of the compound eye In the lobula complex
a set of wide-field movement sensitive neurons is found each of which integrates
the input signals over the whole visual field of the entire eye One of these wide
field neurons that has been classified as I by Hausen has been extensively
studied both anatomically2 as well as electrophysiologically5 The
obtained results generally agree very well with those found in behavioral
optomotor experiments on movement detection and can be understood in terms of
Reichardts correlation model
The I neuron is sensitive to horizontal movement and directionally
selective very high rates of action potentials spikes up to per second can be
recorded from this element in the case of visual stimuli which move horizontally
inward from back to front in the visual field pre/erred direction whereas
movement horizontally outward from front to back null direction suppresses
its activity
American Institute of Physics
EXPERIMENTAL RESULTS AS A MODELLING BASE
When the I neuron is stimulated in its preferred direction with a step wise
pattern displacement it will respond with an increase of neural activity By
repeating this stimulus step over and over one can obtain the averaged response
after a ms latency period the response manifests itself as a sharp increase in
average firing rate followed by a much slower decay to the spontaneous activity
level Two examples of such averaged responses are shown in the Post Stimulus
Time Histograms PSTH's of figure Time to peak and peak height are related
and depend on modulation depth stimulus step size and spatial extent of the
stimulus The tail of the responses can be described adequately by an exponential
decay toward a constant spontaneous firing rate
For each setting of the stimulus parameters the response parameters
defined by equation can be estimated by a least-squares fit to the tail of the
PSTH The smooth lines in figure are the results of two such fits
tlmsl
OJ
I'JO
tf
MoO IO
Mdl05
Fig.l
I
lsI
A veraged responses PSTH's obtained from the I neuron being
adapted to smooth stimulus motion with velocities top and
bottom respectively The smooth lines represent least-squares
fits to the PSTH's of the form Values of for the
two PSTH's are and 24 ms respectively de Ruyter van Steveninck
Fitted values of as a function of adaptation velocity for three
modulation depths M. The straight line is a least-squares fit to represent
the data for in the region It has the form
f=Q with ms and de Ruyter van Steveninck
Fig.2
Figure shows fitted values of the response time constant as a function of
the angular velocity of a moving stimulus square wave grating in most
experiments which was presented to the animal during a period long enough to let
its visual system adapt to this moving pattern and before the step wise pattern
displacement which reveals was given The straight line described by
with in Is and in ms represents a least-squares fit to the data over the
velocity range from to Is. For this range varies from to roughly
ms with ms and Defining the adaptation range of as
that interval of velocities for which decreases with increasing velocity we may
conclude from figure that within the adaptation range is not very sensitive to
the modulation depth
The outcome of similar experiments with a constant modulation depth of the
pattern and a constant pattern velocity but with four different values of
the contrast frequency fc the number of spatial periods per second that
traverse an individual visual axis as determined by the spatial wavelength As of the
pattern and the pattern velocity according to fc=v lAs reveal also an almost
complete independency of the behaviour of on contrast frequency Other
experiments in which the stimulus field was subdivided into regions with different
adaptation velocities made clear that the time constants of the input channels of
the I neuron were set locally by the values of the stimulus velocity in each
stimulus sub-region Finally it was found that the adaptation of is driven by
the stimulus velocity independent of its direction
These findings can be summarized qualitatively as follows in steady state
the response time constants of the neural units at the highest level in the fly
visual system are found to be tuned locally within a large velocity range
exclusively by the magnitude of the velocity of the moving pattern and not by its
direction despite the directional selectivity of the neuron itself We will not go
into the question of how this amazing adaptive mechanism may be hard-wired in
the fly visual system Instead we will make advantage of the results derived thus
far and attempt to fit the experimental observations into an image processing
approach A large number of theories and several distinct classes of algorithms to
encode velocity and direction of movement in visual systems have been suggested
by for example Marr and Ullman I I and van Santen and Sperling12
We hypothesize that the adaptive mechanism for the setting of the time
constants leads to an optimization for the overall performance of the visual system
by realizing a velocity independent representation of the moving object In other
words within the range of velocities for which the time constants are found to be
tuned by the velocity the representation of that stimulus at a certain level within
the visual circuitry should remain independent of any variation in stimulus
velocity
OBJECT MOTION DEGRADATION MODELLING
Given the physical description of motion and a linear space invariant model
the motion degradation process can be represented by the following convolution
integral
co co
JJ
flu dudv
where is the object intensity at position in the object coordinate
frame is the Point Spread Function PSF of the imaging system
which is the response at to a unit pulse at and is the image
intensity at the spatial position as blurred by the imaging system Any
possible additive white noise degradation of the already motion blurred image is
neglected in the present considerations
For a review of principles and techniques in the field of digital image
degradation and restoration the reader is referred to Harris 13 Sawchuk
Sondhi Nahi A boutalib 17 18 Hildebrand 19 Rajala de Figueiredo20
It has been demonstrated first by Aboutalib that for situations in which
the motion blur occurs in a straight line along one spatial coordinate say along the
horizontal axis it is correct to look at the blurred image as a collection of
degraded line scans through the entire image The dependence on the vertical
coordinate may then be dropped and eq reduces to
f(u)du
Given the mathematical description of the relative movement
corresponding PSF can be derived exactly and equation becomes
b(x f(u)du
the
where is the extent of the motion blur Typically a discrete version of
applicable for digital image processing purposes is described by
I
where and I take on integer values and is related to the motion blur extent
According to Aboutalib 18 a scalar difference equation model
can then be derived to model the motion degradation process
cmA(i-m
where is the m-dimensional state vector at position along a scan line is
the input intensity at position is the output intensity is the blur extent
is the number of elements in a line is a scalar a and are constant
matrices of order mxl and lxm respectively containing the discrete
values Cj of the blurring PSF for and is the Kronecker delta
function
INFLUENCE OF BOTH TIME CONSTANT AND VELOCITY
ON THE AMOUNT OF MOTION BLUR IN AN ARTIFICIAL
RECEPTOR ARRAY
To start with we incorporate in our simulation model a PSF derived from
equation to model the performance of all neural columnar arranged filters in
the lobula complex with the restriction that the time constants remain fixed
throughout the whole range of stimulus velocities Realization of this PSF can
easily be achieved via the just mentioned state space model
I.
I.
Fig.3
POSITION IN
ARTIFICIAL RECEPTOR ARRAY
upper part Demonstration of the effect that an increase in magnitude of
the time constants of an one-dimensional array of filters will result in
increase in motion blur while the pattern velocity remains constant
Original pattern shown in solid lines is a square-wave grating with a
spatial wavelength equal to artificial receptor distances The three
other wave forms drawn show that for a gradual increase increase in
magnitude of the time constants the representation of the original
square-wave will consequently degrade lower part A gradual increase in
velocity of the moving square-wave while the filter time constants are
kept fixed results also in a clear increase of degradation
First we demonstrate the effect that an increase in time constant while the
pattern velocity remains the same will result in an increase in blur Therefore we
introduce an one dimensional array of filters all being equipped with the same
time constant in their impulse response The original pattern shown in square and
solid lines in the upper part of figure consists of a square wave grating with a
spatial period overlapping artificial receptive filters The other patterns drawn
there show that for the same constant velocity of the moving grating an increase
in the magnitude of the time constants of the filters results in an increased blur in
the representation of that grating On the other hand an increase in velocity
while the time constants of the artificial receptive units remain the same also
results in a clear increase in motion blur as demonstrated in the lower part of
figure
Inspection of the two wave forms drawn by means of the dashed lines in
both upper and lower half of the figure yields the conclusion that apart from
rounding errors introduced by the rather small number of artificial filters
available equal amounts of smear will be produced when the product of time
constant and pattern velocity is equal For the upper dashed wave form the
velocity was four times smaller but the time constant four times larger than for its
equivalent in the lower part of the figure
ADAPTIVE SCHEME
In designing a proper image processing procedure our next step is to
incorporate the experimentally observed flexibility property of the time constants
in the imaging elements of our device In figure 4a a scheme is shown which
filters the information with fixed time constants not influenced by the pattern
velocity In figure 4b a network is shown where the time constants also remain
fixed no matter what pattern movement is presented but now at the next level of
information processing a spatially differential network is incorporated in order to
enhance blurred contrasts
In the filtering network in figure 4c first a measurement of the magnitude
of the velocity of the moving objects is done by thus far hypothetically introduced
movement processing algorithms modelled here as a set of receptive elements
sampling the environment in such a manner that proper estimation of local pattern
velocities can be done Then the time constants of the artificial receptive elements
will be tuned according to the estimated velocities and finally the same
differential network as in scheme 4b is used
The actual tuning mechanism used for our simulations is outlined in figure
once given the range of velocities for which the model is supposed to be
operational and given a lower limit for the time constant min min can be the
smallest value which physically can be realized the time constant will be tuned to
a new value according to the experimentally observed reciprocal relationship and
will for all velocities within the adaptive range be larger than the fixed minimum
value As demonstrated in the previous section the corresponding blur in the
representation of the moving stimulus will thus always be larger than for the
situation in which the filtering is done with fixed and smallest time constants
min More important however is the fact that due to this tuning mechanism the
blur will be constant since the product of velocity and time constant is kept
constant So once the information has been processed by such a system a velocity
independent representation of the image will be the result which can serve as the
input for the spatially differentiating network as outlined in figure 4c
The most elementary form for this differential filtering procedure is the one
in which the gradient of two filters K-I and K+l which are the nearest neighbors
of filter is taken and then added with a constant weighing factor to the central
output as drawn in figure and where the sign of the gradient depends on
the direction of the estimated movement Essential for our model is that we claim
that this weighing factor should be constant throughout the whole set of filters
and for the whole high velocity range in which the heterodyne imaging has to be
performed Important to notice is the existence of a so-called settling time the
minimal time needed for our movement processing device to be able to accurately
measure the object velocity Note this time can be set equal to zero in the case
that the relative stimulus velocity is known a priori as demonstrated in figure
Since without doubt within this settling period estimated velocity values will
come out erroneously and thus no optimal performance of our imaging device can
be expected in all further examples results after this initial settling procedure
will be shown
A
yV
rYO
i~J
t"if
Pattern movement in this figure is to the right
A Network consisting of a set of filters with a fixed pattern velocity
independent time constant in their impulse response
Identical network as in figure 4A now followed by a spatially
differentiating circuitry which adds the weighed gradients of two
neighboring filter outputs K-l and K+I to the central filter output
K.
The time constants of the filtering network are tuned by a
hypothetical movement estimating mechanism visualized here as a
number of receptive elements of which the combined output tunes
the filters A detailed description of this mechanism is shown in
figure This tuned network is followed by an identical spatially
differentiating circuit as described in figure
increasing velocity
decreasing time constant
min
Detailed description of the mechanism used to tune the time constants
The time constant of a specific neural channel is set by the pattern
velocity according to the relationship shown in the insert which is
derived from eq with I and I.
4r
I
I
I
I
I
I
I
I
4V
I
I
a
2V
Wi
8V
I
POSITION IN ARTIFICIAL RECEPTOR ARRAY
Fig.6
Thick lines square-wave stimulus pattern with a spatial wavelength
overlapping 32 artificial receptive elements Thick lines responses for
different pattern velocities in a system consisting of paralleling neural
filters equipped with time constants tuned by this velocity and followed
by a spatially differentiating network as described
Dashed lines responses to the different pattern velocities in a filtering
system with fixed time constants followed by the same spatial
differentiating circuitry as before Note the sharp over and under
shoots for this case
Results obtained with an imaging procedure as drawn in figure and 4c
are shown in figure The pattern consists of a square wave overlapping 32
picture elements The pattern moves to the left with different velocities
At each velocity only one wavelength is shown Thick lines
square wave pattern Dashed lines the outputs of an imaging device as depicted in
figure constant time constants and a constant weighing factor in the spatial
processing stage Note the large differences between the several outputs Thin
continuous lines the outputs of an imaging device as drawn in figure tuned
time constants according to the reciprocal relationship between pattern velocity
and time constant and a constant weighing factor in the spatial processing stage
For further simulation details the reader is referred to Zaagman Now the
outputs are almost completely the same and in good agreement with the original
stimulus throughout the whole velocity range
Figure shows the effect of the gradient weighing factor on the overall
filter performance estimated as the improvement of the deblurred images as
compared with the blurred image measured in dB This quantitative measure has
been determined for the case of a moving square wave pattern with motion blur
IX
ItI
a
weighing factor
Effect of the weighing factor on the overall filter performance Curve
measured for the case of a moving square-wave grating Filter
performance is estimated as the improvement in signal to noise ratio
I:iI
where is the original intensity at position in the image
is the intensity at the same position in the motion blurred image and
is the intensity at in the image generated with the adaptive
tuning procedure
extents comparable to those used for the simulations to be discussed in section IV.
From this curve it is apparent that for this situation there is an optimum value for
this weighing factor Keeping the weight close to this optimum value will result in
a constant output of our adaptive scheme thus enabling an optimal deblurring of
the smeared image of the moving object
On the other hand starting from the point of view that the time constants
should remain fixed throughout the filtering process we should had have to tune
the gradient weights to the velocity in order to produce a constant output as
demonstrated in figure where the dashed lines show strongly differing outputs of
a fixed time constant system with spatial processing with constant weight figure
4b In other words tuning of the time constants as proposed in this section results
in I the realization of the blur-constancy criterion as formulated previously and
as a consequence the possibility to deblur the obtained image oPtimally with
one and the same weighing factor of the gradient in the final spatial processing
layer over the whole heterodyne velocity range
COMPUTER SIMULATION RESULTS AND
CONCLUSIONS
The image quality improvement algorithm developed in the present
contribution has been implemented on a general purpose DG Eclipse Sjl40 minicomputer for our two dimensional simulations Figure Sa shows an undisturbed
image consisting of lines of each pixels with bit intensity resolution
Figure Sb shows what happens with the original image if the PSF is modelled
according to the exponential decay In this case the time constants of all
spatial information processing channels have been kept fixed Again information
content in the higher spatial frequencies has been reduced largely The
implementation of the heterodyne filtering procedure was now done as follows
first the adaptation range was defined by setting the range of velocities This
means that our adaptive heterodyne algorithm is supposed to operate adequately
only within the thus defined velocity range and that in that range the time
constants are tuned according to relationship and will always come out larger
than the minimum value min For demonstration purposes we set Q=I and in
eq thus introducing the phenomenon that for any velocity the two
dimensional set of spatial filters with time constants tuned by that velocity will
always produce a constant output independent of this velocity which introduces
the motion blur Figure Sc shows this representation It is important to note here
that this constant output has far more worse quality than any set of filters with
smallest and fixed time constants min would produce for velocities within the
operational range The advantage of a velocity independent output at this level in
our simulation model is that in the next stage a differential scheme can be
implemented as discussed in detail in the preceding paragraph Constancy of the
weighing factor which is used in this differential processing scheme is guaranteed
by the velocity independency of the obtained image representation
Figure Sd shows the result of the differential operation with an optimized
gradient weighing factor This weighing factor has been optimized based on an
almost identical performance curve as described previously in figure A clear
and good restoration is apparent from this figure though close inspection reveals
fine structure especially for areas with high intensities which is unrelated with
the original intensity distribution These artifacts are caused by the phenomenon
that for these high intensity areas possible tuning errors will show up much more
pronounced than for low intensities
Fig.8a
Fig.8b
8c
Fig.8d
a
Original bit picture
Motion degraded image with a PSF derived from
where is kept fixed to pixels and the motion blur extent is 32
pixels
Worst case the result of motion degradation of the original image
with a PSF as in figure 8b but with tuning of the time constants based
on the velocity
Restored version of the degraded image using the heterodyne adaptive
processing scheme
In conclusion a heterodyne adaptive image processing technique inspired by
the fly visual system has been presented as an imaging device for moving objects
A scalar difference equation model has been used to represent the motion blur
degradation process Based on the experimental results described and on this state
space model we developed an adaptive filtering scheme which produces at a
certain level within the system a constant output permitting further differential
operations in order to produce an optimally deblurred representation of the
moving object
ACKNOWLEDGEMENTS
The authors wish to thank mT Eric Bosman for his expert programming
assistance mr Franco Tommasi for many inspiring discussions and advises during
the implementation of the simulation model and dr Rob de Ruyter van Steveninck
for experimental help This research was partly supported by the Netherlands
Organization lor the Advancement 01 Pure Research through the
foundation Stichting voor Biolysica

<<----------------------------------------------------------------------------------------------------------------------->>

title: 49-connecting-to-the-past.pdf

CONNECTING TO THE PAST
Bruce A. MacDonald Assistant Professor
Knowledge Sciences Laboratory Computer Science Department
The University of Calgary University Drive NW
Calgary Alberta T2N IN4
ABSTRACT
Recently there has been renewed interest in neural-like processing systems evidenced for example in the two volumes Parallel Distributed Processing edited by Rumelhart and McClelland
and discussed as parallel distributed systems connectionist models neural nets value passing
systems and multiple context systems Dissatisfaction with symbolic manipulation paradigms
for artificial intelligence seems partly responsible for this attention encouraged by the promise
of massively parallel systems implemented in hardware This paper relates simple neural-like
systems based on multiple context to some other well-known formalisms-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier sequence prediction results in a new light
INTRODUCTION
The revival of neural net research has been very strong exemplified recently by Rumelhart
and McClelland new journals and a number of meetings The nets are also described as
parallel distributed systems connectionist models value passing systems3 and multiple context
learning systems4 The symbolic manipulation paradigm for artificial intelligence does
not seem to have been as successful as some hoped and there seems at last to be real promise
of massively parallel systems implemented in hardware However in the flurry of new work it
is important to consolidate new ideas and place them solidly alongside established ones This
paper relates simple neural-like systems to some other well-known notions-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier results on the abilities of such networks in a new light
The general form of a connectionist system lO is simplified to a three layer net with binary
fixed weights in the hidden layer thereby avoiding many of the difficulties-and challengesof the recent work on neural nets The hidden unit weights are regularly patterned using a
template Sophisticated expensive learning algorithms are avoided and a simple method is
used for determining output unit weights In this way we gain some of the advantages of multilayered nets while retaining some of the simplicity of two layer net training methods Certainly
nothing is lost in computational power-as I will explain-and the limitations of two layer
nets are not carried over to the simplified three layer one Biological systems may similarly
avoid the need for learning algorithms such as the simulated annealing method commonly
used in connectionist models For one thing biological systems do not have the same clearly
distinguished training phase
Briefly the simplified net is a production system implemented as three layers of neuron-like
units an output layer an input layer and a hidden layer for the productions themselves Each
hidden production unit potentially connects a predetermined set of inputs to any output A
k-Iength sequence predictor is formed once Ie levels of delay unit are introduced into the input
layer k-Iength predictors are unable to distinguish simple sequences such as ba a and aa a
since after Ie or more characters the system has forgotten whether an a or appeared first If
the k-Iength predictor is augmented with auxiliary actions it is able to learn this and other
regular languages since the auxiliary actions can be equivalent to states and can be inputs to
aAmong them the 1st International Conference on Neural Nets San Diego,CA June and this
con.ference
bRoughly equivalent to a single context system in Andreae's multiple context system See also
MacDonald
@
American Institute of Physics
Figure The general form of a connectionist system
Form of a unit
Operations within a unit
in~uts excitation-.I
weIghts
sum
aCtiVation--W output
Typical
Typical
the production units enabling predictions to depend on previous states By combining several
augmented sequence predictors a Thring machine tape can be simulated along with a finite-state
controller giving the net the computational power of a Universal Turing machine Relatively
simple neural-like systems do not lack computational ability Previous implementations of
this ability are production system equivalents to the simplified nets
Organization of the paper
The next section briefly reviews the general form of connectionist systems Section simplifies
this then section explains that the result is equivalent to a production system dealing only
with inputs and outputs of the net Section extends the simplified version enabling it to learn
to predict sequences Section explains how the computational power of the sequence predictor
can be increased to that of a Thring machine if some input units receive auxiliary actions in fact
the system can learn to be a TUring machine Section discusses the possibility of a number of
nets combining their outputs forming an overall net with association areas
General form of a connectionist system
Figure shows the general form of a connectionist system unit neuron or ce1l In the figure
unit has inputs which are the outputs OJ of possibly all units in the network and an output of
its own The net input excitation net is the weighted sum of inputs where Vij is the weight
connecting the output from unit as an input to unit The activation of the unit is some
function Fi of the net input excitation Typically Fi is semilinear that is non-decreasing and
differentiable 13 and is the same function for all or at least large groups of units The output is
a function fi of the activation typically some kind of threshold function I will assume that the
quantities vary over discrete time steps so for example the activation at time is
and is given by Fi((neti(t
In general there is no restriction on the connections that may be made between units
Units not connected directly to inputs or outputs are hidden units In more complex nets
than those described in this paper there may be more than one type of connection Figure
shows a common connection topology where there are three layers of units-input hidden and
output-with no cycles of connection
The net is trained by presenting it with input combinations each along with the desired
output combination Once trained the system should produce the desired outputs given just
Figure The basic structure of a three layer connectionist system
input units
hidden
units
output units
inputs During training the weights are adjusted in some fashion that reduces the discrepancy
between desired and actual output The general method is lO
where is the desired training activation Equation is a general form of Hebb's classic
rule for adjusting the weight between two units with high activations lO The weight adjustment
is the product of two functions one that depends on the desired and actual activations--often
just the difference-and another that depends on the input to that weight and the weight itself
As a simple example suppose is the difference and as just the output OJ. Then the weight
change is the product of the output error and the input excitation to that weight
where the constant determines the learning rate This is the Widrow-Hoff or Delta rule which
may be used in nets without hidden units 1o
The important contribution of recent work on connectionist systems is how to implement
equation in hidden units for which there are no training signals ti directly available The
Boltzmann learning method iteratively varies both weights and hidden unit training activations
using the controlled gradually decreasing randomizing method simulated annealing Backpropagation 13 is also iterative performing gradient descent by propagating training signal errors
back through the net to hidden units I will avoid the need to determine training signals for
hidden units by fixing the weights of hidden units in section below
SIMPLIFIED SYSTEM
Assume these simplifications are made to the general connectionist system of section
The system has three layers with the topology shown in Figure ie no cycles
All hidden layer unit weights are fixed say at unity or zero
Each unit is a linear threshold unit lO which means the activation function for all units
is the identity function giving just net a weighted sum of the inputs and the output
function is a simple binary threshold of the form
I
output
threshold
activation
so that the output is binary on or oft Hidden units will have thresholds requiring all
inputs to be active for the output to be active like an AND gate while output units will
have thresholds requiring only or two active highly weighted inputs for an output to be
generated like an OR gate This is in keeping with the production system view of the
net explained in section
Learning-which now occurs only at the output unit weights-gives weight adjustments
according to
Wij
Wij
if
OJ
otherwise
so that weights are turned on if their input and the unit output are on and off otherwise
That is Wij A OJ. A simple example is given in Figure in section below
This simple form of net can be made probabilistic by replacing with below
Adjust weights so that Wij estimates the conditional probability of the unit output being
on when output is on That is
Wij
estimate of P(odoj
Then assuming independence of the inputs to a unit an output unit is turned on when the
conditional probability of occurrence of that output exceeds the threshold of the output
function
Once these simplifications are made there is no need for learning in the hidden units Also no
iterative learning is required weights are either assigned binary values or estimate conditional
probabilities This paper presents some of the characteristics of the simplified net Section
discusses the motivation for simplifying neural nets in this way
PRODUCTION SYSTEMS
The simplified net is a kind of simple production system A production system comprises a
global database a set of production rules and a control system The database for the net is
the system it interacts with providing inputs as reactions to outputs from t.he net The hidden
units of the network are the production rules which have the form
IF
precondition
THEN
action
The precondition is satisfied when the input excitation exceeds the threshold of a hidden unit
The actions are represented by the output units which the hidden production units activate
The control system of a production system chooses the rule whose action to perform from the
set of rules whose preconditions have been met In a neural net the control system is distributed
throughout the net in the output units For example the output units might form a winner-takeall net In production systems more complex control involves forward and backward chaining to
choose actions that seek goals This is discussed elsewhere4.12.16 Figure illust.rates a simple
production implemented as a neural net As the figure shows the inputs to hidden units are
just the elements of the precondition When the appropriate input combination is present the
associated hidden production unit is fired Once weights have been leamed connecting hidden
units to output units firing a production results in output The simplified neural net is directly
equivalent to a production system whose elements are inputs and outputs
Some production systems have symbolic elements such as variables which can be given
values by production actions The neural net cannot directly implement this since it can
have outputs only from a predetermined set However we will see later that extensions t.o the
framework enable this and other abilities
CThis might be referred to as a sensory-motor production system since when implemented ill a l'eal system
such as a robot it deals only with sensed inputs and executable motor actions which may include the auxiliary
actions of section
Figure A production implemented in a simplified neural net
A production rule
IF
Icloudy I Ipressure falling I
AND
THEN
Iit will rain I
The rule implemented as a hidden unit The threshold of the hidden unit is so it is
an AND gate The threshold of the output unit is so it is an OR gate The learned
weight will be or if the net is not probabilistic otherwise it will be an estimate of
P(it will rainlclouds AND pressure falling
It will
rain
weight
Figure A net that predicts the next character in a sequence based on only the last character
The net Production units hidden units have been combined with input units
For example this net could predict the sequence abcabcabc Productions have the
form IF last character is THEN next character will be The learning rule is
Wij
if inputj AND outputi Output is
WijOj
input
neural net
output
a
a
Learning procedure
Clamp inputs and outputs to desired values
System calculates weight values
Repeat and for all required input/output combinations
SEQUENCE PREDICTION
A production system or neural net can predict sequences Given examples of a repeating sequence productions are learned which predict future events on the basis of recent ones Figure
shows a trivially simple sequence predictor It predicts the next character of a sequence based
on the previous one The figure also gives the details of the learning procedure for the simplified
net The net need be trained only once on each input combination then it will predict as
an output every character seen after the current one The probabilistic form of the net would
estimate conditional probabilities for the next character conditional on the current one Many
Figure Using delayed inputs a neural net can implement a k-length sequence predictor
A net with the last three characters as input
input
hidden
output
a
a
a
2nd last
An example production
IF
last three characters were THEN
presentations of each possible character pair would be needed to properly estimate the probabilities The net would be learning the probability distribution of character pairs A predictor like
the one in Figure can be extended to a general k-Iength 17 predictor so long as inputs delayed
by steps are available Then as illustrated in Figure for 3-length prediction hidden
production units represent all possible combinations of symbols Again output weights are
trained to respond to previously seen input combinations here of three characters These delays
can be provided by dedicated neural nets such as that shown in Figure Note that the net
is assumed to be synchronously updated so that the input from feedback around units is not
changed until one step after the output changes There are various ways of implementing delay
in neurons and Andreae investigates some of them for the same purpose-delaying inputs-in
a more detailed simulation of a similar net
Other work on sequence prediction in neural nets
Feldman and Ballard find connectionist systems initially not suited to representing changes
with time One form of change is sequence and they suggest two methods for representing
sequence in nets The first is by units connected to each other in sequence so that sequential
tasks are represented by firing these units in succession The second method is to buffer the
inputs in time so that inputs from the recent past are available as well as current inputs that
is delayed inputs are available as suggested above An important difference is the necessary
length of the buffer Feldman and Ballard suggest the buffer be long enough to hold a phrase of
natural language but I expect to use buffers no longer than about after Andreae Symbolic
inputs can represent more complex information effectively giving the length seven buffers more
information than the most recent seven simple inputs as discussed in section
The method of back-propagation13 enables recurrent networks to learn sequential tasks in a
dFeldman and Ballard2 give some dedicated neural net connections for a variety of flUlctions
Figure Inputs can be delayed by dedicated neural subnets A two stage delay is shown
Delay network
Timing diagram for
tml
A
original signal
delay of one step
delay of two steps
manner similar to the first suggestion in the last paragraph where sequences of connected units
represent sequenced events In one example a net learns to complete a sequence of characters
when given the first two characters of a six character sequence the next four are output Errors
must be propagated around cycles in a recurrent net a number of times
Seriality may also be achieved by a sequence of states of distributed activation 18 An example
is a net playing both sides of a tic-tac-toe game 18 The sequential nature of the net's behavior is
derived from the sequential nature of the responses to the net's actions tic-tac-toe moves A net
can model sequence internally by modeling a sequential part of its environment For example
a tic-tac-toe playing net can have a model of its opponent
k-Iength sequence predictors are unable to learn sequences which do not repeat more frequently that every characters Their k-Iength context includes only information about the last
events However there are two ways in which information from before the kth last input can
be retained in the net The first method latches some inputs while the second involves auxiliary
actions
Latch units
Inputs can be latched and held indefinitely using the combination shown in Figure Not all
inputs would normally be latched Andreae discusses this technique of threading latched
events among non-latched events giving the net both information arbitrarily far back in its
input-output history and information from the immediate past Briefly the sequence ba a
can be distinguished from aa a if the first character is latched However this is an ad hoc
solution to this problem
Auxiliary actions
When an output is fed back into the net as an input signal this enables the system to choose the
next output at least partly based on the previous one as indicated in Figure If a particular
fed back output is also one without external manifestation or whose external manifestation
is independent of the task being performed then that output is an auxiliary action It Las
The interested reader should refer to Andreae where more extensive analysis is given
Figure Threading A latch circuit remembers an event until another comes along This is a
two input latch for two letters a and but any number of units may be similarly connected
It is formed from a mutual inhibition layer or winner-take-all connection along with positive
feedback to keep the selected output activated when the input disappears
a
Figure Auxiliary actions-the outputs-are fed back to the inputs of a net enabling the
net to remember a state Here both part of a net and an example of a production are shown
There are two types of action characters and actions
Sinputs
outputs
character inputs
IF
input is
and character input is
character outputs
THEN
output character
lliJ and ill
no direct effect on the task the system is performing since it evokes no relevant inputs and
so can be used by the net as a symbolic action If an auxiliary action is latched at the input
then the symbolic information can be remembered indefinitely being lost only when another
auxiliary action of that kind is input and takes over the latch Thus auxiliary actions can act
like remembered states the system performs an action to remind itself to be in a particular
state The figure illustrates this for a system that predicts characters and state changes given
the previous character and state An obvious candidate for auxiliary actions is speech So
the blank oval in the figure would represent the net's environment through which its own
speech actions are heard Although it is externally manifested speech has no direct effect on
our physical interactions with the world Its symbolic ability not only provides the power of
auxiliary actions but also includes other speakers in the interaction
SIMULATING ABSTRACT AUTOMATA
The example in Figure gives the essence of simulating a finite state automaton with a production system or its neural net equivalent It illustrates the transition function of an automaton
the new state and output are a function of the previous state and input Thus a neural net can
simulate a finite state automaton so long as it has additional auxiliary actions
A Thring machine is a finite state automaton controller plus an unbounded memory A
neural net could simulate a lUring machine in two ways and both ways have been demonstrated
with production system implementations-equivalent to neural nets----(;alled multiple context
learning systems briefly explained in section The first Thring machine simulation has the
system simulate only the finite state controller but is able to use an unbounded external memory
fSee John Andreae's and his colleagues work4
Figure Multiple context learning system implementation as multiple neural nets Each:3
layer net has the simplified form presented above with a number of elaborations such as extra
connections for goal-seeking by forward and backward chaining
Output
channels
from the real world much like the paper of Turing's original work 19 The second simnlat.ion
embeds the memory in the multiple context learning system along with a counter for accessing
this simulated memory Both learn all the productions-equivalent to learning output unit
weights-required for the simulations The second is able to add internal memory as required
up to a limit dependent on the size of the network which can easily be large enough to allow 70
years of computation The second could also employ external memory as the first did Briefly
the second simulation comprised multiple sequence predictors which predicted auxiliary actions
for remembering the state of the controller and the current memory position The memory
element is updated by relearning the production representing that element the precondition is
the address and the production action the stored item
MULTIPLE SYSTEMS FORM ASSOCIATION AREAS
A multiple context learning system is production system version of a multiple neural net although a simple version has been implemented as a simulated net It effectively comprises
several nets--or association areas-which may have outputs and inputs in common as indicated in Figure Hidden unit weights are specified by templates one for each net A template
gives the inputs to have a zero weight for the hidden units of a net and the inputs to have a
weight of unity Delayed and latched inputs are also available The actual outputs are selected
from the combined predictions of the nets in a winner-take-all fashion
I see the design for real neural nets say as controllers for real robots requiring a large
degree of predetermined connectivity A robot controller could not be one three layer net wit.h
every input connected to every hidden unit in turn connected to every output There will
need to be some connectivity constraints so the net reflects the functional specialization in the
control requirements The multiple context learning system has all the hidden layer connections
predetermined but allows output connections to be learned This avoids the credit assignment
problem and therefore also the need for learning algorithms such as Boltzmann learning and
back-propagation However as the multiple context learning system has auxiliary actions and
delayed and latched inputs it does not lack computational power Future work in this area
should investigate for example the ability of different kinds of nets to learn auxiliary act.ions
This may be difficult as symbolic actions may not be provided in training inputs and output.s
For
example a controller for a robot body would have to deal with vision manipulation motion etc
CONCLUSION
This paper has presented a sImplified three layer connectionist model with fixed weights for
hidden units delays and latches for inputs sequence prediction ability auxiliary state actions
and the ability to use internal and external memory The result is able to learn to simulate a
Turing machine Simple neural-like systems do not lack computational power
ACKNOWLEDGEMENTS
This work is supported by the Natural Sciences and Engineering Council of Canada

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 49-connecting-to-the-past.pdf

CONNECTING TO THE PAST
Bruce A. MacDonald Assistant Professor
Knowledge Sciences Laboratory Computer Science Department
The University of Calgary University Drive NW
Calgary Alberta T2N IN4
ABSTRACT
Recently there has been renewed interest in neural-like processing systems evidenced for example in the two volumes Parallel Distributed Processing edited by Rumelhart and McClelland
and discussed as parallel distributed systems connectionist models neural nets value passing
systems and multiple context systems Dissatisfaction with symbolic manipulation paradigms
for artificial intelligence seems partly responsible for this attention encouraged by the promise
of massively parallel systems implemented in hardware This paper relates simple neural-like
systems based on multiple context to some other well-known formalisms-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier sequence prediction results in a new light
INTRODUCTION
The revival of neural net research has been very strong exemplified recently by Rumelhart
and McClelland new journals and a number of meetings The nets are also described as
parallel distributed systems connectionist models value passing systems3 and multiple context
learning systems4 The symbolic manipulation paradigm for artificial intelligence does
not seem to have been as successful as some hoped and there seems at last to be real promise
of massively parallel systems implemented in hardware However in the flurry of new work it
is important to consolidate new ideas and place them solidly alongside established ones This
paper relates simple neural-like systems to some other well-known notions-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier results on the abilities of such networks in a new light
The general form of a connectionist system lO is simplified to a three layer net with binary
fixed weights in the hidden layer thereby avoiding many of the difficulties-and challengesof the recent work on neural nets The hidden unit weights are regularly patterned using a
template Sophisticated expensive learning algorithms are avoided and a simple method is
used for determining output unit weights In this way we gain some of the advantages of multilayered nets while retaining some of the simplicity of two layer net training methods Certainly
nothing is lost in computational power-as I will explain-and the limitations of two layer
nets are not carried over to the simplified three layer one Biological systems may similarly
avoid the need for learning algorithms such as the simulated annealing method commonly
used in connectionist models For one thing biological systems do not have the same clearly
distinguished training phase
Briefly the simplified net is a production system implemented as three layers of neuron-like
units an output layer an input layer and a hidden layer for the productions themselves Each
hidden production unit potentially connects a predetermined set of inputs to any output A
k-Iength sequence predictor is formed once Ie levels of delay unit are introduced into the input
layer k-Iength predictors are unable to distinguish simple sequences such as ba a and aa a
since after Ie or more characters the system has forgotten whether an a or appeared first If
the k-Iength predictor is augmented with auxiliary actions it is able to learn this and other
regular languages since the auxiliary actions can be equivalent to states and can be inputs to
aAmong them the 1st International Conference on Neural Nets San Diego,CA June and this
con.ference
bRoughly equivalent to a single context system in Andreae's multiple context system See also
MacDonald
@
American Institute of Physics
Figure The general form of a connectionist system
Form of a unit
Operations within a unit
in~uts excitation-.I
weIghts
sum
aCtiVation--W output
Typical
Typical
the production units enabling predictions to depend on previous states By combining several
augmented sequence predictors a Thring machine tape can be simulated along with a finite-state
controller giving the net the computational power of a Universal Turing machine Relatively
simple neural-like systems do not lack computational ability Previous implementations of
this ability are production system equivalents to the simplified nets
Organization of the paper
The next section briefly reviews the general form of connectionist systems Section simplifies
this then section explains that the result is equivalent to a production system dealing only
with inputs and outputs of the net Section extends the simplified version enabling it to learn
to predict sequences Section explains how the computational power of the sequence predictor
can be increased to that of a Thring machine if some input units receive auxiliary actions in fact
the system can learn to be a TUring machine Section discusses the possibility of a number of
nets combining their outputs forming an overall net with association areas
General form of a connectionist system
Figure shows the general form of a connectionist system unit neuron or ce1l In the figure
unit has inputs which are the outputs OJ of possibly all units in the network and an output of
its own The net input excitation net is the weighted sum of inputs where Vij is the weight
connecting the output from unit as an input to unit The activation of the unit is some
function Fi of the net input excitation Typically Fi is semilinear that is non-decreasing and
differentiable 13 and is the same function for all or at least large groups of units The output is
a function fi of the activation typically some kind of threshold function I will assume that the
quantities vary over discrete time steps so for example the activation at time is
and is given by Fi((neti(t
In general there is no restriction on the connections that may be made between units
Units not connected directly to inputs or outputs are hidden units In more complex nets
than those described in this paper there may be more than one type of connection Figure
shows a common connection topology where there are three layers of units-input hidden and
output-with no cycles of connection
The net is trained by presenting it with input combinations each along with the desired
output combination Once trained the system should produce the desired outputs given just
Figure The basic structure of a three layer connectionist system
input units
hidden
units
output units
inputs During training the weights are adjusted in some fashion that reduces the discrepancy
between desired and actual output The general method is lO
where is the desired training activation Equation is a general form of Hebb's classic
rule for adjusting the weight between two units with high activations lO The weight adjustment
is the product of two functions one that depends on the desired and actual activations--often
just the difference-and another that depends on the input to that weight and the weight itself
As a simple example suppose is the difference and as just the output OJ. Then the weight
change is the product of the output error and the input excitation to that weight
where the constant determines the learning rate This is the Widrow-Hoff or Delta rule which
may be used in nets without hidden units 1o
The important contribution of recent work on connectionist systems is how to implement
equation in hidden units for which there are no training signals ti directly available The
Boltzmann learning method iteratively varies both weights and hidden unit training activations
using the controlled gradually decreasing randomizing method simulated annealing Backpropagation 13 is also iterative performing gradient descent by propagating training signal errors
back through the net to hidden units I will avoid the need to determine training signals for
hidden units by fixing the weights of hidden units in section below
SIMPLIFIED SYSTEM
Assume these simplifications are made to the general connectionist system of section
The system has three layers with the topology shown in Figure ie no cycles
All hidden layer unit weights are fixed say at unity or zero
Each unit is a linear threshold unit lO which means the activation function for all units
is the identity function giving just net a weighted sum of the inputs and the output
function is a simple binary threshold of the form
I
output
threshold
activation
so that the output is binary on or oft Hidden units will have thresholds requiring all
inputs to be active for the output to be active like an AND gate while output units will
have thresholds requiring only or two active highly weighted inputs for an output to be
generated like an OR gate This is in keeping with the production system view of the
net explained in section
Learning-which now occurs only at the output unit weights-gives weight adjustments
according to
Wij
Wij
if
OJ
otherwise
so that weights are turned on if their input and the unit output are on and off otherwise
That is Wij A OJ. A simple example is given in Figure in section below
This simple form of net can be made probabilistic by replacing with below
Adjust weights so that Wij estimates the conditional probability of the unit output being
on when output is on That is
Wij
estimate of P(odoj
Then assuming independence of the inputs to a unit an output unit is turned on when the
conditional probability of occurrence of that output exceeds the threshold of the output
function
Once these simplifications are made there is no need for learning in the hidden units Also no
iterative learning is required weights are either assigned binary values or estimate conditional
probabilities This paper presents some of the characteristics of the simplified net Section
discusses the motivation for simplifying neural nets in this way
PRODUCTION SYSTEMS
The simplified net is a kind of simple production system A production system comprises a
global database a set of production rules and a control system The database for the net is
the system it interacts with providing inputs as reactions to outputs from t.he net The hidden
units of the network are the production rules which have the form
IF
precondition
THEN
action
The precondition is satisfied when the input excitation exceeds the threshold of a hidden unit
The actions are represented by the output units which the hidden production units activate
The control system of a production system chooses the rule whose action to perform from the
set of rules whose preconditions have been met In a neural net the control system is distributed
throughout the net in the output units For example the output units might form a winner-takeall net In production systems more complex control involves forward and backward chaining to
choose actions that seek goals This is discussed elsewhere4.12.16 Figure illust.rates a simple
production implemented as a neural net As the figure shows the inputs to hidden units are
just the elements of the precondition When the appropriate input combination is present the
associated hidden production unit is fired Once weights have been leamed connecting hidden
units to output units firing a production results in output The simplified neural net is directly
equivalent to a production system whose elements are inputs and outputs
Some production systems have symbolic elements such as variables which can be given
values by production actions The neural net cannot directly implement this since it can
have outputs only from a predetermined set However we will see later that extensions t.o the
framework enable this and other abilities
CThis might be referred to as a sensory-motor production system since when implemented ill a l'eal system
such as a robot it deals only with sensed inputs and executable motor actions which may include the auxiliary
actions of section
Figure A production implemented in a simplified neural net
A production rule
IF
Icloudy I Ipressure falling I
AND
THEN
Iit will rain I
The rule implemented as a hidden unit The threshold of the hidden unit is so it is
an AND gate The threshold of the output unit is so it is an OR gate The learned
weight will be or if the net is not probabilistic otherwise it will be an estimate of
P(it will rainlclouds AND pressure falling
It will
rain
weight
Figure A net that predicts the next character in a sequence based on only the last character
The net Production units hidden units have been combined with input units
For example this net could predict the sequence abcabcabc Productions have the
form IF last character is THEN next character will be The learning rule is
Wij
if inputj AND outputi Output is
WijOj
input
neural net
output
a
a
Learning procedure
Clamp inputs and outputs to desired values
System calculates weight values
Repeat and for all required input/output combinations
SEQUENCE PREDICTION
A production system or neural net can predict sequences Given examples of a repeating sequence productions are learned which predict future events on the basis of recent ones Figure
shows a trivially simple sequence predictor It predicts the next character of a sequence based
on the previous one The figure also gives the details of the learning procedure for the simplified
net The net need be trained only once on each input combination then it will predict as
an output every character seen after the current one The probabilistic form of the net would
estimate conditional probabilities for the next character conditional on the current one Many
Figure Using delayed inputs a neural net can implement a k-length sequence predictor
A net with the last three characters as input
input
hidden
output
a
a
a
2nd last
An example production
IF
last three characters were THEN
presentations of each possible character pair would be needed to properly estimate the probabilities The net would be learning the probability distribution of character pairs A predictor like
the one in Figure can be extended to a general k-Iength 17 predictor so long as inputs delayed
by steps are available Then as illustrated in Figure for 3-length prediction hidden
production units represent all possible combinations of symbols Again output weights are
trained to respond to previously seen input combinations here of three characters These delays
can be provided by dedicated neural nets such as that shown in Figure Note that the net
is assumed to be synchronously updated so that the input from feedback around units is not
changed until one step after the output changes There are various ways of implementing delay
in neurons and Andreae investigates some of them for the same purpose-delaying inputs-in
a more detailed simulation of a similar net
Other work on sequence prediction in neural nets
Feldman and Ballard find connectionist systems initially not suited to representing changes
with time One form of change is sequence and they suggest two methods for representing
sequence in nets The first is by units connected to each other in sequence so that sequential
tasks are represented by firing these units in succession The second method is to buffer the
inputs in time so that inputs from the recent past are available as well as current inputs that
is delayed inputs are available as suggested above An important difference is the necessary
length of the buffer Feldman and Ballard suggest the buffer be long enough to hold a phrase of
natural language but I expect to use buffers no longer than about after Andreae Symbolic
inputs can represent more complex information effectively giving the length seven buffers more
information than the most recent seven simple inputs as discussed in section
The method of back-propagation13 enables recurrent networks to learn sequential tasks in a
dFeldman and Ballard2 give some dedicated neural net connections for a variety of flUlctions
Figure Inputs can be delayed by dedicated neural subnets A two stage delay is shown
Delay network
Timing diagram for
tml
A
original signal
delay of one step
delay of two steps
manner similar to the first suggestion in the last paragraph where sequences of connected units
represent sequenced events In one example a net learns to complete a sequence of characters
when given the first two characters of a six character sequence the next four are output Errors
must be propagated around cycles in a recurrent net a number of times
Seriality may also be achieved by a sequence of states of distributed activation 18 An example
is a net playing both sides of a tic-tac-toe game 18 The sequential nature of the net's behavior is
derived from the sequential nature of the responses to the net's actions tic-tac-toe moves A net
can model sequence internally by modeling a sequential part of its environment For example
a tic-tac-toe playing net can have a model of its opponent
k-Iength sequence predictors are unable to learn sequences which do not repeat more frequently that every characters Their k-Iength context includes only information about the last
events However there are two ways in which information from before the kth last input can
be retained in the net The first method latches some inputs while the second involves auxiliary
actions
Latch units
Inputs can be latched and held indefinitely using the combination shown in Figure Not all
inputs would normally be latched Andreae discusses this technique of threading latched
events among non-latched events giving the net both information arbitrarily far back in its
input-output history and information from the immediate past Briefly the sequence ba a
can be distinguished from aa a if the first character is latched However this is an ad hoc
solution to this problem
Auxiliary actions
When an output is fed back into the net as an input signal this enables the system to choose the
next output at least partly based on the previous one as indicated in Figure If a particular
fed back output is also one without external manifestation or whose external manifestation
is independent of the task being performed then that output is an auxiliary action It Las
The interested reader should refer to Andreae where more extensive analysis is given
Figure Threading A latch circuit remembers an event until another comes along This is a
two input latch for two letters a and but any number of units may be similarly connected
It is formed from a mutual inhibition layer or winner-take-all connection along with positive
feedback to keep the selected output activated when the input disappears
a
Figure Auxiliary actions-the outputs-are fed back to the inputs of a net enabling the
net to remember a state Here both part of a net and an example of a production are shown
There are two types of action characters and actions
Sinputs
outputs
character inputs
IF
input is
and character input is
character outputs
THEN
output character
lliJ and ill
no direct effect on the task the system is performing since it evokes no relevant inputs and
so can be used by the net as a symbolic action If an auxiliary action is latched at the input
then the symbolic information can be remembered indefinitely being lost only when another
auxiliary action of that kind is input and takes over the latch Thus auxiliary actions can act
like remembered states the system performs an action to remind itself to be in a particular
state The figure illustrates this for a system that predicts characters and state changes given
the previous character and state An obvious candidate for auxiliary actions is speech So
the blank oval in the figure would represent the net's environment through which its own
speech actions are heard Although it is externally manifested speech has no direct effect on
our physical interactions with the world Its symbolic ability not only provides the power of
auxiliary actions but also includes other speakers in the interaction
SIMULATING ABSTRACT AUTOMATA
The example in Figure gives the essence of simulating a finite state automaton with a production system or its neural net equivalent It illustrates the transition function of an automaton
the new state and output are a function of the previous state and input Thus a neural net can
simulate a finite state automaton so long as it has additional auxiliary actions
A Thring machine is a finite state automaton controller plus an unbounded memory A
neural net could simulate a lUring machine in two ways and both ways have been demonstrated
with production system implementations-equivalent to neural nets----(;alled multiple context
learning systems briefly explained in section The first Thring machine simulation has the
system simulate only the finite state controller but is able to use an unbounded external memory
fSee John Andreae's and his colleagues work4
Figure Multiple context learning system implementation as multiple neural nets Each:3
layer net has the simplified form presented above with a number of elaborations such as extra
connections for goal-seeking by forward and backward chaining
Output
channels
from the real world much like the paper of Turing's original work 19 The second simnlat.ion
embeds the memory in the multiple context learning system along with a counter for accessing
this simulated memory Both learn all the productions-equivalent to learning output unit
weights-required for the simulations The second is able to add internal memory as required
up to a limit dependent on the size of the network which can easily be large enough to allow 70
years of computation The second could also employ external memory as the first did Briefly
the second simulation comprised multiple sequence predictors which predicted auxiliary actions
for remembering the state of the controller and the current memory position The memory
element is updated by relearning the production representing that element the precondition is
the address and the production action the stored item
MULTIPLE SYSTEMS FORM ASSOCIATION AREAS
A multiple context learning system is production system version of a multiple neural net although a simple version has been implemented as a simulated net It effectively comprises
several nets--or association areas-which may have outputs and inputs in common as indicated in Figure Hidden unit weights are specified by templates one for each net A template
gives the inputs to have a zero weight for the hidden units of a net and the inputs to have a
weight of unity Delayed and latched inputs are also available The actual outputs are selected
from the combined predictions of the nets in a winner-take-all fashion
I see the design for real neural nets say as controllers for real robots requiring a large
degree of predetermined connectivity A robot controller could not be one three layer net wit.h
every input connected to every hidden unit in turn connected to every output There will
need to be some connectivity constraints so the net reflects the functional specialization in the
control requirements The multiple context learning system has all the hidden layer connections
predetermined but allows output connections to be learned This avoids the credit assignment
problem and therefore also the need for learning algorithms such as Boltzmann learning and
back-propagation However as the multiple context learning system has auxiliary actions and
delayed and latched inputs it does not lack computational power Future work in this area
should investigate for example the ability of different kinds of nets to learn auxiliary act.ions
This may be difficult as symbolic actions may not be provided in training inputs and output.s
For
example a controller for a robot body would have to deal with vision manipulation motion etc
CONCLUSION
This paper has presented a sImplified three layer connectionist model with fixed weights for
hidden units delays and latches for inputs sequence prediction ability auxiliary state actions
and the ability to use internal and external memory The result is able to learn to simulate a
Turing machine Simple neural-like systems do not lack computational power
ACKNOWLEDGEMENTS
This work is supported by the Natural Sciences and Engineering Council of Canada

<<----------------------------------------------------------------------------------------------------------------------->>

title: 53-the-connectivity-analysis-of-simple-association.pdf

The Connectivity Analysis of Simple Association
orHow Many Connections Do You Need
Dan Hammerstrom
Oregon Graduate Center Beaverton OR
ABSTRACT
The efficient realization using current silicon technology of Very Large Connection
Networks VLCN with more than a billion connections requires that these networks exhibit
a high degree of communication locality Real neural networks exhibit significant locality
yet most connectionist/neural network models have little In this paper the connectivity
requirements of a simple associative network are analyzed using communication theory
Several techniques based on communication theory are presented that improve the robustness of the network in the face of sparse local interconnect structures Also discussed are
some potential problems when information is distributed too widely
INTRODUCTION
Connectionist/neural network researchers are learning to program networks that exhibit a broad range of cognitive behavior Unfortunately existing computer systems are limited in their ability to emulate such networks efficiently The cost of emulating a network
whether with special purpose highly parallel silicon-based architectures or with traditional
parallel architectures is directly proportional to the number of connections in the network
This number tends to increase geometrically as the number of nodes increases Even with
large massively parallel architectures connections take time and silicon area Many existing neural network models scale poorly in learning time and connections precluding large
implementations
The connectivity costs of a network are directly related to its locality A network
exhibits locality 01 communication if most of its processing elements connect to other physically adjacent processing elements in any reasonable mapping of the elements onto a planar
surface There is much evidence that real neural networks exhibit locality2 In this paper
a technique is presented for analyzing the effects of locality on the process of association
These networks use a complex node similar to the higher-order learning units of Maxwell
NETWORK MODEL
The network model used in this paper is now defined Figure
Definition A recursive neural network called a c-graph is a graph structure
where
There is a set of CNs network nodes whose outputs can take a range of positive
real values Vi between and There are N. nodes in the set
There is a set of codons that can take a range of positive real values eij for
codon of node between and There are Ne codons dedicated to each CN the
output of each codon is only used by its local so there are a total of Ne N. codons
in the network The fan-in or order of a codon is Ie. It is assumed that leis the
same for each codon and Ne is the same for each CN.
This work was supported in part by the Semiconductor Research Corporation contract no and
jointly by the Office of Naval Research and Air Force Office of Scientific Research ONR contract no NOOO14 87
American Institute of Physics
Ie
codon
Figure A ON
Cijk is a set of connections of ONs to codons and Ne Cijk can
take two values indicating the existence of a connection from ON to codon
of ON
Definition The value of ON is
Vi
F[8+~eijl
J-l
The function is a continuous non-linear monotonic function such as the sigmoid function
Definition Define a mapping where is an input vector to rand is
the Ie element input vector of codon of ON That is has as its elements those elements of Zk of where Cijk=1
The function indicates the subset of seen by codon of ON Different input vectors may map to the same codon vectors and D(i,j,Zj-y where
Definition The codon values eij are determined as follows Let be input vector
of the learned input vectors for ON For codon eij of ON let Tij be the set of I cdimensional vectors such that lij(m)E ij and That is each vector
lij in Tij consists of those subvectors of that are in codon ii's receptive field
The variable indexes the vectors of ij The number of distinct vectors in Tij
may be less than the total number of learned vectors Though the are
distinct the subsets lij(m need not be since there is a possible many to one mapping of
the vectors onto each vector lij
Let Xl be the subset of vectors where vi=l ON is supposed to output a and
those vectors where vi=O then define
izeof
for and that map to this I. That is is the number of
xo be
vectors that map
into Iij{l where
tlj-O
and is the number of vectors that map into Iii where
The compreaaion of a codon for a vector then is defined as
I IJ
Hqj(l)=O when both nt The output of codon
eii is the maximum-likelyhood
decoding
Where He indicates the likely hood of when a vector that maps to is input and
is that vector where I I and is the current input vector In other words is that vector of the set of subset learned vectors that codon ij
receives that is closest using distance measure to the subset input vector
The output of a codon is the most-likely output according to its inputs For example when there is no code compression at a codon if the closest terms of some
measure of vector distance Hamming distance subvector in the receptive field of the
codon belongs to a learned vector where the CN is to output a The codons described here
are very similar to those proposed by Marr and implement ne!'Lrest-neighbor classification
It is assumed that codon function is determined statically prior to network operation that
is the desired categories have already been learned
To measure performance network capacity is used
Definition The input noiae Or is the average between an input vector and the
closest minimum learned vector where is a measure of the difference between two
vectors for bit vectors this can be Hamming distance The output noise is the average
distance between network output and the learned output vector associated with the closest
learned input vector The in/ormation gain Gr is just
Gt
I
Definition The capacity of a network is the maximum number of learned vectors such
that the information gain Gr is strictly positive
COMMUNICATION ANALOGY
Consider a single connection network node or CN. The remainder of this paper will
be restricted to a single Assume that the CN output value space is restricted to two
values and Therefore the CN must decide whether the input it sees belongs to the
class of codes those codes for which it remains off or the class of codes those codes
for which it becomes active The inputs it sees in its receptive field constitute a subset of
the input vectors the function to the network It is also assumed that the CN is an
ideal I-NN Nearest Neighbor classifier or feature detector That is given a particular set
of learned vectors the CN will classify an arbitrary input according to the class of the
nearest using as a measure of distance learned vector This situation is equivalent to
the case where a single CN has a single codon whose receptive field size is equivalent to that
of the CN.
Imagine a sender who wishes to send one bit of information over a noisy channel The
sender has a probabilistic encoder that choses a code word learned vector according to
some probability distribution The receiver knows this code set though it has no knowledge
of which bit is being sent Noise is added to the code word during its transmission over the
channel which is analogous to applying an input vector to a network's inputs where the
vector lies within some learned vector's region The noise is represented by the distance
between the input vector and the associated learned vector
The code word sent over the channel consists of those bits that are seen in the receptive field of the ON being modeled In the associative mapping of input vectors to output
vectors each ON must respond with the appropriate output or for the associated
learned output vector Therefore a ON is a decoder that estimates in which class the
received code word belongs This is a classic block encoding problem where increasing the
field size is equivalent to increasing code length As the receptive field size increases the
performance of the decoder improves in the presence of noise Using communication theory
then the trade-off between interconnection costs as they relate to field size and the functionality of a node as it relates to the correctness of its decision making process output
errors can be characterized
As the receptive field size of a node increases so does the redundancy of the input
though this is dependent on the particular codes being used for the learned vectors since
there are situations where increasing the field size provides no additional information
There is a point of diminishing returns where each additional bit provides ever less reduction in output error Another factor is that interconnection costs increase exponentially
with field size The result of these two trends is a cost performance measure that has a single global maximum value In other words given a set of learned vectors and their probabilities and a set of interconnection costs a best receptive field size can be determined
beyond which increasing connectivity brings diminishing returns
SINGLE CODON WITH NO CODE COMPRESSION
A single neural element with a single codon and with no code compression can be
modelled exactly as a communication channel Figure Each network node is assumed
to have a single codon whose receptive field size is equal to that of the receptive field size of
the node
sender
I I
encoder
nOIsy
I
I
transmitter
receiver
I
decoder
ON
Figure A Transmission Channel
recelver
The operation of the channel is as follows A bit is input into the channel encoder
which selects a random code of length and transmits that code over the channel The
receiver then using nearest neighbor classification decides if the original message was either
a or a
Let be the number of code words used by the encoder The rate then indicates the
density of the code space
Definition The rate of a communication channel is
The block length corresponds directly to the receptive field size of the codon
The derivations in later sections use a related measure
Definition The code utilization is the number of learned vectors assigned to a particular code or
can be written in terms of
2N
As approaches code compression increases is essentially unbounded since may be
significantly larger than
The decode error information loss due to code compression is a random variable that
depends on the compression rate and the a priori probabilities therefore it will be different
with different learned vector sets and codons within a set As the average code utilization
for all codons approaches code compression occurs more often and codon decode error is
unavoidable
Let Zi be the vector output of the encoder and the input to the channel where each
element of Zi is either a or Let Vi be the vector output of the channel and the input to
the decoder where each element is either a or a The Noisy Channel Coding Theorem is
now presented for a general case where the individual input codes are to be distinguished The result is then extended to a CN where even though input codes are
used the ON need only distinguish those codes where it must output a from those where it
must output a The theorem is from Gallager Random codes are assumed
throughout
Theorem Let a discrete memoryless channel have transition probabilities PNU/k
and for any positive integer and positive number consider the ensemble of
block codes in which each letter of each code word is independently selected according to
fe
the probability assignment Then for each message NR
and all
the ensemble average probability of decoding error using maximum-likelyhood
decoding satisfies
where
In the definitions given here and the theorems below the notation of Gall ager is used Many of the
definitions and theorems are also from Gallager
Q(k)PU/kp!p
i-il
l+P
k-il
These results are now adjusted ror our special case
Theorem For a single CN the average channel error rate ror random code vectors is
Pe
where
I
is the probability or an input vector bit being a
These results cover a wide range or models A more easily computable expression can
be derived by recognizing some or the restrictions inherent in the CN model First assume
that all channel code bits are equally likely that is I that the error model is
the Binary Symmetric Channel and that the errors are identically distributed and
independent that is each bit has the same probability or being in error independent
or the code word and the bit position in the code word
A simplified version or the above theorem can be derived Maximizing gives the
tightest bounds
O$p~l
maxPe(p
where letting codon input be the block length I
The minimum value or this expression is obtained when for
Eo log
SINGLE-CODON WITH CODE COMPRESSION
Unfortunately the implementation complexity of a codon grows exponentially with the
size or the codon which limits its practical size An alternative is to approximate single
codon function of a single CN with many smaller overlapped codons The goal is to maintain performance and reduce implementation costs thus improving the cost/performance of
the decoding process As codons get smaller the receptive field size becomes smaller relative
to the number of CNs in the network When this happens there is codon compression or
vector alia6ing that introduces its own errors into the decoding process due to information
loss Networks can overcome this error by using multiple redundant codons with overlapping receptive fields that tend to correct the compression error
Compression occurs when two code words requiring different decoder output share the
same representation within the receptive field or the codon The following theorem gives
the probability of incorrect codon output with and without compression error
Theorem For a BSC model where the codon receptive field is Ic the code utilization is and the channel bits are selected randomly and independently the probability
of a codon decoding error when is approximately
where the expected compression error per codon is approximated by
Pc
and from equations when
exp
log
I-RI
Proof is given in Hammerstrom6
As grows Pc approaches asymptotically Thus the performance of a single codon
degrades rapidly in the presence of even small amounts of compression
MULTIPLE CODONS WITH CODE COMPRESSION
The use or mUltiple small codons is more efficient than a few large codons but there
are some fundamental performance constraints When a codon is split into two or more
smaller codons and the original receptive field is subdivided accordingly there are several
effects to be considered First the error rate of each new codon increases due to a decrease
in receptive field size the codon's block code length The second effect is that the code
utilization will increase for each codon since the same number of learned vectors is
mapped into a smaller receptive field This change also increases the error rate per codon
due to code compression In fact as the individual codon receptive fields get smaller
significant code compression occurs For higher-order input codes there is an added error
that occurs when the order of the individual codons is decreased since random codes are
being assumed this effect is not considered here The third effect is the mass action of
large numbers of codons Even though individual codons may be in error if the majority
are correct then the ON will have correct output This effect decreases the total error rate
Assume that each ON has more than one codon The union of the receptive fields
for these codons is the receptive field for the ON with no no restrictions on the degree of
overlap of the various codon receptive fields within or between ONs. For a ON with a large
number of codons the codon overlap will generally be random and uniformly distributed
Also assume that the transmission errors seen by different receptive fields are independent
Now consider what happens to a codon's compression error rate ignoring transmission
error for the time being when a codon is replaced by two or more smaller co dons covering
the same receptive field This replacement process can continue until there are only
codons which incidentally is analogous to most current neural models For a multiple
codon ON assume that each codon votes a or The summation unit then totals this
information and outputs a if the majority of codons vote for a etc
Theorem The probability of a ON error due to compression error is
Pc
where
Pc
dy
is given in equation and
Pc incorporates the two effects of moving to mUltiple smaller codons and adding more
codons Using equation 17 gives the total error probability per bit PeN
Proof is in Hammerstrom6
For networks that perform association as defined in this paper the connection weights
rapidly approach a single uniform value as the size of the network grows In information
theoretic terms the information content of those weights approaches zero as the compression increases Why then do simple non-conjunctive networks 1-codon equivalent work at
alI In the next section I define connectivity cost constraints and show that the answer to
the first question is that the general associative structures defined here do not scale costeffectively and more importantly that there are limits to the degree of distribution of information
CONNECTIVITY COSTS
It is much easier to assess costs if some implementation medium is assumed I have
chosen standard silicon which is a two dimensional surface where ON's and codons take up
surface area according to their receptive field sizes In addition there is area devoted to
the metal lines that interconnect the ONs. A specific VLSI technology need not be assumed
since the comparisons are relative thus keeping ONs codons and metal in the proper proportions according to a standard metal width which also includes the inter-metal
pitch For the analyses performed here it is assumed that
levels of metal are possible
In the previous section I established the relationship of network performance in terms
of the transmission error rate and the network capacity M. In this section I present an
implementation cost which is total silicon area A. This figure can then be used to derive a
cost/performance figure that can be used to compare such factors as codon size and receptive field size There are two components to the total area A ON the area of a ON and
AMI the area of the metal interconnect between ONs. AON consists of the silicon area
requirements of the codons for all ONs. The metal area for local intra-ON interconnect is
considered to be much smaller than that of the codons themselves and of that of the more
global inter-ON interconnect and is not considered here The area per ON is roughly
AON cfeme
where me is the maximum number of vectors that each codon must distinguish for
me
Theorem Assume a rectangular un6ounded grid of ONs all ONs are equi-distant
from their four nearest neighbors where each ON has a bounded receptive field of its nON
nearest ONs where ON is the receptive field size for the ON nON
C~e
where is the
number of codons and is the intra-ON redundancy that is the ratio of inputs to
synapses when R=l each ON input is used once at the ON when each input is
used on the average at two sites The metal area required to support each ON's receptive
field is proof is giving by Hammerstrom6
AMI
The total area per ON A then is
Another implementation IItrategy ill to place eNII along a diagonal which givell area However thill
technique only works ror a bounded number or eNII and when dendritic computation can be lipread over a large
area which limits the range or p08llible eN implementationll The theorem IItated here covers an infinite plane or
eNII each with a bounded receptive Held
Even with the assumption of maximum locality the total metal interconnect area
increases as the cube of the per CN receptive field size
SINGLE CN SIMULATION
What do the bounds tell us about CN connectivity requirements From simulations
increasing the CN's receptive field size improves the performance increases capacity but
there is also an increasing cost which increases faster than the performance Another
observation is that redundancy is quite effective as a means for increasing the effectiveness
of a CN with constrained connectivity There are some limits to since it can reach a
point where the intra-CN connectivity approaches that of inter-CN for some situations
With a fixed nON increasing cost-effectiveness A is possible by increasing both order
and redundancy
In order to verify the derived bounds I also wrote a discrete event simulation of a CN
where a random set of learned vectors were chosen and the CN's codons were programmed
according to the model presented earlier Learned vectors were chosen randomly and subjected to random noise The CN then attempted to categorize these inputs into two
major groups CN output and CN output For the most part the analytic bounds
agreed with the simulation though they tended to be optimistic in slightly underestimating
the error These differences can be easily explained by the simplifying assumptions that
were made to make the analytic bounds mathematically tractable
DISTRmUTED VS. LOCALIZED
Throughout this paper it has been tacitly assumed that representations are distributed
across a number of CNs and that any single CN participates in a number of representations In a local representation each CN represents a single concept or feature It is the distribution of representation that makes the CN's decode job difficult since it is the cause of
the code compression problem
There has been much debate in the connectionist/neuromodelling community as to the
advantages and disadvantages of each approach the interested reader is referred to Hinton7 Baum and BallardQ Some of the results derived here are relevant to this
debate A1s the distribution of representation increases the compression per CN increases
accordingly It was shown above that the mean error in a codon's response quickly
approaches independent of the input noise This result also holds at the CN level For
each individual CN this error can be offset by adding more codons but this is expensive
and tends to obviate one of the arguments in favor of distributed representations that is
the multi-use advantage where fewer CNs are needed because of more complex redundant
encodings A1s the degree of distribution increases the required connectivity and the code
compression increases so the added information that each codon adds to its CN's decoding
process goes to zero equivalent to all weights approaching a uniform value
SUMMARY AND CONCLUSIONS
In this paper a single CN node performance model was developed that was based on
Communication Theory Likewise an implementation cost model was derived
The communication model introduced the codon as a higher-order decoding element
and showed that for small codons much less than total CN fan-in or convergence code
compression or vector aliasing within the codon's receptive field is a severe problem for
large networks As code compression increases the information added by any individual
codon to the CN's decoding task rapidly approaches zero
The cost model showed that for 2-dimensional silicon the area required for inter-node
metal connectivity grows as the cube of a CN's fan-in
The combination of these two trends indicates that past a certain point which is
highly dependent on the probability structure of the learned vector space increasing the
fan-in of a CN as is done for example when the distribution of representation is increased
yields diminishing returns in terms of total cost-performance Though the rate of diminishing returns can be decreased by the use of redundant higher-order connections
The next step is to apply these techniques to ensembles of nodes CNs operating in a
competitive learning or feature extraction environment

<<----------------------------------------------------------------------------------------------------------------------->>

title: 52-teaching-artificial-neural-systems-to-drive-manual-training-techniques-for-autonomous-systems.pdf

Teaching Artificial Neural Systems to Drive
Manual Training Techniques for Autonomous Systems
J. F. Shepanski and S. A. Macy
TRW Inc
One Space Park
Redondo Beach CA
Abetract
We have developed a methodology for manually training autononlous control systems
based on artificial neural systems In applications where the rule set governing an expert's
decisions is difficult to formulate ANS can be used to ext.ra.c:t rules by associating the information
an expert receives with the actions takes Properly constructed networks imitate rules of
behavior that permits them to function autonomously when they are trained on the spanning set
of possible situations This training can be provided manually either under the direct supervision
or a system trainer or indirectly using a background mode where the network assimilates training
data as the expert perrorms his day-to-day tasks To demonstrate these methods we have trained
an ANS network to drive a vehicle through simulated rreeway traffic
I ntJooducticn
Computational systems employing fine grained parallelism are revolutionizing the way we
approach a number or long standing problems involving pattern recognition and cognitive processing The field spans a wide variety or computational networks rrom constructs emulating neural
runctions to more crystalline configurations that resemble systolic arrays Several titles are used
to describe this broad area or research we use the term artificial neural systems Our concern in this work is the use or ANS ror manually training certain types or autonomous systems
where the desired rules of behavior are difficult to rormulate
Artificial neural systems consist of a number or processing elements interconnected in a
weighted user-specified fashion the interconnection weights acting as memory ror the system
Each processing element calculatE an output value based on the weighted sum or its inputs In
addition the input data is correlated with the output or desired output specified by an instructive
agent in a training rule that is used to adjust the interconnection weights In this way the ne
work learns patterns or imitates rules of behavior and decision making
The partiCUlar ANS architecture we use is a variation of Rummelhart lJ multi-layer
perceptron employing the generalized delta rule GD R). Instead of a single multi-layer structure our final network has a a multiple component or block configuration where one blOt'k
output reeds into another Figure The training methodology we have developed is not
tied to a particular training rule or architecture and should work well with alternative networks
like Grossberg's adaptive resonance model[2J
American Institute of Physics
The equations describing the network are derived and described in detail by Rumelhart
In summary they are
Transfer function
Sj
WjiOi
i-O
Weight adaptation rule
Error calculation
a
OJ
a l'??Awp.revious
OJ E0.tW.ti
where OJ is the output or processing element or a sensor input is the interconnection weight
leading from element ito is the number of inputs to Aw is the adjustment of is the
training constant a is the training momentum OJ is the calculated error for element and
is the Canout oC a given element Element zero is a constant input equal to one so that WjO is
equivalent to the bias threshold of element The factor in equation differs from standard GDR formulation but it is useful for keeping track of the relative magnitudes of the two
terms For the network's output layer the summation in equation is replaced with the
difference between the desired and actual output value of element
These networks are usually trained by presenting the system with sets of input/output data
vectors in cyclic fashion the entire cycle of database presentation repeated dozens of times This
method is effective when the training agent is a computer operating in batch mode but would be
intolerable for a human instructor There are two developments that will help real-time human
training The first is a more efficient incorporation of data/response patterns into a network The
second which we are addressing in this paper is a suitable environment wherein a man and ANS
network can interact in training situation with minimum inconvenience or boredom on the
human's part The ability to systematically train networks in this fashion is extremely useful for
developing certain types of expert systems including automatic signal processors autopilots
robots and other autonomous machines We report a number of techniques aimed at facilitating
this type of training and we propose a general method for teaching these networks
System Development
Our work focuses on the utility of ANS for system control It began as an application of
Barto and Sutton's associative search network[3 Although their approach was useful in a
number of ways it fell short when we tried to use it for capturing the subtleties of human
decision-making In response we shifted our emphasis rrom constructing goal runctions for
automatic learning to methods for training networks using direct human instruction An integral
part or this is the development or suitable interraces between humans networks and the outside
world or simulator In this section we will report various approaches to these ends and describe a
general methodology for manually teaching ANS networks To demonstrate these techniques we
taught a network to drive a robot vehicle down a simulated highway in traffic This application
combines binary decision making and control of continuous parameters
Initially we investigated the use or automatic learning based on goal functions[3 for training control systems We trained a network-controlled vehicle to maintain acceptable following
distances from cars ahead or it On a graphics workstation a one lane circular track was
constructed and occupied by two vehicles a network-controlled robot car and a pace car that
varied its speed at random Input data to the network consisted of the separation distance and
the speed of the robot vehicle The values of a goal function were translated into desired output
for GDR training Output controls consisted of three binary decision elements accelerate one
increment of speed maintain speed and decelerate one increment of speed At all times
the desired output vector had exactly one of these three elements active The goal runction was
quadratic with a minimum corresponding to the optimal following distance Although it had no
direct control over the simulation the goal function positively or negatively reinforced the
system's behavior
The network was given complete control of the robot vehicle and the human trainer had
no influence except the ability to start and terminate training This proved unsatisractory because
the initial system behavior--governed by random interconnection weights--was very unstable The
robot tended to run over the car in rront of it before significant training occurred By carerully
halting and restarting training we achieved stable system behavior At first the rollowing distance
maintained by the robot car oscillated as ir the vehicle was attached by a sj)ring to the pace car
This activity gradually damped Arter about one thousand training steps the vehicle maintained
the optimal following distance and responded quickly to changes in the pace car's speed
Constructing composite goal functions to promote more sophisticated abilities proved
difficult even ill-defined because there were many unspecified parameters To generate goal
runctions ror these abilities would be similar to conventional programming--the type or labor we
want to circumvent using ANS. On the other hand humans are adept at assessing complex situations and making decisions based on qualitative data but their goal runctions are difficult ir not
impossible to capture analytically One attraction of ANS is that it can imitate behavior based on
these elusive rules without rormally specifying them At this point we turned our efforts to
manual training techniques
The initially trained network was grafted into a larger system and augmented with additional inputs distance and speed inrormation on nearby pace cars in a second traffic lane and an
output control signal governing lane changes The original network's ability to maintain a safe
following distance was retained intact Thts grafting procedure is one of two methods we studied
for adding ne abilities to an existin system The second which employs a block structure is
described below The network remained in direct control of the robot vehicle but a human
trainer instructed it when and when not to change lanes His commands were interpreted as the
desired output and used in the GDR training algorithm This technique which we call coaching
proved userul and the network quickly correlated its environmental inputs with the teacher's
instructions The network became adept at changing lanes and weaving through traffic We found
that the network took on the behavior pattern or its trainer A conservative teacher produced a
timid network while an aggressive tzainer produced a network that tended to cut off other automobiles and squeeze through tight openings Despite its success the coaching method of training
did not solve the problem or initial network instability
The stability problem was solved by giving the trainer direct control over the simulation
The system configuration Figure allows the expert to exert control or release it to the
work During initial tzaining the expert is in the driver's seat while the network acts the role of
apprentice It receives sensor information predicts system commands and compares its predictions against the desired output the trainer's commands Figure shows the data and command flow in detail Input data is processed through different channels and presented to the
trainer and network Where visual and audio formats are effective for humans the network uses
information in vector form This differentiation of data presentation is a limitation of the system
removing it is a cask for future search The trainer issues control commands in accordance with
his assigned while the network takes the trainer's actions as desired system responses and
correlates these with the input We refer to this procedure as master/apprentice training network
training proceeds invisibly in the background as the expert proceeds with his day to day work It
avoids the instability problem because the network is free to make errors without the adverse
consequence of throwing the operating environment into disarray
I
Input
World sensors
or
Simulation
Actuation
I
Ne',WOrk
I
Expert
Commands
Figure A scheme for manually training ANS networks Input data is received by both
the network and trainer The trainer issues commands that are actuated solid command
line or he coaches the network in how it ought to respond broken command line
Commands
Preprocessing
tortunan
Input
data
Preprocessing
for network
twork
Predicted
commands
Actuation
Coaching/emphasis
Training
rule
Fegure Data and convnand flow In the training system Input data is processed and presented
to the trainer and network In master/appre~ice training solid command Hne the trainer's
orders are actuated and the network treats his commands as the system's desired output In
coaching the network's predicted oonvnands are actuated broken command line and the
trainer influences weight adaptation by specifying the desired system output and controlHng
the values of trailing constants-his suggestions are not cirec:tty actuated
Once initial bacqround wainmg is complete the expert proceeds in a more formal
manner to teach the network He releases control of the command system to the network in
order to evaluate ita behavior and weaknesses He then resumes control and works through a
series of scenarios designed to train t.he network out of its bad behavior By switching back and
forth between human and network control the expert assesses the network's reliability and
teaches correct responses as needed We find master/apprentice training works well for behavior
involving continuous functions like steering On the other hand coaching is appropriate for decision Cunctions like when Ule car ought to pass Our methodology employs both techniques
The Driving Network
The fully developed freeway simulation consists of a two lane highway that is made of
joined straight and curved segments which vary at random in length and curvature Several
pace cars move at random speeds near the robot vehicle The network is given the tasks of tracking the road negotiating curves returning to the road if placed far afield maintaining safe distances from the pace cars and changing lanes when appropriate Instead of a single multi-layer
structure the network is composed of two blocks one controls the steering and the other regulates speed and decides when the vehicle should change lanes Figure The first block receives
information about the position and speed of the robot vehicle relative to other ears in its vicinity
Its output is used to determine the automobile's speed and whet.her the robot should change
lanes The passing signal is converted to a lane assignment based on the car's current lane position The second block receives the lane assignment and data pertinent to the position and orientation of the vehicle with respect to the road The output is used to determine the steering angle
of the robot car
Block
Inputs
Outputs
Constant
Speed
Disl Ahead Pl
Disl Ahead Ol
Dist Behind Ol
ReI. Speed Ahead Pl
ReI. Speed Ahead Ol
ReI. Speed Behind Ol
I
Speed
Change lanes
Steering Angle
Convert lane change to lane number
Constant
Rei. Orientation
lane Nurmer
lateral Dist
Curvature
Figure The two blocks of the driving ANS network Heavy arrows Indicate total interconnectivity
between layers PL designates the traffic lane presently oca.apied by the robot vehicle Ol refers
to the other lane QJrvature refers to the road lane nurrber is either or relative orientation and
lateral distance refers to the robot car's direction and podion relative to the road'l direction and
center line respectively
The input data is displayed in pictorial and textual form to the driving instructor He views
the road and nearby vehicles from the perspective of the driver's seat or overhead The network
receives information in the form of a vector whose elements have been scaled to unitary order
Wide ranging input parameters like distance are compressed using the hyperbolic tangent
or logarithmic functions In each block the input layer is totally interconnected to both the ou
put and a hidden layer Our scheme trains in real time and as we discuss later it trains more
smoothly with a small modification of the training algorithm
Output is interpreted in two ways as a binary decision or as a continuously varying parameter The first simply compares the sigmoid output against a threshold The second scales the
output to an appropriate range for its application For example on the steering output element a
value is interpreted as a zero steering angle Left and right turns of varying degrees are initiated when this output is above or below respectively
The network is divided into two blocks that can be trained separately Beside being conceptually easier to understand we find this component approach is easy to train systematically
Because each block has a restricted well-defined set of tasks the trainer can concentrate
specifically on those functions without being concerned that other aspects of the network behavior
are deteriorating
trained the system from bottom up first teaching the network to stay on the road
negotiate curves chan~e lanes and how to return if the vehicle strayed off the highway Block
responsible for steering learned these skills in a few minutes using the master/apprentice mode
It tended to steer more slowly than a human but further training progressively improved its
responsiveness
We experimented with different trammg constants and momentum values Large
values about caused weights to change too coarsely values an order of magnitude smaller
worked well We found DO advantage in using momentum for this method of training in fact
the system responded about three times more slowly when than when the momentt:m
term was dropped Our standard training parameters were and Cl
Figure Typical behavior of a network-controlled vehicle dam rectangle when trained by
a conservative miYer ItI:I reckless driver Speed Is indicated by the length of the arrows
After Block Was trained we gave steering control to the network and concentrated on
teaching the network to change lanes and adjust speed Speed control in this was a continuous variable and was best taught using master/apprentice training On the other hand the binary
decision to change lanes was best taught by coaching About ten minutes of training were needed
to teach the network to weave through traffic We found that the network readily adapts the
behavioral pattern of its trainer A conservative trainer generated a network that hardly ever
passed while an aggressive trainer produced a network that drove recklessly and tended to cut off
other-cars Figure
Discussion
One of the strengths of el:pert 5ystf'mS based on ANS is that the use of input data in the
decision making and control proc~ss does not have to be specified The network adapts its internal weights to conform to input output correlat.ions it discovers It is important however that
data used by the human expert is also available to the network The different processing of sensor data for man and network may have important consequences key information may be
presented to the man but not the machine
This difference in data processing is particularly worrisome for image data where human
ability to extract detail is vastly superior to our au tomatic image processing capabilities Though
we would not require an image processing system to understand images it would have to extract
relevant information from cluttered backgrounds Until we have sufficiently sophisticated algorithms or networks to do this our efforts at constructing expert systems which halldle image data
are handicapped
Scaling input data to the unitary order of magnitude is important for training stability
is evident from equations and The sigmoid transfer function ranges from to in
approximat.eiy four units that is over an domain If system response must change in reaction to a large swing of a given input parameter the weight associated with that input will
be trained toward an magnitude On the other hand if the same system responds to an
input whose range is its associated weight will also be The weight adjustment equation does not recognize differences in weight magnitude therefore relatively small weights will
undergo wild magnitude adjustments and converge weakly On the other hand if all input parameters are of the same magnitude their associated weights will reflect this and the training constant
can be adjusted for gentle weight convergence Because the output of hidden units are constrained between zero and one is a good target range for input parameters Both the hyperbolic tangent and logarithmic functions are useful for scaling wide ranging inputs A useful form
of the latter is
if
ifx<-o
where and defines the limits of the intermediate linear section and is a scaling factor
This symmetric logarithmic function is continuous in its first derivative and useful when network
behavior should change slowly as a parameter increases without bound On the othl'r hand if the
system should approach a limiting behavior the tanh function is appropriate
Weight adaptation is also complicated by relaxing the common practice of restricting interconnections to adjacent layers Equation shows that the calculated error for a hidden layergiven comparable weights fanouts and output errors-will be one quarter or less than that of the
output layer This is caused by the slope ractor oil The difference in error magnitudes is
not noticeable in networks restricted to adjacent layer interconnectivity But when this constraint
is released the effect of errors originating directly from an output unit has times the magnitude
and effect of an error originating from a hidden unit removed layers from the output layer
Compared to the corrections arising from the output units those from the hidden units have little
influence on weight adjustment and the power of a multilayer structure is weakened The system
will train if we restrict connections to adjacent layers but it trains slowly To compensate for this
effect we attenuate the error magnitudes originating from the output layer by the above factor
This heuristic procedure works well and racilitates smooth learning
Though we have made progress in real-time learning systems using GDR compared to
humans-who can learn from a single data presentation-they remain relatively sluggish in learning
and response rates We are interested in improvements of the GDR algorithm or alternative
architectures that facilitate one-shot or rapid learning In the latter case we are considering least
squares restoration techniquesl4 and Grossberg and Carpenter's adaptive resonance modelsI3,5
The construction of automated expert systems by observation of human personnel is
attractive because of its efficient use of the expert's time and effort Though the classic AI
approach of rule base inference is applicable when such rules are clear cut and well organized too
often a human expert can not put his decision making process in words or specify the values of
parameters that influence him The attraction or ANS based systems is that imitations of expert
behavior emerge as a natural consequence of their training

<<----------------------------------------------------------------------------------------------------------------------->>

title: 48-a-neural-network-classifier-based-on-coding-theory.pdf

A Neural Network Classifier Based on Coding Theory
Tzt-Dar Chlueh and Rodney Goodman
eanrornla Instltute of Technology Pasadena eanromla
ABSTRACT
The new neural network classifier we propose transforms the
classification problem into the coding theory problem of decoding a noisy
codeword An input vector in the feature space is transformed into an internal
representation which is a codeword in the code space and then error correction
decoded in this space to classify the input feature vector to its class Two classes
of codes which give high performance are the Hadamard matrix code and the
maximal length sequence code We show that the number of classes stored in an
N-neuron system is linear in and significantly more than that obtainable by
using the Hopfield type memory as a classifier
I. INTRODUCTION
Associative recall using neural networks has recently received a great deal
of attention Hopfield in his papers deSCribes a mechanism which iterates
through a feedback loop and stabilizes at the memory element that is nearest the
input provided that not many memory vectors are stored in the machine He has
also shown that the number of memories that can be stored in an N-neuron
system is about for between and McEliece in their work
showed that for synchronous operation of the Hopfield memory about N/(2IogN
data vectors can be stored reliably when is large Abu-Mostafa has predicted
that the upper bound for the number of data vectors in an N-neuron Hopfield
machine is N. We believe that one should be able to devise a machine with the
number of data vectors linear in and larger than the achieved by the
Hopfield method
Feature Space
Code Space
Figure Classification problems versus Error control decoding problems
In this paper we are specifically concerned with the problem of
classification as in pattern recognition We propose a new method of building a
neural network classifier based on the well established techniques of error
control coding ConSider a typical classification problem in which one
is given a priori a set of classes a M. Associated with each class is a
feature vector which labels the class the exemplar of the class I.e. it is the
American Institute of Physics
most representative point in the class region The input is classified into the
class with the nearest exemplar to the input Hence for each class there is a
region in the N-dimensional binary feature space BN in which every
vector will be classified to the corresponding class
A similar problem is that of decoding a codeword in an error correcting
code as shown in In this case codewords are constructed by design and
are usually at least dmtn apart The received corrupted codeword is the input to
the decoder which then finds the nearest codeword to the input In principle
then if the distance between codewords is greater than 2t it is possible to
decode classify a noisy codeword feature vector into the correct codeword
exemplar provided that the Hamming distance between the noisy codeword and
the correct codeword is no more than Note that there is no guarantee that the
exemplars are uniformly distributed in BN. consequently the attraction radius
the maximum number of errors that can occur in any given feature vector such
that the vector can be correctly classified will depend on the minimum
distance between exemplars
Many solutions to the minimum Hamming distance classification have
been proposed the one commonly used is derived from the idea of matched filters
in communication theory Lippmann proposed a two-stage neural network
that solves this classification problem by first correlating the input with all
exemplars and then picking the maximum by a winner-take-all circuit or a
network composed of two-input comparators In Figure fI.f2 fN are the
input bits and SI.S2 SM are the matching score s(Similartty of with the
exemplars The second block picks the maximum of sI.S2 SM and produces the
index of the exemplar with the largest score The main disadvantage of such a
classifier is the complexity of the maximum-picking circuit for example a
winner-take-all net needs connection weights of large dynamic range and
graded-response neurons whilst the comparator maximum net demands M-I
comparators organized in log2M stages
A
DECODER~SS(f
I
cloSS(f
Feature
Space
Code
Space
A matched filter type classifier Structure of the proposed classifier
Our main idea is thus to transform every vector in the feature space to a
vector in some code space in such a way that every exemplar corresponds to a
codeword in that code The code should preferably but not necessarily have the
property that codewords are uniformly distributed in the code space that is the
Hamming distance between every pair of codewords is the same With this
transformation we turn the problem of classification into the coding problem of
decoding a noisy codeword We then do error correction decoding on the vector in
the code space to obtain the index of the noisy codeword and hence classify the
original feature vector as shown in Figure
This paper develops the construction of such a classification machine as
follows First we conSider the problem of transforming the input vectors from the
feature space to the code space We describe two hetero-associative memories for
dOing this the first method uses an outer product matrix technique Similar to
that of Hopfield's and the second method generates its matrix by the
pseudoinverse techruque[S.7J Given that we have transformed the problem of
associative recall or classification into the problem of decoding a noisy
codeword we next consider suitable codes for our machine We require the
codewords in this code to have the property of orthogonality or
pseudo-orthogonality that is the ratio of the cross-correlation to the
auto-correlation of the codewords is small We show two classes of such good
codes for this particular decoding problem the Hadamard matrix codes and
the maximal length sequence codes[8J We next formulate the complete decoding
algorithm and describe the overall structure of the classifier in terms of a two
layer neural network The first layer performs the mapping operation on the
input and the second one decodes its output to produce the index of the class to
which the input belongs
The second part of the paper is concerned with the performance of the
classifier We first analyze the performance of this new classifier by finding the
relation between the maximum number of classes that can be stored and the
classification error rate We show when using a transform based on the outer
product method that for negligible misclassification rate and large N. a not very
tight lower bound on M. the number of stored classes is We then present
comprehensive simulation results that confirm and exceed our theoretical
expectations The Simulation results compare our method with the Hopfield
model for both the outer product and pseudo-inverse method and for both the
analog and hard limited connection matrices In all cases our classifier exceeds
the performance of the Hopfield memory in terms of the number of classes that
can be reliably recovered
D. TRANSFORM TECHNIQUES
Our objective is to build a machine that can discriminate among input
vectors and classify each one of them into the appropriate class
Suppose
BN is the exemplar ofthe corresponding class a Given the
input we want the machine to be able to identify the class whose exemplar is
closest to that is we want to calculate the follOWing function
class
a
if
I I
I
I
where I I denotes Hamming distance in BN.
We approach the problem by seeking a transform that maps each
exemplar in BN to the corresponding codeword in BL. And an input
feature vector dey is thus mapped to a noisy codeword wlY where
is the error added to the exemplar and is the corresponding error pattern in the
code space We then do error correction decoding on to get the index of the
corresponding codeword Note that may not have the same Hamming weight as
that is the transformation may either generate more errors or eliminate
errors that are present in the original input feature vector We require to
satisfy the following equation
M-l
and
will be implemented uSing a Single-layer feedfoIWard network
Thus we first construct a matrix according to the sets of and call it
and define as
where sgn is the threshold operator that maps a vector in RL to BL and is the
field of real numbers
Let be an matrix whose lth column is and be an
matrix whose th column Is The two possible methods of constructing the
matrix for are as follows
Scheme A outer product method In this scheme the matrix Is
defined as the sum of outer products of all exemplar-codeword pairs
M-l
T(A)y
die
or equivalently
WDt
Scheme pseudo-Inverse method We want to find a matrix
satisfying the follOWing equation
In general is not a square matrix moreover may be singular so D-l
may not exist To circumvent this difficulty we calculate the pseudo-inverse
denoted Dt of the matrix instead of its real Inverse let DtD)-lDt can
be formulated as
Dt ot nt
CODES
The codes we are looking for should preferably have the property that its
codewords be distributed uniformly in BL that is the distance between each two
codewords must be the same and as large as pOSSible We thus seek classes of
eqUidistant codes Two such classes are the Hadamard matrix codes and the
maximal length sequence codes
First define the word pseudo-orthogonal
Defmition Let wO(a),Wl WL-l BL be the ath codeword of
code where a Code is said to be pseudo-orthogonal iff
L-l
Wl(a
where
where denotes inner product of two vectors
Hadamard Matrices An orthogonal code of length whose codewords are
rows or columns of an Hadamard matrix In this case and the
distance between any two codewords is L/2. It is conjectured that there exist such
codes for all which are multiples of thus providing a large class of codes[8
Mazlmal Length Sequence Codes There exists a family of maximal length
sequence also called pseudo-random or PN sequence codes(8 generated by shift
registers that satisfy pseudo-orthogonality with Suppose is a
primitive polynomial over OF of degree D. and let 2D and if
f(xl
l/g xl
ck xk
k=O
then CO.Cl is a periodic sequence of period since I If code is
made up of the cyclic shifts of
CO. cl Il
then code satisfies pseudo-orthogonality with One then easily sees that
the minimum distance of this code is which gives a correcting power of
approximately errors for large L.
IV. OVERALL CLASSIFIER STRUCTURE
We shall now describe the overall classifier structure essentially it
consists of the mapping followed by the error correction decoder for the
maximal length sequence code or Hadamard matrix code The decoder operates
by correlating the input vector with every codeword and then thresholding the
result at The rationale of this algorithm is as follows since the distance
between every two codewords in this code is exactly bits the decoder
should be able to correct any error pattern with less than errors if the
threshold is set halfway between Land I.e.
Suppose the input vector to the decoder is and has Hamming
weight nonzero components then we have
2s
2s
where a
From the above equation if is less than errors away from
then will be more than and will be
less than for all a As a result we arrive at the following decoding
algorithm
deax1e sgn
where which is an vector
In the case when and less than errors in the input the output
will be a vector in SM with only one component positive the index
of which is the index of the class that the input vector belongs However if there
are more than errors the output can be either the all negative vector
decoder failure or another vector with one pOSitive component(decoder error
The function class can now be defined as the composition of and decode
the overall structure of the new classifier is depicted in Figure It can be viewed
as a twO-layer neural network with hidden units and output neurons The
first layer is for mapping the input feature vector to a noisy codeword in the code
space the internal representation while the second one decodes the first's
output and produces the index of the class to which the input belongs
or
91
f1
f2
fN
9L
Figure
Overall architecture of the new neural network classifier
PERFORMANCE ANALYSIS
From the previous section we know that our classifier will make an error
only if the transformed vector in the code space which is the input to the decoder
has no less than errors We now proceed to find the error rate for this
classifier in the case when the input is one of the exemplars no error say
and an outer product connection matrix for Following the approach of
McEl1ece we have
N-l M-l
sgl
Wl(a dj(a
j=o a
N-l
sgn
M-l
Wl(a dl a
j=o a=O
Assume without loss of generality that and if
N-l
M-l
j=O
Wl(a dl a
a=o
then
Notice that we assumed all are random namely each component of
any is the outcome of a Bernoulli trial accordingly is the sum of
independent identically distributed random variables with mean and variance
In the asymptotic case when Nand are both very large can be
approximated by a normal distribution with mean variance NM. Thus
Pr
Q(vlN/M
where
vi TT
fOO
dt
Next we calculate the misclassification rate of the new classifier as follows
assuming
Pe
k=IL/4J
pk(l_p)L-k
where is the integer floor Since in generallt is not possible to express the
summation expliCitly we use the Chernoff method to bound Pe from above
Multiplying each term in the summation by a number larger than unity
et(k with and summing from instead of
Pe
t(k
k=O
Differentiating the RHS of the above equation and set it to we find
the optimal to as eto The condition that to implies that
and since we are dealing with the case where is small it is automatically
satisfied Substituting the optimal to we obtain
where
From the expression for Pe we can estimate the number of classes that
can be classified with negllgible misclassification rate in the following way
suppose Pe where land then
For small we have Log and since is a fixed value as
approaches infinity we have
From the above lower bound for one easily see that this new machlne is able to
classify a constant times classes which is better than the number of memory
items a Hopfield model can store Le. Although the analysis is done
assumlng approaches lnfinlty the simulation results in the next section show
that when is moderately large the above lower bound applles
VI. SIMULATION RESULTS AND A CHARACTER RECOGNITION EXAMPLE
We have Simulated both the Hopfield model and our new machine(using
maxlmallength sequence codes for 63 and for the following four cases
respectively
connection matrix generated by outer product method
connection matrix generated by pseudo-inverse method
ill connection matrix generated by outer product method the components of the
connection matrix are hard limited
connection matrix generated by pseudo-inverse method the components of
the connection matrix are hard limited
For each case and each choice of N. the program fixes and the number of
errors in the input vector then randomly generates sets of exemplars and
computes the connection matrix for each machine For each machine it
randomly picks an exemplar and adds nOise to it by randomly complementing
the specified number of bits to generate trial input vectors it then simulates
the machine and checks whether or not the input is classified to the nearest class
and reports the percentage of success for each machine
The simulation results are shown in Figure in each graph the hOrizontal
axis is and the vertical axis is the attraction radius The data we show are
obtained by collecting only those cases when the success rate is more than
that is for fixed what is the largest attraction radius number of bits in error of
the input vector that has a success rate of more than Here we use the
attraction radiUS of to denote that for this particular M. with the input being
an exemplar the success rate is less than in that machine
Hopfield Model
New Classifier{Op
New Classtfier{PI
Analog Connection Matrix
Binary Connection Matrix
CIl
23
a 18 It lit
tD
I.
23
en
tl.a
Binary Connection Matrix
13
17
Analog Connection Matrix
19
17
13
23
27
31
35 39 43
47 51
55
59
83
23
27
31
35
39 43
47 61
Figure Simulation results of the Hopfield memory and the new classifier
Hopfield Model
New Classifier(OP.L=63
New Classifier(OP.L=31
23
19
17
rIl
u.a
13
13
17
19
23
27
29
31
Figure Perfonnance of the new classifier using codes of different lengths
In all cases our classifier exceeds the perfonnance of the Hopfield model
in tenns of the number of classes that can be reliably recovered For example
consider the case of 63 and a hard limited connection matrix for both the new
classifier and the Hopfield model we find that for an attraction radius of zero
that is no error in the input vector the Hopfield model has a classification
capacity of approximately while our new model can store 47 Also for an
attraction radius of that is an average of errors in the input vector the
Hopfield model can reliably store classes while our new model stores 27
classes Another Simulation USing a shorter code 31 instead of
reveals that by shortening the code the performance of the classifier degrades
only slightly We therefore conjecture that it is pOSSible to use traditional error
correcting codes BCH code as internal representations however by going to
a higher rate code one is trading minimum distance of the code error tolerance
for complexity number of hidden units which implies pOSSibly poorer
performance of the classifier
We also notice that the superiority of the pseudoinverse method over the
outer product method appears only when the connection matrices are hard
limited The reason for this is that the pseudOinverse method is best for
decorrelating the dependency among exemplars yet the exemplars in this
simulation are generated randomly and are presumably independent
consequently one can not see the advantage of pseudoinverse method For
correlated exemplars we expect the pseudoinverse method to be clearly better
next example
Next we present an example of applying this classifier to recognizing
characters Each character is represented by a pixel array the input is
generated by flipping every pixel with and probability The input is then
passed to five machines Hopfield memory the new classifier with either the
pseudotnverse method or outer product method and or 31 Figure and
show the results of all machines for and pixel flipping probability
respectively a blank output means that the classifier refuses to make a decision
First note that the case is not necessarily worse than the case this
confirms the earlier conjecture that fewer hidden units shorter code only
degrades perfonnance slightly Also one eaSily sees that the pseudoinverse
method is better than the outer product method because of the correlation
between exemplars Both methods outperform the Hopfield memory since the
latter mixes exemplars that are to be remembered and produces a blend of
exemplars rather than the exemplars themselves accordingly it cannot classify
the input without mistakes
tF
Figure The character recognition
example with pixel reverse
probability input correct
output Hopfield Model new
classifier OP
PI PI 31
Figure The character recognition
example with pixel reverse
probability input correct
output Hopfield Model new
classifier OP
PI. PI. 31
Vll. CONCLUSION
In this paper we have presented a new neural network classifier design
based on coding theory techniques The classifier uses codewords from an error
correcting code as its internal representations Two classes of codes which give
high performance are the Hadamard matrix codes and the maximal length
sequence codes In penormance terms we have shown that the new machine is
significantly better than using the Hopfield model as a classifier We should also
note that when comparing the new classifier with the Hopfield model the
increased performance of the new classifier does not entail extra complexity
since it needs only hard limiter neurons and L(N connection weights
versus neurons and N2 weights in a Hopfield memory
In conclusion we believe that our model forms the basis of a fast practical
method of classification with an effiCiency greater than other previOUS neural
network techniques

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 54-a-method-for-the-design-of-stable-lateral-inhibition-networks-that-is-robust-in-the-presence-of-circuit-parasitics.pdf

A METHOD FOR THE DESIGN OF STABLE LATERAL INHIBITION
NETWORKS THAT IS ROBUST IN THE PRESENCE
OF CIRCUIT PARASITICS
J.L. WYATT Jr and D.L. STANDLEY
Department of Electrical Engineering and Computer Science
Massachusetts Institute of Technology
Cambridge Massachusetts
ABSTRACT
In the analog VLSI implementation of neural systems it is
sometimes convenient to build lateral inhibition networks by using
a locally connected on-chip resistive grid A serious problem
of unwanted spontaneous oscillation often arises with these
circuits and renders them unusable in practice This paper reports
a design approach that guarantees such a system will be stable
even though the values of designed elements and parasitic elements
in the resistive grid may be unknown The method is based on a
rigorous somewhat novel mathematical analysis using Tellegen's
theorem and the idea of Popov multipliers from control theory It
is thoroughly practical because the criteria are local in the sense
that no overall analysis of the interconnected system is required
empirical in the sense that they involve only measurable frequency
response data on the individual cells and robust in the sense that
unmodelled parasitic resistances and capacitances in the interconnection network cannot affect the analysis
I.
INTRODUCTION
The term lateral inhibition first arose in neurophysiology to
describe a common form of neural circuitry in which the output of
each neuron in some population is used to inhibit the response of
each of its neighbors Perhaps the best understood example is the
horizontal cell layer in the vertebrate retina in which lateral
inhibition simultaneously enhances intensity edges and acts as an
automatic lain control to extend the dynamic range of the retina
as a whole The principle has been used in the design of artificial
neural system algorithms by Kohonen and others and in the electronic
design of neural chips by Carver Mead
In the VLSI implementation of neural systems it is convenient
to build lateral inhibition networks by using a locally connected
on-chip resistive grid Linear resistors fabricated in
polysilicon yield a very compact realization and nonlinear
resistive grids made from MOS transistors have been found useful
for image segmentation Networks of this type can be divided into
two classes feedback systems and feedforward-only systems In the
feedforward case one set of amplifiers imposes signal voltages or
American Institute of Physics
currents on the grid and another set reads out the resulting response
for subsequent processing while the same amplifiers both write to
the grid and read from it in a feedback arrangement Feedforward
networks of this type are inherently stable but feedback networks
need not be
A practical example is one of Carver Meadls retina chips3 that
achieves edge enhancement by means of lateral inhibition through a
resistive grid Figure shows a single cell in a continuous-time
version of this chip Note that the capacitor voltage is affected
both by the local light intensity incident on that cell and by the
capacitor voltages on neighboring cells of identical design Any
cell drives its neighbors which drive both their distant neighbors
and the original cell in turn Thus the necessary ingredients for
instability--active elements and signal feedback--are both present
in this system and in fact the continuous-time version oscillates
so badly that the original design is scarcely usable in practice
with the lateral inhibition paths enabled Such oscillations can
I
incident
light
out
Figure This photoreceptor and signal processor Circuit using two
MOS transconductance amplifiers realizes lateral inhibition by
communicating with similar units through a resistive grid
readily occur in any resistive grid circuit with active elements and
feedback,even when each individual cell is quite stable Analysis
of the conditions of instability by straightforward methods appears
hopeless since any repeated array contains many cells each of
which influences many others directly or indirectly and is influenced
by them in turn so that the number of simultaneously active feedback loops is enormous
This paper reports a practical design approach that rigorously
guarantees such a system will be stable The very simplest version
of the idea is intuitively obvious design each individual cell so
that although internally active it acts like a passive system as
seen from the resistive grid In circuit theory language the
design goal here is that each cellis output impedance should be a
positive-real function This is sometimes not too difficult in
practice we will show that the original network in satisfies
this condition in the absence of certain parasitic elements More
important perhaps it is a condition one can verify experimentally
by frequency-response measurements
It is physically apparent that a collection of cells that
appear passive at their terminals will form a stable system when
interconnected through a passive medium such as a resistive grid
The research contributions reported here in summary form are
a demonstration that this passivity or positive-real condition
is much stronger than we actually need and that weaker conditions
more easily achieved in practice suffice to guarantee stability of
the linear network model and ii an extension of to the nonlinear
domain that furthermore rules out large-signal oscillations under
certain conditions
II.
FIRST-ORDER LINEAR ANALYSIS OF A SINGLE CELL
We begin with a linear analysis of an elementary model for the
circuit in For an initial approximation to the output
admittance of the cell we simplify the topology without loss of
relevant information and use a naive'model for the transconductance
amplifiers as shown in
Figure Simplified network topology and transconductance amplifier
model for the circuit in The capacitor in has been
absorbed into CO2
Straightforward calculations show that the output admittance is
given by
yes
This is a positive-real passive admittance since it can always
be realized by a network of the form shown in where
Ro2 gmlgm2Rol
and COI/gmlgm2
Although the original circuit contains no inductors the
realization has both capacitors and inductors and thus is capable
of damped oscillations Nonetheless the transamp model in
were perfectly accurate no network created by interconnecting
such cells through a resistive grid with parasitic capacitances
could exhibit sustained oscillations For element values that may
be typical in practice the model in has a lightly damped
resonance around I KHz with a This disturbingly high
suggests that the cell will be highly sensitive to parasitic elements
not captured by the simple models in Our preliminary
Rl
yes
Figure Passive network realization of the output admittance
of the circuit in
analysis of a much more complex model extracted from a physical
circuit layout created in Carver Mead's laboratory indicates that
the output impedance will not be passive for all values of the transamp bias currents But a definite explanation of the instability
awaits a more careful circuit modelling effort and perhaps the design
of an on-chip impedance measuring instrument
III.
POSITIVE-REAL FUNCTIONS e-POSITlVE FUNCTIONS AND
STABILITY OF LINEAR NETWORK MODELS
In the following discussion cr+jw is a complex variable
is a rational function ratio of polynomials in with real
coefficients and we assume for simplicity that has no pure
imaginary poles The term closed right halE plane refers to the set
of complex numbers with Re{s
Def. I
The function is said to be positive-real if it has no
poles in the right half plane and Re{H(jw for all
If we know at the outset that has no right half plane poles
then Def. I reduces to a simple graphical criterion is positivereal if and only if the Nyquist diagram of the plot of
H(jW for as in lies entirely in the closed right half
plane
Note that positive-real functions are necessarily stable since
they have no right half plane poles but stable functions are not
necessarily positive-real as Example will show
A deep link between positive real functions physical networks
and passivity is established by the classical result in linear
circuit theory which states that is positive-real if and only if
it is possible to synthesize a 2-terminal network of positive linear
resistors capacitors inductors and ideal transformers that has
as its driving-point impedance or admittance
Oef.
The function is said to be a-positive for a particular value
of e(e if has no poles in the right half plane
and the Nyquist plot of lies strictly to the right of the
straight line passing through the origin at an angle a to the real
positive axis
Note that every a-positive function is stable and any function
that is e-positive with is necessarily positive-real
I
Re{G(jw
Figure Nyquist diagram for a fUnction that is a-positive but
not positive-real
Example
The function
is a-positive for any between about and and stable but it
is not positive-real since its Nyquist diagram shown in
crosses into the left half plane
The importance of e-positive functions lies in the following
observations an interconnection of passive linear resistors and
capacitors and cells with stable linear impedances can result in an
unstable network such an instability cannot result if the
impedances are also positive-real a-positive impedances form a
larger class than positive-real ones and hence a-positivity is a less
demanding synthesis goal and Theorem below shows that such an
instability cannot result if the impedances are a-positive even if
they are not positive-real
Theorem
Consider a linear network of arbitrary topology consisting of
any number of passive 2-terminal resistors and capacitors of arbitrary
value driven by any number of active cells If the output impedances
of all the active cells are a-positive for some common a 22
then the network is stable
The proof of Theorem relies on Lemma below
Lemma
If is a-positive for some fixed a then for all So in the
closed first quadrant of the complex plane H(so lies strictly to
the right of the straight line passing through the origin at an angle
a to the real positive axis Re{so and Im{so
a
Proof of Lemma Outline
Let be the function that assigns to each in the closed right
half plane the perpendicular distance des from to the line
defined in Def. Note that des is harmonic in the closed right
half plane since is analytic there It then follows by application
of the maximum modulus principle8 for harmonic functions that takes
its minimum value on the boundary of its domain which is the
imaginary axis This establishes Lemma
Proof of Theorem OUtline
The network is unstable or marginally stable if and only if it
has a natural frequency in the closed right half plane and So is a
natural frequency if and only if the network equations have a nonzero
solution at so Let denote the complex branch currents Of such
a solution By Tellegen I theorern9 the sum of the complex powers
absorbed by the circuit elements must vanish at such a solution
IIk12/s0Ck
capac~tances
cell
terminal pairs
where the second term is deleted in the special case so=O since the
complex power into capacitors vanishes at so=O
If the network has a natural frequency in the closed right half
plane it must have one in the closed first quadrant since natural
frequencies are either real or else occur in complex conjugate pairs
But cannot be satisfied for any So in the closed first quadrant
as we can see by dividing both sides of by
IIkI2 where the
sum is taken over all network branches After this division
asserts that zero is a convex combination of terms of the form Rk
terms of the form CkSo)-I and terms of the form Zk(So
Visualize where these terms lie in the complex plane the first set lies
on the real positive axis the second set lies in the closed
adrant since So lies in the closed 1st quadrant by assumption and
the third set lies to the right of a line passing through the origin
at an angle a by Lemma Thus all these terms lie strictly to the
right of this line which implies that no convex combination of them
can equal zero Hence the network is stable
IV.
STABILITY RESULT FOR NETWORKS WITH NONLINEAR
RESISTORS AND CAPACITORS
The previous result for linear networks can afford some limited
insight into the behavior of nonlinear networks First the nonlinear
equations are linearized about an equilibrium point and Theorem is
applied to the linear model If the linearized model is stable then
the equilibrium point of the original nonlinear network is locally
stable the network will return to that equilibrium point if
the initial condition is sufficiently near it But the result in this
section in contrast applies to the full nonlinear circuit model and
allows one to conclude that in certain circumstances the network
cannot oscillate even if the initial state is arbitrarily far from
the equilibrium point
Def.
A function as described in Section III is said tc satisfy
the Popov criterion lO if there exists a real number r>O such that
Re{(l+jwr for all
Note that positive real functions satisfy the Popov criterion
with And the reader can easily verify that in Exam~le I
satisfies the Popov criterion for a range of values of The important
effect of the term l+jwr in Def. is to rotate the Nyquist plot
counterclockwise by progressively greater amounts up to as
increases
Theorem
Consider a network consisting of nonlinear 2-terminal resistors
and capacitors and cells with linear output impedances Suppose
the resistor curves are characterized by continuously
diffefentiable functions gk(vk where gk(O and
gk(vk for all values of and vk
ii the capacitors are characterized by Ck(Vk)~k with
CI Ck(v C2 for all values of and vk
iii the impedances Zk(s have no poles in the closed right
half plane and all satisfy the Popov criterion for some common
value of
If these conditions are satisfied then the network is stable in the
sense that for any initial condition
oo
I
all branches
dt
The proof based on Tellegen's theorem is rather involved
will be omitted here and will appear elsewhere
It
ACKNOWLEDGEMENT
We sincerely thank Professor Carver Mead of Cal Tech for
enthusiastically supporting this work and for making it possible for
us to present an early report on it in this conference proceedings
This work was supportedJ Defense Advanced Research Projects Agency
through the Office of Naval Research under ARPA Order No.
Contract No. and Defense Advanced Research
Projects Agency DARPA Contract No.

<<----------------------------------------------------------------------------------------------------------------------->>

title: 49-connecting-to-the-past.pdf

CONNECTING TO THE PAST
Bruce A. MacDonald Assistant Professor
Knowledge Sciences Laboratory Computer Science Department
The University of Calgary University Drive NW
Calgary Alberta T2N IN4
ABSTRACT
Recently there has been renewed interest in neural-like processing systems evidenced for example in the two volumes Parallel Distributed Processing edited by Rumelhart and McClelland
and discussed as parallel distributed systems connectionist models neural nets value passing
systems and multiple context systems Dissatisfaction with symbolic manipulation paradigms
for artificial intelligence seems partly responsible for this attention encouraged by the promise
of massively parallel systems implemented in hardware This paper relates simple neural-like
systems based on multiple context to some other well-known formalisms-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier sequence prediction results in a new light
INTRODUCTION
The revival of neural net research has been very strong exemplified recently by Rumelhart
and McClelland new journals and a number of meetings The nets are also described as
parallel distributed systems connectionist models value passing systems3 and multiple context
learning systems4 The symbolic manipulation paradigm for artificial intelligence does
not seem to have been as successful as some hoped and there seems at last to be real promise
of massively parallel systems implemented in hardware However in the flurry of new work it
is important to consolidate new ideas and place them solidly alongside established ones This
paper relates simple neural-like systems to some other well-known notions-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier results on the abilities of such networks in a new light
The general form of a connectionist system lO is simplified to a three layer net with binary
fixed weights in the hidden layer thereby avoiding many of the difficulties-and challengesof the recent work on neural nets The hidden unit weights are regularly patterned using a
template Sophisticated expensive learning algorithms are avoided and a simple method is
used for determining output unit weights In this way we gain some of the advantages of multilayered nets while retaining some of the simplicity of two layer net training methods Certainly
nothing is lost in computational power-as I will explain-and the limitations of two layer
nets are not carried over to the simplified three layer one Biological systems may similarly
avoid the need for learning algorithms such as the simulated annealing method commonly
used in connectionist models For one thing biological systems do not have the same clearly
distinguished training phase
Briefly the simplified net is a production system implemented as three layers of neuron-like
units an output layer an input layer and a hidden layer for the productions themselves Each
hidden production unit potentially connects a predetermined set of inputs to any output A
k-Iength sequence predictor is formed once Ie levels of delay unit are introduced into the input
layer k-Iength predictors are unable to distinguish simple sequences such as ba a and aa a
since after Ie or more characters the system has forgotten whether an a or appeared first If
the k-Iength predictor is augmented with auxiliary actions it is able to learn this and other
regular languages since the auxiliary actions can be equivalent to states and can be inputs to
aAmong them the 1st International Conference on Neural Nets San Diego,CA June and this
con.ference
bRoughly equivalent to a single context system in Andreae's multiple context system See also
MacDonald
@
American Institute of Physics
Figure The general form of a connectionist system
Form of a unit
Operations within a unit
in~uts excitation-.I
weIghts
sum
aCtiVation--W output
Typical
Typical
the production units enabling predictions to depend on previous states By combining several
augmented sequence predictors a Thring machine tape can be simulated along with a finite-state
controller giving the net the computational power of a Universal Turing machine Relatively
simple neural-like systems do not lack computational ability Previous implementations of
this ability are production system equivalents to the simplified nets
Organization of the paper
The next section briefly reviews the general form of connectionist systems Section simplifies
this then section explains that the result is equivalent to a production system dealing only
with inputs and outputs of the net Section extends the simplified version enabling it to learn
to predict sequences Section explains how the computational power of the sequence predictor
can be increased to that of a Thring machine if some input units receive auxiliary actions in fact
the system can learn to be a TUring machine Section discusses the possibility of a number of
nets combining their outputs forming an overall net with association areas
General form of a connectionist system
Figure shows the general form of a connectionist system unit neuron or ce1l In the figure
unit has inputs which are the outputs OJ of possibly all units in the network and an output of
its own The net input excitation net is the weighted sum of inputs where Vij is the weight
connecting the output from unit as an input to unit The activation of the unit is some
function Fi of the net input excitation Typically Fi is semilinear that is non-decreasing and
differentiable 13 and is the same function for all or at least large groups of units The output is
a function fi of the activation typically some kind of threshold function I will assume that the
quantities vary over discrete time steps so for example the activation at time is
and is given by Fi((neti(t
In general there is no restriction on the connections that may be made between units
Units not connected directly to inputs or outputs are hidden units In more complex nets
than those described in this paper there may be more than one type of connection Figure
shows a common connection topology where there are three layers of units-input hidden and
output-with no cycles of connection
The net is trained by presenting it with input combinations each along with the desired
output combination Once trained the system should produce the desired outputs given just
Figure The basic structure of a three layer connectionist system
input units
hidden
units
output units
inputs During training the weights are adjusted in some fashion that reduces the discrepancy
between desired and actual output The general method is lO
where is the desired training activation Equation is a general form of Hebb's classic
rule for adjusting the weight between two units with high activations lO The weight adjustment
is the product of two functions one that depends on the desired and actual activations--often
just the difference-and another that depends on the input to that weight and the weight itself
As a simple example suppose is the difference and as just the output OJ. Then the weight
change is the product of the output error and the input excitation to that weight
where the constant determines the learning rate This is the Widrow-Hoff or Delta rule which
may be used in nets without hidden units 1o
The important contribution of recent work on connectionist systems is how to implement
equation in hidden units for which there are no training signals ti directly available The
Boltzmann learning method iteratively varies both weights and hidden unit training activations
using the controlled gradually decreasing randomizing method simulated annealing Backpropagation 13 is also iterative performing gradient descent by propagating training signal errors
back through the net to hidden units I will avoid the need to determine training signals for
hidden units by fixing the weights of hidden units in section below
SIMPLIFIED SYSTEM
Assume these simplifications are made to the general connectionist system of section
The system has three layers with the topology shown in Figure ie no cycles
All hidden layer unit weights are fixed say at unity or zero
Each unit is a linear threshold unit lO which means the activation function for all units
is the identity function giving just net a weighted sum of the inputs and the output
function is a simple binary threshold of the form
I
output
threshold
activation
so that the output is binary on or oft Hidden units will have thresholds requiring all
inputs to be active for the output to be active like an AND gate while output units will
have thresholds requiring only or two active highly weighted inputs for an output to be
generated like an OR gate This is in keeping with the production system view of the
net explained in section
Learning-which now occurs only at the output unit weights-gives weight adjustments
according to
Wij
Wij
if
OJ
otherwise
so that weights are turned on if their input and the unit output are on and off otherwise
That is Wij A OJ. A simple example is given in Figure in section below
This simple form of net can be made probabilistic by replacing with below
Adjust weights so that Wij estimates the conditional probability of the unit output being
on when output is on That is
Wij
estimate of P(odoj
Then assuming independence of the inputs to a unit an output unit is turned on when the
conditional probability of occurrence of that output exceeds the threshold of the output
function
Once these simplifications are made there is no need for learning in the hidden units Also no
iterative learning is required weights are either assigned binary values or estimate conditional
probabilities This paper presents some of the characteristics of the simplified net Section
discusses the motivation for simplifying neural nets in this way
PRODUCTION SYSTEMS
The simplified net is a kind of simple production system A production system comprises a
global database a set of production rules and a control system The database for the net is
the system it interacts with providing inputs as reactions to outputs from t.he net The hidden
units of the network are the production rules which have the form
IF
precondition
THEN
action
The precondition is satisfied when the input excitation exceeds the threshold of a hidden unit
The actions are represented by the output units which the hidden production units activate
The control system of a production system chooses the rule whose action to perform from the
set of rules whose preconditions have been met In a neural net the control system is distributed
throughout the net in the output units For example the output units might form a winner-takeall net In production systems more complex control involves forward and backward chaining to
choose actions that seek goals This is discussed elsewhere4.12.16 Figure illust.rates a simple
production implemented as a neural net As the figure shows the inputs to hidden units are
just the elements of the precondition When the appropriate input combination is present the
associated hidden production unit is fired Once weights have been leamed connecting hidden
units to output units firing a production results in output The simplified neural net is directly
equivalent to a production system whose elements are inputs and outputs
Some production systems have symbolic elements such as variables which can be given
values by production actions The neural net cannot directly implement this since it can
have outputs only from a predetermined set However we will see later that extensions t.o the
framework enable this and other abilities
CThis might be referred to as a sensory-motor production system since when implemented ill a l'eal system
such as a robot it deals only with sensed inputs and executable motor actions which may include the auxiliary
actions of section
Figure A production implemented in a simplified neural net
A production rule
IF
Icloudy I Ipressure falling I
AND
THEN
Iit will rain I
The rule implemented as a hidden unit The threshold of the hidden unit is so it is
an AND gate The threshold of the output unit is so it is an OR gate The learned
weight will be or if the net is not probabilistic otherwise it will be an estimate of
P(it will rainlclouds AND pressure falling
It will
rain
weight
Figure A net that predicts the next character in a sequence based on only the last character
The net Production units hidden units have been combined with input units
For example this net could predict the sequence abcabcabc Productions have the
form IF last character is THEN next character will be The learning rule is
Wij
if inputj AND outputi Output is
WijOj
input
neural net
output
a
a
Learning procedure
Clamp inputs and outputs to desired values
System calculates weight values
Repeat and for all required input/output combinations
SEQUENCE PREDICTION
A production system or neural net can predict sequences Given examples of a repeating sequence productions are learned which predict future events on the basis of recent ones Figure
shows a trivially simple sequence predictor It predicts the next character of a sequence based
on the previous one The figure also gives the details of the learning procedure for the simplified
net The net need be trained only once on each input combination then it will predict as
an output every character seen after the current one The probabilistic form of the net would
estimate conditional probabilities for the next character conditional on the current one Many
Figure Using delayed inputs a neural net can implement a k-length sequence predictor
A net with the last three characters as input
input
hidden
output
a
a
a
2nd last
An example production
IF
last three characters were THEN
presentations of each possible character pair would be needed to properly estimate the probabilities The net would be learning the probability distribution of character pairs A predictor like
the one in Figure can be extended to a general k-Iength 17 predictor so long as inputs delayed
by steps are available Then as illustrated in Figure for 3-length prediction hidden
production units represent all possible combinations of symbols Again output weights are
trained to respond to previously seen input combinations here of three characters These delays
can be provided by dedicated neural nets such as that shown in Figure Note that the net
is assumed to be synchronously updated so that the input from feedback around units is not
changed until one step after the output changes There are various ways of implementing delay
in neurons and Andreae investigates some of them for the same purpose-delaying inputs-in
a more detailed simulation of a similar net
Other work on sequence prediction in neural nets
Feldman and Ballard find connectionist systems initially not suited to representing changes
with time One form of change is sequence and they suggest two methods for representing
sequence in nets The first is by units connected to each other in sequence so that sequential
tasks are represented by firing these units in succession The second method is to buffer the
inputs in time so that inputs from the recent past are available as well as current inputs that
is delayed inputs are available as suggested above An important difference is the necessary
length of the buffer Feldman and Ballard suggest the buffer be long enough to hold a phrase of
natural language but I expect to use buffers no longer than about after Andreae Symbolic
inputs can represent more complex information effectively giving the length seven buffers more
information than the most recent seven simple inputs as discussed in section
The method of back-propagation13 enables recurrent networks to learn sequential tasks in a
dFeldman and Ballard2 give some dedicated neural net connections for a variety of flUlctions
Figure Inputs can be delayed by dedicated neural subnets A two stage delay is shown
Delay network
Timing diagram for
tml
A
original signal
delay of one step
delay of two steps
manner similar to the first suggestion in the last paragraph where sequences of connected units
represent sequenced events In one example a net learns to complete a sequence of characters
when given the first two characters of a six character sequence the next four are output Errors
must be propagated around cycles in a recurrent net a number of times
Seriality may also be achieved by a sequence of states of distributed activation 18 An example
is a net playing both sides of a tic-tac-toe game 18 The sequential nature of the net's behavior is
derived from the sequential nature of the responses to the net's actions tic-tac-toe moves A net
can model sequence internally by modeling a sequential part of its environment For example
a tic-tac-toe playing net can have a model of its opponent
k-Iength sequence predictors are unable to learn sequences which do not repeat more frequently that every characters Their k-Iength context includes only information about the last
events However there are two ways in which information from before the kth last input can
be retained in the net The first method latches some inputs while the second involves auxiliary
actions
Latch units
Inputs can be latched and held indefinitely using the combination shown in Figure Not all
inputs would normally be latched Andreae discusses this technique of threading latched
events among non-latched events giving the net both information arbitrarily far back in its
input-output history and information from the immediate past Briefly the sequence ba a
can be distinguished from aa a if the first character is latched However this is an ad hoc
solution to this problem
Auxiliary actions
When an output is fed back into the net as an input signal this enables the system to choose the
next output at least partly based on the previous one as indicated in Figure If a particular
fed back output is also one without external manifestation or whose external manifestation
is independent of the task being performed then that output is an auxiliary action It Las
The interested reader should refer to Andreae where more extensive analysis is given
Figure Threading A latch circuit remembers an event until another comes along This is a
two input latch for two letters a and but any number of units may be similarly connected
It is formed from a mutual inhibition layer or winner-take-all connection along with positive
feedback to keep the selected output activated when the input disappears
a
Figure Auxiliary actions-the outputs-are fed back to the inputs of a net enabling the
net to remember a state Here both part of a net and an example of a production are shown
There are two types of action characters and actions
Sinputs
outputs
character inputs
IF
input is
and character input is
character outputs
THEN
output character
lliJ and ill
no direct effect on the task the system is performing since it evokes no relevant inputs and
so can be used by the net as a symbolic action If an auxiliary action is latched at the input
then the symbolic information can be remembered indefinitely being lost only when another
auxiliary action of that kind is input and takes over the latch Thus auxiliary actions can act
like remembered states the system performs an action to remind itself to be in a particular
state The figure illustrates this for a system that predicts characters and state changes given
the previous character and state An obvious candidate for auxiliary actions is speech So
the blank oval in the figure would represent the net's environment through which its own
speech actions are heard Although it is externally manifested speech has no direct effect on
our physical interactions with the world Its symbolic ability not only provides the power of
auxiliary actions but also includes other speakers in the interaction
SIMULATING ABSTRACT AUTOMATA
The example in Figure gives the essence of simulating a finite state automaton with a production system or its neural net equivalent It illustrates the transition function of an automaton
the new state and output are a function of the previous state and input Thus a neural net can
simulate a finite state automaton so long as it has additional auxiliary actions
A Thring machine is a finite state automaton controller plus an unbounded memory A
neural net could simulate a lUring machine in two ways and both ways have been demonstrated
with production system implementations-equivalent to neural nets----(;alled multiple context
learning systems briefly explained in section The first Thring machine simulation has the
system simulate only the finite state controller but is able to use an unbounded external memory
fSee John Andreae's and his colleagues work4
Figure Multiple context learning system implementation as multiple neural nets Each:3
layer net has the simplified form presented above with a number of elaborations such as extra
connections for goal-seeking by forward and backward chaining
Output
channels
from the real world much like the paper of Turing's original work 19 The second simnlat.ion
embeds the memory in the multiple context learning system along with a counter for accessing
this simulated memory Both learn all the productions-equivalent to learning output unit
weights-required for the simulations The second is able to add internal memory as required
up to a limit dependent on the size of the network which can easily be large enough to allow 70
years of computation The second could also employ external memory as the first did Briefly
the second simulation comprised multiple sequence predictors which predicted auxiliary actions
for remembering the state of the controller and the current memory position The memory
element is updated by relearning the production representing that element the precondition is
the address and the production action the stored item
MULTIPLE SYSTEMS FORM ASSOCIATION AREAS
A multiple context learning system is production system version of a multiple neural net although a simple version has been implemented as a simulated net It effectively comprises
several nets--or association areas-which may have outputs and inputs in common as indicated in Figure Hidden unit weights are specified by templates one for each net A template
gives the inputs to have a zero weight for the hidden units of a net and the inputs to have a
weight of unity Delayed and latched inputs are also available The actual outputs are selected
from the combined predictions of the nets in a winner-take-all fashion
I see the design for real neural nets say as controllers for real robots requiring a large
degree of predetermined connectivity A robot controller could not be one three layer net wit.h
every input connected to every hidden unit in turn connected to every output There will
need to be some connectivity constraints so the net reflects the functional specialization in the
control requirements The multiple context learning system has all the hidden layer connections
predetermined but allows output connections to be learned This avoids the credit assignment
problem and therefore also the need for learning algorithms such as Boltzmann learning and
back-propagation However as the multiple context learning system has auxiliary actions and
delayed and latched inputs it does not lack computational power Future work in this area
should investigate for example the ability of different kinds of nets to learn auxiliary act.ions
This may be difficult as symbolic actions may not be provided in training inputs and output.s
For
example a controller for a robot body would have to deal with vision manipulation motion etc
CONCLUSION
This paper has presented a sImplified three layer connectionist model with fixed weights for
hidden units delays and latches for inputs sequence prediction ability auxiliary state actions
and the ability to use internal and external memory The result is able to learn to simulate a
Turing machine Simple neural-like systems do not lack computational power
ACKNOWLEDGEMENTS
This work is supported by the Natural Sciences and Engineering Council of Canada

<<----------------------------------------------------------------------------------------------------------------------->>

title: 52-teaching-artificial-neural-systems-to-drive-manual-training-techniques-for-autonomous-systems.pdf

Teaching Artificial Neural Systems to Drive
Manual Training Techniques for Autonomous Systems
J. F. Shepanski and S. A. Macy
TRW Inc
One Space Park
Redondo Beach CA
Abetract
We have developed a methodology for manually training autononlous control systems
based on artificial neural systems In applications where the rule set governing an expert's
decisions is difficult to formulate ANS can be used to ext.ra.c:t rules by associating the information
an expert receives with the actions takes Properly constructed networks imitate rules of
behavior that permits them to function autonomously when they are trained on the spanning set
of possible situations This training can be provided manually either under the direct supervision
or a system trainer or indirectly using a background mode where the network assimilates training
data as the expert perrorms his day-to-day tasks To demonstrate these methods we have trained
an ANS network to drive a vehicle through simulated rreeway traffic
I ntJooducticn
Computational systems employing fine grained parallelism are revolutionizing the way we
approach a number or long standing problems involving pattern recognition and cognitive processing The field spans a wide variety or computational networks rrom constructs emulating neural
runctions to more crystalline configurations that resemble systolic arrays Several titles are used
to describe this broad area or research we use the term artificial neural systems Our concern in this work is the use or ANS ror manually training certain types or autonomous systems
where the desired rules of behavior are difficult to rormulate
Artificial neural systems consist of a number or processing elements interconnected in a
weighted user-specified fashion the interconnection weights acting as memory ror the system
Each processing element calculatE an output value based on the weighted sum or its inputs In
addition the input data is correlated with the output or desired output specified by an instructive
agent in a training rule that is used to adjust the interconnection weights In this way the ne
work learns patterns or imitates rules of behavior and decision making
The partiCUlar ANS architecture we use is a variation of Rummelhart lJ multi-layer
perceptron employing the generalized delta rule GD R). Instead of a single multi-layer structure our final network has a a multiple component or block configuration where one blOt'k
output reeds into another Figure The training methodology we have developed is not
tied to a particular training rule or architecture and should work well with alternative networks
like Grossberg's adaptive resonance model[2J
American Institute of Physics
The equations describing the network are derived and described in detail by Rumelhart
In summary they are
Transfer function
Sj
WjiOi
i-O
Weight adaptation rule
Error calculation
a
OJ
a l'??Awp.revious
OJ E0.tW.ti
where OJ is the output or processing element or a sensor input is the interconnection weight
leading from element ito is the number of inputs to Aw is the adjustment of is the
training constant a is the training momentum OJ is the calculated error for element and
is the Canout oC a given element Element zero is a constant input equal to one so that WjO is
equivalent to the bias threshold of element The factor in equation differs from standard GDR formulation but it is useful for keeping track of the relative magnitudes of the two
terms For the network's output layer the summation in equation is replaced with the
difference between the desired and actual output value of element
These networks are usually trained by presenting the system with sets of input/output data
vectors in cyclic fashion the entire cycle of database presentation repeated dozens of times This
method is effective when the training agent is a computer operating in batch mode but would be
intolerable for a human instructor There are two developments that will help real-time human
training The first is a more efficient incorporation of data/response patterns into a network The
second which we are addressing in this paper is a suitable environment wherein a man and ANS
network can interact in training situation with minimum inconvenience or boredom on the
human's part The ability to systematically train networks in this fashion is extremely useful for
developing certain types of expert systems including automatic signal processors autopilots
robots and other autonomous machines We report a number of techniques aimed at facilitating
this type of training and we propose a general method for teaching these networks
System Development
Our work focuses on the utility of ANS for system control It began as an application of
Barto and Sutton's associative search network[3 Although their approach was useful in a
number of ways it fell short when we tried to use it for capturing the subtleties of human
decision-making In response we shifted our emphasis rrom constructing goal runctions for
automatic learning to methods for training networks using direct human instruction An integral
part or this is the development or suitable interraces between humans networks and the outside
world or simulator In this section we will report various approaches to these ends and describe a
general methodology for manually teaching ANS networks To demonstrate these techniques we
taught a network to drive a robot vehicle down a simulated highway in traffic This application
combines binary decision making and control of continuous parameters
Initially we investigated the use or automatic learning based on goal functions[3 for training control systems We trained a network-controlled vehicle to maintain acceptable following
distances from cars ahead or it On a graphics workstation a one lane circular track was
constructed and occupied by two vehicles a network-controlled robot car and a pace car that
varied its speed at random Input data to the network consisted of the separation distance and
the speed of the robot vehicle The values of a goal function were translated into desired output
for GDR training Output controls consisted of three binary decision elements accelerate one
increment of speed maintain speed and decelerate one increment of speed At all times
the desired output vector had exactly one of these three elements active The goal runction was
quadratic with a minimum corresponding to the optimal following distance Although it had no
direct control over the simulation the goal function positively or negatively reinforced the
system's behavior
The network was given complete control of the robot vehicle and the human trainer had
no influence except the ability to start and terminate training This proved unsatisractory because
the initial system behavior--governed by random interconnection weights--was very unstable The
robot tended to run over the car in rront of it before significant training occurred By carerully
halting and restarting training we achieved stable system behavior At first the rollowing distance
maintained by the robot car oscillated as ir the vehicle was attached by a sj)ring to the pace car
This activity gradually damped Arter about one thousand training steps the vehicle maintained
the optimal following distance and responded quickly to changes in the pace car's speed
Constructing composite goal functions to promote more sophisticated abilities proved
difficult even ill-defined because there were many unspecified parameters To generate goal
runctions ror these abilities would be similar to conventional programming--the type or labor we
want to circumvent using ANS. On the other hand humans are adept at assessing complex situations and making decisions based on qualitative data but their goal runctions are difficult ir not
impossible to capture analytically One attraction of ANS is that it can imitate behavior based on
these elusive rules without rormally specifying them At this point we turned our efforts to
manual training techniques
The initially trained network was grafted into a larger system and augmented with additional inputs distance and speed inrormation on nearby pace cars in a second traffic lane and an
output control signal governing lane changes The original network's ability to maintain a safe
following distance was retained intact Thts grafting procedure is one of two methods we studied
for adding ne abilities to an existin system The second which employs a block structure is
described below The network remained in direct control of the robot vehicle but a human
trainer instructed it when and when not to change lanes His commands were interpreted as the
desired output and used in the GDR training algorithm This technique which we call coaching
proved userul and the network quickly correlated its environmental inputs with the teacher's
instructions The network became adept at changing lanes and weaving through traffic We found
that the network took on the behavior pattern or its trainer A conservative teacher produced a
timid network while an aggressive tzainer produced a network that tended to cut off other automobiles and squeeze through tight openings Despite its success the coaching method of training
did not solve the problem or initial network instability
The stability problem was solved by giving the trainer direct control over the simulation
The system configuration Figure allows the expert to exert control or release it to the
work During initial tzaining the expert is in the driver's seat while the network acts the role of
apprentice It receives sensor information predicts system commands and compares its predictions against the desired output the trainer's commands Figure shows the data and command flow in detail Input data is processed through different channels and presented to the
trainer and network Where visual and audio formats are effective for humans the network uses
information in vector form This differentiation of data presentation is a limitation of the system
removing it is a cask for future search The trainer issues control commands in accordance with
his assigned while the network takes the trainer's actions as desired system responses and
correlates these with the input We refer to this procedure as master/apprentice training network
training proceeds invisibly in the background as the expert proceeds with his day to day work It
avoids the instability problem because the network is free to make errors without the adverse
consequence of throwing the operating environment into disarray
I
Input
World sensors
or
Simulation
Actuation
I
Ne',WOrk
I
Expert
Commands
Figure A scheme for manually training ANS networks Input data is received by both
the network and trainer The trainer issues commands that are actuated solid command
line or he coaches the network in how it ought to respond broken command line
Commands
Preprocessing
tortunan
Input
data
Preprocessing
for network
twork
Predicted
commands
Actuation
Coaching/emphasis
Training
rule
Fegure Data and convnand flow In the training system Input data is processed and presented
to the trainer and network In master/appre~ice training solid command Hne the trainer's
orders are actuated and the network treats his commands as the system's desired output In
coaching the network's predicted oonvnands are actuated broken command line and the
trainer influences weight adaptation by specifying the desired system output and controlHng
the values of trailing constants-his suggestions are not cirec:tty actuated
Once initial bacqround wainmg is complete the expert proceeds in a more formal
manner to teach the network He releases control of the command system to the network in
order to evaluate ita behavior and weaknesses He then resumes control and works through a
series of scenarios designed to train t.he network out of its bad behavior By switching back and
forth between human and network control the expert assesses the network's reliability and
teaches correct responses as needed We find master/apprentice training works well for behavior
involving continuous functions like steering On the other hand coaching is appropriate for decision Cunctions like when Ule car ought to pass Our methodology employs both techniques
The Driving Network
The fully developed freeway simulation consists of a two lane highway that is made of
joined straight and curved segments which vary at random in length and curvature Several
pace cars move at random speeds near the robot vehicle The network is given the tasks of tracking the road negotiating curves returning to the road if placed far afield maintaining safe distances from the pace cars and changing lanes when appropriate Instead of a single multi-layer
structure the network is composed of two blocks one controls the steering and the other regulates speed and decides when the vehicle should change lanes Figure The first block receives
information about the position and speed of the robot vehicle relative to other ears in its vicinity
Its output is used to determine the automobile's speed and whet.her the robot should change
lanes The passing signal is converted to a lane assignment based on the car's current lane position The second block receives the lane assignment and data pertinent to the position and orientation of the vehicle with respect to the road The output is used to determine the steering angle
of the robot car
Block
Inputs
Outputs
Constant
Speed
Disl Ahead Pl
Disl Ahead Ol
Dist Behind Ol
ReI. Speed Ahead Pl
ReI. Speed Ahead Ol
ReI. Speed Behind Ol
I
Speed
Change lanes
Steering Angle
Convert lane change to lane number
Constant
Rei. Orientation
lane Nurmer
lateral Dist
Curvature
Figure The two blocks of the driving ANS network Heavy arrows Indicate total interconnectivity
between layers PL designates the traffic lane presently oca.apied by the robot vehicle Ol refers
to the other lane QJrvature refers to the road lane nurrber is either or relative orientation and
lateral distance refers to the robot car's direction and podion relative to the road'l direction and
center line respectively
The input data is displayed in pictorial and textual form to the driving instructor He views
the road and nearby vehicles from the perspective of the driver's seat or overhead The network
receives information in the form of a vector whose elements have been scaled to unitary order
Wide ranging input parameters like distance are compressed using the hyperbolic tangent
or logarithmic functions In each block the input layer is totally interconnected to both the ou
put and a hidden layer Our scheme trains in real time and as we discuss later it trains more
smoothly with a small modification of the training algorithm
Output is interpreted in two ways as a binary decision or as a continuously varying parameter The first simply compares the sigmoid output against a threshold The second scales the
output to an appropriate range for its application For example on the steering output element a
value is interpreted as a zero steering angle Left and right turns of varying degrees are initiated when this output is above or below respectively
The network is divided into two blocks that can be trained separately Beside being conceptually easier to understand we find this component approach is easy to train systematically
Because each block has a restricted well-defined set of tasks the trainer can concentrate
specifically on those functions without being concerned that other aspects of the network behavior
are deteriorating
trained the system from bottom up first teaching the network to stay on the road
negotiate curves chan~e lanes and how to return if the vehicle strayed off the highway Block
responsible for steering learned these skills in a few minutes using the master/apprentice mode
It tended to steer more slowly than a human but further training progressively improved its
responsiveness
We experimented with different trammg constants and momentum values Large
values about caused weights to change too coarsely values an order of magnitude smaller
worked well We found DO advantage in using momentum for this method of training in fact
the system responded about three times more slowly when than when the momentt:m
term was dropped Our standard training parameters were and Cl
Figure Typical behavior of a network-controlled vehicle dam rectangle when trained by
a conservative miYer ItI:I reckless driver Speed Is indicated by the length of the arrows
After Block Was trained we gave steering control to the network and concentrated on
teaching the network to change lanes and adjust speed Speed control in this was a continuous variable and was best taught using master/apprentice training On the other hand the binary
decision to change lanes was best taught by coaching About ten minutes of training were needed
to teach the network to weave through traffic We found that the network readily adapts the
behavioral pattern of its trainer A conservative trainer generated a network that hardly ever
passed while an aggressive trainer produced a network that drove recklessly and tended to cut off
other-cars Figure
Discussion
One of the strengths of el:pert 5ystf'mS based on ANS is that the use of input data in the
decision making and control proc~ss does not have to be specified The network adapts its internal weights to conform to input output correlat.ions it discovers It is important however that
data used by the human expert is also available to the network The different processing of sensor data for man and network may have important consequences key information may be
presented to the man but not the machine
This difference in data processing is particularly worrisome for image data where human
ability to extract detail is vastly superior to our au tomatic image processing capabilities Though
we would not require an image processing system to understand images it would have to extract
relevant information from cluttered backgrounds Until we have sufficiently sophisticated algorithms or networks to do this our efforts at constructing expert systems which halldle image data
are handicapped
Scaling input data to the unitary order of magnitude is important for training stability
is evident from equations and The sigmoid transfer function ranges from to in
approximat.eiy four units that is over an domain If system response must change in reaction to a large swing of a given input parameter the weight associated with that input will
be trained toward an magnitude On the other hand if the same system responds to an
input whose range is its associated weight will also be The weight adjustment equation does not recognize differences in weight magnitude therefore relatively small weights will
undergo wild magnitude adjustments and converge weakly On the other hand if all input parameters are of the same magnitude their associated weights will reflect this and the training constant
can be adjusted for gentle weight convergence Because the output of hidden units are constrained between zero and one is a good target range for input parameters Both the hyperbolic tangent and logarithmic functions are useful for scaling wide ranging inputs A useful form
of the latter is
if
ifx<-o
where and defines the limits of the intermediate linear section and is a scaling factor
This symmetric logarithmic function is continuous in its first derivative and useful when network
behavior should change slowly as a parameter increases without bound On the othl'r hand if the
system should approach a limiting behavior the tanh function is appropriate
Weight adaptation is also complicated by relaxing the common practice of restricting interconnections to adjacent layers Equation shows that the calculated error for a hidden layergiven comparable weights fanouts and output errors-will be one quarter or less than that of the
output layer This is caused by the slope ractor oil The difference in error magnitudes is
not noticeable in networks restricted to adjacent layer interconnectivity But when this constraint
is released the effect of errors originating directly from an output unit has times the magnitude
and effect of an error originating from a hidden unit removed layers from the output layer
Compared to the corrections arising from the output units those from the hidden units have little
influence on weight adjustment and the power of a multilayer structure is weakened The system
will train if we restrict connections to adjacent layers but it trains slowly To compensate for this
effect we attenuate the error magnitudes originating from the output layer by the above factor
This heuristic procedure works well and racilitates smooth learning
Though we have made progress in real-time learning systems using GDR compared to
humans-who can learn from a single data presentation-they remain relatively sluggish in learning
and response rates We are interested in improvements of the GDR algorithm or alternative
architectures that facilitate one-shot or rapid learning In the latter case we are considering least
squares restoration techniquesl4 and Grossberg and Carpenter's adaptive resonance modelsI3,5
The construction of automated expert systems by observation of human personnel is
attractive because of its efficient use of the expert's time and effort Though the classic AI
approach of rule base inference is applicable when such rules are clear cut and well organized too
often a human expert can not put his decision making process in words or specify the values of
parameters that influence him The attraction or ANS based systems is that imitations of expert
behavior emerge as a natural consequence of their training

<<----------------------------------------------------------------------------------------------------------------------->>

title: 53-the-connectivity-analysis-of-simple-association.pdf

The Connectivity Analysis of Simple Association
orHow Many Connections Do You Need
Dan Hammerstrom
Oregon Graduate Center Beaverton OR
ABSTRACT
The efficient realization using current silicon technology of Very Large Connection
Networks VLCN with more than a billion connections requires that these networks exhibit
a high degree of communication locality Real neural networks exhibit significant locality
yet most connectionist/neural network models have little In this paper the connectivity
requirements of a simple associative network are analyzed using communication theory
Several techniques based on communication theory are presented that improve the robustness of the network in the face of sparse local interconnect structures Also discussed are
some potential problems when information is distributed too widely
INTRODUCTION
Connectionist/neural network researchers are learning to program networks that exhibit a broad range of cognitive behavior Unfortunately existing computer systems are limited in their ability to emulate such networks efficiently The cost of emulating a network
whether with special purpose highly parallel silicon-based architectures or with traditional
parallel architectures is directly proportional to the number of connections in the network
This number tends to increase geometrically as the number of nodes increases Even with
large massively parallel architectures connections take time and silicon area Many existing neural network models scale poorly in learning time and connections precluding large
implementations
The connectivity costs of a network are directly related to its locality A network
exhibits locality 01 communication if most of its processing elements connect to other physically adjacent processing elements in any reasonable mapping of the elements onto a planar
surface There is much evidence that real neural networks exhibit locality2 In this paper
a technique is presented for analyzing the effects of locality on the process of association
These networks use a complex node similar to the higher-order learning units of Maxwell
NETWORK MODEL
The network model used in this paper is now defined Figure
Definition A recursive neural network called a c-graph is a graph structure
where
There is a set of CNs network nodes whose outputs can take a range of positive
real values Vi between and There are N. nodes in the set
There is a set of codons that can take a range of positive real values eij for
codon of node between and There are Ne codons dedicated to each CN the
output of each codon is only used by its local so there are a total of Ne N. codons
in the network The fan-in or order of a codon is Ie. It is assumed that leis the
same for each codon and Ne is the same for each CN.
This work was supported in part by the Semiconductor Research Corporation contract no and
jointly by the Office of Naval Research and Air Force Office of Scientific Research ONR contract no NOOO14 87
American Institute of Physics
Ie
codon
Figure A ON
Cijk is a set of connections of ONs to codons and Ne Cijk can
take two values indicating the existence of a connection from ON to codon
of ON
Definition The value of ON is
Vi
F[8+~eijl
J-l
The function is a continuous non-linear monotonic function such as the sigmoid function
Definition Define a mapping where is an input vector to rand is
the Ie element input vector of codon of ON That is has as its elements those elements of Zk of where Cijk=1
The function indicates the subset of seen by codon of ON Different input vectors may map to the same codon vectors and D(i,j,Zj-y where
Definition The codon values eij are determined as follows Let be input vector
of the learned input vectors for ON For codon eij of ON let Tij be the set of I cdimensional vectors such that lij(m)E ij and That is each vector
lij in Tij consists of those subvectors of that are in codon ii's receptive field
The variable indexes the vectors of ij The number of distinct vectors in Tij
may be less than the total number of learned vectors Though the are
distinct the subsets lij(m need not be since there is a possible many to one mapping of
the vectors onto each vector lij
Let Xl be the subset of vectors where vi=l ON is supposed to output a and
those vectors where vi=O then define
izeof
for and that map to this I. That is is the number of
xo be
vectors that map
into Iij{l where
tlj-O
and is the number of vectors that map into Iii where
The compreaaion of a codon for a vector then is defined as
I IJ
Hqj(l)=O when both nt The output of codon
eii is the maximum-likelyhood
decoding
Where He indicates the likely hood of when a vector that maps to is input and
is that vector where I I and is the current input vector In other words is that vector of the set of subset learned vectors that codon ij
receives that is closest using distance measure to the subset input vector
The output of a codon is the most-likely output according to its inputs For example when there is no code compression at a codon if the closest terms of some
measure of vector distance Hamming distance subvector in the receptive field of the
codon belongs to a learned vector where the CN is to output a The codons described here
are very similar to those proposed by Marr and implement ne!'Lrest-neighbor classification
It is assumed that codon function is determined statically prior to network operation that
is the desired categories have already been learned
To measure performance network capacity is used
Definition The input noiae Or is the average between an input vector and the
closest minimum learned vector where is a measure of the difference between two
vectors for bit vectors this can be Hamming distance The output noise is the average
distance between network output and the learned output vector associated with the closest
learned input vector The in/ormation gain Gr is just
Gt
I
Definition The capacity of a network is the maximum number of learned vectors such
that the information gain Gr is strictly positive
COMMUNICATION ANALOGY
Consider a single connection network node or CN. The remainder of this paper will
be restricted to a single Assume that the CN output value space is restricted to two
values and Therefore the CN must decide whether the input it sees belongs to the
class of codes those codes for which it remains off or the class of codes those codes
for which it becomes active The inputs it sees in its receptive field constitute a subset of
the input vectors the function to the network It is also assumed that the CN is an
ideal I-NN Nearest Neighbor classifier or feature detector That is given a particular set
of learned vectors the CN will classify an arbitrary input according to the class of the
nearest using as a measure of distance learned vector This situation is equivalent to
the case where a single CN has a single codon whose receptive field size is equivalent to that
of the CN.
Imagine a sender who wishes to send one bit of information over a noisy channel The
sender has a probabilistic encoder that choses a code word learned vector according to
some probability distribution The receiver knows this code set though it has no knowledge
of which bit is being sent Noise is added to the code word during its transmission over the
channel which is analogous to applying an input vector to a network's inputs where the
vector lies within some learned vector's region The noise is represented by the distance
between the input vector and the associated learned vector
The code word sent over the channel consists of those bits that are seen in the receptive field of the ON being modeled In the associative mapping of input vectors to output
vectors each ON must respond with the appropriate output or for the associated
learned output vector Therefore a ON is a decoder that estimates in which class the
received code word belongs This is a classic block encoding problem where increasing the
field size is equivalent to increasing code length As the receptive field size increases the
performance of the decoder improves in the presence of noise Using communication theory
then the trade-off between interconnection costs as they relate to field size and the functionality of a node as it relates to the correctness of its decision making process output
errors can be characterized
As the receptive field size of a node increases so does the redundancy of the input
though this is dependent on the particular codes being used for the learned vectors since
there are situations where increasing the field size provides no additional information
There is a point of diminishing returns where each additional bit provides ever less reduction in output error Another factor is that interconnection costs increase exponentially
with field size The result of these two trends is a cost performance measure that has a single global maximum value In other words given a set of learned vectors and their probabilities and a set of interconnection costs a best receptive field size can be determined
beyond which increasing connectivity brings diminishing returns
SINGLE CODON WITH NO CODE COMPRESSION
A single neural element with a single codon and with no code compression can be
modelled exactly as a communication channel Figure Each network node is assumed
to have a single codon whose receptive field size is equal to that of the receptive field size of
the node
sender
I I
encoder
nOIsy
I
I
transmitter
receiver
I
decoder
ON
Figure A Transmission Channel
recelver
The operation of the channel is as follows A bit is input into the channel encoder
which selects a random code of length and transmits that code over the channel The
receiver then using nearest neighbor classification decides if the original message was either
a or a
Let be the number of code words used by the encoder The rate then indicates the
density of the code space
Definition The rate of a communication channel is
The block length corresponds directly to the receptive field size of the codon
The derivations in later sections use a related measure
Definition The code utilization is the number of learned vectors assigned to a particular code or
can be written in terms of
2N
As approaches code compression increases is essentially unbounded since may be
significantly larger than
The decode error information loss due to code compression is a random variable that
depends on the compression rate and the a priori probabilities therefore it will be different
with different learned vector sets and codons within a set As the average code utilization
for all codons approaches code compression occurs more often and codon decode error is
unavoidable
Let Zi be the vector output of the encoder and the input to the channel where each
element of Zi is either a or Let Vi be the vector output of the channel and the input to
the decoder where each element is either a or a The Noisy Channel Coding Theorem is
now presented for a general case where the individual input codes are to be distinguished The result is then extended to a CN where even though input codes are
used the ON need only distinguish those codes where it must output a from those where it
must output a The theorem is from Gallager Random codes are assumed
throughout
Theorem Let a discrete memoryless channel have transition probabilities PNU/k
and for any positive integer and positive number consider the ensemble of
block codes in which each letter of each code word is independently selected according to
fe
the probability assignment Then for each message NR
and all
the ensemble average probability of decoding error using maximum-likelyhood
decoding satisfies
where
In the definitions given here and the theorems below the notation of Gall ager is used Many of the
definitions and theorems are also from Gallager
Q(k)PU/kp!p
i-il
l+P
k-il
These results are now adjusted ror our special case
Theorem For a single CN the average channel error rate ror random code vectors is
Pe
where
I
is the probability or an input vector bit being a
These results cover a wide range or models A more easily computable expression can
be derived by recognizing some or the restrictions inherent in the CN model First assume
that all channel code bits are equally likely that is I that the error model is
the Binary Symmetric Channel and that the errors are identically distributed and
independent that is each bit has the same probability or being in error independent
or the code word and the bit position in the code word
A simplified version or the above theorem can be derived Maximizing gives the
tightest bounds
O$p~l
maxPe(p
where letting codon input be the block length I
The minimum value or this expression is obtained when for
Eo log
SINGLE-CODON WITH CODE COMPRESSION
Unfortunately the implementation complexity of a codon grows exponentially with the
size or the codon which limits its practical size An alternative is to approximate single
codon function of a single CN with many smaller overlapped codons The goal is to maintain performance and reduce implementation costs thus improving the cost/performance of
the decoding process As codons get smaller the receptive field size becomes smaller relative
to the number of CNs in the network When this happens there is codon compression or
vector alia6ing that introduces its own errors into the decoding process due to information
loss Networks can overcome this error by using multiple redundant codons with overlapping receptive fields that tend to correct the compression error
Compression occurs when two code words requiring different decoder output share the
same representation within the receptive field or the codon The following theorem gives
the probability of incorrect codon output with and without compression error
Theorem For a BSC model where the codon receptive field is Ic the code utilization is and the channel bits are selected randomly and independently the probability
of a codon decoding error when is approximately
where the expected compression error per codon is approximated by
Pc
and from equations when
exp
log
I-RI
Proof is given in Hammerstrom6
As grows Pc approaches asymptotically Thus the performance of a single codon
degrades rapidly in the presence of even small amounts of compression
MULTIPLE CODONS WITH CODE COMPRESSION
The use or mUltiple small codons is more efficient than a few large codons but there
are some fundamental performance constraints When a codon is split into two or more
smaller codons and the original receptive field is subdivided accordingly there are several
effects to be considered First the error rate of each new codon increases due to a decrease
in receptive field size the codon's block code length The second effect is that the code
utilization will increase for each codon since the same number of learned vectors is
mapped into a smaller receptive field This change also increases the error rate per codon
due to code compression In fact as the individual codon receptive fields get smaller
significant code compression occurs For higher-order input codes there is an added error
that occurs when the order of the individual codons is decreased since random codes are
being assumed this effect is not considered here The third effect is the mass action of
large numbers of codons Even though individual codons may be in error if the majority
are correct then the ON will have correct output This effect decreases the total error rate
Assume that each ON has more than one codon The union of the receptive fields
for these codons is the receptive field for the ON with no no restrictions on the degree of
overlap of the various codon receptive fields within or between ONs. For a ON with a large
number of codons the codon overlap will generally be random and uniformly distributed
Also assume that the transmission errors seen by different receptive fields are independent
Now consider what happens to a codon's compression error rate ignoring transmission
error for the time being when a codon is replaced by two or more smaller co dons covering
the same receptive field This replacement process can continue until there are only
codons which incidentally is analogous to most current neural models For a multiple
codon ON assume that each codon votes a or The summation unit then totals this
information and outputs a if the majority of codons vote for a etc
Theorem The probability of a ON error due to compression error is
Pc
where
Pc
dy
is given in equation and
Pc incorporates the two effects of moving to mUltiple smaller codons and adding more
codons Using equation 17 gives the total error probability per bit PeN
Proof is in Hammerstrom6
For networks that perform association as defined in this paper the connection weights
rapidly approach a single uniform value as the size of the network grows In information
theoretic terms the information content of those weights approaches zero as the compression increases Why then do simple non-conjunctive networks 1-codon equivalent work at
alI In the next section I define connectivity cost constraints and show that the answer to
the first question is that the general associative structures defined here do not scale costeffectively and more importantly that there are limits to the degree of distribution of information
CONNECTIVITY COSTS
It is much easier to assess costs if some implementation medium is assumed I have
chosen standard silicon which is a two dimensional surface where ON's and codons take up
surface area according to their receptive field sizes In addition there is area devoted to
the metal lines that interconnect the ONs. A specific VLSI technology need not be assumed
since the comparisons are relative thus keeping ONs codons and metal in the proper proportions according to a standard metal width which also includes the inter-metal
pitch For the analyses performed here it is assumed that
levels of metal are possible
In the previous section I established the relationship of network performance in terms
of the transmission error rate and the network capacity M. In this section I present an
implementation cost which is total silicon area A. This figure can then be used to derive a
cost/performance figure that can be used to compare such factors as codon size and receptive field size There are two components to the total area A ON the area of a ON and
AMI the area of the metal interconnect between ONs. AON consists of the silicon area
requirements of the codons for all ONs. The metal area for local intra-ON interconnect is
considered to be much smaller than that of the codons themselves and of that of the more
global inter-ON interconnect and is not considered here The area per ON is roughly
AON cfeme
where me is the maximum number of vectors that each codon must distinguish for
me
Theorem Assume a rectangular un6ounded grid of ONs all ONs are equi-distant
from their four nearest neighbors where each ON has a bounded receptive field of its nON
nearest ONs where ON is the receptive field size for the ON nON
C~e
where is the
number of codons and is the intra-ON redundancy that is the ratio of inputs to
synapses when R=l each ON input is used once at the ON when each input is
used on the average at two sites The metal area required to support each ON's receptive
field is proof is giving by Hammerstrom6
AMI
The total area per ON A then is
Another implementation IItrategy ill to place eNII along a diagonal which givell area However thill
technique only works ror a bounded number or eNII and when dendritic computation can be lipread over a large
area which limits the range or p08llible eN implementationll The theorem IItated here covers an infinite plane or
eNII each with a bounded receptive Held
Even with the assumption of maximum locality the total metal interconnect area
increases as the cube of the per CN receptive field size
SINGLE CN SIMULATION
What do the bounds tell us about CN connectivity requirements From simulations
increasing the CN's receptive field size improves the performance increases capacity but
there is also an increasing cost which increases faster than the performance Another
observation is that redundancy is quite effective as a means for increasing the effectiveness
of a CN with constrained connectivity There are some limits to since it can reach a
point where the intra-CN connectivity approaches that of inter-CN for some situations
With a fixed nON increasing cost-effectiveness A is possible by increasing both order
and redundancy
In order to verify the derived bounds I also wrote a discrete event simulation of a CN
where a random set of learned vectors were chosen and the CN's codons were programmed
according to the model presented earlier Learned vectors were chosen randomly and subjected to random noise The CN then attempted to categorize these inputs into two
major groups CN output and CN output For the most part the analytic bounds
agreed with the simulation though they tended to be optimistic in slightly underestimating
the error These differences can be easily explained by the simplifying assumptions that
were made to make the analytic bounds mathematically tractable
DISTRmUTED VS. LOCALIZED
Throughout this paper it has been tacitly assumed that representations are distributed
across a number of CNs and that any single CN participates in a number of representations In a local representation each CN represents a single concept or feature It is the distribution of representation that makes the CN's decode job difficult since it is the cause of
the code compression problem
There has been much debate in the connectionist/neuromodelling community as to the
advantages and disadvantages of each approach the interested reader is referred to Hinton7 Baum and BallardQ Some of the results derived here are relevant to this
debate A1s the distribution of representation increases the compression per CN increases
accordingly It was shown above that the mean error in a codon's response quickly
approaches independent of the input noise This result also holds at the CN level For
each individual CN this error can be offset by adding more codons but this is expensive
and tends to obviate one of the arguments in favor of distributed representations that is
the multi-use advantage where fewer CNs are needed because of more complex redundant
encodings A1s the degree of distribution increases the required connectivity and the code
compression increases so the added information that each codon adds to its CN's decoding
process goes to zero equivalent to all weights approaching a uniform value
SUMMARY AND CONCLUSIONS
In this paper a single CN node performance model was developed that was based on
Communication Theory Likewise an implementation cost model was derived
The communication model introduced the codon as a higher-order decoding element
and showed that for small codons much less than total CN fan-in or convergence code
compression or vector aliasing within the codon's receptive field is a severe problem for
large networks As code compression increases the information added by any individual
codon to the CN's decoding task rapidly approaches zero
The cost model showed that for 2-dimensional silicon the area required for inter-node
metal connectivity grows as the cube of a CN's fan-in
The combination of these two trends indicates that past a certain point which is
highly dependent on the probability structure of the learned vector space increasing the
fan-in of a CN as is done for example when the distribution of representation is increased
yields diminishing returns in terms of total cost-performance Though the rate of diminishing returns can be decreased by the use of redundant higher-order connections
The next step is to apply these techniques to ensembles of nodes CNs operating in a
competitive learning or feature extraction environment

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 52-teaching-artificial-neural-systems-to-drive-manual-training-techniques-for-autonomous-systems.pdf

Teaching Artificial Neural Systems to Drive
Manual Training Techniques for Autonomous Systems
J. F. Shepanski and S. A. Macy
TRW Inc
One Space Park
Redondo Beach CA
Abetract
We have developed a methodology for manually training autononlous control systems
based on artificial neural systems In applications where the rule set governing an expert's
decisions is difficult to formulate ANS can be used to ext.ra.c:t rules by associating the information
an expert receives with the actions takes Properly constructed networks imitate rules of
behavior that permits them to function autonomously when they are trained on the spanning set
of possible situations This training can be provided manually either under the direct supervision
or a system trainer or indirectly using a background mode where the network assimilates training
data as the expert perrorms his day-to-day tasks To demonstrate these methods we have trained
an ANS network to drive a vehicle through simulated rreeway traffic
I ntJooducticn
Computational systems employing fine grained parallelism are revolutionizing the way we
approach a number or long standing problems involving pattern recognition and cognitive processing The field spans a wide variety or computational networks rrom constructs emulating neural
runctions to more crystalline configurations that resemble systolic arrays Several titles are used
to describe this broad area or research we use the term artificial neural systems Our concern in this work is the use or ANS ror manually training certain types or autonomous systems
where the desired rules of behavior are difficult to rormulate
Artificial neural systems consist of a number or processing elements interconnected in a
weighted user-specified fashion the interconnection weights acting as memory ror the system
Each processing element calculatE an output value based on the weighted sum or its inputs In
addition the input data is correlated with the output or desired output specified by an instructive
agent in a training rule that is used to adjust the interconnection weights In this way the ne
work learns patterns or imitates rules of behavior and decision making
The partiCUlar ANS architecture we use is a variation of Rummelhart lJ multi-layer
perceptron employing the generalized delta rule GD R). Instead of a single multi-layer structure our final network has a a multiple component or block configuration where one blOt'k
output reeds into another Figure The training methodology we have developed is not
tied to a particular training rule or architecture and should work well with alternative networks
like Grossberg's adaptive resonance model[2J
American Institute of Physics
The equations describing the network are derived and described in detail by Rumelhart
In summary they are
Transfer function
Sj
WjiOi
i-O
Weight adaptation rule
Error calculation
a
OJ
a l'??Awp.revious
OJ E0.tW.ti
where OJ is the output or processing element or a sensor input is the interconnection weight
leading from element ito is the number of inputs to Aw is the adjustment of is the
training constant a is the training momentum OJ is the calculated error for element and
is the Canout oC a given element Element zero is a constant input equal to one so that WjO is
equivalent to the bias threshold of element The factor in equation differs from standard GDR formulation but it is useful for keeping track of the relative magnitudes of the two
terms For the network's output layer the summation in equation is replaced with the
difference between the desired and actual output value of element
These networks are usually trained by presenting the system with sets of input/output data
vectors in cyclic fashion the entire cycle of database presentation repeated dozens of times This
method is effective when the training agent is a computer operating in batch mode but would be
intolerable for a human instructor There are two developments that will help real-time human
training The first is a more efficient incorporation of data/response patterns into a network The
second which we are addressing in this paper is a suitable environment wherein a man and ANS
network can interact in training situation with minimum inconvenience or boredom on the
human's part The ability to systematically train networks in this fashion is extremely useful for
developing certain types of expert systems including automatic signal processors autopilots
robots and other autonomous machines We report a number of techniques aimed at facilitating
this type of training and we propose a general method for teaching these networks
System Development
Our work focuses on the utility of ANS for system control It began as an application of
Barto and Sutton's associative search network[3 Although their approach was useful in a
number of ways it fell short when we tried to use it for capturing the subtleties of human
decision-making In response we shifted our emphasis rrom constructing goal runctions for
automatic learning to methods for training networks using direct human instruction An integral
part or this is the development or suitable interraces between humans networks and the outside
world or simulator In this section we will report various approaches to these ends and describe a
general methodology for manually teaching ANS networks To demonstrate these techniques we
taught a network to drive a robot vehicle down a simulated highway in traffic This application
combines binary decision making and control of continuous parameters
Initially we investigated the use or automatic learning based on goal functions[3 for training control systems We trained a network-controlled vehicle to maintain acceptable following
distances from cars ahead or it On a graphics workstation a one lane circular track was
constructed and occupied by two vehicles a network-controlled robot car and a pace car that
varied its speed at random Input data to the network consisted of the separation distance and
the speed of the robot vehicle The values of a goal function were translated into desired output
for GDR training Output controls consisted of three binary decision elements accelerate one
increment of speed maintain speed and decelerate one increment of speed At all times
the desired output vector had exactly one of these three elements active The goal runction was
quadratic with a minimum corresponding to the optimal following distance Although it had no
direct control over the simulation the goal function positively or negatively reinforced the
system's behavior
The network was given complete control of the robot vehicle and the human trainer had
no influence except the ability to start and terminate training This proved unsatisractory because
the initial system behavior--governed by random interconnection weights--was very unstable The
robot tended to run over the car in rront of it before significant training occurred By carerully
halting and restarting training we achieved stable system behavior At first the rollowing distance
maintained by the robot car oscillated as ir the vehicle was attached by a sj)ring to the pace car
This activity gradually damped Arter about one thousand training steps the vehicle maintained
the optimal following distance and responded quickly to changes in the pace car's speed
Constructing composite goal functions to promote more sophisticated abilities proved
difficult even ill-defined because there were many unspecified parameters To generate goal
runctions ror these abilities would be similar to conventional programming--the type or labor we
want to circumvent using ANS. On the other hand humans are adept at assessing complex situations and making decisions based on qualitative data but their goal runctions are difficult ir not
impossible to capture analytically One attraction of ANS is that it can imitate behavior based on
these elusive rules without rormally specifying them At this point we turned our efforts to
manual training techniques
The initially trained network was grafted into a larger system and augmented with additional inputs distance and speed inrormation on nearby pace cars in a second traffic lane and an
output control signal governing lane changes The original network's ability to maintain a safe
following distance was retained intact Thts grafting procedure is one of two methods we studied
for adding ne abilities to an existin system The second which employs a block structure is
described below The network remained in direct control of the robot vehicle but a human
trainer instructed it when and when not to change lanes His commands were interpreted as the
desired output and used in the GDR training algorithm This technique which we call coaching
proved userul and the network quickly correlated its environmental inputs with the teacher's
instructions The network became adept at changing lanes and weaving through traffic We found
that the network took on the behavior pattern or its trainer A conservative teacher produced a
timid network while an aggressive tzainer produced a network that tended to cut off other automobiles and squeeze through tight openings Despite its success the coaching method of training
did not solve the problem or initial network instability
The stability problem was solved by giving the trainer direct control over the simulation
The system configuration Figure allows the expert to exert control or release it to the
work During initial tzaining the expert is in the driver's seat while the network acts the role of
apprentice It receives sensor information predicts system commands and compares its predictions against the desired output the trainer's commands Figure shows the data and command flow in detail Input data is processed through different channels and presented to the
trainer and network Where visual and audio formats are effective for humans the network uses
information in vector form This differentiation of data presentation is a limitation of the system
removing it is a cask for future search The trainer issues control commands in accordance with
his assigned while the network takes the trainer's actions as desired system responses and
correlates these with the input We refer to this procedure as master/apprentice training network
training proceeds invisibly in the background as the expert proceeds with his day to day work It
avoids the instability problem because the network is free to make errors without the adverse
consequence of throwing the operating environment into disarray
I
Input
World sensors
or
Simulation
Actuation
I
Ne',WOrk
I
Expert
Commands
Figure A scheme for manually training ANS networks Input data is received by both
the network and trainer The trainer issues commands that are actuated solid command
line or he coaches the network in how it ought to respond broken command line
Commands
Preprocessing
tortunan
Input
data
Preprocessing
for network
twork
Predicted
commands
Actuation
Coaching/emphasis
Training
rule
Fegure Data and convnand flow In the training system Input data is processed and presented
to the trainer and network In master/appre~ice training solid command Hne the trainer's
orders are actuated and the network treats his commands as the system's desired output In
coaching the network's predicted oonvnands are actuated broken command line and the
trainer influences weight adaptation by specifying the desired system output and controlHng
the values of trailing constants-his suggestions are not cirec:tty actuated
Once initial bacqround wainmg is complete the expert proceeds in a more formal
manner to teach the network He releases control of the command system to the network in
order to evaluate ita behavior and weaknesses He then resumes control and works through a
series of scenarios designed to train t.he network out of its bad behavior By switching back and
forth between human and network control the expert assesses the network's reliability and
teaches correct responses as needed We find master/apprentice training works well for behavior
involving continuous functions like steering On the other hand coaching is appropriate for decision Cunctions like when Ule car ought to pass Our methodology employs both techniques
The Driving Network
The fully developed freeway simulation consists of a two lane highway that is made of
joined straight and curved segments which vary at random in length and curvature Several
pace cars move at random speeds near the robot vehicle The network is given the tasks of tracking the road negotiating curves returning to the road if placed far afield maintaining safe distances from the pace cars and changing lanes when appropriate Instead of a single multi-layer
structure the network is composed of two blocks one controls the steering and the other regulates speed and decides when the vehicle should change lanes Figure The first block receives
information about the position and speed of the robot vehicle relative to other ears in its vicinity
Its output is used to determine the automobile's speed and whet.her the robot should change
lanes The passing signal is converted to a lane assignment based on the car's current lane position The second block receives the lane assignment and data pertinent to the position and orientation of the vehicle with respect to the road The output is used to determine the steering angle
of the robot car
Block
Inputs
Outputs
Constant
Speed
Disl Ahead Pl
Disl Ahead Ol
Dist Behind Ol
ReI. Speed Ahead Pl
ReI. Speed Ahead Ol
ReI. Speed Behind Ol
I
Speed
Change lanes
Steering Angle
Convert lane change to lane number
Constant
Rei. Orientation
lane Nurmer
lateral Dist
Curvature
Figure The two blocks of the driving ANS network Heavy arrows Indicate total interconnectivity
between layers PL designates the traffic lane presently oca.apied by the robot vehicle Ol refers
to the other lane QJrvature refers to the road lane nurrber is either or relative orientation and
lateral distance refers to the robot car's direction and podion relative to the road'l direction and
center line respectively
The input data is displayed in pictorial and textual form to the driving instructor He views
the road and nearby vehicles from the perspective of the driver's seat or overhead The network
receives information in the form of a vector whose elements have been scaled to unitary order
Wide ranging input parameters like distance are compressed using the hyperbolic tangent
or logarithmic functions In each block the input layer is totally interconnected to both the ou
put and a hidden layer Our scheme trains in real time and as we discuss later it trains more
smoothly with a small modification of the training algorithm
Output is interpreted in two ways as a binary decision or as a continuously varying parameter The first simply compares the sigmoid output against a threshold The second scales the
output to an appropriate range for its application For example on the steering output element a
value is interpreted as a zero steering angle Left and right turns of varying degrees are initiated when this output is above or below respectively
The network is divided into two blocks that can be trained separately Beside being conceptually easier to understand we find this component approach is easy to train systematically
Because each block has a restricted well-defined set of tasks the trainer can concentrate
specifically on those functions without being concerned that other aspects of the network behavior
are deteriorating
trained the system from bottom up first teaching the network to stay on the road
negotiate curves chan~e lanes and how to return if the vehicle strayed off the highway Block
responsible for steering learned these skills in a few minutes using the master/apprentice mode
It tended to steer more slowly than a human but further training progressively improved its
responsiveness
We experimented with different trammg constants and momentum values Large
values about caused weights to change too coarsely values an order of magnitude smaller
worked well We found DO advantage in using momentum for this method of training in fact
the system responded about three times more slowly when than when the momentt:m
term was dropped Our standard training parameters were and Cl
Figure Typical behavior of a network-controlled vehicle dam rectangle when trained by
a conservative miYer ItI:I reckless driver Speed Is indicated by the length of the arrows
After Block Was trained we gave steering control to the network and concentrated on
teaching the network to change lanes and adjust speed Speed control in this was a continuous variable and was best taught using master/apprentice training On the other hand the binary
decision to change lanes was best taught by coaching About ten minutes of training were needed
to teach the network to weave through traffic We found that the network readily adapts the
behavioral pattern of its trainer A conservative trainer generated a network that hardly ever
passed while an aggressive trainer produced a network that drove recklessly and tended to cut off
other-cars Figure
Discussion
One of the strengths of el:pert 5ystf'mS based on ANS is that the use of input data in the
decision making and control proc~ss does not have to be specified The network adapts its internal weights to conform to input output correlat.ions it discovers It is important however that
data used by the human expert is also available to the network The different processing of sensor data for man and network may have important consequences key information may be
presented to the man but not the machine
This difference in data processing is particularly worrisome for image data where human
ability to extract detail is vastly superior to our au tomatic image processing capabilities Though
we would not require an image processing system to understand images it would have to extract
relevant information from cluttered backgrounds Until we have sufficiently sophisticated algorithms or networks to do this our efforts at constructing expert systems which halldle image data
are handicapped
Scaling input data to the unitary order of magnitude is important for training stability
is evident from equations and The sigmoid transfer function ranges from to in
approximat.eiy four units that is over an domain If system response must change in reaction to a large swing of a given input parameter the weight associated with that input will
be trained toward an magnitude On the other hand if the same system responds to an
input whose range is its associated weight will also be The weight adjustment equation does not recognize differences in weight magnitude therefore relatively small weights will
undergo wild magnitude adjustments and converge weakly On the other hand if all input parameters are of the same magnitude their associated weights will reflect this and the training constant
can be adjusted for gentle weight convergence Because the output of hidden units are constrained between zero and one is a good target range for input parameters Both the hyperbolic tangent and logarithmic functions are useful for scaling wide ranging inputs A useful form
of the latter is
if
ifx<-o
where and defines the limits of the intermediate linear section and is a scaling factor
This symmetric logarithmic function is continuous in its first derivative and useful when network
behavior should change slowly as a parameter increases without bound On the othl'r hand if the
system should approach a limiting behavior the tanh function is appropriate
Weight adaptation is also complicated by relaxing the common practice of restricting interconnections to adjacent layers Equation shows that the calculated error for a hidden layergiven comparable weights fanouts and output errors-will be one quarter or less than that of the
output layer This is caused by the slope ractor oil The difference in error magnitudes is
not noticeable in networks restricted to adjacent layer interconnectivity But when this constraint
is released the effect of errors originating directly from an output unit has times the magnitude
and effect of an error originating from a hidden unit removed layers from the output layer
Compared to the corrections arising from the output units those from the hidden units have little
influence on weight adjustment and the power of a multilayer structure is weakened The system
will train if we restrict connections to adjacent layers but it trains slowly To compensate for this
effect we attenuate the error magnitudes originating from the output layer by the above factor
This heuristic procedure works well and racilitates smooth learning
Though we have made progress in real-time learning systems using GDR compared to
humans-who can learn from a single data presentation-they remain relatively sluggish in learning
and response rates We are interested in improvements of the GDR algorithm or alternative
architectures that facilitate one-shot or rapid learning In the latter case we are considering least
squares restoration techniquesl4 and Grossberg and Carpenter's adaptive resonance modelsI3,5
The construction of automated expert systems by observation of human personnel is
attractive because of its efficient use of the expert's time and effort Though the classic AI
approach of rule base inference is applicable when such rules are clear cut and well organized too
often a human expert can not put his decision making process in words or specify the values of
parameters that influence him The attraction or ANS based systems is that imitations of expert
behavior emerge as a natural consequence of their training

<<----------------------------------------------------------------------------------------------------------------------->>

title: 55-mathematical-analysis-of-learning-behavior-of-neuronal-models.pdf

MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
By
JOHN Y. CHEUNG
MASSOUD OMIDVAR
SCHOOL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCE
UNIVERSITY OF OKLAHOMA
NORMAN OK
Presented to the IEEE Conference on Neural Information Processing SystemsNatural and Synthetic Denver November and to be published in
the Collection of Papers from the IEEE Conference on NIPS
Please address all further correspondence to
John Y. Cheung
School of EECS
W. Boyd CEC
Norman OK
November
American Institute of Physics
MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
John Y. Cheung and Massoud Omidvar
School of Electrical Engineering
and Computer Science
ABSTRACT
In this paper we wish to analyze the convergence behavior of a number
of neuronal plasticity models Recent neurophysiological research suggests that
the neuronal behavior is adaptive In particular memory stored within a neuron
is associated with the synaptic weights which are varied or adjusted to achieve
learning A number of adaptive neuronal models have been proposed in the
literature Three specific models will be analyzed in this paper specifically the
Hebb model the Sutton-Barto model and the most recent trace model In this
paper we will examine the conditions for convergence the position of convergence and the rate at convergence of these models as they applied to classical
conditioning Simulation results are also presented to verify the analysis
INTRODUCTION
A number of static models to describe the behavior of a neuron have been
in use in the past decades More recently research in neurophysiology suggests
that a static view may be insufficient Rather the parameters within a neuron
tend to vary with past history to achieve learning It was suggested that by
altering the internal parameters neurons may adapt themselves to repetitive
input stimuli and become conditioned Learning thus occurs when the neurons
are conditioned To describe this behavior of neuronal plasticity a number
of models have been proposed The earliest one may have been postulated
by Hebb and more recently by Sutton and Barto We will also introduce a
new model the most recent trace MRT model in this paper The primary
objective of this paper however is to analyze the convergence behavior of these
models during adaptation
The general neuronal model used in this paper is shown in Figure There
are a number of neuronal inputs N. Each input is scaled by
the corresponding synaptic weights N. The weighted inputs
are arithmetically summed
where is taken to be zero
Neuronal inputs are assumed to take on numerical values ranging from zero
to one inclusively Synaptic weights are allowed to take on any reasonable values
for the purpose of this paper though in reality the weights may very well be
bounded Since the relative magnitude of the weights and the neuronal inputs
are not well defined at this point we will not put a bound on the magnitude
of the weights also The neuronal output is normally the result of a sigmoidal
transformation For simplicity we will approximate this operation by a linear
transformation
Sigmodial
Transfonution
neuronal
output
rilure
A leneral aeuronal adel
For convergence analysis we will assume that there are only two neuronal
inputs in the traditional classical conditioning environment for simplicity Of
course the analysis techniques can be extended to any number of inputs In
classical conditioning the two inputs are the conditioned stimulus Xc and
the unconditioned stimulus
THE SUTTON-BARTO MODEL
More recently Sutton and Barto have proposed an adaptive model based
on both the signal trace and the output trace as given below
y(t
Xi(t axi(t Xi(t
where both a and are positive constants
Condition of Convergence
In order to simplify the analysis we will choose
and
and
y(t
In other words becomes
Wi(t
Wi(t CXi(t)(y(t y(t
The above assumption only serves to simplify the analysis and will not affect the
convergence conditions because the boundedness of and only depends
on that for Xi(t and y(t respectively
As in the previous section we recognize that is a recurrence relation so
convergence can be checked by the ratio test It is also possible to rewrite
in matrix format Due to the recursion of the neuronal output in the equation
we will include the neuronal output in the parameter vector also
or
To show convergence we need to set the magnitude of the determinant of
A to be less than unity
Hence the condition for convergence is
From we can see that the adaptation constant must be chosen to be less
than the reciprocal of the Euclidean sum of energies of all the inputs The
same techniques can be extended to any number of inputs This can be proved
merely by following the same procedures outlined above
Position At Convergence
Having proved convergence of the Sutton-Barto model equations of neuronal plasticity we want to find out next at what location the system remains
when converged We have seen earlier that at convergence the weights cease to
change and so does the neuronal output We will denote this converged position
as In other words
Since any arbitrary parameter vector can always be decomposed into a weighted
sum of the eigenvectors
The constants Ql and Q3 can easily be found by inverting The
eigenvalues of can be shown to be and When is
within the region of convergence the magnitude of the third eigenvalue is less
than unity That means that at convergence there will be no contribution from
the third eigenvector Hence
From we can predict precisely what the converged position would be given
only with the initial conditions
Rate of Convergence
We have seen that when is carefully chosen the Sutton-Barto model will
converge and we have also derived an expression for the converged position
Next we want to find out how fast convergence can be attained The rate
of convergence is a measure of how fast the initial parameter approaches the
optimal position The asymptotic rate of convergence is
where SeA is the spectral radius and is equalled to in this
case This completes the convergence analysis on the Sutton-Barto model of
neuronal plasticity
THE MRT MODEL OF NEURONAL PLASTICITY
The most recent trace MRT model of neuronal plasticity developed by
the authors can be considered as a cross between the Sutton-Barto model and
the Klopf's model The adaptation of the synaptic weights can he expressed
as follows
A comparison of and the Sutton-Barto model in ahOWl that the cond
term on the right hand aide contains an extra factor which iI used to
apeed up the convergence as ahoWD later The output trace hu been replaced
by If(t the most recent output hence the name the most recent trace
model The input trace is also replaced by the most recent input
Condition of Convergence
We can now proceed to analyze the condition of convergence for the MRT
model Due to the presence of the Wi(t factor in the second term in the
ratio test cannot be applied here To analyze the convergence behavior further
let us rewrite in matrix format
WI(t
y(t
or
The superscript denotes the matrix transpose operation The above equation
is quadratic in Complete convergence analysis of this equation is
extremely difficult
In order to understand the convergence behavior of we note that
the dominant term that determines convergence mainly relates to the second
quadratic term Hence for convergence analysis only we will ignore the first
term
We can readily see from above that the primary convergence factor is BT
Since is only dependent on convergence can be obtained if the duration
of the synaptic inputs being active is bounded It can be shown that the
condition of convergence is bounded by
We can readily see that the adaptation constant can be chosen according
to to ensure convergence for T.
SIMULATIONS
To verify the theoretical analysis of these three adaptive neuronal models
based on classical conditioning these models have been simulated on the mM
mainframe using the FORTRAN language in single precision Several test
scenarios have been designed to compare the analytical predictions with actual
simulation results
To verify the conditions for convergence we will vary the value of the
adaptation constant The conditioned and unconditioned stimuli were set
to unity and the value of varies between to For the Sutton-Barto
model the simulation given in shows that convergence is obtained for
as expected from theoretical analysis For the MRT model simulation
results given in shows that convergence is obtained for also as
expected from theoretical analysis The theoretical location at convergence for
the Sutton and Barto model is also shown in Figure It is readily seen that
the simulation results confirm the theoretical expectations
I
Output
Figure lou or MuroD&l tpuu YeT.US Ule er of for the
Suttoa-Barto el witb 1frerent alues of aptat1on CODstant
lleuroul
Output
I
I
I
a
Ju.ber of iteratiOGa
Figure Plotl of oeuroaal outputl craus the uuaber of iteratious
for the MaT el with different alues of adantatlon
I:DDStaut
To illustrate the rate of convergence we will plot the trajectory of the
deviation in synaptic weights from the optimal values in the logarithmic scale
since this error is logarithmic as found earlier The slope of the line yields the
rate of convergence The trajectory for the Sutton-Barto Model is given in
Figure while that for the MRT model is given in Figure It is clear from
Figure that the trajectory in the logarithmic form is a straight line The
slope can readily be calculated The curve for the MRT model
given in Figure is also a straight line but with a much larger slope showing
faster convergence
SUMMARY
In this paper we have sought to discover analytically the convergence
behavior of three adaptive neuronal models From the analysis we see that
the Hebb model does not converge at all With constant active inputs the
output will grow exponentially In spite of this lack of convergence the Hebb
model is still a workable model realizing that the divergent behavior would
be curtailed by the sigmoidal transformation to yield realistic outputs The
I
uroul
Output
Dniatiotl
Lto
I
I
u.ber of iterationa
Figure
Trajectories of Deuronal output deviationa froa atatic alues
for the Sutton-"rt el with lfferent value adaptation
cOIIstallt C.
lleuroD&l
Output
Deviation
Ltl
I
Nuaber of iterations
Figure
Trajectories of neuronal output deviations fra atatic
values for tbe KRT el witb different values of
adaptation constant
analysis on the Sutton and Barto model shows that this model will converge
when the adaptation constant is carefully chosen The bounds for is also
found for this model Due to the structure of this model both the location at
convergence and the rate of convergence are also found We have also introduced
a new model of neuronal plasticity called the most recent trace MRT model
Certain similarities exist between the MRT model and the Sutton-Barto model
and also between the MRT model and the Klopf model Analysis shows that the
update equations for the synaptic weights are quadratic resulting in polynomial
rate of convergence Simulation results also show that much faster convergence
rate can be obtained with the MRT model

<<----------------------------------------------------------------------------------------------------------------------->>

title: 51-reflexive-associative-memories.pdf

REFLEXIVE ASSOCIATIVE MEMORIES
Hendrlcus G. Loos
Laguna Research Laboratory Fallbrook CA
ABSTRACT
In the synchronous discrete model the average memory capacity of
bidirectional associative memories BAMs is compared with that of
Hopfield memories by means of a calculat10n of the percentage of good
recall for random BAMs of dimension for different numbers
of stored vectors The memory capac1ty Is found to be much smal1er than
the Kosko upper bound which Is the lesser of the two dimensions of the
BAM. On the average a BAM has about 68 of the capacity of the
corresponding Hopfield memory with the same number of neurons Orthonormal coding of the BAM Increases the effective storage capaCity by
only The memory capacity limitations are due to spurious stable
states which arise In BAMs In much the same way as in Hopfleld
memories Occurrence of spurious stable states can be avoided by
replacing the thresholding in the backlayer of the BAM by another
nonl1near process here called Dominant Label Selection The
simplest DLS is the wlnner-take-all net which gives a fault-sensitive
memory Fault tolerance can be improved by the use of an orthogonal or
unitary transformation An optical application of the latter is a Fourier
transform which is implemented simply by a lens
INTRODUCT ION
A reflexive associative memory also called bidirectional associative memory is a two-layer neural net with bidirectional connections
between the layers This architecture is implied by Dana Anderson's
optical resonator and by similar configurations Bart KoSk0 coined
the name Bidirectional Associative Memory and Investigated
several basic propertles We are here concerned with the memory
capac1ty of the BAM with the relation between BAMs and Hopfleld
memories and with certain variations on the BAM.
American Institute of Physics
BAM STRUCTURE
We will use the discrete model In which the state of a layer of
neurons Is described by a bipolar vector The Dirac notationS will be
used In which I and I denote respectively column and row vectors al
and la are each other transposes alb Is a scalar product and la><bl is
an outer product As depicted in the BAM has two layers of
neurons a front layer of Nneurons tth state vector and a back layer
back layer neurons
back
of neurons with state vector
state vector
stroke
Ib>. The bidirectional connectlons between the layers allow
signal flow In two directions
frOnt1ay~r eurons forward
The front stroke gives
state vector
stroke
s(Blf where the connecFig BAM structure
tlon matrix and Is a threshold function operating at
zero The back stroke results 1n an u~graded front state
whIch also may be wr1tten as Ib where the superscr1pt
denotes transpos1t10n We consider the synchronous model where all
neurons of a layer are updated s1multaneously but the front and back
layers are UPdated at d1fferent t1mes The BAM act10n 1s shown 1n F1g.
The forward stroke entalls takIng scalar products between a front
state vector If and the rows or and enter1ng the thresholded results
as elements of the back state vector Ib>. In the back stroke we take
threshold ing
reflection
lID
NxP
FIg. BAM act
threshold ing
reflection
hreShOlding
4J
NxN
feedback
Ftg. Autoassoc1at1ve
memory act10n
scalar products of Ib w1th column vectors of and enter the
thresholded results as elements of an upgraded state vector In
contrast the act10n of an autoassoc1at1ve memory 1s shown 1n F1gure
The BAM may also be described as an autoassoc1at1ve memory5 by
concatenating the front and back vectors tnto a s1ngle state vector
Iv>=lf,b>,and by taking the connection matrtx as shown in F1g.
This autoassoclat1ve memory has the same number of neurons as our
BAM viz N+P. The BAM operat1on where
initially only the front state 1s specif thresholding
zero IDT
feedback
f1ed may be obtained with the corresponding autoassoc1ative memory by
lID zero
initially spectfying Ib as zero and by
BAM as autoassoarranging the threshold1ng operat1on
ctative memory
such that does not alter the state
vector component For a Hopfteld
memory7 the connection matrix 1s
mD MI
m=l
I
where to are stored vectors and I is the tdentity matr1x
Writing the N+P d1mens1onal vectors as concatenations Idm,c
takes the form
I
ldm><dml+lcm><cml+ldm><cml+lcm><dmD)-MI
m=l
w1th proper block plactng of submatr1ces understood Writing
Llcm><dml
m=l
Hd=(Lldm><dmD-MI
L'lcm><cml>-MI
m=l
m=l
where the I are identities in appropriate subspaces the Hopfield matrix
may be partitioned as shown in is just the BAM matrix given
by Kosko and previously used by Kohonen for linear heteroassoclatjve
memories Comparison of Figs and shows that in the synchronous
discrete model the BAM with connection matrix is equivalent to a
Hopfield memory in which the diagonal blocks Hd and Hc have been
deleted Since the Hopfleld memory is robust this prun1ng may not
affect much the associative recall of stored vectors if is small
however on the average pruning will not improve the memory capaclty
It follows that on the average a discrete synchronous BAM with matrix
can at best have the capacity of a Hopfleld memory with the same
number of neurons
We have performed computations of the average memory capacity
for BAMs and for corresponding Hopfleld memories
Monte Carlo calculations were done for memories each of which
stores random bipolar vectors The straight recall of all these vectors
was checked al10wtng for 24 Iterations For the BAMs the iterations
were started with a forward stroke in which one of the stored vectors
Idm was used as input The percentage of good recall and its standard
deviation were calculated The results plotted in show that the
square BAM has about of the capacity of the corresponding Hopfleld
memory Although the total number of neurons is the same the BAM only
needs of the number of connections of the Hopfield memory The
storage capacity found Is much smaller than the Kosko upper bound
which Is min
Partitioned
Hopfield matrix
M. number of stored vectors
of good recall versus
CODED BAM
So far we have considered both front and back states to be used for
data There is another use of the BAM in which only front states are used
as data and the back states are seen as providing a code label or
pOinter for the front state Such use was antiCipated in our expression
for the BAM matrix which stores data vectors Idm and their labels or
codes lem For a square BAM. such an arrangement cuts the Information
contained in a single stored data vector jn half However the freedom of
choosing the labels fC may perhaps be put to good use Part of the
problem of spurious stable states which plagues BAMs as well as
Hopf1eld memories as they are loaded up is due to the lack of
orthogonality of the stored vectors In the coded BAM we have the
opportunity to remove part of this problem by choosing the labels as
orthonorma1 Such labels have been used previously by Kohonen 1n linear
heteroassociative memories The question whether memory capacity can
be Improved In this manner was explored by taking BAt1s In which
the labels are chosen as Hadamard vectors The latter are bipolar vectors
with Euclidean norm which form an orthonormal set These vectors
are rows of a PxP Hadamard matrix for a discussion see Harwtt and
Sloane The storage capacity of such Hadamard-coded BAMs was
calculated as function of the number of stored vectors for cases
for each value of in the manner discussed before The percentage of
good recall and its standard deviation are shown 1n It Is seen that
the Hadamard coding gives about a factor in compared to the
ordinary BAM. However the coded BAM has only half the stored
data vector dimension Accounting for this factor reduction of data
vector dimension the effective storage capacity advantage obtained by
Hadamard coding comes to only
HALF BAt1 WITH HADAMARD CODING
For the coded BAM there is the option of deleting the threshold
operation In the front layer The resulting architecture may be called
half In the half BAM thresholding Is only done on the labels and
consequently the data may be taken as analog vectors Although such an
arrangement diminishes the robustness of the memory somewhat there
are applications of interest We have calculated the percentage of good
recall for cases and found that giving up the data thresholding cuts
the storage capacity of the Hadamard-coded BAt1 by about
SELECTIVE REFLEXIVE MEMORY
The memory capacity limitations shown in are due to the
occurence of spurious states when the memories are loaded up
Consider a discrete BAM with stored data vectors to
orthonormal labels Icm and the connection matrix
For an input data vector Iv which is closest to the stored data vector
one has 1n the forward stroke
Ib>=s(clc
amlcm
where
llv
and
am=<mlv
Although for am<c for some vector component the sum
amlc
may accumulate to such a large value as to affect the thresholded result
Ib>. The problem would be avoided jf the thresholding operation in the
back layer of the BAM were to be replaced by another nonl1near operation
which selects from the I inear combination
clc
amlcm
the dominant label Ic The hypothetical device which performs this
operation is here called the Dominant Label Selector DLS and we
call the resulting memory architecture Selective Reflexive Memory
With the back state selected as the dominant label Ic the back
stroke gives by the orthogonal ity of the labels
Icm It follows that the SRM g1ves perfect assoc1attve recall of the
nearest stored data vector for any number of vectors stored Of course
the llnear independence of the P-dimensionallabel vectors Icm to
requires
The DLS must select from a linear combination of orthonormal
labels the dominant label A trivial case is obtained by choosing the
labels Icm>as basis vectors Ium which have all components zero except
for the mth component which 1s unity With this choice of labels the
DLS may be taken as a winnertake-all net as shown in
winner
This case appears to be Included in
take-all
net
Adapt Ive Resonance Theory
ART as a special sjmpllf1ed
case A relationship between
Simplest reflexive
the ordinary BAM and ART was
memory with DLS
pOinted out by KoskoS As in ART
there Is cons1derable fault sensitivity tn this memory because the
stored data vectors appear in the connectton matrix as rows
A memory with better fault tolerance may be obtained by using
orthogonal labels other than basis vectors The DLS can then be taken as
an orthogonal transformation followed by a winner-take-an net as
shown 1n is to be chosen such that 1t transforms the labels Icm
rthogonal
I
transformation
winner take-all
net
F1g. Select1ve reflex1ve
memory
tnto vectors proportional to the
basts vectors This can always
be done by tak1ng
G=[Iup><cpl
p=l
where the Icp to form a
complete orthonormal set which
contains the labels Icm m=l to M. The neurons in the DLS serve as
grandmother cells Once a single winning cell has been activated
the state of the layer Is a single basis vector say lu I this vector
must be passed back after appllcation of the transformation such
as to produce the label at the back of the BAM. Since 1s
orthogonal we have so that the reQu1red 1nverse
transformation may be accompl1shed sfmply by sending the bas1s vector
back through the transformer this gives
1IUp><cpl=<c
p=l
as required
HAlF SRM
The SRM may be modified by deleting the thresholding operation in
the front layer The front neurons then have a I inear output which is
reflected back through the SRM as shown in In this case the
stored data vectors and the
input data vectors may be taken
I near neurons
orthogonal
as analog vectors but we
transfor.1
Qu1re all the stored vectors to
mation
have the same norm The act on
winnerof the SRM proceeds in the same
I take-all
net
way as described above except
that we now require the orthoFig Half SRM with l1near
normal labels to have unit
norm It follows that just l1ke
neurons in front layer
the full SRM the half SRM gives
perfect associative recall to the nearest stored vector for any number
of stored vectors up to the dimension of the labels The latter
condition 1s due to the fact that a P-dimensional vector space can at
most conta1n orthonormal vectors
In the SRM the output transform Gis 1ntroduced in order to improve
the fauJt tolerance of the connection matrix K. This is accomplished at
the cost of some fault sensitivity of the extent of which needs to be
investigated In this regard 1t is noted that in certatn optical implementat ions of reflexive memories such as Dana Anderson's resonator I and
Similar conflgurations the transformation is a Fourier transform
which is implemented simply as a lens Such an implementation ts quite
insentive to the common semiconductor damage mechanisms
EQUIVALENT AUTOASSOCIATIVE MEMORIES
Concatenation of the front and back state vectors allows description of the SRMs tn terms of autoassociative memories For the SRM
which uses basis vectors as labels the corresponding autoassociative
memory js shown tn Fjg. This connect jon matrtx structure was also
proposed by Guest 13 The wtnner-take-all net needs to be
given t1me to settle on a basis
vector state before the state Ib
slow thres
holding
can influence the front state If>.
feedback
This may perhaps be achieved by
zero I[T
arranging the network to have a
ast thres thresholding and feedback which
WI bl olding
feedback
are fast compared with that of the
network An alternate method
Equivalent automay be to equip the network
associat lve memory
w1th an output gate which is
opened only after the net has
sett led These arrangements
present a compUcatlon and cause a delay which in some appllcations
may be 1nappropriate and In others may be acceptable in a trade
between speed and memory density
For the SRM wtth output transformer and orthonormal1abels other
than basis vectors a corresponf eedback
ding autoassoclat1ve memory may
be composed as shown In Fig.l1
thresholded
OJ OJ
An output gate in the layer is
linear
OJ
GT
I
chosen as the device which
thresholded
WI
prevents the backstroke through
output gate
the BAM to take place before the
w1nner-take-al net has settled
Autoassoc1at1ve memory
equivalent to SRM with transform
The same effect may perhaps be
achieved by choosing different
response times for the neuron
output gate
layers and These matters
wr winner-take-all
require investigation Unless
Woutput
the output transform 1s already
t@
back layer
required for other reasons as in
linear
some optical resonators the DLS
front layer
BAM connections
with output transform is clumsy
@ orthogonal transformat on
I would far better to combine
winner-take-all net
the transformer and the net
into a single network To find
Structure of SRM
such a DLS should be considered
a cha enge
The wort was partly supported by the Defense Advanced Research
projects Agency ARPA order through Contract DAAHOI-86-C
with the U.S. Army Missile Command

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 50-an-adaptive-and-heterodyne-filtering-procedure-for-the-imaging-of-moving-objects.pdf

AN ADAPTIVE AND HETERODYNE FILTERING PROCEDURE
FOR THE IMAGING OF MOVING OBJECTS
F. H. Schuling H. A. K. Mastebroek and W. H. Zaagman
Biophysics Department Laboratory for General Physics
Westersingel 34 eM Groningen The Netherlands
ABSTRACT
Recent experimental work on the stimulus velocity dependent time resolving
power of the neural units situated in the highest order optic ganglion of the
blowfly revealed the at first sight amazing phenomenon that at this high level of
the fly visual system the time constants of these units which are involved in the
processing of neural activity evoked by moving objects are roughly spokeninverse proportional to the velocity of those objects over an extremely wide range
In this paper we will discuss the implementation of a two dimensional heterodyne
adaptive filter construction into a computer simulation model The features of this
simulation model include the ability to account for the experimentally observed
stimulus-tuned adaptive temporal behaviour of time constants in the fly visual
system The simulation results obtained clearly show that the application of such
an adaptive processing procedure delivers an improved imaging technique of
moving patterns in the high velocity range
A FEW REMARKS ON THE FLY VISUAL SYSTEM
The visual system of the diptera including the blowfly Calliphora
erythrocephala is very regularly organized and allows therefore very precise
optical stimulation techniques Also long term electrophysiological recordings can
be made relatively easy in this visual system For these reasons the blowfly which
is well-known as a very rapid and clever pilot turns out to be an extremely
suitable animal for a systematic study of basic principles that may underlie the
detection and further processing of movement information at the neural level
In the fly visual system the input retinal mosaic structure is precisely
mapped onto the higher order optic ganglia lamina medulla lobula This means
that each neural column in each ganglion in this visual system corresponds to a
certain optical axis in the visual field of the compound eye In the lobula complex
a set of wide-field movement sensitive neurons is found each of which integrates
the input signals over the whole visual field of the entire eye One of these wide
field neurons that has been classified as I by Hausen has been extensively
studied both anatomically2 as well as electrophysiologically5 The
obtained results generally agree very well with those found in behavioral
optomotor experiments on movement detection and can be understood in terms of
Reichardts correlation model
The I neuron is sensitive to horizontal movement and directionally
selective very high rates of action potentials spikes up to per second can be
recorded from this element in the case of visual stimuli which move horizontally
inward from back to front in the visual field pre/erred direction whereas
movement horizontally outward from front to back null direction suppresses
its activity
American Institute of Physics
EXPERIMENTAL RESULTS AS A MODELLING BASE
When the I neuron is stimulated in its preferred direction with a step wise
pattern displacement it will respond with an increase of neural activity By
repeating this stimulus step over and over one can obtain the averaged response
after a ms latency period the response manifests itself as a sharp increase in
average firing rate followed by a much slower decay to the spontaneous activity
level Two examples of such averaged responses are shown in the Post Stimulus
Time Histograms PSTH's of figure Time to peak and peak height are related
and depend on modulation depth stimulus step size and spatial extent of the
stimulus The tail of the responses can be described adequately by an exponential
decay toward a constant spontaneous firing rate
For each setting of the stimulus parameters the response parameters
defined by equation can be estimated by a least-squares fit to the tail of the
PSTH The smooth lines in figure are the results of two such fits
tlmsl
OJ
I'JO
tf
MoO IO
Mdl05
Fig.l
I
lsI
A veraged responses PSTH's obtained from the I neuron being
adapted to smooth stimulus motion with velocities top and
bottom respectively The smooth lines represent least-squares
fits to the PSTH's of the form Values of for the
two PSTH's are and 24 ms respectively de Ruyter van Steveninck
Fitted values of as a function of adaptation velocity for three
modulation depths M. The straight line is a least-squares fit to represent
the data for in the region It has the form
f=Q with ms and de Ruyter van Steveninck
Fig.2
Figure shows fitted values of the response time constant as a function of
the angular velocity of a moving stimulus square wave grating in most
experiments which was presented to the animal during a period long enough to let
its visual system adapt to this moving pattern and before the step wise pattern
displacement which reveals was given The straight line described by
with in Is and in ms represents a least-squares fit to the data over the
velocity range from to Is. For this range varies from to roughly
ms with ms and Defining the adaptation range of as
that interval of velocities for which decreases with increasing velocity we may
conclude from figure that within the adaptation range is not very sensitive to
the modulation depth
The outcome of similar experiments with a constant modulation depth of the
pattern and a constant pattern velocity but with four different values of
the contrast frequency fc the number of spatial periods per second that
traverse an individual visual axis as determined by the spatial wavelength As of the
pattern and the pattern velocity according to fc=v lAs reveal also an almost
complete independency of the behaviour of on contrast frequency Other
experiments in which the stimulus field was subdivided into regions with different
adaptation velocities made clear that the time constants of the input channels of
the I neuron were set locally by the values of the stimulus velocity in each
stimulus sub-region Finally it was found that the adaptation of is driven by
the stimulus velocity independent of its direction
These findings can be summarized qualitatively as follows in steady state
the response time constants of the neural units at the highest level in the fly
visual system are found to be tuned locally within a large velocity range
exclusively by the magnitude of the velocity of the moving pattern and not by its
direction despite the directional selectivity of the neuron itself We will not go
into the question of how this amazing adaptive mechanism may be hard-wired in
the fly visual system Instead we will make advantage of the results derived thus
far and attempt to fit the experimental observations into an image processing
approach A large number of theories and several distinct classes of algorithms to
encode velocity and direction of movement in visual systems have been suggested
by for example Marr and Ullman I I and van Santen and Sperling12
We hypothesize that the adaptive mechanism for the setting of the time
constants leads to an optimization for the overall performance of the visual system
by realizing a velocity independent representation of the moving object In other
words within the range of velocities for which the time constants are found to be
tuned by the velocity the representation of that stimulus at a certain level within
the visual circuitry should remain independent of any variation in stimulus
velocity
OBJECT MOTION DEGRADATION MODELLING
Given the physical description of motion and a linear space invariant model
the motion degradation process can be represented by the following convolution
integral
co co
JJ
flu dudv
where is the object intensity at position in the object coordinate
frame is the Point Spread Function PSF of the imaging system
which is the response at to a unit pulse at and is the image
intensity at the spatial position as blurred by the imaging system Any
possible additive white noise degradation of the already motion blurred image is
neglected in the present considerations
For a review of principles and techniques in the field of digital image
degradation and restoration the reader is referred to Harris 13 Sawchuk
Sondhi Nahi A boutalib 17 18 Hildebrand 19 Rajala de Figueiredo20
It has been demonstrated first by Aboutalib that for situations in which
the motion blur occurs in a straight line along one spatial coordinate say along the
horizontal axis it is correct to look at the blurred image as a collection of
degraded line scans through the entire image The dependence on the vertical
coordinate may then be dropped and eq reduces to
f(u)du
Given the mathematical description of the relative movement
corresponding PSF can be derived exactly and equation becomes
b(x f(u)du
the
where is the extent of the motion blur Typically a discrete version of
applicable for digital image processing purposes is described by
I
where and I take on integer values and is related to the motion blur extent
According to Aboutalib 18 a scalar difference equation model
can then be derived to model the motion degradation process
cmA(i-m
where is the m-dimensional state vector at position along a scan line is
the input intensity at position is the output intensity is the blur extent
is the number of elements in a line is a scalar a and are constant
matrices of order mxl and lxm respectively containing the discrete
values Cj of the blurring PSF for and is the Kronecker delta
function
INFLUENCE OF BOTH TIME CONSTANT AND VELOCITY
ON THE AMOUNT OF MOTION BLUR IN AN ARTIFICIAL
RECEPTOR ARRAY
To start with we incorporate in our simulation model a PSF derived from
equation to model the performance of all neural columnar arranged filters in
the lobula complex with the restriction that the time constants remain fixed
throughout the whole range of stimulus velocities Realization of this PSF can
easily be achieved via the just mentioned state space model
I.
I.
Fig.3
POSITION IN
ARTIFICIAL RECEPTOR ARRAY
upper part Demonstration of the effect that an increase in magnitude of
the time constants of an one-dimensional array of filters will result in
increase in motion blur while the pattern velocity remains constant
Original pattern shown in solid lines is a square-wave grating with a
spatial wavelength equal to artificial receptor distances The three
other wave forms drawn show that for a gradual increase increase in
magnitude of the time constants the representation of the original
square-wave will consequently degrade lower part A gradual increase in
velocity of the moving square-wave while the filter time constants are
kept fixed results also in a clear increase of degradation
First we demonstrate the effect that an increase in time constant while the
pattern velocity remains the same will result in an increase in blur Therefore we
introduce an one dimensional array of filters all being equipped with the same
time constant in their impulse response The original pattern shown in square and
solid lines in the upper part of figure consists of a square wave grating with a
spatial period overlapping artificial receptive filters The other patterns drawn
there show that for the same constant velocity of the moving grating an increase
in the magnitude of the time constants of the filters results in an increased blur in
the representation of that grating On the other hand an increase in velocity
while the time constants of the artificial receptive units remain the same also
results in a clear increase in motion blur as demonstrated in the lower part of
figure
Inspection of the two wave forms drawn by means of the dashed lines in
both upper and lower half of the figure yields the conclusion that apart from
rounding errors introduced by the rather small number of artificial filters
available equal amounts of smear will be produced when the product of time
constant and pattern velocity is equal For the upper dashed wave form the
velocity was four times smaller but the time constant four times larger than for its
equivalent in the lower part of the figure
ADAPTIVE SCHEME
In designing a proper image processing procedure our next step is to
incorporate the experimentally observed flexibility property of the time constants
in the imaging elements of our device In figure 4a a scheme is shown which
filters the information with fixed time constants not influenced by the pattern
velocity In figure 4b a network is shown where the time constants also remain
fixed no matter what pattern movement is presented but now at the next level of
information processing a spatially differential network is incorporated in order to
enhance blurred contrasts
In the filtering network in figure 4c first a measurement of the magnitude
of the velocity of the moving objects is done by thus far hypothetically introduced
movement processing algorithms modelled here as a set of receptive elements
sampling the environment in such a manner that proper estimation of local pattern
velocities can be done Then the time constants of the artificial receptive elements
will be tuned according to the estimated velocities and finally the same
differential network as in scheme 4b is used
The actual tuning mechanism used for our simulations is outlined in figure
once given the range of velocities for which the model is supposed to be
operational and given a lower limit for the time constant min min can be the
smallest value which physically can be realized the time constant will be tuned to
a new value according to the experimentally observed reciprocal relationship and
will for all velocities within the adaptive range be larger than the fixed minimum
value As demonstrated in the previous section the corresponding blur in the
representation of the moving stimulus will thus always be larger than for the
situation in which the filtering is done with fixed and smallest time constants
min More important however is the fact that due to this tuning mechanism the
blur will be constant since the product of velocity and time constant is kept
constant So once the information has been processed by such a system a velocity
independent representation of the image will be the result which can serve as the
input for the spatially differentiating network as outlined in figure 4c
The most elementary form for this differential filtering procedure is the one
in which the gradient of two filters K-I and K+l which are the nearest neighbors
of filter is taken and then added with a constant weighing factor to the central
output as drawn in figure and where the sign of the gradient depends on
the direction of the estimated movement Essential for our model is that we claim
that this weighing factor should be constant throughout the whole set of filters
and for the whole high velocity range in which the heterodyne imaging has to be
performed Important to notice is the existence of a so-called settling time the
minimal time needed for our movement processing device to be able to accurately
measure the object velocity Note this time can be set equal to zero in the case
that the relative stimulus velocity is known a priori as demonstrated in figure
Since without doubt within this settling period estimated velocity values will
come out erroneously and thus no optimal performance of our imaging device can
be expected in all further examples results after this initial settling procedure
will be shown
A
yV
rYO
i~J
t"if
Pattern movement in this figure is to the right
A Network consisting of a set of filters with a fixed pattern velocity
independent time constant in their impulse response
Identical network as in figure 4A now followed by a spatially
differentiating circuitry which adds the weighed gradients of two
neighboring filter outputs K-l and K+I to the central filter output
K.
The time constants of the filtering network are tuned by a
hypothetical movement estimating mechanism visualized here as a
number of receptive elements of which the combined output tunes
the filters A detailed description of this mechanism is shown in
figure This tuned network is followed by an identical spatially
differentiating circuit as described in figure
increasing velocity
decreasing time constant
min
Detailed description of the mechanism used to tune the time constants
The time constant of a specific neural channel is set by the pattern
velocity according to the relationship shown in the insert which is
derived from eq with I and I.
4r
I
I
I
I
I
I
I
I
4V
I
I
a
2V
Wi
8V
I
POSITION IN ARTIFICIAL RECEPTOR ARRAY
Fig.6
Thick lines square-wave stimulus pattern with a spatial wavelength
overlapping 32 artificial receptive elements Thick lines responses for
different pattern velocities in a system consisting of paralleling neural
filters equipped with time constants tuned by this velocity and followed
by a spatially differentiating network as described
Dashed lines responses to the different pattern velocities in a filtering
system with fixed time constants followed by the same spatial
differentiating circuitry as before Note the sharp over and under
shoots for this case
Results obtained with an imaging procedure as drawn in figure and 4c
are shown in figure The pattern consists of a square wave overlapping 32
picture elements The pattern moves to the left with different velocities
At each velocity only one wavelength is shown Thick lines
square wave pattern Dashed lines the outputs of an imaging device as depicted in
figure constant time constants and a constant weighing factor in the spatial
processing stage Note the large differences between the several outputs Thin
continuous lines the outputs of an imaging device as drawn in figure tuned
time constants according to the reciprocal relationship between pattern velocity
and time constant and a constant weighing factor in the spatial processing stage
For further simulation details the reader is referred to Zaagman Now the
outputs are almost completely the same and in good agreement with the original
stimulus throughout the whole velocity range
Figure shows the effect of the gradient weighing factor on the overall
filter performance estimated as the improvement of the deblurred images as
compared with the blurred image measured in dB This quantitative measure has
been determined for the case of a moving square wave pattern with motion blur
IX
ItI
a
weighing factor
Effect of the weighing factor on the overall filter performance Curve
measured for the case of a moving square-wave grating Filter
performance is estimated as the improvement in signal to noise ratio
I:iI
where is the original intensity at position in the image
is the intensity at the same position in the motion blurred image and
is the intensity at in the image generated with the adaptive
tuning procedure
extents comparable to those used for the simulations to be discussed in section IV.
From this curve it is apparent that for this situation there is an optimum value for
this weighing factor Keeping the weight close to this optimum value will result in
a constant output of our adaptive scheme thus enabling an optimal deblurring of
the smeared image of the moving object
On the other hand starting from the point of view that the time constants
should remain fixed throughout the filtering process we should had have to tune
the gradient weights to the velocity in order to produce a constant output as
demonstrated in figure where the dashed lines show strongly differing outputs of
a fixed time constant system with spatial processing with constant weight figure
4b In other words tuning of the time constants as proposed in this section results
in I the realization of the blur-constancy criterion as formulated previously and
as a consequence the possibility to deblur the obtained image oPtimally with
one and the same weighing factor of the gradient in the final spatial processing
layer over the whole heterodyne velocity range
COMPUTER SIMULATION RESULTS AND
CONCLUSIONS
The image quality improvement algorithm developed in the present
contribution has been implemented on a general purpose DG Eclipse Sjl40 minicomputer for our two dimensional simulations Figure Sa shows an undisturbed
image consisting of lines of each pixels with bit intensity resolution
Figure Sb shows what happens with the original image if the PSF is modelled
according to the exponential decay In this case the time constants of all
spatial information processing channels have been kept fixed Again information
content in the higher spatial frequencies has been reduced largely The
implementation of the heterodyne filtering procedure was now done as follows
first the adaptation range was defined by setting the range of velocities This
means that our adaptive heterodyne algorithm is supposed to operate adequately
only within the thus defined velocity range and that in that range the time
constants are tuned according to relationship and will always come out larger
than the minimum value min For demonstration purposes we set Q=I and in
eq thus introducing the phenomenon that for any velocity the two
dimensional set of spatial filters with time constants tuned by that velocity will
always produce a constant output independent of this velocity which introduces
the motion blur Figure Sc shows this representation It is important to note here
that this constant output has far more worse quality than any set of filters with
smallest and fixed time constants min would produce for velocities within the
operational range The advantage of a velocity independent output at this level in
our simulation model is that in the next stage a differential scheme can be
implemented as discussed in detail in the preceding paragraph Constancy of the
weighing factor which is used in this differential processing scheme is guaranteed
by the velocity independency of the obtained image representation
Figure Sd shows the result of the differential operation with an optimized
gradient weighing factor This weighing factor has been optimized based on an
almost identical performance curve as described previously in figure A clear
and good restoration is apparent from this figure though close inspection reveals
fine structure especially for areas with high intensities which is unrelated with
the original intensity distribution These artifacts are caused by the phenomenon
that for these high intensity areas possible tuning errors will show up much more
pronounced than for low intensities
Fig.8a
Fig.8b
8c
Fig.8d
a
Original bit picture
Motion degraded image with a PSF derived from
where is kept fixed to pixels and the motion blur extent is 32
pixels
Worst case the result of motion degradation of the original image
with a PSF as in figure 8b but with tuning of the time constants based
on the velocity
Restored version of the degraded image using the heterodyne adaptive
processing scheme
In conclusion a heterodyne adaptive image processing technique inspired by
the fly visual system has been presented as an imaging device for moving objects
A scalar difference equation model has been used to represent the motion blur
degradation process Based on the experimental results described and on this state
space model we developed an adaptive filtering scheme which produces at a
certain level within the system a constant output permitting further differential
operations in order to produce an optimally deblurred representation of the
moving object
ACKNOWLEDGEMENTS
The authors wish to thank mT Eric Bosman for his expert programming
assistance mr Franco Tommasi for many inspiring discussions and advises during
the implementation of the simulation model and dr Rob de Ruyter van Steveninck
for experimental help This research was partly supported by the Netherlands
Organization lor the Advancement 01 Pure Research through the
foundation Stichting voor Biolysica

<<----------------------------------------------------------------------------------------------------------------------->>

title: 51-reflexive-associative-memories.pdf

REFLEXIVE ASSOCIATIVE MEMORIES
Hendrlcus G. Loos
Laguna Research Laboratory Fallbrook CA
ABSTRACT
In the synchronous discrete model the average memory capacity of
bidirectional associative memories BAMs is compared with that of
Hopfield memories by means of a calculat10n of the percentage of good
recall for random BAMs of dimension for different numbers
of stored vectors The memory capac1ty Is found to be much smal1er than
the Kosko upper bound which Is the lesser of the two dimensions of the
BAM. On the average a BAM has about 68 of the capacity of the
corresponding Hopfield memory with the same number of neurons Orthonormal coding of the BAM Increases the effective storage capaCity by
only The memory capacity limitations are due to spurious stable
states which arise In BAMs In much the same way as in Hopfleld
memories Occurrence of spurious stable states can be avoided by
replacing the thresholding in the backlayer of the BAM by another
nonl1near process here called Dominant Label Selection The
simplest DLS is the wlnner-take-all net which gives a fault-sensitive
memory Fault tolerance can be improved by the use of an orthogonal or
unitary transformation An optical application of the latter is a Fourier
transform which is implemented simply by a lens
INTRODUCT ION
A reflexive associative memory also called bidirectional associative memory is a two-layer neural net with bidirectional connections
between the layers This architecture is implied by Dana Anderson's
optical resonator and by similar configurations Bart KoSk0 coined
the name Bidirectional Associative Memory and Investigated
several basic propertles We are here concerned with the memory
capac1ty of the BAM with the relation between BAMs and Hopfleld
memories and with certain variations on the BAM.
American Institute of Physics
BAM STRUCTURE
We will use the discrete model In which the state of a layer of
neurons Is described by a bipolar vector The Dirac notationS will be
used In which I and I denote respectively column and row vectors al
and la are each other transposes alb Is a scalar product and la><bl is
an outer product As depicted in the BAM has two layers of
neurons a front layer of Nneurons tth state vector and a back layer
back layer neurons
back
of neurons with state vector
state vector
stroke
Ib>. The bidirectional connectlons between the layers allow
signal flow In two directions
frOnt1ay~r eurons forward
The front stroke gives
state vector
stroke
s(Blf where the connecFig BAM structure
tlon matrix and Is a threshold function operating at
zero The back stroke results 1n an u~graded front state
whIch also may be wr1tten as Ib where the superscr1pt
denotes transpos1t10n We consider the synchronous model where all
neurons of a layer are updated s1multaneously but the front and back
layers are UPdated at d1fferent t1mes The BAM act10n 1s shown 1n F1g.
The forward stroke entalls takIng scalar products between a front
state vector If and the rows or and enter1ng the thresholded results
as elements of the back state vector Ib>. In the back stroke we take
threshold ing
reflection
lID
NxP
FIg. BAM act
threshold ing
reflection
hreShOlding
4J
NxN
feedback
Ftg. Autoassoc1at1ve
memory act10n
scalar products of Ib w1th column vectors of and enter the
thresholded results as elements of an upgraded state vector In
contrast the act10n of an autoassoc1at1ve memory 1s shown 1n F1gure
The BAM may also be described as an autoassoc1at1ve memory5 by
concatenating the front and back vectors tnto a s1ngle state vector
Iv>=lf,b>,and by taking the connection matrtx as shown in F1g.
This autoassoclat1ve memory has the same number of neurons as our
BAM viz N+P. The BAM operat1on where
initially only the front state 1s specif thresholding
zero IDT
feedback
f1ed may be obtained with the corresponding autoassoc1ative memory by
lID zero
initially spectfying Ib as zero and by
BAM as autoassoarranging the threshold1ng operat1on
ctative memory
such that does not alter the state
vector component For a Hopfteld
memory7 the connection matrix 1s
mD MI
m=l
I
where to are stored vectors and I is the tdentity matr1x
Writing the N+P d1mens1onal vectors as concatenations Idm,c
takes the form
I
ldm><dml+lcm><cml+ldm><cml+lcm><dmD)-MI
m=l
w1th proper block plactng of submatr1ces understood Writing
Llcm><dml
m=l
Hd=(Lldm><dmD-MI
L'lcm><cml>-MI
m=l
m=l
where the I are identities in appropriate subspaces the Hopfield matrix
may be partitioned as shown in is just the BAM matrix given
by Kosko and previously used by Kohonen for linear heteroassoclatjve
memories Comparison of Figs and shows that in the synchronous
discrete model the BAM with connection matrix is equivalent to a
Hopfield memory in which the diagonal blocks Hd and Hc have been
deleted Since the Hopfleld memory is robust this prun1ng may not
affect much the associative recall of stored vectors if is small
however on the average pruning will not improve the memory capaclty
It follows that on the average a discrete synchronous BAM with matrix
can at best have the capacity of a Hopfleld memory with the same
number of neurons
We have performed computations of the average memory capacity
for BAMs and for corresponding Hopfleld memories
Monte Carlo calculations were done for memories each of which
stores random bipolar vectors The straight recall of all these vectors
was checked al10wtng for 24 Iterations For the BAMs the iterations
were started with a forward stroke in which one of the stored vectors
Idm was used as input The percentage of good recall and its standard
deviation were calculated The results plotted in show that the
square BAM has about of the capacity of the corresponding Hopfleld
memory Although the total number of neurons is the same the BAM only
needs of the number of connections of the Hopfield memory The
storage capacity found Is much smaller than the Kosko upper bound
which Is min
Partitioned
Hopfield matrix
M. number of stored vectors
of good recall versus
CODED BAM
So far we have considered both front and back states to be used for
data There is another use of the BAM in which only front states are used
as data and the back states are seen as providing a code label or
pOinter for the front state Such use was antiCipated in our expression
for the BAM matrix which stores data vectors Idm and their labels or
codes lem For a square BAM. such an arrangement cuts the Information
contained in a single stored data vector jn half However the freedom of
choosing the labels fC may perhaps be put to good use Part of the
problem of spurious stable states which plagues BAMs as well as
Hopf1eld memories as they are loaded up is due to the lack of
orthogonality of the stored vectors In the coded BAM we have the
opportunity to remove part of this problem by choosing the labels as
orthonorma1 Such labels have been used previously by Kohonen 1n linear
heteroassociative memories The question whether memory capacity can
be Improved In this manner was explored by taking BAt1s In which
the labels are chosen as Hadamard vectors The latter are bipolar vectors
with Euclidean norm which form an orthonormal set These vectors
are rows of a PxP Hadamard matrix for a discussion see Harwtt and
Sloane The storage capacity of such Hadamard-coded BAMs was
calculated as function of the number of stored vectors for cases
for each value of in the manner discussed before The percentage of
good recall and its standard deviation are shown 1n It Is seen that
the Hadamard coding gives about a factor in compared to the
ordinary BAM. However the coded BAM has only half the stored
data vector dimension Accounting for this factor reduction of data
vector dimension the effective storage capacity advantage obtained by
Hadamard coding comes to only
HALF BAt1 WITH HADAMARD CODING
For the coded BAM there is the option of deleting the threshold
operation In the front layer The resulting architecture may be called
half In the half BAM thresholding Is only done on the labels and
consequently the data may be taken as analog vectors Although such an
arrangement diminishes the robustness of the memory somewhat there
are applications of interest We have calculated the percentage of good
recall for cases and found that giving up the data thresholding cuts
the storage capacity of the Hadamard-coded BAt1 by about
SELECTIVE REFLEXIVE MEMORY
The memory capacity limitations shown in are due to the
occurence of spurious states when the memories are loaded up
Consider a discrete BAM with stored data vectors to
orthonormal labels Icm and the connection matrix
For an input data vector Iv which is closest to the stored data vector
one has 1n the forward stroke
Ib>=s(clc
amlcm
where
llv
and
am=<mlv
Although for am<c for some vector component the sum
amlc
may accumulate to such a large value as to affect the thresholded result
Ib>. The problem would be avoided jf the thresholding operation in the
back layer of the BAM were to be replaced by another nonl1near operation
which selects from the I inear combination
clc
amlcm
the dominant label Ic The hypothetical device which performs this
operation is here called the Dominant Label Selector DLS and we
call the resulting memory architecture Selective Reflexive Memory
With the back state selected as the dominant label Ic the back
stroke gives by the orthogonal ity of the labels
Icm It follows that the SRM g1ves perfect assoc1attve recall of the
nearest stored data vector for any number of vectors stored Of course
the llnear independence of the P-dimensionallabel vectors Icm to
requires
The DLS must select from a linear combination of orthonormal
labels the dominant label A trivial case is obtained by choosing the
labels Icm>as basis vectors Ium which have all components zero except
for the mth component which 1s unity With this choice of labels the
DLS may be taken as a winnertake-all net as shown in
winner
This case appears to be Included in
take-all
net
Adapt Ive Resonance Theory
ART as a special sjmpllf1ed
case A relationship between
Simplest reflexive
the ordinary BAM and ART was
memory with DLS
pOinted out by KoskoS As in ART
there Is cons1derable fault sensitivity tn this memory because the
stored data vectors appear in the connectton matrix as rows
A memory with better fault tolerance may be obtained by using
orthogonal labels other than basis vectors The DLS can then be taken as
an orthogonal transformation followed by a winner-take-an net as
shown 1n is to be chosen such that 1t transforms the labels Icm
rthogonal
I
transformation
winner take-all
net
F1g. Select1ve reflex1ve
memory
tnto vectors proportional to the
basts vectors This can always
be done by tak1ng
G=[Iup><cpl
p=l
where the Icp to form a
complete orthonormal set which
contains the labels Icm m=l to M. The neurons in the DLS serve as
grandmother cells Once a single winning cell has been activated
the state of the layer Is a single basis vector say lu I this vector
must be passed back after appllcation of the transformation such
as to produce the label at the back of the BAM. Since 1s
orthogonal we have so that the reQu1red 1nverse
transformation may be accompl1shed sfmply by sending the bas1s vector
back through the transformer this gives
1IUp><cpl=<c
p=l
as required
HAlF SRM
The SRM may be modified by deleting the thresholding operation in
the front layer The front neurons then have a I inear output which is
reflected back through the SRM as shown in In this case the
stored data vectors and the
input data vectors may be taken
I near neurons
orthogonal
as analog vectors but we
transfor.1
Qu1re all the stored vectors to
mation
have the same norm The act on
winnerof the SRM proceeds in the same
I take-all
net
way as described above except
that we now require the orthoFig Half SRM with l1near
normal labels to have unit
norm It follows that just l1ke
neurons in front layer
the full SRM the half SRM gives
perfect associative recall to the nearest stored vector for any number
of stored vectors up to the dimension of the labels The latter
condition 1s due to the fact that a P-dimensional vector space can at
most conta1n orthonormal vectors
In the SRM the output transform Gis 1ntroduced in order to improve
the fauJt tolerance of the connection matrix K. This is accomplished at
the cost of some fault sensitivity of the extent of which needs to be
investigated In this regard 1t is noted that in certatn optical implementat ions of reflexive memories such as Dana Anderson's resonator I and
Similar conflgurations the transformation is a Fourier transform
which is implemented simply as a lens Such an implementation ts quite
insentive to the common semiconductor damage mechanisms
EQUIVALENT AUTOASSOCIATIVE MEMORIES
Concatenation of the front and back state vectors allows description of the SRMs tn terms of autoassociative memories For the SRM
which uses basis vectors as labels the corresponding autoassociative
memory js shown tn Fjg. This connect jon matrtx structure was also
proposed by Guest 13 The wtnner-take-all net needs to be
given t1me to settle on a basis
vector state before the state Ib
slow thres
holding
can influence the front state If>.
feedback
This may perhaps be achieved by
zero I[T
arranging the network to have a
ast thres thresholding and feedback which
WI bl olding
feedback
are fast compared with that of the
network An alternate method
Equivalent automay be to equip the network
associat lve memory
w1th an output gate which is
opened only after the net has
sett led These arrangements
present a compUcatlon and cause a delay which in some appllcations
may be 1nappropriate and In others may be acceptable in a trade
between speed and memory density
For the SRM wtth output transformer and orthonormal1abels other
than basis vectors a corresponf eedback
ding autoassoclat1ve memory may
be composed as shown In Fig.l1
thresholded
OJ OJ
An output gate in the layer is
linear
OJ
GT
I
chosen as the device which
thresholded
WI
prevents the backstroke through
output gate
the BAM to take place before the
w1nner-take-al net has settled
Autoassoc1at1ve memory
equivalent to SRM with transform
The same effect may perhaps be
achieved by choosing different
response times for the neuron
output gate
layers and These matters
wr winner-take-all
require investigation Unless
Woutput
the output transform 1s already
t@
back layer
required for other reasons as in
linear
some optical resonators the DLS
front layer
BAM connections
with output transform is clumsy
@ orthogonal transformat on
I would far better to combine
winner-take-all net
the transformer and the net
into a single network To find
Structure of SRM
such a DLS should be considered
a cha enge
The wort was partly supported by the Defense Advanced Research
projects Agency ARPA order through Contract DAAHOI-86-C
with the U.S. Army Missile Command

<<----------------------------------------------------------------------------------------------------------------------->>

title: 55-mathematical-analysis-of-learning-behavior-of-neuronal-models.pdf

MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
By
JOHN Y. CHEUNG
MASSOUD OMIDVAR
SCHOOL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCE
UNIVERSITY OF OKLAHOMA
NORMAN OK
Presented to the IEEE Conference on Neural Information Processing SystemsNatural and Synthetic Denver November and to be published in
the Collection of Papers from the IEEE Conference on NIPS
Please address all further correspondence to
John Y. Cheung
School of EECS
W. Boyd CEC
Norman OK
November
American Institute of Physics
MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR
OF NEURONAL MODELS
John Y. Cheung and Massoud Omidvar
School of Electrical Engineering
and Computer Science
ABSTRACT
In this paper we wish to analyze the convergence behavior of a number
of neuronal plasticity models Recent neurophysiological research suggests that
the neuronal behavior is adaptive In particular memory stored within a neuron
is associated with the synaptic weights which are varied or adjusted to achieve
learning A number of adaptive neuronal models have been proposed in the
literature Three specific models will be analyzed in this paper specifically the
Hebb model the Sutton-Barto model and the most recent trace model In this
paper we will examine the conditions for convergence the position of convergence and the rate at convergence of these models as they applied to classical
conditioning Simulation results are also presented to verify the analysis
INTRODUCTION
A number of static models to describe the behavior of a neuron have been
in use in the past decades More recently research in neurophysiology suggests
that a static view may be insufficient Rather the parameters within a neuron
tend to vary with past history to achieve learning It was suggested that by
altering the internal parameters neurons may adapt themselves to repetitive
input stimuli and become conditioned Learning thus occurs when the neurons
are conditioned To describe this behavior of neuronal plasticity a number
of models have been proposed The earliest one may have been postulated
by Hebb and more recently by Sutton and Barto We will also introduce a
new model the most recent trace MRT model in this paper The primary
objective of this paper however is to analyze the convergence behavior of these
models during adaptation
The general neuronal model used in this paper is shown in Figure There
are a number of neuronal inputs N. Each input is scaled by
the corresponding synaptic weights N. The weighted inputs
are arithmetically summed
where is taken to be zero
Neuronal inputs are assumed to take on numerical values ranging from zero
to one inclusively Synaptic weights are allowed to take on any reasonable values
for the purpose of this paper though in reality the weights may very well be
bounded Since the relative magnitude of the weights and the neuronal inputs
are not well defined at this point we will not put a bound on the magnitude
of the weights also The neuronal output is normally the result of a sigmoidal
transformation For simplicity we will approximate this operation by a linear
transformation
Sigmodial
Transfonution
neuronal
output
rilure
A leneral aeuronal adel
For convergence analysis we will assume that there are only two neuronal
inputs in the traditional classical conditioning environment for simplicity Of
course the analysis techniques can be extended to any number of inputs In
classical conditioning the two inputs are the conditioned stimulus Xc and
the unconditioned stimulus
THE SUTTON-BARTO MODEL
More recently Sutton and Barto have proposed an adaptive model based
on both the signal trace and the output trace as given below
y(t
Xi(t axi(t Xi(t
where both a and are positive constants
Condition of Convergence
In order to simplify the analysis we will choose
and
and
y(t
In other words becomes
Wi(t
Wi(t CXi(t)(y(t y(t
The above assumption only serves to simplify the analysis and will not affect the
convergence conditions because the boundedness of and only depends
on that for Xi(t and y(t respectively
As in the previous section we recognize that is a recurrence relation so
convergence can be checked by the ratio test It is also possible to rewrite
in matrix format Due to the recursion of the neuronal output in the equation
we will include the neuronal output in the parameter vector also
or
To show convergence we need to set the magnitude of the determinant of
A to be less than unity
Hence the condition for convergence is
From we can see that the adaptation constant must be chosen to be less
than the reciprocal of the Euclidean sum of energies of all the inputs The
same techniques can be extended to any number of inputs This can be proved
merely by following the same procedures outlined above
Position At Convergence
Having proved convergence of the Sutton-Barto model equations of neuronal plasticity we want to find out next at what location the system remains
when converged We have seen earlier that at convergence the weights cease to
change and so does the neuronal output We will denote this converged position
as In other words
Since any arbitrary parameter vector can always be decomposed into a weighted
sum of the eigenvectors
The constants Ql and Q3 can easily be found by inverting The
eigenvalues of can be shown to be and When is
within the region of convergence the magnitude of the third eigenvalue is less
than unity That means that at convergence there will be no contribution from
the third eigenvector Hence
From we can predict precisely what the converged position would be given
only with the initial conditions
Rate of Convergence
We have seen that when is carefully chosen the Sutton-Barto model will
converge and we have also derived an expression for the converged position
Next we want to find out how fast convergence can be attained The rate
of convergence is a measure of how fast the initial parameter approaches the
optimal position The asymptotic rate of convergence is
where SeA is the spectral radius and is equalled to in this
case This completes the convergence analysis on the Sutton-Barto model of
neuronal plasticity
THE MRT MODEL OF NEURONAL PLASTICITY
The most recent trace MRT model of neuronal plasticity developed by
the authors can be considered as a cross between the Sutton-Barto model and
the Klopf's model The adaptation of the synaptic weights can he expressed
as follows
A comparison of and the Sutton-Barto model in ahOWl that the cond
term on the right hand aide contains an extra factor which iI used to
apeed up the convergence as ahoWD later The output trace hu been replaced
by If(t the most recent output hence the name the most recent trace
model The input trace is also replaced by the most recent input
Condition of Convergence
We can now proceed to analyze the condition of convergence for the MRT
model Due to the presence of the Wi(t factor in the second term in the
ratio test cannot be applied here To analyze the convergence behavior further
let us rewrite in matrix format
WI(t
y(t
or
The superscript denotes the matrix transpose operation The above equation
is quadratic in Complete convergence analysis of this equation is
extremely difficult
In order to understand the convergence behavior of we note that
the dominant term that determines convergence mainly relates to the second
quadratic term Hence for convergence analysis only we will ignore the first
term
We can readily see from above that the primary convergence factor is BT
Since is only dependent on convergence can be obtained if the duration
of the synaptic inputs being active is bounded It can be shown that the
condition of convergence is bounded by
We can readily see that the adaptation constant can be chosen according
to to ensure convergence for T.
SIMULATIONS
To verify the theoretical analysis of these three adaptive neuronal models
based on classical conditioning these models have been simulated on the mM
mainframe using the FORTRAN language in single precision Several test
scenarios have been designed to compare the analytical predictions with actual
simulation results
To verify the conditions for convergence we will vary the value of the
adaptation constant The conditioned and unconditioned stimuli were set
to unity and the value of varies between to For the Sutton-Barto
model the simulation given in shows that convergence is obtained for
as expected from theoretical analysis For the MRT model simulation
results given in shows that convergence is obtained for also as
expected from theoretical analysis The theoretical location at convergence for
the Sutton and Barto model is also shown in Figure It is readily seen that
the simulation results confirm the theoretical expectations
I
Output
Figure lou or MuroD&l tpuu YeT.US Ule er of for the
Suttoa-Barto el witb 1frerent alues of aptat1on CODstant
lleuroul
Output
I
I
I
a
Ju.ber of iteratiOGa
Figure Plotl of oeuroaal outputl craus the uuaber of iteratious
for the MaT el with different alues of adantatlon
I:DDStaut
To illustrate the rate of convergence we will plot the trajectory of the
deviation in synaptic weights from the optimal values in the logarithmic scale
since this error is logarithmic as found earlier The slope of the line yields the
rate of convergence The trajectory for the Sutton-Barto Model is given in
Figure while that for the MRT model is given in Figure It is clear from
Figure that the trajectory in the logarithmic form is a straight line The
slope can readily be calculated The curve for the MRT model
given in Figure is also a straight line but with a much larger slope showing
faster convergence
SUMMARY
In this paper we have sought to discover analytically the convergence
behavior of three adaptive neuronal models From the analysis we see that
the Hebb model does not converge at all With constant active inputs the
output will grow exponentially In spite of this lack of convergence the Hebb
model is still a workable model realizing that the divergent behavior would
be curtailed by the sigmoidal transformation to yield realistic outputs The
I
uroul
Output
Dniatiotl
Lto
I
I
u.ber of iterationa
Figure
Trajectories of Deuronal output deviationa froa atatic alues
for the Sutton-"rt el with lfferent value adaptation
cOIIstallt C.
lleuroD&l
Output
Deviation
Ltl
I
Nuaber of iterations
Figure
Trajectories of neuronal output deviations fra atatic
values for tbe KRT el witb different values of
adaptation constant
analysis on the Sutton and Barto model shows that this model will converge
when the adaptation constant is carefully chosen The bounds for is also
found for this model Due to the structure of this model both the location at
convergence and the rate of convergence are also found We have also introduced
a new model of neuronal plasticity called the most recent trace MRT model
Certain similarities exist between the MRT model and the Sutton-Barto model
and also between the MRT model and the Klopf model Analysis shows that the
update equations for the synaptic weights are quadratic resulting in polynomial
rate of convergence Simulation results also show that much faster convergence
rate can be obtained with the MRT model

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 53-the-connectivity-analysis-of-simple-association.pdf

The Connectivity Analysis of Simple Association
orHow Many Connections Do You Need
Dan Hammerstrom
Oregon Graduate Center Beaverton OR
ABSTRACT
The efficient realization using current silicon technology of Very Large Connection
Networks VLCN with more than a billion connections requires that these networks exhibit
a high degree of communication locality Real neural networks exhibit significant locality
yet most connectionist/neural network models have little In this paper the connectivity
requirements of a simple associative network are analyzed using communication theory
Several techniques based on communication theory are presented that improve the robustness of the network in the face of sparse local interconnect structures Also discussed are
some potential problems when information is distributed too widely
INTRODUCTION
Connectionist/neural network researchers are learning to program networks that exhibit a broad range of cognitive behavior Unfortunately existing computer systems are limited in their ability to emulate such networks efficiently The cost of emulating a network
whether with special purpose highly parallel silicon-based architectures or with traditional
parallel architectures is directly proportional to the number of connections in the network
This number tends to increase geometrically as the number of nodes increases Even with
large massively parallel architectures connections take time and silicon area Many existing neural network models scale poorly in learning time and connections precluding large
implementations
The connectivity costs of a network are directly related to its locality A network
exhibits locality 01 communication if most of its processing elements connect to other physically adjacent processing elements in any reasonable mapping of the elements onto a planar
surface There is much evidence that real neural networks exhibit locality2 In this paper
a technique is presented for analyzing the effects of locality on the process of association
These networks use a complex node similar to the higher-order learning units of Maxwell
NETWORK MODEL
The network model used in this paper is now defined Figure
Definition A recursive neural network called a c-graph is a graph structure
where
There is a set of CNs network nodes whose outputs can take a range of positive
real values Vi between and There are N. nodes in the set
There is a set of codons that can take a range of positive real values eij for
codon of node between and There are Ne codons dedicated to each CN the
output of each codon is only used by its local so there are a total of Ne N. codons
in the network The fan-in or order of a codon is Ie. It is assumed that leis the
same for each codon and Ne is the same for each CN.
This work was supported in part by the Semiconductor Research Corporation contract no and
jointly by the Office of Naval Research and Air Force Office of Scientific Research ONR contract no NOOO14 87
American Institute of Physics
Ie
codon
Figure A ON
Cijk is a set of connections of ONs to codons and Ne Cijk can
take two values indicating the existence of a connection from ON to codon
of ON
Definition The value of ON is
Vi
F[8+~eijl
J-l
The function is a continuous non-linear monotonic function such as the sigmoid function
Definition Define a mapping where is an input vector to rand is
the Ie element input vector of codon of ON That is has as its elements those elements of Zk of where Cijk=1
The function indicates the subset of seen by codon of ON Different input vectors may map to the same codon vectors and D(i,j,Zj-y where
Definition The codon values eij are determined as follows Let be input vector
of the learned input vectors for ON For codon eij of ON let Tij be the set of I cdimensional vectors such that lij(m)E ij and That is each vector
lij in Tij consists of those subvectors of that are in codon ii's receptive field
The variable indexes the vectors of ij The number of distinct vectors in Tij
may be less than the total number of learned vectors Though the are
distinct the subsets lij(m need not be since there is a possible many to one mapping of
the vectors onto each vector lij
Let Xl be the subset of vectors where vi=l ON is supposed to output a and
those vectors where vi=O then define
izeof
for and that map to this I. That is is the number of
xo be
vectors that map
into Iij{l where
tlj-O
and is the number of vectors that map into Iii where
The compreaaion of a codon for a vector then is defined as
I IJ
Hqj(l)=O when both nt The output of codon
eii is the maximum-likelyhood
decoding
Where He indicates the likely hood of when a vector that maps to is input and
is that vector where I I and is the current input vector In other words is that vector of the set of subset learned vectors that codon ij
receives that is closest using distance measure to the subset input vector
The output of a codon is the most-likely output according to its inputs For example when there is no code compression at a codon if the closest terms of some
measure of vector distance Hamming distance subvector in the receptive field of the
codon belongs to a learned vector where the CN is to output a The codons described here
are very similar to those proposed by Marr and implement ne!'Lrest-neighbor classification
It is assumed that codon function is determined statically prior to network operation that
is the desired categories have already been learned
To measure performance network capacity is used
Definition The input noiae Or is the average between an input vector and the
closest minimum learned vector where is a measure of the difference between two
vectors for bit vectors this can be Hamming distance The output noise is the average
distance between network output and the learned output vector associated with the closest
learned input vector The in/ormation gain Gr is just
Gt
I
Definition The capacity of a network is the maximum number of learned vectors such
that the information gain Gr is strictly positive
COMMUNICATION ANALOGY
Consider a single connection network node or CN. The remainder of this paper will
be restricted to a single Assume that the CN output value space is restricted to two
values and Therefore the CN must decide whether the input it sees belongs to the
class of codes those codes for which it remains off or the class of codes those codes
for which it becomes active The inputs it sees in its receptive field constitute a subset of
the input vectors the function to the network It is also assumed that the CN is an
ideal I-NN Nearest Neighbor classifier or feature detector That is given a particular set
of learned vectors the CN will classify an arbitrary input according to the class of the
nearest using as a measure of distance learned vector This situation is equivalent to
the case where a single CN has a single codon whose receptive field size is equivalent to that
of the CN.
Imagine a sender who wishes to send one bit of information over a noisy channel The
sender has a probabilistic encoder that choses a code word learned vector according to
some probability distribution The receiver knows this code set though it has no knowledge
of which bit is being sent Noise is added to the code word during its transmission over the
channel which is analogous to applying an input vector to a network's inputs where the
vector lies within some learned vector's region The noise is represented by the distance
between the input vector and the associated learned vector
The code word sent over the channel consists of those bits that are seen in the receptive field of the ON being modeled In the associative mapping of input vectors to output
vectors each ON must respond with the appropriate output or for the associated
learned output vector Therefore a ON is a decoder that estimates in which class the
received code word belongs This is a classic block encoding problem where increasing the
field size is equivalent to increasing code length As the receptive field size increases the
performance of the decoder improves in the presence of noise Using communication theory
then the trade-off between interconnection costs as they relate to field size and the functionality of a node as it relates to the correctness of its decision making process output
errors can be characterized
As the receptive field size of a node increases so does the redundancy of the input
though this is dependent on the particular codes being used for the learned vectors since
there are situations where increasing the field size provides no additional information
There is a point of diminishing returns where each additional bit provides ever less reduction in output error Another factor is that interconnection costs increase exponentially
with field size The result of these two trends is a cost performance measure that has a single global maximum value In other words given a set of learned vectors and their probabilities and a set of interconnection costs a best receptive field size can be determined
beyond which increasing connectivity brings diminishing returns
SINGLE CODON WITH NO CODE COMPRESSION
A single neural element with a single codon and with no code compression can be
modelled exactly as a communication channel Figure Each network node is assumed
to have a single codon whose receptive field size is equal to that of the receptive field size of
the node
sender
I I
encoder
nOIsy
I
I
transmitter
receiver
I
decoder
ON
Figure A Transmission Channel
recelver
The operation of the channel is as follows A bit is input into the channel encoder
which selects a random code of length and transmits that code over the channel The
receiver then using nearest neighbor classification decides if the original message was either
a or a
Let be the number of code words used by the encoder The rate then indicates the
density of the code space
Definition The rate of a communication channel is
The block length corresponds directly to the receptive field size of the codon
The derivations in later sections use a related measure
Definition The code utilization is the number of learned vectors assigned to a particular code or
can be written in terms of
2N
As approaches code compression increases is essentially unbounded since may be
significantly larger than
The decode error information loss due to code compression is a random variable that
depends on the compression rate and the a priori probabilities therefore it will be different
with different learned vector sets and codons within a set As the average code utilization
for all codons approaches code compression occurs more often and codon decode error is
unavoidable
Let Zi be the vector output of the encoder and the input to the channel where each
element of Zi is either a or Let Vi be the vector output of the channel and the input to
the decoder where each element is either a or a The Noisy Channel Coding Theorem is
now presented for a general case where the individual input codes are to be distinguished The result is then extended to a CN where even though input codes are
used the ON need only distinguish those codes where it must output a from those where it
must output a The theorem is from Gallager Random codes are assumed
throughout
Theorem Let a discrete memoryless channel have transition probabilities PNU/k
and for any positive integer and positive number consider the ensemble of
block codes in which each letter of each code word is independently selected according to
fe
the probability assignment Then for each message NR
and all
the ensemble average probability of decoding error using maximum-likelyhood
decoding satisfies
where
In the definitions given here and the theorems below the notation of Gall ager is used Many of the
definitions and theorems are also from Gallager
Q(k)PU/kp!p
i-il
l+P
k-il
These results are now adjusted ror our special case
Theorem For a single CN the average channel error rate ror random code vectors is
Pe
where
I
is the probability or an input vector bit being a
These results cover a wide range or models A more easily computable expression can
be derived by recognizing some or the restrictions inherent in the CN model First assume
that all channel code bits are equally likely that is I that the error model is
the Binary Symmetric Channel and that the errors are identically distributed and
independent that is each bit has the same probability or being in error independent
or the code word and the bit position in the code word
A simplified version or the above theorem can be derived Maximizing gives the
tightest bounds
O$p~l
maxPe(p
where letting codon input be the block length I
The minimum value or this expression is obtained when for
Eo log
SINGLE-CODON WITH CODE COMPRESSION
Unfortunately the implementation complexity of a codon grows exponentially with the
size or the codon which limits its practical size An alternative is to approximate single
codon function of a single CN with many smaller overlapped codons The goal is to maintain performance and reduce implementation costs thus improving the cost/performance of
the decoding process As codons get smaller the receptive field size becomes smaller relative
to the number of CNs in the network When this happens there is codon compression or
vector alia6ing that introduces its own errors into the decoding process due to information
loss Networks can overcome this error by using multiple redundant codons with overlapping receptive fields that tend to correct the compression error
Compression occurs when two code words requiring different decoder output share the
same representation within the receptive field or the codon The following theorem gives
the probability of incorrect codon output with and without compression error
Theorem For a BSC model where the codon receptive field is Ic the code utilization is and the channel bits are selected randomly and independently the probability
of a codon decoding error when is approximately
where the expected compression error per codon is approximated by
Pc
and from equations when
exp
log
I-RI
Proof is given in Hammerstrom6
As grows Pc approaches asymptotically Thus the performance of a single codon
degrades rapidly in the presence of even small amounts of compression
MULTIPLE CODONS WITH CODE COMPRESSION
The use or mUltiple small codons is more efficient than a few large codons but there
are some fundamental performance constraints When a codon is split into two or more
smaller codons and the original receptive field is subdivided accordingly there are several
effects to be considered First the error rate of each new codon increases due to a decrease
in receptive field size the codon's block code length The second effect is that the code
utilization will increase for each codon since the same number of learned vectors is
mapped into a smaller receptive field This change also increases the error rate per codon
due to code compression In fact as the individual codon receptive fields get smaller
significant code compression occurs For higher-order input codes there is an added error
that occurs when the order of the individual codons is decreased since random codes are
being assumed this effect is not considered here The third effect is the mass action of
large numbers of codons Even though individual codons may be in error if the majority
are correct then the ON will have correct output This effect decreases the total error rate
Assume that each ON has more than one codon The union of the receptive fields
for these codons is the receptive field for the ON with no no restrictions on the degree of
overlap of the various codon receptive fields within or between ONs. For a ON with a large
number of codons the codon overlap will generally be random and uniformly distributed
Also assume that the transmission errors seen by different receptive fields are independent
Now consider what happens to a codon's compression error rate ignoring transmission
error for the time being when a codon is replaced by two or more smaller co dons covering
the same receptive field This replacement process can continue until there are only
codons which incidentally is analogous to most current neural models For a multiple
codon ON assume that each codon votes a or The summation unit then totals this
information and outputs a if the majority of codons vote for a etc
Theorem The probability of a ON error due to compression error is
Pc
where
Pc
dy
is given in equation and
Pc incorporates the two effects of moving to mUltiple smaller codons and adding more
codons Using equation 17 gives the total error probability per bit PeN
Proof is in Hammerstrom6
For networks that perform association as defined in this paper the connection weights
rapidly approach a single uniform value as the size of the network grows In information
theoretic terms the information content of those weights approaches zero as the compression increases Why then do simple non-conjunctive networks 1-codon equivalent work at
alI In the next section I define connectivity cost constraints and show that the answer to
the first question is that the general associative structures defined here do not scale costeffectively and more importantly that there are limits to the degree of distribution of information
CONNECTIVITY COSTS
It is much easier to assess costs if some implementation medium is assumed I have
chosen standard silicon which is a two dimensional surface where ON's and codons take up
surface area according to their receptive field sizes In addition there is area devoted to
the metal lines that interconnect the ONs. A specific VLSI technology need not be assumed
since the comparisons are relative thus keeping ONs codons and metal in the proper proportions according to a standard metal width which also includes the inter-metal
pitch For the analyses performed here it is assumed that
levels of metal are possible
In the previous section I established the relationship of network performance in terms
of the transmission error rate and the network capacity M. In this section I present an
implementation cost which is total silicon area A. This figure can then be used to derive a
cost/performance figure that can be used to compare such factors as codon size and receptive field size There are two components to the total area A ON the area of a ON and
AMI the area of the metal interconnect between ONs. AON consists of the silicon area
requirements of the codons for all ONs. The metal area for local intra-ON interconnect is
considered to be much smaller than that of the codons themselves and of that of the more
global inter-ON interconnect and is not considered here The area per ON is roughly
AON cfeme
where me is the maximum number of vectors that each codon must distinguish for
me
Theorem Assume a rectangular un6ounded grid of ONs all ONs are equi-distant
from their four nearest neighbors where each ON has a bounded receptive field of its nON
nearest ONs where ON is the receptive field size for the ON nON
C~e
where is the
number of codons and is the intra-ON redundancy that is the ratio of inputs to
synapses when R=l each ON input is used once at the ON when each input is
used on the average at two sites The metal area required to support each ON's receptive
field is proof is giving by Hammerstrom6
AMI
The total area per ON A then is
Another implementation IItrategy ill to place eNII along a diagonal which givell area However thill
technique only works ror a bounded number or eNII and when dendritic computation can be lipread over a large
area which limits the range or p08llible eN implementationll The theorem IItated here covers an infinite plane or
eNII each with a bounded receptive Held
Even with the assumption of maximum locality the total metal interconnect area
increases as the cube of the per CN receptive field size
SINGLE CN SIMULATION
What do the bounds tell us about CN connectivity requirements From simulations
increasing the CN's receptive field size improves the performance increases capacity but
there is also an increasing cost which increases faster than the performance Another
observation is that redundancy is quite effective as a means for increasing the effectiveness
of a CN with constrained connectivity There are some limits to since it can reach a
point where the intra-CN connectivity approaches that of inter-CN for some situations
With a fixed nON increasing cost-effectiveness A is possible by increasing both order
and redundancy
In order to verify the derived bounds I also wrote a discrete event simulation of a CN
where a random set of learned vectors were chosen and the CN's codons were programmed
according to the model presented earlier Learned vectors were chosen randomly and subjected to random noise The CN then attempted to categorize these inputs into two
major groups CN output and CN output For the most part the analytic bounds
agreed with the simulation though they tended to be optimistic in slightly underestimating
the error These differences can be easily explained by the simplifying assumptions that
were made to make the analytic bounds mathematically tractable
DISTRmUTED VS. LOCALIZED
Throughout this paper it has been tacitly assumed that representations are distributed
across a number of CNs and that any single CN participates in a number of representations In a local representation each CN represents a single concept or feature It is the distribution of representation that makes the CN's decode job difficult since it is the cause of
the code compression problem
There has been much debate in the connectionist/neuromodelling community as to the
advantages and disadvantages of each approach the interested reader is referred to Hinton7 Baum and BallardQ Some of the results derived here are relevant to this
debate A1s the distribution of representation increases the compression per CN increases
accordingly It was shown above that the mean error in a codon's response quickly
approaches independent of the input noise This result also holds at the CN level For
each individual CN this error can be offset by adding more codons but this is expensive
and tends to obviate one of the arguments in favor of distributed representations that is
the multi-use advantage where fewer CNs are needed because of more complex redundant
encodings A1s the degree of distribution increases the required connectivity and the code
compression increases so the added information that each codon adds to its CN's decoding
process goes to zero equivalent to all weights approaching a uniform value
SUMMARY AND CONCLUSIONS
In this paper a single CN node performance model was developed that was based on
Communication Theory Likewise an implementation cost model was derived
The communication model introduced the codon as a higher-order decoding element
and showed that for small codons much less than total CN fan-in or convergence code
compression or vector aliasing within the codon's receptive field is a severe problem for
large networks As code compression increases the information added by any individual
codon to the CN's decoding task rapidly approaches zero
The cost model showed that for 2-dimensional silicon the area required for inter-node
metal connectivity grows as the cube of a CN's fan-in
The combination of these two trends indicates that past a certain point which is
highly dependent on the probability structure of the learned vector space increasing the
fan-in of a CN as is done for example when the distribution of representation is increased
yields diminishing returns in terms of total cost-performance Though the rate of diminishing returns can be decreased by the use of redundant higher-order connections
The next step is to apply these techniques to ensembles of nodes CNs operating in a
competitive learning or feature extraction environment

<<----------------------------------------------------------------------------------------------------------------------->>

title: 49-connecting-to-the-past.pdf

CONNECTING TO THE PAST
Bruce A. MacDonald Assistant Professor
Knowledge Sciences Laboratory Computer Science Department
The University of Calgary University Drive NW
Calgary Alberta T2N IN4
ABSTRACT
Recently there has been renewed interest in neural-like processing systems evidenced for example in the two volumes Parallel Distributed Processing edited by Rumelhart and McClelland
and discussed as parallel distributed systems connectionist models neural nets value passing
systems and multiple context systems Dissatisfaction with symbolic manipulation paradigms
for artificial intelligence seems partly responsible for this attention encouraged by the promise
of massively parallel systems implemented in hardware This paper relates simple neural-like
systems based on multiple context to some other well-known formalisms-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier sequence prediction results in a new light
INTRODUCTION
The revival of neural net research has been very strong exemplified recently by Rumelhart
and McClelland new journals and a number of meetings The nets are also described as
parallel distributed systems connectionist models value passing systems3 and multiple context
learning systems4 The symbolic manipulation paradigm for artificial intelligence does
not seem to have been as successful as some hoped and there seems at last to be real promise
of massively parallel systems implemented in hardware However in the flurry of new work it
is important to consolidate new ideas and place them solidly alongside established ones This
paper relates simple neural-like systems to some other well-known notions-namely production
systems k-Iength sequence prediction finite-state machines and Turing machines-and presents
earlier results on the abilities of such networks in a new light
The general form of a connectionist system lO is simplified to a three layer net with binary
fixed weights in the hidden layer thereby avoiding many of the difficulties-and challengesof the recent work on neural nets The hidden unit weights are regularly patterned using a
template Sophisticated expensive learning algorithms are avoided and a simple method is
used for determining output unit weights In this way we gain some of the advantages of multilayered nets while retaining some of the simplicity of two layer net training methods Certainly
nothing is lost in computational power-as I will explain-and the limitations of two layer
nets are not carried over to the simplified three layer one Biological systems may similarly
avoid the need for learning algorithms such as the simulated annealing method commonly
used in connectionist models For one thing biological systems do not have the same clearly
distinguished training phase
Briefly the simplified net is a production system implemented as three layers of neuron-like
units an output layer an input layer and a hidden layer for the productions themselves Each
hidden production unit potentially connects a predetermined set of inputs to any output A
k-Iength sequence predictor is formed once Ie levels of delay unit are introduced into the input
layer k-Iength predictors are unable to distinguish simple sequences such as ba a and aa a
since after Ie or more characters the system has forgotten whether an a or appeared first If
the k-Iength predictor is augmented with auxiliary actions it is able to learn this and other
regular languages since the auxiliary actions can be equivalent to states and can be inputs to
aAmong them the 1st International Conference on Neural Nets San Diego,CA June and this
con.ference
bRoughly equivalent to a single context system in Andreae's multiple context system See also
MacDonald
@
American Institute of Physics
Figure The general form of a connectionist system
Form of a unit
Operations within a unit
in~uts excitation-.I
weIghts
sum
aCtiVation--W output
Typical
Typical
the production units enabling predictions to depend on previous states By combining several
augmented sequence predictors a Thring machine tape can be simulated along with a finite-state
controller giving the net the computational power of a Universal Turing machine Relatively
simple neural-like systems do not lack computational ability Previous implementations of
this ability are production system equivalents to the simplified nets
Organization of the paper
The next section briefly reviews the general form of connectionist systems Section simplifies
this then section explains that the result is equivalent to a production system dealing only
with inputs and outputs of the net Section extends the simplified version enabling it to learn
to predict sequences Section explains how the computational power of the sequence predictor
can be increased to that of a Thring machine if some input units receive auxiliary actions in fact
the system can learn to be a TUring machine Section discusses the possibility of a number of
nets combining their outputs forming an overall net with association areas
General form of a connectionist system
Figure shows the general form of a connectionist system unit neuron or ce1l In the figure
unit has inputs which are the outputs OJ of possibly all units in the network and an output of
its own The net input excitation net is the weighted sum of inputs where Vij is the weight
connecting the output from unit as an input to unit The activation of the unit is some
function Fi of the net input excitation Typically Fi is semilinear that is non-decreasing and
differentiable 13 and is the same function for all or at least large groups of units The output is
a function fi of the activation typically some kind of threshold function I will assume that the
quantities vary over discrete time steps so for example the activation at time is
and is given by Fi((neti(t
In general there is no restriction on the connections that may be made between units
Units not connected directly to inputs or outputs are hidden units In more complex nets
than those described in this paper there may be more than one type of connection Figure
shows a common connection topology where there are three layers of units-input hidden and
output-with no cycles of connection
The net is trained by presenting it with input combinations each along with the desired
output combination Once trained the system should produce the desired outputs given just
Figure The basic structure of a three layer connectionist system
input units
hidden
units
output units
inputs During training the weights are adjusted in some fashion that reduces the discrepancy
between desired and actual output The general method is lO
where is the desired training activation Equation is a general form of Hebb's classic
rule for adjusting the weight between two units with high activations lO The weight adjustment
is the product of two functions one that depends on the desired and actual activations--often
just the difference-and another that depends on the input to that weight and the weight itself
As a simple example suppose is the difference and as just the output OJ. Then the weight
change is the product of the output error and the input excitation to that weight
where the constant determines the learning rate This is the Widrow-Hoff or Delta rule which
may be used in nets without hidden units 1o
The important contribution of recent work on connectionist systems is how to implement
equation in hidden units for which there are no training signals ti directly available The
Boltzmann learning method iteratively varies both weights and hidden unit training activations
using the controlled gradually decreasing randomizing method simulated annealing Backpropagation 13 is also iterative performing gradient descent by propagating training signal errors
back through the net to hidden units I will avoid the need to determine training signals for
hidden units by fixing the weights of hidden units in section below
SIMPLIFIED SYSTEM
Assume these simplifications are made to the general connectionist system of section
The system has three layers with the topology shown in Figure ie no cycles
All hidden layer unit weights are fixed say at unity or zero
Each unit is a linear threshold unit lO which means the activation function for all units
is the identity function giving just net a weighted sum of the inputs and the output
function is a simple binary threshold of the form
I
output
threshold
activation
so that the output is binary on or oft Hidden units will have thresholds requiring all
inputs to be active for the output to be active like an AND gate while output units will
have thresholds requiring only or two active highly weighted inputs for an output to be
generated like an OR gate This is in keeping with the production system view of the
net explained in section
Learning-which now occurs only at the output unit weights-gives weight adjustments
according to
Wij
Wij
if
OJ
otherwise
so that weights are turned on if their input and the unit output are on and off otherwise
That is Wij A OJ. A simple example is given in Figure in section below
This simple form of net can be made probabilistic by replacing with below
Adjust weights so that Wij estimates the conditional probability of the unit output being
on when output is on That is
Wij
estimate of P(odoj
Then assuming independence of the inputs to a unit an output unit is turned on when the
conditional probability of occurrence of that output exceeds the threshold of the output
function
Once these simplifications are made there is no need for learning in the hidden units Also no
iterative learning is required weights are either assigned binary values or estimate conditional
probabilities This paper presents some of the characteristics of the simplified net Section
discusses the motivation for simplifying neural nets in this way
PRODUCTION SYSTEMS
The simplified net is a kind of simple production system A production system comprises a
global database a set of production rules and a control system The database for the net is
the system it interacts with providing inputs as reactions to outputs from t.he net The hidden
units of the network are the production rules which have the form
IF
precondition
THEN
action
The precondition is satisfied when the input excitation exceeds the threshold of a hidden unit
The actions are represented by the output units which the hidden production units activate
The control system of a production system chooses the rule whose action to perform from the
set of rules whose preconditions have been met In a neural net the control system is distributed
throughout the net in the output units For example the output units might form a winner-takeall net In production systems more complex control involves forward and backward chaining to
choose actions that seek goals This is discussed elsewhere4.12.16 Figure illust.rates a simple
production implemented as a neural net As the figure shows the inputs to hidden units are
just the elements of the precondition When the appropriate input combination is present the
associated hidden production unit is fired Once weights have been leamed connecting hidden
units to output units firing a production results in output The simplified neural net is directly
equivalent to a production system whose elements are inputs and outputs
Some production systems have symbolic elements such as variables which can be given
values by production actions The neural net cannot directly implement this since it can
have outputs only from a predetermined set However we will see later that extensions t.o the
framework enable this and other abilities
CThis might be referred to as a sensory-motor production system since when implemented ill a l'eal system
such as a robot it deals only with sensed inputs and executable motor actions which may include the auxiliary
actions of section
Figure A production implemented in a simplified neural net
A production rule
IF
Icloudy I Ipressure falling I
AND
THEN
Iit will rain I
The rule implemented as a hidden unit The threshold of the hidden unit is so it is
an AND gate The threshold of the output unit is so it is an OR gate The learned
weight will be or if the net is not probabilistic otherwise it will be an estimate of
P(it will rainlclouds AND pressure falling
It will
rain
weight
Figure A net that predicts the next character in a sequence based on only the last character
The net Production units hidden units have been combined with input units
For example this net could predict the sequence abcabcabc Productions have the
form IF last character is THEN next character will be The learning rule is
Wij
if inputj AND outputi Output is
WijOj
input
neural net
output
a
a
Learning procedure
Clamp inputs and outputs to desired values
System calculates weight values
Repeat and for all required input/output combinations
SEQUENCE PREDICTION
A production system or neural net can predict sequences Given examples of a repeating sequence productions are learned which predict future events on the basis of recent ones Figure
shows a trivially simple sequence predictor It predicts the next character of a sequence based
on the previous one The figure also gives the details of the learning procedure for the simplified
net The net need be trained only once on each input combination then it will predict as
an output every character seen after the current one The probabilistic form of the net would
estimate conditional probabilities for the next character conditional on the current one Many
Figure Using delayed inputs a neural net can implement a k-length sequence predictor
A net with the last three characters as input
input
hidden
output
a
a
a
2nd last
An example production
IF
last three characters were THEN
presentations of each possible character pair would be needed to properly estimate the probabilities The net would be learning the probability distribution of character pairs A predictor like
the one in Figure can be extended to a general k-Iength 17 predictor so long as inputs delayed
by steps are available Then as illustrated in Figure for 3-length prediction hidden
production units represent all possible combinations of symbols Again output weights are
trained to respond to previously seen input combinations here of three characters These delays
can be provided by dedicated neural nets such as that shown in Figure Note that the net
is assumed to be synchronously updated so that the input from feedback around units is not
changed until one step after the output changes There are various ways of implementing delay
in neurons and Andreae investigates some of them for the same purpose-delaying inputs-in
a more detailed simulation of a similar net
Other work on sequence prediction in neural nets
Feldman and Ballard find connectionist systems initially not suited to representing changes
with time One form of change is sequence and they suggest two methods for representing
sequence in nets The first is by units connected to each other in sequence so that sequential
tasks are represented by firing these units in succession The second method is to buffer the
inputs in time so that inputs from the recent past are available as well as current inputs that
is delayed inputs are available as suggested above An important difference is the necessary
length of the buffer Feldman and Ballard suggest the buffer be long enough to hold a phrase of
natural language but I expect to use buffers no longer than about after Andreae Symbolic
inputs can represent more complex information effectively giving the length seven buffers more
information than the most recent seven simple inputs as discussed in section
The method of back-propagation13 enables recurrent networks to learn sequential tasks in a
dFeldman and Ballard2 give some dedicated neural net connections for a variety of flUlctions
Figure Inputs can be delayed by dedicated neural subnets A two stage delay is shown
Delay network
Timing diagram for
tml
A
original signal
delay of one step
delay of two steps
manner similar to the first suggestion in the last paragraph where sequences of connected units
represent sequenced events In one example a net learns to complete a sequence of characters
when given the first two characters of a six character sequence the next four are output Errors
must be propagated around cycles in a recurrent net a number of times
Seriality may also be achieved by a sequence of states of distributed activation 18 An example
is a net playing both sides of a tic-tac-toe game 18 The sequential nature of the net's behavior is
derived from the sequential nature of the responses to the net's actions tic-tac-toe moves A net
can model sequence internally by modeling a sequential part of its environment For example
a tic-tac-toe playing net can have a model of its opponent
k-Iength sequence predictors are unable to learn sequences which do not repeat more frequently that every characters Their k-Iength context includes only information about the last
events However there are two ways in which information from before the kth last input can
be retained in the net The first method latches some inputs while the second involves auxiliary
actions
Latch units
Inputs can be latched and held indefinitely using the combination shown in Figure Not all
inputs would normally be latched Andreae discusses this technique of threading latched
events among non-latched events giving the net both information arbitrarily far back in its
input-output history and information from the immediate past Briefly the sequence ba a
can be distinguished from aa a if the first character is latched However this is an ad hoc
solution to this problem
Auxiliary actions
When an output is fed back into the net as an input signal this enables the system to choose the
next output at least partly based on the previous one as indicated in Figure If a particular
fed back output is also one without external manifestation or whose external manifestation
is independent of the task being performed then that output is an auxiliary action It Las
The interested reader should refer to Andreae where more extensive analysis is given
Figure Threading A latch circuit remembers an event until another comes along This is a
two input latch for two letters a and but any number of units may be similarly connected
It is formed from a mutual inhibition layer or winner-take-all connection along with positive
feedback to keep the selected output activated when the input disappears
a
Figure Auxiliary actions-the outputs-are fed back to the inputs of a net enabling the
net to remember a state Here both part of a net and an example of a production are shown
There are two types of action characters and actions
Sinputs
outputs
character inputs
IF
input is
and character input is
character outputs
THEN
output character
lliJ and ill
no direct effect on the task the system is performing since it evokes no relevant inputs and
so can be used by the net as a symbolic action If an auxiliary action is latched at the input
then the symbolic information can be remembered indefinitely being lost only when another
auxiliary action of that kind is input and takes over the latch Thus auxiliary actions can act
like remembered states the system performs an action to remind itself to be in a particular
state The figure illustrates this for a system that predicts characters and state changes given
the previous character and state An obvious candidate for auxiliary actions is speech So
the blank oval in the figure would represent the net's environment through which its own
speech actions are heard Although it is externally manifested speech has no direct effect on
our physical interactions with the world Its symbolic ability not only provides the power of
auxiliary actions but also includes other speakers in the interaction
SIMULATING ABSTRACT AUTOMATA
The example in Figure gives the essence of simulating a finite state automaton with a production system or its neural net equivalent It illustrates the transition function of an automaton
the new state and output are a function of the previous state and input Thus a neural net can
simulate a finite state automaton so long as it has additional auxiliary actions
A Thring machine is a finite state automaton controller plus an unbounded memory A
neural net could simulate a lUring machine in two ways and both ways have been demonstrated
with production system implementations-equivalent to neural nets----(;alled multiple context
learning systems briefly explained in section The first Thring machine simulation has the
system simulate only the finite state controller but is able to use an unbounded external memory
fSee John Andreae's and his colleagues work4
Figure Multiple context learning system implementation as multiple neural nets Each:3
layer net has the simplified form presented above with a number of elaborations such as extra
connections for goal-seeking by forward and backward chaining
Output
channels
from the real world much like the paper of Turing's original work 19 The second simnlat.ion
embeds the memory in the multiple context learning system along with a counter for accessing
this simulated memory Both learn all the productions-equivalent to learning output unit
weights-required for the simulations The second is able to add internal memory as required
up to a limit dependent on the size of the network which can easily be large enough to allow 70
years of computation The second could also employ external memory as the first did Briefly
the second simulation comprised multiple sequence predictors which predicted auxiliary actions
for remembering the state of the controller and the current memory position The memory
element is updated by relearning the production representing that element the precondition is
the address and the production action the stored item
MULTIPLE SYSTEMS FORM ASSOCIATION AREAS
A multiple context learning system is production system version of a multiple neural net although a simple version has been implemented as a simulated net It effectively comprises
several nets--or association areas-which may have outputs and inputs in common as indicated in Figure Hidden unit weights are specified by templates one for each net A template
gives the inputs to have a zero weight for the hidden units of a net and the inputs to have a
weight of unity Delayed and latched inputs are also available The actual outputs are selected
from the combined predictions of the nets in a winner-take-all fashion
I see the design for real neural nets say as controllers for real robots requiring a large
degree of predetermined connectivity A robot controller could not be one three layer net wit.h
every input connected to every hidden unit in turn connected to every output There will
need to be some connectivity constraints so the net reflects the functional specialization in the
control requirements The multiple context learning system has all the hidden layer connections
predetermined but allows output connections to be learned This avoids the credit assignment
problem and therefore also the need for learning algorithms such as Boltzmann learning and
back-propagation However as the multiple context learning system has auxiliary actions and
delayed and latched inputs it does not lack computational power Future work in this area
should investigate for example the ability of different kinds of nets to learn auxiliary act.ions
This may be difficult as symbolic actions may not be provided in training inputs and output.s
For
example a controller for a robot body would have to deal with vision manipulation motion etc
CONCLUSION
This paper has presented a sImplified three layer connectionist model with fixed weights for
hidden units delays and latches for inputs sequence prediction ability auxiliary state actions
and the ability to use internal and external memory The result is able to learn to simulate a
Turing machine Simple neural-like systems do not lack computational power
ACKNOWLEDGEMENTS
This work is supported by the Natural Sciences and Engineering Council of Canada

<<----------------------------------------------------------------------------------------------------------------------->>

title: 54-a-method-for-the-design-of-stable-lateral-inhibition-networks-that-is-robust-in-the-presence-of-circuit-parasitics.pdf

A METHOD FOR THE DESIGN OF STABLE LATERAL INHIBITION
NETWORKS THAT IS ROBUST IN THE PRESENCE
OF CIRCUIT PARASITICS
J.L. WYATT Jr and D.L. STANDLEY
Department of Electrical Engineering and Computer Science
Massachusetts Institute of Technology
Cambridge Massachusetts
ABSTRACT
In the analog VLSI implementation of neural systems it is
sometimes convenient to build lateral inhibition networks by using
a locally connected on-chip resistive grid A serious problem
of unwanted spontaneous oscillation often arises with these
circuits and renders them unusable in practice This paper reports
a design approach that guarantees such a system will be stable
even though the values of designed elements and parasitic elements
in the resistive grid may be unknown The method is based on a
rigorous somewhat novel mathematical analysis using Tellegen's
theorem and the idea of Popov multipliers from control theory It
is thoroughly practical because the criteria are local in the sense
that no overall analysis of the interconnected system is required
empirical in the sense that they involve only measurable frequency
response data on the individual cells and robust in the sense that
unmodelled parasitic resistances and capacitances in the interconnection network cannot affect the analysis
I.
INTRODUCTION
The term lateral inhibition first arose in neurophysiology to
describe a common form of neural circuitry in which the output of
each neuron in some population is used to inhibit the response of
each of its neighbors Perhaps the best understood example is the
horizontal cell layer in the vertebrate retina in which lateral
inhibition simultaneously enhances intensity edges and acts as an
automatic lain control to extend the dynamic range of the retina
as a whole The principle has been used in the design of artificial
neural system algorithms by Kohonen and others and in the electronic
design of neural chips by Carver Mead
In the VLSI implementation of neural systems it is convenient
to build lateral inhibition networks by using a locally connected
on-chip resistive grid Linear resistors fabricated in
polysilicon yield a very compact realization and nonlinear
resistive grids made from MOS transistors have been found useful
for image segmentation Networks of this type can be divided into
two classes feedback systems and feedforward-only systems In the
feedforward case one set of amplifiers imposes signal voltages or
American Institute of Physics
currents on the grid and another set reads out the resulting response
for subsequent processing while the same amplifiers both write to
the grid and read from it in a feedback arrangement Feedforward
networks of this type are inherently stable but feedback networks
need not be
A practical example is one of Carver Meadls retina chips3 that
achieves edge enhancement by means of lateral inhibition through a
resistive grid Figure shows a single cell in a continuous-time
version of this chip Note that the capacitor voltage is affected
both by the local light intensity incident on that cell and by the
capacitor voltages on neighboring cells of identical design Any
cell drives its neighbors which drive both their distant neighbors
and the original cell in turn Thus the necessary ingredients for
instability--active elements and signal feedback--are both present
in this system and in fact the continuous-time version oscillates
so badly that the original design is scarcely usable in practice
with the lateral inhibition paths enabled Such oscillations can
I
incident
light
out
Figure This photoreceptor and signal processor Circuit using two
MOS transconductance amplifiers realizes lateral inhibition by
communicating with similar units through a resistive grid
readily occur in any resistive grid circuit with active elements and
feedback,even when each individual cell is quite stable Analysis
of the conditions of instability by straightforward methods appears
hopeless since any repeated array contains many cells each of
which influences many others directly or indirectly and is influenced
by them in turn so that the number of simultaneously active feedback loops is enormous
This paper reports a practical design approach that rigorously
guarantees such a system will be stable The very simplest version
of the idea is intuitively obvious design each individual cell so
that although internally active it acts like a passive system as
seen from the resistive grid In circuit theory language the
design goal here is that each cellis output impedance should be a
positive-real function This is sometimes not too difficult in
practice we will show that the original network in satisfies
this condition in the absence of certain parasitic elements More
important perhaps it is a condition one can verify experimentally
by frequency-response measurements
It is physically apparent that a collection of cells that
appear passive at their terminals will form a stable system when
interconnected through a passive medium such as a resistive grid
The research contributions reported here in summary form are
a demonstration that this passivity or positive-real condition
is much stronger than we actually need and that weaker conditions
more easily achieved in practice suffice to guarantee stability of
the linear network model and ii an extension of to the nonlinear
domain that furthermore rules out large-signal oscillations under
certain conditions
II.
FIRST-ORDER LINEAR ANALYSIS OF A SINGLE CELL
We begin with a linear analysis of an elementary model for the
circuit in For an initial approximation to the output
admittance of the cell we simplify the topology without loss of
relevant information and use a naive'model for the transconductance
amplifiers as shown in
Figure Simplified network topology and transconductance amplifier
model for the circuit in The capacitor in has been
absorbed into CO2
Straightforward calculations show that the output admittance is
given by
yes
This is a positive-real passive admittance since it can always
be realized by a network of the form shown in where
Ro2 gmlgm2Rol
and COI/gmlgm2
Although the original circuit contains no inductors the
realization has both capacitors and inductors and thus is capable
of damped oscillations Nonetheless the transamp model in
were perfectly accurate no network created by interconnecting
such cells through a resistive grid with parasitic capacitances
could exhibit sustained oscillations For element values that may
be typical in practice the model in has a lightly damped
resonance around I KHz with a This disturbingly high
suggests that the cell will be highly sensitive to parasitic elements
not captured by the simple models in Our preliminary
Rl
yes
Figure Passive network realization of the output admittance
of the circuit in
analysis of a much more complex model extracted from a physical
circuit layout created in Carver Mead's laboratory indicates that
the output impedance will not be passive for all values of the transamp bias currents But a definite explanation of the instability
awaits a more careful circuit modelling effort and perhaps the design
of an on-chip impedance measuring instrument
III.
POSITIVE-REAL FUNCTIONS e-POSITlVE FUNCTIONS AND
STABILITY OF LINEAR NETWORK MODELS
In the following discussion cr+jw is a complex variable
is a rational function ratio of polynomials in with real
coefficients and we assume for simplicity that has no pure
imaginary poles The term closed right halE plane refers to the set
of complex numbers with Re{s
Def. I
The function is said to be positive-real if it has no
poles in the right half plane and Re{H(jw for all
If we know at the outset that has no right half plane poles
then Def. I reduces to a simple graphical criterion is positivereal if and only if the Nyquist diagram of the plot of
H(jW for as in lies entirely in the closed right half
plane
Note that positive-real functions are necessarily stable since
they have no right half plane poles but stable functions are not
necessarily positive-real as Example will show
A deep link between positive real functions physical networks
and passivity is established by the classical result in linear
circuit theory which states that is positive-real if and only if
it is possible to synthesize a 2-terminal network of positive linear
resistors capacitors inductors and ideal transformers that has
as its driving-point impedance or admittance
Oef.
The function is said to be a-positive for a particular value
of e(e if has no poles in the right half plane
and the Nyquist plot of lies strictly to the right of the
straight line passing through the origin at an angle a to the real
positive axis
Note that every a-positive function is stable and any function
that is e-positive with is necessarily positive-real
I
Re{G(jw
Figure Nyquist diagram for a fUnction that is a-positive but
not positive-real
Example
The function
is a-positive for any between about and and stable but it
is not positive-real since its Nyquist diagram shown in
crosses into the left half plane
The importance of e-positive functions lies in the following
observations an interconnection of passive linear resistors and
capacitors and cells with stable linear impedances can result in an
unstable network such an instability cannot result if the
impedances are also positive-real a-positive impedances form a
larger class than positive-real ones and hence a-positivity is a less
demanding synthesis goal and Theorem below shows that such an
instability cannot result if the impedances are a-positive even if
they are not positive-real
Theorem
Consider a linear network of arbitrary topology consisting of
any number of passive 2-terminal resistors and capacitors of arbitrary
value driven by any number of active cells If the output impedances
of all the active cells are a-positive for some common a 22
then the network is stable
The proof of Theorem relies on Lemma below
Lemma
If is a-positive for some fixed a then for all So in the
closed first quadrant of the complex plane H(so lies strictly to
the right of the straight line passing through the origin at an angle
a to the real positive axis Re{so and Im{so
a
Proof of Lemma Outline
Let be the function that assigns to each in the closed right
half plane the perpendicular distance des from to the line
defined in Def. Note that des is harmonic in the closed right
half plane since is analytic there It then follows by application
of the maximum modulus principle8 for harmonic functions that takes
its minimum value on the boundary of its domain which is the
imaginary axis This establishes Lemma
Proof of Theorem OUtline
The network is unstable or marginally stable if and only if it
has a natural frequency in the closed right half plane and So is a
natural frequency if and only if the network equations have a nonzero
solution at so Let denote the complex branch currents Of such
a solution By Tellegen I theorern9 the sum of the complex powers
absorbed by the circuit elements must vanish at such a solution
IIk12/s0Ck
capac~tances
cell
terminal pairs
where the second term is deleted in the special case so=O since the
complex power into capacitors vanishes at so=O
If the network has a natural frequency in the closed right half
plane it must have one in the closed first quadrant since natural
frequencies are either real or else occur in complex conjugate pairs
But cannot be satisfied for any So in the closed first quadrant
as we can see by dividing both sides of by
IIkI2 where the
sum is taken over all network branches After this division
asserts that zero is a convex combination of terms of the form Rk
terms of the form CkSo)-I and terms of the form Zk(So
Visualize where these terms lie in the complex plane the first set lies
on the real positive axis the second set lies in the closed
adrant since So lies in the closed 1st quadrant by assumption and
the third set lies to the right of a line passing through the origin
at an angle a by Lemma Thus all these terms lie strictly to the
right of this line which implies that no convex combination of them
can equal zero Hence the network is stable
IV.
STABILITY RESULT FOR NETWORKS WITH NONLINEAR
RESISTORS AND CAPACITORS
The previous result for linear networks can afford some limited
insight into the behavior of nonlinear networks First the nonlinear
equations are linearized about an equilibrium point and Theorem is
applied to the linear model If the linearized model is stable then
the equilibrium point of the original nonlinear network is locally
stable the network will return to that equilibrium point if
the initial condition is sufficiently near it But the result in this
section in contrast applies to the full nonlinear circuit model and
allows one to conclude that in certain circumstances the network
cannot oscillate even if the initial state is arbitrarily far from
the equilibrium point
Def.
A function as described in Section III is said tc satisfy
the Popov criterion lO if there exists a real number r>O such that
Re{(l+jwr for all
Note that positive real functions satisfy the Popov criterion
with And the reader can easily verify that in Exam~le I
satisfies the Popov criterion for a range of values of The important
effect of the term l+jwr in Def. is to rotate the Nyquist plot
counterclockwise by progressively greater amounts up to as
increases
Theorem
Consider a network consisting of nonlinear 2-terminal resistors
and capacitors and cells with linear output impedances Suppose
the resistor curves are characterized by continuously
diffefentiable functions gk(vk where gk(O and
gk(vk for all values of and vk
ii the capacitors are characterized by Ck(Vk)~k with
CI Ck(v C2 for all values of and vk
iii the impedances Zk(s have no poles in the closed right
half plane and all satisfy the Popov criterion for some common
value of
If these conditions are satisfied then the network is stable in the
sense that for any initial condition
oo
I
all branches
dt
The proof based on Tellegen's theorem is rather involved
will be omitted here and will appear elsewhere
It
ACKNOWLEDGEMENT
We sincerely thank Professor Carver Mead of Cal Tech for
enthusiastically supporting this work and for making it possible for
us to present an early report on it in this conference proceedings
This work was supportedJ Defense Advanced Research Projects Agency
through the Office of Naval Research under ARPA Order No.
Contract No. and Defense Advanced Research
Projects Agency DARPA Contract No.

<<----------------------------------------------------------------------------------------------------------------------->>

title: 32-synchronization-in-neural-nets.pdf

SYNCHRONIZATION IN NEURAL NETS
Jacques J. Vidal
University of California Los Angeles Los Angeles Ca.
John Haggerty
ABSTRACT
The paper presents an artificial neural network concept the
Synchronizable Oscillator Networks where the instants of individual
firings in the form of point processes constitute the only form of
information transmitted between joining neurons This type of
communication contrasts with that which is assumed in most other
models which typically are continuous or discrete value-passing
networks Limiting the messages received by each processing unit to
time markers that signal the firing of other units presents significant
implemen tation advantages
In our model neurons fire spontaneously and regularly in the
absence of perturbation When interaction is present the scheduled
firings are advanced or delayed by the firing of neighboring neurons
Networks of such neurons become global oscillators which exhibit
multiple synchronizing attractors From arbitrary initial states
energy minimization learning procedures can make the network
converge to oscillatory modes that satisfy multi-dimensional
constraints Such networks can directly represent routing and
scheduling problems that conSist of ordering sequences of events
INTRODUCTION
Most neural network models derive from variants of Rosenblatt's
original perceptron and as such are value-passing networks This is
the case in particular with the networks proposed by Fukushima I
Hopfield Rumelhart and many others In every case the inputs to
the processing elements are either binary or continuous amplitude
signals which are weighted by synaptic gains and subsequently
summed integrated The resulting activation is then passed
through a sigmoid or threshold filter and again produce a continuous
or quantized output which may become the input to other neurons
The behavior of these models can be related to that of living neurons
even if they fall considerably short of accounting for their complexity
Indeed it can be observed with many real neurons that action
potentials spikes are fired and propagate down the axonal branches
when the internal activation reaches some threshold and that higher
John Haggerty is with Interactive Systems Los angeles
W. 6th St. LA Ca.
@
American Institute of Physics
input rates levels result in more rapid firing
Behind these
traditional models there is the assumption that the average
frequency of action potentials is the carrier of information between
neurons Because of integration the firings of individual neurons are
considered effective only to the extent to which they contribute to
the average intensities It is therefore assumed that the activity is
simply frequency coded The exact timing of individual firing is
ignored
This view however does not cover some other well known
aspects of neural communication Indeed the precise timing of
spike arrivals can make a crucial difference to the outcome of some
neural interactions One classic example is that of pre-synaptic
inhibition a widespread mechanism in the brain machinery Several
studies have also demonstrated the occurrence and functional
importance of precise timing or phase relationship between
cooperating neurons in local networks
The model presented in this paper contrasts with the ones just
mentioned in that in the networks each firing is considered as an
individual output event On the input side of each node the firing of
other nodes the presynaptic neurons either delay inhibit or
advance excite the node firing As seen earlier this type of
neuronal interaction which would be called phase-modulation in
engineering systems can also find its rationale in experimental
neurophysiology Neurophysiological plausibility however is not the
major concern here Rather we propose to explore a potentially
useful mechanism for parallel distributed computing The merit of
this approach for artificial neural networks is that digital pulses are
used for internode communication instead of analog voltages The
model is particularly well suited to the time-ordering and
sequencing found in a large class of routing and trajectory control
problems
NEURONS AS SYNCHRONIZABLE OSCILLATORS
In our model the proceSSing elements the neurons are
relaxation oscillators with built-in self-inhibition A relaxation
oscillator is a dynamic system that is capable of accumulating
potential energy until some threshold or breakdown point is
reached At that point the energy is abruptly released and a new
cycle begins
The description above fits the dynamic behavior of neuronal
membranes A richly structured empirical model of this behavior is
found in the well-established differential formulation of Hodgkin and
Huxley and in a simplified version given by Fitzhugh7 These
differential equations account for the foundations of neuronal activity
and are also capable of representing subthreshold behavior and the
refractoriness that follows each firing
When the membrane
potential enters the critical region an abrupt depolarization a
collapse of the potential difference across the membrane occurs
followed by a somewhat slower recovery This brief electrical
shorting of the membrane is called the action potential or spike
and constitutes the output event for the neuron If the causes for the
initial depolarization are maintained
oscillation limit-cycles
develops generating multiple firings Depending on input level and
membrane parameters the oscillation can be limited to a single
spike or may produce an oscillatory burst or even continually
sustained activity
The present model shares the same general properties but uses
the much simpler description of relaxation oscillator illustrated on
Figure
Activation
EnergyE(t
Exdt3tOIJ
OJ
Input
Out
InJrjh1~olJ
Input perturbation
utl
Intemilf
l!neJU Inpul
ty
Figure Relaxation Oscillator with perturbation input
Firing occurs when the energy level reaches some critical
level Ec. Assuming a constant rate of energy influx a firing will
occur with the natural period
Ec
T=a:When pre-synaptic pulses impinge on the course of energy
accumulation the firing schedule is disturbed Letting to represent
the instant of the last firing of the cell and tj the
intants of impinging arrivals from other cells
E(t to aCt to
Wj uo(t til
Ec
where uo(t represents the unit impulse at
The dramatic complexity of synchronization dynamics can be
appreCiated by considering the simplest possible case that of a
master slave interaction between two regularly firing oscillator units
A and with natural periods TA and TB. At the instants of firing
unit A unidirectionally sends a spike Signal to unit which is
received at some interval measured from the last time fired
Upon reception the spike is transformed into a quantum of energy
6E which depends upon the post-firing arrival time The
relationship can be shaped to represent refractoriness and
other post-spike properties Here it is assumed to be a simple ramp
function If the interaction is inhibitory the consequence of this
arrival is that the next firing of unit is delayed with respect to
what its schedule would have been in absence of perturbation by
some positive interval Figure Because of the shape of
the delaying action nil immediately after firing becomes longer for
impinging pre-synaptic spikes that arrive later in the interval If the
interaction is excitatory the delay is negative Le. a shortening of the
natural firing interval Under very general assumptions regarding the
function will tend to synchronize to A. Within a given
range of coupling gains
the phase will self-adjust until
equilibrium is achieved With a given this equilibrium
corresponds to a distribution of maximum entropy to the point
where both cells receive the same amouint of activation during their
common cycle
I
I
Inhibition
Excitation
Figure Relationship between phase and delay when input effiCiently
increases linearly in the after-spike interval
The synchronization dynamiCS presents an attractor for each
rational frequency pair To each ratio is aSSOCiated a range of stability
but only the ratios of lowest cardinality have wide zones of phaselocking Figure The wider stability wnes correspond to a one to
one ratio between fA and fB between their inverses TA and TBl.
Kohn and Segundo have demonstrated that such phase locking
occurs in living invertebrate neurons and pointed out the paradoxical
nature of phase-locked inhibition which within each stability region
takes the appearence of excitation since small increases in input
firing rate will locally result in increased output rates
The areas between these ranges of stability have the appearance
of unstable transitions but in fact as recently pOinted out by Bak9
form an infinity of locking steps known as the Devil's Staircase
corresponding to the infinity of intermediate rational pairs figure
Bak showed that the staircase is self-similar under scaling and that
the transitions form a fractal Cantor set with a fractal dimension
which is a universal constant of dynamic systems
I
Excitation
Inhibiti~~v I
lI?L
Figure Unilateral SynchroniZation
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS
The global synchronization of an interconnected network of
mutually phase-locking oscillators is a constraint satisfaction
problem For each synchronization equilibrium the nodes fire in
interlocked patterns that organize inter-spike intervals into integer
ratios
The often cited Traveling Salesman Problem the archetype
for a class of important hard problems is a special case when the
ratio must be all nodes must fire at the same frequency Here
the equilibrium condition is that every node will accumulate the the
same amount of energy during the global cycle Furthermore the
firings must be ordered along a minimal path
Using stochastic energy minimization and simulated annealing the
first simulations have demonstrated the feasibility of the approach
with a limited number of nodes The TSP is isomorphic to many
other sequencing problems which involve distributed constraints and
fall into the oscillator array neural net paradigm in a particularly
natural way Work is being pursued to more rigorously establish the
limits of applicability of the model
I
Annea/./ng
Figure The Traveling Salesman Problem In the global
oscillation oj minimal energy each node is constrained to fire at
the same rate in the order corresponding to the minimal path
ACKNOWLEDGEMENT
Research supported in part by Aerojet Electro-Systems under the Aerojet-UCLA Cooperative
Research Master Agreement No. and by NASA NAG

<<----------------------------------------------------------------------------------------------------------------------->>

title: 10-a-mean-field-theory-of-layer-iv-of-visual-cortex-and-its-application-to-artificial-neural-networks.pdf

A MEAN FIELD THEORY OF LAYER IV OF VISUAL CORTEX
AND ITS APPLICATION TO ARTIFICIAL NEURAL NETWORKS
Christopher L. Scofield
Center for Neural Science and Physics Department
Brown University
Providence Rhode Island
and
Nestor Inc Richmond Square Providence Rhode Island
ABSTRACT
A single cell theory for the development of selectivity and
ocular dominance in visual cortex has been presented previously
by Bienenstock Cooper and Munrol This has been extended to a
network applicable to layer IV of visual cortex In this paper
we present a mean field approximation that captures in a fairly
transparent manner the qualitative and many of the
quantitative results of the network theory Finally we consider
the application of this theory to artificial neural networks and
show that a significant reduction in architectural complexity is
possible
A SINGLE LAYER NETWORK AND THE MEAN FIELD
APPROXIMATION
We consider a single layer network of ideal neurons which
receive signals from outside of the layer and from cells within
the layer Figure The activity of the ith cell in the network is
Each cell
is a vector of afferent signals to the network
receives input from fibers outside of the cortical network
through the matrix of synapses mi Intra-layer input to each cell
is then transmitted through the matrix of cortico-cortical
synapses L.
American Institute of Physics
Afferent
Signals
m2
m1
mn
Figure The general single layer recurrent
network
Light circles are the LGN cortical
synapses
Dark circles are the nonmodifiable cortico-cortical synapses
We now expand the response of the th cell into individual
terms describing the number of cortical synapses traversed by
the signal before arriving through synapses Lij at cell
Expanding Cj in the response of cell becomes
ci
mi mj jL Ljk mk 2Ljk Lkn mn
Note that each term contains a factor of the form
This factor describes the first order effect on cell of the
cortical transformation of the signal
The mean field
approximation consists of estimating this factor to be a constant
independant of cell location
This assumption does not imply that each cell in the network is
selective to the same pattern and thus that mi Rather
the assumption is that the vector sum is a constant
This amounts to assuming that each cell in the network is
surrounded by a population of cells which represent on average
all possible pattern preferences
Thus the vector sum of the
afferent synaptic states describing these pattern preferences is a
constant independent of location
Finally if we assume that the lateral connection strengths are
a function only of i-j then Lij becomes a circular matrix so that
Lij Lji Lo constan
Then the response of the cell becomes
for I
I
where we define the spatial average of cortical cell activity in
and is the average number of intracortical synapses
Here in a manner similar to that in the theory of magnetism
we have replaced the effect of individual cortical cells by their
average effect as though all other cortical cells can be replaced
by an effective cell figure Note that we have retained all
orders of synaptic traversal of the signal
Thus we now focus on the activity of the layer after
relaxation to equilibrium In the mean field approximation we
can therefore write
where the mean field
a
with
am
and we asume that
inhibitory
Afferent
Signals
Lo the network is
on
average
Figure The single layer mean field network
Detailed connectivity between all cells of the
network is replaced with a single nonmodifiable synapse from an effective cell
LEARNING IN THE CORTICAL NETWORK
We will first consider evolution of the network according to a
synaptic modification rule that has been studied in detail for
single cells elsewhere
We consider the LGN cortical
synapses to be the site of plasticity and assume for maximum
simplicity that there is no modification of cortico-cortical
synapses Then
Lij
In what follows denotes the spatial average over cortical cells
while Cj denotes the time averaged activity of the th cortical cell
The function cj has been discussed extensively elsewhere
Here
we note that cj describes a function of the cell response that has
both hebbian and anti-hebbian regions
This leads to a very complex set of non-linear stochastic
equations that have been analyzed partially elsewhere In
general the afferent synaptic state has fixed points that are
stable and selective and unstable fixed points that are nonselective These arguments may now be generalized for the
network In the mean field approximation
The mean field a has a time dependent component This
varies as the average over all of the network modifiable
synapses and in most environmental situations should change
slowly compared to the change of the modifiable synapses to a
single cell Then in this approximation we can write
cj>[mi(a a
We see that there is a mapping
mi mica a
such that for every mj(a there exists a corresponding mapped
point mj which satisfies
the original equation for the mean field zero theory It can be
shown that for every fixed point of mj a there exists a
corresponding fixed point mj with the same selectivity and
stability properties
The fixed points are available to the
neurons if there is sufficient inhibition in the network ILo I is
sufficiently large
APPLICATION OF THE MEAN FIELD NETWORK TO
LAYER IV OF VISUAL CORTEX
Neurons in the primary visual cortex of normal adult cats are
sharply tuned for the orientation of an elongated slit of light and
most are activated by stimulation of either eye Both of these
properties--orientation selectivity and binocularity--depend on
the type of visual environment experienced during a critical
period of early postnatal development For example deprivation
of patterned input during this critical period leads to loss of
orientation selectivity while monocular deprivation results
in a dramatic shift in the ocular dominance of cortical neurons
such that most will be responsive exclusively to the open eye
The ocular dominance shift after MD is the best known and most
intensively studied type of visual cortical plasticity
The behavior of visual cortical cells in various rearing
conditions suggests that some cells respond more rapidly to
environmental changes than others
In monocular deprivation
for example some cells remain responsive to the closed eye in
spite of the very large shift of most cells to the open eye Singer
found using intracellular recording that geniculo-cortical
synapses on inhibitory interneurons are more resistant to
monocular deprivation than are synapses on pyramidal cell
dendrites Recent work suggests that the density of inhibitory
GABAergic synapses in kitten striate cortex is also unaffected by
MD during the cortical period
These results suggest that some LGN cortical synapses modify
rapidly while others modify relatively slowly with slow
modification of some cortico-cortical synapses Excitatory LGNcortical synapses into excitatory cells may be those that modify
primarily
To embody these facts we introduce two types of
LGN cortical synapses
those that modify and those
that remain relatively constant In a simple limit we have
and
We assume for simplicity and consistent with the above
physiological interpretation that these two types of synapses are
confined to two different classes of cells and that both left and
right eye have similar synapses both or both Zk on a given
cell Then for binocular cells in the mean field approximation
where binocular terms are in italics
where dl(r are the explicit left right eye time averaged signals
arriving form the LGN.
Note that contain terms from
modifiable and non-modifiable synapses
al(r
a
Under conditions of monocular deprivation the animal is reared
with one eye closed For the sake of analysis assume that the
right eye is closed and that only noise-like signals arrive at
cortex from the right eye Then the environment of the cortical
cells is
Further assume that the left eye synapses have reached their
selective fixed point selective to pattern Then
with IXil
linear analysis of the
the closed eye
Following the methods of BCM a local
function is employed to show that for
a
where A. NmIN is the ratio of the number modifiable cells to the
total number of cells in the network That is the asymptotic
state of the closed eye synapses is a scaled function of the meanfield due to non-modifiable inhibitory cortical cells The scale
of this state is set not only by the proportion of non-modifiable
cells but in addition by the averaged intracortical synaptic
strength Lo.
Thus contrasted with the mean field zero theory the deprived
eye LGN-cortical synapses do not go to zero
Rather they
approach the constant value dependent on the average inhibition
produced by the non-modifiable cells in such a way that the
asymptotic output of the cortical cell is zero it cannot be driven
by the deprived eye However lessening the effect of inhibitory
synapses by application of an inhibitory blocking agent such
as bicuculine reduces the magnitude of a so that one could once
more obtain a response from the deprived eye
We find consistent with previous theory and experiment
that most learning can occur in the LGN-cortical synapse for
inhibitory cortico-cortical synapses need not modify
Some
non-modifiable LGN-cortical synapses are required
THE MEAN FIELD APPROXIMATION AND
ARTIFICIAL NEURAL NETWORKS
The mean field approximation may be applied to networks in
which the cortico-cortical feedback is a general function of cell
activity In particular the feedback may measure the difference
between the network activity and memories of network activity
In this way a network may be used as a content addressable
memory
We have been discussing the properties of a mean
field network after equilibrium has been reached We now focus
on the detailed time dependence of the relaxation of the cell
activity to a state of equilibrium
Hopfield8 introduced a simple formalism for the analysis of
the time dependence of network activity
In this model
network activity is mapped onto a physical system in which the
state of neuron activity is considered as a particle on a potential
energy surface
Identification of the pattern occurs when the
activity relaxes to a nearby minima of the energy
Thus
mlmma are employed as the sites of memories For a Hopfield
network of neurons the intra-layer connectivity required is of
order N2. This connectivity is a significant constraint on the
practical implementation of such systems for large scale
problems Further the Hopfield model allows a storage capacity
which is limited to memories This is a result of the
proliferation of unwanted local minima in the energy surface
Recently Bachmann have proposed a model for the
relaxation of network activity in which memories of activity
patterns are the sites of negative charges and the activity
caused by a test pattern is a positive test charge Then in this
model the energy function is the electrostatic energy of the
unit test charge with the collection of charges at the memory
sites
IlL Qj I Xj I
where Jl is a vector describing the initial network activity
caused by a test pattern and Xj the site of the jth memory is
a parameter related to the network size
This model has the advantage that storage density is not
restricted by the the network size as it is in the Hopfield model
and in addition the architecture employs a connectivity of order
N.
Note that at each stage in the settling of Jl to a memory
of network activity Xj the only feedback from the network to
each cell is the scalar
Q. I Jl I
This quantity is an integrated measure of the distance of the
current network state from stored memories
Importantly this
measure is the same for all cells it is as if a single virtual cell
was computing the distance in activity space between the
current state and stored states The result of the computation is
This is a
then broadcast to all of the cells in the network
generalization of the idea that the detailed activity of each cell in
the network need not be fed back to each cell
Rather some
global measure performed by a single effective cell is all that is
sufficient in the feedback
DISCUSSION
We have been discussing a formalism for the analysis of
networks of ideal neurons based on a mean field approximation
of the detailed activity of the cells in the network We find that
a simple assumption concerning the spatial distribution of the
pattern preferences of the cells allows a great simplification of
the analysis In particular the detailed activity of the cells of
the network may be replaced with a mean field that in effect is
computed by a single effective cell
Further the application of this formalism to the cortical layer
IV of visual cortex allows the prediction that much of learning in
cortex may be localized to the LGN-cortical synaptic states and
that cortico-cortical plasticity is relatively unimportant We find
in agreement with experiment that monocular deprivation of
the cortical cells will drive closed-eye responses to zero but
chemical blockage of the cortical inhibitory pathways would
reveal non-zero closed-eye synaptic states
Finally the mean field approximation allows the development
of single layer models of memory storage that are unrestricted
in storage density but require a connectivity of order mxN This
is significant for the fabrication of practical content addressable
memories
ACKNOWLEOOEMENTS
I would like to thank Leon Cooper for many helpful discussions
and the contributions he made to this work
This work was supported by the Office of Naval Research and
the Army Research Office under contracts
and

<<----------------------------------------------------------------------------------------------------------------------->>

