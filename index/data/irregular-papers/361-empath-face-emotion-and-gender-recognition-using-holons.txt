EMPATH: Face, Emotion, and Gender Recognition Using Holons

Munro & Zipser (1987) showed that a back propagation network could be used
compression. The network is trained to simply reproduce its input, and so can
as a non-linear version of Kohonen's (1977) auto-associator. However it must
through a narrow channel of hidden units, so it must extract regularities from the
during learning. Empirical analysis of the trained network showed that the
span the principal subspace of the image vectors, with some noise on the
component due to network nonlinearity (Cottrell & Munro, 1988).

EMPATH:
Face, Emotion, and Gender
Recognition Using Ho10ns

the network uses error-correction learning, no teacher other than the input is
so the learning can be regarded as unsupervised. We suggested that this
be used for automatic feature extraction in a pattern recognition system.
approach taken here.
is shown in Figure 1. The image compression network extracts the features,
hidden unit representation so developed is given as input to one and two
')lll',......
networks which yield identity, gender, and emotion as output. In
we showed that the features developed by the model are holistic rather
fea'ture:s, that they can combine to form faces thatthe model has never been
that they form a redintegrative memory, able to complete noisy or partial
et aI., 1977). We have dubbed them holons.
J ..

Garrison w. CottreU
.
.
Computer Science and Engm~enng Dept
Institute for Neural Computati~n
University of California San Diego
La Jolla, CA 92093

Abstract
The dimens~onali~y of a set Off 1601:~ :a:~s ~~?. 10 .
female subjects IS reduced rom
........ .
network The extracted features do not correspond to
in previ~us face recognition systems (KaR
? na~e, 19~;)y' ......??.?..
d' tances between facial elements. at. er, .. ......\
f~tures we call holons. The hol.ons are fV~~ t~!
propagation networks th.at are teamed toc ~:~~~ . y
identity. feigned emouonal state. and g. f ..
....
extracted holons provide a. suf~cient basIS or
discriminations, 99% of the Idenuty .'
.t
emotion discriminations ~mong the traml: S~~d .
'ud ements of the emouons are compar .'
~et!orkS tend to confuse more distant emouons

. ..

comprised the input to the network were selected from full face pictures
and 10 males. All subjects were introductory psychology studentc; at
of California, San Diego who received partial course credit for
the procedure outlined by Galton (1878), images were aligned
eyes and mouth. These images were captured by a fraOl~ grabber,
pixels by averaging. To prevent the use of first order statistics for
were normalized to have equal brightness and variance. The
scaled to the range [0 ?.8]. Part of the training set and its
~I'; ~lIItclenl~oder are shown in Figure 2.
faceness

O~?? ?. ?~

1 Introduction and motivation
d ribe further research on the use of
.
:og:on first described in (Cottrell ~ Flemmg.
There, we demonstrated that an U~SUpe~lSed autoerIC~[llnl~\
features from faces sufficient for Idenuty
.
show that a network so trained can also recognIZe

564

gender

inputs (hiddeils from auto-associator)

Face informa.ticnextractor

b
'nrt'~iti,.....

model. (a) An image compression network is trained
4096 inputs into 40 hidden units. (b) The hiddenunits
'.:""llti1(\lr1l" are used as inputs to various recognition networks.

565

566

Cottrell and Metcalfe
Each column corresponds to one of 8 different feigned emotional eXI)r~;sioins)
(1980) has shown that subjects' judgements of adjectives describing human
be represented in a two-dimensional "emotion space" (Figure 3).
dimension can be characterized as pleasure/displeasure; the vertical <1lnllensiril
arousal/low arousal. Russell and his colleagues have shown using
scaling techniques (RusseU, 1980, 1983; Russell & Bullock, 1986) that
human emotions fallon a circle within this space. We chose adjectives from
be the emotions that we asked our subjects to feign. The adjectives for
those in the numbered circles in Figure 3. If the subject did not respond
the adjectives, others from the circled region were given as en<;ouragement
proper facial expression. We labeled these classes with one adjective from
astonished, happy, pleased, relaxed, sleepy, bored, miserable and angry.
were presented in randomized order to offset possible carry over effects.
We found that subjects were enthusiastically expressive with certain of
such as astonished and delighted. However, despite claims of negative
cued with adjectives such as miserable, bored and sleepy, the subjects
express these negative emotions very clearly.

EMPATH: Face, Emotion, and Gender Recognition Using Holons
We used a learning rate of .25 at the output layer during the first epoch in
learn the bias, or "palette", then a rate of .1 was used for the remaining
where an epoch corresponds to the presentation of all 160 images. The
used a constant learning rate of .0001. The initial weight span was .1 (+/_
no momentum or weight decay. The average squared error per unit at the
17. This corresponds to about 12 gray levels per pixel. Sample
of trained images are shown in Figure 2.
vectors produced by the hidden units of the compression network are
input to a single layer network that has a Iocalist unit for every name and a
A two-layer network with 20 hidden units is used for identifying which
adjectives that were given to the subjects pertains to each image. The
to produce .5 for the wrong answer, and 1 for the correct answer. The
is trained for 1000 epochs, which reduces the total sum squared error to
.
how performance changed with further training, we trained this
2000
epochs. 9 other networks were trained using the features from
.
network for 1000 epochs from different initial random weights for
human subjects on the same task.

3 Procedure
The whole image is input at once to our network, so the input layer is
40 hidden units, and a 64x64 output layer, with a sigmoidal activation
range [-1,11. Due to the extreme difference in fan-in at the hidden and
(4096 vs. 40), differential learning rates were used at the two layers.
learning rate led to most of the hidden units becoming pinned at full off or

correctness was that the output unit with the maximum activation must
the correct answer. The network learned to discriminate 99% of the
identity. One image of one woman was taken for another. Sex
was perfect. It was found that performance was . better on these tasks
layer. The emotion classification network performed better with a

AIAIiMEO'

M ultidim('Mional ~(':lIi"~ !nrulion

(0C'" 18

affect ~Yords.

two-dimensional emotion space extracted via multi-dimensional scaling
similarity ratings. Data from Russell (1980).
Figure 2: Three subjects and their reproductions by the cOInm:ess:ionl J'

567

EMPATH: Face, Emotion, and Gender Recognition Using Holons

568

Cottrell and Metcalfe
Table 1: Percentage hits on each emotion (Generalization in prurenlthe:seSl

delighted
pleased
relaxed
sleepy
bored
miserable
hidden layer. However, the observation during data acquisition that
are poorly portrayed was confirmed by the network's early performance
Initially, the network was much better at detecting positive states than
Later training improved some categories at the expense of others, .." ... "'~~....
network did not have enough capacity to perform all the discriminations.
tests were performed on a small set of 5 subjects (40 faces in all), with the
in parentheses in Table 1. Generalization gets w~rse with more ~in~ng,
network is becoming overtrained. The network IS best at generalization
emotions. This also suggests that the negative emotions are not easily
olir data set. The generalization results, while not spectacular, should be .
the light of the fact that thetrainirig set o~ly contain~ 20 SU?ject.s, and it
that the compression netwodc: was not tramed on the Images In thIS test set

similar to the "eigenfaces" found by Turk & Pentland (submitted) in their
components analysis of faces. Such a representation, if localized by a
such as Sanger's (1990), or as we have found in previous work develops at
rates (Cottrell & Fleming, 1990), could provide a computational basis for
cell recordings found in the STS of monkey cortex, without resorting
"grandmother" cells for each face.

with human subjects
compare our network performance to that of human subjects on the same task,
human subjects on the same discriminations the networks were required to
. ??? 10 subjects were presented with one quarter of the training set (40 images of 5
.... times in randomized order in each block (320 presentations total). On each
? of an image, the subject was asked to make a Yes/No discrimination as to
image is a good example of one of the adjective class names.
(small sample size, large heterogeneity of variance) prevented a reliable
test of the model vs. the subjects. However, it is informative to compare the
. . matrices for the two pools of subjects (the other 9 network simulations are
here). All "yes" responses to each kind of face with each adjective are summed
..
for the humans and the networks. The networks' responses were
"yes/no" responses by thresholding the outputs of the networks for each
?..
8 yes/no responses. The threshold was chosen to produce approximately
. . overall number of "yes" responses for the 10 networks as the 10 humans. The
. .. shown in Table 2. The rows correspond to the portrayals of the emotions,
are the adjectives presented with them. So, for example, across 10 subjects
45 instances of calling a "pleased" face a good example of "delighted" (out of

5 Internal representation
We investigated the representation formed by the compression network.
receptive fields of the hidden units in this network to be white noise. In
the actual features used, we recorded the hidden unit activations as the "plUlnrlt
all 160 images. We formed the covariance matrix of the hidden unit
extracted the principal components. Note that this operation
components from the distributed representation used. T~e r~sulting
decompressed for viewing purposes. The results are shown 10 Figure 4.

the tables that there is a lot of regularity in the the human subjects data
totally captured by the model. The first three emotions/adjectives form a
? do the last four. Since these adjectives are listed in the order of a tour around
?
.
of Russell's circomptex model, the confusability of nearby emotions
. the clustering of descriptive adjectives is matched by a perceptual clustering
? expressions produced by a subject in response to those adjectives. However,
? diagonal band of confusabitity, as would be predicted by the circomplex, the
ne~ath,e dimension appears to separate into two clusters. For example, anger
?
rure separated more than would be expected from Russell's circomplex
. is no "wrap-around" in this matrix). In between these two clusters, the
is seen by the subjects as compatible with nearly every facial
degree, but the "relaxed" faces rure not compatible with the first three
lIIUI,luna! categories.
while displaying some of the clustering shown in the human data, have
along the diagonals, due to having been trained on this data, and more
()nlUSJ1ons in regions where the human subjects (upper right and lower left) have
entries, such as "angry" labels on "delighted" and "pleased" faces. This
to forcing the netwodc:s to make as many responses as the humans. We
minor threshold change leads to many more responses, suggesting that we
uractll1lO' responses from the network.

Figure 4: Sixteen botons derived by PCA from hidden unit re~,nol~se:

569

570

EMPATH: Face, Emotion, and Gender RecognitioriUshlg Hol()l:ts

Cottrell and Metcalfe

several category confusions that humans do not.

Table 2: Confusion matrices for human and network subjects

astonished
delighted
pleased
relaxed
sleepy
bored

24
1
6 29
6
2 45 48 18
0
1 0 7 42 22 32
o 0 0 28 31 33
o 0 1 33 24 38
o 0 1 24 17

5
27
50
2
2
15
9

14
7
1
46
39
26
3

13
8
3
43
49
21
18

:, ~ ..:.

:

G. & Fleming, M. (1990). Face recognition using unsupervised feature
In Proceedings of the International Neural Network Conference, Paris.

'0, Munro, P.
? !.;o..ft~~,~,

& Zipser, D. (1987)~ Learning internal representations of gray
An example of extensional programming. In Proc. Ninth Annual Cognitive

Conference, Seattle, Wa.
? G.W. and Munro, P. (1988) Principal components analysis of images via back
In Proc. Soc. of Photo-Optical Instr. Eng., Cambridge, MA.

7 Holons

R., Albright. T., Gross, C., and Bruce, C. (1984). Stimulus-selective
of inferior temporal neurons in the Macaque. J. Neuroscience. 4, 2051-2062.

This work demonstrates that, at least for our data set, dimensionality reduction
preprocessing step that can maintain enough information for the recognition
term the representational units used by the compression network "holons".
than just another name for a distributed representation. By this we simply
representational element is a holon if its receptive field sub tends the whole
represented. Ideally we want to require that the infonnation in a set of
maximally distributed: i.e., the average unit entropy is maximized. The latter
eliminates grandmother cells, insures that the representation be noise resls~mt a
distributes the processing Joadeventy. A weak point of our definition is the
defining precisely the notion of a "whole object".
This definition applies to many distributed representational schemes, but does ..
to articulated ones such as the Wickelfeatures used by Rumelhart and
.
in their past tense model as these only represent portions of the verb. On the
we would not have holons for a "room", simply because we can not get a
not extend beyond our sensory surface at once. Given this meaning for
units of area 17 are not holons, but the units in Superior Temporal Sulcus
main motivation for this definition is to give an alternative notion to the ...... ntir....
one for face cells in STS (Desimone et al., 1984).


Demoristralion
processing properties of the optimal associative mappings. In Proc Inti. Conj.
?"'"r,..",ti,,. .. and Society, Wash., D.C.
.

:.

. . 1. A.


8 Conclusions
We have shown that a network model that extracts features from its "n"irr,rim
unsupervised manner can achieve near perfect recognition rales
discrimination and sex discrimination, even though the features were not
that purpose. Where categories become "fuzzier", as in emotional states,
abilities are also limited. In particular, generali7..ation to new faces is
preliminary study of human perception of these faces, we found support for
when subjects are asked to produce expressions based on "near" aUII""",'L.n~~.,,,?
space, they produce "near" expressions in perceptual space. These
positive/negative clusters much more than the circomplex model
However, this could be a fault of the subjects' abilities to portray the
rather than a fault of the Circomplex model. Finally, we cornoatred
perfonnance to that of humans. We found that the networks (when l"n"C!tr<1lin,~rl
as many responses as humans), while generally following the pattern of the
..,


